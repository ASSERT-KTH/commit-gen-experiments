BLEU SCORE: 0.5900468726392808

TEST MSG: perf ( server : sequence ) : reduce updates by key
GENERATED MSG: perf ( server : sequence ) : bulk updates writing

TEST DIFF (one line): diff - - git a / actor - server / actor - core / src / main / protobuf / sequence . proto b / actor - server / actor - core / src / main / protobuf / sequence . proto < nl > index 49d2dee . . 7ecced0 100644 < nl > - - - a / actor - server / actor - core / src / main / protobuf / sequence . proto < nl > + + + b / actor - server / actor - core / src / main / protobuf / sequence . proto < nl > @ @ - 8 , 6 + 8 , 7 @ @ option ( scalapb . options ) = { < nl > } ; < nl > < nl > import " scalapb / scalapb . proto " ; < nl > + import " google / protobuf / wrappers . proto " ; < nl > import " model / push . proto " ; < nl > import " model . proto " ; < nl > < nl > @ @ - 47 , 6 + 48 , 7 @ @ message UserSequenceCommands { < nl > message DeliverUpdate { < nl > UpdateMapping mapping = 1 ; < nl > PushRules push _ rules = 2 ; < nl > + google . protobuf . StringValue reduce _ key = 5 ; < nl > string delivery _ id = 4 ; < nl > } < nl > < nl > diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / group / GroupProcessorRegion . scala b / actor - server / actor - core / src / main / scala / im / actor / server / group / GroupProcessorRegion . scala < nl > index 3eaf83a . . 8693c9d 100644 < nl > - - - a / actor - server / actor - core / src / main / scala / im / actor / server / group / GroupProcessorRegion . scala < nl > + + + b / actor - server / actor - core / src / main / scala / im / actor / server / group / GroupProcessorRegion . scala < nl > @ @ - 6 , 6 + 6 , 8 @ @ import akka . event . Logging < nl > import im . actor . server . dialog . DialogCommands . Envelope < nl > import im . actor . server . model . { Peer , PeerType } < nl > < nl > + import scala . util . { Try , Success } < nl > + < nl > object GroupProcessorRegion { < nl > private def extractEntityId ( system : ActorSystem ) : ShardRegion . ExtractEntityId = { < nl > val log = Logging ( system , getClass ) < nl > @ @ - 15 , 9 + 17 , 9 @ @ object GroupProcessorRegion { < nl > case q : GroupQuery ⇒ ( q . groupId . toString , q ) < nl > case e @ Envelope ( peer , payload ) ⇒ peer match { < nl > case Peer ( PeerType . Group , groupId ) ⇒ < nl > - e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) match { < nl > - case Some ( any ) ⇒ ( groupId . toString , any ) < nl > - case None ⇒ < nl > + Try ( e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) ) match { < nl > + case Success ( any ) ⇒ ( groupId . toString , any ) < nl > + case _ ⇒ < nl > val error = new RuntimeException ( s " Payload not found for $ e " ) < nl > log . error ( error , error . getMessage ) < nl > throw error < nl > diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerRegion . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerRegion . scala < nl > index 6fbc993 . . 13ba687 100644 < nl > - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerRegion . scala < nl > + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerRegion . scala < nl > @ @ - 4 , 6 + 4 , 8 @ @ import akka . actor . { ActorRef , ActorSystem , Props } < nl > import akka . cluster . sharding . { ClusterSharding , ClusterShardingSettings , ShardRegion } < nl > import akka . event . Logging < nl > < nl > + import scala . util . { Success , Try } < nl > + < nl > final case class SeqUpdatesManagerRegion ( ref : ActorRef ) < nl > < nl > object SeqUpdatesManagerRegion { < nl > @ @ - 14 , 9 + 16 , 9 @ @ object SeqUpdatesManagerRegion { < nl > val log = Logging ( system , getClass ) < nl > < nl > { < nl > - case e @ Envelope ( userId , payload ) ⇒ ( userId . toString , e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) match { < nl > - case Some ( any ) ⇒ any < nl > - case None ⇒ < nl > + case e @ Envelope ( userId , payload ) ⇒ ( userId . toString , Try ( e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) ) match { < nl > + case Success ( any ) ⇒ any < nl > + case _ ⇒ < nl > val error = new RuntimeException ( s " Payload not found for $ e " ) < nl > log . error ( error , error . getMessage ) < nl > throw error < nl > diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala < nl > index eaca44f . . f0941e3 100644 < nl > - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala < nl > + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala < nl > @ @ - 4 , 6 + 4 , 7 @ @ import akka . actor . _ < nl > import akka . pattern . pipe < nl > import com . github . benmanes . caffeine . cache . Caffeine < nl > import com . google . protobuf . ByteString < nl > + import com . google . protobuf . wrappers . StringValue < nl > import im . actor . server . db . DbExtension < nl > import im . actor . server . model . { SeqUpdate , UpdateMapping } < nl > import im . actor . server . persist . sequence . UserSequenceRepo < nl > @ @ - 74 , 9 + 75 , 9 @ @ private [ sequence ] final class UserSequence ( < nl > < nl > def initialized : Receive = { < nl > case cmd : VendorPushCommand ⇒ vendorPush forward cmd < nl > - case DeliverUpdate ( mappingOpt , pushRules , deliveryId ) ⇒ < nl > + case DeliverUpdate ( mappingOpt , pushRules , reduceKey , deliveryId ) ⇒ < nl > mappingOpt match { < nl > - case Some ( mapping ) ⇒ deliver ( mapping , pushRules , deliveryId ) < nl > + case Some ( mapping ) ⇒ deliver ( mapping , pushRules , reduceKey , deliveryId ) < nl > case None ⇒ < nl > log . error ( " Empty mapping " ) < nl > } < nl > @ @ - 89 , 7 + 90 , 7 @ @ private [ sequence ] final class UserSequence ( < nl > seq ← UserSequenceRepo . fetchSeq ( userId ) map ( _ getOrElse 0 ) < nl > } yield Initialized ( seq ) ) pipeTo self < nl > < nl > - private def deliver ( mapping : UpdateMapping , pushRules : Option [ PushRules ] , deliveryId : String ) : Unit = { < nl > + private def deliver ( mapping : UpdateMapping , pushRules : Option [ PushRules ] , reduceKey : Option [ StringValue ] , deliveryId : String ) : Unit = { < nl > cached ( deliveryId ) { < nl > val seq = nextSeq ( ) < nl > < nl > @ @ - 97 , 6 + 98 , 7 @ @ private [ sequence ] final class UserSequence ( < nl > userId , < nl > seq , < nl > System . currentTimeMillis ( ) , < nl > + reduceKey , < nl > Some ( mapping ) < nl > ) < nl > < nl > diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / user / UserProcessorRegion . scala b / actor - server / actor - core / src / main / scala / im / actor / server / user / UserProcessorRegion . scala < nl > index 8e7593e . . 28319df 100644 < nl > - - - a / actor - server / actor - core / src / main / scala / im / actor / server / user / UserProcessorRegion . scala < nl > + + + b / actor - server / actor - core / src / main / scala / im / actor / server / user / UserProcessorRegion . scala < nl > @ @ - 6 , 6 + 6 , 8 @ @ import akka . event . Logging < nl > import im . actor . server . dialog . DialogCommands . Envelope < nl > import im . actor . server . model . { Peer , PeerType } < nl > < nl > + import scala . util . { Try , Success } < nl > + < nl > object UserProcessorRegion { < nl > private def extractEntityId ( system : ActorSystem ) : ShardRegion . ExtractEntityId = { < nl > val log = Logging ( system , getClass ) < nl > @ @ - 15 , 9 + 17 , 9 @ @ object UserProcessorRegion { < nl > case q : UserQuery ⇒ ( q . userId . toString , q ) < nl > case e @ Envelope ( peer , payload ) ⇒ peer match { < nl > case Peer ( PeerType . Private , userId ) ⇒ < nl > - e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) match { < nl > - case Some ( any ) ⇒ ( userId . toString , any ) < nl > - case None ⇒ < nl > + Try ( e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) ) match { < nl > + case Success ( any ) ⇒ ( userId . toString , any ) < nl > + case _ ⇒ < nl > val error = new RuntimeException ( s " Payload not found for $ e " ) < nl > log . error ( error , error . getMessage ) < nl > throw error < nl > diff - - git a / actor - server / actor - models / src / main / protobuf / model . proto b / actor - server / actor - models / src / main / protobuf / model . proto < nl > index 278815e . . a296bea 100644 < nl > - - - a / actor - server / actor - models / src / main / protobuf / model . proto < nl > + + + b / actor - server / actor - models / src / main / protobuf / model . proto < nl > @ @ - 3 , 6 + 3 , 7 @ @ syntax = ' proto3 ' ; < nl > package im . actor . server ; < nl > < nl > import " scalapb / scalapb . proto " ; < nl > + import " google / protobuf / wrappers . proto " ; < nl > < nl > option ( scalapb . options ) = { < nl > import : " im . actor . server . model . ModelTypeMappers . _ " < nl > @ @ - 24 , 6 + 25 , 7 @ @ message SeqUpdate { < nl > int32 user _ id = 1 ; < nl > int32 seq = 2 ; < nl > int64 timestamp = 3 ; < nl > + google . protobuf . StringValue reduce _ key = 5 ; < nl > UpdateMapping mapping = 4 ; < nl > } < nl > < nl > diff - - git a / actor - server / actor - persist / src / main / resources / sql / migration / V20160121182140 _ _ CreateReduceKey . sql b / actor - server / actor - persist / src / main / resources / sql / migration / V20160121182140 _ _ CreateReduceKey . sql < nl > new file mode 100644 < nl > index 0000000 . . ca6a2d5 < nl > - - - / dev / null < nl > + + + b / actor - server / actor - persist / src / main / resources / sql / migration / V20160121182140 _ _ CreateReduceKey . sql < nl > @ @ - 0 , 0 + 1 , 2 @ @ < nl > + ALTER TABLE user _ sequence ADD COLUMN reduce _ key TEXT ; < nl > + CREATE INDEX on user _ sequence ( user _ id , reduce _ key , seq ) ; < nl > \ No newline at end of file < nl > diff - - git a / actor - server / actor - persist / src / main / scala / im / actor / server / db / ActorPostgresDriver . scala b / actor - server / actor - persist / src / main / scala / im / actor / server / db / ActorPostgresDriver . scala < nl > index 20a7fa3 . . a1757d5 100644 < nl > - - - a / actor - server / actor - persist / src / main / scala / im / actor / server / db / ActorPostgresDriver . scala < nl > + + + b / actor - server / actor - persist / src / main / scala / im / actor / server / db / ActorPostgresDriver . scala < nl > @ @ - 2 , 6 + 2 , 7 @ @ package im . actor . server . db < nl > < nl > import com . github . tminglei . slickpg . _ < nl > import com . google . protobuf . ByteString < nl > + import com . google . protobuf . wrappers . StringValue < nl > < nl > trait ByteStringImplicits { < nl > < nl > @ @ - 13 , 6 + 14 , 15 @ @ trait ByteStringImplicits { < nl > ) < nl > } < nl > < nl > + trait ProtoWrappersImplicits { < nl > + import slick . driver . PostgresDriver . api . _ < nl > + < nl > + implicit val stringValueColumnType = MappedColumnType . base [ StringValue , String ] ( < nl > + { sv ⇒ sv . value } , < nl > + { s ⇒ StringValue ( s ) } < nl > + ) < nl > + } < nl > + < nl > trait ActorPostgresDriver extends ExPostgresDriver < nl > with PgDateSupport < nl > with PgDate2Support < nl > @ @ - 20 , 7 + 30 , 7 @ @ trait ActorPostgresDriver extends ExPostgresDriver < nl > with PgLTreeSupport { < nl > < nl > override val api = < nl > - new API with ArrayImplicits with LTreeImplicits with DateTimeImplicits with ByteStringImplicits < nl > + new API with ArrayImplicits with LTreeImplicits with DateTimeImplicits with ByteStringImplicits with ProtoWrappersImplicits < nl > } < nl > < nl > object ActorPostgresDriver extends ActorPostgresDriver < nl > \ No newline at end of file < nl > diff - - git a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala b / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala < nl > index f225350 . . 0d8f9d4 100644 < nl > - - - a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala < nl > + + + b / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala < nl > @ @ - 1 , 5 + 1 , 6 @ @ < nl > package im . actor . server . persist . sequence < nl > < nl > + import com . google . protobuf . wrappers . StringValue < nl > import im . actor . server . db . ActorPostgresDriver . api . _ < nl > import im . actor . server . model . { UpdateMapping , SeqUpdate } < nl > < nl > @ @ - 7 , 16 + 8 , 27 @ @ private [ sequence ] final class UserSequenceTable ( tag : Tag ) extends Table [ SeqUpdat < nl > def userId = column [ Int ] ( " user _ id " , O . PrimaryKey ) < nl > def seq = column [ Int ] ( " seq " , O . PrimaryKey ) < nl > def timestamp = column [ Long ] ( " timestamp " ) < nl > + def reduceKey = column [ Option [ StringValue ] ] ( " reduce _ key " ) < nl > def mapping = column [ Array [ Byte ] ] ( " mapping " ) < nl > < nl > - def * = ( userId , seq , timestamp , mapping ) < > ( applySeqUpdate . tupled , unapplySeqUpdate ) < nl > + def * = ( userId , seq , timestamp , reduceKey , mapping ) < > ( applySeqUpdate . tupled , unapplySeqUpdate ) < nl > < nl > - private def applySeqUpdate : ( Int , Int , Long , Array [ Byte ] ) ⇒ SeqUpdate = { < nl > - ( userId , seq , timestamp , mapping ) ⇒ SeqUpdate ( userId , seq , timestamp , Some ( UpdateMapping . parseFrom ( mapping ) ) ) < nl > + private def applySeqUpdate : ( Int , Int , Long , Option [ StringValue ] , Array [ Byte ] ) ⇒ SeqUpdate = { < nl > + ( userId , seq , timestamp , reduceKey , mapping ) ⇒ < nl > + SeqUpdate ( userId , seq , timestamp , reduceKey , Some ( UpdateMapping . parseFrom ( mapping ) ) ) < nl > } < nl > < nl > - private def unapplySeqUpdate : SeqUpdate ⇒ Option [ ( Int , Int , Long , Array [ Byte ] ) ] = { < nl > - seqUpdate ⇒ Some ( ( seqUpdate . userId , seqUpdate . seq , seqUpdate . timestamp , seqUpdate . mapping . map ( _ . toByteArray ) . getOrElse ( Array . empty ) ) ) < nl > + private def unapplySeqUpdate : SeqUpdate ⇒ Option [ ( Int , Int , Long , Option [ StringValue ] , Array [ Byte ] ) ] = { < nl > + seqUpdate ⇒ < nl > + Some ( < nl > + ( < nl > + seqUpdate . userId , < nl > + seqUpdate . seq , < nl > + seqUpdate . timestamp , < nl > + seqUpdate . reduceKey , < nl > + seqUpdate . mapping . map ( _ . toByteArray ) . getOrElse ( Array . empty ) < nl > + ) < nl > + ) < nl > } < nl > } < nl > < nl > @ @ - 27 , 7 + 39 , 20 @ @ object UserSequenceRepo { < nl > < nl > private def byUser ( userId : Rep [ Int ] ) = sequence . filter ( _ . userId = = = userId ) < nl > < nl > - private def byUserAfterSeq ( userId : Rep [ Int ] , seq : Rep [ Int ] , limit : ConstColumn [ Long ] ) = byUser ( userId ) . filter ( _ . seq > seq ) . sortBy ( _ . seq . asc ) . take ( limit ) < nl > + private def byUserAfterSeq ( userId : Rep [ Int ] , seq : Rep [ Int ] , limit : ConstColumn [ Long ] ) = < nl > + byUser ( userId ) < nl > + . filter ( _ . seq > seq ) < nl > + . sortBy ( _ . seq . asc ) < nl > + . filter { notReduced ⇒ < nl > + notReduced . reduceKey . isEmpty | | < nl > + notReduced . seq . in ( < nl > + byUser ( userId ) < nl > + . filter ( _ . reduceKey = = = notReduced . reduceKey ) < nl > + . groupBy ( _ . reduceKey ) < nl > + . map ( _ . _ 2 . map ( _ . seq ) . max ) < nl > + ) < nl > + } < nl > + . take ( limit ) < nl > < nl > private val userSequence = Compiled ( byUserAfterSeq _ ) < nl > < nl > diff - - git a / actor - server / actor - session / src / main / scala / im / actor / server / session / Session . scala b / actor - server / actor - session / src / main / scala / im / actor / server / session / Session . scala < nl > index dd9a910 . . 373271c 100644 < nl > - - - a / actor - server / actor - session / src / main / scala / im / actor / server / session / Session . scala < nl > + + + b / actor - server / actor - session / src / main / scala / im / actor / server / session / Session . scala < nl > @ @ - 26 , 6 + 26 , 7 @ @ import slick . driver . PostgresDriver . api . _ < nl > import scala . collection . immutable < nl > import scala . concurrent . ExecutionContext < nl > import scala . concurrent . duration . _ < nl > + import scala . util . { Success , Try } < nl > < nl > final case class SessionConfig ( idleTimeout : Duration , reSendConfig : ReSenderConfig ) < nl > < nl > @ @ - 42 , 9 + 43 , 9 @ @ object Session { < nl > < nl > private [ this ] val extractEntityId : ShardRegion . ExtractEntityId = { < nl > case env @ SessionEnvelope ( authId , sessionId , payload ) ⇒ < nl > - env . getField ( SessionEnvelope . descriptor . findFieldByNumber ( payload . number ) ) match { < nl > - case Some ( any ) ⇒ s " $ { authId } _ $ sessionId " → any < nl > - case None ⇒ throw new RuntimeException ( s " Empty payload $ env " ) < nl > + Try ( env . getField ( SessionEnvelope . descriptor . findFieldByNumber ( payload . number ) ) ) match { < nl > + case Success ( any ) ⇒ s " $ { authId } _ $ sessionId " → any < nl > + case _ ⇒ throw new RuntimeException ( s " Empty payload $ env " ) < nl > } < nl > } < nl > < nl > diff - - git a / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / UserSequenceSpec . scala b / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / UserSequenceSpec . scala < nl > index ff68b98 . . ef9bc00 100644 < nl > - - - a / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / UserSequenceSpec . scala < nl > + + + b / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / UserSequenceSpec . scala < nl > @ @ - 3 , 10 + 3 , 12 @ @ package im . actor . server . sequence < nl > import akka . pattern . ask < nl > import akka . testkit . _ < nl > import com . google . protobuf . ByteString < nl > + import com . google . protobuf . wrappers . StringValue < nl > import com . typesafe . config . _ < nl > - import im . actor . api . rpc . contacts . UpdateContactsAdded < nl > + import im . actor . api . rpc . contacts . { UpdateContactRegistered , UpdateContactsAdded } < nl > import im . actor . server . _ < nl > import im . actor . server . model . { SerializedUpdate , UpdateMapping } < nl > + import im . actor . server . persist . sequence . UserSequenceRepo < nl > import im . actor . server . sequence . UserSequenceCommands . { DeliverUpdate , Envelope } < nl > import org . scalatest . time . { Seconds , Span } < nl > < nl > @ @ - 23 , 6 + 25 , 8 @ @ final class UserSequenceSpec extends BaseAppSuite ( < nl > < nl > it should " not reply with seq of the ongoing update ( concurrency problem ) " in e2 < nl > < nl > + it should " reduce updates " in reduceUpdates < nl > + < nl > override implicit def patienceConfig : PatienceConfig = < nl > new PatienceConfig ( timeout = Span ( 10 , Seconds ) ) < nl > < nl > @ @ - 105 , 4 + 109 , 49 @ @ final class UserSequenceSpec extends BaseAppSuite ( < nl > } < nl > } < nl > } < nl > + < nl > + def reduceUpdates ( ) = { < nl > + val ( user , _ , _ , _ ) = createUser ( ) < nl > + < nl > + val update = UpdateContactsAdded ( Vector ( 1 , 2 , 3 ) ) < nl > + val deliverUpd = DeliverUpdate ( < nl > + mapping = Some ( UpdateMapping ( Some ( SerializedUpdate ( < nl > + header = update . header , < nl > + body = ByteString . copyFrom ( update . toByteArray ) , < nl > + userIds = update . _ relatedUserIds , < nl > + groupIds = update . _ relatedGroupIds < nl > + ) ) ) ) < nl > + ) < nl > + < nl > + val updateSame = UpdateContactRegistered ( 1 , isSilent = false , 0L , 0L ) < nl > + val deliverUpdSame = DeliverUpdate ( < nl > + reduceKey = Some ( StringValue ( " same " ) ) , < nl > + mapping = Some ( UpdateMapping ( Some ( SerializedUpdate ( < nl > + header = updateSame . header , < nl > + body = ByteString . copyFrom ( updateSame . toByteArray ) , < nl > + userIds = update . _ relatedUserIds , < nl > + groupIds = update . _ relatedGroupIds < nl > + ) ) ) ) < nl > + ) < nl > + < nl > + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpd ) ) ( identity ) < nl > + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpd ) ) ( identity ) < nl > + < nl > + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpdSame ) ) ( identity ) < nl > + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpdSame ) ) ( identity ) < nl > + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpdSame ) ) ( identity ) < nl > + < nl > + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpd ) ) ( identity ) < nl > + < nl > + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpdSame ) ) ( identity ) < nl > + < nl > + whenReady ( db . run ( UserSequenceRepo . fetchAfterSeq ( user . id , 0 , 100L ) ) ) { updates ⇒ < nl > + updates . map ( _ . mapping . get . default . get . header ) shouldBe Seq ( < nl > + UpdateContactsAdded . header , < nl > + UpdateContactsAdded . header , < nl > + UpdateContactsAdded . header , < nl > + UpdateContactRegistered . header < nl > + ) < nl > + } < nl > + } < nl > } < nl > diff - - git a / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / V20151108011300 _ _ FillUserSequenceSpec . scala b / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / V20151108011300 _ _ FillUserSequenceSpec . scala < nl > index a465f48 . . 99805ba 100644 < nl > - - - a / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / V20151108011300 _ _ FillUserSequenceSpec . scala < nl > + + + b / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / V20151108011300 _ _ FillUserSequenceSpec . scala < nl > @ @ - 18 , 11 + 18 , 11 @ @ final class V20151108011300 _ _ FillUserSequenceSpec extends BaseAppSuite with Impl < nl > it should " properly migrate updates from authId with max sequence " in maxSeq < nl > it should " migrate new updates on second run " in secondRun < nl > < nl > - implicit val getSeqUpdate = GetResult [ SeqUpdate ] ( r ⇒ SeqUpdate ( < nl > + implicit val getSeqUpdate = GetResult [ New ] ( r ⇒ New ( < nl > userId = r . nextInt ( ) , < nl > seq = r . nextInt ( ) , < nl > timestamp = r . nextLong ( ) , < nl > - mapping = Some ( UpdateMapping . parseFrom ( r . nextBytes ( ) ) ) < nl > + mapping = UpdateMapping . parseFrom ( r . nextBytes ( ) ) . toByteArray < nl > ) ) < nl > < nl > def maxSeq ( ) = { < nl > @ @ - 74 , 18 + 74 , 18 @ @ final class V20151108011300 _ _ FillUserSequenceSpec extends BaseAppSuite with Impl < nl > < nl > private def checkValidSeq ( userId : Int , oldestAuthId : Long ) : Unit = { < nl > Await . result ( db . run ( for { < nl > - seqs ← sql " " " SELECT * FROM user _ sequence WHERE user _ id = $ userId ORDER BY seq ASC " " " . as [ SeqUpdate ] < nl > + seqs ← sql " " " SELECT * FROM user _ sequence WHERE user _ id = $ userId ORDER BY seq ASC " " " . as [ New ] < nl > obsSeq ← sql " " " SELECT seq FROM seq _ updates _ ngen WHERE auth _ id = $ oldestAuthId ORDER BY timestamp DESC LIMIT 1 " " " < nl > . as [ Int ] . headOption . map ( _ . getOrElse ( 0 ) ) < nl > } yield { < nl > - assert ( seqs . size . toInt = = obsSeq , " wrong sequence size " ) < nl > + assert ( seqs . size . toInt = = obsSeq . toInt , " wrong sequence size " ) < nl > < nl > seqs . zipWithIndex foreach { < nl > - case ( SeqUpdate ( ` userId ` , seq , timestamp , Some ( mappingBytes ) ) , index ) ⇒ < nl > + case ( New ( ` userId ` , seq , timestamp , mappingBytes ) , index ) ⇒ < nl > assert ( index + 1 = = seq , " seq is broken " ) < nl > val seqUpd = < nl > UpdateMapping < nl > - . parseFrom ( mappingBytes . toByteArray ) < nl > + . parseFrom ( mappingBytes ) < nl > . getDefault < nl > < nl > assert ( seqUpd . header = = UpdateContactsAdded . header , " wrong header " ) < nl > diff - - git a / actor - server / project / Dependencies . scala b / actor - server / project / Dependencies . scala < nl > index 5e32937 . . e4bdcf8 100644 < nl > - - - a / actor - server / project / Dependencies . scala < nl > + + + b / actor - server / project / Dependencies . scala < nl > @ @ - 17 , 7 + 17 , 7 @ @ object Dependencies { < nl > val slickPg = " 0 . 10 . 2 " < nl > val scalatest = " 2 . 2 . 4 " < nl > val shardakka = " 0 . 1 . 20 " < nl > - val scalapbSer = " 0 . 1 . 6 " < nl > + val scalapbSer = " 0 . 1 . 9 " < nl > } < nl > < nl > object Compile {
NEAREST DIFF (one line): diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / BatchUpdatesWriter . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / BatchUpdatesWriter . scala < nl > index efbc692 . . 3203bdd 100644 < nl > - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / BatchUpdatesWriter . scala < nl > + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / BatchUpdatesWriter . scala < nl > @ @ - 4 , 24 + 4 , 27 @ @ import java . util . concurrent . TimeUnit < nl > < nl > import akka . actor . _ < nl > import im . actor . server . db . DbExtension < nl > - import scala . collection . immutable < nl > - import im . actor . server . persist < nl > - import im . actor . server . model < nl > + import im . actor . server . model . SeqUpdate < nl > + import im . actor . server . persist . sequence . UserSequenceRepo < nl > < nl > - import scala . concurrent . { Promise , ExecutionContext , Future } < nl > + import scala . collection . immutable < nl > import scala . concurrent . duration . _ < nl > + import scala . concurrent . { ExecutionContext , Future , Promise } < nl > import scala . util . { Failure , Success } < nl > < nl > private [ sequence ] object BatchUpdatesWriter { < nl > - final case class Enqueue ( update : model . sequence . SeqUpdateObsolete , promise : Promise [ Unit ] ) < nl > < nl > - private final case object Resume < nl > - private final case object ScheduledFlush < nl > + final case class Enqueue ( update : SeqUpdate , promise : Promise [ Unit ] ) < nl > + < nl > + private case object Resume < nl > + < nl > + private case object ScheduledFlush < nl > < nl > def props = Props ( classOf [ BatchUpdatesWriter ] ) < nl > } < nl > < nl > private [ sequence ] class BatchUpdatesWriter extends Actor with ActorLogging with Stash { < nl > + < nl > import BatchUpdatesWriter . _ < nl > < nl > private val MaxUpdatesBatchSize = context . system . settings . config . getInt ( " sequence . max - updates - batch - size " ) < nl > @ @ - 30 , 7 + 33 , 7 @ @ private [ sequence ] class BatchUpdatesWriter extends Actor with ActorLogging with < nl > private val db = DbExtension ( context . system ) . db < nl > private implicit val ec : ExecutionContext = context . dispatcher < nl > < nl > - private [ this ] var queue = immutable . Queue . empty [ model . sequence . SeqUpdateObsolete ] < nl > + private [ this ] var queue = immutable . Queue . empty [ SeqUpdate ] < nl > private [ this ] var senders = immutable . Queue . empty [ Promise [ Unit ] ] < nl > private [ this ] var scheduledFlush : Option [ Cancellable ] = None < nl > < nl > @ @ - 48 , 7 + 51 , 7 @ @ private [ sequence ] class BatchUpdatesWriter extends Actor with ActorLogging with < nl > case msg ⇒ stash ( ) < nl > } < nl > < nl > - private def enqueue ( update : model . sequence . SeqUpdateObsolete , promise : Promise [ Unit ] ) : Unit = { < nl > + private def enqueue ( update : SeqUpdate , promise : Promise [ Unit ] ) : Unit = { < nl > this . queue = this . queue . enqueue ( update ) < nl > this . senders = this . senders . enqueue ( promise ) < nl > < nl > @ @ - 83 , 8 + 86 , 8 @ @ private [ sequence ] class BatchUpdatesWriter extends Actor with ActorLogging with < nl > } < nl > } < nl > < nl > - private def batchWrite ( updates : Seq [ model . sequence . SeqUpdateObsolete ] ) : Future [ Unit ] = < nl > - db . run ( persist . sequence . SeqUpdateRepo . createBulk ( updates ) ) map ( _ ⇒ ( ) ) < nl > + private def batchWrite ( updates : Seq [ SeqUpdate ] ) : Future [ Unit ] = < nl > + db . run ( UserSequenceRepo . create ( updates ) ) map ( _ ⇒ ( ) ) < nl > < nl > override def postRestart ( reason : Throwable ) : Unit = { < nl > log . error ( reason , " Failed " ) < nl > diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesExtension . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesExtension . scala < nl > index 70a036a . . 6d71b3a 100644 < nl > - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesExtension . scala < nl > + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesExtension . scala < nl > @ @ - 1 , 7 + 1 , 7 @ @ < nl > package im . actor . server . sequence < nl > < nl > import akka . actor . _ < nl > - import akka . cluster . pubsub . { DistributedPubSubMediator , DistributedPubSub } < nl > + import akka . cluster . pubsub . { DistributedPubSub , DistributedPubSubMediator } < nl > import akka . pattern . ask < nl > import akka . util . Timeout < nl > import com . google . protobuf . ByteString < nl > @ @ - 9 , 8 + 9 , 7 @ @ import im . actor . api . rpc . Update < nl > import im . actor . api . rpc . messaging . UpdateMessage < nl > import im . actor . server . db . DbExtension < nl > import im . actor . server . model . _ < nl > - import im . actor . server . model . sequence . SeqUpdateObsolete < nl > - import im . actor . server . model . push . { GooglePushCredentials ⇒ GooglePushCredentialsModel , ApplePushCredentials ⇒ ApplePushCredentialsModel } < nl > + import im . actor . server . model . push . { ApplePushCredentials ⇒ ApplePushCredentialsModel , GooglePushCredentials ⇒ GooglePushCredentialsModel } < nl > import im . actor . server . persist . sequence . UserSequenceRepo < nl > import slick . dbio . DBIO < nl > < nl > @ @ - 153 , 7 + 152 , 7 @ @ final class SeqUpdatesExtension ( < nl > < nl > def deleteApplePushCredentials ( token : Array [ Byte ] ) : Future [ Unit ] = Future . successful ( ( ) ) < nl > < nl > - def persistUpdate ( update : SeqUpdateObsolete ) : Future [ Unit ] = { < nl > + def persistUpdate ( update : SeqUpdate ) : Future [ Unit ] = { < nl > val promise = Promise [ Unit ] ( ) < nl > writer ! BatchUpdatesWriter . Enqueue ( update , promise ) < nl > promise . future < nl > diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerActor . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerActor . scala < nl > index e049584 . . aa9e4c7 100644 < nl > - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerActor . scala < nl > + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerActor . scala < nl > @ @ - 22 , 7 + 22 , 6 @ @ import im . actor . server . db . DbExtension < nl > import im . actor . server . persist . HistoryMessageRepo < nl > import im . actor . server . { persist ⇒ p } < nl > import im . actor . server . model . push . { ApplePushCredentials ⇒ ApplePushCredentialsModel , GooglePushCredentials ⇒ GooglePushCredentialsModel } < nl > - import im . actor . server . model . sequence . { SeqUpdateObsolete ⇒ SeqUpdateModel } < nl > < nl > / * < nl > trait SeqUpdatesManagerMessage { < nl > diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala < nl > index fa2ebe1 . . c839d2b 100644 < nl > - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala < nl > + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala < nl > @ @ - 11 , 6 + 11 , 7 @ @ import im . actor . server . persist . sequence . UserSequenceRepo < nl > < nl > import scala . concurrent . Future < nl > import scala . language . postfixOps < nl > + import scala . util . { Failure , Success } < nl > < nl > object UserSequence { < nl > def topic ( userId : Int ) : String = s " sequence . $ userId " < nl > @ @ - 40 , 12 + 41 , 13 @ @ private [ sequence ] final class UserSequence extends Actor with ActorLogging with < nl > import context . dispatcher < nl > < nl > private val db = DbExtension ( context . system ) . db < nl > + private val seqUpdExt = SeqUpdatesExtension ( context . system ) < nl > < nl > val userId = self . path . name . toInt < nl > < nl > private val mediator = DistributedPubSub ( context . system ) . mediator < nl > < nl > - val deliveryCache = Caffeine . newBuilder ( ) . maximumSize ( 100 ) . executor ( context . dispatcher ) . build [ String , SeqState ] ( ) < nl > + private val deliveryCache = Caffeine . newBuilder ( ) . maximumSize ( 100 ) . executor ( context . dispatcher ) . build [ String , SeqState ] ( ) < nl > < nl > init ( ) < nl > < nl > @ @ - 71 , 13 + 73 , 6 @ @ private [ sequence ] final class UserSequence extends Actor with ActorLogging with < nl > sender ( ) ! SeqState ( getSeq ) < nl > } < nl > < nl > - private def becomeStashing ( f : ActorRef ⇒ Receive ) : Unit = < nl > - context . become ( f ( sender ( ) ) orElse stashing , discardOld = false ) < nl > - < nl > - private def stashing : Receive = { < nl > - case msg ⇒ stash ( ) < nl > - } < nl > - < nl > private def init ( ) : Unit = < nl > db . run ( UserSequenceRepo . fetchSeq ( userId ) ) map ( seqOpt ⇒ Initialized ( seqOpt . getOrElse ( 0 ) ) ) pipeTo self < nl > < nl > @ @ - 92 , 21 + 87 , 9 @ @ private [ sequence ] final class UserSequence extends Actor with ActorLogging with < nl > Some ( mapping ) < nl > ) < nl > < nl > - becomeStashing ( replyTo ⇒ { < nl > - case s : SeqState ⇒ < nl > - unstashAll ( ) < nl > - context . unbecome ( ) < nl > - < nl > - mediator ! Publish ( topic ( userId ) , UserSequenceEvents . NewUpdate ( Some ( seqUpdate ) , pushRules , ByteString . EMPTY ) ) < nl > - case s @ Status . Failure ( e ) ⇒ < nl > - log . error ( e , " Failed to write seq update : { } " , seqUpdate ) < nl > - replyTo ! s < nl > - < nl > - unstashAll ( ) < nl > - context . unbecome ( ) < nl > - } ) < nl > - < nl > - writeToDb ( seqUpdate ) map ( _ ⇒ SeqState ( seq ) ) pipeTo self < nl > + writeToDb ( seqUpdate ) map ( _ ⇒ SeqState ( seq ) ) andThen { < nl > + case Success ( _ ) ⇒ mediator ! Publish ( topic ( userId ) , UserSequenceEvents . NewUpdate ( Some ( seqUpdate ) , pushRules , ByteString . EMPTY ) ) < nl > + } < nl > } < nl > } < nl > < nl > @ @ - 116 , 10 + 99 , 13 @ @ private [ sequence ] final class UserSequence extends Actor with ActorLogging with < nl > case Some ( seqstate ) ⇒ Future . successful ( seqstate ) < nl > case None ⇒ f < nl > } < nl > - } else f ) pipeTo sender ( ) onSuccess { case s ⇒ deliveryCache . put ( deliveryId , s ) } < nl > + } else f ) pipeTo sender ( ) onComplete { < nl > + case Success ( s ) ⇒ deliveryCache . put ( deliveryId , s ) < nl > + case Failure ( e ) ⇒ log . error ( e , " Failed to deliver " ) < nl > + } < nl > } < nl > < nl > - private def writeToDb ( seqUpdate : SeqUpdate ) : Future [ Unit ] = db . run ( UserSequenceRepo . create ( seqUpdate ) ) map ( _ ⇒ ( ) ) < nl > + private def writeToDb ( seqUpdate : SeqUpdate ) : Future [ Unit ] = seqUpdExt . persistUpdate ( seqUpdate ) < nl > < nl > override def preRestart ( reason : Throwable , message : Option [ Any ] ) : Unit = { < nl > super . preRestart ( reason , message ) < nl > diff - - git a / actor - server / actor - models / src / main / scala / im / actor / server / model / sequence / SeqUpdateObsolete . scala b / actor - server / actor - models / src / main / scala / im / actor / server / model / sequence / SeqUpdateObsolete . scala < nl > deleted file mode 100644 < nl > index aa82bc4 . . 0000000 < nl > - - - a / actor - server / actor - models / src / main / scala / im / actor / server / model / sequence / SeqUpdateObsolete . scala < nl > + + + / dev / null < nl > @ @ - 1 , 4 + 0 , 0 @ @ < nl > - package im . actor . server . model . sequence < nl > - < nl > - case class SeqUpdateObsolete ( authId : Long , timestamp : Long , seq : Int , header : Int , serializedData : Array [ Byte ] , userIds : Set [ Int ] , groupIds : Set [ Int ] ) < nl > - < nl > diff - - git a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / SeqUpdateRepo . scala b / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / SeqUpdateRepo . scala < nl > deleted file mode 100644 < nl > index dc7246d . . 0000000 < nl > - - - a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / SeqUpdateRepo . scala < nl > + + + / dev / null < nl > @ @ - 1 , 72 + 0 , 0 @ @ < nl > - package im . actor . server . persist . sequence < nl > - < nl > - import slick . driver . PostgresDriver . api . _ < nl > - < nl > - import im . actor . server . model < nl > - < nl > - final class SeqUpdateTable ( tag : Tag ) extends Table [ model . sequence . SeqUpdateObsolete ] ( tag , " seq _ updates _ ngen " ) { < nl > - def authId = column [ Long ] ( " auth _ id " , O . PrimaryKey ) < nl > - < nl > - def timestamp = column [ Long ] ( " timestamp " ) < nl > - < nl > - def seq = column [ Int ] ( " seq " ) < nl > - < nl > - def header = column [ Int ] ( " header " ) < nl > - < nl > - def serializedData = column [ Array [ Byte ] ] ( " serialized _ data " ) < nl > - < nl > - def userIds = column [ String ] ( " user _ ids _ str " ) < nl > - < nl > - def groupIds = column [ String ] ( " group _ ids _ str " ) < nl > - < nl > - def * = ( authId , timestamp , seq , header , serializedData , userIds , groupIds ) < > ( ( toModel _ ) . tupled , fromModel ) < nl > - < nl > - private def toModel ( authId : Long , timestamp : Long , seq : Int , header : Int , serializedData : Array [ Byte ] , userIdsStr : String , groupIdsStr : String ) : model . sequence . SeqUpdateObsolete = { < nl > - model . sequence . SeqUpdateObsolete ( authId , timestamp , seq , header , serializedData , toIntSet ( userIdsStr ) , toIntSet ( groupIdsStr ) ) < nl > - } < nl > - < nl > - private def fromModel ( update : model . sequence . SeqUpdateObsolete ) = < nl > - Some ( ( update . authId , update . timestamp , update . seq , update . header , update . serializedData , update . userIds . mkString ( " , " ) , update . groupIds . mkString ( " , " ) ) ) < nl > - < nl > - private def toIntSet ( str : String ) : Set [ Int ] = { < nl > - if ( str . isEmpty ) { < nl > - Set . empty < nl > - } else { < nl > - str . split ( ' , ' ) . map ( x ⇒ x . toInt ) . toSet < nl > - } < nl > - } < nl > - } < nl > - < nl > - object SeqUpdateRepo { < nl > - val updates = TableQuery [ SeqUpdateTable ] < nl > - < nl > - val DiffStep = 100L < nl > - < nl > - val updatesC = Compiled ( updates ) < nl > - < nl > - def afterTimestamp ( authId : Rep [ Long ] , timestamp : Rep [ Long ] , limit : ConstColumn [ Long ] ) = < nl > - updates . filter ( u ⇒ u . authId = = = authId & & u . timestamp > timestamp ) . sortBy ( _ . timestamp . asc ) . take ( limit ) < nl > - def last ( authId : Rep [ Long ] ) = < nl > - updates . filter ( _ . authId = = = authId ) . sortBy ( _ . timestamp . desc ) . take ( 1 ) < nl > - def byAuthId ( authId : Rep [ Long ] ) = < nl > - updates . filter ( _ . authId = = = authId ) . sortBy ( _ . timestamp . desc ) < nl > - < nl > - val afterTimestampC = Compiled ( afterTimestamp _ ) < nl > - val lastC = Compiled ( last _ ) < nl > - val byAuthIdC = Compiled ( byAuthId _ ) < nl > - < nl > - def create ( update : model . sequence . SeqUpdateObsolete ) = < nl > - updatesC + = update < nl > - < nl > - def createBulk ( newUpdates : Seq [ model . sequence . SeqUpdateObsolete ] ) = < nl > - updatesC + + = newUpdates < nl > - < nl > - def findLast ( authId : Long ) = < nl > - lastC ( authId ) . result . headOption < nl > - < nl > - def find ( authId : Long ) = < nl > - byAuthIdC ( authId ) . result < nl > - < nl > - def findAfter ( authId : Long , timestamp : Long ) = < nl > - afterTimestampC ( ( authId , timestamp , DiffStep ) ) . result < nl > - } < nl > diff - - git a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala b / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala < nl > index 5e3f1cb . . f225350 100644 < nl > - - - a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala < nl > + + + b / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala < nl > @ @ - 35 , 7 + 35 , 7 @ @ object UserSequenceRepo { < nl > byUser _ andThen ( _ . sortBy ( _ . seq . desc ) . map ( _ . seq ) . take ( 1 ) ) < nl > } < nl > < nl > - def create ( updates : Seq [ SeqUpdate ] ) = sequenceC + + = updates < nl > + def create ( updates : Seq [ SeqUpdate ] ) = ( sequenceC + + = updates ) . transactionally < nl > < nl > def create ( update : SeqUpdate ) = sequenceC + = update < nl > < nl > diff - - git a / actor - server / actor - tests / src / test / scala / im / actor / server / api / rpc / service / SequenceServiceSpec . scala b / actor - server / actor - tests / src / test / scala / im / actor / server / api / rpc / service / SequenceServiceSpec . scala < nl > index e8c5d07 . . 0b2b060 100644 < nl > - - - a / actor - server / actor - tests / src / test / scala / im / actor / server / api / rpc / service / SequenceServiceSpec . scala < nl > + + + b / actor - server / actor - tests / src / test / scala / im / actor / server / api / rpc / service / SequenceServiceSpec . scala < nl > @ @ - 7 , 13 + 7 , 12 @ @ import im . actor . api . rpc . messaging . { ApiTextMessage , UpdateMessageContentChanged < nl > import im . actor . api . rpc . misc . ResponseSeq < nl > import im . actor . api . rpc . peers . { ApiPeer , ApiPeerType } < nl > import im . actor . api . rpc . sequence . { ApiDifferenceUpdate , ResponseGetDifference } < nl > - import im . actor . concurrent . FutureExt < nl > import im . actor . server . _ < nl > import im . actor . server . api . rpc . service . sequence . SequenceServiceConfig < nl > import im . actor . server . sequence . SeqUpdatesExtension < nl > < nl > import scala . concurrent . duration . _ < nl > - import scala . concurrent . Await < nl > + import scala . concurrent . { Future , Await } < nl > < nl > final class SequenceServiceSpec extends BaseAppSuite ( { < nl > ActorSpecification . createSystem ( < nl > @ @ - 29 , 7 + 28 , 7 @ @ final class SequenceServiceSpec extends BaseAppSuite ( { < nl > < nl > it should " get state " in getState < nl > it should " get difference " in getDifference < nl > - it should " get difference if there is one update bigger than difference size limit " in bigUpdate < nl > + it should " not produce empty difference if there is one update bigger than difference size limit " in bigUpdate < nl > < nl > private val config = SequenceServiceConfig . load ( ) . get < nl > private lazy val seqUpdExt = SeqUpdatesExtension ( system ) < nl > @ @ - 65 , 10 + 64 , 10 @ @ final class SequenceServiceSpec extends BaseAppSuite ( { < nl > < nl > / / serialized update size is : 40 bytes for body + 4 bytes for header , 44 bytes total < nl > / / with max update size of 20 KiB 1281 updates should split into three parts < nl > - Await . result ( FutureExt . ftraverse ( 0L to 1280L ) { i ⇒ < nl > + Await . result ( Future . sequence ( ( 0L to 1280L ) map { i ⇒ < nl > val update = UpdateMessageContentChanged ( user2Peer , i , message ) < nl > seqUpdExt . deliverSingleUpdate ( user . id , update ) < nl > - } , 10 . seconds ) < nl > + } ) , 10 . seconds ) < nl > < nl > var totalUpdates : Seq [ ApiDifferenceUpdate ] = Seq . empty

TEST DIFF:
diff - - git a / actor - server / actor - core / src / main / protobuf / sequence . proto b / actor - server / actor - core / src / main / protobuf / sequence . proto 
 index 49d2dee . . 7ecced0 100644 
 - - - a / actor - server / actor - core / src / main / protobuf / sequence . proto 
 + + + b / actor - server / actor - core / src / main / protobuf / sequence . proto 
 @ @ - 8 , 6 + 8 , 7 @ @ option ( scalapb . options ) = { 
 } ; 
 
 import " scalapb / scalapb . proto " ; 
 + import " google / protobuf / wrappers . proto " ; 
 import " model / push . proto " ; 
 import " model . proto " ; 
 
 @ @ - 47 , 6 + 48 , 7 @ @ message UserSequenceCommands { 
 message DeliverUpdate { 
 UpdateMapping mapping = 1 ; 
 PushRules push _ rules = 2 ; 
 + google . protobuf . StringValue reduce _ key = 5 ; 
 string delivery _ id = 4 ; 
 } 
 
 diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / group / GroupProcessorRegion . scala b / actor - server / actor - core / src / main / scala / im / actor / server / group / GroupProcessorRegion . scala 
 index 3eaf83a . . 8693c9d 100644 
 - - - a / actor - server / actor - core / src / main / scala / im / actor / server / group / GroupProcessorRegion . scala 
 + + + b / actor - server / actor - core / src / main / scala / im / actor / server / group / GroupProcessorRegion . scala 
 @ @ - 6 , 6 + 6 , 8 @ @ import akka . event . Logging 
 import im . actor . server . dialog . DialogCommands . Envelope 
 import im . actor . server . model . { Peer , PeerType } 
 
 + import scala . util . { Try , Success } 
 + 
 object GroupProcessorRegion { 
 private def extractEntityId ( system : ActorSystem ) : ShardRegion . ExtractEntityId = { 
 val log = Logging ( system , getClass ) 
 @ @ - 15 , 9 + 17 , 9 @ @ object GroupProcessorRegion { 
 case q : GroupQuery ⇒ ( q . groupId . toString , q ) 
 case e @ Envelope ( peer , payload ) ⇒ peer match { 
 case Peer ( PeerType . Group , groupId ) ⇒ 
 - e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) match { 
 - case Some ( any ) ⇒ ( groupId . toString , any ) 
 - case None ⇒ 
 + Try ( e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) ) match { 
 + case Success ( any ) ⇒ ( groupId . toString , any ) 
 + case _ ⇒ 
 val error = new RuntimeException ( s " Payload not found for $ e " ) 
 log . error ( error , error . getMessage ) 
 throw error 
 diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerRegion . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerRegion . scala 
 index 6fbc993 . . 13ba687 100644 
 - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerRegion . scala 
 + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerRegion . scala 
 @ @ - 4 , 6 + 4 , 8 @ @ import akka . actor . { ActorRef , ActorSystem , Props } 
 import akka . cluster . sharding . { ClusterSharding , ClusterShardingSettings , ShardRegion } 
 import akka . event . Logging 
 
 + import scala . util . { Success , Try } 
 + 
 final case class SeqUpdatesManagerRegion ( ref : ActorRef ) 
 
 object SeqUpdatesManagerRegion { 
 @ @ - 14 , 9 + 16 , 9 @ @ object SeqUpdatesManagerRegion { 
 val log = Logging ( system , getClass ) 
 
 { 
 - case e @ Envelope ( userId , payload ) ⇒ ( userId . toString , e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) match { 
 - case Some ( any ) ⇒ any 
 - case None ⇒ 
 + case e @ Envelope ( userId , payload ) ⇒ ( userId . toString , Try ( e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) ) match { 
 + case Success ( any ) ⇒ any 
 + case _ ⇒ 
 val error = new RuntimeException ( s " Payload not found for $ e " ) 
 log . error ( error , error . getMessage ) 
 throw error 
 diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala 
 index eaca44f . . f0941e3 100644 
 - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala 
 + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala 
 @ @ - 4 , 6 + 4 , 7 @ @ import akka . actor . _ 
 import akka . pattern . pipe 
 import com . github . benmanes . caffeine . cache . Caffeine 
 import com . google . protobuf . ByteString 
 + import com . google . protobuf . wrappers . StringValue 
 import im . actor . server . db . DbExtension 
 import im . actor . server . model . { SeqUpdate , UpdateMapping } 
 import im . actor . server . persist . sequence . UserSequenceRepo 
 @ @ - 74 , 9 + 75 , 9 @ @ private [ sequence ] final class UserSequence ( 
 
 def initialized : Receive = { 
 case cmd : VendorPushCommand ⇒ vendorPush forward cmd 
 - case DeliverUpdate ( mappingOpt , pushRules , deliveryId ) ⇒ 
 + case DeliverUpdate ( mappingOpt , pushRules , reduceKey , deliveryId ) ⇒ 
 mappingOpt match { 
 - case Some ( mapping ) ⇒ deliver ( mapping , pushRules , deliveryId ) 
 + case Some ( mapping ) ⇒ deliver ( mapping , pushRules , reduceKey , deliveryId ) 
 case None ⇒ 
 log . error ( " Empty mapping " ) 
 } 
 @ @ - 89 , 7 + 90 , 7 @ @ private [ sequence ] final class UserSequence ( 
 seq ← UserSequenceRepo . fetchSeq ( userId ) map ( _ getOrElse 0 ) 
 } yield Initialized ( seq ) ) pipeTo self 
 
 - private def deliver ( mapping : UpdateMapping , pushRules : Option [ PushRules ] , deliveryId : String ) : Unit = { 
 + private def deliver ( mapping : UpdateMapping , pushRules : Option [ PushRules ] , reduceKey : Option [ StringValue ] , deliveryId : String ) : Unit = { 
 cached ( deliveryId ) { 
 val seq = nextSeq ( ) 
 
 @ @ - 97 , 6 + 98 , 7 @ @ private [ sequence ] final class UserSequence ( 
 userId , 
 seq , 
 System . currentTimeMillis ( ) , 
 + reduceKey , 
 Some ( mapping ) 
 ) 
 
 diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / user / UserProcessorRegion . scala b / actor - server / actor - core / src / main / scala / im / actor / server / user / UserProcessorRegion . scala 
 index 8e7593e . . 28319df 100644 
 - - - a / actor - server / actor - core / src / main / scala / im / actor / server / user / UserProcessorRegion . scala 
 + + + b / actor - server / actor - core / src / main / scala / im / actor / server / user / UserProcessorRegion . scala 
 @ @ - 6 , 6 + 6 , 8 @ @ import akka . event . Logging 
 import im . actor . server . dialog . DialogCommands . Envelope 
 import im . actor . server . model . { Peer , PeerType } 
 
 + import scala . util . { Try , Success } 
 + 
 object UserProcessorRegion { 
 private def extractEntityId ( system : ActorSystem ) : ShardRegion . ExtractEntityId = { 
 val log = Logging ( system , getClass ) 
 @ @ - 15 , 9 + 17 , 9 @ @ object UserProcessorRegion { 
 case q : UserQuery ⇒ ( q . userId . toString , q ) 
 case e @ Envelope ( peer , payload ) ⇒ peer match { 
 case Peer ( PeerType . Private , userId ) ⇒ 
 - e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) match { 
 - case Some ( any ) ⇒ ( userId . toString , any ) 
 - case None ⇒ 
 + Try ( e . getField ( Envelope . descriptor . findFieldByNumber ( payload . number ) ) ) match { 
 + case Success ( any ) ⇒ ( userId . toString , any ) 
 + case _ ⇒ 
 val error = new RuntimeException ( s " Payload not found for $ e " ) 
 log . error ( error , error . getMessage ) 
 throw error 
 diff - - git a / actor - server / actor - models / src / main / protobuf / model . proto b / actor - server / actor - models / src / main / protobuf / model . proto 
 index 278815e . . a296bea 100644 
 - - - a / actor - server / actor - models / src / main / protobuf / model . proto 
 + + + b / actor - server / actor - models / src / main / protobuf / model . proto 
 @ @ - 3 , 6 + 3 , 7 @ @ syntax = ' proto3 ' ; 
 package im . actor . server ; 
 
 import " scalapb / scalapb . proto " ; 
 + import " google / protobuf / wrappers . proto " ; 
 
 option ( scalapb . options ) = { 
 import : " im . actor . server . model . ModelTypeMappers . _ " 
 @ @ - 24 , 6 + 25 , 7 @ @ message SeqUpdate { 
 int32 user _ id = 1 ; 
 int32 seq = 2 ; 
 int64 timestamp = 3 ; 
 + google . protobuf . StringValue reduce _ key = 5 ; 
 UpdateMapping mapping = 4 ; 
 } 
 
 diff - - git a / actor - server / actor - persist / src / main / resources / sql / migration / V20160121182140 _ _ CreateReduceKey . sql b / actor - server / actor - persist / src / main / resources / sql / migration / V20160121182140 _ _ CreateReduceKey . sql 
 new file mode 100644 
 index 0000000 . . ca6a2d5 
 - - - / dev / null 
 + + + b / actor - server / actor - persist / src / main / resources / sql / migration / V20160121182140 _ _ CreateReduceKey . sql 
 @ @ - 0 , 0 + 1 , 2 @ @ 
 + ALTER TABLE user _ sequence ADD COLUMN reduce _ key TEXT ; 
 + CREATE INDEX on user _ sequence ( user _ id , reduce _ key , seq ) ; 
 \ No newline at end of file 
 diff - - git a / actor - server / actor - persist / src / main / scala / im / actor / server / db / ActorPostgresDriver . scala b / actor - server / actor - persist / src / main / scala / im / actor / server / db / ActorPostgresDriver . scala 
 index 20a7fa3 . . a1757d5 100644 
 - - - a / actor - server / actor - persist / src / main / scala / im / actor / server / db / ActorPostgresDriver . scala 
 + + + b / actor - server / actor - persist / src / main / scala / im / actor / server / db / ActorPostgresDriver . scala 
 @ @ - 2 , 6 + 2 , 7 @ @ package im . actor . server . db 
 
 import com . github . tminglei . slickpg . _ 
 import com . google . protobuf . ByteString 
 + import com . google . protobuf . wrappers . StringValue 
 
 trait ByteStringImplicits { 
 
 @ @ - 13 , 6 + 14 , 15 @ @ trait ByteStringImplicits { 
 ) 
 } 
 
 + trait ProtoWrappersImplicits { 
 + import slick . driver . PostgresDriver . api . _ 
 + 
 + implicit val stringValueColumnType = MappedColumnType . base [ StringValue , String ] ( 
 + { sv ⇒ sv . value } , 
 + { s ⇒ StringValue ( s ) } 
 + ) 
 + } 
 + 
 trait ActorPostgresDriver extends ExPostgresDriver 
 with PgDateSupport 
 with PgDate2Support 
 @ @ - 20 , 7 + 30 , 7 @ @ trait ActorPostgresDriver extends ExPostgresDriver 
 with PgLTreeSupport { 
 
 override val api = 
 - new API with ArrayImplicits with LTreeImplicits with DateTimeImplicits with ByteStringImplicits 
 + new API with ArrayImplicits with LTreeImplicits with DateTimeImplicits with ByteStringImplicits with ProtoWrappersImplicits 
 } 
 
 object ActorPostgresDriver extends ActorPostgresDriver 
 \ No newline at end of file 
 diff - - git a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala b / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala 
 index f225350 . . 0d8f9d4 100644 
 - - - a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala 
 + + + b / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala 
 @ @ - 1 , 5 + 1 , 6 @ @ 
 package im . actor . server . persist . sequence 
 
 + import com . google . protobuf . wrappers . StringValue 
 import im . actor . server . db . ActorPostgresDriver . api . _ 
 import im . actor . server . model . { UpdateMapping , SeqUpdate } 
 
 @ @ - 7 , 16 + 8 , 27 @ @ private [ sequence ] final class UserSequenceTable ( tag : Tag ) extends Table [ SeqUpdat 
 def userId = column [ Int ] ( " user _ id " , O . PrimaryKey ) 
 def seq = column [ Int ] ( " seq " , O . PrimaryKey ) 
 def timestamp = column [ Long ] ( " timestamp " ) 
 + def reduceKey = column [ Option [ StringValue ] ] ( " reduce _ key " ) 
 def mapping = column [ Array [ Byte ] ] ( " mapping " ) 
 
 - def * = ( userId , seq , timestamp , mapping ) < > ( applySeqUpdate . tupled , unapplySeqUpdate ) 
 + def * = ( userId , seq , timestamp , reduceKey , mapping ) < > ( applySeqUpdate . tupled , unapplySeqUpdate ) 
 
 - private def applySeqUpdate : ( Int , Int , Long , Array [ Byte ] ) ⇒ SeqUpdate = { 
 - ( userId , seq , timestamp , mapping ) ⇒ SeqUpdate ( userId , seq , timestamp , Some ( UpdateMapping . parseFrom ( mapping ) ) ) 
 + private def applySeqUpdate : ( Int , Int , Long , Option [ StringValue ] , Array [ Byte ] ) ⇒ SeqUpdate = { 
 + ( userId , seq , timestamp , reduceKey , mapping ) ⇒ 
 + SeqUpdate ( userId , seq , timestamp , reduceKey , Some ( UpdateMapping . parseFrom ( mapping ) ) ) 
 } 
 
 - private def unapplySeqUpdate : SeqUpdate ⇒ Option [ ( Int , Int , Long , Array [ Byte ] ) ] = { 
 - seqUpdate ⇒ Some ( ( seqUpdate . userId , seqUpdate . seq , seqUpdate . timestamp , seqUpdate . mapping . map ( _ . toByteArray ) . getOrElse ( Array . empty ) ) ) 
 + private def unapplySeqUpdate : SeqUpdate ⇒ Option [ ( Int , Int , Long , Option [ StringValue ] , Array [ Byte ] ) ] = { 
 + seqUpdate ⇒ 
 + Some ( 
 + ( 
 + seqUpdate . userId , 
 + seqUpdate . seq , 
 + seqUpdate . timestamp , 
 + seqUpdate . reduceKey , 
 + seqUpdate . mapping . map ( _ . toByteArray ) . getOrElse ( Array . empty ) 
 + ) 
 + ) 
 } 
 } 
 
 @ @ - 27 , 7 + 39 , 20 @ @ object UserSequenceRepo { 
 
 private def byUser ( userId : Rep [ Int ] ) = sequence . filter ( _ . userId = = = userId ) 
 
 - private def byUserAfterSeq ( userId : Rep [ Int ] , seq : Rep [ Int ] , limit : ConstColumn [ Long ] ) = byUser ( userId ) . filter ( _ . seq > seq ) . sortBy ( _ . seq . asc ) . take ( limit ) 
 + private def byUserAfterSeq ( userId : Rep [ Int ] , seq : Rep [ Int ] , limit : ConstColumn [ Long ] ) = 
 + byUser ( userId ) 
 + . filter ( _ . seq > seq ) 
 + . sortBy ( _ . seq . asc ) 
 + . filter { notReduced ⇒ 
 + notReduced . reduceKey . isEmpty | | 
 + notReduced . seq . in ( 
 + byUser ( userId ) 
 + . filter ( _ . reduceKey = = = notReduced . reduceKey ) 
 + . groupBy ( _ . reduceKey ) 
 + . map ( _ . _ 2 . map ( _ . seq ) . max ) 
 + ) 
 + } 
 + . take ( limit ) 
 
 private val userSequence = Compiled ( byUserAfterSeq _ ) 
 
 diff - - git a / actor - server / actor - session / src / main / scala / im / actor / server / session / Session . scala b / actor - server / actor - session / src / main / scala / im / actor / server / session / Session . scala 
 index dd9a910 . . 373271c 100644 
 - - - a / actor - server / actor - session / src / main / scala / im / actor / server / session / Session . scala 
 + + + b / actor - server / actor - session / src / main / scala / im / actor / server / session / Session . scala 
 @ @ - 26 , 6 + 26 , 7 @ @ import slick . driver . PostgresDriver . api . _ 
 import scala . collection . immutable 
 import scala . concurrent . ExecutionContext 
 import scala . concurrent . duration . _ 
 + import scala . util . { Success , Try } 
 
 final case class SessionConfig ( idleTimeout : Duration , reSendConfig : ReSenderConfig ) 
 
 @ @ - 42 , 9 + 43 , 9 @ @ object Session { 
 
 private [ this ] val extractEntityId : ShardRegion . ExtractEntityId = { 
 case env @ SessionEnvelope ( authId , sessionId , payload ) ⇒ 
 - env . getField ( SessionEnvelope . descriptor . findFieldByNumber ( payload . number ) ) match { 
 - case Some ( any ) ⇒ s " $ { authId } _ $ sessionId " → any 
 - case None ⇒ throw new RuntimeException ( s " Empty payload $ env " ) 
 + Try ( env . getField ( SessionEnvelope . descriptor . findFieldByNumber ( payload . number ) ) ) match { 
 + case Success ( any ) ⇒ s " $ { authId } _ $ sessionId " → any 
 + case _ ⇒ throw new RuntimeException ( s " Empty payload $ env " ) 
 } 
 } 
 
 diff - - git a / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / UserSequenceSpec . scala b / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / UserSequenceSpec . scala 
 index ff68b98 . . ef9bc00 100644 
 - - - a / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / UserSequenceSpec . scala 
 + + + b / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / UserSequenceSpec . scala 
 @ @ - 3 , 10 + 3 , 12 @ @ package im . actor . server . sequence 
 import akka . pattern . ask 
 import akka . testkit . _ 
 import com . google . protobuf . ByteString 
 + import com . google . protobuf . wrappers . StringValue 
 import com . typesafe . config . _ 
 - import im . actor . api . rpc . contacts . UpdateContactsAdded 
 + import im . actor . api . rpc . contacts . { UpdateContactRegistered , UpdateContactsAdded } 
 import im . actor . server . _ 
 import im . actor . server . model . { SerializedUpdate , UpdateMapping } 
 + import im . actor . server . persist . sequence . UserSequenceRepo 
 import im . actor . server . sequence . UserSequenceCommands . { DeliverUpdate , Envelope } 
 import org . scalatest . time . { Seconds , Span } 
 
 @ @ - 23 , 6 + 25 , 8 @ @ final class UserSequenceSpec extends BaseAppSuite ( 
 
 it should " not reply with seq of the ongoing update ( concurrency problem ) " in e2 
 
 + it should " reduce updates " in reduceUpdates 
 + 
 override implicit def patienceConfig : PatienceConfig = 
 new PatienceConfig ( timeout = Span ( 10 , Seconds ) ) 
 
 @ @ - 105 , 4 + 109 , 49 @ @ final class UserSequenceSpec extends BaseAppSuite ( 
 } 
 } 
 } 
 + 
 + def reduceUpdates ( ) = { 
 + val ( user , _ , _ , _ ) = createUser ( ) 
 + 
 + val update = UpdateContactsAdded ( Vector ( 1 , 2 , 3 ) ) 
 + val deliverUpd = DeliverUpdate ( 
 + mapping = Some ( UpdateMapping ( Some ( SerializedUpdate ( 
 + header = update . header , 
 + body = ByteString . copyFrom ( update . toByteArray ) , 
 + userIds = update . _ relatedUserIds , 
 + groupIds = update . _ relatedGroupIds 
 + ) ) ) ) 
 + ) 
 + 
 + val updateSame = UpdateContactRegistered ( 1 , isSilent = false , 0L , 0L ) 
 + val deliverUpdSame = DeliverUpdate ( 
 + reduceKey = Some ( StringValue ( " same " ) ) , 
 + mapping = Some ( UpdateMapping ( Some ( SerializedUpdate ( 
 + header = updateSame . header , 
 + body = ByteString . copyFrom ( updateSame . toByteArray ) , 
 + userIds = update . _ relatedUserIds , 
 + groupIds = update . _ relatedGroupIds 
 + ) ) ) ) 
 + ) 
 + 
 + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpd ) ) ( identity ) 
 + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpd ) ) ( identity ) 
 + 
 + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpdSame ) ) ( identity ) 
 + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpdSame ) ) ( identity ) 
 + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpdSame ) ) ( identity ) 
 + 
 + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpd ) ) ( identity ) 
 + 
 + whenReady ( region . ref ? Envelope ( user . id ) . withDeliverUpdate ( deliverUpdSame ) ) ( identity ) 
 + 
 + whenReady ( db . run ( UserSequenceRepo . fetchAfterSeq ( user . id , 0 , 100L ) ) ) { updates ⇒ 
 + updates . map ( _ . mapping . get . default . get . header ) shouldBe Seq ( 
 + UpdateContactsAdded . header , 
 + UpdateContactsAdded . header , 
 + UpdateContactsAdded . header , 
 + UpdateContactRegistered . header 
 + ) 
 + } 
 + } 
 } 
 diff - - git a / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / V20151108011300 _ _ FillUserSequenceSpec . scala b / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / V20151108011300 _ _ FillUserSequenceSpec . scala 
 index a465f48 . . 99805ba 100644 
 - - - a / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / V20151108011300 _ _ FillUserSequenceSpec . scala 
 + + + b / actor - server / actor - tests / src / test / scala / im / actor / server / sequence / V20151108011300 _ _ FillUserSequenceSpec . scala 
 @ @ - 18 , 11 + 18 , 11 @ @ final class V20151108011300 _ _ FillUserSequenceSpec extends BaseAppSuite with Impl 
 it should " properly migrate updates from authId with max sequence " in maxSeq 
 it should " migrate new updates on second run " in secondRun 
 
 - implicit val getSeqUpdate = GetResult [ SeqUpdate ] ( r ⇒ SeqUpdate ( 
 + implicit val getSeqUpdate = GetResult [ New ] ( r ⇒ New ( 
 userId = r . nextInt ( ) , 
 seq = r . nextInt ( ) , 
 timestamp = r . nextLong ( ) , 
 - mapping = Some ( UpdateMapping . parseFrom ( r . nextBytes ( ) ) ) 
 + mapping = UpdateMapping . parseFrom ( r . nextBytes ( ) ) . toByteArray 
 ) ) 
 
 def maxSeq ( ) = { 
 @ @ - 74 , 18 + 74 , 18 @ @ final class V20151108011300 _ _ FillUserSequenceSpec extends BaseAppSuite with Impl 
 
 private def checkValidSeq ( userId : Int , oldestAuthId : Long ) : Unit = { 
 Await . result ( db . run ( for { 
 - seqs ← sql " " " SELECT * FROM user _ sequence WHERE user _ id = $ userId ORDER BY seq ASC " " " . as [ SeqUpdate ] 
 + seqs ← sql " " " SELECT * FROM user _ sequence WHERE user _ id = $ userId ORDER BY seq ASC " " " . as [ New ] 
 obsSeq ← sql " " " SELECT seq FROM seq _ updates _ ngen WHERE auth _ id = $ oldestAuthId ORDER BY timestamp DESC LIMIT 1 " " " 
 . as [ Int ] . headOption . map ( _ . getOrElse ( 0 ) ) 
 } yield { 
 - assert ( seqs . size . toInt = = obsSeq , " wrong sequence size " ) 
 + assert ( seqs . size . toInt = = obsSeq . toInt , " wrong sequence size " ) 
 
 seqs . zipWithIndex foreach { 
 - case ( SeqUpdate ( ` userId ` , seq , timestamp , Some ( mappingBytes ) ) , index ) ⇒ 
 + case ( New ( ` userId ` , seq , timestamp , mappingBytes ) , index ) ⇒ 
 assert ( index + 1 = = seq , " seq is broken " ) 
 val seqUpd = 
 UpdateMapping 
 - . parseFrom ( mappingBytes . toByteArray ) 
 + . parseFrom ( mappingBytes ) 
 . getDefault 
 
 assert ( seqUpd . header = = UpdateContactsAdded . header , " wrong header " ) 
 diff - - git a / actor - server / project / Dependencies . scala b / actor - server / project / Dependencies . scala 
 index 5e32937 . . e4bdcf8 100644 
 - - - a / actor - server / project / Dependencies . scala 
 + + + b / actor - server / project / Dependencies . scala 
 @ @ - 17 , 7 + 17 , 7 @ @ object Dependencies { 
 val slickPg = " 0 . 10 . 2 " 
 val scalatest = " 2 . 2 . 4 " 
 val shardakka = " 0 . 1 . 20 " 
 - val scalapbSer = " 0 . 1 . 6 " 
 + val scalapbSer = " 0 . 1 . 9 " 
 } 
 
 object Compile {

NEAREST DIFF:
diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / BatchUpdatesWriter . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / BatchUpdatesWriter . scala 
 index efbc692 . . 3203bdd 100644 
 - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / BatchUpdatesWriter . scala 
 + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / BatchUpdatesWriter . scala 
 @ @ - 4 , 24 + 4 , 27 @ @ import java . util . concurrent . TimeUnit 
 
 import akka . actor . _ 
 import im . actor . server . db . DbExtension 
 - import scala . collection . immutable 
 - import im . actor . server . persist 
 - import im . actor . server . model 
 + import im . actor . server . model . SeqUpdate 
 + import im . actor . server . persist . sequence . UserSequenceRepo 
 
 - import scala . concurrent . { Promise , ExecutionContext , Future } 
 + import scala . collection . immutable 
 import scala . concurrent . duration . _ 
 + import scala . concurrent . { ExecutionContext , Future , Promise } 
 import scala . util . { Failure , Success } 
 
 private [ sequence ] object BatchUpdatesWriter { 
 - final case class Enqueue ( update : model . sequence . SeqUpdateObsolete , promise : Promise [ Unit ] ) 
 
 - private final case object Resume 
 - private final case object ScheduledFlush 
 + final case class Enqueue ( update : SeqUpdate , promise : Promise [ Unit ] ) 
 + 
 + private case object Resume 
 + 
 + private case object ScheduledFlush 
 
 def props = Props ( classOf [ BatchUpdatesWriter ] ) 
 } 
 
 private [ sequence ] class BatchUpdatesWriter extends Actor with ActorLogging with Stash { 
 + 
 import BatchUpdatesWriter . _ 
 
 private val MaxUpdatesBatchSize = context . system . settings . config . getInt ( " sequence . max - updates - batch - size " ) 
 @ @ - 30 , 7 + 33 , 7 @ @ private [ sequence ] class BatchUpdatesWriter extends Actor with ActorLogging with 
 private val db = DbExtension ( context . system ) . db 
 private implicit val ec : ExecutionContext = context . dispatcher 
 
 - private [ this ] var queue = immutable . Queue . empty [ model . sequence . SeqUpdateObsolete ] 
 + private [ this ] var queue = immutable . Queue . empty [ SeqUpdate ] 
 private [ this ] var senders = immutable . Queue . empty [ Promise [ Unit ] ] 
 private [ this ] var scheduledFlush : Option [ Cancellable ] = None 
 
 @ @ - 48 , 7 + 51 , 7 @ @ private [ sequence ] class BatchUpdatesWriter extends Actor with ActorLogging with 
 case msg ⇒ stash ( ) 
 } 
 
 - private def enqueue ( update : model . sequence . SeqUpdateObsolete , promise : Promise [ Unit ] ) : Unit = { 
 + private def enqueue ( update : SeqUpdate , promise : Promise [ Unit ] ) : Unit = { 
 this . queue = this . queue . enqueue ( update ) 
 this . senders = this . senders . enqueue ( promise ) 
 
 @ @ - 83 , 8 + 86 , 8 @ @ private [ sequence ] class BatchUpdatesWriter extends Actor with ActorLogging with 
 } 
 } 
 
 - private def batchWrite ( updates : Seq [ model . sequence . SeqUpdateObsolete ] ) : Future [ Unit ] = 
 - db . run ( persist . sequence . SeqUpdateRepo . createBulk ( updates ) ) map ( _ ⇒ ( ) ) 
 + private def batchWrite ( updates : Seq [ SeqUpdate ] ) : Future [ Unit ] = 
 + db . run ( UserSequenceRepo . create ( updates ) ) map ( _ ⇒ ( ) ) 
 
 override def postRestart ( reason : Throwable ) : Unit = { 
 log . error ( reason , " Failed " ) 
 diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesExtension . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesExtension . scala 
 index 70a036a . . 6d71b3a 100644 
 - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesExtension . scala 
 + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesExtension . scala 
 @ @ - 1 , 7 + 1 , 7 @ @ 
 package im . actor . server . sequence 
 
 import akka . actor . _ 
 - import akka . cluster . pubsub . { DistributedPubSubMediator , DistributedPubSub } 
 + import akka . cluster . pubsub . { DistributedPubSub , DistributedPubSubMediator } 
 import akka . pattern . ask 
 import akka . util . Timeout 
 import com . google . protobuf . ByteString 
 @ @ - 9 , 8 + 9 , 7 @ @ import im . actor . api . rpc . Update 
 import im . actor . api . rpc . messaging . UpdateMessage 
 import im . actor . server . db . DbExtension 
 import im . actor . server . model . _ 
 - import im . actor . server . model . sequence . SeqUpdateObsolete 
 - import im . actor . server . model . push . { GooglePushCredentials ⇒ GooglePushCredentialsModel , ApplePushCredentials ⇒ ApplePushCredentialsModel } 
 + import im . actor . server . model . push . { ApplePushCredentials ⇒ ApplePushCredentialsModel , GooglePushCredentials ⇒ GooglePushCredentialsModel } 
 import im . actor . server . persist . sequence . UserSequenceRepo 
 import slick . dbio . DBIO 
 
 @ @ - 153 , 7 + 152 , 7 @ @ final class SeqUpdatesExtension ( 
 
 def deleteApplePushCredentials ( token : Array [ Byte ] ) : Future [ Unit ] = Future . successful ( ( ) ) 
 
 - def persistUpdate ( update : SeqUpdateObsolete ) : Future [ Unit ] = { 
 + def persistUpdate ( update : SeqUpdate ) : Future [ Unit ] = { 
 val promise = Promise [ Unit ] ( ) 
 writer ! BatchUpdatesWriter . Enqueue ( update , promise ) 
 promise . future 
 diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerActor . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerActor . scala 
 index e049584 . . aa9e4c7 100644 
 - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerActor . scala 
 + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / SeqUpdatesManagerActor . scala 
 @ @ - 22 , 7 + 22 , 6 @ @ import im . actor . server . db . DbExtension 
 import im . actor . server . persist . HistoryMessageRepo 
 import im . actor . server . { persist ⇒ p } 
 import im . actor . server . model . push . { ApplePushCredentials ⇒ ApplePushCredentialsModel , GooglePushCredentials ⇒ GooglePushCredentialsModel } 
 - import im . actor . server . model . sequence . { SeqUpdateObsolete ⇒ SeqUpdateModel } 
 
 / * 
 trait SeqUpdatesManagerMessage { 
 diff - - git a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala 
 index fa2ebe1 . . c839d2b 100644 
 - - - a / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala 
 + + + b / actor - server / actor - core / src / main / scala / im / actor / server / sequence / UserSequence . scala 
 @ @ - 11 , 6 + 11 , 7 @ @ import im . actor . server . persist . sequence . UserSequenceRepo 
 
 import scala . concurrent . Future 
 import scala . language . postfixOps 
 + import scala . util . { Failure , Success } 
 
 object UserSequence { 
 def topic ( userId : Int ) : String = s " sequence . $ userId " 
 @ @ - 40 , 12 + 41 , 13 @ @ private [ sequence ] final class UserSequence extends Actor with ActorLogging with 
 import context . dispatcher 
 
 private val db = DbExtension ( context . system ) . db 
 + private val seqUpdExt = SeqUpdatesExtension ( context . system ) 
 
 val userId = self . path . name . toInt 
 
 private val mediator = DistributedPubSub ( context . system ) . mediator 
 
 - val deliveryCache = Caffeine . newBuilder ( ) . maximumSize ( 100 ) . executor ( context . dispatcher ) . build [ String , SeqState ] ( ) 
 + private val deliveryCache = Caffeine . newBuilder ( ) . maximumSize ( 100 ) . executor ( context . dispatcher ) . build [ String , SeqState ] ( ) 
 
 init ( ) 
 
 @ @ - 71 , 13 + 73 , 6 @ @ private [ sequence ] final class UserSequence extends Actor with ActorLogging with 
 sender ( ) ! SeqState ( getSeq ) 
 } 
 
 - private def becomeStashing ( f : ActorRef ⇒ Receive ) : Unit = 
 - context . become ( f ( sender ( ) ) orElse stashing , discardOld = false ) 
 - 
 - private def stashing : Receive = { 
 - case msg ⇒ stash ( ) 
 - } 
 - 
 private def init ( ) : Unit = 
 db . run ( UserSequenceRepo . fetchSeq ( userId ) ) map ( seqOpt ⇒ Initialized ( seqOpt . getOrElse ( 0 ) ) ) pipeTo self 
 
 @ @ - 92 , 21 + 87 , 9 @ @ private [ sequence ] final class UserSequence extends Actor with ActorLogging with 
 Some ( mapping ) 
 ) 
 
 - becomeStashing ( replyTo ⇒ { 
 - case s : SeqState ⇒ 
 - unstashAll ( ) 
 - context . unbecome ( ) 
 - 
 - mediator ! Publish ( topic ( userId ) , UserSequenceEvents . NewUpdate ( Some ( seqUpdate ) , pushRules , ByteString . EMPTY ) ) 
 - case s @ Status . Failure ( e ) ⇒ 
 - log . error ( e , " Failed to write seq update : { } " , seqUpdate ) 
 - replyTo ! s 
 - 
 - unstashAll ( ) 
 - context . unbecome ( ) 
 - } ) 
 - 
 - writeToDb ( seqUpdate ) map ( _ ⇒ SeqState ( seq ) ) pipeTo self 
 + writeToDb ( seqUpdate ) map ( _ ⇒ SeqState ( seq ) ) andThen { 
 + case Success ( _ ) ⇒ mediator ! Publish ( topic ( userId ) , UserSequenceEvents . NewUpdate ( Some ( seqUpdate ) , pushRules , ByteString . EMPTY ) ) 
 + } 
 } 
 } 
 
 @ @ - 116 , 10 + 99 , 13 @ @ private [ sequence ] final class UserSequence extends Actor with ActorLogging with 
 case Some ( seqstate ) ⇒ Future . successful ( seqstate ) 
 case None ⇒ f 
 } 
 - } else f ) pipeTo sender ( ) onSuccess { case s ⇒ deliveryCache . put ( deliveryId , s ) } 
 + } else f ) pipeTo sender ( ) onComplete { 
 + case Success ( s ) ⇒ deliveryCache . put ( deliveryId , s ) 
 + case Failure ( e ) ⇒ log . error ( e , " Failed to deliver " ) 
 + } 
 } 
 
 - private def writeToDb ( seqUpdate : SeqUpdate ) : Future [ Unit ] = db . run ( UserSequenceRepo . create ( seqUpdate ) ) map ( _ ⇒ ( ) ) 
 + private def writeToDb ( seqUpdate : SeqUpdate ) : Future [ Unit ] = seqUpdExt . persistUpdate ( seqUpdate ) 
 
 override def preRestart ( reason : Throwable , message : Option [ Any ] ) : Unit = { 
 super . preRestart ( reason , message ) 
 diff - - git a / actor - server / actor - models / src / main / scala / im / actor / server / model / sequence / SeqUpdateObsolete . scala b / actor - server / actor - models / src / main / scala / im / actor / server / model / sequence / SeqUpdateObsolete . scala 
 deleted file mode 100644 
 index aa82bc4 . . 0000000 
 - - - a / actor - server / actor - models / src / main / scala / im / actor / server / model / sequence / SeqUpdateObsolete . scala 
 + + + / dev / null 
 @ @ - 1 , 4 + 0 , 0 @ @ 
 - package im . actor . server . model . sequence 
 - 
 - case class SeqUpdateObsolete ( authId : Long , timestamp : Long , seq : Int , header : Int , serializedData : Array [ Byte ] , userIds : Set [ Int ] , groupIds : Set [ Int ] ) 
 - 
 diff - - git a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / SeqUpdateRepo . scala b / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / SeqUpdateRepo . scala 
 deleted file mode 100644 
 index dc7246d . . 0000000 
 - - - a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / SeqUpdateRepo . scala 
 + + + / dev / null 
 @ @ - 1 , 72 + 0 , 0 @ @ 
 - package im . actor . server . persist . sequence 
 - 
 - import slick . driver . PostgresDriver . api . _ 
 - 
 - import im . actor . server . model 
 - 
 - final class SeqUpdateTable ( tag : Tag ) extends Table [ model . sequence . SeqUpdateObsolete ] ( tag , " seq _ updates _ ngen " ) { 
 - def authId = column [ Long ] ( " auth _ id " , O . PrimaryKey ) 
 - 
 - def timestamp = column [ Long ] ( " timestamp " ) 
 - 
 - def seq = column [ Int ] ( " seq " ) 
 - 
 - def header = column [ Int ] ( " header " ) 
 - 
 - def serializedData = column [ Array [ Byte ] ] ( " serialized _ data " ) 
 - 
 - def userIds = column [ String ] ( " user _ ids _ str " ) 
 - 
 - def groupIds = column [ String ] ( " group _ ids _ str " ) 
 - 
 - def * = ( authId , timestamp , seq , header , serializedData , userIds , groupIds ) < > ( ( toModel _ ) . tupled , fromModel ) 
 - 
 - private def toModel ( authId : Long , timestamp : Long , seq : Int , header : Int , serializedData : Array [ Byte ] , userIdsStr : String , groupIdsStr : String ) : model . sequence . SeqUpdateObsolete = { 
 - model . sequence . SeqUpdateObsolete ( authId , timestamp , seq , header , serializedData , toIntSet ( userIdsStr ) , toIntSet ( groupIdsStr ) ) 
 - } 
 - 
 - private def fromModel ( update : model . sequence . SeqUpdateObsolete ) = 
 - Some ( ( update . authId , update . timestamp , update . seq , update . header , update . serializedData , update . userIds . mkString ( " , " ) , update . groupIds . mkString ( " , " ) ) ) 
 - 
 - private def toIntSet ( str : String ) : Set [ Int ] = { 
 - if ( str . isEmpty ) { 
 - Set . empty 
 - } else { 
 - str . split ( ' , ' ) . map ( x ⇒ x . toInt ) . toSet 
 - } 
 - } 
 - } 
 - 
 - object SeqUpdateRepo { 
 - val updates = TableQuery [ SeqUpdateTable ] 
 - 
 - val DiffStep = 100L 
 - 
 - val updatesC = Compiled ( updates ) 
 - 
 - def afterTimestamp ( authId : Rep [ Long ] , timestamp : Rep [ Long ] , limit : ConstColumn [ Long ] ) = 
 - updates . filter ( u ⇒ u . authId = = = authId & & u . timestamp > timestamp ) . sortBy ( _ . timestamp . asc ) . take ( limit ) 
 - def last ( authId : Rep [ Long ] ) = 
 - updates . filter ( _ . authId = = = authId ) . sortBy ( _ . timestamp . desc ) . take ( 1 ) 
 - def byAuthId ( authId : Rep [ Long ] ) = 
 - updates . filter ( _ . authId = = = authId ) . sortBy ( _ . timestamp . desc ) 
 - 
 - val afterTimestampC = Compiled ( afterTimestamp _ ) 
 - val lastC = Compiled ( last _ ) 
 - val byAuthIdC = Compiled ( byAuthId _ ) 
 - 
 - def create ( update : model . sequence . SeqUpdateObsolete ) = 
 - updatesC + = update 
 - 
 - def createBulk ( newUpdates : Seq [ model . sequence . SeqUpdateObsolete ] ) = 
 - updatesC + + = newUpdates 
 - 
 - def findLast ( authId : Long ) = 
 - lastC ( authId ) . result . headOption 
 - 
 - def find ( authId : Long ) = 
 - byAuthIdC ( authId ) . result 
 - 
 - def findAfter ( authId : Long , timestamp : Long ) = 
 - afterTimestampC ( ( authId , timestamp , DiffStep ) ) . result 
 - } 
 diff - - git a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala b / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala 
 index 5e3f1cb . . f225350 100644 
 - - - a / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala 
 + + + b / actor - server / actor - persist / src / main / scala / im / actor / server / persist / sequence / UserSequenceRepo . scala 
 @ @ - 35 , 7 + 35 , 7 @ @ object UserSequenceRepo { 
 byUser _ andThen ( _ . sortBy ( _ . seq . desc ) . map ( _ . seq ) . take ( 1 ) ) 
 } 
 
 - def create ( updates : Seq [ SeqUpdate ] ) = sequenceC + + = updates 
 + def create ( updates : Seq [ SeqUpdate ] ) = ( sequenceC + + = updates ) . transactionally 
 
 def create ( update : SeqUpdate ) = sequenceC + = update 
 
 diff - - git a / actor - server / actor - tests / src / test / scala / im / actor / server / api / rpc / service / SequenceServiceSpec . scala b / actor - server / actor - tests / src / test / scala / im / actor / server / api / rpc / service / SequenceServiceSpec . scala 
 index e8c5d07 . . 0b2b060 100644 
 - - - a / actor - server / actor - tests / src / test / scala / im / actor / server / api / rpc / service / SequenceServiceSpec . scala 
 + + + b / actor - server / actor - tests / src / test / scala / im / actor / server / api / rpc / service / SequenceServiceSpec . scala 
 @ @ - 7 , 13 + 7 , 12 @ @ import im . actor . api . rpc . messaging . { ApiTextMessage , UpdateMessageContentChanged 
 import im . actor . api . rpc . misc . ResponseSeq 
 import im . actor . api . rpc . peers . { ApiPeer , ApiPeerType } 
 import im . actor . api . rpc . sequence . { ApiDifferenceUpdate , ResponseGetDifference } 
 - import im . actor . concurrent . FutureExt 
 import im . actor . server . _ 
 import im . actor . server . api . rpc . service . sequence . SequenceServiceConfig 
 import im . actor . server . sequence . SeqUpdatesExtension 
 
 import scala . concurrent . duration . _ 
 - import scala . concurrent . Await 
 + import scala . concurrent . { Future , Await } 
 
 final class SequenceServiceSpec extends BaseAppSuite ( { 
 ActorSpecification . createSystem ( 
 @ @ - 29 , 7 + 28 , 7 @ @ final class SequenceServiceSpec extends BaseAppSuite ( { 
 
 it should " get state " in getState 
 it should " get difference " in getDifference 
 - it should " get difference if there is one update bigger than difference size limit " in bigUpdate 
 + it should " not produce empty difference if there is one update bigger than difference size limit " in bigUpdate 
 
 private val config = SequenceServiceConfig . load ( ) . get 
 private lazy val seqUpdExt = SeqUpdatesExtension ( system ) 
 @ @ - 65 , 10 + 64 , 10 @ @ final class SequenceServiceSpec extends BaseAppSuite ( { 
 
 / / serialized update size is : 40 bytes for body + 4 bytes for header , 44 bytes total 
 / / with max update size of 20 KiB 1281 updates should split into three parts 
 - Await . result ( FutureExt . ftraverse ( 0L to 1280L ) { i ⇒ 
 + Await . result ( Future . sequence ( ( 0L to 1280L ) map { i ⇒ 
 val update = UpdateMessageContentChanged ( user2Peer , i , message ) 
 seqUpdExt . deliverSingleUpdate ( user . id , update ) 
 - } , 10 . seconds ) 
 + } ) , 10 . seconds ) 
 
 var totalUpdates : Seq [ ApiDifferenceUpdate ] = Seq . empty
