BLEU SCORE: 0.06285596338261261

TEST MSG: fix ( server ) : workaround to akka / akka # 20338 take 2
GENERATED MSG: feat ( http - api ) : methods for group invite info

TEST DIFF (one line): diff - - git a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / FilesHttpHandler . scala b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / FilesHttpHandler . scala < nl > index 03a888d . . 4a4e7eb 100644 < nl > - - - a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / FilesHttpHandler . scala < nl > + + + b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / FilesHttpHandler . scala < nl > @ @ - 13 , 6 + 13 , 7 @ @ import akka . http . scaladsl . server . _ < nl > import akka . stream . ActorMaterializer < nl > import im . actor . server . api . http . HttpHandler < nl > import im . actor . server . api . http . HttpApiHelpers . _ < nl > + import im . actor . server . file . local . http . fix . GetFileFix < nl > import im . actor . server . file . local . { FileStorageOperations , LocalFileStorageConfig , RequestSigning } < nl > import im . actor . util . log . AnyRefLogSource < nl > < nl > @ @ - 63 , 22 + 64 , 20 @ @ private [ local ] final class FilesHttpHandler ( storageConfig : LocalFileStorageConfi < nl > / / v1 / files / : fileId < nl > path ( Segments ( 0 , 1 ) ) { seqName = > < nl > log . debug ( " Download file request , fileId : { } " , fileId ) < nl > - withRangeSupport { < nl > - onComplete ( getFile ( fileId ) ) { < nl > - case Success ( Some ( file ) ) = > < nl > - log . debug ( " Serving fileId : { } , file : { } parts " , fileId , file ) < nl > - respondWithDefaultHeader ( < nl > - ` Content - Disposition ` ( attachment , Map ( " filename " - > file . name ) ) < nl > - ) { < nl > - / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed < nl > - getFromFileFix ( file . toJava ) < nl > - } < nl > - case Success ( None ) = > < nl > - complete ( HttpResponse ( StatusCodes . NotFound ) ) < nl > - case Failure ( e ) = > < nl > - log . error ( e , " Failed to get file content , fileId : { } " , fileId ) < nl > - complete ( HttpResponse ( 500 ) ) < nl > - } < nl > + onComplete ( getFile ( fileId ) ) { < nl > + case Success ( Some ( file ) ) = > < nl > + log . debug ( " Serving fileId : { } , file : { } parts " , fileId , file ) < nl > + respondWithDefaultHeader ( < nl > + ` Content - Disposition ` ( attachment , Map ( " filename " - > file . name ) ) < nl > + ) { < nl > + / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed < nl > + getFromFileFix ( file . toJava ) < nl > + } < nl > + case Success ( None ) = > < nl > + complete ( HttpResponse ( StatusCodes . NotFound ) ) < nl > + case Failure ( e ) = > < nl > + log . error ( e , " Failed to get file content , fileId : { } " , fileId ) < nl > + complete ( HttpResponse ( 500 ) ) < nl > } < nl > } < nl > } ~ < nl > diff - - git a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / GetFileFix . scala b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / GetFileFix . scala < nl > deleted file mode 100644 < nl > index 81eeac4 . . 0000000 < nl > - - - a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / GetFileFix . scala < nl > + + + / dev / null < nl > @ @ - 1 , 53 + 0 , 0 @ @ < nl > - package im . actor . server . file . local . http < nl > - < nl > - import java . io . File < nl > - < nl > - import akka . http . scaladsl . model . headers . EntityTag < nl > - import akka . http . scaladsl . server . _ < nl > - import akka . http . scaladsl . server . Directives . _ < nl > - import akka . http . scaladsl . model . { ContentType , DateTime , HttpEntity } < nl > - import akka . http . scaladsl . server . Route < nl > - import akka . http . scaladsl . server . directives . BasicDirectives . { extractSettings ⇒ _ , pass ⇒ _ , _ } < nl > - import akka . http . scaladsl . server . directives . CacheConditionDirectives . { conditional ⇒ _ , _ } < nl > - import akka . http . scaladsl . server . directives . { BasicDirectives , CodingDirectives , ContentTypeResolver , RangeDirectives } < nl > - import akka . stream . ActorAttributes < nl > - import akka . stream . scaladsl . FileIO < nl > - < nl > - / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed < nl > - trait GetFileFix { < nl > - < nl > - private val withRangeSupportAndPrecompressedMediaTypeSupportAndExtractSettings = < nl > - RangeDirectives . withRangeSupport & < nl > - CodingDirectives . withPrecompressedMediaTypeSupport & < nl > - BasicDirectives . extractSettings < nl > - < nl > - def getFromFileFix ( file : File ) ( implicit resolver : ContentTypeResolver ) : Route = < nl > - getFromFile ( file , resolver ( file . getName ) ) < nl > - < nl > - private def getFromFile ( file : File , contentType : ContentType ) : Route = < nl > - get { < nl > - if ( file . isFile & & file . canRead ) < nl > - conditionalFor ( file . length , file . lastModified ) { < nl > - if ( file . length > 0 ) { < nl > - withRangeSupportAndPrecompressedMediaTypeSupportAndExtractSettings { settings ⇒ < nl > - complete { < nl > - HttpEntity . Chunked . fromData ( < nl > - contentType , < nl > - FileIO . fromFile ( file ) . withAttributes ( ActorAttributes . dispatcher ( settings . fileIODispatcher ) ) < nl > - ) < nl > - } < nl > - } < nl > - } else complete ( HttpEntity . Empty ) < nl > - } < nl > - else reject < nl > - } < nl > - < nl > - private def conditionalFor ( length : Long , lastModified : Long ) : Directive0 = < nl > - extractSettings . flatMap ( settings ⇒ < nl > - if ( settings . fileGetConditional ) { < nl > - val tag = java . lang . Long . toHexString ( lastModified ^ java . lang . Long . reverse ( length ) ) < nl > - val lastModifiedDateTime = DateTime ( math . min ( lastModified , System . currentTimeMillis ) ) < nl > - conditional ( EntityTag ( tag ) , lastModifiedDateTime ) < nl > - } else pass ) < nl > - < nl > - } < nl > diff - - git a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / GetFileFix . scala b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / GetFileFix . scala < nl > new file mode 100644 < nl > index 0000000 . . f2bc574 < nl > - - - / dev / null < nl > + + + b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / GetFileFix . scala < nl > @ @ - 0 , 0 + 1 , 50 @ @ < nl > + package im . actor . server . file . local . http . fix < nl > + < nl > + import java . io . File < nl > + < nl > + import akka . http . scaladsl . model . headers . EntityTag < nl > + import akka . http . scaladsl . model . { ContentType , DateTime , HttpEntity } < nl > + import akka . http . scaladsl . server . Directives . _ < nl > + import akka . http . scaladsl . server . { Route , _ } < nl > + import akka . http . scaladsl . server . directives . BasicDirectives . { extractSettings ⇒ _ , pass ⇒ _ } < nl > + import akka . http . scaladsl . server . directives . CacheConditionDirectives . { conditional ⇒ _ } < nl > + import akka . http . scaladsl . server . directives . { BasicDirectives , CodingDirectives , ContentTypeResolver } < nl > + import akka . stream . ActorAttributes < nl > + import akka . stream . scaladsl . FileIO < nl > + < nl > + / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed < nl > + trait GetFileFix { < nl > + < nl > + private val withRangeSupportAndPrecompressedMediaTypeSupportAndExtractSettings = < nl > + RangeDirectivesFix . withRangeSupport & < nl > + CodingDirectives . withPrecompressedMediaTypeSupport & < nl > + BasicDirectives . extractSettings < nl > + < nl > + def getFromFileFix ( file : File ) ( implicit resolver : ContentTypeResolver ) : Route = < nl > + getFromFile ( file , resolver ( file . getName ) ) < nl > + < nl > + private def getFromFile ( file : File , contentType : ContentType ) : Route = < nl > + get { < nl > + if ( file . isFile & & file . canRead ) < nl > + conditionalFor ( file . length , file . lastModified ) { < nl > + if ( file . length > 0 ) { < nl > + withRangeSupportAndPrecompressedMediaTypeSupportAndExtractSettings { settings ⇒ < nl > + complete { < nl > + HttpEntity . Default ( contentType , file . length , < nl > + FileIO . fromFile ( file ) . withAttributes ( ActorAttributes . dispatcher ( settings . fileIODispatcher ) ) ) < nl > + } < nl > + } < nl > + } else complete ( HttpEntity . Empty ) < nl > + } < nl > + else reject < nl > + } < nl > + < nl > + private def conditionalFor ( length : Long , lastModified : Long ) : Directive0 = < nl > + extractSettings . flatMap ( settings ⇒ < nl > + if ( settings . fileGetConditional ) { < nl > + val tag = java . lang . Long . toHexString ( lastModified ^ java . lang . Long . reverse ( length ) ) < nl > + val lastModifiedDateTime = DateTime ( math . min ( lastModified , System . currentTimeMillis ) ) < nl > + conditional ( EntityTag ( tag ) , lastModifiedDateTime ) < nl > + } else pass ) < nl > + < nl > + } < nl > diff - - git a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / RangeDirectivesFix . scala b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / RangeDirectivesFix . scala < nl > new file mode 100644 < nl > index 0000000 . . c3d2fdf < nl > - - - / dev / null < nl > + + + b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / RangeDirectivesFix . scala < nl > @ @ - 0 , 0 + 1 , 162 @ @ < nl > + / * < nl > + * Copyright ( C ) 2009 - 2016 Lightbend Inc . < http : / / www . lightbend . com > < nl > + * / < nl > + < nl > + package im . actor . server . file . local . http . fix < nl > + < nl > + import akka . http . scaladsl . model . StatusCodes . _ < nl > + import akka . http . scaladsl . model . _ < nl > + import akka . http . scaladsl . model . headers . _ < nl > + import akka . http . scaladsl . server . RouteResult . Complete < nl > + import akka . http . scaladsl . server . directives . { MethodDirectives , RespondWithDirectives } < nl > + import akka . http . scaladsl . server . { Directive0 , RequestContext , TooManyRangesRejection , UnsatisfiableRangeRejection } < nl > + import akka . stream . scaladsl . _ < nl > + import akka . stream . { OverflowStrategy , SourceShape } < nl > + import akka . util . ByteString < nl > + < nl > + import scala . collection . immutable < nl > + < nl > + / * * < nl > + * @ groupname range Range directives < nl > + * @ groupprio range 180 < nl > + * / < nl > + / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed < nl > + trait RangeDirectivesFix { < nl > + import akka . http . scaladsl . server . directives . BasicDirectives . _ < nl > + import akka . http . scaladsl . server . directives . RouteDirectives . _ < nl > + < nl > + / * * < nl > + * Answers GET requests with an ` Accept - Ranges : bytes ` header and converts HttpResponses coming back from its inner < nl > + * route into partial responses if the initial request contained a valid ` Range ` request header . The requested < nl > + * byte - ranges may be coalesced . < nl > + * This directive is transparent to non - GET requests < nl > + * Rejects requests with unsatisfiable ranges ` UnsatisfiableRangeRejection ` . < nl > + * Rejects requests with too many expected ranges . < nl > + * < nl > + * Note : if you want to combine this directive with ` conditional ( . . . ) ` you need to put < nl > + * it on the * inside * of the ` conditional ( . . . ) ` directive , i . e . ` conditional ( . . . ) ` must be < nl > + * on a higher level in your route structure in order to function correctly . < nl > + * < nl > + * @ see [ [ https : / / tools . ietf . org / html / rfc7233 ] ] < nl > + * < nl > + * @ group range < nl > + * / < nl > + def withRangeSupport : Directive0 = < nl > + extractRequestContext . flatMap { ctx ⇒ < nl > + val settings = ctx . settings < nl > + implicit val log = ctx . log < nl > + import settings . { rangeCoalescingThreshold , rangeCountLimit } < nl > + < nl > + class IndexRange ( val start : Long , val end : Long ) { < nl > + def length = end - start < nl > + def apply ( entity : UniversalEntity ) : UniversalEntity = entity . transformDataBytes ( length , StreamUtilsFix . sliceBytesTransformer ( start , length ) ) < nl > + def distance ( other : IndexRange ) = mergedEnd ( other ) - mergedStart ( other ) - ( length + other . length ) < nl > + def mergeWith ( other : IndexRange ) = new IndexRange ( mergedStart ( other ) , mergedEnd ( other ) ) < nl > + def contentRange ( entityLength : Long ) = ContentRange ( start , end - 1 , entityLength ) < nl > + private def mergedStart ( other : IndexRange ) = math . min ( start , other . start ) < nl > + private def mergedEnd ( other : IndexRange ) = math . max ( end , other . end ) < nl > + } < nl > + < nl > + def indexRange ( entityLength : Long ) ( range : ByteRange ) : IndexRange = < nl > + range match { < nl > + case ByteRange . Slice ( start , end ) ⇒ new IndexRange ( start , math . min ( end + 1 , entityLength ) ) < nl > + case ByteRange . FromOffset ( first ) ⇒ new IndexRange ( first , entityLength ) < nl > + case ByteRange . Suffix ( suffixLength ) ⇒ new IndexRange ( math . max ( 0 , entityLength - suffixLength ) , entityLength ) < nl > + } < nl > + < nl > + / / See comment of the ` range - coalescing - threshold ` setting in ` reference . conf ` for the rationale of this behavior . < nl > + def coalesceRanges ( iRanges : Seq [ IndexRange ] ) : Seq [ IndexRange ] = < nl > + iRanges . foldLeft ( Seq . empty [ IndexRange ] ) { ( acc , iRange ) ⇒ < nl > + val ( mergeCandidates , otherCandidates ) = acc . partition ( _ . distance ( iRange ) < = rangeCoalescingThreshold ) < nl > + val merged = mergeCandidates . foldLeft ( iRange ) ( _ mergeWith _ ) < nl > + otherCandidates : + merged < nl > + } < nl > + < nl > + def multipartRanges ( ranges : Seq [ ByteRange ] , entity : UniversalEntity ) : Multipart . ByteRanges = { < nl > + val length = entity . contentLength < nl > + val iRanges : Seq [ IndexRange ] = ranges . map ( indexRange ( length ) ) < nl > + < nl > + / / It ' s only possible to run once over the input entity data stream because it ' s not known if the < nl > + / / source is reusable . < nl > + / / Therefore , ranges need to be sorted to prevent that some selected ranges already start to accumulate data < nl > + / / but cannot be sent out because another range is blocking the queue . < nl > + val coalescedRanges = coalesceRanges ( iRanges ) . sortBy ( _ . start ) < nl > + val source = coalescedRanges . size match { < nl > + case 0 ⇒ Source . empty < nl > + case 1 ⇒ < nl > + val range = coalescedRanges . head < nl > + val flow = StreamUtilsFix . sliceBytesTransformer ( range . start , range . length ) < nl > + val bytes = entity . dataBytes . via ( flow ) < nl > + val part = Multipart . ByteRanges . BodyPart ( range . contentRange ( length ) , HttpEntity ( entity . contentType , range . length , bytes ) ) < nl > + Source . single ( part ) < nl > + case n ⇒ < nl > + Source fromGraph GraphDSL . create ( ) { implicit b ⇒ < nl > + import GraphDSL . Implicits . _ < nl > + val bcast = b . add ( Broadcast [ ByteString ] ( n ) ) < nl > + val merge = b . add ( Concat [ Multipart . ByteRanges . BodyPart ] ( n ) ) < nl > + for ( range ← coalescedRanges ) { < nl > + val flow = StreamUtilsFix . sliceBytesTransformer ( range . start , range . length ) < nl > + bcast ~ > flow . buffer ( 16 , OverflowStrategy . backpressure ) . prefixAndTail ( 0 ) . map { < nl > + case ( _ , bytes ) ⇒ < nl > + Multipart . ByteRanges . BodyPart ( range . contentRange ( length ) , HttpEntity ( entity . contentType , range . length , bytes ) ) < nl > + } ~ > merge < nl > + } < nl > + entity . dataBytes ~ > bcast < nl > + SourceShape ( merge . out ) < nl > + } < nl > + } < nl > + Multipart . ByteRanges ( source ) < nl > + } < nl > + < nl > + def rangeResponse ( range : ByteRange , entity : UniversalEntity , length : Long , headers : immutable . Seq [ HttpHeader ] ) = { < nl > + val aiRange = indexRange ( length ) ( range ) < nl > + HttpResponse ( PartialContent , ` Content - Range ` ( aiRange . contentRange ( length ) ) + : headers , aiRange ( entity ) ) < nl > + } < nl > + < nl > + def satisfiable ( entityLength : Long ) ( range : ByteRange ) : Boolean = < nl > + range match { < nl > + case ByteRange . Slice ( firstPos , _ ) ⇒ firstPos < entityLength < nl > + case ByteRange . FromOffset ( firstPos ) ⇒ firstPos < entityLength < nl > + case ByteRange . Suffix ( length ) ⇒ length > 0 < nl > + } < nl > + def universal ( entity : HttpEntity ) : Option [ UniversalEntity ] = entity match { < nl > + case u : UniversalEntity ⇒ Some ( u ) < nl > + case _ ⇒ None < nl > + } < nl > + < nl > + def applyRanges ( ranges : immutable . Seq [ ByteRange ] ) : Directive0 = < nl > + extractRequestContext . flatMap { ctx ⇒ < nl > + mapRouteResultWithPF { < nl > + case Complete ( HttpResponse ( OK , headers , entity , protocol ) ) ⇒ < nl > + universal ( entity ) match { < nl > + case Some ( entity ) ⇒ < nl > + val length = entity . contentLength < nl > + ranges . filter ( satisfiable ( length ) ) match { < nl > + case Nil ⇒ ctx . reject ( UnsatisfiableRangeRejection ( ranges , length ) ) < nl > + case Seq ( satisfiableRange ) ⇒ ctx . complete ( rangeResponse ( satisfiableRange , entity , length , headers ) ) < nl > + case satisfiableRanges ⇒ < nl > + ctx . complete ( ( PartialContent , headers , multipartRanges ( satisfiableRanges , entity ) ) ) < nl > + } < nl > + case None ⇒ < nl > + / / Ranges not supported for Chunked or CloseDelimited responses < nl > + ctx . reject ( UnsatisfiableRangeRejection ( ranges , - 1 ) ) / / FIXME : provide better error < nl > + } < nl > + } < nl > + } < nl > + < nl > + def rangeHeaderOfGetRequests ( ctx : RequestContext ) : Option [ Range ] = < nl > + if ( ctx . request . method = = HttpMethods . GET ) ctx . request . header [ Range ] else None < nl > + < nl > + extract ( rangeHeaderOfGetRequests ) . flatMap { < nl > + case Some ( Range ( RangeUnits . Bytes , ranges ) ) ⇒ < nl > + if ( ranges . size < = rangeCountLimit ) applyRanges ( ranges ) & RangeDirectivesFix . respondWithAcceptByteRangesHeader < nl > + else reject ( TooManyRangesRejection ( rangeCountLimit ) ) < nl > + case _ ⇒ MethodDirectives . get & RangeDirectivesFix . respondWithAcceptByteRangesHeader | pass < nl > + } < nl > + } < nl > + } < nl > + < nl > + object RangeDirectivesFix extends RangeDirectivesFix { < nl > + private val respondWithAcceptByteRangesHeader : Directive0 = < nl > + RespondWithDirectives . respondWithHeader ( ` Accept - Ranges ` ( RangeUnits . Bytes ) ) < nl > + } < nl > diff - - git a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / StreamUtilsFix . scala b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / StreamUtilsFix . scala < nl > new file mode 100644 < nl > index 0000000 . . 79f68d0 < nl > - - - / dev / null < nl > + + + b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / StreamUtilsFix . scala < nl > @ @ - 0 , 0 + 1 , 45 @ @ < nl > + package im . actor . server . file . local . http . fix < nl > + < nl > + import akka . NotUsed < nl > + import akka . stream . scaladsl . Flow < nl > + import akka . stream . stage . { Context , StatefulStage , SyncDirective } < nl > + import akka . util . ByteString < nl > + < nl > + / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed < nl > + object StreamUtilsFix { < nl > + < nl > + def sliceBytesTransformer ( start : Long , length : Long ) : Flow [ ByteString , ByteString , NotUsed ] = { < nl > + val transformer = new StatefulStage [ ByteString , ByteString ] { < nl > + < nl > + def skipping = new State { < nl > + var toSkip = start < nl > + < nl > + override def onPush ( element : ByteString , ctx : Context [ ByteString ] ) : SyncDirective = < nl > + if ( element . length < toSkip ) { < nl > + / / keep skipping < nl > + toSkip - = element . length < nl > + ctx . pull ( ) < nl > + } else { < nl > + become ( taking ( length ) ) < nl > + / / toSkip < = element . length < = Int . MaxValue < nl > + current . onPush ( element . drop ( toSkip . toInt ) , ctx ) < nl > + } < nl > + } < nl > + < nl > + def taking ( initiallyRemaining : Long ) = new State { < nl > + var remaining : Long = initiallyRemaining < nl > + < nl > + override def onPush ( element : ByteString , ctx : Context [ ByteString ] ) : SyncDirective = { < nl > + val data = element . take ( math . min ( remaining , Int . MaxValue ) . toInt ) < nl > + remaining - = data . size < nl > + if ( remaining < = 0 ) ctx . pushAndFinish ( data ) < nl > + else ctx . push ( data ) < nl > + } < nl > + } < nl > + < nl > + override def initial : State = if ( start > 0 ) skipping else taking ( length ) < nl > + } < nl > + Flow [ ByteString ] . transform ( ( ) ⇒ transformer ) . named ( " sliceBytes " ) < nl > + } < nl > + < nl > + } < nl > diff - - git a / actor - server / project / Build . scala b / actor - server / project / Build . scala < nl > index f7bf8b0 . . 63f0304 100644 < nl > - - - a / actor - server / project / Build . scala < nl > + + + b / actor - server / project / Build . scala < nl > @ @ - 263 , 7 + 263 , 8 @ @ object Build extends sbt . Build with Versioning with Releasing { < nl > id = " actor - fs - adapters " , < nl > base = file ( " actor - fs - adapters " ) , < nl > settings = defaultSettingsServer + + Seq ( < nl > - libraryDependencies + + = Dependencies . fileAdapter < nl > + libraryDependencies + + = Dependencies . fileAdapter , < nl > + scalacOptions in Compile : = ( scalacOptions in Compile ) . value . filterNot ( _ = = " - Xfatal - warnings " ) < nl > ) < nl > ) < nl > . dependsOn ( actorHttpApi , actorPersist )
NEAREST DIFF (one line): diff - - git a / actor - http - api / src / main / scala / im / actor / server / api / http / GroupInfoHandler . scala b / actor - http - api / src / main / scala / im / actor / server / api / http / GroupInfoHandler . scala < nl > new file mode 100644 < nl > index 0000000 . . de782d5 < nl > - - - / dev / null < nl > + + + b / actor - http - api / src / main / scala / im / actor / server / api / http / GroupInfoHandler . scala < nl > @ @ - 0 , 0 + 1 , 57 @ @ < nl > + package im . actor . server . api . http < nl > + < nl > + import scala . concurrent . duration . _ < nl > + import scala . concurrent . { ExecutionContext , Future } < nl > + < nl > + import akka . actor . ActorSystem < nl > + import com . github . dwhjames . awswrap . s3 . AmazonS3ScalaClient < nl > + import slick . driver . PostgresDriver . api . _ < nl > + < nl > + import im . actor . server . util . FileUtils . getFileUrl < nl > + import im . actor . server . util . ImageUtils . getAvatar < nl > + import im . actor . server . { models , persist } < nl > + < nl > + class GroupInfoHandler ( s3BucketName : String ) ( < nl > + implicit < nl > + db : Database , < nl > + system : ActorSystem , < nl > + ec : ExecutionContext , < nl > + client : AmazonS3ScalaClient < nl > + ) { < nl > + < nl > + def retrieve ( token : String ) : Future [ Either [ Errors , GroupInviteInfo ] ] = < nl > + db . run { < nl > + for { < nl > + optToken ← persist . GroupInviteToken . findByToken ( token ) < nl > + result ← optToken . map { token ⇒ < nl > + for { < nl > + groupTitle ← persist . Group . findTitle ( token . groupId ) < nl > + groupAvatar ← persist . AvatarData . findByGroupId ( token . groupId ) < nl > + groupAvatarUrl ← avatarUrl ( groupAvatar ) < nl > + < nl > + inviterName ← persist . User . findName ( token . creatorId ) < nl > + inviterAvatar ← persist . AvatarData . findByUserId ( token . creatorId ) . headOption < nl > + inviterAvatarUrl ← avatarUrl ( inviterAvatar ) < nl > + } yield Right ( GroupInviteInfo ( groupTitle . getOrElse ( " Group " ) , groupAvatarUrl , inviterName . getOrElse ( " User " ) , inviterAvatarUrl ) ) < nl > + } . getOrElse ( DBIO . successful ( Left ( Errors ( " Expired or invalid token " ) ) ) ) < nl > + } yield result < nl > + } < nl > + < nl > + private def avatarUrl ( optAvatar : Option [ models . AvatarData ] ) : DBIO [ Option [ String ] ] = { < nl > + val optLocation = for { < nl > + modelAvatar ← optAvatar < nl > + structAvatar = getAvatar ( modelAvatar ) < nl > + fileLocation ← List ( structAvatar . largeImage , structAvatar . smallImage , structAvatar . fullImage ) . find ( _ . isDefined ) . flatten . map ( _ . fileLocation ) < nl > + } yield fileLocation < nl > + implicit val timeout = 1 . day < nl > + optLocation . map { location ⇒ < nl > + for { < nl > + fileOpt ← persist . File . find ( location . fileId ) < nl > + url ← fileOpt . map { file ⇒ < nl > + DBIO . from ( getFileUrl ( file , location . accessHash , s3BucketName ) ) < nl > + } . getOrElse ( DBIO . successful ( None ) ) < nl > + } yield url < nl > + } . getOrElse ( DBIO . successful ( None ) ) < nl > + } < nl > + < nl > + } < nl > \ No newline at end of file < nl > diff - - git a / actor - http - api / src / main / scala / im / actor / server / api / http / HttpApiFrontend . scala b / actor - http - api / src / main / scala / im / actor / server / api / http / HttpApiFrontend . scala < nl > index 0facb91 . . d2b8bf1 100644 < nl > - - - a / actor - http - api / src / main / scala / im / actor / server / api / http / HttpApiFrontend . scala < nl > + + + b / actor - http - api / src / main / scala / im / actor / server / api / http / HttpApiFrontend . scala < nl > @ @ - 5 , 49 + 5 , 72 @ @ import scala . util . { Failure , Success } < nl > < nl > import akka . actor . ActorSystem < nl > import akka . http . scaladsl . Http < nl > - import akka . http . scaladsl . model . { HttpRequest , HttpResponse , StatusCodes } < nl > + import akka . http . scaladsl . model . StatusCodes . { InternalServerError , NotAcceptable , OK } < nl > + import akka . http . scaladsl . model . { HttpRequest , HttpResponse } < nl > import akka . http . scaladsl . server . Directives . _ < nl > import akka . http . scaladsl . server . Route < nl > import akka . http . scaladsl . unmarshalling . Unmarshaller < nl > import akka . stream . FlowMaterializer < nl > import akka . stream . scaladsl . Sink < nl > + import com . github . dwhjames . awswrap . s3 . AmazonS3ScalaClient < nl > import play . api . libs . json . Json < nl > import slick . driver . PostgresDriver . api . _ < nl > < nl > + import im . actor . server . api . http . JsonImplicits . _ < nl > import im . actor . server . peermanagers . GroupPeerManagerRegion < nl > < nl > object HttpApiFrontend { < nl > < nl > - def start ( config : HttpApiConfig ) ( < nl > + def start ( config : HttpApiConfig , s3BucketName : String ) ( < nl > implicit < nl > system : ActorSystem , < nl > materializer : FlowMaterializer , < nl > db : Database , < nl > - groupPeerManagerRegion : GroupPeerManagerRegion < nl > + groupPeerManagerRegion : GroupPeerManagerRegion , < nl > + client : AmazonS3ScalaClient < nl > ) : Unit = { < nl > < nl > implicit val ec : ExecutionContext = system . dispatcher < nl > < nl > + val groupInfo = new GroupInfoHandler ( s3BucketName ) < nl > + val webhooks = new WebhookHandler ( ) < nl > + < nl > / / TODO : replace to object , import in scope < nl > implicit val toContent = Unmarshaller . apply [ HttpRequest , Content ] { implicit ec ⇒ req ⇒ < nl > - < nl > - import JsonImplicits . _ < nl > - < nl > req . entity . dataBytes < nl > . map { data ⇒ Json . parse ( data . decodeString ( " utf - 8 " ) ) . as [ Content ] } < nl > . runWith ( Sink . head ) < nl > } < nl > < nl > def routes : Route = < nl > - path ( " v1 " / " webhooks " / Segment ) { token ⇒ < nl > - post { < nl > - entity ( as [ Content ] ) { content ⇒ < nl > - onComplete ( new WebhookHandler ( ) . send ( content , token ) ) { < nl > - case Success ( _ ) ⇒ complete ( HttpResponse ( StatusCodes . OK ) ) < nl > - case Failure ( e ) ⇒ complete ( HttpResponse ( StatusCodes . InternalServerError ) ) < nl > + pathPrefix ( " v1 " ) { < nl > + path ( " group - invite - info " / Segment ) { token ⇒ < nl > + ( get | post ) { < nl > + onComplete ( groupInfo . retrieve ( token ) ) { < nl > + case Success ( Right ( result ) ) ⇒ < nl > + complete ( HttpResponse ( < nl > + status = OK , < nl > + entity = Json . stringify ( Json . toJson ( result ) ) < nl > + ) ) < nl > + case Success ( Left ( errors ) ) ⇒ < nl > + complete ( HttpResponse ( < nl > + status = NotAcceptable , < nl > + entity = Json . stringify ( Json . toJson ( errors ) ) < nl > + ) ) < nl > + case Failure ( e ) ⇒ complete ( HttpResponse ( InternalServerError ) ) < nl > + } < nl > + } < nl > + } ~ < nl > + path ( " webhooks " / Segment ) { token ⇒ < nl > + post { < nl > + entity ( as [ Content ] ) { content ⇒ < nl > + onComplete ( webhooks . send ( content , token ) ) { < nl > + case Success ( _ ) ⇒ complete ( HttpResponse ( OK ) ) < nl > + case Failure ( e ) ⇒ complete ( HttpResponse ( InternalServerError ) ) < nl > + } < nl > + } < nl > } < nl > } < nl > - } < nl > } < nl > < nl > Http ( ) . bind ( config . interface , config . port ) . runForeach { connection ⇒ < nl > diff - - git a / actor - http - api / src / main / scala / im / actor / server / api / http / Models . scala b / actor - http - api / src / main / scala / im / actor / server / api / http / Models . scala < nl > index 42d9504 . . 051b6fb 100644 < nl > - - - a / actor - http - api / src / main / scala / im / actor / server / api / http / Models . scala < nl > + + + b / actor - http - api / src / main / scala / im / actor / server / api / http / Models . scala < nl > @ @ - 8 , 6 + 8 , 14 @ @ case class Text ( text : String ) extends Content < nl > case class Image ( imageUrl : String ) extends Content < nl > case class Document ( documentUrl : String ) extends Content < nl > < nl > + case class GroupInviteInfo ( < nl > + groupTitle : String , < nl > + groupAvatarUrl : Option [ String ] , < nl > + inviterName : String , < nl > + inviterAvatarUrl : Option [ String ] < nl > + ) < nl > + case class Errors ( message : String ) < nl > + < nl > object JsonImplicits { < nl > < nl > implicit val textReads : Reads [ Content ] = < nl > @ @ - 15 , 4 + 23 , 7 @ @ object JsonImplicits { < nl > ( JsPath \ " document _ url " ) . read [ String ] . map [ Content ] { Document } | < nl > ( JsPath \ " image _ url " ) . read [ String ] . map [ Content ] { Image } < nl > < nl > + implicit val groupInviteInfoFormat : Format [ GroupInviteInfo ] = Json . format [ GroupInviteInfo ] < nl > + implicit val errorsFormat : Format [ Errors ] = Json . format [ Errors ] < nl > + < nl > } < nl > \ No newline at end of file < nl > diff - - git a / actor - rpc - api / src / main / scala / im / actor / server / api / rpc / service / files / FilesServiceImpl . scala b / actor - rpc - api / src / main / scala / im / actor / server / api / rpc / service / files / FilesServiceImpl . scala < nl > index 629b0d3 . . 67d9eb6 100644 < nl > - - - a / actor - rpc - api / src / main / scala / im / actor / server / api / rpc / service / files / FilesServiceImpl . scala < nl > + + + b / actor - rpc - api / src / main / scala / im / actor / server / api / rpc / service / files / FilesServiceImpl . scala < nl > @ @ - 7 , 6 + 7 , 7 @ @ import scala . collection . mutable < nl > import scala . concurrent . duration . _ < nl > import scala . concurrent . forkjoin . ThreadLocalRandom < nl > import scala . concurrent . { ExecutionContext , Future } < nl > + import scala . util . { Failure , Success } < nl > < nl > import akka . actor . _ < nl > import com . amazonaws . HttpMethod < nl > @ @ - 36 , 30 + 37 , 21 @ @ class FilesServiceImpl ( bucketName : String ) ( < nl > override implicit val ec : ExecutionContext = actorSystem . dispatcher < nl > < nl > override def jhandleGetFileUrl ( location : FileLocation , clientData : ClientData ) : Future [ HandlerResult [ ResponseGetFileUrl ] ] = { < nl > - val authorizedAction = requireAuth ( clientData ) . map { client ⇒ < nl > + val authorizedAction = requireAuth ( clientData ) map { client ⇒ < nl > persist . File . find ( location . fileId ) flatMap { < nl > - case Some ( file ) ⇒ < nl > - if ( ACLUtils . fileAccessHash ( file . id , file . accessSalt ) = = location . accessHash ) { < nl > - val presignedRequest = new GeneratePresignedUrlRequest ( bucketName , FileUtils . s3Key ( file . id , file . name ) ) < nl > - val timeout = 1 . day < nl > - < nl > - val expiration = new java . util . Date < nl > - expiration . setTime ( expiration . getTime + timeout . toMillis ) < nl > - presignedRequest . setExpiration ( expiration ) < nl > - presignedRequest . setMethod ( HttpMethod . GET ) < nl > - < nl > - for { < nl > - url ← DBIO . from ( s3Client . generatePresignedUrlRequest ( presignedRequest ) ) < nl > - } yield { < nl > - Ok ( ResponseGetFileUrl ( url . toString , timeout . toSeconds . toInt ) ) < nl > + implicit val timeout = 1 . day < nl > + < nl > + { < nl > + case Some ( file ) ⇒ < nl > + DBIO . from ( FileUtils . getFileUrl ( file , location . accessHash , bucketName ) ) . map { optUrl ⇒ < nl > + optUrl . map { url ⇒ < nl > + Ok ( ResponseGetFileUrl ( url , timeout . toSeconds . toInt ) ) < nl > + } . getOrElse ( Error ( Errors . LocationInvalid ) ) < nl > } < nl > - } else { < nl > - DBIO . successful ( Error ( Errors . LocationInvalid ) ) < nl > - } < nl > - case None ⇒ DBIO . successful ( Error ( Errors . LocationInvalid ) ) < nl > + case None ⇒ DBIO . successful ( Error ( Errors . LocationInvalid ) ) < nl > + } < nl > } < nl > } < nl > - < nl > db . run ( toDBIOAction ( authorizedAction ) ) < nl > } < nl > < nl > diff - - git a / actor - tests / src / test / scala / im / actor / server / http / HttpApiFrontendSpec . scala b / actor - tests / src / test / scala / im / actor / server / http / HttpApiFrontendSpec . scala < nl > index 804adfa . . 1071cf9 100644 < nl > - - - a / actor - tests / src / test / scala / im / actor / server / http / HttpApiFrontendSpec . scala < nl > + + + b / actor - tests / src / test / scala / im / actor / server / http / HttpApiFrontendSpec . scala < nl > @ @ - 4 , 6 + 4 , 7 @ @ import akka . http . scaladsl . Http < nl > import akka . http . scaladsl . model . { HttpMethods , HttpRequest , StatusCodes } < nl > import com . amazonaws . auth . EnvironmentVariableCredentialsProvider < nl > import com . amazonaws . services . s3 . transfer . TransferManager < nl > + import com . github . dwhjames . awswrap . s3 . AmazonS3ScalaClient < nl > < nl > import im . actor . api . rpc . ClientData < nl > import im . actor . server . api . http . { HttpApiConfig , HttpApiFrontend } < nl > @ @ - 36 , 6 + 37 , 7 @ @ class HttpApiFrontendSpec extends BaseAppSuite with GroupsServiceHelpers { < nl > val bucketName = " actor - uploads - test " < nl > val awsCredentials = new EnvironmentVariableCredentialsProvider ( ) < nl > implicit val transferManager = new TransferManager ( awsCredentials ) < nl > + implicit val client = new AmazonS3ScalaClient ( awsCredentials ) < nl > val groupInviteConfig = GroupInviteConfig ( " http : / / actor . im " ) < nl > < nl > implicit val service = messaging . MessagingServiceImpl ( mediator ) < nl > @ @ - 53 , 7 + 55 , 7 @ @ class HttpApiFrontendSpec extends BaseAppSuite with GroupsServiceHelpers { < nl > val groupOutPeer = createGroup ( " Bot test group " , Set ( user2 . id ) ) . groupPeer < nl > < nl > val config = HttpApiConfig ( " http " , " localhost " , 9000 ) < nl > - HttpApiFrontend . start ( config ) < nl > + HttpApiFrontend . start ( config , " actor - uploads - test " ) < nl > < nl > val http = Http ( ) < nl > < nl > diff - - git a / actor - tests / src / test / scala / im / actor / server / http / WebhookHandlerSpec . scala b / actor - tests / src / test / scala / im / actor / server / http / WebhookHandlerSpec . scala < nl > index fb0a06a . . e6e3017 100644 < nl > - - - a / actor - tests / src / test / scala / im / actor / server / http / WebhookHandlerSpec . scala < nl > + + + b / actor - tests / src / test / scala / im / actor / server / http / WebhookHandlerSpec . scala < nl > @ @ - 5 , 7 + 5 , 7 @ @ import com . amazonaws . services . s3 . transfer . TransferManager < nl > < nl > import im . actor . api . rpc . ClientData < nl > import im . actor . api . rpc . messaging . TextMessage < nl > - import im . actor . server . api . http . { WebhookHandler , Text } < nl > + import im . actor . server . api . http . { Text , WebhookHandler } < nl > import im . actor . server . api . rpc . service . GroupsServiceHelpers < nl > import im . actor . server . api . rpc . service . groups . { GroupInviteConfig , GroupsServiceImpl } < nl > import im . actor . server . models . Peer < nl > diff - - git a / actor - utils / src / main / scala / im / actor / server / util / FileUtils . scala b / actor - utils / src / main / scala / im / actor / server / util / FileUtils . scala < nl > index b2c952a . . 3450b75 100644 < nl > - - - a / actor - utils / src / main / scala / im / actor / server / util / FileUtils . scala < nl > + + + b / actor - utils / src / main / scala / im / actor / server / util / FileUtils . scala < nl > @ @ - 1 , 8 + 1 , 9 @ @ < nl > package im . actor . server . util < nl > < nl > - import java . io . File < nl > + import java . io . { Serializable , File } < nl > import java . nio . file . { Files , Path } < nl > < nl > + import scala . concurrent . duration . FiniteDuration < nl > import scala . concurrent . forkjoin . ThreadLocalRandom < nl > import scala . concurrent . { ExecutionContext , Future , blocking } < nl > < nl > @ @ - 11 , 15 + 12 , 18 @ @ import akka . stream . FlowMaterializer < nl > import akka . stream . io . SynchronousFileSink < nl > import akka . stream . scaladsl . Source < nl > import akka . util . ByteString < nl > + import com . amazonaws . HttpMethod < nl > + import com . amazonaws . services . s3 . model . GeneratePresignedUrlRequest < nl > import com . amazonaws . services . s3 . transfer . TransferManager < nl > import com . amazonaws . services . s3 . transfer . model . UploadResult < nl > - import com . github . dwhjames . awswrap . s3 . FutureTransfer < nl > + import com . github . dwhjames . awswrap . s3 . { AmazonS3ScalaClient , FutureTransfer } < nl > import slick . dbio < nl > import slick . dbio . Effect . { Read , Write } < nl > import slick . driver . PostgresDriver . api . _ < nl > < nl > - import im . actor . api . rpc . files . FileLocation < nl > + import im . actor . api . rpc . files . { ResponseGetFileUrl , FileLocation } < nl > import im . actor . server . persist < nl > + import im . actor . server . models < nl > < nl > object FileUtils { < nl > < nl > @ @ - 70 , 6 + 74 , 25 @ @ object FileUtils { < nl > FutureTransfer . listenFor ( transferManager . upload ( bucketName , s3Key ( id , name ) , file ) ) map ( _ . waitForUploadResult ( ) ) < nl > } < nl > < nl > + def getFileUrl ( file : models . File , accessHash : Long , bucketName : String ) ( < nl > + implicit < nl > + system : ActorSystem , < nl > + ec : ExecutionContext , < nl > + s3Client : AmazonS3ScalaClient , < nl > + timeout : FiniteDuration < nl > + ) : Future [ Option [ String ] ] = { < nl > + if ( ACLUtils . fileAccessHash ( file . id , file . accessSalt ) = = accessHash ) { < nl > + val presignedRequest = new GeneratePresignedUrlRequest ( bucketName , s3Key ( file . id , file . name ) ) < nl > + < nl > + val expiration = new java . util . Date < nl > + expiration . setTime ( expiration . getTime + timeout . toMillis ) < nl > + presignedRequest . setExpiration ( expiration ) < nl > + presignedRequest . setMethod ( HttpMethod . GET ) < nl > + < nl > + s3Client . generatePresignedUrlRequest ( presignedRequest ) . map ( _ . toString ) . map ( Some ( _ ) ) < nl > + } else Future . successful ( None ) < nl > + } < nl > + < nl > def s3Key ( id : Long , name : String ) : String = { < nl > if ( name . isEmpty ) { < nl > s " file _ $ { id } " < nl > diff - - git a / src / main / scala / im / actor / server / Main . scala b / src / main / scala / im / actor / server / Main . scala < nl > index 9a49377 . . ed53512 100644 < nl > - - - a / src / main / scala / im / actor / server / Main . scala < nl > + + + b / src / main / scala / im / actor / server / Main . scala < nl > @ @ - 107 , 15 + 107 , 13 @ @ class Main extends Bootable with DbInit with FlywayInit { < nl > val downloadManager = new DownloadManager < nl > implicit val uploadManager = new UploadManager ( s3BucketName ) < nl > < nl > - val messagingService = MessagingServiceImpl ( mediator ) < nl > - < nl > MessageInterceptor . startSingleton ( ilectro , downloadManager , uploadManager , mediator , ilectroInterceptionConfig ) < nl > RichMessageWorker . startWorker ( richMessageConfig , mediator ) < nl > < nl > val services = Seq ( < nl > new AuthServiceImpl ( activationContext , mediator ) , < nl > new ContactsServiceImpl , < nl > - messagingService , < nl > + MessagingServiceImpl ( mediator ) , < nl > new GroupsServiceImpl ( s3BucketName , groupInviteConfig ) , < nl > new SequenceServiceImpl , < nl > new WeakServiceImpl , < nl > @ @ - 130 , 7 + 128 , 7 @ @ class Main extends Bootable with DbInit with FlywayInit { < nl > < nl > system . actorOf ( RpcApiService . props ( services ) , " rpcApiService " ) < nl > < nl > - HttpApiFrontend . start ( httpApiConfig ) < nl > + HttpApiFrontend . start ( httpApiConfig , s3BucketName ) < nl > TcpFrontend . start ( serverConfig , sessionRegion ) < nl > WsFrontend . start ( serverConfig , sessionRegion )

TEST DIFF:
diff - - git a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / FilesHttpHandler . scala b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / FilesHttpHandler . scala 
 index 03a888d . . 4a4e7eb 100644 
 - - - a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / FilesHttpHandler . scala 
 + + + b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / FilesHttpHandler . scala 
 @ @ - 13 , 6 + 13 , 7 @ @ import akka . http . scaladsl . server . _ 
 import akka . stream . ActorMaterializer 
 import im . actor . server . api . http . HttpHandler 
 import im . actor . server . api . http . HttpApiHelpers . _ 
 + import im . actor . server . file . local . http . fix . GetFileFix 
 import im . actor . server . file . local . { FileStorageOperations , LocalFileStorageConfig , RequestSigning } 
 import im . actor . util . log . AnyRefLogSource 
 
 @ @ - 63 , 22 + 64 , 20 @ @ private [ local ] final class FilesHttpHandler ( storageConfig : LocalFileStorageConfi 
 / / v1 / files / : fileId 
 path ( Segments ( 0 , 1 ) ) { seqName = > 
 log . debug ( " Download file request , fileId : { } " , fileId ) 
 - withRangeSupport { 
 - onComplete ( getFile ( fileId ) ) { 
 - case Success ( Some ( file ) ) = > 
 - log . debug ( " Serving fileId : { } , file : { } parts " , fileId , file ) 
 - respondWithDefaultHeader ( 
 - ` Content - Disposition ` ( attachment , Map ( " filename " - > file . name ) ) 
 - ) { 
 - / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed 
 - getFromFileFix ( file . toJava ) 
 - } 
 - case Success ( None ) = > 
 - complete ( HttpResponse ( StatusCodes . NotFound ) ) 
 - case Failure ( e ) = > 
 - log . error ( e , " Failed to get file content , fileId : { } " , fileId ) 
 - complete ( HttpResponse ( 500 ) ) 
 - } 
 + onComplete ( getFile ( fileId ) ) { 
 + case Success ( Some ( file ) ) = > 
 + log . debug ( " Serving fileId : { } , file : { } parts " , fileId , file ) 
 + respondWithDefaultHeader ( 
 + ` Content - Disposition ` ( attachment , Map ( " filename " - > file . name ) ) 
 + ) { 
 + / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed 
 + getFromFileFix ( file . toJava ) 
 + } 
 + case Success ( None ) = > 
 + complete ( HttpResponse ( StatusCodes . NotFound ) ) 
 + case Failure ( e ) = > 
 + log . error ( e , " Failed to get file content , fileId : { } " , fileId ) 
 + complete ( HttpResponse ( 500 ) ) 
 } 
 } 
 } ~ 
 diff - - git a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / GetFileFix . scala b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / GetFileFix . scala 
 deleted file mode 100644 
 index 81eeac4 . . 0000000 
 - - - a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / GetFileFix . scala 
 + + + / dev / null 
 @ @ - 1 , 53 + 0 , 0 @ @ 
 - package im . actor . server . file . local . http 
 - 
 - import java . io . File 
 - 
 - import akka . http . scaladsl . model . headers . EntityTag 
 - import akka . http . scaladsl . server . _ 
 - import akka . http . scaladsl . server . Directives . _ 
 - import akka . http . scaladsl . model . { ContentType , DateTime , HttpEntity } 
 - import akka . http . scaladsl . server . Route 
 - import akka . http . scaladsl . server . directives . BasicDirectives . { extractSettings ⇒ _ , pass ⇒ _ , _ } 
 - import akka . http . scaladsl . server . directives . CacheConditionDirectives . { conditional ⇒ _ , _ } 
 - import akka . http . scaladsl . server . directives . { BasicDirectives , CodingDirectives , ContentTypeResolver , RangeDirectives } 
 - import akka . stream . ActorAttributes 
 - import akka . stream . scaladsl . FileIO 
 - 
 - / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed 
 - trait GetFileFix { 
 - 
 - private val withRangeSupportAndPrecompressedMediaTypeSupportAndExtractSettings = 
 - RangeDirectives . withRangeSupport & 
 - CodingDirectives . withPrecompressedMediaTypeSupport & 
 - BasicDirectives . extractSettings 
 - 
 - def getFromFileFix ( file : File ) ( implicit resolver : ContentTypeResolver ) : Route = 
 - getFromFile ( file , resolver ( file . getName ) ) 
 - 
 - private def getFromFile ( file : File , contentType : ContentType ) : Route = 
 - get { 
 - if ( file . isFile & & file . canRead ) 
 - conditionalFor ( file . length , file . lastModified ) { 
 - if ( file . length > 0 ) { 
 - withRangeSupportAndPrecompressedMediaTypeSupportAndExtractSettings { settings ⇒ 
 - complete { 
 - HttpEntity . Chunked . fromData ( 
 - contentType , 
 - FileIO . fromFile ( file ) . withAttributes ( ActorAttributes . dispatcher ( settings . fileIODispatcher ) ) 
 - ) 
 - } 
 - } 
 - } else complete ( HttpEntity . Empty ) 
 - } 
 - else reject 
 - } 
 - 
 - private def conditionalFor ( length : Long , lastModified : Long ) : Directive0 = 
 - extractSettings . flatMap ( settings ⇒ 
 - if ( settings . fileGetConditional ) { 
 - val tag = java . lang . Long . toHexString ( lastModified ^ java . lang . Long . reverse ( length ) ) 
 - val lastModifiedDateTime = DateTime ( math . min ( lastModified , System . currentTimeMillis ) ) 
 - conditional ( EntityTag ( tag ) , lastModifiedDateTime ) 
 - } else pass ) 
 - 
 - } 
 diff - - git a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / GetFileFix . scala b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / GetFileFix . scala 
 new file mode 100644 
 index 0000000 . . f2bc574 
 - - - / dev / null 
 + + + b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / GetFileFix . scala 
 @ @ - 0 , 0 + 1 , 50 @ @ 
 + package im . actor . server . file . local . http . fix 
 + 
 + import java . io . File 
 + 
 + import akka . http . scaladsl . model . headers . EntityTag 
 + import akka . http . scaladsl . model . { ContentType , DateTime , HttpEntity } 
 + import akka . http . scaladsl . server . Directives . _ 
 + import akka . http . scaladsl . server . { Route , _ } 
 + import akka . http . scaladsl . server . directives . BasicDirectives . { extractSettings ⇒ _ , pass ⇒ _ } 
 + import akka . http . scaladsl . server . directives . CacheConditionDirectives . { conditional ⇒ _ } 
 + import akka . http . scaladsl . server . directives . { BasicDirectives , CodingDirectives , ContentTypeResolver } 
 + import akka . stream . ActorAttributes 
 + import akka . stream . scaladsl . FileIO 
 + 
 + / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed 
 + trait GetFileFix { 
 + 
 + private val withRangeSupportAndPrecompressedMediaTypeSupportAndExtractSettings = 
 + RangeDirectivesFix . withRangeSupport & 
 + CodingDirectives . withPrecompressedMediaTypeSupport & 
 + BasicDirectives . extractSettings 
 + 
 + def getFromFileFix ( file : File ) ( implicit resolver : ContentTypeResolver ) : Route = 
 + getFromFile ( file , resolver ( file . getName ) ) 
 + 
 + private def getFromFile ( file : File , contentType : ContentType ) : Route = 
 + get { 
 + if ( file . isFile & & file . canRead ) 
 + conditionalFor ( file . length , file . lastModified ) { 
 + if ( file . length > 0 ) { 
 + withRangeSupportAndPrecompressedMediaTypeSupportAndExtractSettings { settings ⇒ 
 + complete { 
 + HttpEntity . Default ( contentType , file . length , 
 + FileIO . fromFile ( file ) . withAttributes ( ActorAttributes . dispatcher ( settings . fileIODispatcher ) ) ) 
 + } 
 + } 
 + } else complete ( HttpEntity . Empty ) 
 + } 
 + else reject 
 + } 
 + 
 + private def conditionalFor ( length : Long , lastModified : Long ) : Directive0 = 
 + extractSettings . flatMap ( settings ⇒ 
 + if ( settings . fileGetConditional ) { 
 + val tag = java . lang . Long . toHexString ( lastModified ^ java . lang . Long . reverse ( length ) ) 
 + val lastModifiedDateTime = DateTime ( math . min ( lastModified , System . currentTimeMillis ) ) 
 + conditional ( EntityTag ( tag ) , lastModifiedDateTime ) 
 + } else pass ) 
 + 
 + } 
 diff - - git a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / RangeDirectivesFix . scala b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / RangeDirectivesFix . scala 
 new file mode 100644 
 index 0000000 . . c3d2fdf 
 - - - / dev / null 
 + + + b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / RangeDirectivesFix . scala 
 @ @ - 0 , 0 + 1 , 162 @ @ 
 + / * 
 + * Copyright ( C ) 2009 - 2016 Lightbend Inc . < http : / / www . lightbend . com > 
 + * / 
 + 
 + package im . actor . server . file . local . http . fix 
 + 
 + import akka . http . scaladsl . model . StatusCodes . _ 
 + import akka . http . scaladsl . model . _ 
 + import akka . http . scaladsl . model . headers . _ 
 + import akka . http . scaladsl . server . RouteResult . Complete 
 + import akka . http . scaladsl . server . directives . { MethodDirectives , RespondWithDirectives } 
 + import akka . http . scaladsl . server . { Directive0 , RequestContext , TooManyRangesRejection , UnsatisfiableRangeRejection } 
 + import akka . stream . scaladsl . _ 
 + import akka . stream . { OverflowStrategy , SourceShape } 
 + import akka . util . ByteString 
 + 
 + import scala . collection . immutable 
 + 
 + / * * 
 + * @ groupname range Range directives 
 + * @ groupprio range 180 
 + * / 
 + / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed 
 + trait RangeDirectivesFix { 
 + import akka . http . scaladsl . server . directives . BasicDirectives . _ 
 + import akka . http . scaladsl . server . directives . RouteDirectives . _ 
 + 
 + / * * 
 + * Answers GET requests with an ` Accept - Ranges : bytes ` header and converts HttpResponses coming back from its inner 
 + * route into partial responses if the initial request contained a valid ` Range ` request header . The requested 
 + * byte - ranges may be coalesced . 
 + * This directive is transparent to non - GET requests 
 + * Rejects requests with unsatisfiable ranges ` UnsatisfiableRangeRejection ` . 
 + * Rejects requests with too many expected ranges . 
 + * 
 + * Note : if you want to combine this directive with ` conditional ( . . . ) ` you need to put 
 + * it on the * inside * of the ` conditional ( . . . ) ` directive , i . e . ` conditional ( . . . ) ` must be 
 + * on a higher level in your route structure in order to function correctly . 
 + * 
 + * @ see [ [ https : / / tools . ietf . org / html / rfc7233 ] ] 
 + * 
 + * @ group range 
 + * / 
 + def withRangeSupport : Directive0 = 
 + extractRequestContext . flatMap { ctx ⇒ 
 + val settings = ctx . settings 
 + implicit val log = ctx . log 
 + import settings . { rangeCoalescingThreshold , rangeCountLimit } 
 + 
 + class IndexRange ( val start : Long , val end : Long ) { 
 + def length = end - start 
 + def apply ( entity : UniversalEntity ) : UniversalEntity = entity . transformDataBytes ( length , StreamUtilsFix . sliceBytesTransformer ( start , length ) ) 
 + def distance ( other : IndexRange ) = mergedEnd ( other ) - mergedStart ( other ) - ( length + other . length ) 
 + def mergeWith ( other : IndexRange ) = new IndexRange ( mergedStart ( other ) , mergedEnd ( other ) ) 
 + def contentRange ( entityLength : Long ) = ContentRange ( start , end - 1 , entityLength ) 
 + private def mergedStart ( other : IndexRange ) = math . min ( start , other . start ) 
 + private def mergedEnd ( other : IndexRange ) = math . max ( end , other . end ) 
 + } 
 + 
 + def indexRange ( entityLength : Long ) ( range : ByteRange ) : IndexRange = 
 + range match { 
 + case ByteRange . Slice ( start , end ) ⇒ new IndexRange ( start , math . min ( end + 1 , entityLength ) ) 
 + case ByteRange . FromOffset ( first ) ⇒ new IndexRange ( first , entityLength ) 
 + case ByteRange . Suffix ( suffixLength ) ⇒ new IndexRange ( math . max ( 0 , entityLength - suffixLength ) , entityLength ) 
 + } 
 + 
 + / / See comment of the ` range - coalescing - threshold ` setting in ` reference . conf ` for the rationale of this behavior . 
 + def coalesceRanges ( iRanges : Seq [ IndexRange ] ) : Seq [ IndexRange ] = 
 + iRanges . foldLeft ( Seq . empty [ IndexRange ] ) { ( acc , iRange ) ⇒ 
 + val ( mergeCandidates , otherCandidates ) = acc . partition ( _ . distance ( iRange ) < = rangeCoalescingThreshold ) 
 + val merged = mergeCandidates . foldLeft ( iRange ) ( _ mergeWith _ ) 
 + otherCandidates : + merged 
 + } 
 + 
 + def multipartRanges ( ranges : Seq [ ByteRange ] , entity : UniversalEntity ) : Multipart . ByteRanges = { 
 + val length = entity . contentLength 
 + val iRanges : Seq [ IndexRange ] = ranges . map ( indexRange ( length ) ) 
 + 
 + / / It ' s only possible to run once over the input entity data stream because it ' s not known if the 
 + / / source is reusable . 
 + / / Therefore , ranges need to be sorted to prevent that some selected ranges already start to accumulate data 
 + / / but cannot be sent out because another range is blocking the queue . 
 + val coalescedRanges = coalesceRanges ( iRanges ) . sortBy ( _ . start ) 
 + val source = coalescedRanges . size match { 
 + case 0 ⇒ Source . empty 
 + case 1 ⇒ 
 + val range = coalescedRanges . head 
 + val flow = StreamUtilsFix . sliceBytesTransformer ( range . start , range . length ) 
 + val bytes = entity . dataBytes . via ( flow ) 
 + val part = Multipart . ByteRanges . BodyPart ( range . contentRange ( length ) , HttpEntity ( entity . contentType , range . length , bytes ) ) 
 + Source . single ( part ) 
 + case n ⇒ 
 + Source fromGraph GraphDSL . create ( ) { implicit b ⇒ 
 + import GraphDSL . Implicits . _ 
 + val bcast = b . add ( Broadcast [ ByteString ] ( n ) ) 
 + val merge = b . add ( Concat [ Multipart . ByteRanges . BodyPart ] ( n ) ) 
 + for ( range ← coalescedRanges ) { 
 + val flow = StreamUtilsFix . sliceBytesTransformer ( range . start , range . length ) 
 + bcast ~ > flow . buffer ( 16 , OverflowStrategy . backpressure ) . prefixAndTail ( 0 ) . map { 
 + case ( _ , bytes ) ⇒ 
 + Multipart . ByteRanges . BodyPart ( range . contentRange ( length ) , HttpEntity ( entity . contentType , range . length , bytes ) ) 
 + } ~ > merge 
 + } 
 + entity . dataBytes ~ > bcast 
 + SourceShape ( merge . out ) 
 + } 
 + } 
 + Multipart . ByteRanges ( source ) 
 + } 
 + 
 + def rangeResponse ( range : ByteRange , entity : UniversalEntity , length : Long , headers : immutable . Seq [ HttpHeader ] ) = { 
 + val aiRange = indexRange ( length ) ( range ) 
 + HttpResponse ( PartialContent , ` Content - Range ` ( aiRange . contentRange ( length ) ) + : headers , aiRange ( entity ) ) 
 + } 
 + 
 + def satisfiable ( entityLength : Long ) ( range : ByteRange ) : Boolean = 
 + range match { 
 + case ByteRange . Slice ( firstPos , _ ) ⇒ firstPos < entityLength 
 + case ByteRange . FromOffset ( firstPos ) ⇒ firstPos < entityLength 
 + case ByteRange . Suffix ( length ) ⇒ length > 0 
 + } 
 + def universal ( entity : HttpEntity ) : Option [ UniversalEntity ] = entity match { 
 + case u : UniversalEntity ⇒ Some ( u ) 
 + case _ ⇒ None 
 + } 
 + 
 + def applyRanges ( ranges : immutable . Seq [ ByteRange ] ) : Directive0 = 
 + extractRequestContext . flatMap { ctx ⇒ 
 + mapRouteResultWithPF { 
 + case Complete ( HttpResponse ( OK , headers , entity , protocol ) ) ⇒ 
 + universal ( entity ) match { 
 + case Some ( entity ) ⇒ 
 + val length = entity . contentLength 
 + ranges . filter ( satisfiable ( length ) ) match { 
 + case Nil ⇒ ctx . reject ( UnsatisfiableRangeRejection ( ranges , length ) ) 
 + case Seq ( satisfiableRange ) ⇒ ctx . complete ( rangeResponse ( satisfiableRange , entity , length , headers ) ) 
 + case satisfiableRanges ⇒ 
 + ctx . complete ( ( PartialContent , headers , multipartRanges ( satisfiableRanges , entity ) ) ) 
 + } 
 + case None ⇒ 
 + / / Ranges not supported for Chunked or CloseDelimited responses 
 + ctx . reject ( UnsatisfiableRangeRejection ( ranges , - 1 ) ) / / FIXME : provide better error 
 + } 
 + } 
 + } 
 + 
 + def rangeHeaderOfGetRequests ( ctx : RequestContext ) : Option [ Range ] = 
 + if ( ctx . request . method = = HttpMethods . GET ) ctx . request . header [ Range ] else None 
 + 
 + extract ( rangeHeaderOfGetRequests ) . flatMap { 
 + case Some ( Range ( RangeUnits . Bytes , ranges ) ) ⇒ 
 + if ( ranges . size < = rangeCountLimit ) applyRanges ( ranges ) & RangeDirectivesFix . respondWithAcceptByteRangesHeader 
 + else reject ( TooManyRangesRejection ( rangeCountLimit ) ) 
 + case _ ⇒ MethodDirectives . get & RangeDirectivesFix . respondWithAcceptByteRangesHeader | pass 
 + } 
 + } 
 + } 
 + 
 + object RangeDirectivesFix extends RangeDirectivesFix { 
 + private val respondWithAcceptByteRangesHeader : Directive0 = 
 + RespondWithDirectives . respondWithHeader ( ` Accept - Ranges ` ( RangeUnits . Bytes ) ) 
 + } 
 diff - - git a / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / StreamUtilsFix . scala b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / StreamUtilsFix . scala 
 new file mode 100644 
 index 0000000 . . 79f68d0 
 - - - / dev / null 
 + + + b / actor - server / actor - fs - adapters / src / main / scala / im / actor / server / file / local / http / fix / StreamUtilsFix . scala 
 @ @ - 0 , 0 + 1 , 45 @ @ 
 + package im . actor . server . file . local . http . fix 
 + 
 + import akka . NotUsed 
 + import akka . stream . scaladsl . Flow 
 + import akka . stream . stage . { Context , StatefulStage , SyncDirective } 
 + import akka . util . ByteString 
 + 
 + / / TODO : remove as soon , as https : / / github . com / akka / akka / issues / 20338 get fixed 
 + object StreamUtilsFix { 
 + 
 + def sliceBytesTransformer ( start : Long , length : Long ) : Flow [ ByteString , ByteString , NotUsed ] = { 
 + val transformer = new StatefulStage [ ByteString , ByteString ] { 
 + 
 + def skipping = new State { 
 + var toSkip = start 
 + 
 + override def onPush ( element : ByteString , ctx : Context [ ByteString ] ) : SyncDirective = 
 + if ( element . length < toSkip ) { 
 + / / keep skipping 
 + toSkip - = element . length 
 + ctx . pull ( ) 
 + } else { 
 + become ( taking ( length ) ) 
 + / / toSkip < = element . length < = Int . MaxValue 
 + current . onPush ( element . drop ( toSkip . toInt ) , ctx ) 
 + } 
 + } 
 + 
 + def taking ( initiallyRemaining : Long ) = new State { 
 + var remaining : Long = initiallyRemaining 
 + 
 + override def onPush ( element : ByteString , ctx : Context [ ByteString ] ) : SyncDirective = { 
 + val data = element . take ( math . min ( remaining , Int . MaxValue ) . toInt ) 
 + remaining - = data . size 
 + if ( remaining < = 0 ) ctx . pushAndFinish ( data ) 
 + else ctx . push ( data ) 
 + } 
 + } 
 + 
 + override def initial : State = if ( start > 0 ) skipping else taking ( length ) 
 + } 
 + Flow [ ByteString ] . transform ( ( ) ⇒ transformer ) . named ( " sliceBytes " ) 
 + } 
 + 
 + } 
 diff - - git a / actor - server / project / Build . scala b / actor - server / project / Build . scala 
 index f7bf8b0 . . 63f0304 100644 
 - - - a / actor - server / project / Build . scala 
 + + + b / actor - server / project / Build . scala 
 @ @ - 263 , 7 + 263 , 8 @ @ object Build extends sbt . Build with Versioning with Releasing { 
 id = " actor - fs - adapters " , 
 base = file ( " actor - fs - adapters " ) , 
 settings = defaultSettingsServer + + Seq ( 
 - libraryDependencies + + = Dependencies . fileAdapter 
 + libraryDependencies + + = Dependencies . fileAdapter , 
 + scalacOptions in Compile : = ( scalacOptions in Compile ) . value . filterNot ( _ = = " - Xfatal - warnings " ) 
 ) 
 ) 
 . dependsOn ( actorHttpApi , actorPersist )

NEAREST DIFF:
diff - - git a / actor - http - api / src / main / scala / im / actor / server / api / http / GroupInfoHandler . scala b / actor - http - api / src / main / scala / im / actor / server / api / http / GroupInfoHandler . scala 
 new file mode 100644 
 index 0000000 . . de782d5 
 - - - / dev / null 
 + + + b / actor - http - api / src / main / scala / im / actor / server / api / http / GroupInfoHandler . scala 
 @ @ - 0 , 0 + 1 , 57 @ @ 
 + package im . actor . server . api . http 
 + 
 + import scala . concurrent . duration . _ 
 + import scala . concurrent . { ExecutionContext , Future } 
 + 
 + import akka . actor . ActorSystem 
 + import com . github . dwhjames . awswrap . s3 . AmazonS3ScalaClient 
 + import slick . driver . PostgresDriver . api . _ 
 + 
 + import im . actor . server . util . FileUtils . getFileUrl 
 + import im . actor . server . util . ImageUtils . getAvatar 
 + import im . actor . server . { models , persist } 
 + 
 + class GroupInfoHandler ( s3BucketName : String ) ( 
 + implicit 
 + db : Database , 
 + system : ActorSystem , 
 + ec : ExecutionContext , 
 + client : AmazonS3ScalaClient 
 + ) { 
 + 
 + def retrieve ( token : String ) : Future [ Either [ Errors , GroupInviteInfo ] ] = 
 + db . run { 
 + for { 
 + optToken ← persist . GroupInviteToken . findByToken ( token ) 
 + result ← optToken . map { token ⇒ 
 + for { 
 + groupTitle ← persist . Group . findTitle ( token . groupId ) 
 + groupAvatar ← persist . AvatarData . findByGroupId ( token . groupId ) 
 + groupAvatarUrl ← avatarUrl ( groupAvatar ) 
 + 
 + inviterName ← persist . User . findName ( token . creatorId ) 
 + inviterAvatar ← persist . AvatarData . findByUserId ( token . creatorId ) . headOption 
 + inviterAvatarUrl ← avatarUrl ( inviterAvatar ) 
 + } yield Right ( GroupInviteInfo ( groupTitle . getOrElse ( " Group " ) , groupAvatarUrl , inviterName . getOrElse ( " User " ) , inviterAvatarUrl ) ) 
 + } . getOrElse ( DBIO . successful ( Left ( Errors ( " Expired or invalid token " ) ) ) ) 
 + } yield result 
 + } 
 + 
 + private def avatarUrl ( optAvatar : Option [ models . AvatarData ] ) : DBIO [ Option [ String ] ] = { 
 + val optLocation = for { 
 + modelAvatar ← optAvatar 
 + structAvatar = getAvatar ( modelAvatar ) 
 + fileLocation ← List ( structAvatar . largeImage , structAvatar . smallImage , structAvatar . fullImage ) . find ( _ . isDefined ) . flatten . map ( _ . fileLocation ) 
 + } yield fileLocation 
 + implicit val timeout = 1 . day 
 + optLocation . map { location ⇒ 
 + for { 
 + fileOpt ← persist . File . find ( location . fileId ) 
 + url ← fileOpt . map { file ⇒ 
 + DBIO . from ( getFileUrl ( file , location . accessHash , s3BucketName ) ) 
 + } . getOrElse ( DBIO . successful ( None ) ) 
 + } yield url 
 + } . getOrElse ( DBIO . successful ( None ) ) 
 + } 
 + 
 + } 
 \ No newline at end of file 
 diff - - git a / actor - http - api / src / main / scala / im / actor / server / api / http / HttpApiFrontend . scala b / actor - http - api / src / main / scala / im / actor / server / api / http / HttpApiFrontend . scala 
 index 0facb91 . . d2b8bf1 100644 
 - - - a / actor - http - api / src / main / scala / im / actor / server / api / http / HttpApiFrontend . scala 
 + + + b / actor - http - api / src / main / scala / im / actor / server / api / http / HttpApiFrontend . scala 
 @ @ - 5 , 49 + 5 , 72 @ @ import scala . util . { Failure , Success } 
 
 import akka . actor . ActorSystem 
 import akka . http . scaladsl . Http 
 - import akka . http . scaladsl . model . { HttpRequest , HttpResponse , StatusCodes } 
 + import akka . http . scaladsl . model . StatusCodes . { InternalServerError , NotAcceptable , OK } 
 + import akka . http . scaladsl . model . { HttpRequest , HttpResponse } 
 import akka . http . scaladsl . server . Directives . _ 
 import akka . http . scaladsl . server . Route 
 import akka . http . scaladsl . unmarshalling . Unmarshaller 
 import akka . stream . FlowMaterializer 
 import akka . stream . scaladsl . Sink 
 + import com . github . dwhjames . awswrap . s3 . AmazonS3ScalaClient 
 import play . api . libs . json . Json 
 import slick . driver . PostgresDriver . api . _ 
 
 + import im . actor . server . api . http . JsonImplicits . _ 
 import im . actor . server . peermanagers . GroupPeerManagerRegion 
 
 object HttpApiFrontend { 
 
 - def start ( config : HttpApiConfig ) ( 
 + def start ( config : HttpApiConfig , s3BucketName : String ) ( 
 implicit 
 system : ActorSystem , 
 materializer : FlowMaterializer , 
 db : Database , 
 - groupPeerManagerRegion : GroupPeerManagerRegion 
 + groupPeerManagerRegion : GroupPeerManagerRegion , 
 + client : AmazonS3ScalaClient 
 ) : Unit = { 
 
 implicit val ec : ExecutionContext = system . dispatcher 
 
 + val groupInfo = new GroupInfoHandler ( s3BucketName ) 
 + val webhooks = new WebhookHandler ( ) 
 + 
 / / TODO : replace to object , import in scope 
 implicit val toContent = Unmarshaller . apply [ HttpRequest , Content ] { implicit ec ⇒ req ⇒ 
 - 
 - import JsonImplicits . _ 
 - 
 req . entity . dataBytes 
 . map { data ⇒ Json . parse ( data . decodeString ( " utf - 8 " ) ) . as [ Content ] } 
 . runWith ( Sink . head ) 
 } 
 
 def routes : Route = 
 - path ( " v1 " / " webhooks " / Segment ) { token ⇒ 
 - post { 
 - entity ( as [ Content ] ) { content ⇒ 
 - onComplete ( new WebhookHandler ( ) . send ( content , token ) ) { 
 - case Success ( _ ) ⇒ complete ( HttpResponse ( StatusCodes . OK ) ) 
 - case Failure ( e ) ⇒ complete ( HttpResponse ( StatusCodes . InternalServerError ) ) 
 + pathPrefix ( " v1 " ) { 
 + path ( " group - invite - info " / Segment ) { token ⇒ 
 + ( get | post ) { 
 + onComplete ( groupInfo . retrieve ( token ) ) { 
 + case Success ( Right ( result ) ) ⇒ 
 + complete ( HttpResponse ( 
 + status = OK , 
 + entity = Json . stringify ( Json . toJson ( result ) ) 
 + ) ) 
 + case Success ( Left ( errors ) ) ⇒ 
 + complete ( HttpResponse ( 
 + status = NotAcceptable , 
 + entity = Json . stringify ( Json . toJson ( errors ) ) 
 + ) ) 
 + case Failure ( e ) ⇒ complete ( HttpResponse ( InternalServerError ) ) 
 + } 
 + } 
 + } ~ 
 + path ( " webhooks " / Segment ) { token ⇒ 
 + post { 
 + entity ( as [ Content ] ) { content ⇒ 
 + onComplete ( webhooks . send ( content , token ) ) { 
 + case Success ( _ ) ⇒ complete ( HttpResponse ( OK ) ) 
 + case Failure ( e ) ⇒ complete ( HttpResponse ( InternalServerError ) ) 
 + } 
 + } 
 } 
 } 
 - } 
 } 
 
 Http ( ) . bind ( config . interface , config . port ) . runForeach { connection ⇒ 
 diff - - git a / actor - http - api / src / main / scala / im / actor / server / api / http / Models . scala b / actor - http - api / src / main / scala / im / actor / server / api / http / Models . scala 
 index 42d9504 . . 051b6fb 100644 
 - - - a / actor - http - api / src / main / scala / im / actor / server / api / http / Models . scala 
 + + + b / actor - http - api / src / main / scala / im / actor / server / api / http / Models . scala 
 @ @ - 8 , 6 + 8 , 14 @ @ case class Text ( text : String ) extends Content 
 case class Image ( imageUrl : String ) extends Content 
 case class Document ( documentUrl : String ) extends Content 
 
 + case class GroupInviteInfo ( 
 + groupTitle : String , 
 + groupAvatarUrl : Option [ String ] , 
 + inviterName : String , 
 + inviterAvatarUrl : Option [ String ] 
 + ) 
 + case class Errors ( message : String ) 
 + 
 object JsonImplicits { 
 
 implicit val textReads : Reads [ Content ] = 
 @ @ - 15 , 4 + 23 , 7 @ @ object JsonImplicits { 
 ( JsPath \ " document _ url " ) . read [ String ] . map [ Content ] { Document } | 
 ( JsPath \ " image _ url " ) . read [ String ] . map [ Content ] { Image } 
 
 + implicit val groupInviteInfoFormat : Format [ GroupInviteInfo ] = Json . format [ GroupInviteInfo ] 
 + implicit val errorsFormat : Format [ Errors ] = Json . format [ Errors ] 
 + 
 } 
 \ No newline at end of file 
 diff - - git a / actor - rpc - api / src / main / scala / im / actor / server / api / rpc / service / files / FilesServiceImpl . scala b / actor - rpc - api / src / main / scala / im / actor / server / api / rpc / service / files / FilesServiceImpl . scala 
 index 629b0d3 . . 67d9eb6 100644 
 - - - a / actor - rpc - api / src / main / scala / im / actor / server / api / rpc / service / files / FilesServiceImpl . scala 
 + + + b / actor - rpc - api / src / main / scala / im / actor / server / api / rpc / service / files / FilesServiceImpl . scala 
 @ @ - 7 , 6 + 7 , 7 @ @ import scala . collection . mutable 
 import scala . concurrent . duration . _ 
 import scala . concurrent . forkjoin . ThreadLocalRandom 
 import scala . concurrent . { ExecutionContext , Future } 
 + import scala . util . { Failure , Success } 
 
 import akka . actor . _ 
 import com . amazonaws . HttpMethod 
 @ @ - 36 , 30 + 37 , 21 @ @ class FilesServiceImpl ( bucketName : String ) ( 
 override implicit val ec : ExecutionContext = actorSystem . dispatcher 
 
 override def jhandleGetFileUrl ( location : FileLocation , clientData : ClientData ) : Future [ HandlerResult [ ResponseGetFileUrl ] ] = { 
 - val authorizedAction = requireAuth ( clientData ) . map { client ⇒ 
 + val authorizedAction = requireAuth ( clientData ) map { client ⇒ 
 persist . File . find ( location . fileId ) flatMap { 
 - case Some ( file ) ⇒ 
 - if ( ACLUtils . fileAccessHash ( file . id , file . accessSalt ) = = location . accessHash ) { 
 - val presignedRequest = new GeneratePresignedUrlRequest ( bucketName , FileUtils . s3Key ( file . id , file . name ) ) 
 - val timeout = 1 . day 
 - 
 - val expiration = new java . util . Date 
 - expiration . setTime ( expiration . getTime + timeout . toMillis ) 
 - presignedRequest . setExpiration ( expiration ) 
 - presignedRequest . setMethod ( HttpMethod . GET ) 
 - 
 - for { 
 - url ← DBIO . from ( s3Client . generatePresignedUrlRequest ( presignedRequest ) ) 
 - } yield { 
 - Ok ( ResponseGetFileUrl ( url . toString , timeout . toSeconds . toInt ) ) 
 + implicit val timeout = 1 . day 
 + 
 + { 
 + case Some ( file ) ⇒ 
 + DBIO . from ( FileUtils . getFileUrl ( file , location . accessHash , bucketName ) ) . map { optUrl ⇒ 
 + optUrl . map { url ⇒ 
 + Ok ( ResponseGetFileUrl ( url , timeout . toSeconds . toInt ) ) 
 + } . getOrElse ( Error ( Errors . LocationInvalid ) ) 
 } 
 - } else { 
 - DBIO . successful ( Error ( Errors . LocationInvalid ) ) 
 - } 
 - case None ⇒ DBIO . successful ( Error ( Errors . LocationInvalid ) ) 
 + case None ⇒ DBIO . successful ( Error ( Errors . LocationInvalid ) ) 
 + } 
 } 
 } 
 - 
 db . run ( toDBIOAction ( authorizedAction ) ) 
 } 
 
 diff - - git a / actor - tests / src / test / scala / im / actor / server / http / HttpApiFrontendSpec . scala b / actor - tests / src / test / scala / im / actor / server / http / HttpApiFrontendSpec . scala 
 index 804adfa . . 1071cf9 100644 
 - - - a / actor - tests / src / test / scala / im / actor / server / http / HttpApiFrontendSpec . scala 
 + + + b / actor - tests / src / test / scala / im / actor / server / http / HttpApiFrontendSpec . scala 
 @ @ - 4 , 6 + 4 , 7 @ @ import akka . http . scaladsl . Http 
 import akka . http . scaladsl . model . { HttpMethods , HttpRequest , StatusCodes } 
 import com . amazonaws . auth . EnvironmentVariableCredentialsProvider 
 import com . amazonaws . services . s3 . transfer . TransferManager 
 + import com . github . dwhjames . awswrap . s3 . AmazonS3ScalaClient 
 
 import im . actor . api . rpc . ClientData 
 import im . actor . server . api . http . { HttpApiConfig , HttpApiFrontend } 
 @ @ - 36 , 6 + 37 , 7 @ @ class HttpApiFrontendSpec extends BaseAppSuite with GroupsServiceHelpers { 
 val bucketName = " actor - uploads - test " 
 val awsCredentials = new EnvironmentVariableCredentialsProvider ( ) 
 implicit val transferManager = new TransferManager ( awsCredentials ) 
 + implicit val client = new AmazonS3ScalaClient ( awsCredentials ) 
 val groupInviteConfig = GroupInviteConfig ( " http : / / actor . im " ) 
 
 implicit val service = messaging . MessagingServiceImpl ( mediator ) 
 @ @ - 53 , 7 + 55 , 7 @ @ class HttpApiFrontendSpec extends BaseAppSuite with GroupsServiceHelpers { 
 val groupOutPeer = createGroup ( " Bot test group " , Set ( user2 . id ) ) . groupPeer 
 
 val config = HttpApiConfig ( " http " , " localhost " , 9000 ) 
 - HttpApiFrontend . start ( config ) 
 + HttpApiFrontend . start ( config , " actor - uploads - test " ) 
 
 val http = Http ( ) 
 
 diff - - git a / actor - tests / src / test / scala / im / actor / server / http / WebhookHandlerSpec . scala b / actor - tests / src / test / scala / im / actor / server / http / WebhookHandlerSpec . scala 
 index fb0a06a . . e6e3017 100644 
 - - - a / actor - tests / src / test / scala / im / actor / server / http / WebhookHandlerSpec . scala 
 + + + b / actor - tests / src / test / scala / im / actor / server / http / WebhookHandlerSpec . scala 
 @ @ - 5 , 7 + 5 , 7 @ @ import com . amazonaws . services . s3 . transfer . TransferManager 
 
 import im . actor . api . rpc . ClientData 
 import im . actor . api . rpc . messaging . TextMessage 
 - import im . actor . server . api . http . { WebhookHandler , Text } 
 + import im . actor . server . api . http . { Text , WebhookHandler } 
 import im . actor . server . api . rpc . service . GroupsServiceHelpers 
 import im . actor . server . api . rpc . service . groups . { GroupInviteConfig , GroupsServiceImpl } 
 import im . actor . server . models . Peer 
 diff - - git a / actor - utils / src / main / scala / im / actor / server / util / FileUtils . scala b / actor - utils / src / main / scala / im / actor / server / util / FileUtils . scala 
 index b2c952a . . 3450b75 100644 
 - - - a / actor - utils / src / main / scala / im / actor / server / util / FileUtils . scala 
 + + + b / actor - utils / src / main / scala / im / actor / server / util / FileUtils . scala 
 @ @ - 1 , 8 + 1 , 9 @ @ 
 package im . actor . server . util 
 
 - import java . io . File 
 + import java . io . { Serializable , File } 
 import java . nio . file . { Files , Path } 
 
 + import scala . concurrent . duration . FiniteDuration 
 import scala . concurrent . forkjoin . ThreadLocalRandom 
 import scala . concurrent . { ExecutionContext , Future , blocking } 
 
 @ @ - 11 , 15 + 12 , 18 @ @ import akka . stream . FlowMaterializer 
 import akka . stream . io . SynchronousFileSink 
 import akka . stream . scaladsl . Source 
 import akka . util . ByteString 
 + import com . amazonaws . HttpMethod 
 + import com . amazonaws . services . s3 . model . GeneratePresignedUrlRequest 
 import com . amazonaws . services . s3 . transfer . TransferManager 
 import com . amazonaws . services . s3 . transfer . model . UploadResult 
 - import com . github . dwhjames . awswrap . s3 . FutureTransfer 
 + import com . github . dwhjames . awswrap . s3 . { AmazonS3ScalaClient , FutureTransfer } 
 import slick . dbio 
 import slick . dbio . Effect . { Read , Write } 
 import slick . driver . PostgresDriver . api . _ 
 
 - import im . actor . api . rpc . files . FileLocation 
 + import im . actor . api . rpc . files . { ResponseGetFileUrl , FileLocation } 
 import im . actor . server . persist 
 + import im . actor . server . models 
 
 object FileUtils { 
 
 @ @ - 70 , 6 + 74 , 25 @ @ object FileUtils { 
 FutureTransfer . listenFor ( transferManager . upload ( bucketName , s3Key ( id , name ) , file ) ) map ( _ . waitForUploadResult ( ) ) 
 } 
 
 + def getFileUrl ( file : models . File , accessHash : Long , bucketName : String ) ( 
 + implicit 
 + system : ActorSystem , 
 + ec : ExecutionContext , 
 + s3Client : AmazonS3ScalaClient , 
 + timeout : FiniteDuration 
 + ) : Future [ Option [ String ] ] = { 
 + if ( ACLUtils . fileAccessHash ( file . id , file . accessSalt ) = = accessHash ) { 
 + val presignedRequest = new GeneratePresignedUrlRequest ( bucketName , s3Key ( file . id , file . name ) ) 
 + 
 + val expiration = new java . util . Date 
 + expiration . setTime ( expiration . getTime + timeout . toMillis ) 
 + presignedRequest . setExpiration ( expiration ) 
 + presignedRequest . setMethod ( HttpMethod . GET ) 
 + 
 + s3Client . generatePresignedUrlRequest ( presignedRequest ) . map ( _ . toString ) . map ( Some ( _ ) ) 
 + } else Future . successful ( None ) 
 + } 
 + 
 def s3Key ( id : Long , name : String ) : String = { 
 if ( name . isEmpty ) { 
 s " file _ $ { id } " 
 diff - - git a / src / main / scala / im / actor / server / Main . scala b / src / main / scala / im / actor / server / Main . scala 
 index 9a49377 . . ed53512 100644 
 - - - a / src / main / scala / im / actor / server / Main . scala 
 + + + b / src / main / scala / im / actor / server / Main . scala 
 @ @ - 107 , 15 + 107 , 13 @ @ class Main extends Bootable with DbInit with FlywayInit { 
 val downloadManager = new DownloadManager 
 implicit val uploadManager = new UploadManager ( s3BucketName ) 
 
 - val messagingService = MessagingServiceImpl ( mediator ) 
 - 
 MessageInterceptor . startSingleton ( ilectro , downloadManager , uploadManager , mediator , ilectroInterceptionConfig ) 
 RichMessageWorker . startWorker ( richMessageConfig , mediator ) 
 
 val services = Seq ( 
 new AuthServiceImpl ( activationContext , mediator ) , 
 new ContactsServiceImpl , 
 - messagingService , 
 + MessagingServiceImpl ( mediator ) , 
 new GroupsServiceImpl ( s3BucketName , groupInviteConfig ) , 
 new SequenceServiceImpl , 
 new WeakServiceImpl , 
 @ @ - 130 , 7 + 128 , 7 @ @ class Main extends Bootable with DbInit with FlywayInit { 
 
 system . actorOf ( RpcApiService . props ( services ) , " rpcApiService " ) 
 
 - HttpApiFrontend . start ( httpApiConfig ) 
 + HttpApiFrontend . start ( httpApiConfig , s3BucketName ) 
 TcpFrontend . start ( serverConfig , sessionRegion ) 
 WsFrontend . start ( serverConfig , sessionRegion )
