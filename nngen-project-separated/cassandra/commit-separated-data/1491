BLEU SCORE: 0.04372912656590315

TEST MSG: Handle corrupt files on startup
GENERATED MSG: clean up tmpfiles after failed compaction

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 7635227 . . 5f4fdf2 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 1 . 9 <nl> + * Handle corrupt files on startup ( CASSANDRA - 9686 ) <nl> * Fix clientutil jar and tests ( CASSANDRA - 9760 ) <nl> * ( cqlsh ) Allow the SSL protocol version to be specified through the <nl> config file or environment variables ( CASSANDRA - 9544 ) <nl> diff - - git a / conf / cassandra . yaml b / conf / cassandra . yaml <nl> index e4b7cbd . . 3047586 100644 <nl> - - - a / conf / cassandra . yaml <nl> + + + b / conf / cassandra . yaml <nl> @ @ - 112 , 11 + 112 , 12 @ @ partitioner : org . apache . cassandra . dht . Murmur3Partitioner <nl> # commitlog _ directory : / var / lib / cassandra / commitlog <nl> <nl> # policy for data disk failures : <nl> - # die : shut down gossip and Thrift and kill the JVM for any fs errors or <nl> + # die : shut down gossip and client transports and kill the JVM for any fs errors or <nl> # single - sstable errors , so the node can be replaced . <nl> - # stop _ paranoid : shut down gossip and Thrift even for single - sstable errors . <nl> - # stop : shut down gossip and Thrift , leaving the node effectively dead , but <nl> - # can still be inspected via JMX . <nl> + # stop _ paranoid : shut down gossip and client transports even for single - sstable errors , <nl> + # kill the JVM for errors during startup . <nl> + # stop : shut down gossip and client transports , leaving the node effectively dead , but <nl> + # can still be inspected via JMX , kill the JVM for errors during startup . <nl> # best _ effort : stop using the failed disk and respond to requests based on <nl> # remaining available sstables . This means you WILL see obsolete <nl> # data at CL . ONE ! <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> index 6879834 . . 92c9b55 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> @ @ - 69 , 6 + 69 , 7 @ @ import org . apache . cassandra . dht . IPartitioner ; <nl> import org . apache . cassandra . dht . LocalPartitioner ; <nl> import org . apache . cassandra . dht . Range ; <nl> import org . apache . cassandra . dht . Token ; <nl> + import org . apache . cassandra . io . FSError ; <nl> import org . apache . cassandra . io . compress . CompressionMetadata ; <nl> import org . apache . cassandra . io . sstable . metadata . CompactionMetadata ; <nl> import org . apache . cassandra . io . sstable . metadata . MetadataComponent ; <nl> @ @ - 477 , 19 + 478 , 27 @ @ public class SSTableReader extends SSTable implements SelfRefCounted < SSTableRead <nl> statsMetadata , <nl> OpenReason . NORMAL ) ; <nl> <nl> - / / load index and filter <nl> - long start = System . nanoTime ( ) ; <nl> - sstable . load ( validationMetadata ) ; <nl> - logger . debug ( " INDEX LOAD TIME for { } : { } ms . " , descriptor , TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - start ) ) ; <nl> + try <nl> + { <nl> + / / load index and filter <nl> + long start = System . nanoTime ( ) ; <nl> + sstable . load ( validationMetadata ) ; <nl> + logger . debug ( " INDEX LOAD TIME for { } : { } ms . " , descriptor , TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - start ) ) ; <nl> <nl> - sstable . setup ( ! validate ) ; <nl> - if ( validate ) <nl> - sstable . validate ( ) ; <nl> + sstable . setup ( ! validate ) ; <nl> + if ( validate ) <nl> + sstable . validate ( ) ; <nl> <nl> - if ( sstable . getKeyCache ( ) ! = null ) <nl> - logger . debug ( " key cache contains { } / { } keys " , sstable . getKeyCache ( ) . size ( ) , sstable . getKeyCache ( ) . getCapacity ( ) ) ; <nl> + if ( sstable . getKeyCache ( ) ! = null ) <nl> + logger . debug ( " key cache contains { } / { } keys " , sstable . getKeyCache ( ) . size ( ) , sstable . getKeyCache ( ) . getCapacity ( ) ) ; <nl> <nl> - return sstable ; <nl> + return sstable ; <nl> + } <nl> + catch ( Throwable t ) <nl> + { <nl> + sstable . selfRef ( ) . release ( ) ; <nl> + throw t ; <nl> + } <nl> } <nl> <nl> public static void logOpenException ( Descriptor descriptor , IOException e ) <nl> @ @ - 518 , 9 + 527 , 21 @ @ public class SSTableReader extends SSTable implements SelfRefCounted < SSTableRead <nl> { <nl> sstable = open ( entry . getKey ( ) , entry . getValue ( ) , metadata , partitioner ) ; <nl> } <nl> + catch ( CorruptSSTableException ex ) <nl> + { <nl> + FileUtils . handleCorruptSSTable ( ex ) ; <nl> + logger . error ( " Corrupt sstable { } ; skipping table " , entry , ex ) ; <nl> + return ; <nl> + } <nl> + catch ( FSError ex ) <nl> + { <nl> + FileUtils . handleFSError ( ex ) ; <nl> + logger . error ( " Cannot read sstable { } ; file system error , skipping table " , entry , ex ) ; <nl> + return ; <nl> + } <nl> catch ( IOException ex ) <nl> { <nl> - logger . error ( " Corrupt sstable { } ; skipped " , entry , ex ) ; <nl> + logger . error ( " Cannot read sstable { } ; other IO error , skipping table " , entry , ex ) ; <nl> return ; <nl> } <nl> sstables . add ( sstable ) ; <nl> @ @ - 704 , 46 + 725 , 71 @ @ public class SSTableReader extends SSTable implements SelfRefCounted < SSTableRead <nl> * / <nl> private void load ( boolean recreateBloomFilter , boolean saveSummaryIfCreated ) throws IOException <nl> { <nl> - SegmentedFile . Builder ibuilder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; <nl> - SegmentedFile . Builder dbuilder = compression <nl> + try <nl> + { <nl> + SegmentedFile . Builder ibuilder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; <nl> + SegmentedFile . Builder dbuilder = compression <nl> ? SegmentedFile . getCompressedBuilder ( ) <nl> : SegmentedFile . getBuilder ( DatabaseDescriptor . getDiskAccessMode ( ) ) ; <nl> <nl> - boolean summaryLoaded = loadSummary ( ibuilder , dbuilder ) ; <nl> - boolean builtSummary = false ; <nl> - if ( recreateBloomFilter | | ! summaryLoaded ) <nl> - { <nl> - buildSummary ( recreateBloomFilter , ibuilder , dbuilder , summaryLoaded , Downsampling . BASE _ SAMPLING _ LEVEL ) ; <nl> - builtSummary = true ; <nl> - } <nl> - <nl> - if ( components . contains ( Component . PRIMARY _ INDEX ) ) <nl> - ifile = ibuilder . complete ( descriptor . filenameFor ( Component . PRIMARY _ INDEX ) ) ; <nl> - <nl> - dfile = dbuilder . complete ( descriptor . filenameFor ( Component . DATA ) ) ; <nl> + boolean summaryLoaded = loadSummary ( ibuilder , dbuilder ) ; <nl> + boolean builtSummary = false ; <nl> + if ( recreateBloomFilter | | ! summaryLoaded ) <nl> + { <nl> + buildSummary ( recreateBloomFilter , ibuilder , dbuilder , summaryLoaded , Downsampling . BASE _ SAMPLING _ LEVEL ) ; <nl> + builtSummary = true ; <nl> + } <nl> <nl> - / / Check for an index summary that was downsampled even though the serialization format doesn ' t support <nl> - / / that . If it was downsampled , rebuild it . See CASSANDRA - 8993 for details . <nl> - if ( ! descriptor . version . hasSamplingLevel & & ! builtSummary & & ! validateSummarySamplingLevel ( ) & & ifile ! = null ) <nl> - { <nl> - indexSummary . close ( ) ; <nl> - ifile . close ( ) ; <nl> - dfile . close ( ) ; <nl> + if ( components . contains ( Component . PRIMARY _ INDEX ) ) <nl> + ifile = ibuilder . complete ( descriptor . filenameFor ( Component . PRIMARY _ INDEX ) ) ; <nl> <nl> - logger . info ( " Detected erroneously downsampled index summary ; will rebuild summary at full sampling " ) ; <nl> - FileUtils . deleteWithConfirm ( new File ( descriptor . filenameFor ( Component . SUMMARY ) ) ) ; <nl> - ibuilder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; <nl> - dbuilder = compression <nl> - ? SegmentedFile . getCompressedBuilder ( ) <nl> - : SegmentedFile . getBuilder ( DatabaseDescriptor . getDiskAccessMode ( ) ) ; <nl> - buildSummary ( false , ibuilder , dbuilder , false , Downsampling . BASE _ SAMPLING _ LEVEL ) ; <nl> - ifile = ibuilder . complete ( descriptor . filenameFor ( Component . PRIMARY _ INDEX ) ) ; <nl> dfile = dbuilder . complete ( descriptor . filenameFor ( Component . DATA ) ) ; <nl> - saveSummary ( ibuilder , dbuilder ) ; <nl> + <nl> + / / Check for an index summary that was downsampled even though the serialization format doesn ' t support <nl> + / / that . If it was downsampled , rebuild it . See CASSANDRA - 8993 for details . <nl> + if ( ! descriptor . version . hasSamplingLevel & & ! builtSummary & & ! validateSummarySamplingLevel ( ) & & ifile ! = null ) <nl> + { <nl> + indexSummary . close ( ) ; <nl> + ifile . close ( ) ; <nl> + dfile . close ( ) ; <nl> + <nl> + logger . info ( " Detected erroneously downsampled index summary ; will rebuild summary at full sampling " ) ; <nl> + FileUtils . deleteWithConfirm ( new File ( descriptor . filenameFor ( Component . SUMMARY ) ) ) ; <nl> + ibuilder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; <nl> + dbuilder = compression <nl> + ? SegmentedFile . getCompressedBuilder ( ) <nl> + : SegmentedFile . getBuilder ( DatabaseDescriptor . getDiskAccessMode ( ) ) ; <nl> + buildSummary ( false , ibuilder , dbuilder , false , Downsampling . BASE _ SAMPLING _ LEVEL ) ; <nl> + ifile = ibuilder . complete ( descriptor . filenameFor ( Component . PRIMARY _ INDEX ) ) ; <nl> + dfile = dbuilder . complete ( descriptor . filenameFor ( Component . DATA ) ) ; <nl> + saveSummary ( ibuilder , dbuilder ) ; <nl> + } <nl> + else if ( saveSummaryIfCreated & & builtSummary ) <nl> + { <nl> + saveSummary ( ibuilder , dbuilder ) ; <nl> + } <nl> } <nl> - else if ( saveSummaryIfCreated & & builtSummary ) <nl> - { <nl> - saveSummary ( ibuilder , dbuilder ) ; <nl> + catch ( Throwable t ) <nl> + { / / Because the tidier has not been set - up yet in SSTableReader . open ( ) , we must release the files in case of error <nl> + if ( ifile ! = null ) <nl> + { <nl> + ifile . close ( ) ; <nl> + ifile = null ; <nl> + } <nl> + <nl> + if ( dfile ! = null ) <nl> + { <nl> + dfile . close ( ) ; <nl> + dfile = null ; <nl> + } <nl> + <nl> + if ( indexSummary ! = null ) <nl> + { <nl> + indexSummary . close ( ) ; <nl> + indexSummary = null ; <nl> + } <nl> + <nl> + throw t ; <nl> } <nl> } <nl> <nl> @ @ - 2174 , 7 + 2220 , 8 @ @ public class SSTableReader extends SSTable implements SelfRefCounted < SSTableRead <nl> summary . close ( ) ; <nl> if ( runOnClose ! = null ) <nl> runOnClose . run ( ) ; <nl> - dfile . close ( ) ; <nl> + if ( dfile ! = null ) <nl> + dfile . close ( ) ; <nl> if ( ifile ! = null ) <nl> ifile . close ( ) ; <nl> typeRef . release ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / io / util / FileUtils . java b / src / java / org / apache / cassandra / io / util / FileUtils . java <nl> index 7d187ac . . 3be7c99 100644 <nl> - - - a / src / java / org / apache / cassandra / io / util / FileUtils . java <nl> + + + b / src / java / org / apache / cassandra / io / util / FileUtils . java <nl> @ @ - 395 , 6 + 395 , 9 @ @ public class FileUtils <nl> <nl> public static void handleCorruptSSTable ( CorruptSSTableException e ) <nl> { <nl> + if ( ! StorageService . instance . isSetupCompleted ( ) ) <nl> + handleStartupFSError ( e ) ; <nl> + <nl> JVMStabilityInspector . inspectThrowable ( e ) ; <nl> switch ( DatabaseDescriptor . getDiskFailurePolicy ( ) ) <nl> { <nl> @ @ - 406 , 6 + 409 , 9 @ @ public class FileUtils <nl> <nl> public static void handleFSError ( FSError e ) <nl> { <nl> + if ( ! StorageService . instance . isSetupCompleted ( ) ) <nl> + handleStartupFSError ( e ) ; <nl> + <nl> JVMStabilityInspector . inspectThrowable ( e ) ; <nl> switch ( DatabaseDescriptor . getDiskFailurePolicy ( ) ) <nl> { <nl> @ @ - 431 , 6 + 437 , 22 @ @ public class FileUtils <nl> } <nl> } <nl> <nl> + private static void handleStartupFSError ( Throwable t ) <nl> + { <nl> + switch ( DatabaseDescriptor . getDiskFailurePolicy ( ) ) <nl> + { <nl> + case stop _ paranoid : <nl> + case stop : <nl> + case die : <nl> + logger . error ( " Exiting forcefully due to file system exception on startup , disk failure policy \ " { } \ " " , <nl> + DatabaseDescriptor . getDiskFailurePolicy ( ) , <nl> + t ) ; <nl> + JVMStabilityInspector . killCurrentJVM ( t , true ) ; <nl> + break ; <nl> + default : <nl> + break ; <nl> + } <nl> + } <nl> / * * <nl> * Get the size of a directory in bytes <nl> * @ param directory The directory for which we need size . <nl> diff - - git a / src / java / org / apache / cassandra / service / CassandraDaemon . java b / src / java / org / apache / cassandra / service / CassandraDaemon . java <nl> index f66e523 . . 949ea4c 100644 <nl> - - - a / src / java / org / apache / cassandra / service / CassandraDaemon . java <nl> + + + b / src / java / org / apache / cassandra / service / CassandraDaemon . java <nl> @ @ - 134 , 7 + 134 , 7 @ @ public class CassandraDaemon <nl> <nl> public Server thriftServer ; <nl> public Server nativeServer ; <nl> - <nl> + private boolean setupCompleted = false ; <nl> / * * <nl> * This is a hook for concrete daemons to initialize themselves suitably . <nl> * <nl> @ @ - 425 , 6 + 425 , 13 @ @ public class CassandraDaemon <nl> InetAddress nativeAddr = DatabaseDescriptor . getRpcAddress ( ) ; <nl> int nativePort = DatabaseDescriptor . getNativeTransportPort ( ) ; <nl> nativeServer = new org . apache . cassandra . transport . Server ( nativeAddr , nativePort ) ; <nl> + <nl> + setupCompleted = true ; <nl> + } <nl> + <nl> + public boolean setupCompleted ( ) <nl> + { <nl> + return setupCompleted ; <nl> } <nl> <nl> / * * <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index e4ffc5b . . 4a32bad 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 486 , 6 + 486 , 13 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> return initialized ; <nl> } <nl> <nl> + public boolean isSetupCompleted ( ) <nl> + { <nl> + return daemon = = null <nl> + ? false <nl> + : daemon . setupCompleted ( ) ; <nl> + } <nl> + <nl> public void stopDaemon ( ) <nl> { <nl> if ( daemon = = null ) <nl> diff - - git a / src / java / org / apache / cassandra / utils / JVMStabilityInspector . java b / src / java / org / apache / cassandra / utils / JVMStabilityInspector . java <nl> index 2883ab3 . . c0ab84f 100644 <nl> - - - a / src / java / org / apache / cassandra / utils / JVMStabilityInspector . java <nl> + + + b / src / java / org / apache / cassandra / utils / JVMStabilityInspector . java <nl> @ @ - 72 , 6 + 72 , 11 @ @ public final class JVMStabilityInspector <nl> inspectThrowable ( t ) ; <nl> } <nl> <nl> + public static void killCurrentJVM ( Throwable t , boolean quiet ) <nl> + { <nl> + killer . killCurrentJVM ( t , quiet ) ; <nl> + } <nl> + <nl> @ VisibleForTesting <nl> public static Killer replaceKiller ( Killer newKiller ) { <nl> Killer oldKiller = JVMStabilityInspector . killer ; <nl> @ @ - 90 , 8 + 95 , 16 @ @ public final class JVMStabilityInspector <nl> * / <nl> protected void killCurrentJVM ( Throwable t ) <nl> { <nl> - t . printStackTrace ( System . err ) ; <nl> - logger . error ( " JVM state determined to be unstable . Exiting forcefully due to : " , t ) ; <nl> + killCurrentJVM ( t , false ) ; <nl> + } <nl> + <nl> + protected void killCurrentJVM ( Throwable t , boolean quiet ) <nl> + { <nl> + if ( ! quiet ) <nl> + { <nl> + t . printStackTrace ( System . err ) ; <nl> + logger . error ( " JVM state determined to be unstable . Exiting forcefully due to : " , t ) ; <nl> + } <nl> StorageService . instance . removeShutdownHook ( ) ; <nl> System . exit ( 100 ) ; <nl> }
NEAREST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / concurrent / DebuggableThreadPoolExecutor . java b / src / java / org / apache / cassandra / concurrent / DebuggableThreadPoolExecutor . java <nl> index 08af5fa . . 38d73de 100644 <nl> - - - a / src / java / org / apache / cassandra / concurrent / DebuggableThreadPoolExecutor . java <nl> + + + b / src / java / org / apache / cassandra / concurrent / DebuggableThreadPoolExecutor . java <nl> @ @ - 57 , 9 + 57 , 9 @ @ public class DebuggableThreadPoolExecutor extends ThreadPoolExecutor <nl> super ( corePoolSize , corePoolSize , keepAliveTime , unit , workQueue , threadFactory ) ; <nl> allowCoreThreadTimeOut ( true ) ; <nl> <nl> - / / preserve task serialization . this is more complicated than it needs to be , <nl> - / / since TPE rejects if queue . offer reports a full queue . we ' ll just <nl> - / / override this with a handler that retries until it gets in . ugly , but effective . <nl> + / / block task submissions until queue has room . <nl> + / / this is fighting TPE ' s design a bit because TPE rejects if queue . offer reports a full queue . <nl> + / / we ' ll just override this with a handler that retries until it gets in . ugly , but effective . <nl> / / ( there is an extensive analysis of the options here at <nl> / / http : / / today . java . net / pub / a / today / 2008 / 10 / 23 / creating - a - notifying - blocking - thread - pool - executor . html ) <nl> this . setRejectedExecutionHandler ( new RejectedExecutionHandler ( )

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 7635227 . . 5f4fdf2 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 1 . 9 
 + * Handle corrupt files on startup ( CASSANDRA - 9686 ) 
 * Fix clientutil jar and tests ( CASSANDRA - 9760 ) 
 * ( cqlsh ) Allow the SSL protocol version to be specified through the 
 config file or environment variables ( CASSANDRA - 9544 ) 
 diff - - git a / conf / cassandra . yaml b / conf / cassandra . yaml 
 index e4b7cbd . . 3047586 100644 
 - - - a / conf / cassandra . yaml 
 + + + b / conf / cassandra . yaml 
 @ @ - 112 , 11 + 112 , 12 @ @ partitioner : org . apache . cassandra . dht . Murmur3Partitioner 
 # commitlog _ directory : / var / lib / cassandra / commitlog 
 
 # policy for data disk failures : 
 - # die : shut down gossip and Thrift and kill the JVM for any fs errors or 
 + # die : shut down gossip and client transports and kill the JVM for any fs errors or 
 # single - sstable errors , so the node can be replaced . 
 - # stop _ paranoid : shut down gossip and Thrift even for single - sstable errors . 
 - # stop : shut down gossip and Thrift , leaving the node effectively dead , but 
 - # can still be inspected via JMX . 
 + # stop _ paranoid : shut down gossip and client transports even for single - sstable errors , 
 + # kill the JVM for errors during startup . 
 + # stop : shut down gossip and client transports , leaving the node effectively dead , but 
 + # can still be inspected via JMX , kill the JVM for errors during startup . 
 # best _ effort : stop using the failed disk and respond to requests based on 
 # remaining available sstables . This means you WILL see obsolete 
 # data at CL . ONE ! 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 index 6879834 . . 92c9b55 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 @ @ - 69 , 6 + 69 , 7 @ @ import org . apache . cassandra . dht . IPartitioner ; 
 import org . apache . cassandra . dht . LocalPartitioner ; 
 import org . apache . cassandra . dht . Range ; 
 import org . apache . cassandra . dht . Token ; 
 + import org . apache . cassandra . io . FSError ; 
 import org . apache . cassandra . io . compress . CompressionMetadata ; 
 import org . apache . cassandra . io . sstable . metadata . CompactionMetadata ; 
 import org . apache . cassandra . io . sstable . metadata . MetadataComponent ; 
 @ @ - 477 , 19 + 478 , 27 @ @ public class SSTableReader extends SSTable implements SelfRefCounted < SSTableRead 
 statsMetadata , 
 OpenReason . NORMAL ) ; 
 
 - / / load index and filter 
 - long start = System . nanoTime ( ) ; 
 - sstable . load ( validationMetadata ) ; 
 - logger . debug ( " INDEX LOAD TIME for { } : { } ms . " , descriptor , TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - start ) ) ; 
 + try 
 + { 
 + / / load index and filter 
 + long start = System . nanoTime ( ) ; 
 + sstable . load ( validationMetadata ) ; 
 + logger . debug ( " INDEX LOAD TIME for { } : { } ms . " , descriptor , TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - start ) ) ; 
 
 - sstable . setup ( ! validate ) ; 
 - if ( validate ) 
 - sstable . validate ( ) ; 
 + sstable . setup ( ! validate ) ; 
 + if ( validate ) 
 + sstable . validate ( ) ; 
 
 - if ( sstable . getKeyCache ( ) ! = null ) 
 - logger . debug ( " key cache contains { } / { } keys " , sstable . getKeyCache ( ) . size ( ) , sstable . getKeyCache ( ) . getCapacity ( ) ) ; 
 + if ( sstable . getKeyCache ( ) ! = null ) 
 + logger . debug ( " key cache contains { } / { } keys " , sstable . getKeyCache ( ) . size ( ) , sstable . getKeyCache ( ) . getCapacity ( ) ) ; 
 
 - return sstable ; 
 + return sstable ; 
 + } 
 + catch ( Throwable t ) 
 + { 
 + sstable . selfRef ( ) . release ( ) ; 
 + throw t ; 
 + } 
 } 
 
 public static void logOpenException ( Descriptor descriptor , IOException e ) 
 @ @ - 518 , 9 + 527 , 21 @ @ public class SSTableReader extends SSTable implements SelfRefCounted < SSTableRead 
 { 
 sstable = open ( entry . getKey ( ) , entry . getValue ( ) , metadata , partitioner ) ; 
 } 
 + catch ( CorruptSSTableException ex ) 
 + { 
 + FileUtils . handleCorruptSSTable ( ex ) ; 
 + logger . error ( " Corrupt sstable { } ; skipping table " , entry , ex ) ; 
 + return ; 
 + } 
 + catch ( FSError ex ) 
 + { 
 + FileUtils . handleFSError ( ex ) ; 
 + logger . error ( " Cannot read sstable { } ; file system error , skipping table " , entry , ex ) ; 
 + return ; 
 + } 
 catch ( IOException ex ) 
 { 
 - logger . error ( " Corrupt sstable { } ; skipped " , entry , ex ) ; 
 + logger . error ( " Cannot read sstable { } ; other IO error , skipping table " , entry , ex ) ; 
 return ; 
 } 
 sstables . add ( sstable ) ; 
 @ @ - 704 , 46 + 725 , 71 @ @ public class SSTableReader extends SSTable implements SelfRefCounted < SSTableRead 
 * / 
 private void load ( boolean recreateBloomFilter , boolean saveSummaryIfCreated ) throws IOException 
 { 
 - SegmentedFile . Builder ibuilder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; 
 - SegmentedFile . Builder dbuilder = compression 
 + try 
 + { 
 + SegmentedFile . Builder ibuilder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; 
 + SegmentedFile . Builder dbuilder = compression 
 ? SegmentedFile . getCompressedBuilder ( ) 
 : SegmentedFile . getBuilder ( DatabaseDescriptor . getDiskAccessMode ( ) ) ; 
 
 - boolean summaryLoaded = loadSummary ( ibuilder , dbuilder ) ; 
 - boolean builtSummary = false ; 
 - if ( recreateBloomFilter | | ! summaryLoaded ) 
 - { 
 - buildSummary ( recreateBloomFilter , ibuilder , dbuilder , summaryLoaded , Downsampling . BASE _ SAMPLING _ LEVEL ) ; 
 - builtSummary = true ; 
 - } 
 - 
 - if ( components . contains ( Component . PRIMARY _ INDEX ) ) 
 - ifile = ibuilder . complete ( descriptor . filenameFor ( Component . PRIMARY _ INDEX ) ) ; 
 - 
 - dfile = dbuilder . complete ( descriptor . filenameFor ( Component . DATA ) ) ; 
 + boolean summaryLoaded = loadSummary ( ibuilder , dbuilder ) ; 
 + boolean builtSummary = false ; 
 + if ( recreateBloomFilter | | ! summaryLoaded ) 
 + { 
 + buildSummary ( recreateBloomFilter , ibuilder , dbuilder , summaryLoaded , Downsampling . BASE _ SAMPLING _ LEVEL ) ; 
 + builtSummary = true ; 
 + } 
 
 - / / Check for an index summary that was downsampled even though the serialization format doesn ' t support 
 - / / that . If it was downsampled , rebuild it . See CASSANDRA - 8993 for details . 
 - if ( ! descriptor . version . hasSamplingLevel & & ! builtSummary & & ! validateSummarySamplingLevel ( ) & & ifile ! = null ) 
 - { 
 - indexSummary . close ( ) ; 
 - ifile . close ( ) ; 
 - dfile . close ( ) ; 
 + if ( components . contains ( Component . PRIMARY _ INDEX ) ) 
 + ifile = ibuilder . complete ( descriptor . filenameFor ( Component . PRIMARY _ INDEX ) ) ; 
 
 - logger . info ( " Detected erroneously downsampled index summary ; will rebuild summary at full sampling " ) ; 
 - FileUtils . deleteWithConfirm ( new File ( descriptor . filenameFor ( Component . SUMMARY ) ) ) ; 
 - ibuilder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; 
 - dbuilder = compression 
 - ? SegmentedFile . getCompressedBuilder ( ) 
 - : SegmentedFile . getBuilder ( DatabaseDescriptor . getDiskAccessMode ( ) ) ; 
 - buildSummary ( false , ibuilder , dbuilder , false , Downsampling . BASE _ SAMPLING _ LEVEL ) ; 
 - ifile = ibuilder . complete ( descriptor . filenameFor ( Component . PRIMARY _ INDEX ) ) ; 
 dfile = dbuilder . complete ( descriptor . filenameFor ( Component . DATA ) ) ; 
 - saveSummary ( ibuilder , dbuilder ) ; 
 + 
 + / / Check for an index summary that was downsampled even though the serialization format doesn ' t support 
 + / / that . If it was downsampled , rebuild it . See CASSANDRA - 8993 for details . 
 + if ( ! descriptor . version . hasSamplingLevel & & ! builtSummary & & ! validateSummarySamplingLevel ( ) & & ifile ! = null ) 
 + { 
 + indexSummary . close ( ) ; 
 + ifile . close ( ) ; 
 + dfile . close ( ) ; 
 + 
 + logger . info ( " Detected erroneously downsampled index summary ; will rebuild summary at full sampling " ) ; 
 + FileUtils . deleteWithConfirm ( new File ( descriptor . filenameFor ( Component . SUMMARY ) ) ) ; 
 + ibuilder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; 
 + dbuilder = compression 
 + ? SegmentedFile . getCompressedBuilder ( ) 
 + : SegmentedFile . getBuilder ( DatabaseDescriptor . getDiskAccessMode ( ) ) ; 
 + buildSummary ( false , ibuilder , dbuilder , false , Downsampling . BASE _ SAMPLING _ LEVEL ) ; 
 + ifile = ibuilder . complete ( descriptor . filenameFor ( Component . PRIMARY _ INDEX ) ) ; 
 + dfile = dbuilder . complete ( descriptor . filenameFor ( Component . DATA ) ) ; 
 + saveSummary ( ibuilder , dbuilder ) ; 
 + } 
 + else if ( saveSummaryIfCreated & & builtSummary ) 
 + { 
 + saveSummary ( ibuilder , dbuilder ) ; 
 + } 
 } 
 - else if ( saveSummaryIfCreated & & builtSummary ) 
 - { 
 - saveSummary ( ibuilder , dbuilder ) ; 
 + catch ( Throwable t ) 
 + { / / Because the tidier has not been set - up yet in SSTableReader . open ( ) , we must release the files in case of error 
 + if ( ifile ! = null ) 
 + { 
 + ifile . close ( ) ; 
 + ifile = null ; 
 + } 
 + 
 + if ( dfile ! = null ) 
 + { 
 + dfile . close ( ) ; 
 + dfile = null ; 
 + } 
 + 
 + if ( indexSummary ! = null ) 
 + { 
 + indexSummary . close ( ) ; 
 + indexSummary = null ; 
 + } 
 + 
 + throw t ; 
 } 
 } 
 
 @ @ - 2174 , 7 + 2220 , 8 @ @ public class SSTableReader extends SSTable implements SelfRefCounted < SSTableRead 
 summary . close ( ) ; 
 if ( runOnClose ! = null ) 
 runOnClose . run ( ) ; 
 - dfile . close ( ) ; 
 + if ( dfile ! = null ) 
 + dfile . close ( ) ; 
 if ( ifile ! = null ) 
 ifile . close ( ) ; 
 typeRef . release ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / io / util / FileUtils . java b / src / java / org / apache / cassandra / io / util / FileUtils . java 
 index 7d187ac . . 3be7c99 100644 
 - - - a / src / java / org / apache / cassandra / io / util / FileUtils . java 
 + + + b / src / java / org / apache / cassandra / io / util / FileUtils . java 
 @ @ - 395 , 6 + 395 , 9 @ @ public class FileUtils 
 
 public static void handleCorruptSSTable ( CorruptSSTableException e ) 
 { 
 + if ( ! StorageService . instance . isSetupCompleted ( ) ) 
 + handleStartupFSError ( e ) ; 
 + 
 JVMStabilityInspector . inspectThrowable ( e ) ; 
 switch ( DatabaseDescriptor . getDiskFailurePolicy ( ) ) 
 { 
 @ @ - 406 , 6 + 409 , 9 @ @ public class FileUtils 
 
 public static void handleFSError ( FSError e ) 
 { 
 + if ( ! StorageService . instance . isSetupCompleted ( ) ) 
 + handleStartupFSError ( e ) ; 
 + 
 JVMStabilityInspector . inspectThrowable ( e ) ; 
 switch ( DatabaseDescriptor . getDiskFailurePolicy ( ) ) 
 { 
 @ @ - 431 , 6 + 437 , 22 @ @ public class FileUtils 
 } 
 } 
 
 + private static void handleStartupFSError ( Throwable t ) 
 + { 
 + switch ( DatabaseDescriptor . getDiskFailurePolicy ( ) ) 
 + { 
 + case stop _ paranoid : 
 + case stop : 
 + case die : 
 + logger . error ( " Exiting forcefully due to file system exception on startup , disk failure policy \ " { } \ " " , 
 + DatabaseDescriptor . getDiskFailurePolicy ( ) , 
 + t ) ; 
 + JVMStabilityInspector . killCurrentJVM ( t , true ) ; 
 + break ; 
 + default : 
 + break ; 
 + } 
 + } 
 / * * 
 * Get the size of a directory in bytes 
 * @ param directory The directory for which we need size . 
 diff - - git a / src / java / org / apache / cassandra / service / CassandraDaemon . java b / src / java / org / apache / cassandra / service / CassandraDaemon . java 
 index f66e523 . . 949ea4c 100644 
 - - - a / src / java / org / apache / cassandra / service / CassandraDaemon . java 
 + + + b / src / java / org / apache / cassandra / service / CassandraDaemon . java 
 @ @ - 134 , 7 + 134 , 7 @ @ public class CassandraDaemon 
 
 public Server thriftServer ; 
 public Server nativeServer ; 
 - 
 + private boolean setupCompleted = false ; 
 / * * 
 * This is a hook for concrete daemons to initialize themselves suitably . 
 * 
 @ @ - 425 , 6 + 425 , 13 @ @ public class CassandraDaemon 
 InetAddress nativeAddr = DatabaseDescriptor . getRpcAddress ( ) ; 
 int nativePort = DatabaseDescriptor . getNativeTransportPort ( ) ; 
 nativeServer = new org . apache . cassandra . transport . Server ( nativeAddr , nativePort ) ; 
 + 
 + setupCompleted = true ; 
 + } 
 + 
 + public boolean setupCompleted ( ) 
 + { 
 + return setupCompleted ; 
 } 
 
 / * * 
 diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index e4ffc5b . . 4a32bad 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 486 , 6 + 486 , 13 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 return initialized ; 
 } 
 
 + public boolean isSetupCompleted ( ) 
 + { 
 + return daemon = = null 
 + ? false 
 + : daemon . setupCompleted ( ) ; 
 + } 
 + 
 public void stopDaemon ( ) 
 { 
 if ( daemon = = null ) 
 diff - - git a / src / java / org / apache / cassandra / utils / JVMStabilityInspector . java b / src / java / org / apache / cassandra / utils / JVMStabilityInspector . java 
 index 2883ab3 . . c0ab84f 100644 
 - - - a / src / java / org / apache / cassandra / utils / JVMStabilityInspector . java 
 + + + b / src / java / org / apache / cassandra / utils / JVMStabilityInspector . java 
 @ @ - 72 , 6 + 72 , 11 @ @ public final class JVMStabilityInspector 
 inspectThrowable ( t ) ; 
 } 
 
 + public static void killCurrentJVM ( Throwable t , boolean quiet ) 
 + { 
 + killer . killCurrentJVM ( t , quiet ) ; 
 + } 
 + 
 @ VisibleForTesting 
 public static Killer replaceKiller ( Killer newKiller ) { 
 Killer oldKiller = JVMStabilityInspector . killer ; 
 @ @ - 90 , 8 + 95 , 16 @ @ public final class JVMStabilityInspector 
 * / 
 protected void killCurrentJVM ( Throwable t ) 
 { 
 - t . printStackTrace ( System . err ) ; 
 - logger . error ( " JVM state determined to be unstable . Exiting forcefully due to : " , t ) ; 
 + killCurrentJVM ( t , false ) ; 
 + } 
 + 
 + protected void killCurrentJVM ( Throwable t , boolean quiet ) 
 + { 
 + if ( ! quiet ) 
 + { 
 + t . printStackTrace ( System . err ) ; 
 + logger . error ( " JVM state determined to be unstable . Exiting forcefully due to : " , t ) ; 
 + } 
 StorageService . instance . removeShutdownHook ( ) ; 
 System . exit ( 100 ) ; 
 }

NEAREST DIFF:
diff - - git a / src / java / org / apache / cassandra / concurrent / DebuggableThreadPoolExecutor . java b / src / java / org / apache / cassandra / concurrent / DebuggableThreadPoolExecutor . java 
 index 08af5fa . . 38d73de 100644 
 - - - a / src / java / org / apache / cassandra / concurrent / DebuggableThreadPoolExecutor . java 
 + + + b / src / java / org / apache / cassandra / concurrent / DebuggableThreadPoolExecutor . java 
 @ @ - 57 , 9 + 57 , 9 @ @ public class DebuggableThreadPoolExecutor extends ThreadPoolExecutor 
 super ( corePoolSize , corePoolSize , keepAliveTime , unit , workQueue , threadFactory ) ; 
 allowCoreThreadTimeOut ( true ) ; 
 
 - / / preserve task serialization . this is more complicated than it needs to be , 
 - / / since TPE rejects if queue . offer reports a full queue . we ' ll just 
 - / / override this with a handler that retries until it gets in . ugly , but effective . 
 + / / block task submissions until queue has room . 
 + / / this is fighting TPE ' s design a bit because TPE rejects if queue . offer reports a full queue . 
 + / / we ' ll just override this with a handler that retries until it gets in . ugly , but effective . 
 / / ( there is an extensive analysis of the options here at 
 / / http : / / today . java . net / pub / a / today / 2008 / 10 / 23 / creating - a - notifying - blocking - thread - pool - executor . html ) 
 this . setRejectedExecutionHandler ( new RejectedExecutionHandler ( )
