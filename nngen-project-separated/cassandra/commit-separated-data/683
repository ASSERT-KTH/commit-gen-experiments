BLEU SCORE: 0.027611988917697356

TEST MSG: Define executeLocally ( ) at the ReadQuery Level
GENERATED MSG: merge from 1 . 0

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index f46b23e . . 1c73c7d 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 3 . 10 <nl> + * Define executeLocally ( ) at the ReadQuery Level ( CASSANDRA - 12474 ) <nl> * Extend read / write failure messages with a map of replica addresses <nl> to error codes in the v5 native protocol ( CASSANDRA - 12311 ) <nl> * Fix rebuild of SASI indexes with existing index files ( CASSANDRA - 12374 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / ReadExecutionController . java b / src / java / org / apache / cassandra / db / ReadExecutionController . java <nl> index 7ddc8df . . 56bb0d3 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ReadExecutionController . java <nl> + + + b / src / java / org / apache / cassandra / db / ReadExecutionController . java <nl> @ @ - 120 , 6 + 120 , 11 @ @ public class ReadExecutionController implements AutoCloseable <nl> return index = = null ? null : index . getBackingTable ( ) . orElse ( null ) ; <nl> } <nl> <nl> + public CFMetaData metaData ( ) <nl> + { <nl> + return baseMetadata ; <nl> + } <nl> + <nl> public void close ( ) <nl> { <nl> try <nl> diff - - git a / src / java / org / apache / cassandra / db / ReadQuery . java b / src / java / org / apache / cassandra / db / ReadQuery . java <nl> index d74834c . . c6b2b3e 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ReadQuery . java <nl> + + + b / src / java / org / apache / cassandra / db / ReadQuery . java <nl> @ @ - 50 , 6 + 50 , 11 @ @ public interface ReadQuery <nl> return EmptyIterators . partition ( ) ; <nl> } <nl> <nl> + public UnfilteredPartitionIterator executeLocally ( ReadExecutionController executionController ) <nl> + { <nl> + return EmptyIterators . unfilteredPartition ( executionController . metaData ( ) , false ) ; <nl> + } <nl> + <nl> public DataLimits limits ( ) <nl> { <nl> / / What we return here doesn ' t matter much in practice . However , returning DataLimits . NONE means <nl> @ @ - 105 , 6 + 110 , 15 @ @ public interface ReadQuery <nl> public PartitionIterator executeInternal ( ReadExecutionController controller ) ; <nl> <nl> / * * <nl> + * Execute the query locally . This is similar to { @ link ReadQuery # executeInternal ( ReadExecutionController ) } <nl> + * but it returns an unfiltered partition iterator that can be merged later on . <nl> + * <nl> + * @ param controller the { @ code ReadExecutionController } protecting the read . <nl> + * @ return the result of the read query . <nl> + * / <nl> + public UnfilteredPartitionIterator executeLocally ( ReadExecutionController executionController ) ; <nl> + <nl> + / * * <nl> * Returns a pager for the query . <nl> * <nl> * @ param pagingState the { @ code PagingState } to start from if this is a paging continuation . This can be <nl> diff - - git a / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java b / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java <nl> index cea8c0c . . ad73a17 100644 <nl> - - - a / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java <nl> @ @ - 20 , 10 + 20 , 13 @ @ package org . apache . cassandra . db ; <nl> import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> + import java . util . stream . Collectors ; <nl> <nl> import com . google . common . collect . Iterables ; <nl> import com . google . common . collect . Sets ; <nl> <nl> + import org . apache . commons . lang3 . tuple . Pair ; <nl> + <nl> import org . apache . cassandra . cache . IRowCacheEntry ; <nl> import org . apache . cassandra . cache . RowCacheKey ; <nl> import org . apache . cassandra . cache . RowCacheSentinel ; <nl> @ @ - 1012 , 12 + 1015 , 35 @ @ public class SinglePartitionReadCommand extends ReadCommand <nl> <nl> public PartitionIterator executeInternal ( ReadExecutionController controller ) <nl> { <nl> - List < PartitionIterator > partitions = new ArrayList < > ( commands . size ( ) ) ; <nl> + return limits . filter ( UnfilteredPartitionIterators . filter ( executeLocally ( controller , false ) , nowInSec ) , nowInSec ) ; <nl> + } <nl> + <nl> + public UnfilteredPartitionIterator executeLocally ( ReadExecutionController executionController ) <nl> + { <nl> + return executeLocally ( executionController , true ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Implementation of { @ link ReadQuery # executeLocally ( ReadExecutionController ) } . <nl> + * <nl> + * @ param executionController - the { @ code ReadExecutionController } protecting the read . <nl> + * @ param sort - whether to sort the inner commands by partition key , required for merging the iterator <nl> + * later on . This will be false when called by { @ link ReadQuery # executeInternal ( ReadExecutionController ) } <nl> + * because in this case it is safe to do so as there is no merging involved and we don ' t want to <nl> + * change the old behavior which was to not sort by partition . <nl> + * <nl> + * @ return - the iterator that can be used to retrieve the query result . <nl> + * / <nl> + private UnfilteredPartitionIterator executeLocally ( ReadExecutionController executionController , boolean sort ) <nl> + { <nl> + List < Pair < DecoratedKey , UnfilteredPartitionIterator > > partitions = new ArrayList < > ( commands . size ( ) ) ; <nl> for ( SinglePartitionReadCommand cmd : commands ) <nl> - partitions . add ( cmd . executeInternal ( controller ) ) ; <nl> + partitions . add ( Pair . of ( cmd . partitionKey , cmd . executeLocally ( executionController ) ) ) ; <nl> + <nl> + if ( sort ) <nl> + Collections . sort ( partitions , ( p1 , p2 ) - > p1 . getLeft ( ) . compareTo ( p2 . getLeft ( ) ) ) ; <nl> <nl> - / / Because we only have enforce the limit per command , we need to enforce it globally . <nl> - return limits . filter ( PartitionIterators . concat ( partitions ) , nowInSec ) ; <nl> + return UnfilteredPartitionIterators . concat ( partitions . stream ( ) . map ( p - > p . getRight ( ) ) . collect ( Collectors . toList ( ) ) ) ; <nl> } <nl> <nl> public QueryPager getPager ( PagingState pagingState , int protocolVersion ) <nl> diff - - git a / src / java / org / apache / cassandra / db / partitions / UnfilteredPartitionIterators . java b / src / java / org / apache / cassandra / db / partitions / UnfilteredPartitionIterators . java <nl> index b7f6793 . . 852d95e 100644 <nl> - - - a / src / java / org / apache / cassandra / db / partitions / UnfilteredPartitionIterators . java <nl> + + + b / src / java / org / apache / cassandra / db / partitions / UnfilteredPartitionIterators . java <nl> @ @ - 27 , 6 + 27 , 7 @ @ import org . apache . cassandra . db . * ; <nl> import org . apache . cassandra . db . filter . ColumnFilter ; <nl> import org . apache . cassandra . db . rows . * ; <nl> import org . apache . cassandra . db . transform . FilteredPartitions ; <nl> + import org . apache . cassandra . db . transform . MorePartitions ; <nl> import org . apache . cassandra . db . transform . Transformation ; <nl> import org . apache . cassandra . io . util . DataInputPlus ; <nl> import org . apache . cassandra . io . util . DataOutputPlus ; <nl> @ @ - 77 , 6 + 78 , 25 @ @ public abstract class UnfilteredPartitionIterators <nl> return Transformation . apply ( toReturn , new Close ( ) ) ; <nl> } <nl> <nl> + public static UnfilteredPartitionIterator concat ( final List < UnfilteredPartitionIterator > iterators ) <nl> + { <nl> + if ( iterators . size ( ) = = 1 ) <nl> + return iterators . get ( 0 ) ; <nl> + <nl> + class Extend implements MorePartitions < UnfilteredPartitionIterator > <nl> + { <nl> + int i = 1 ; <nl> + public UnfilteredPartitionIterator moreContents ( ) <nl> + { <nl> + if ( i > = iterators . size ( ) ) <nl> + return null ; <nl> + return iterators . get ( i + + ) ; <nl> + } <nl> + } <nl> + return MorePartitions . extend ( iterators . get ( 0 ) , new Extend ( ) ) ; <nl> + } <nl> + <nl> + <nl> public static PartitionIterator mergeAndFilter ( List < UnfilteredPartitionIterator > iterators , int nowInSec , MergeListener listener ) <nl> { <nl> / / TODO : we could have a somewhat faster version if we were to merge the UnfilteredRowIterators directly as RowIterators <nl> diff - - git a / test / unit / org / apache / cassandra / db / ReadCommandTest . java b / test / unit / org / apache / cassandra / db / ReadCommandTest . java <nl> index fddd347 . . 2aef2a7 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / ReadCommandTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / ReadCommandTest . java <nl> @ @ - 18 , 6 + 18 , 8 @ @ <nl> <nl> package org . apache . cassandra . db ; <nl> <nl> + import java . nio . ByteBuffer ; <nl> + import java . util . ArrayList ; <nl> import java . util . List ; <nl> <nl> import org . junit . BeforeClass ; <nl> @ @ - 27 , 12 + 29 , 28 @ @ import org . apache . cassandra . SchemaLoader ; <nl> import org . apache . cassandra . Util ; <nl> import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> + import org . apache . cassandra . db . filter . ClusteringIndexSliceFilter ; <nl> + import org . apache . cassandra . db . filter . ColumnFilter ; <nl> + import org . apache . cassandra . db . filter . DataLimits ; <nl> + import org . apache . cassandra . db . filter . RowFilter ; <nl> import org . apache . cassandra . db . marshal . AsciiType ; <nl> import org . apache . cassandra . db . marshal . BytesType ; <nl> import org . apache . cassandra . db . partitions . FilteredPartition ; <nl> + import org . apache . cassandra . db . partitions . PartitionIterator ; <nl> + import org . apache . cassandra . db . partitions . UnfilteredPartitionIterator ; <nl> + import org . apache . cassandra . db . partitions . UnfilteredPartitionIterators ; <nl> + import org . apache . cassandra . db . rows . Row ; <nl> + import org . apache . cassandra . db . rows . RowIterator ; <nl> + import org . apache . cassandra . db . rows . SerializationHelper ; <nl> + import org . apache . cassandra . db . rows . UnfilteredRowIterator ; <nl> + import org . apache . cassandra . db . rows . UnfilteredRowIterators ; <nl> import org . apache . cassandra . exceptions . ConfigurationException ; <nl> + import org . apache . cassandra . io . util . DataInputBuffer ; <nl> + import org . apache . cassandra . io . util . DataOutputBuffer ; <nl> + import org . apache . cassandra . net . MessagingService ; <nl> import org . apache . cassandra . schema . KeyspaceParams ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> + import org . apache . cassandra . utils . FBUtilities ; <nl> <nl> import static org . junit . Assert . assertEquals ; <nl> <nl> @ @ - 41 , 6 + 59 , 7 @ @ public class ReadCommandTest <nl> private static final String KEYSPACE = " ReadCommandTest " ; <nl> private static final String CF1 = " Standard1 " ; <nl> private static final String CF2 = " Standard2 " ; <nl> + private static final String CF3 = " Standard3 " ; <nl> <nl> @ BeforeClass <nl> public static void defineSchema ( ) throws ConfigurationException <nl> @ @ - 55 , 11 + 74 , 22 @ @ public class ReadCommandTest <nl> . addRegularColumn ( " a " , AsciiType . instance ) <nl> . addRegularColumn ( " b " , AsciiType . instance ) . build ( ) ; <nl> <nl> + CFMetaData metadata3 = CFMetaData . Builder . create ( KEYSPACE , CF3 ) <nl> + . addPartitionKey ( " key " , BytesType . instance ) <nl> + . addClusteringColumn ( " col " , AsciiType . instance ) <nl> + . addRegularColumn ( " a " , AsciiType . instance ) <nl> + . addRegularColumn ( " b " , AsciiType . instance ) <nl> + . addRegularColumn ( " c " , AsciiType . instance ) <nl> + . addRegularColumn ( " d " , AsciiType . instance ) <nl> + . addRegularColumn ( " e " , AsciiType . instance ) <nl> + . addRegularColumn ( " f " , AsciiType . instance ) . build ( ) ; <nl> + <nl> SchemaLoader . prepareServer ( ) ; <nl> SchemaLoader . createKeyspace ( KEYSPACE , <nl> KeyspaceParams . simple ( 1 ) , <nl> metadata1 , <nl> - metadata2 ) ; <nl> + metadata2 , <nl> + metadata3 ) ; <nl> } <nl> <nl> @ Test <nl> @ @ - 149 , 4 + 179 , 133 @ @ public class ReadCommandTest <nl> readCommand . abort ( ) ; <nl> assertEquals ( 0 , Util . getAll ( readCommand ) . size ( ) ) ; <nl> } <nl> + <nl> + @ Test <nl> + public void testSinglePartitionGroupMerge ( ) throws Exception <nl> + { <nl> + ColumnFamilyStore cfs = Keyspace . open ( KEYSPACE ) . getColumnFamilyStore ( CF3 ) ; <nl> + <nl> + String [ ] [ ] [ ] groups = new String [ ] [ ] [ ] { <nl> + new String [ ] [ ] { <nl> + new String [ ] { " 1 " , " key1 " , " aa " , " a " } , / / " 1 " indicates to create the data , " - 1 " to delete the row <nl> + new String [ ] { " 1 " , " key2 " , " bb " , " b " } , <nl> + new String [ ] { " 1 " , " key3 " , " cc " , " c " } <nl> + } , <nl> + new String [ ] [ ] { <nl> + new String [ ] { " 1 " , " key3 " , " dd " , " d " } , <nl> + new String [ ] { " 1 " , " key2 " , " ee " , " e " } , <nl> + new String [ ] { " 1 " , " key1 " , " ff " , " f " } <nl> + } , <nl> + new String [ ] [ ] { <nl> + new String [ ] { " 1 " , " key6 " , " aa " , " a " } , <nl> + new String [ ] { " 1 " , " key5 " , " bb " , " b " } , <nl> + new String [ ] { " 1 " , " key4 " , " cc " , " c " } <nl> + } , <nl> + new String [ ] [ ] { <nl> + new String [ ] { " - 1 " , " key6 " , " aa " , " a " } , <nl> + new String [ ] { " - 1 " , " key2 " , " bb " , " b " } <nl> + } <nl> + } ; <nl> + <nl> + / / Given the data above , when the keys are sorted and the deletions removed , we should <nl> + / / get these clustering rows in this order <nl> + String [ ] expectedRows = new String [ ] { " aa " , " ff " , " ee " , " cc " , " dd " , " cc " , " bb " } ; <nl> + <nl> + List < ByteBuffer > buffers = new ArrayList < > ( groups . length ) ; <nl> + int nowInSeconds = FBUtilities . nowInSeconds ( ) ; <nl> + ColumnFilter columnFilter = ColumnFilter . allColumnsBuilder ( cfs . metadata ) . build ( ) ; <nl> + RowFilter rowFilter = RowFilter . create ( ) ; <nl> + Slice slice = Slice . make ( ClusteringBound . BOTTOM , ClusteringBound . TOP ) ; <nl> + ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter ( Slices . with ( cfs . metadata . comparator , slice ) , false ) ; <nl> + <nl> + for ( String [ ] [ ] group : groups ) <nl> + { <nl> + cfs . truncateBlocking ( ) ; <nl> + <nl> + List < SinglePartitionReadCommand > commands = new ArrayList < > ( group . length ) ; <nl> + <nl> + for ( String [ ] data : group ) <nl> + { <nl> + if ( data [ 0 ] . equals ( " 1 " ) ) <nl> + { <nl> + new RowUpdateBuilder ( cfs . metadata , 0 , ByteBufferUtil . bytes ( data [ 1 ] ) ) <nl> + . clustering ( data [ 2 ] ) <nl> + . add ( data [ 3 ] , ByteBufferUtil . bytes ( " blah " ) ) <nl> + . build ( ) <nl> + . apply ( ) ; <nl> + } <nl> + else <nl> + { <nl> + RowUpdateBuilder . deleteRow ( cfs . metadata , FBUtilities . timestampMicros ( ) , ByteBufferUtil . bytes ( data [ 1 ] ) , data [ 2 ] ) . apply ( ) ; <nl> + } <nl> + commands . add ( SinglePartitionReadCommand . create ( cfs . metadata , nowInSeconds , columnFilter , rowFilter , DataLimits . NONE , Util . dk ( data [ 1 ] ) , sliceFilter ) ) ; <nl> + } <nl> + <nl> + cfs . forceBlockingFlush ( ) ; <nl> + <nl> + ReadQuery query = new SinglePartitionReadCommand . Group ( commands , DataLimits . NONE ) ; <nl> + <nl> + try ( ReadExecutionController executionController = query . executionController ( ) ; <nl> + UnfilteredPartitionIterator iter = query . executeLocally ( executionController ) ; <nl> + DataOutputBuffer buffer = new DataOutputBuffer ( ) ) <nl> + { <nl> + UnfilteredPartitionIterators . serializerForIntraNode ( ) . serialize ( iter , <nl> + columnFilter , <nl> + buffer , <nl> + MessagingService . current _ version ) ; <nl> + buffers . add ( buffer . buffer ( ) ) ; <nl> + } <nl> + } <nl> + <nl> + / / deserialize , merge and check the results are all there <nl> + List < UnfilteredPartitionIterator > iterators = new ArrayList < > ( ) ; <nl> + <nl> + for ( ByteBuffer buffer : buffers ) <nl> + { <nl> + try ( DataInputBuffer in = new DataInputBuffer ( buffer , true ) ) <nl> + { <nl> + iterators . add ( UnfilteredPartitionIterators . serializerForIntraNode ( ) . deserialize ( in , <nl> + MessagingService . current _ version , <nl> + cfs . metadata , <nl> + columnFilter , <nl> + SerializationHelper . Flag . LOCAL ) ) ; <nl> + } <nl> + } <nl> + <nl> + try ( PartitionIterator partitionIterator = UnfilteredPartitionIterators . mergeAndFilter ( iterators , <nl> + nowInSeconds , <nl> + new UnfilteredPartitionIterators . MergeListener ( ) <nl> + { <nl> + public UnfilteredRowIterators . MergeListener getRowMergeListener ( DecoratedKey partitionKey , List < UnfilteredRowIterator > versions ) <nl> + { <nl> + return null ; <nl> + } <nl> + <nl> + public void close ( ) <nl> + { <nl> + <nl> + } <nl> + } ) ) <nl> + { <nl> + <nl> + int i = 0 ; <nl> + int numPartitions = 0 ; <nl> + while ( partitionIterator . hasNext ( ) ) <nl> + { <nl> + numPartitions + + ; <nl> + try ( RowIterator rowIterator = partitionIterator . next ( ) ) <nl> + { <nl> + while ( rowIterator . hasNext ( ) ) <nl> + { <nl> + Row row = rowIterator . next ( ) ; <nl> + assertEquals ( " col = " + expectedRows [ i + + ] , row . clustering ( ) . toString ( cfs . metadata ) ) ; <nl> + / / System . out . print ( row . toString ( cfs . metadata , true ) ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + assertEquals ( 5 , numPartitions ) ; <nl> + assertEquals ( expectedRows . length , i ) ; <nl> + } <nl> + } <nl> }
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index d518830 . . 52cc2c1 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 29 , 7 + 29 , 7 @ @ <nl> * add scheduler JMX metrics ( CASSANDRA - 2962 ) <nl> * add block level checksum for compressed data ( CASSANDRA - 1717 ) <nl> * make column family backed column map pluggable and introduce unsynchronized <nl> - ArrayList backed one to speedup reads ( CASSANDRA - 2843 ) <nl> + ArrayList backed one to speedup reads ( CASSANDRA - 2843 , 3165 ) <nl> * refactoring of the secondary index api ( CASSANDRA - 2982 ) <nl> * make CL > ONE reads wait for digest reconciliation before returning <nl> ( CASSANDRA - 2494 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / ArrayBackedSortedColumns . java b / src / java / org / apache / cassandra / db / ArrayBackedSortedColumns . java <nl> index c316a85 . . 71c7213 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ArrayBackedSortedColumns . java <nl> + + + b / src / java / org / apache / cassandra / db / ArrayBackedSortedColumns . java <nl> @ @ - 67 , 6 + 67 , 11 @ @ public class ArrayBackedSortedColumns extends ArrayList < IColumn > implements ISor <nl> this . reversed = reversed ; <nl> } <nl> <nl> + public ISortedColumns . Factory getFactory ( ) <nl> + { <nl> + return factory ( ) ; <nl> + } <nl> + <nl> public AbstractType < ? > getComparator ( ) <nl> { <nl> return comparator ; <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamily . java b / src / java / org / apache / cassandra / db / ColumnFamily . java <nl> index 1239d1c . . 38bc0d7 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamily . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamily . java <nl> @ @ - 81 , 14 + 81 , 19 @ @ public class ColumnFamily extends AbstractColumnContainer <nl> this . cfm = cfm ; <nl> } <nl> <nl> - public ColumnFamily cloneMeShallow ( ) <nl> + public ColumnFamily cloneMeShallow ( ISortedColumns . Factory factory ) <nl> { <nl> - ColumnFamily cf = ColumnFamily . create ( cfm ) ; <nl> + ColumnFamily cf = ColumnFamily . create ( cfm , factory ) ; <nl> / / since deletion info is immutable , aliasing it is fine <nl> cf . deletionInfo . set ( deletionInfo . get ( ) ) ; <nl> return cf ; <nl> } <nl> <nl> + public ColumnFamily cloneMeShallow ( ) <nl> + { <nl> + return cloneMeShallow ( columns . getFactory ( ) ) ; <nl> + } <nl> + <nl> public AbstractType getSubComparator ( ) <nl> { <nl> IColumnSerializer s = getColumnSerializer ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index 0bfd1c5 . . 552d3e9 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 1162 , 8 + 1162 , 11 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> } <nl> } <nl> <nl> - / * * filter a cached row , which will not be modified by the filter , but may be modified by throwing out <nl> - * tombstones that are no longer relevant . * / <nl> + / * * <nl> + * Filter a cached row , which will not be modified by the filter , but may be modified by throwing out <nl> + * tombstones that are no longer relevant . <nl> + * The returned column family won ' t be thread safe . <nl> + * / <nl> ColumnFamily filterColumnFamily ( ColumnFamily cached , QueryFilter filter , int gcBefore ) <nl> { <nl> / / special case slicing the entire row : <nl> @ @ - 1184 , 7 + 1187 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> IColumn sc = cached . getColumn ( filter . path . superColumnName ) ; <nl> if ( sc = = null | | sliceFilter . count > = sc . getSubColumns ( ) . size ( ) ) <nl> { <nl> - ColumnFamily cf = cached . cloneMeShallow ( ) ; <nl> + ColumnFamily cf = cached . cloneMeShallow ( ArrayBackedSortedColumns . factory ( ) ) ; <nl> if ( sc ! = null ) <nl> cf . addColumn ( sc , HeapAllocator . instance ) ; <nl> return removeDeleted ( cf , gcBefore ) ; <nl> @ @ - 1203 , 7 + 1206 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> } <nl> <nl> IColumnIterator ci = filter . getMemtableColumnIterator ( cached , null , getComparator ( ) ) ; <nl> - ColumnFamily cf = ci . getColumnFamily ( ) . cloneMeShallow ( ) ; <nl> + ColumnFamily cf = ci . getColumnFamily ( ) . cloneMeShallow ( ArrayBackedSortedColumns . factory ( ) ) ; <nl> filter . collateColumns ( cf , Collections . singletonList ( ci ) , getComparator ( ) , gcBefore ) ; <nl> / / TODO this is necessary because when we collate supercolumns together , we don ' t check <nl> / / their subcolumns for relevance , so we need to do a second prune post facto here . <nl> diff - - git a / src / java / org / apache / cassandra / db / ISortedColumns . java b / src / java / org / apache / cassandra / db / ISortedColumns . java <nl> index 37f5a60 . . 624dec7 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ISortedColumns . java <nl> + + + b / src / java / org / apache / cassandra / db / ISortedColumns . java <nl> @ @ - 42 , 6 + 42 , 11 @ @ public interface ISortedColumns extends IIterableColumns <nl> public ISortedColumns cloneMe ( ) ; <nl> <nl> / * * <nl> + * Returns the factory used for this ISortedColumns implementation . <nl> + * / <nl> + public Factory getFactory ( ) ; <nl> + <nl> + / * * <nl> * Adds a column to this column map . <nl> * If a column with the same name is already present in the map , it will <nl> * be replaced by the newly added column . <nl> diff - - git a / src / java / org / apache / cassandra / db / ThreadSafeSortedColumns . java b / src / java / org / apache / cassandra / db / ThreadSafeSortedColumns . java <nl> index cd2488a . . 13a111a 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ThreadSafeSortedColumns . java <nl> + + + b / src / java / org / apache / cassandra / db / ThreadSafeSortedColumns . java <nl> @ @ - 62 , 6 + 62 , 11 @ @ public class ThreadSafeSortedColumns extends ConcurrentSkipListMap < ByteBuffer , I <nl> super ( columns ) ; <nl> } <nl> <nl> + public ISortedColumns . Factory getFactory ( ) <nl> + { <nl> + return factory ( ) ; <nl> + } <nl> + <nl> public ISortedColumns cloneMe ( ) <nl> { <nl> return new ThreadSafeSortedColumns ( this ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / TreeMapBackedSortedColumns . java b / src / java / org / apache / cassandra / db / TreeMapBackedSortedColumns . java <nl> index 34e83dc . . 6c3fc42 100644 <nl> - - - a / src / java / org / apache / cassandra / db / TreeMapBackedSortedColumns . java <nl> + + + b / src / java / org / apache / cassandra / db / TreeMapBackedSortedColumns . java <nl> @ @ - 62 , 6 + 62 , 11 @ @ public class TreeMapBackedSortedColumns extends TreeMap < ByteBuffer , IColumn > imp <nl> super ( columns ) ; <nl> } <nl> <nl> + public ISortedColumns . Factory getFactory ( ) <nl> + { <nl> + return factory ( ) ; <nl> + } <nl> + <nl> public ISortedColumns cloneMe ( ) <nl> { <nl> return new TreeMapBackedSortedColumns ( this ) ;

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index f46b23e . . 1c73c7d 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 3 . 10 
 + * Define executeLocally ( ) at the ReadQuery Level ( CASSANDRA - 12474 ) 
 * Extend read / write failure messages with a map of replica addresses 
 to error codes in the v5 native protocol ( CASSANDRA - 12311 ) 
 * Fix rebuild of SASI indexes with existing index files ( CASSANDRA - 12374 ) 
 diff - - git a / src / java / org / apache / cassandra / db / ReadExecutionController . java b / src / java / org / apache / cassandra / db / ReadExecutionController . java 
 index 7ddc8df . . 56bb0d3 100644 
 - - - a / src / java / org / apache / cassandra / db / ReadExecutionController . java 
 + + + b / src / java / org / apache / cassandra / db / ReadExecutionController . java 
 @ @ - 120 , 6 + 120 , 11 @ @ public class ReadExecutionController implements AutoCloseable 
 return index = = null ? null : index . getBackingTable ( ) . orElse ( null ) ; 
 } 
 
 + public CFMetaData metaData ( ) 
 + { 
 + return baseMetadata ; 
 + } 
 + 
 public void close ( ) 
 { 
 try 
 diff - - git a / src / java / org / apache / cassandra / db / ReadQuery . java b / src / java / org / apache / cassandra / db / ReadQuery . java 
 index d74834c . . c6b2b3e 100644 
 - - - a / src / java / org / apache / cassandra / db / ReadQuery . java 
 + + + b / src / java / org / apache / cassandra / db / ReadQuery . java 
 @ @ - 50 , 6 + 50 , 11 @ @ public interface ReadQuery 
 return EmptyIterators . partition ( ) ; 
 } 
 
 + public UnfilteredPartitionIterator executeLocally ( ReadExecutionController executionController ) 
 + { 
 + return EmptyIterators . unfilteredPartition ( executionController . metaData ( ) , false ) ; 
 + } 
 + 
 public DataLimits limits ( ) 
 { 
 / / What we return here doesn ' t matter much in practice . However , returning DataLimits . NONE means 
 @ @ - 105 , 6 + 110 , 15 @ @ public interface ReadQuery 
 public PartitionIterator executeInternal ( ReadExecutionController controller ) ; 
 
 / * * 
 + * Execute the query locally . This is similar to { @ link ReadQuery # executeInternal ( ReadExecutionController ) } 
 + * but it returns an unfiltered partition iterator that can be merged later on . 
 + * 
 + * @ param controller the { @ code ReadExecutionController } protecting the read . 
 + * @ return the result of the read query . 
 + * / 
 + public UnfilteredPartitionIterator executeLocally ( ReadExecutionController executionController ) ; 
 + 
 + / * * 
 * Returns a pager for the query . 
 * 
 * @ param pagingState the { @ code PagingState } to start from if this is a paging continuation . This can be 
 diff - - git a / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java b / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java 
 index cea8c0c . . ad73a17 100644 
 - - - a / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java 
 + + + b / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java 
 @ @ - 20 , 10 + 20 , 13 @ @ package org . apache . cassandra . db ; 
 import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 import java . util . * ; 
 + import java . util . stream . Collectors ; 
 
 import com . google . common . collect . Iterables ; 
 import com . google . common . collect . Sets ; 
 
 + import org . apache . commons . lang3 . tuple . Pair ; 
 + 
 import org . apache . cassandra . cache . IRowCacheEntry ; 
 import org . apache . cassandra . cache . RowCacheKey ; 
 import org . apache . cassandra . cache . RowCacheSentinel ; 
 @ @ - 1012 , 12 + 1015 , 35 @ @ public class SinglePartitionReadCommand extends ReadCommand 
 
 public PartitionIterator executeInternal ( ReadExecutionController controller ) 
 { 
 - List < PartitionIterator > partitions = new ArrayList < > ( commands . size ( ) ) ; 
 + return limits . filter ( UnfilteredPartitionIterators . filter ( executeLocally ( controller , false ) , nowInSec ) , nowInSec ) ; 
 + } 
 + 
 + public UnfilteredPartitionIterator executeLocally ( ReadExecutionController executionController ) 
 + { 
 + return executeLocally ( executionController , true ) ; 
 + } 
 + 
 + / * * 
 + * Implementation of { @ link ReadQuery # executeLocally ( ReadExecutionController ) } . 
 + * 
 + * @ param executionController - the { @ code ReadExecutionController } protecting the read . 
 + * @ param sort - whether to sort the inner commands by partition key , required for merging the iterator 
 + * later on . This will be false when called by { @ link ReadQuery # executeInternal ( ReadExecutionController ) } 
 + * because in this case it is safe to do so as there is no merging involved and we don ' t want to 
 + * change the old behavior which was to not sort by partition . 
 + * 
 + * @ return - the iterator that can be used to retrieve the query result . 
 + * / 
 + private UnfilteredPartitionIterator executeLocally ( ReadExecutionController executionController , boolean sort ) 
 + { 
 + List < Pair < DecoratedKey , UnfilteredPartitionIterator > > partitions = new ArrayList < > ( commands . size ( ) ) ; 
 for ( SinglePartitionReadCommand cmd : commands ) 
 - partitions . add ( cmd . executeInternal ( controller ) ) ; 
 + partitions . add ( Pair . of ( cmd . partitionKey , cmd . executeLocally ( executionController ) ) ) ; 
 + 
 + if ( sort ) 
 + Collections . sort ( partitions , ( p1 , p2 ) - > p1 . getLeft ( ) . compareTo ( p2 . getLeft ( ) ) ) ; 
 
 - / / Because we only have enforce the limit per command , we need to enforce it globally . 
 - return limits . filter ( PartitionIterators . concat ( partitions ) , nowInSec ) ; 
 + return UnfilteredPartitionIterators . concat ( partitions . stream ( ) . map ( p - > p . getRight ( ) ) . collect ( Collectors . toList ( ) ) ) ; 
 } 
 
 public QueryPager getPager ( PagingState pagingState , int protocolVersion ) 
 diff - - git a / src / java / org / apache / cassandra / db / partitions / UnfilteredPartitionIterators . java b / src / java / org / apache / cassandra / db / partitions / UnfilteredPartitionIterators . java 
 index b7f6793 . . 852d95e 100644 
 - - - a / src / java / org / apache / cassandra / db / partitions / UnfilteredPartitionIterators . java 
 + + + b / src / java / org / apache / cassandra / db / partitions / UnfilteredPartitionIterators . java 
 @ @ - 27 , 6 + 27 , 7 @ @ import org . apache . cassandra . db . * ; 
 import org . apache . cassandra . db . filter . ColumnFilter ; 
 import org . apache . cassandra . db . rows . * ; 
 import org . apache . cassandra . db . transform . FilteredPartitions ; 
 + import org . apache . cassandra . db . transform . MorePartitions ; 
 import org . apache . cassandra . db . transform . Transformation ; 
 import org . apache . cassandra . io . util . DataInputPlus ; 
 import org . apache . cassandra . io . util . DataOutputPlus ; 
 @ @ - 77 , 6 + 78 , 25 @ @ public abstract class UnfilteredPartitionIterators 
 return Transformation . apply ( toReturn , new Close ( ) ) ; 
 } 
 
 + public static UnfilteredPartitionIterator concat ( final List < UnfilteredPartitionIterator > iterators ) 
 + { 
 + if ( iterators . size ( ) = = 1 ) 
 + return iterators . get ( 0 ) ; 
 + 
 + class Extend implements MorePartitions < UnfilteredPartitionIterator > 
 + { 
 + int i = 1 ; 
 + public UnfilteredPartitionIterator moreContents ( ) 
 + { 
 + if ( i > = iterators . size ( ) ) 
 + return null ; 
 + return iterators . get ( i + + ) ; 
 + } 
 + } 
 + return MorePartitions . extend ( iterators . get ( 0 ) , new Extend ( ) ) ; 
 + } 
 + 
 + 
 public static PartitionIterator mergeAndFilter ( List < UnfilteredPartitionIterator > iterators , int nowInSec , MergeListener listener ) 
 { 
 / / TODO : we could have a somewhat faster version if we were to merge the UnfilteredRowIterators directly as RowIterators 
 diff - - git a / test / unit / org / apache / cassandra / db / ReadCommandTest . java b / test / unit / org / apache / cassandra / db / ReadCommandTest . java 
 index fddd347 . . 2aef2a7 100644 
 - - - a / test / unit / org / apache / cassandra / db / ReadCommandTest . java 
 + + + b / test / unit / org / apache / cassandra / db / ReadCommandTest . java 
 @ @ - 18 , 6 + 18 , 8 @ @ 
 
 package org . apache . cassandra . db ; 
 
 + import java . nio . ByteBuffer ; 
 + import java . util . ArrayList ; 
 import java . util . List ; 
 
 import org . junit . BeforeClass ; 
 @ @ - 27 , 12 + 29 , 28 @ @ import org . apache . cassandra . SchemaLoader ; 
 import org . apache . cassandra . Util ; 
 import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 + import org . apache . cassandra . db . filter . ClusteringIndexSliceFilter ; 
 + import org . apache . cassandra . db . filter . ColumnFilter ; 
 + import org . apache . cassandra . db . filter . DataLimits ; 
 + import org . apache . cassandra . db . filter . RowFilter ; 
 import org . apache . cassandra . db . marshal . AsciiType ; 
 import org . apache . cassandra . db . marshal . BytesType ; 
 import org . apache . cassandra . db . partitions . FilteredPartition ; 
 + import org . apache . cassandra . db . partitions . PartitionIterator ; 
 + import org . apache . cassandra . db . partitions . UnfilteredPartitionIterator ; 
 + import org . apache . cassandra . db . partitions . UnfilteredPartitionIterators ; 
 + import org . apache . cassandra . db . rows . Row ; 
 + import org . apache . cassandra . db . rows . RowIterator ; 
 + import org . apache . cassandra . db . rows . SerializationHelper ; 
 + import org . apache . cassandra . db . rows . UnfilteredRowIterator ; 
 + import org . apache . cassandra . db . rows . UnfilteredRowIterators ; 
 import org . apache . cassandra . exceptions . ConfigurationException ; 
 + import org . apache . cassandra . io . util . DataInputBuffer ; 
 + import org . apache . cassandra . io . util . DataOutputBuffer ; 
 + import org . apache . cassandra . net . MessagingService ; 
 import org . apache . cassandra . schema . KeyspaceParams ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 + import org . apache . cassandra . utils . FBUtilities ; 
 
 import static org . junit . Assert . assertEquals ; 
 
 @ @ - 41 , 6 + 59 , 7 @ @ public class ReadCommandTest 
 private static final String KEYSPACE = " ReadCommandTest " ; 
 private static final String CF1 = " Standard1 " ; 
 private static final String CF2 = " Standard2 " ; 
 + private static final String CF3 = " Standard3 " ; 
 
 @ BeforeClass 
 public static void defineSchema ( ) throws ConfigurationException 
 @ @ - 55 , 11 + 74 , 22 @ @ public class ReadCommandTest 
 . addRegularColumn ( " a " , AsciiType . instance ) 
 . addRegularColumn ( " b " , AsciiType . instance ) . build ( ) ; 
 
 + CFMetaData metadata3 = CFMetaData . Builder . create ( KEYSPACE , CF3 ) 
 + . addPartitionKey ( " key " , BytesType . instance ) 
 + . addClusteringColumn ( " col " , AsciiType . instance ) 
 + . addRegularColumn ( " a " , AsciiType . instance ) 
 + . addRegularColumn ( " b " , AsciiType . instance ) 
 + . addRegularColumn ( " c " , AsciiType . instance ) 
 + . addRegularColumn ( " d " , AsciiType . instance ) 
 + . addRegularColumn ( " e " , AsciiType . instance ) 
 + . addRegularColumn ( " f " , AsciiType . instance ) . build ( ) ; 
 + 
 SchemaLoader . prepareServer ( ) ; 
 SchemaLoader . createKeyspace ( KEYSPACE , 
 KeyspaceParams . simple ( 1 ) , 
 metadata1 , 
 - metadata2 ) ; 
 + metadata2 , 
 + metadata3 ) ; 
 } 
 
 @ Test 
 @ @ - 149 , 4 + 179 , 133 @ @ public class ReadCommandTest 
 readCommand . abort ( ) ; 
 assertEquals ( 0 , Util . getAll ( readCommand ) . size ( ) ) ; 
 } 
 + 
 + @ Test 
 + public void testSinglePartitionGroupMerge ( ) throws Exception 
 + { 
 + ColumnFamilyStore cfs = Keyspace . open ( KEYSPACE ) . getColumnFamilyStore ( CF3 ) ; 
 + 
 + String [ ] [ ] [ ] groups = new String [ ] [ ] [ ] { 
 + new String [ ] [ ] { 
 + new String [ ] { " 1 " , " key1 " , " aa " , " a " } , / / " 1 " indicates to create the data , " - 1 " to delete the row 
 + new String [ ] { " 1 " , " key2 " , " bb " , " b " } , 
 + new String [ ] { " 1 " , " key3 " , " cc " , " c " } 
 + } , 
 + new String [ ] [ ] { 
 + new String [ ] { " 1 " , " key3 " , " dd " , " d " } , 
 + new String [ ] { " 1 " , " key2 " , " ee " , " e " } , 
 + new String [ ] { " 1 " , " key1 " , " ff " , " f " } 
 + } , 
 + new String [ ] [ ] { 
 + new String [ ] { " 1 " , " key6 " , " aa " , " a " } , 
 + new String [ ] { " 1 " , " key5 " , " bb " , " b " } , 
 + new String [ ] { " 1 " , " key4 " , " cc " , " c " } 
 + } , 
 + new String [ ] [ ] { 
 + new String [ ] { " - 1 " , " key6 " , " aa " , " a " } , 
 + new String [ ] { " - 1 " , " key2 " , " bb " , " b " } 
 + } 
 + } ; 
 + 
 + / / Given the data above , when the keys are sorted and the deletions removed , we should 
 + / / get these clustering rows in this order 
 + String [ ] expectedRows = new String [ ] { " aa " , " ff " , " ee " , " cc " , " dd " , " cc " , " bb " } ; 
 + 
 + List < ByteBuffer > buffers = new ArrayList < > ( groups . length ) ; 
 + int nowInSeconds = FBUtilities . nowInSeconds ( ) ; 
 + ColumnFilter columnFilter = ColumnFilter . allColumnsBuilder ( cfs . metadata ) . build ( ) ; 
 + RowFilter rowFilter = RowFilter . create ( ) ; 
 + Slice slice = Slice . make ( ClusteringBound . BOTTOM , ClusteringBound . TOP ) ; 
 + ClusteringIndexSliceFilter sliceFilter = new ClusteringIndexSliceFilter ( Slices . with ( cfs . metadata . comparator , slice ) , false ) ; 
 + 
 + for ( String [ ] [ ] group : groups ) 
 + { 
 + cfs . truncateBlocking ( ) ; 
 + 
 + List < SinglePartitionReadCommand > commands = new ArrayList < > ( group . length ) ; 
 + 
 + for ( String [ ] data : group ) 
 + { 
 + if ( data [ 0 ] . equals ( " 1 " ) ) 
 + { 
 + new RowUpdateBuilder ( cfs . metadata , 0 , ByteBufferUtil . bytes ( data [ 1 ] ) ) 
 + . clustering ( data [ 2 ] ) 
 + . add ( data [ 3 ] , ByteBufferUtil . bytes ( " blah " ) ) 
 + . build ( ) 
 + . apply ( ) ; 
 + } 
 + else 
 + { 
 + RowUpdateBuilder . deleteRow ( cfs . metadata , FBUtilities . timestampMicros ( ) , ByteBufferUtil . bytes ( data [ 1 ] ) , data [ 2 ] ) . apply ( ) ; 
 + } 
 + commands . add ( SinglePartitionReadCommand . create ( cfs . metadata , nowInSeconds , columnFilter , rowFilter , DataLimits . NONE , Util . dk ( data [ 1 ] ) , sliceFilter ) ) ; 
 + } 
 + 
 + cfs . forceBlockingFlush ( ) ; 
 + 
 + ReadQuery query = new SinglePartitionReadCommand . Group ( commands , DataLimits . NONE ) ; 
 + 
 + try ( ReadExecutionController executionController = query . executionController ( ) ; 
 + UnfilteredPartitionIterator iter = query . executeLocally ( executionController ) ; 
 + DataOutputBuffer buffer = new DataOutputBuffer ( ) ) 
 + { 
 + UnfilteredPartitionIterators . serializerForIntraNode ( ) . serialize ( iter , 
 + columnFilter , 
 + buffer , 
 + MessagingService . current _ version ) ; 
 + buffers . add ( buffer . buffer ( ) ) ; 
 + } 
 + } 
 + 
 + / / deserialize , merge and check the results are all there 
 + List < UnfilteredPartitionIterator > iterators = new ArrayList < > ( ) ; 
 + 
 + for ( ByteBuffer buffer : buffers ) 
 + { 
 + try ( DataInputBuffer in = new DataInputBuffer ( buffer , true ) ) 
 + { 
 + iterators . add ( UnfilteredPartitionIterators . serializerForIntraNode ( ) . deserialize ( in , 
 + MessagingService . current _ version , 
 + cfs . metadata , 
 + columnFilter , 
 + SerializationHelper . Flag . LOCAL ) ) ; 
 + } 
 + } 
 + 
 + try ( PartitionIterator partitionIterator = UnfilteredPartitionIterators . mergeAndFilter ( iterators , 
 + nowInSeconds , 
 + new UnfilteredPartitionIterators . MergeListener ( ) 
 + { 
 + public UnfilteredRowIterators . MergeListener getRowMergeListener ( DecoratedKey partitionKey , List < UnfilteredRowIterator > versions ) 
 + { 
 + return null ; 
 + } 
 + 
 + public void close ( ) 
 + { 
 + 
 + } 
 + } ) ) 
 + { 
 + 
 + int i = 0 ; 
 + int numPartitions = 0 ; 
 + while ( partitionIterator . hasNext ( ) ) 
 + { 
 + numPartitions + + ; 
 + try ( RowIterator rowIterator = partitionIterator . next ( ) ) 
 + { 
 + while ( rowIterator . hasNext ( ) ) 
 + { 
 + Row row = rowIterator . next ( ) ; 
 + assertEquals ( " col = " + expectedRows [ i + + ] , row . clustering ( ) . toString ( cfs . metadata ) ) ; 
 + / / System . out . print ( row . toString ( cfs . metadata , true ) ) ; 
 + } 
 + } 
 + } 
 + 
 + assertEquals ( 5 , numPartitions ) ; 
 + assertEquals ( expectedRows . length , i ) ; 
 + } 
 + } 
 }

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index d518830 . . 52cc2c1 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 29 , 7 + 29 , 7 @ @ 
 * add scheduler JMX metrics ( CASSANDRA - 2962 ) 
 * add block level checksum for compressed data ( CASSANDRA - 1717 ) 
 * make column family backed column map pluggable and introduce unsynchronized 
 - ArrayList backed one to speedup reads ( CASSANDRA - 2843 ) 
 + ArrayList backed one to speedup reads ( CASSANDRA - 2843 , 3165 ) 
 * refactoring of the secondary index api ( CASSANDRA - 2982 ) 
 * make CL > ONE reads wait for digest reconciliation before returning 
 ( CASSANDRA - 2494 ) 
 diff - - git a / src / java / org / apache / cassandra / db / ArrayBackedSortedColumns . java b / src / java / org / apache / cassandra / db / ArrayBackedSortedColumns . java 
 index c316a85 . . 71c7213 100644 
 - - - a / src / java / org / apache / cassandra / db / ArrayBackedSortedColumns . java 
 + + + b / src / java / org / apache / cassandra / db / ArrayBackedSortedColumns . java 
 @ @ - 67 , 6 + 67 , 11 @ @ public class ArrayBackedSortedColumns extends ArrayList < IColumn > implements ISor 
 this . reversed = reversed ; 
 } 
 
 + public ISortedColumns . Factory getFactory ( ) 
 + { 
 + return factory ( ) ; 
 + } 
 + 
 public AbstractType < ? > getComparator ( ) 
 { 
 return comparator ; 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamily . java b / src / java / org / apache / cassandra / db / ColumnFamily . java 
 index 1239d1c . . 38bc0d7 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamily . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamily . java 
 @ @ - 81 , 14 + 81 , 19 @ @ public class ColumnFamily extends AbstractColumnContainer 
 this . cfm = cfm ; 
 } 
 
 - public ColumnFamily cloneMeShallow ( ) 
 + public ColumnFamily cloneMeShallow ( ISortedColumns . Factory factory ) 
 { 
 - ColumnFamily cf = ColumnFamily . create ( cfm ) ; 
 + ColumnFamily cf = ColumnFamily . create ( cfm , factory ) ; 
 / / since deletion info is immutable , aliasing it is fine 
 cf . deletionInfo . set ( deletionInfo . get ( ) ) ; 
 return cf ; 
 } 
 
 + public ColumnFamily cloneMeShallow ( ) 
 + { 
 + return cloneMeShallow ( columns . getFactory ( ) ) ; 
 + } 
 + 
 public AbstractType getSubComparator ( ) 
 { 
 IColumnSerializer s = getColumnSerializer ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index 0bfd1c5 . . 552d3e9 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 1162 , 8 + 1162 , 11 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 } 
 } 
 
 - / * * filter a cached row , which will not be modified by the filter , but may be modified by throwing out 
 - * tombstones that are no longer relevant . * / 
 + / * * 
 + * Filter a cached row , which will not be modified by the filter , but may be modified by throwing out 
 + * tombstones that are no longer relevant . 
 + * The returned column family won ' t be thread safe . 
 + * / 
 ColumnFamily filterColumnFamily ( ColumnFamily cached , QueryFilter filter , int gcBefore ) 
 { 
 / / special case slicing the entire row : 
 @ @ - 1184 , 7 + 1187 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 IColumn sc = cached . getColumn ( filter . path . superColumnName ) ; 
 if ( sc = = null | | sliceFilter . count > = sc . getSubColumns ( ) . size ( ) ) 
 { 
 - ColumnFamily cf = cached . cloneMeShallow ( ) ; 
 + ColumnFamily cf = cached . cloneMeShallow ( ArrayBackedSortedColumns . factory ( ) ) ; 
 if ( sc ! = null ) 
 cf . addColumn ( sc , HeapAllocator . instance ) ; 
 return removeDeleted ( cf , gcBefore ) ; 
 @ @ - 1203 , 7 + 1206 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 } 
 
 IColumnIterator ci = filter . getMemtableColumnIterator ( cached , null , getComparator ( ) ) ; 
 - ColumnFamily cf = ci . getColumnFamily ( ) . cloneMeShallow ( ) ; 
 + ColumnFamily cf = ci . getColumnFamily ( ) . cloneMeShallow ( ArrayBackedSortedColumns . factory ( ) ) ; 
 filter . collateColumns ( cf , Collections . singletonList ( ci ) , getComparator ( ) , gcBefore ) ; 
 / / TODO this is necessary because when we collate supercolumns together , we don ' t check 
 / / their subcolumns for relevance , so we need to do a second prune post facto here . 
 diff - - git a / src / java / org / apache / cassandra / db / ISortedColumns . java b / src / java / org / apache / cassandra / db / ISortedColumns . java 
 index 37f5a60 . . 624dec7 100644 
 - - - a / src / java / org / apache / cassandra / db / ISortedColumns . java 
 + + + b / src / java / org / apache / cassandra / db / ISortedColumns . java 
 @ @ - 42 , 6 + 42 , 11 @ @ public interface ISortedColumns extends IIterableColumns 
 public ISortedColumns cloneMe ( ) ; 
 
 / * * 
 + * Returns the factory used for this ISortedColumns implementation . 
 + * / 
 + public Factory getFactory ( ) ; 
 + 
 + / * * 
 * Adds a column to this column map . 
 * If a column with the same name is already present in the map , it will 
 * be replaced by the newly added column . 
 diff - - git a / src / java / org / apache / cassandra / db / ThreadSafeSortedColumns . java b / src / java / org / apache / cassandra / db / ThreadSafeSortedColumns . java 
 index cd2488a . . 13a111a 100644 
 - - - a / src / java / org / apache / cassandra / db / ThreadSafeSortedColumns . java 
 + + + b / src / java / org / apache / cassandra / db / ThreadSafeSortedColumns . java 
 @ @ - 62 , 6 + 62 , 11 @ @ public class ThreadSafeSortedColumns extends ConcurrentSkipListMap < ByteBuffer , I 
 super ( columns ) ; 
 } 
 
 + public ISortedColumns . Factory getFactory ( ) 
 + { 
 + return factory ( ) ; 
 + } 
 + 
 public ISortedColumns cloneMe ( ) 
 { 
 return new ThreadSafeSortedColumns ( this ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / TreeMapBackedSortedColumns . java b / src / java / org / apache / cassandra / db / TreeMapBackedSortedColumns . java 
 index 34e83dc . . 6c3fc42 100644 
 - - - a / src / java / org / apache / cassandra / db / TreeMapBackedSortedColumns . java 
 + + + b / src / java / org / apache / cassandra / db / TreeMapBackedSortedColumns . java 
 @ @ - 62 , 6 + 62 , 11 @ @ public class TreeMapBackedSortedColumns extends TreeMap < ByteBuffer , IColumn > imp 
 super ( columns ) ; 
 } 
 
 + public ISortedColumns . Factory getFactory ( ) 
 + { 
 + return factory ( ) ; 
 + } 
 + 
 public ISortedColumns cloneMe ( ) 
 { 
 return new TreeMapBackedSortedColumns ( this ) ;
