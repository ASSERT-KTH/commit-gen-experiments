BLEU SCORE: 1.4688049193322928E-15

TEST MSG: Optimise Interval Tree
GENERATED MSG: Replace PriorityQueue mess with a CompactionIterator that efficiently yields compacted Rows from a set of sstables by feeding CollationIterator into a ReducingIterator transform . ( " Efficiently " means we never deserialize data until it is needed , so the number of sstables that can be compacted at once is virtually unlimited , and if only one sstable contains a given key that row data will be copied over without an intermediate de / serialize step . ) This is a very natural fit for the compaction algorithm and almost entirely gets rid of duplicated code between doFileCompaction and doAntiCompaction .

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 7df303f . . 3bbc48f 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 3 . 0 <nl> + * Optimise IntervalTree ( CASSANDRA - 8988 ) <nl> * Add a key - value payload for third party usage ( CASSANDRA - 8553 ) <nl> * Bump metrics - reporter - config dependency for metrics 3 . 0 ( CASSANDRA - 8149 ) <nl> * Partition intra - cluster message streams by size , not type ( CASSANDRA - 8789 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / DataTracker . java b / src / java / org / apache / cassandra / db / DataTracker . java <nl> index 0271cd8 . . dd1dc5a 100644 <nl> - - - a / src / java / org / apache / cassandra / db / DataTracker . java <nl> + + + b / src / java / org / apache / cassandra / db / DataTracker . java <nl> @ @ - 592 , 7 + 592 , 7 @ @ public class DataTracker <nl> <nl> private SSTableIntervalTree ( Collection < Interval < RowPosition , SSTableReader > > intervals ) <nl> { <nl> - super ( intervals , null ) ; <nl> + super ( intervals ) ; <nl> } <nl> <nl> public static SSTableIntervalTree empty ( ) <nl> diff - - git a / src / java / org / apache / cassandra / utils / AsymmetricOrdering . java b / src / java / org / apache / cassandra / utils / AsymmetricOrdering . java <nl> new file mode 100644 <nl> index 0000000 . . ed8c99f <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / utils / AsymmetricOrdering . java <nl> @ @ - 0 , 0 + 1 , 143 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , <nl> + * software distributed under the License is distributed on an <nl> + * " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY <nl> + * KIND , either express or implied . See the License for the <nl> + * specific language governing permissions and limitations <nl> + * under the License . <nl> + * / <nl> + package org . apache . cassandra . utils ; <nl> + <nl> + import java . util . List ; <nl> + <nl> + import com . google . common . collect . Ordering ; <nl> + <nl> + import net . nicoulaj . compilecommand . annotations . Inline ; <nl> + <nl> + public abstract class AsymmetricOrdering < T1 , T2 > extends Ordering < T1 > <nl> + { <nl> + <nl> + public abstract int compareAsymmetric ( T1 left , T2 right ) ; <nl> + <nl> + public static enum Op <nl> + { <nl> + / / maximum index < key ; - 1 if no such key . = = CEIL - 1 <nl> + LOWER , <nl> + <nl> + / / maximum index < = key ; - 1 if no such key . = = HIGHER + 1 <nl> + FLOOR , <nl> + <nl> + / / minimum index > = key ; size ( ) if no such key . = = LOWER + 1 <nl> + CEIL , <nl> + <nl> + / / minimum index > key ; size ( ) if no such key . = = FLOOR - 1 <nl> + HIGHER <nl> + } <nl> + <nl> + / * * <nl> + * @ param searchIn sorted list to look in <nl> + * @ param searchFor key to find <nl> + * / <nl> + public int binarySearchAsymmetric ( List < ? extends T1 > searchIn , T2 searchFor , Op op ) <nl> + { <nl> + final int strictnessOfLessThan = strictnessOfLessThan ( op ) ; <nl> + int lb = - 1 ; <nl> + int ub = searchIn . size ( ) ; <nl> + / / a [ - 1 ] ^ = - infinity <nl> + / / a [ search . size ( ) ] ^ = + infinity <nl> + <nl> + while ( lb + 1 < ub ) <nl> + { <nl> + int m = ( lb + ub ) / 2 ; <nl> + int c = compareAsymmetric ( searchIn . get ( m ) , searchFor ) ; <nl> + <nl> + if ( c < strictnessOfLessThan ) lb = m ; <nl> + else ub = m ; <nl> + } <nl> + <nl> + return selectBoundary ( op , lb , ub ) ; <nl> + } <nl> + <nl> + @ Inline <nl> + / / this value , used as the right operand to a less than operator for the result <nl> + / / of a compare ( ) makes its behaviour either strict ( < ) or not strict ( < = ) . <nl> + / / a value of 1 is not strict , whereas 0 is strict <nl> + private static int strictnessOfLessThan ( Op op ) <nl> + { <nl> + switch ( op ) <nl> + { <nl> + case FLOOR : case HIGHER : <nl> + <nl> + / / { a [ lb ] < = v ^ a [ ub ] > v } <nl> + return 1 ; <nl> + <nl> + / / { a [ m ] > v = = > a [ ub ] > v = = > a [ lb ] < = v ^ a [ ub ] > v } <nl> + / / { a [ m ] < = v = = > a [ lb ] < = v = = > a [ lb ] < = v ^ a [ ub ] > v } <nl> + <nl> + case CEIL : case LOWER : <nl> + <nl> + / / { a [ lb ] < v ^ a [ ub ] > = v } <nl> + <nl> + return 0 ; <nl> + <nl> + / / { a [ m ] > = v = = > a [ ub ] > = v = = > a [ lb ] < v ^ a [ ub ] > = v } <nl> + / / { a [ m ] < v = = > a [ lb ] < v = = > a [ lb ] < v ^ a [ ub ] > = v } <nl> + } <nl> + <nl> + throw new IllegalStateException ( ) ; <nl> + } <nl> + <nl> + @ Inline <nl> + private static int selectBoundary ( Op op , int lb , int ub ) <nl> + { <nl> + switch ( op ) <nl> + { <nl> + case CEIL : <nl> + / / { a [ lb ] < v ^ a [ ub ] > = v } <nl> + case HIGHER : <nl> + / / { a [ lb ] < = v ^ a [ ub ] > v } <nl> + return ub ; <nl> + case FLOOR : <nl> + / / { a [ lb ] < = v ^ a [ ub ] > v } <nl> + case LOWER : <nl> + / / { a [ lb ] < v ^ a [ ub ] > = v } <nl> + return lb ; <nl> + } <nl> + throw new IllegalStateException ( ) ; <nl> + } <nl> + <nl> + <nl> + <nl> + private class Reversed extends AsymmetricOrdering < T1 , T2 > <nl> + { <nl> + public int compareAsymmetric ( T1 left , T2 right ) <nl> + { <nl> + return - AsymmetricOrdering . this . compareAsymmetric ( left , right ) ; <nl> + } <nl> + <nl> + public int compare ( T1 left , T1 right ) <nl> + { <nl> + return AsymmetricOrdering . this . compare ( right , left ) ; <nl> + } <nl> + <nl> + public AsymmetricOrdering < T1 , T2 > reverse ( ) <nl> + { <nl> + return AsymmetricOrdering . this ; <nl> + } <nl> + } <nl> + <nl> + public AsymmetricOrdering < T1 , T2 > reverse ( ) <nl> + { <nl> + return new Reversed ( ) ; <nl> + } <nl> + } <nl> diff - - git a / src / java / org / apache / cassandra / utils / Interval . java b / src / java / org / apache / cassandra / utils / Interval . java <nl> index c74f153 . . 9398144 100644 <nl> - - - a / src / java / org / apache / cassandra / utils / Interval . java <nl> + + + b / src / java / org / apache / cassandra / utils / Interval . java <nl> @ @ - 64 , 4 + 64 , 44 @ @ public class Interval < C , D > <nl> / / handles nulls properly <nl> return Objects . equal ( min , that . min ) & & Objects . equal ( max , that . max ) & & Objects . equal ( data , that . data ) ; <nl> } <nl> + <nl> + private static final AsymmetricOrdering < Interval < Comparable , Object > , Comparable > minOrdering <nl> + = new AsymmetricOrdering < Interval < Comparable , Object > , Comparable > ( ) <nl> + { <nl> + public int compareAsymmetric ( Interval < Comparable , Object > left , Comparable right ) <nl> + { <nl> + return left . min . compareTo ( right ) ; <nl> + } <nl> + <nl> + public int compare ( Interval < Comparable , Object > i1 , Interval < Comparable , Object > i2 ) <nl> + { <nl> + return i1 . min . compareTo ( i2 . min ) ; <nl> + } <nl> + } ; <nl> + <nl> + private static final AsymmetricOrdering < Interval < Comparable , Object > , Comparable > maxOrdering <nl> + = new AsymmetricOrdering < Interval < Comparable , Object > , Comparable > ( ) <nl> + { <nl> + public int compareAsymmetric ( Interval < Comparable , Object > left , Comparable right ) <nl> + { <nl> + return left . max . compareTo ( right ) ; <nl> + } <nl> + <nl> + public int compare ( Interval < Comparable , Object > i1 , Interval < Comparable , Object > i2 ) <nl> + { <nl> + return i1 . max . compareTo ( i2 . max ) ; <nl> + } <nl> + } ; <nl> + <nl> + private static final AsymmetricOrdering < Interval < Comparable , Object > , Comparable > reverseMaxOrdering = maxOrdering . reverse ( ) ; <nl> + <nl> + public static < C extends Comparable < ? super C > , V > AsymmetricOrdering < Interval < C , V > , C > minOrdering ( ) <nl> + { <nl> + return ( AsymmetricOrdering ) minOrdering ; <nl> + } <nl> + <nl> + public static < C extends Comparable < ? super C > , V > AsymmetricOrdering < Interval < C , V > , C > maxOrdering ( ) <nl> + { <nl> + return ( AsymmetricOrdering ) maxOrdering ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / utils / IntervalTree . java b / src / java / org / apache / cassandra / utils / IntervalTree . java <nl> index 3755c54 . . 0c3c611 100644 <nl> - - - a / src / java / org / apache / cassandra / utils / IntervalTree . java <nl> + + + b / src / java / org / apache / cassandra / utils / IntervalTree . java <nl> @ @ - 26 , 7 + 26 , 6 @ @ import java . util . * ; <nl> import com . google . common . base . Joiner ; <nl> import com . google . common . collect . AbstractIterator ; <nl> import com . google . common . collect . Iterators ; <nl> - import com . google . common . collect . Ordering ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 34 , 77 + 33 , 52 @ @ import org . apache . cassandra . db . TypeSizes ; <nl> import org . apache . cassandra . io . ISerializer ; <nl> import org . apache . cassandra . io . IVersionedSerializer ; <nl> import org . apache . cassandra . io . util . DataOutputPlus ; <nl> + import org . apache . cassandra . utils . AsymmetricOrdering . Op ; <nl> <nl> - public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > <nl> + public class IntervalTree < C extends Comparable < ? super C > , D , I extends Interval < C , D > > implements Iterable < I > <nl> { <nl> private static final Logger logger = LoggerFactory . getLogger ( IntervalTree . class ) ; <nl> <nl> @ SuppressWarnings ( " unchecked " ) <nl> - private static final IntervalTree EMPTY _ TREE = new IntervalTree ( null , null ) ; <nl> + private static final IntervalTree EMPTY _ TREE = new IntervalTree ( null ) ; <nl> <nl> private final IntervalNode head ; <nl> private final int count ; <nl> - private final Comparator < C > comparator ; <nl> <nl> - final Ordering < I > minOrdering ; <nl> - final Ordering < I > maxOrdering ; <nl> - <nl> - protected IntervalTree ( Collection < I > intervals , Comparator < C > comparator ) <nl> + protected IntervalTree ( Collection < I > intervals ) <nl> { <nl> - this . comparator = comparator ; <nl> - <nl> final IntervalTree it = this ; <nl> - this . minOrdering = new Ordering < I > ( ) <nl> - { <nl> - public int compare ( I interval1 , I interval2 ) <nl> - { <nl> - return it . comparePoints ( interval1 . min , interval2 . min ) ; <nl> - } <nl> - } ; <nl> - this . maxOrdering = new Ordering < I > ( ) <nl> - { <nl> - public int compare ( I interval1 , I interval2 ) <nl> - { <nl> - return it . comparePoints ( interval1 . max , interval2 . max ) ; <nl> - } <nl> - } ; <nl> - <nl> this . head = intervals = = null | | intervals . isEmpty ( ) ? null : new IntervalNode ( intervals ) ; <nl> this . count = intervals = = null ? 0 : intervals . size ( ) ; <nl> } <nl> <nl> - public static < C , D , I extends Interval < C , D > > IntervalTree < C , D , I > build ( Collection < I > intervals , Comparator < C > comparator ) <nl> + public static < C extends Comparable < ? super C > , D , I extends Interval < C , D > > IntervalTree < C , D , I > build ( Collection < I > intervals , Comparator < C > comparator ) <nl> { <nl> if ( intervals = = null | | intervals . isEmpty ( ) ) <nl> return emptyTree ( ) ; <nl> <nl> - return new IntervalTree < C , D , I > ( intervals , comparator ) ; <nl> + return new IntervalTree < C , D , I > ( intervals ) ; <nl> } <nl> <nl> - public static < C extends Comparable < C > , D , I extends Interval < C , D > > IntervalTree < C , D , I > build ( Collection < I > intervals ) <nl> + public static < C extends Comparable < ? super C > , D , I extends Interval < C , D > > IntervalTree < C , D , I > build ( Collection < I > intervals ) <nl> { <nl> if ( intervals = = null | | intervals . isEmpty ( ) ) <nl> return emptyTree ( ) ; <nl> <nl> - return new IntervalTree < C , D , I > ( intervals , null ) ; <nl> + return new IntervalTree < C , D , I > ( intervals ) ; <nl> } <nl> <nl> - public static < C , D , I extends Interval < C , D > > Serializer < C , D , I > serializer ( ISerializer < C > pointSerializer , ISerializer < D > dataSerializer , Constructor < I > constructor ) <nl> + public static < C extends Comparable < ? super C > , D , I extends Interval < C , D > > Serializer < C , D , I > serializer ( ISerializer < C > pointSerializer , ISerializer < D > dataSerializer , Constructor < I > constructor ) <nl> { <nl> return new Serializer < > ( pointSerializer , dataSerializer , constructor ) ; <nl> } <nl> <nl> @ SuppressWarnings ( " unchecked " ) <nl> - public static < C , D , I extends Interval < C , D > > IntervalTree < C , D , I > emptyTree ( ) <nl> + public static < C extends Comparable < ? super C > , D , I extends Interval < C , D > > IntervalTree < C , D , I > emptyTree ( ) <nl> { <nl> return ( IntervalTree < C , D , I > ) EMPTY _ TREE ; <nl> } <nl> <nl> - public Comparator < C > comparator ( ) <nl> - { <nl> - return comparator ; <nl> - } <nl> - <nl> public int intervalCount ( ) <nl> { <nl> return count ; <nl> @ @ - 172 , 43 + 146 , 12 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > <nl> @ Override <nl> public final int hashCode ( ) <nl> { <nl> - int result = comparator . hashCode ( ) ; <nl> + int result = 0 ; <nl> for ( Interval < C , D > interval : this ) <nl> result = 31 * result + interval . hashCode ( ) ; <nl> return result ; <nl> } <nl> <nl> - private int comparePoints ( C point1 , C point2 ) <nl> - { <nl> - if ( comparator ! = null ) <nl> - { <nl> - return comparator . compare ( point1 , point2 ) ; <nl> - } <nl> - else <nl> - { <nl> - assert point1 instanceof Comparable ; <nl> - assert point2 instanceof Comparable ; <nl> - return ( ( Comparable < C > ) point1 ) . compareTo ( point2 ) ; <nl> - } <nl> - } <nl> - <nl> - private boolean encloses ( Interval < C , D > enclosing , Interval < C , D > enclosed ) <nl> - { <nl> - return comparePoints ( enclosing . min , enclosed . min ) < = 0 <nl> - & & comparePoints ( enclosing . max , enclosed . max ) > = 0 ; <nl> - } <nl> - <nl> - private boolean contains ( Interval < C , D > interval , C point ) <nl> - { <nl> - return comparePoints ( interval . min , point ) < = 0 <nl> - & & comparePoints ( interval . max , point ) > = 0 ; <nl> - } <nl> - <nl> - private boolean intersects ( Interval < C , D > interval1 , Interval < C , D > interval2 ) <nl> - { <nl> - return contains ( interval1 , interval2 . min ) | | contains ( interval1 , interval2 . max ) ; <nl> - } <nl> - <nl> private class IntervalNode <nl> { <nl> final C center ; <nl> @ @ - 246 , 15 + 189 , 11 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > <nl> List < C > allEndpoints = new ArrayList < C > ( toBisect . size ( ) * 2 ) ; <nl> for ( I interval : toBisect ) <nl> { <nl> - assert ( comparator = = null ? ( ( Comparable ) interval . min ) . compareTo ( interval . max ) <nl> - : comparator . compare ( interval . min , interval . max ) ) < = 0 : " Interval min > max " ; <nl> allEndpoints . add ( interval . min ) ; <nl> allEndpoints . add ( interval . max ) ; <nl> } <nl> - if ( comparator ! = null ) <nl> - Collections . sort ( allEndpoints , comparator ) ; <nl> - else <nl> - Collections . sort ( ( List < Comparable > ) allEndpoints ) ; <nl> + <nl> + Collections . sort ( allEndpoints ) ; <nl> <nl> low = allEndpoints . get ( 0 ) ; <nl> center = allEndpoints . get ( toBisect . size ( ) ) ; <nl> @ @ - 267 , 16 + 206 , 16 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > <nl> <nl> for ( I candidate : toBisect ) <nl> { <nl> - if ( comparePoints ( candidate . max , center ) < 0 ) <nl> + if ( candidate . max . compareTo ( center ) < 0 ) <nl> leftSegment . add ( candidate ) ; <nl> - else if ( comparePoints ( candidate . min , center ) > 0 ) <nl> + else if ( candidate . min . compareTo ( center ) > 0 ) <nl> rightSegment . add ( candidate ) ; <nl> else <nl> intersects . add ( candidate ) ; <nl> } <nl> <nl> - intersectsLeft = minOrdering . sortedCopy ( intersects ) ; <nl> - intersectsRight = maxOrdering . reverse ( ) . sortedCopy ( intersects ) ; <nl> + intersectsLeft = Interval . < C , D > minOrdering ( ) . sortedCopy ( intersects ) ; <nl> + intersectsRight = Interval . < C , D > maxOrdering ( ) . sortedCopy ( intersects ) ; <nl> left = leftSegment . isEmpty ( ) ? null : new IntervalNode ( leftSegment ) ; <nl> right = rightSegment . isEmpty ( ) ? null : new IntervalNode ( rightSegment ) ; <nl> <nl> @ @ - 290 , 49 + 229 , 41 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > <nl> <nl> void searchInternal ( Interval < C , D > searchInterval , List < D > results ) <nl> { <nl> - if ( comparePoints ( searchInterval . max , low ) < 0 | | comparePoints ( searchInterval . min , high ) > 0 ) <nl> - return ; <nl> - <nl> - if ( contains ( searchInterval , center ) ) <nl> + if ( center . compareTo ( searchInterval . min ) < 0 ) <nl> { <nl> - / / Adds every interval contained in this node to the result set then search left and right for further <nl> - / / overlapping intervals <nl> - for ( Interval < C , D > interval : intersectsLeft ) <nl> - results . add ( interval . data ) ; <nl> + int i = Interval . < C , D > maxOrdering ( ) . binarySearchAsymmetric ( intersectsRight , searchInterval . min , Op . CEIL ) ; <nl> + if ( i = = intersectsRight . size ( ) & & high . compareTo ( searchInterval . min ) < 0 ) <nl> + return ; <nl> + <nl> + while ( i < intersectsRight . size ( ) ) <nl> + results . add ( intersectsRight . get ( i + + ) . data ) ; <nl> <nl> - if ( left ! = null ) <nl> - left . searchInternal ( searchInterval , results ) ; <nl> if ( right ! = null ) <nl> right . searchInternal ( searchInterval , results ) ; <nl> } <nl> - else if ( comparePoints ( center , searchInterval . min ) < 0 ) <nl> + else if ( center . compareTo ( searchInterval . max ) > 0 ) <nl> { <nl> - / / Adds intervals i in intersects right as long as i . max > = searchInterval . min <nl> - / / then search right <nl> - for ( Interval < C , D > interval : intersectsRight ) <nl> - { <nl> - if ( comparePoints ( interval . max , searchInterval . min ) > = 0 ) <nl> - results . add ( interval . data ) ; <nl> - else <nl> - break ; <nl> - } <nl> - if ( right ! = null ) <nl> - right . searchInternal ( searchInterval , results ) ; <nl> + int j = Interval . < C , D > minOrdering ( ) . binarySearchAsymmetric ( intersectsLeft , searchInterval . max , Op . HIGHER ) ; <nl> + if ( j = = 0 & & low . compareTo ( searchInterval . max ) > 0 ) <nl> + return ; <nl> + <nl> + for ( int i = 0 ; i < j ; i + + ) <nl> + results . add ( intersectsLeft . get ( i ) . data ) ; <nl> + <nl> + if ( left ! = null ) <nl> + left . searchInternal ( searchInterval , results ) ; <nl> } <nl> else <nl> { <nl> - assert comparePoints ( center , searchInterval . max ) > 0 ; <nl> - / / Adds intervals i in intersects left as long as i . min > = searchInterval . max <nl> - / / then search left <nl> + / / Adds every interval contained in this node to the result set then search left and right for further <nl> + / / overlapping intervals <nl> for ( Interval < C , D > interval : intersectsLeft ) <nl> - { <nl> - if ( comparePoints ( interval . min , searchInterval . max ) < = 0 ) <nl> - results . add ( interval . data ) ; <nl> - else <nl> - break ; <nl> - } <nl> + results . add ( interval . data ) ; <nl> + <nl> if ( left ! = null ) <nl> left . searchInternal ( searchInterval , results ) ; <nl> + if ( right ! = null ) <nl> + right . searchInternal ( searchInterval , results ) ; <nl> } <nl> } <nl> } <nl> @ @ - 377 , 7 + 308 , 7 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > <nl> } <nl> } <nl> <nl> - public static class Serializer < C , D , I extends Interval < C , D > > implements IVersionedSerializer < IntervalTree < C , D , I > > <nl> + public static class Serializer < C extends Comparable < ? super C > , D , I extends Interval < C , D > > implements IVersionedSerializer < IntervalTree < C , D , I > > <nl> { <nl> private final ISerializer < C > pointSerializer ; <nl> private final ISerializer < D > dataSerializer ; <nl> @ @ - 417 , 7 + 348 , 7 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > <nl> try <nl> { <nl> int count = in . readInt ( ) ; <nl> - List < Interval < C , D > > intervals = new ArrayList < Interval < C , D > > ( count ) ; <nl> + List < I > intervals = new ArrayList < I > ( count ) ; <nl> for ( int i = 0 ; i < count ; i + + ) <nl> { <nl> C min = pointSerializer . deserialize ( in ) ; <nl> @ @ - 425 , 7 + 356 , 7 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > <nl> D data = dataSerializer . deserialize ( in ) ; <nl> intervals . add ( constructor . newInstance ( min , max , data ) ) ; <nl> } <nl> - return new IntervalTree ( intervals , comparator ) ; <nl> + return new IntervalTree < C , D , I > ( intervals ) ; <nl> } <nl> catch ( InstantiationException e ) <nl> { <nl> diff - - git a / test / unit / org / apache / cassandra / utils / IntervalTreeTest . java b / test / unit / org / apache / cassandra / utils / IntervalTreeTest . java <nl> index ea88092 . . 8409a26 100644 <nl> - - - a / test / unit / org / apache / cassandra / utils / IntervalTreeTest . java <nl> + + + b / test / unit / org / apache / cassandra / utils / IntervalTreeTest . java <nl> @ @ - 115 , 7 + 115 , 7 @ @ public class IntervalTreeTest <nl> <nl> IntervalTree < Integer , Void , Interval < Integer , Void > > it = IntervalTree . build ( intervals ) ; <nl> <nl> - Collections . sort ( intervals , it . minOrdering ) ; <nl> + Collections . sort ( intervals , Interval . < Integer , Void > minOrdering ( ) ) ; <nl> <nl> List < Interval < Integer , Void > > l = new ArrayList < Interval < Integer , Void > > ( ) ; <nl> for ( Interval < Integer , Void > i : it )
NEAREST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / db / ColumnFamily . java b / src / java / org / apache / cassandra / db / ColumnFamily . java <nl> index c3bddd4 . . cb87833 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamily . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamily . java <nl> @ @ - 35 , 7 + 35 , 6 @ @ import org . apache . cassandra . utils . FBUtilities ; <nl> import org . apache . cassandra . io . ICompactSerializer2 ; <nl> import org . apache . cassandra . db . filter . QueryPath ; <nl> import org . apache . cassandra . db . marshal . AbstractType ; <nl> - import org . apache . cassandra . db . marshal . MarshalException ; <nl> <nl> <nl> public final class ColumnFamily implements IColumnContainer <nl> @ @ - 121 , 12 + 120 , 13 @ @ public final class ColumnFamily implements IColumnContainer <nl> * We need to go through each column <nl> * in the column family and resolve it before adding <nl> * / <nl> - void addColumns ( ColumnFamily cf ) <nl> + public void addAll ( ColumnFamily cf ) <nl> { <nl> for ( IColumn column : cf . getSortedColumns ( ) ) <nl> { <nl> addColumn ( column ) ; <nl> } <nl> + delete ( cf ) ; <nl> } <nl> <nl> public ICompactSerializer2 < IColumn > getColumnSerializer ( ) <nl> @ @ - 415 , 8 + 415 , 7 @ @ public final class ColumnFamily implements IColumnContainer <nl> for ( ColumnFamily cf2 : columnFamilies ) <nl> { <nl> assert cf . name ( ) . equals ( cf2 . name ( ) ) ; <nl> - cf . addColumns ( cf2 ) ; <nl> - cf . delete ( cf2 ) ; <nl> + cf . addAll ( cf2 ) ; <nl> } <nl> return cf ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index 001c644 . . 96bb18b 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 560 , 26 + 560 , 6 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> CompactionManager . instance ( ) . submit ( this ) ; <nl> } <nl> <nl> - private PriorityQueue < FileStruct > initializePriorityQueue ( Collection < SSTableReader > sstables , List < Range > ranges ) throws IOException <nl> - { <nl> - PriorityQueue < FileStruct > pq = new PriorityQueue < FileStruct > ( ) ; <nl> - if ( sstables . size ( ) > 1 | | ( ranges ! = null & & sstables . size ( ) > 0 ) ) <nl> - { <nl> - FileStruct fs = null ; <nl> - for ( SSTableReader sstable : sstables ) <nl> - { <nl> - fs = sstable . getFileStruct ( ) ; <nl> - fs . advance ( true ) ; <nl> - if ( fs . isExhausted ( ) ) <nl> - { <nl> - continue ; <nl> - } <nl> - pq . add ( fs ) ; <nl> - } <nl> - } <nl> - return pq ; <nl> - } <nl> - <nl> / * <nl> * Group files of similar size into buckets . <nl> * / <nl> @ @ - 766 , 150 + 746 , 67 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> * / <nl> List < SSTableReader > doFileAntiCompaction ( Collection < SSTableReader > sstables , List < Range > ranges , EndPoint target ) throws IOException <nl> { <nl> - List < SSTableReader > results = new ArrayList < SSTableReader > ( ) ; <nl> - long startTime = System . currentTimeMillis ( ) ; <nl> - long totalBytesRead = 0 ; <nl> - long totalBytesWritten = 0 ; <nl> - long totalkeysRead = 0 ; <nl> - long totalkeysWritten = 0 ; <nl> - String rangeFileLocation ; <nl> - String mergedFileName ; <nl> + logger _ . info ( " AntiCompacting [ " + StringUtils . join ( sstables , " , " ) + " ] " ) ; <nl> / / Calculate the expected compacted filesize <nl> - long expectedRangeFileSize = getExpectedCompactedFileSize ( sstables ) ; <nl> - / * in the worst case a node will be giving out half of its data so we take a chance * / <nl> - expectedRangeFileSize = expectedRangeFileSize / 2 ; <nl> - rangeFileLocation = DatabaseDescriptor . getDataFileLocationForTable ( table _ , expectedRangeFileSize ) ; <nl> - / / If the compaction file path is null that means we have no space left for this compaction . <nl> - if ( rangeFileLocation = = null ) <nl> - { <nl> - logger _ . error ( " Total bytes to be written for range compaction . . . " <nl> - + expectedRangeFileSize + " is greater than the safe limit of the disk space available . " ) ; <nl> - return results ; <nl> - } <nl> - PriorityQueue < FileStruct > pq = initializePriorityQueue ( sstables , ranges ) ; <nl> - if ( pq . isEmpty ( ) ) <nl> + long expectedRangeFileSize = getExpectedCompactedFileSize ( sstables ) / 2 ; <nl> + String compactionFileLocation = DatabaseDescriptor . getDataFileLocationForTable ( table _ , expectedRangeFileSize ) ; <nl> + if ( compactionFileLocation = = null ) <nl> { <nl> - return results ; <nl> + throw new UnsupportedOperationException ( " disk full " ) ; <nl> } <nl> + List < SSTableReader > results = new ArrayList < SSTableReader > ( ) ; <nl> <nl> - mergedFileName = getTempSSTableFileName ( ) ; <nl> - SSTableWriter rangeWriter = null ; <nl> - String lastkey = null ; <nl> - List < FileStruct > lfs = new ArrayList < FileStruct > ( ) ; <nl> - DataOutputBuffer bufOut = new DataOutputBuffer ( ) ; <nl> - int expectedBloomFilterSize = SSTableReader . getApproximateKeyCount ( sstables ) ; <nl> - expectedBloomFilterSize = ( expectedBloomFilterSize > 0 ) ? expectedBloomFilterSize : SSTableReader . indexInterval ( ) ; <nl> + long startTime = System . currentTimeMillis ( ) ; <nl> + long totalkeysWritten = 0 ; <nl> + <nl> + int expectedBloomFilterSize = Math . max ( SSTableReader . indexInterval ( ) , SSTableReader . getApproximateKeyCount ( sstables ) / 2 ) ; <nl> if ( logger _ . isDebugEnabled ( ) ) <nl> logger _ . debug ( " Expected bloom filter size : " + expectedBloomFilterSize ) ; <nl> - List < ColumnFamily > columnFamilies = new ArrayList < ColumnFamily > ( ) ; <nl> <nl> - while ( pq . size ( ) > 0 | | lfs . size ( ) > 0 ) <nl> + SSTableWriter writer = null ; <nl> + CompactionIterator ci = new CompactionIterator ( sstables ) ; <nl> + <nl> + try <nl> { <nl> - FileStruct fs = null ; <nl> - if ( pq . size ( ) > 0 ) <nl> + if ( ! ci . hasNext ( ) ) <nl> { <nl> - fs = pq . poll ( ) ; <nl> + logger _ . warn ( " Nothing to compact ( all files empty or corrupt ) . This should not happen . " ) ; <nl> + return results ; <nl> } <nl> - if ( fs ! = null <nl> - & & ( lastkey = = null | | lastkey . equals ( fs . getKey ( ) ) ) ) <nl> - { <nl> - / / The keys are the same so we need to add this to the <nl> - / / ldfs list <nl> - lastkey = fs . getKey ( ) ; <nl> - lfs . add ( fs ) ; <nl> - } <nl> - else <nl> + <nl> + while ( ci . hasNext ( ) ) <nl> { <nl> - Collections . sort ( lfs , new FileStructComparator ( ) ) ; <nl> - ColumnFamily columnFamily ; <nl> - bufOut . reset ( ) ; <nl> - if ( lfs . size ( ) > 1 ) <nl> + CompactionIterator . CompactedRow row = ci . next ( ) ; <nl> + if ( Range . isTokenInRanges ( StorageService . getPartitioner ( ) . getToken ( row . key ) , ranges ) ) <nl> { <nl> - for ( FileStruct filestruct : lfs ) <nl> - { <nl> - / / We want to add only 2 and resolve them right there in order to save on memory footprint <nl> - if ( columnFamilies . size ( ) > 1 ) <nl> - { <nl> - / / Now merge the 2 column families <nl> - merge ( columnFamilies ) ; <nl> - } <nl> - / / deserialize into column families <nl> - columnFamilies . add ( filestruct . getColumnFamily ( ) ) ; <nl> - } <nl> - / / Now after merging all crap append to the sstable <nl> - columnFamily = resolveAndRemoveDeleted ( columnFamilies ) ; <nl> - columnFamilies . clear ( ) ; <nl> - if ( columnFamily ! = null ) <nl> - { <nl> - ColumnFamily . serializer ( ) . serializeWithIndexes ( columnFamily , bufOut ) ; <nl> - } <nl> - } <nl> - else <nl> - { <nl> - / / TODO deserializing only to reserialize is dumb <nl> - FileStruct filestruct = lfs . get ( 0 ) ; <nl> - ColumnFamily . serializer ( ) . serializeWithIndexes ( filestruct . getColumnFamily ( ) , bufOut ) ; <nl> - } <nl> - if ( Range . isTokenInRanges ( StorageService . getPartitioner ( ) . getToken ( lastkey ) , ranges ) ) <nl> - { <nl> - if ( rangeWriter = = null ) <nl> + if ( writer = = null ) <nl> { <nl> if ( target ! = null ) <nl> { <nl> - rangeFileLocation = rangeFileLocation + File . separator + " bootstrap " ; <nl> + compactionFileLocation = compactionFileLocation + File . separator + " bootstrap " ; <nl> } <nl> - FileUtils . createDirectory ( rangeFileLocation ) ; <nl> - String fname = new File ( rangeFileLocation , mergedFileName ) . getAbsolutePath ( ) ; <nl> - rangeWriter = new SSTableWriter ( fname , expectedBloomFilterSize , StorageService . getPartitioner ( ) ) ; <nl> + FileUtils . createDirectory ( compactionFileLocation ) ; <nl> + String newFilename = new File ( compactionFileLocation , getTempSSTableFileName ( ) ) . getAbsolutePath ( ) ; <nl> + writer = new SSTableWriter ( newFilename , expectedBloomFilterSize , StorageService . getPartitioner ( ) ) ; <nl> } <nl> - rangeWriter . append ( lastkey , bufOut ) ; <nl> - } <nl> - totalkeysWritten + + ; <nl> - for ( FileStruct filestruct : lfs ) <nl> - { <nl> - filestruct . advance ( true ) ; <nl> - if ( filestruct . isExhausted ( ) ) <nl> - { <nl> - continue ; <nl> - } <nl> - / * keep on looping until we find a key in the range * / <nl> - while ( ! Range . isTokenInRanges ( StorageService . getPartitioner ( ) . getToken ( filestruct . getKey ( ) ) , ranges ) ) <nl> - { <nl> - filestruct . advance ( true ) ; <nl> - if ( filestruct . isExhausted ( ) ) <nl> - { <nl> - break ; <nl> - } <nl> - } <nl> - if ( ! filestruct . isExhausted ( ) ) <nl> - { <nl> - pq . add ( filestruct ) ; <nl> - } <nl> - totalkeysRead + + ; <nl> - } <nl> - lfs . clear ( ) ; <nl> - lastkey = null ; <nl> - if ( fs ! = null ) <nl> - { <nl> - / / Add back the fs since we processed the rest of <nl> - / / filestructs <nl> - pq . add ( fs ) ; <nl> + writer . append ( row . key , row . buffer ) ; <nl> + totalkeysWritten + + ; <nl> } <nl> } <nl> } <nl> - <nl> - if ( rangeWriter ! = null ) <nl> + finally <nl> { <nl> - results . add ( rangeWriter . closeAndOpenReader ( ) ) ; <nl> + ci . close ( ) ; <nl> } <nl> <nl> - if ( logger _ . isDebugEnabled ( ) ) <nl> + if ( writer ! = null ) <nl> { <nl> - logger _ . debug ( " Total time taken for range split . . . " + ( System . currentTimeMillis ( ) - startTime ) ) ; <nl> - logger _ . debug ( " Total bytes Read for range split . . . " + totalBytesRead ) ; <nl> - logger _ . debug ( " Total bytes written for range split . . . " <nl> - + totalBytesWritten + " Total keys read . . . " + totalkeysRead ) ; <nl> + results . add ( writer . closeAndOpenReader ( ) ) ; <nl> + String format = " AntiCompacted to % s . % d / % d bytes for % d keys . Time : % dms . " ; <nl> + long dTime = System . currentTimeMillis ( ) - startTime ; <nl> + logger _ . info ( String . format ( format , writer . getFilename ( ) , getTotalBytes ( sstables ) , results . get ( 0 ) . length ( ) , totalkeysWritten , dTime ) ) ; <nl> } <nl> + <nl> return results ; <nl> } <nl> <nl> @ @ - 938 , 111 + 835 , 59 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> } <nl> <nl> long startTime = System . currentTimeMillis ( ) ; <nl> - long totalBytesRead = 0 ; <nl> - long totalkeysRead = 0 ; <nl> long totalkeysWritten = 0 ; <nl> - PriorityQueue < FileStruct > pq = initializePriorityQueue ( sstables , null ) ; <nl> - <nl> - if ( pq . isEmpty ( ) ) <nl> - { <nl> - logger _ . warn ( " Nothing to compact ( all files empty or corrupt ) . This should not happen . " ) ; <nl> - / / TODO clean out bad files , if any <nl> - return 0 ; <nl> - } <nl> <nl> - int expectedBloomFilterSize = SSTableReader . getApproximateKeyCount ( sstables ) ; <nl> - if ( expectedBloomFilterSize < 0 ) <nl> - expectedBloomFilterSize = SSTableReader . indexInterval ( ) ; <nl> - String newFilename = new File ( compactionFileLocation , getTempSSTableFileName ( ) ) . getAbsolutePath ( ) ; <nl> - SSTableWriter writer = new SSTableWriter ( newFilename , expectedBloomFilterSize , StorageService . getPartitioner ( ) ) ; <nl> - SSTableReader ssTable = null ; <nl> - String lastkey = null ; <nl> - List < FileStruct > lfs = new ArrayList < FileStruct > ( ) ; <nl> - DataOutputBuffer bufOut = new DataOutputBuffer ( ) ; <nl> + int expectedBloomFilterSize = Math . max ( SSTableReader . indexInterval ( ) , SSTableReader . getApproximateKeyCount ( sstables ) ) ; <nl> if ( logger _ . isDebugEnabled ( ) ) <nl> logger _ . debug ( " Expected bloom filter size : " + expectedBloomFilterSize ) ; <nl> - List < ColumnFamily > columnFamilies = new ArrayList < ColumnFamily > ( ) ; <nl> <nl> - while ( pq . size ( ) > 0 | | lfs . size ( ) > 0 ) <nl> + SSTableWriter writer ; <nl> + CompactionIterator ci = new CompactionIterator ( sstables ) ; <nl> + <nl> + try <nl> { <nl> - FileStruct fs = null ; <nl> - if ( pq . size ( ) > 0 ) <nl> + if ( ! ci . hasNext ( ) ) <nl> { <nl> - fs = pq . poll ( ) ; <nl> + logger _ . warn ( " Nothing to compact ( all files empty or corrupt ) . This should not happen . " ) ; <nl> + return 0 ; <nl> } <nl> - if ( fs ! = null <nl> - & & ( lastkey = = null | | lastkey . equals ( fs . getKey ( ) ) ) ) <nl> - { <nl> - / / The keys are the same so we need to add this to the <nl> - / / ldfs list <nl> - lastkey = fs . getKey ( ) ; <nl> - lfs . add ( fs ) ; <nl> - } <nl> - else <nl> - { <nl> - Collections . sort ( lfs , new FileStructComparator ( ) ) ; <nl> - ColumnFamily columnFamily ; <nl> - bufOut . reset ( ) ; <nl> - if ( lfs . size ( ) > 1 ) <nl> - { <nl> - for ( FileStruct filestruct : lfs ) <nl> - { <nl> - / / We want to add only 2 and resolve them right there in order to save on memory footprint <nl> - if ( columnFamilies . size ( ) > 1 ) <nl> - { <nl> - merge ( columnFamilies ) ; <nl> - } <nl> - / / deserialize into column families <nl> - columnFamilies . add ( filestruct . getColumnFamily ( ) ) ; <nl> - } <nl> - / / Now after merging all crap append to the sstable <nl> - columnFamily = resolveAndRemoveDeleted ( columnFamilies ) ; <nl> - columnFamilies . clear ( ) ; <nl> - if ( columnFamily ! = null ) <nl> - { <nl> - ColumnFamily . serializer ( ) . serializeWithIndexes ( columnFamily , bufOut ) ; <nl> - } <nl> - } <nl> - else <nl> - { <nl> - / / TODO deserializing only to reserialize is dumb <nl> - FileStruct filestruct = lfs . get ( 0 ) ; <nl> - ColumnFamily . serializer ( ) . serializeWithIndexes ( filestruct . getColumnFamily ( ) , bufOut ) ; <nl> - } <nl> <nl> - writer . append ( lastkey , bufOut ) ; <nl> - totalkeysWritten + + ; <nl> + String newFilename = new File ( compactionFileLocation , getTempSSTableFileName ( ) ) . getAbsolutePath ( ) ; <nl> + writer = new SSTableWriter ( newFilename , expectedBloomFilterSize , StorageService . getPartitioner ( ) ) ; <nl> <nl> - for ( FileStruct filestruct : lfs ) <nl> - { <nl> - filestruct . advance ( true ) ; <nl> - if ( filestruct . isExhausted ( ) ) <nl> - { <nl> - continue ; <nl> - } <nl> - pq . add ( filestruct ) ; <nl> - totalkeysRead + + ; <nl> - } <nl> - lfs . clear ( ) ; <nl> - lastkey = null ; <nl> - if ( fs ! = null ) <nl> - { <nl> - / * Add back the fs since we processed the rest of filestructs * / <nl> - pq . add ( fs ) ; <nl> - } <nl> + while ( ci . hasNext ( ) ) <nl> + { <nl> + CompactionIterator . CompactedRow row = ci . next ( ) ; <nl> + writer . append ( row . key , row . buffer ) ; <nl> + totalkeysWritten + + ; <nl> } <nl> } <nl> - ssTable = writer . closeAndOpenReader ( ) ; <nl> + finally <nl> + { <nl> + ci . close ( ) ; <nl> + } <nl> + <nl> + SSTableReader ssTable = writer . closeAndOpenReader ( ) ; <nl> ssTables _ . add ( ssTable ) ; <nl> ssTables _ . markCompacted ( sstables ) ; <nl> CompactionManager . instance ( ) . submit ( ColumnFamilyStore . this ) ; <nl> <nl> - String format = " Compacted to % s . % d / % d bytes for % d / % d keys read / written . Time : % dms . " ; <nl> + String format = " Compacted to % s . % d / % d bytes for % d keys . Time : % dms . " ; <nl> long dTime = System . currentTimeMillis ( ) - startTime ; <nl> - logger _ . info ( String . format ( format , writer . getFilename ( ) , totalBytesRead , ssTable . length ( ) , totalkeysRead , totalkeysWritten , dTime ) ) ; <nl> + logger _ . info ( String . format ( format , writer . getFilename ( ) , getTotalBytes ( sstables ) , ssTable . length ( ) , totalkeysWritten , dTime ) ) ; <nl> return sstables . size ( ) ; <nl> } <nl> <nl> + private long getTotalBytes ( Iterable < SSTableReader > sstables ) <nl> + { <nl> + long sum = 0 ; <nl> + for ( SSTableReader sstable : sstables ) <nl> + { <nl> + sum + = sstable . length ( ) ; <nl> + } <nl> + return sum ; <nl> + } <nl> + <nl> public static List < Memtable > getUnflushedMemtables ( String cfName ) <nl> { <nl> return new ArrayList < Memtable > ( getMemtablesPendingFlushNotNull ( cfName ) ) ; <nl> @ @ - 1341 , 23 + 1186 , 24 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> / / sstables <nl> for ( SSTableReader sstable : ssTables _ ) <nl> { <nl> - final SSTableScanner fs = sstable . getScanner ( ) ; <nl> - fs . seekTo ( startWith ) ; <nl> - iterators . add ( new Iterator < String > ( ) <nl> + final SSTableScanner scanner = sstable . getScanner ( ) ; <nl> + scanner . seekTo ( startWith ) ; <nl> + Iterator < String > iter = new Iterator < String > ( ) <nl> { <nl> public boolean hasNext ( ) <nl> { <nl> - return fs . hasNext ( ) ; <nl> + return scanner . hasNext ( ) ; <nl> } <nl> public String next ( ) <nl> { <nl> - return fs . next ( ) . getKey ( ) ; <nl> + return scanner . next ( ) . getKey ( ) ; <nl> } <nl> public void remove ( ) <nl> { <nl> throw new UnsupportedOperationException ( ) ; <nl> } <nl> - } ) ; <nl> + } ; <nl> + iterators . add ( iter ) ; <nl> } <nl> <nl> Iterator < String > collated = IteratorUtils . collatedIterator ( comparator , iterators ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / FileStructComparator . java b / src / java / org / apache / cassandra / db / FileStructComparator . java <nl> deleted file mode 100644 <nl> index e81a992 . . 0000000 <nl> - - - a / src / java / org / apache / cassandra / db / FileStructComparator . java <nl> + + + / dev / null <nl> @ @ - 1 , 31 + 0 , 0 @ @ <nl> - / * <nl> - * Licensed to the Apache Software Foundation ( ASF ) under one <nl> - * or more contributor license agreements . See the NOTICE file <nl> - * distributed with this work for additional information <nl> - * regarding copyright ownership . The ASF licenses this file <nl> - * to you under the Apache License , Version 2 . 0 ( the <nl> - * " License " ) ; you may not use this file except in compliance <nl> - * with the License . You may obtain a copy of the License at <nl> - * <nl> - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> - * <nl> - * Unless required by applicable law or agreed to in writing , <nl> - * software distributed under the License is distributed on an <nl> - * " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY <nl> - * KIND , either express or implied . See the License for the <nl> - * specific language governing permissions and limitations <nl> - * under the License . <nl> - * / <nl> - package org . apache . cassandra . db ; <nl> - <nl> - import java . util . Comparator ; <nl> - <nl> - import org . apache . cassandra . io . FileStruct ; <nl> - <nl> - class FileStructComparator implements Comparator < FileStruct > <nl> - { <nl> - public int compare ( FileStruct f , FileStruct f2 ) <nl> - { <nl> - return f . getFileName ( ) . compareTo ( f2 . getFileName ( ) ) ; <nl> - } <nl> - } <nl> \ No newline at end of file <nl> diff - - git a / src / java / org / apache / cassandra / db / Memtable . java b / src / java / org / apache / cassandra / db / Memtable . java <nl> index d88e004 . . 696ae5a 100644 <nl> - - - a / src / java / org / apache / cassandra / db / Memtable . java <nl> + + + b / src / java / org / apache / cassandra / db / Memtable . java <nl> @ @ - 153 , 7 + 153 , 7 @ @ public class Memtable implements Comparable < Memtable > <nl> { <nl> int oldSize = oldCf . size ( ) ; <nl> int oldObjectCount = oldCf . getColumnCount ( ) ; <nl> - oldCf . addColumns ( columnFamily ) ; <nl> + oldCf . addAll ( columnFamily ) ; <nl> int newSize = oldCf . size ( ) ; <nl> int newObjectCount = oldCf . getColumnCount ( ) ; <nl> resolveSize ( oldSize , newSize ) ; <nl> diff - - git a / src / java / org / apache / cassandra / io / CompactionIterator . java b / src / java / org / apache / cassandra / io / CompactionIterator . java <nl> new file mode 100644 <nl> index 0000000 . . b65e132 <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / io / CompactionIterator . java <nl> @ @ - 0 , 0 + 1 , 113 @ @ <nl> + package org . apache . cassandra . io ; <nl> + <nl> + import java . io . Closeable ; <nl> + import java . io . IOException ; <nl> + import java . util . List ; <nl> + import java . util . ArrayList ; <nl> + import java . util . Comparator ; <nl> + <nl> + import org . apache . commons . collections . iterators . CollatingIterator ; <nl> + <nl> + import org . apache . cassandra . utils . ReducingIterator ; <nl> + import org . apache . cassandra . db . ColumnFamily ; <nl> + <nl> + public class CompactionIterator extends ReducingIterator < IteratingRow , CompactionIterator . CompactedRow > implements Closeable <nl> + { <nl> + private final List < IteratingRow > rows = new ArrayList < IteratingRow > ( ) ; <nl> + <nl> + @ SuppressWarnings ( " unchecked " ) <nl> + public CompactionIterator ( Iterable < SSTableReader > sstables ) throws IOException <nl> + { <nl> + super ( getCollatingIterator ( sstables ) ) ; <nl> + } <nl> + <nl> + @ SuppressWarnings ( " unchecked " ) <nl> + private static CollatingIterator getCollatingIterator ( Iterable < SSTableReader > sstables ) throws IOException <nl> + { <nl> + / / CollatingIterator has a bug that causes NPE when you try to use default comparator . : ( <nl> + CollatingIterator iter = new CollatingIterator ( new Comparator ( ) <nl> + { <nl> + public int compare ( Object o1 , Object o2 ) <nl> + { <nl> + return ( ( Comparable ) o1 ) . compareTo ( o2 ) ; <nl> + } <nl> + } ) ; <nl> + for ( SSTableReader sstable : sstables ) <nl> + { <nl> + iter . addIterator ( sstable . getScanner ( ) ) ; <nl> + } <nl> + return iter ; <nl> + } <nl> + <nl> + @ Override <nl> + protected boolean isEqual ( IteratingRow o1 , IteratingRow o2 ) <nl> + { <nl> + return o1 . getKey ( ) . equals ( o2 . getKey ( ) ) ; <nl> + } <nl> + <nl> + public void reduce ( IteratingRow current ) <nl> + { <nl> + rows . add ( current ) ; <nl> + } <nl> + <nl> + protected CompactedRow getReduced ( ) <nl> + { <nl> + try <nl> + { <nl> + return getReducedRaw ( ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> + } <nl> + <nl> + protected CompactedRow getReducedRaw ( ) throws IOException <nl> + { <nl> + DataOutputBuffer buffer = new DataOutputBuffer ( ) ; <nl> + String key = rows . get ( 0 ) . getKey ( ) ; <nl> + if ( rows . size ( ) > 1 ) <nl> + { <nl> + ColumnFamily cf = null ; <nl> + for ( IteratingRow row : rows ) <nl> + { <nl> + if ( cf = = null ) <nl> + { <nl> + cf = row . getColumnFamily ( ) ; <nl> + } <nl> + else <nl> + { <nl> + cf . addAll ( row . getColumnFamily ( ) ) ; <nl> + } <nl> + } <nl> + ColumnFamily . serializer ( ) . serializeWithIndexes ( cf , buffer ) ; <nl> + } <nl> + else <nl> + { <nl> + assert rows . size ( ) = = 1 ; <nl> + rows . get ( 0 ) . echoData ( buffer ) ; <nl> + } <nl> + rows . clear ( ) ; <nl> + return new CompactedRow ( key , buffer ) ; <nl> + } <nl> + <nl> + public void close ( ) throws IOException <nl> + { <nl> + for ( Object o : ( ( CollatingIterator ) source ) . getIterators ( ) ) <nl> + { <nl> + ( ( SSTableScanner ) o ) . close ( ) ; <nl> + } <nl> + } <nl> + <nl> + public static class CompactedRow <nl> + { <nl> + public final String key ; <nl> + public final DataOutputBuffer buffer ; <nl> + <nl> + public CompactedRow ( String key , DataOutputBuffer buffer ) <nl> + { <nl> + this . key = key ; <nl> + this . buffer = buffer ; <nl> + } <nl> + } <nl> + } <nl> diff - - git a / src / java / org / apache / cassandra / io / FileStruct . java b / src / java / org / apache / cassandra / io / FileStruct . java <nl> deleted file mode 100644 <nl> index b561239 . . 0000000 <nl> - - - a / src / java / org / apache / cassandra / io / FileStruct . java <nl> + + + / dev / null <nl> @ @ - 1 , 195 + 0 , 0 @ @ <nl> - / * * <nl> - * Licensed to the Apache Software Foundation ( ASF ) under one <nl> - * or more contributor license agreements . See the NOTICE file <nl> - * distributed with this work for additional information <nl> - * regarding copyright ownership . The ASF licenses this file <nl> - * to you under the Apache License , Version 2 . 0 ( the <nl> - * " License " ) ; you may not use this file except in compliance <nl> - * with the License . You may obtain a copy of the License at <nl> - * <nl> - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> - * <nl> - * Unless required by applicable law or agreed to in writing , software <nl> - * distributed under the License is distributed on an " AS IS " BASIS , <nl> - * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> - * See the License for the specific language governing permissions and <nl> - * limitations under the License . <nl> - * / <nl> - <nl> - package org . apache . cassandra . io ; <nl> - <nl> - import java . io . IOException ; <nl> - import java . io . File ; <nl> - import java . util . Iterator ; <nl> - <nl> - import org . apache . cassandra . db . IColumn ; <nl> - import org . apache . cassandra . db . ColumnFamily ; <nl> - import org . apache . cassandra . config . DatabaseDescriptor ; <nl> - <nl> - import org . apache . log4j . Logger ; <nl> - import com . google . common . collect . AbstractIterator ; <nl> - <nl> - <nl> - public class FileStruct implements Comparable < FileStruct > , Iterator < String > <nl> - { <nl> - private static Logger logger = Logger . getLogger ( FileStruct . class ) ; <nl> - <nl> - private IteratingRow row ; <nl> - private boolean exhausted = false ; <nl> - private BufferedRandomAccessFile file ; <nl> - private SSTableReader sstable ; <nl> - private FileStructIterator iterator ; <nl> - <nl> - FileStruct ( SSTableReader sstable ) throws IOException <nl> - { <nl> - / / TODO this is used for both compactions and key ranges . the buffer sizes we want <nl> - / / to use for these ops are very different . here we are leaning towards the key - range <nl> - / / use case since that is more common . What we really want is to split those <nl> - / / two uses of this class up . <nl> - this . file = new BufferedRandomAccessFile ( sstable . getFilename ( ) , " r " , 256 * 1024 ) ; <nl> - this . sstable = sstable ; <nl> - } <nl> - <nl> - public String getFileName ( ) <nl> - { <nl> - return file . getPath ( ) ; <nl> - } <nl> - <nl> - public void close ( ) throws IOException <nl> - { <nl> - file . close ( ) ; <nl> - } <nl> - <nl> - public boolean isExhausted ( ) <nl> - { <nl> - return exhausted ; <nl> - } <nl> - <nl> - public String getKey ( ) <nl> - { <nl> - return row . getKey ( ) ; <nl> - } <nl> - <nl> - public ColumnFamily getColumnFamily ( ) <nl> - { <nl> - return row . getEmptyColumnFamily ( ) ; <nl> - } <nl> - <nl> - public int compareTo ( FileStruct f ) <nl> - { <nl> - return sstable . getPartitioner ( ) . getDecoratedKeyComparator ( ) . compare ( getKey ( ) , f . getKey ( ) ) ; <nl> - } <nl> - <nl> - public void seekTo ( String seekKey ) <nl> - { <nl> - try <nl> - { <nl> - long position = sstable . getNearestPosition ( seekKey ) ; <nl> - if ( position < 0 ) <nl> - { <nl> - exhausted = true ; <nl> - return ; <nl> - } <nl> - file . seek ( position ) ; <nl> - advance ( false ) ; <nl> - } <nl> - catch ( IOException e ) <nl> - { <nl> - throw new RuntimeException ( " corrupt sstable " , e ) ; <nl> - } <nl> - } <nl> - <nl> - / * <nl> - * Read the next key from the data file . <nl> - * Caller must check isExhausted after each call to see if further <nl> - * reads are valid . <nl> - * Do not mix with calls to the iterator interface ( next / hasnext ) . <nl> - * @ deprecated - - prefer the iterator interface . <nl> - * / <nl> - public void advance ( boolean materialize ) throws IOException <nl> - { <nl> - / / TODO r / m materialize option - - use iterableness ! <nl> - if ( exhausted ) <nl> - { <nl> - throw new IndexOutOfBoundsException ( ) ; <nl> - } <nl> - <nl> - if ( file . isEOF ( ) ) <nl> - { <nl> - file . close ( ) ; <nl> - exhausted = true ; <nl> - return ; <nl> - } <nl> - <nl> - row = new IteratingRow ( file , sstable ) ; <nl> - if ( materialize ) <nl> - { <nl> - while ( row . hasNext ( ) ) <nl> - { <nl> - IColumn column = row . next ( ) ; <nl> - row . getEmptyColumnFamily ( ) . addColumn ( column ) ; <nl> - } <nl> - } <nl> - else <nl> - { <nl> - row . skipRemaining ( ) ; <nl> - } <nl> - } <nl> - <nl> - public boolean hasNext ( ) <nl> - { <nl> - if ( iterator = = null ) <nl> - iterator = new FileStructIterator ( ) ; <nl> - return iterator . hasNext ( ) ; <nl> - } <nl> - <nl> - / * * do not mix with manual calls to advance ( ) . * / <nl> - public String next ( ) <nl> - { <nl> - if ( iterator = = null ) <nl> - iterator = new FileStructIterator ( ) ; <nl> - return iterator . next ( ) ; <nl> - } <nl> - <nl> - public void remove ( ) <nl> - { <nl> - throw new UnsupportedOperationException ( ) ; <nl> - } <nl> - <nl> - private class FileStructIterator extends AbstractIterator < String > <nl> - { <nl> - public FileStructIterator ( ) <nl> - { <nl> - if ( row = = null ) <nl> - { <nl> - if ( ! isExhausted ( ) ) <nl> - { <nl> - forward ( ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> - private void forward ( ) <nl> - { <nl> - try <nl> - { <nl> - advance ( false ) ; <nl> - } <nl> - catch ( IOException e ) <nl> - { <nl> - throw new RuntimeException ( e ) ; <nl> - } <nl> - } <nl> - <nl> - protected String computeNext ( ) <nl> - { <nl> - if ( isExhausted ( ) ) <nl> - { <nl> - return endOfData ( ) ; <nl> - } <nl> - String oldKey = getKey ( ) ; <nl> - forward ( ) ; <nl> - return oldKey ; <nl> - } <nl> - } <nl> - } <nl> diff - - git a / src / java / org / apache / cassandra / io / IteratingRow . java b / src / java / org / apache / cassandra / io / IteratingRow . java <nl> index 5ace95f . . 628fe50 100644 <nl> - - - a / src / java / org / apache / cassandra / io / IteratingRow . java <nl> + + + b / src / java / org / apache / cassandra / io / IteratingRow . java <nl> @ @ - 37 , 7 + 37 , 6 @ @ public class IteratingRow extends AbstractIterator < IColumn > implements Comparabl <nl> { <nl> private final String key ; <nl> private final long finishedAt ; <nl> - private final ColumnFamily emptyColumnFamily ; <nl> private final BufferedRandomAccessFile file ; <nl> private SSTableReader sstable ; <nl> private long dataStart ; <nl> @ @ - 51 , 10 + 50 , 6 @ @ public class IteratingRow extends AbstractIterator < IColumn > implements Comparabl <nl> int dataSize = file . readInt ( ) ; <nl> dataStart = file . getFilePointer ( ) ; <nl> finishedAt = dataStart + dataSize ; <nl> - / / legacy stuff to support FileStruct : <nl> - IndexHelper . skipBloomFilterAndIndex ( file ) ; <nl> - emptyColumnFamily = ColumnFamily . serializer ( ) . deserializeFromSSTableNoColumns ( sstable . makeColumnFamily ( ) , file ) ; <nl> - file . readInt ( ) ; <nl> } <nl> <nl> public String getKey ( ) <nl> @ @ - 62 , 11 + 57 , 6 @ @ public class IteratingRow extends AbstractIterator < IColumn > implements Comparabl <nl> return key ; <nl> } <nl> <nl> - public ColumnFamily getEmptyColumnFamily ( ) <nl> - { <nl> - return emptyColumnFamily ; <nl> - } <nl> - <nl> public void echoData ( DataOutput out ) throws IOException <nl> { <nl> file . seek ( dataStart ) ; <nl> diff - - git a / src / java / org / apache / cassandra / io / SSTableReader . java b / src / java / org / apache / cassandra / io / SSTableReader . java <nl> index fc94fca . . 81a71fd 100644 <nl> - - - a / src / java / org / apache / cassandra / io / SSTableReader . java <nl> + + + b / src / java / org / apache / cassandra / io / SSTableReader . java <nl> @ @ - 333 , 11 + 333 , 6 @ @ public class SSTableReader extends SSTable implements Comparable < SSTableReader > <nl> return partitioner ; <nl> } <nl> <nl> - public FileStruct getFileStruct ( ) throws IOException <nl> - { <nl> - return new FileStruct ( this ) ; <nl> - } <nl> - <nl> public SSTableScanner getScanner ( ) throws IOException <nl> { <nl> return new SSTableScanner ( this ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / ColumnFamilyTest . java b / test / unit / org / apache / cassandra / db / ColumnFamilyTest . java <nl> index 40e5889 . . 4219ff9 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / ColumnFamilyTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / ColumnFamilyTest . java <nl> @ @ - 20 , 8 + 20 , 6 @ @ package org . apache . cassandra . db ; <nl> <nl> import java . io . IOException ; <nl> import java . util . Arrays ; <nl> - import java . util . HashSet ; <nl> - import java . util . Random ; <nl> import java . util . TreeMap ; <nl> <nl> import org . junit . Test ; <nl> @ @ - 125 , 8 + 123 , 8 @ @ public class ColumnFamilyTest <nl> cf _ old . addColumn ( QueryPath . column ( " col2 " . getBytes ( ) ) , val2 , 1 ) ; <nl> cf _ old . addColumn ( QueryPath . column ( " col3 " . getBytes ( ) ) , val2 , 2 ) ; <nl> <nl> - cf _ result . addColumns ( cf _ new ) ; <nl> - cf _ result . addColumns ( cf _ old ) ; <nl> + cf _ result . addAll ( cf _ new ) ; <nl> + cf _ result . addAll ( cf _ old ) ; <nl> <nl> assert 3 = = cf _ result . getColumnCount ( ) : " Count is " + cf _ new . getColumnCount ( ) ; <nl> / / addcolumns will only add if timestamp > = old timestamp

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 7df303f . . 3bbc48f 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 3 . 0 
 + * Optimise IntervalTree ( CASSANDRA - 8988 ) 
 * Add a key - value payload for third party usage ( CASSANDRA - 8553 ) 
 * Bump metrics - reporter - config dependency for metrics 3 . 0 ( CASSANDRA - 8149 ) 
 * Partition intra - cluster message streams by size , not type ( CASSANDRA - 8789 ) 
 diff - - git a / src / java / org / apache / cassandra / db / DataTracker . java b / src / java / org / apache / cassandra / db / DataTracker . java 
 index 0271cd8 . . dd1dc5a 100644 
 - - - a / src / java / org / apache / cassandra / db / DataTracker . java 
 + + + b / src / java / org / apache / cassandra / db / DataTracker . java 
 @ @ - 592 , 7 + 592 , 7 @ @ public class DataTracker 
 
 private SSTableIntervalTree ( Collection < Interval < RowPosition , SSTableReader > > intervals ) 
 { 
 - super ( intervals , null ) ; 
 + super ( intervals ) ; 
 } 
 
 public static SSTableIntervalTree empty ( ) 
 diff - - git a / src / java / org / apache / cassandra / utils / AsymmetricOrdering . java b / src / java / org / apache / cassandra / utils / AsymmetricOrdering . java 
 new file mode 100644 
 index 0000000 . . ed8c99f 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / utils / AsymmetricOrdering . java 
 @ @ - 0 , 0 + 1 , 143 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , 
 + * software distributed under the License is distributed on an 
 + * " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY 
 + * KIND , either express or implied . See the License for the 
 + * specific language governing permissions and limitations 
 + * under the License . 
 + * / 
 + package org . apache . cassandra . utils ; 
 + 
 + import java . util . List ; 
 + 
 + import com . google . common . collect . Ordering ; 
 + 
 + import net . nicoulaj . compilecommand . annotations . Inline ; 
 + 
 + public abstract class AsymmetricOrdering < T1 , T2 > extends Ordering < T1 > 
 + { 
 + 
 + public abstract int compareAsymmetric ( T1 left , T2 right ) ; 
 + 
 + public static enum Op 
 + { 
 + / / maximum index < key ; - 1 if no such key . = = CEIL - 1 
 + LOWER , 
 + 
 + / / maximum index < = key ; - 1 if no such key . = = HIGHER + 1 
 + FLOOR , 
 + 
 + / / minimum index > = key ; size ( ) if no such key . = = LOWER + 1 
 + CEIL , 
 + 
 + / / minimum index > key ; size ( ) if no such key . = = FLOOR - 1 
 + HIGHER 
 + } 
 + 
 + / * * 
 + * @ param searchIn sorted list to look in 
 + * @ param searchFor key to find 
 + * / 
 + public int binarySearchAsymmetric ( List < ? extends T1 > searchIn , T2 searchFor , Op op ) 
 + { 
 + final int strictnessOfLessThan = strictnessOfLessThan ( op ) ; 
 + int lb = - 1 ; 
 + int ub = searchIn . size ( ) ; 
 + / / a [ - 1 ] ^ = - infinity 
 + / / a [ search . size ( ) ] ^ = + infinity 
 + 
 + while ( lb + 1 < ub ) 
 + { 
 + int m = ( lb + ub ) / 2 ; 
 + int c = compareAsymmetric ( searchIn . get ( m ) , searchFor ) ; 
 + 
 + if ( c < strictnessOfLessThan ) lb = m ; 
 + else ub = m ; 
 + } 
 + 
 + return selectBoundary ( op , lb , ub ) ; 
 + } 
 + 
 + @ Inline 
 + / / this value , used as the right operand to a less than operator for the result 
 + / / of a compare ( ) makes its behaviour either strict ( < ) or not strict ( < = ) . 
 + / / a value of 1 is not strict , whereas 0 is strict 
 + private static int strictnessOfLessThan ( Op op ) 
 + { 
 + switch ( op ) 
 + { 
 + case FLOOR : case HIGHER : 
 + 
 + / / { a [ lb ] < = v ^ a [ ub ] > v } 
 + return 1 ; 
 + 
 + / / { a [ m ] > v = = > a [ ub ] > v = = > a [ lb ] < = v ^ a [ ub ] > v } 
 + / / { a [ m ] < = v = = > a [ lb ] < = v = = > a [ lb ] < = v ^ a [ ub ] > v } 
 + 
 + case CEIL : case LOWER : 
 + 
 + / / { a [ lb ] < v ^ a [ ub ] > = v } 
 + 
 + return 0 ; 
 + 
 + / / { a [ m ] > = v = = > a [ ub ] > = v = = > a [ lb ] < v ^ a [ ub ] > = v } 
 + / / { a [ m ] < v = = > a [ lb ] < v = = > a [ lb ] < v ^ a [ ub ] > = v } 
 + } 
 + 
 + throw new IllegalStateException ( ) ; 
 + } 
 + 
 + @ Inline 
 + private static int selectBoundary ( Op op , int lb , int ub ) 
 + { 
 + switch ( op ) 
 + { 
 + case CEIL : 
 + / / { a [ lb ] < v ^ a [ ub ] > = v } 
 + case HIGHER : 
 + / / { a [ lb ] < = v ^ a [ ub ] > v } 
 + return ub ; 
 + case FLOOR : 
 + / / { a [ lb ] < = v ^ a [ ub ] > v } 
 + case LOWER : 
 + / / { a [ lb ] < v ^ a [ ub ] > = v } 
 + return lb ; 
 + } 
 + throw new IllegalStateException ( ) ; 
 + } 
 + 
 + 
 + 
 + private class Reversed extends AsymmetricOrdering < T1 , T2 > 
 + { 
 + public int compareAsymmetric ( T1 left , T2 right ) 
 + { 
 + return - AsymmetricOrdering . this . compareAsymmetric ( left , right ) ; 
 + } 
 + 
 + public int compare ( T1 left , T1 right ) 
 + { 
 + return AsymmetricOrdering . this . compare ( right , left ) ; 
 + } 
 + 
 + public AsymmetricOrdering < T1 , T2 > reverse ( ) 
 + { 
 + return AsymmetricOrdering . this ; 
 + } 
 + } 
 + 
 + public AsymmetricOrdering < T1 , T2 > reverse ( ) 
 + { 
 + return new Reversed ( ) ; 
 + } 
 + } 
 diff - - git a / src / java / org / apache / cassandra / utils / Interval . java b / src / java / org / apache / cassandra / utils / Interval . java 
 index c74f153 . . 9398144 100644 
 - - - a / src / java / org / apache / cassandra / utils / Interval . java 
 + + + b / src / java / org / apache / cassandra / utils / Interval . java 
 @ @ - 64 , 4 + 64 , 44 @ @ public class Interval < C , D > 
 / / handles nulls properly 
 return Objects . equal ( min , that . min ) & & Objects . equal ( max , that . max ) & & Objects . equal ( data , that . data ) ; 
 } 
 + 
 + private static final AsymmetricOrdering < Interval < Comparable , Object > , Comparable > minOrdering 
 + = new AsymmetricOrdering < Interval < Comparable , Object > , Comparable > ( ) 
 + { 
 + public int compareAsymmetric ( Interval < Comparable , Object > left , Comparable right ) 
 + { 
 + return left . min . compareTo ( right ) ; 
 + } 
 + 
 + public int compare ( Interval < Comparable , Object > i1 , Interval < Comparable , Object > i2 ) 
 + { 
 + return i1 . min . compareTo ( i2 . min ) ; 
 + } 
 + } ; 
 + 
 + private static final AsymmetricOrdering < Interval < Comparable , Object > , Comparable > maxOrdering 
 + = new AsymmetricOrdering < Interval < Comparable , Object > , Comparable > ( ) 
 + { 
 + public int compareAsymmetric ( Interval < Comparable , Object > left , Comparable right ) 
 + { 
 + return left . max . compareTo ( right ) ; 
 + } 
 + 
 + public int compare ( Interval < Comparable , Object > i1 , Interval < Comparable , Object > i2 ) 
 + { 
 + return i1 . max . compareTo ( i2 . max ) ; 
 + } 
 + } ; 
 + 
 + private static final AsymmetricOrdering < Interval < Comparable , Object > , Comparable > reverseMaxOrdering = maxOrdering . reverse ( ) ; 
 + 
 + public static < C extends Comparable < ? super C > , V > AsymmetricOrdering < Interval < C , V > , C > minOrdering ( ) 
 + { 
 + return ( AsymmetricOrdering ) minOrdering ; 
 + } 
 + 
 + public static < C extends Comparable < ? super C > , V > AsymmetricOrdering < Interval < C , V > , C > maxOrdering ( ) 
 + { 
 + return ( AsymmetricOrdering ) maxOrdering ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / utils / IntervalTree . java b / src / java / org / apache / cassandra / utils / IntervalTree . java 
 index 3755c54 . . 0c3c611 100644 
 - - - a / src / java / org / apache / cassandra / utils / IntervalTree . java 
 + + + b / src / java / org / apache / cassandra / utils / IntervalTree . java 
 @ @ - 26 , 7 + 26 , 6 @ @ import java . util . * ; 
 import com . google . common . base . Joiner ; 
 import com . google . common . collect . AbstractIterator ; 
 import com . google . common . collect . Iterators ; 
 - import com . google . common . collect . Ordering ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 34 , 77 + 33 , 52 @ @ import org . apache . cassandra . db . TypeSizes ; 
 import org . apache . cassandra . io . ISerializer ; 
 import org . apache . cassandra . io . IVersionedSerializer ; 
 import org . apache . cassandra . io . util . DataOutputPlus ; 
 + import org . apache . cassandra . utils . AsymmetricOrdering . Op ; 
 
 - public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > 
 + public class IntervalTree < C extends Comparable < ? super C > , D , I extends Interval < C , D > > implements Iterable < I > 
 { 
 private static final Logger logger = LoggerFactory . getLogger ( IntervalTree . class ) ; 
 
 @ SuppressWarnings ( " unchecked " ) 
 - private static final IntervalTree EMPTY _ TREE = new IntervalTree ( null , null ) ; 
 + private static final IntervalTree EMPTY _ TREE = new IntervalTree ( null ) ; 
 
 private final IntervalNode head ; 
 private final int count ; 
 - private final Comparator < C > comparator ; 
 
 - final Ordering < I > minOrdering ; 
 - final Ordering < I > maxOrdering ; 
 - 
 - protected IntervalTree ( Collection < I > intervals , Comparator < C > comparator ) 
 + protected IntervalTree ( Collection < I > intervals ) 
 { 
 - this . comparator = comparator ; 
 - 
 final IntervalTree it = this ; 
 - this . minOrdering = new Ordering < I > ( ) 
 - { 
 - public int compare ( I interval1 , I interval2 ) 
 - { 
 - return it . comparePoints ( interval1 . min , interval2 . min ) ; 
 - } 
 - } ; 
 - this . maxOrdering = new Ordering < I > ( ) 
 - { 
 - public int compare ( I interval1 , I interval2 ) 
 - { 
 - return it . comparePoints ( interval1 . max , interval2 . max ) ; 
 - } 
 - } ; 
 - 
 this . head = intervals = = null | | intervals . isEmpty ( ) ? null : new IntervalNode ( intervals ) ; 
 this . count = intervals = = null ? 0 : intervals . size ( ) ; 
 } 
 
 - public static < C , D , I extends Interval < C , D > > IntervalTree < C , D , I > build ( Collection < I > intervals , Comparator < C > comparator ) 
 + public static < C extends Comparable < ? super C > , D , I extends Interval < C , D > > IntervalTree < C , D , I > build ( Collection < I > intervals , Comparator < C > comparator ) 
 { 
 if ( intervals = = null | | intervals . isEmpty ( ) ) 
 return emptyTree ( ) ; 
 
 - return new IntervalTree < C , D , I > ( intervals , comparator ) ; 
 + return new IntervalTree < C , D , I > ( intervals ) ; 
 } 
 
 - public static < C extends Comparable < C > , D , I extends Interval < C , D > > IntervalTree < C , D , I > build ( Collection < I > intervals ) 
 + public static < C extends Comparable < ? super C > , D , I extends Interval < C , D > > IntervalTree < C , D , I > build ( Collection < I > intervals ) 
 { 
 if ( intervals = = null | | intervals . isEmpty ( ) ) 
 return emptyTree ( ) ; 
 
 - return new IntervalTree < C , D , I > ( intervals , null ) ; 
 + return new IntervalTree < C , D , I > ( intervals ) ; 
 } 
 
 - public static < C , D , I extends Interval < C , D > > Serializer < C , D , I > serializer ( ISerializer < C > pointSerializer , ISerializer < D > dataSerializer , Constructor < I > constructor ) 
 + public static < C extends Comparable < ? super C > , D , I extends Interval < C , D > > Serializer < C , D , I > serializer ( ISerializer < C > pointSerializer , ISerializer < D > dataSerializer , Constructor < I > constructor ) 
 { 
 return new Serializer < > ( pointSerializer , dataSerializer , constructor ) ; 
 } 
 
 @ SuppressWarnings ( " unchecked " ) 
 - public static < C , D , I extends Interval < C , D > > IntervalTree < C , D , I > emptyTree ( ) 
 + public static < C extends Comparable < ? super C > , D , I extends Interval < C , D > > IntervalTree < C , D , I > emptyTree ( ) 
 { 
 return ( IntervalTree < C , D , I > ) EMPTY _ TREE ; 
 } 
 
 - public Comparator < C > comparator ( ) 
 - { 
 - return comparator ; 
 - } 
 - 
 public int intervalCount ( ) 
 { 
 return count ; 
 @ @ - 172 , 43 + 146 , 12 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > 
 @ Override 
 public final int hashCode ( ) 
 { 
 - int result = comparator . hashCode ( ) ; 
 + int result = 0 ; 
 for ( Interval < C , D > interval : this ) 
 result = 31 * result + interval . hashCode ( ) ; 
 return result ; 
 } 
 
 - private int comparePoints ( C point1 , C point2 ) 
 - { 
 - if ( comparator ! = null ) 
 - { 
 - return comparator . compare ( point1 , point2 ) ; 
 - } 
 - else 
 - { 
 - assert point1 instanceof Comparable ; 
 - assert point2 instanceof Comparable ; 
 - return ( ( Comparable < C > ) point1 ) . compareTo ( point2 ) ; 
 - } 
 - } 
 - 
 - private boolean encloses ( Interval < C , D > enclosing , Interval < C , D > enclosed ) 
 - { 
 - return comparePoints ( enclosing . min , enclosed . min ) < = 0 
 - & & comparePoints ( enclosing . max , enclosed . max ) > = 0 ; 
 - } 
 - 
 - private boolean contains ( Interval < C , D > interval , C point ) 
 - { 
 - return comparePoints ( interval . min , point ) < = 0 
 - & & comparePoints ( interval . max , point ) > = 0 ; 
 - } 
 - 
 - private boolean intersects ( Interval < C , D > interval1 , Interval < C , D > interval2 ) 
 - { 
 - return contains ( interval1 , interval2 . min ) | | contains ( interval1 , interval2 . max ) ; 
 - } 
 - 
 private class IntervalNode 
 { 
 final C center ; 
 @ @ - 246 , 15 + 189 , 11 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > 
 List < C > allEndpoints = new ArrayList < C > ( toBisect . size ( ) * 2 ) ; 
 for ( I interval : toBisect ) 
 { 
 - assert ( comparator = = null ? ( ( Comparable ) interval . min ) . compareTo ( interval . max ) 
 - : comparator . compare ( interval . min , interval . max ) ) < = 0 : " Interval min > max " ; 
 allEndpoints . add ( interval . min ) ; 
 allEndpoints . add ( interval . max ) ; 
 } 
 - if ( comparator ! = null ) 
 - Collections . sort ( allEndpoints , comparator ) ; 
 - else 
 - Collections . sort ( ( List < Comparable > ) allEndpoints ) ; 
 + 
 + Collections . sort ( allEndpoints ) ; 
 
 low = allEndpoints . get ( 0 ) ; 
 center = allEndpoints . get ( toBisect . size ( ) ) ; 
 @ @ - 267 , 16 + 206 , 16 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > 
 
 for ( I candidate : toBisect ) 
 { 
 - if ( comparePoints ( candidate . max , center ) < 0 ) 
 + if ( candidate . max . compareTo ( center ) < 0 ) 
 leftSegment . add ( candidate ) ; 
 - else if ( comparePoints ( candidate . min , center ) > 0 ) 
 + else if ( candidate . min . compareTo ( center ) > 0 ) 
 rightSegment . add ( candidate ) ; 
 else 
 intersects . add ( candidate ) ; 
 } 
 
 - intersectsLeft = minOrdering . sortedCopy ( intersects ) ; 
 - intersectsRight = maxOrdering . reverse ( ) . sortedCopy ( intersects ) ; 
 + intersectsLeft = Interval . < C , D > minOrdering ( ) . sortedCopy ( intersects ) ; 
 + intersectsRight = Interval . < C , D > maxOrdering ( ) . sortedCopy ( intersects ) ; 
 left = leftSegment . isEmpty ( ) ? null : new IntervalNode ( leftSegment ) ; 
 right = rightSegment . isEmpty ( ) ? null : new IntervalNode ( rightSegment ) ; 
 
 @ @ - 290 , 49 + 229 , 41 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > 
 
 void searchInternal ( Interval < C , D > searchInterval , List < D > results ) 
 { 
 - if ( comparePoints ( searchInterval . max , low ) < 0 | | comparePoints ( searchInterval . min , high ) > 0 ) 
 - return ; 
 - 
 - if ( contains ( searchInterval , center ) ) 
 + if ( center . compareTo ( searchInterval . min ) < 0 ) 
 { 
 - / / Adds every interval contained in this node to the result set then search left and right for further 
 - / / overlapping intervals 
 - for ( Interval < C , D > interval : intersectsLeft ) 
 - results . add ( interval . data ) ; 
 + int i = Interval . < C , D > maxOrdering ( ) . binarySearchAsymmetric ( intersectsRight , searchInterval . min , Op . CEIL ) ; 
 + if ( i = = intersectsRight . size ( ) & & high . compareTo ( searchInterval . min ) < 0 ) 
 + return ; 
 + 
 + while ( i < intersectsRight . size ( ) ) 
 + results . add ( intersectsRight . get ( i + + ) . data ) ; 
 
 - if ( left ! = null ) 
 - left . searchInternal ( searchInterval , results ) ; 
 if ( right ! = null ) 
 right . searchInternal ( searchInterval , results ) ; 
 } 
 - else if ( comparePoints ( center , searchInterval . min ) < 0 ) 
 + else if ( center . compareTo ( searchInterval . max ) > 0 ) 
 { 
 - / / Adds intervals i in intersects right as long as i . max > = searchInterval . min 
 - / / then search right 
 - for ( Interval < C , D > interval : intersectsRight ) 
 - { 
 - if ( comparePoints ( interval . max , searchInterval . min ) > = 0 ) 
 - results . add ( interval . data ) ; 
 - else 
 - break ; 
 - } 
 - if ( right ! = null ) 
 - right . searchInternal ( searchInterval , results ) ; 
 + int j = Interval . < C , D > minOrdering ( ) . binarySearchAsymmetric ( intersectsLeft , searchInterval . max , Op . HIGHER ) ; 
 + if ( j = = 0 & & low . compareTo ( searchInterval . max ) > 0 ) 
 + return ; 
 + 
 + for ( int i = 0 ; i < j ; i + + ) 
 + results . add ( intersectsLeft . get ( i ) . data ) ; 
 + 
 + if ( left ! = null ) 
 + left . searchInternal ( searchInterval , results ) ; 
 } 
 else 
 { 
 - assert comparePoints ( center , searchInterval . max ) > 0 ; 
 - / / Adds intervals i in intersects left as long as i . min > = searchInterval . max 
 - / / then search left 
 + / / Adds every interval contained in this node to the result set then search left and right for further 
 + / / overlapping intervals 
 for ( Interval < C , D > interval : intersectsLeft ) 
 - { 
 - if ( comparePoints ( interval . min , searchInterval . max ) < = 0 ) 
 - results . add ( interval . data ) ; 
 - else 
 - break ; 
 - } 
 + results . add ( interval . data ) ; 
 + 
 if ( left ! = null ) 
 left . searchInternal ( searchInterval , results ) ; 
 + if ( right ! = null ) 
 + right . searchInternal ( searchInterval , results ) ; 
 } 
 } 
 } 
 @ @ - 377 , 7 + 308 , 7 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > 
 } 
 } 
 
 - public static class Serializer < C , D , I extends Interval < C , D > > implements IVersionedSerializer < IntervalTree < C , D , I > > 
 + public static class Serializer < C extends Comparable < ? super C > , D , I extends Interval < C , D > > implements IVersionedSerializer < IntervalTree < C , D , I > > 
 { 
 private final ISerializer < C > pointSerializer ; 
 private final ISerializer < D > dataSerializer ; 
 @ @ - 417 , 7 + 348 , 7 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > 
 try 
 { 
 int count = in . readInt ( ) ; 
 - List < Interval < C , D > > intervals = new ArrayList < Interval < C , D > > ( count ) ; 
 + List < I > intervals = new ArrayList < I > ( count ) ; 
 for ( int i = 0 ; i < count ; i + + ) 
 { 
 C min = pointSerializer . deserialize ( in ) ; 
 @ @ - 425 , 7 + 356 , 7 @ @ public class IntervalTree < C , D , I extends Interval < C , D > > implements Iterable < I > 
 D data = dataSerializer . deserialize ( in ) ; 
 intervals . add ( constructor . newInstance ( min , max , data ) ) ; 
 } 
 - return new IntervalTree ( intervals , comparator ) ; 
 + return new IntervalTree < C , D , I > ( intervals ) ; 
 } 
 catch ( InstantiationException e ) 
 { 
 diff - - git a / test / unit / org / apache / cassandra / utils / IntervalTreeTest . java b / test / unit / org / apache / cassandra / utils / IntervalTreeTest . java 
 index ea88092 . . 8409a26 100644 
 - - - a / test / unit / org / apache / cassandra / utils / IntervalTreeTest . java 
 + + + b / test / unit / org / apache / cassandra / utils / IntervalTreeTest . java 
 @ @ - 115 , 7 + 115 , 7 @ @ public class IntervalTreeTest 
 
 IntervalTree < Integer , Void , Interval < Integer , Void > > it = IntervalTree . build ( intervals ) ; 
 
 - Collections . sort ( intervals , it . minOrdering ) ; 
 + Collections . sort ( intervals , Interval . < Integer , Void > minOrdering ( ) ) ; 
 
 List < Interval < Integer , Void > > l = new ArrayList < Interval < Integer , Void > > ( ) ; 
 for ( Interval < Integer , Void > i : it )

NEAREST DIFF:
diff - - git a / src / java / org / apache / cassandra / db / ColumnFamily . java b / src / java / org / apache / cassandra / db / ColumnFamily . java 
 index c3bddd4 . . cb87833 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamily . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamily . java 
 @ @ - 35 , 7 + 35 , 6 @ @ import org . apache . cassandra . utils . FBUtilities ; 
 import org . apache . cassandra . io . ICompactSerializer2 ; 
 import org . apache . cassandra . db . filter . QueryPath ; 
 import org . apache . cassandra . db . marshal . AbstractType ; 
 - import org . apache . cassandra . db . marshal . MarshalException ; 
 
 
 public final class ColumnFamily implements IColumnContainer 
 @ @ - 121 , 12 + 120 , 13 @ @ public final class ColumnFamily implements IColumnContainer 
 * We need to go through each column 
 * in the column family and resolve it before adding 
 * / 
 - void addColumns ( ColumnFamily cf ) 
 + public void addAll ( ColumnFamily cf ) 
 { 
 for ( IColumn column : cf . getSortedColumns ( ) ) 
 { 
 addColumn ( column ) ; 
 } 
 + delete ( cf ) ; 
 } 
 
 public ICompactSerializer2 < IColumn > getColumnSerializer ( ) 
 @ @ - 415 , 8 + 415 , 7 @ @ public final class ColumnFamily implements IColumnContainer 
 for ( ColumnFamily cf2 : columnFamilies ) 
 { 
 assert cf . name ( ) . equals ( cf2 . name ( ) ) ; 
 - cf . addColumns ( cf2 ) ; 
 - cf . delete ( cf2 ) ; 
 + cf . addAll ( cf2 ) ; 
 } 
 return cf ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index 001c644 . . 96bb18b 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 560 , 26 + 560 , 6 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 CompactionManager . instance ( ) . submit ( this ) ; 
 } 
 
 - private PriorityQueue < FileStruct > initializePriorityQueue ( Collection < SSTableReader > sstables , List < Range > ranges ) throws IOException 
 - { 
 - PriorityQueue < FileStruct > pq = new PriorityQueue < FileStruct > ( ) ; 
 - if ( sstables . size ( ) > 1 | | ( ranges ! = null & & sstables . size ( ) > 0 ) ) 
 - { 
 - FileStruct fs = null ; 
 - for ( SSTableReader sstable : sstables ) 
 - { 
 - fs = sstable . getFileStruct ( ) ; 
 - fs . advance ( true ) ; 
 - if ( fs . isExhausted ( ) ) 
 - { 
 - continue ; 
 - } 
 - pq . add ( fs ) ; 
 - } 
 - } 
 - return pq ; 
 - } 
 - 
 / * 
 * Group files of similar size into buckets . 
 * / 
 @ @ - 766 , 150 + 746 , 67 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 * / 
 List < SSTableReader > doFileAntiCompaction ( Collection < SSTableReader > sstables , List < Range > ranges , EndPoint target ) throws IOException 
 { 
 - List < SSTableReader > results = new ArrayList < SSTableReader > ( ) ; 
 - long startTime = System . currentTimeMillis ( ) ; 
 - long totalBytesRead = 0 ; 
 - long totalBytesWritten = 0 ; 
 - long totalkeysRead = 0 ; 
 - long totalkeysWritten = 0 ; 
 - String rangeFileLocation ; 
 - String mergedFileName ; 
 + logger _ . info ( " AntiCompacting [ " + StringUtils . join ( sstables , " , " ) + " ] " ) ; 
 / / Calculate the expected compacted filesize 
 - long expectedRangeFileSize = getExpectedCompactedFileSize ( sstables ) ; 
 - / * in the worst case a node will be giving out half of its data so we take a chance * / 
 - expectedRangeFileSize = expectedRangeFileSize / 2 ; 
 - rangeFileLocation = DatabaseDescriptor . getDataFileLocationForTable ( table _ , expectedRangeFileSize ) ; 
 - / / If the compaction file path is null that means we have no space left for this compaction . 
 - if ( rangeFileLocation = = null ) 
 - { 
 - logger _ . error ( " Total bytes to be written for range compaction . . . " 
 - + expectedRangeFileSize + " is greater than the safe limit of the disk space available . " ) ; 
 - return results ; 
 - } 
 - PriorityQueue < FileStruct > pq = initializePriorityQueue ( sstables , ranges ) ; 
 - if ( pq . isEmpty ( ) ) 
 + long expectedRangeFileSize = getExpectedCompactedFileSize ( sstables ) / 2 ; 
 + String compactionFileLocation = DatabaseDescriptor . getDataFileLocationForTable ( table _ , expectedRangeFileSize ) ; 
 + if ( compactionFileLocation = = null ) 
 { 
 - return results ; 
 + throw new UnsupportedOperationException ( " disk full " ) ; 
 } 
 + List < SSTableReader > results = new ArrayList < SSTableReader > ( ) ; 
 
 - mergedFileName = getTempSSTableFileName ( ) ; 
 - SSTableWriter rangeWriter = null ; 
 - String lastkey = null ; 
 - List < FileStruct > lfs = new ArrayList < FileStruct > ( ) ; 
 - DataOutputBuffer bufOut = new DataOutputBuffer ( ) ; 
 - int expectedBloomFilterSize = SSTableReader . getApproximateKeyCount ( sstables ) ; 
 - expectedBloomFilterSize = ( expectedBloomFilterSize > 0 ) ? expectedBloomFilterSize : SSTableReader . indexInterval ( ) ; 
 + long startTime = System . currentTimeMillis ( ) ; 
 + long totalkeysWritten = 0 ; 
 + 
 + int expectedBloomFilterSize = Math . max ( SSTableReader . indexInterval ( ) , SSTableReader . getApproximateKeyCount ( sstables ) / 2 ) ; 
 if ( logger _ . isDebugEnabled ( ) ) 
 logger _ . debug ( " Expected bloom filter size : " + expectedBloomFilterSize ) ; 
 - List < ColumnFamily > columnFamilies = new ArrayList < ColumnFamily > ( ) ; 
 
 - while ( pq . size ( ) > 0 | | lfs . size ( ) > 0 ) 
 + SSTableWriter writer = null ; 
 + CompactionIterator ci = new CompactionIterator ( sstables ) ; 
 + 
 + try 
 { 
 - FileStruct fs = null ; 
 - if ( pq . size ( ) > 0 ) 
 + if ( ! ci . hasNext ( ) ) 
 { 
 - fs = pq . poll ( ) ; 
 + logger _ . warn ( " Nothing to compact ( all files empty or corrupt ) . This should not happen . " ) ; 
 + return results ; 
 } 
 - if ( fs ! = null 
 - & & ( lastkey = = null | | lastkey . equals ( fs . getKey ( ) ) ) ) 
 - { 
 - / / The keys are the same so we need to add this to the 
 - / / ldfs list 
 - lastkey = fs . getKey ( ) ; 
 - lfs . add ( fs ) ; 
 - } 
 - else 
 + 
 + while ( ci . hasNext ( ) ) 
 { 
 - Collections . sort ( lfs , new FileStructComparator ( ) ) ; 
 - ColumnFamily columnFamily ; 
 - bufOut . reset ( ) ; 
 - if ( lfs . size ( ) > 1 ) 
 + CompactionIterator . CompactedRow row = ci . next ( ) ; 
 + if ( Range . isTokenInRanges ( StorageService . getPartitioner ( ) . getToken ( row . key ) , ranges ) ) 
 { 
 - for ( FileStruct filestruct : lfs ) 
 - { 
 - / / We want to add only 2 and resolve them right there in order to save on memory footprint 
 - if ( columnFamilies . size ( ) > 1 ) 
 - { 
 - / / Now merge the 2 column families 
 - merge ( columnFamilies ) ; 
 - } 
 - / / deserialize into column families 
 - columnFamilies . add ( filestruct . getColumnFamily ( ) ) ; 
 - } 
 - / / Now after merging all crap append to the sstable 
 - columnFamily = resolveAndRemoveDeleted ( columnFamilies ) ; 
 - columnFamilies . clear ( ) ; 
 - if ( columnFamily ! = null ) 
 - { 
 - ColumnFamily . serializer ( ) . serializeWithIndexes ( columnFamily , bufOut ) ; 
 - } 
 - } 
 - else 
 - { 
 - / / TODO deserializing only to reserialize is dumb 
 - FileStruct filestruct = lfs . get ( 0 ) ; 
 - ColumnFamily . serializer ( ) . serializeWithIndexes ( filestruct . getColumnFamily ( ) , bufOut ) ; 
 - } 
 - if ( Range . isTokenInRanges ( StorageService . getPartitioner ( ) . getToken ( lastkey ) , ranges ) ) 
 - { 
 - if ( rangeWriter = = null ) 
 + if ( writer = = null ) 
 { 
 if ( target ! = null ) 
 { 
 - rangeFileLocation = rangeFileLocation + File . separator + " bootstrap " ; 
 + compactionFileLocation = compactionFileLocation + File . separator + " bootstrap " ; 
 } 
 - FileUtils . createDirectory ( rangeFileLocation ) ; 
 - String fname = new File ( rangeFileLocation , mergedFileName ) . getAbsolutePath ( ) ; 
 - rangeWriter = new SSTableWriter ( fname , expectedBloomFilterSize , StorageService . getPartitioner ( ) ) ; 
 + FileUtils . createDirectory ( compactionFileLocation ) ; 
 + String newFilename = new File ( compactionFileLocation , getTempSSTableFileName ( ) ) . getAbsolutePath ( ) ; 
 + writer = new SSTableWriter ( newFilename , expectedBloomFilterSize , StorageService . getPartitioner ( ) ) ; 
 } 
 - rangeWriter . append ( lastkey , bufOut ) ; 
 - } 
 - totalkeysWritten + + ; 
 - for ( FileStruct filestruct : lfs ) 
 - { 
 - filestruct . advance ( true ) ; 
 - if ( filestruct . isExhausted ( ) ) 
 - { 
 - continue ; 
 - } 
 - / * keep on looping until we find a key in the range * / 
 - while ( ! Range . isTokenInRanges ( StorageService . getPartitioner ( ) . getToken ( filestruct . getKey ( ) ) , ranges ) ) 
 - { 
 - filestruct . advance ( true ) ; 
 - if ( filestruct . isExhausted ( ) ) 
 - { 
 - break ; 
 - } 
 - } 
 - if ( ! filestruct . isExhausted ( ) ) 
 - { 
 - pq . add ( filestruct ) ; 
 - } 
 - totalkeysRead + + ; 
 - } 
 - lfs . clear ( ) ; 
 - lastkey = null ; 
 - if ( fs ! = null ) 
 - { 
 - / / Add back the fs since we processed the rest of 
 - / / filestructs 
 - pq . add ( fs ) ; 
 + writer . append ( row . key , row . buffer ) ; 
 + totalkeysWritten + + ; 
 } 
 } 
 } 
 - 
 - if ( rangeWriter ! = null ) 
 + finally 
 { 
 - results . add ( rangeWriter . closeAndOpenReader ( ) ) ; 
 + ci . close ( ) ; 
 } 
 
 - if ( logger _ . isDebugEnabled ( ) ) 
 + if ( writer ! = null ) 
 { 
 - logger _ . debug ( " Total time taken for range split . . . " + ( System . currentTimeMillis ( ) - startTime ) ) ; 
 - logger _ . debug ( " Total bytes Read for range split . . . " + totalBytesRead ) ; 
 - logger _ . debug ( " Total bytes written for range split . . . " 
 - + totalBytesWritten + " Total keys read . . . " + totalkeysRead ) ; 
 + results . add ( writer . closeAndOpenReader ( ) ) ; 
 + String format = " AntiCompacted to % s . % d / % d bytes for % d keys . Time : % dms . " ; 
 + long dTime = System . currentTimeMillis ( ) - startTime ; 
 + logger _ . info ( String . format ( format , writer . getFilename ( ) , getTotalBytes ( sstables ) , results . get ( 0 ) . length ( ) , totalkeysWritten , dTime ) ) ; 
 } 
 + 
 return results ; 
 } 
 
 @ @ - 938 , 111 + 835 , 59 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 } 
 
 long startTime = System . currentTimeMillis ( ) ; 
 - long totalBytesRead = 0 ; 
 - long totalkeysRead = 0 ; 
 long totalkeysWritten = 0 ; 
 - PriorityQueue < FileStruct > pq = initializePriorityQueue ( sstables , null ) ; 
 - 
 - if ( pq . isEmpty ( ) ) 
 - { 
 - logger _ . warn ( " Nothing to compact ( all files empty or corrupt ) . This should not happen . " ) ; 
 - / / TODO clean out bad files , if any 
 - return 0 ; 
 - } 
 
 - int expectedBloomFilterSize = SSTableReader . getApproximateKeyCount ( sstables ) ; 
 - if ( expectedBloomFilterSize < 0 ) 
 - expectedBloomFilterSize = SSTableReader . indexInterval ( ) ; 
 - String newFilename = new File ( compactionFileLocation , getTempSSTableFileName ( ) ) . getAbsolutePath ( ) ; 
 - SSTableWriter writer = new SSTableWriter ( newFilename , expectedBloomFilterSize , StorageService . getPartitioner ( ) ) ; 
 - SSTableReader ssTable = null ; 
 - String lastkey = null ; 
 - List < FileStruct > lfs = new ArrayList < FileStruct > ( ) ; 
 - DataOutputBuffer bufOut = new DataOutputBuffer ( ) ; 
 + int expectedBloomFilterSize = Math . max ( SSTableReader . indexInterval ( ) , SSTableReader . getApproximateKeyCount ( sstables ) ) ; 
 if ( logger _ . isDebugEnabled ( ) ) 
 logger _ . debug ( " Expected bloom filter size : " + expectedBloomFilterSize ) ; 
 - List < ColumnFamily > columnFamilies = new ArrayList < ColumnFamily > ( ) ; 
 
 - while ( pq . size ( ) > 0 | | lfs . size ( ) > 0 ) 
 + SSTableWriter writer ; 
 + CompactionIterator ci = new CompactionIterator ( sstables ) ; 
 + 
 + try 
 { 
 - FileStruct fs = null ; 
 - if ( pq . size ( ) > 0 ) 
 + if ( ! ci . hasNext ( ) ) 
 { 
 - fs = pq . poll ( ) ; 
 + logger _ . warn ( " Nothing to compact ( all files empty or corrupt ) . This should not happen . " ) ; 
 + return 0 ; 
 } 
 - if ( fs ! = null 
 - & & ( lastkey = = null | | lastkey . equals ( fs . getKey ( ) ) ) ) 
 - { 
 - / / The keys are the same so we need to add this to the 
 - / / ldfs list 
 - lastkey = fs . getKey ( ) ; 
 - lfs . add ( fs ) ; 
 - } 
 - else 
 - { 
 - Collections . sort ( lfs , new FileStructComparator ( ) ) ; 
 - ColumnFamily columnFamily ; 
 - bufOut . reset ( ) ; 
 - if ( lfs . size ( ) > 1 ) 
 - { 
 - for ( FileStruct filestruct : lfs ) 
 - { 
 - / / We want to add only 2 and resolve them right there in order to save on memory footprint 
 - if ( columnFamilies . size ( ) > 1 ) 
 - { 
 - merge ( columnFamilies ) ; 
 - } 
 - / / deserialize into column families 
 - columnFamilies . add ( filestruct . getColumnFamily ( ) ) ; 
 - } 
 - / / Now after merging all crap append to the sstable 
 - columnFamily = resolveAndRemoveDeleted ( columnFamilies ) ; 
 - columnFamilies . clear ( ) ; 
 - if ( columnFamily ! = null ) 
 - { 
 - ColumnFamily . serializer ( ) . serializeWithIndexes ( columnFamily , bufOut ) ; 
 - } 
 - } 
 - else 
 - { 
 - / / TODO deserializing only to reserialize is dumb 
 - FileStruct filestruct = lfs . get ( 0 ) ; 
 - ColumnFamily . serializer ( ) . serializeWithIndexes ( filestruct . getColumnFamily ( ) , bufOut ) ; 
 - } 
 
 - writer . append ( lastkey , bufOut ) ; 
 - totalkeysWritten + + ; 
 + String newFilename = new File ( compactionFileLocation , getTempSSTableFileName ( ) ) . getAbsolutePath ( ) ; 
 + writer = new SSTableWriter ( newFilename , expectedBloomFilterSize , StorageService . getPartitioner ( ) ) ; 
 
 - for ( FileStruct filestruct : lfs ) 
 - { 
 - filestruct . advance ( true ) ; 
 - if ( filestruct . isExhausted ( ) ) 
 - { 
 - continue ; 
 - } 
 - pq . add ( filestruct ) ; 
 - totalkeysRead + + ; 
 - } 
 - lfs . clear ( ) ; 
 - lastkey = null ; 
 - if ( fs ! = null ) 
 - { 
 - / * Add back the fs since we processed the rest of filestructs * / 
 - pq . add ( fs ) ; 
 - } 
 + while ( ci . hasNext ( ) ) 
 + { 
 + CompactionIterator . CompactedRow row = ci . next ( ) ; 
 + writer . append ( row . key , row . buffer ) ; 
 + totalkeysWritten + + ; 
 } 
 } 
 - ssTable = writer . closeAndOpenReader ( ) ; 
 + finally 
 + { 
 + ci . close ( ) ; 
 + } 
 + 
 + SSTableReader ssTable = writer . closeAndOpenReader ( ) ; 
 ssTables _ . add ( ssTable ) ; 
 ssTables _ . markCompacted ( sstables ) ; 
 CompactionManager . instance ( ) . submit ( ColumnFamilyStore . this ) ; 
 
 - String format = " Compacted to % s . % d / % d bytes for % d / % d keys read / written . Time : % dms . " ; 
 + String format = " Compacted to % s . % d / % d bytes for % d keys . Time : % dms . " ; 
 long dTime = System . currentTimeMillis ( ) - startTime ; 
 - logger _ . info ( String . format ( format , writer . getFilename ( ) , totalBytesRead , ssTable . length ( ) , totalkeysRead , totalkeysWritten , dTime ) ) ; 
 + logger _ . info ( String . format ( format , writer . getFilename ( ) , getTotalBytes ( sstables ) , ssTable . length ( ) , totalkeysWritten , dTime ) ) ; 
 return sstables . size ( ) ; 
 } 
 
 + private long getTotalBytes ( Iterable < SSTableReader > sstables ) 
 + { 
 + long sum = 0 ; 
 + for ( SSTableReader sstable : sstables ) 
 + { 
 + sum + = sstable . length ( ) ; 
 + } 
 + return sum ; 
 + } 
 + 
 public static List < Memtable > getUnflushedMemtables ( String cfName ) 
 { 
 return new ArrayList < Memtable > ( getMemtablesPendingFlushNotNull ( cfName ) ) ; 
 @ @ - 1341 , 23 + 1186 , 24 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 / / sstables 
 for ( SSTableReader sstable : ssTables _ ) 
 { 
 - final SSTableScanner fs = sstable . getScanner ( ) ; 
 - fs . seekTo ( startWith ) ; 
 - iterators . add ( new Iterator < String > ( ) 
 + final SSTableScanner scanner = sstable . getScanner ( ) ; 
 + scanner . seekTo ( startWith ) ; 
 + Iterator < String > iter = new Iterator < String > ( ) 
 { 
 public boolean hasNext ( ) 
 { 
 - return fs . hasNext ( ) ; 
 + return scanner . hasNext ( ) ; 
 } 
 public String next ( ) 
 { 
 - return fs . next ( ) . getKey ( ) ; 
 + return scanner . next ( ) . getKey ( ) ; 
 } 
 public void remove ( ) 
 { 
 throw new UnsupportedOperationException ( ) ; 
 } 
 - } ) ; 
 + } ; 
 + iterators . add ( iter ) ; 
 } 
 
 Iterator < String > collated = IteratorUtils . collatedIterator ( comparator , iterators ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / FileStructComparator . java b / src / java / org / apache / cassandra / db / FileStructComparator . java 
 deleted file mode 100644 
 index e81a992 . . 0000000 
 - - - a / src / java / org / apache / cassandra / db / FileStructComparator . java 
 + + + / dev / null 
 @ @ - 1 , 31 + 0 , 0 @ @ 
 - / * 
 - * Licensed to the Apache Software Foundation ( ASF ) under one 
 - * or more contributor license agreements . See the NOTICE file 
 - * distributed with this work for additional information 
 - * regarding copyright ownership . The ASF licenses this file 
 - * to you under the Apache License , Version 2 . 0 ( the 
 - * " License " ) ; you may not use this file except in compliance 
 - * with the License . You may obtain a copy of the License at 
 - * 
 - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 - * 
 - * Unless required by applicable law or agreed to in writing , 
 - * software distributed under the License is distributed on an 
 - * " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY 
 - * KIND , either express or implied . See the License for the 
 - * specific language governing permissions and limitations 
 - * under the License . 
 - * / 
 - package org . apache . cassandra . db ; 
 - 
 - import java . util . Comparator ; 
 - 
 - import org . apache . cassandra . io . FileStruct ; 
 - 
 - class FileStructComparator implements Comparator < FileStruct > 
 - { 
 - public int compare ( FileStruct f , FileStruct f2 ) 
 - { 
 - return f . getFileName ( ) . compareTo ( f2 . getFileName ( ) ) ; 
 - } 
 - } 
 \ No newline at end of file 
 diff - - git a / src / java / org / apache / cassandra / db / Memtable . java b / src / java / org / apache / cassandra / db / Memtable . java 
 index d88e004 . . 696ae5a 100644 
 - - - a / src / java / org / apache / cassandra / db / Memtable . java 
 + + + b / src / java / org / apache / cassandra / db / Memtable . java 
 @ @ - 153 , 7 + 153 , 7 @ @ public class Memtable implements Comparable < Memtable > 
 { 
 int oldSize = oldCf . size ( ) ; 
 int oldObjectCount = oldCf . getColumnCount ( ) ; 
 - oldCf . addColumns ( columnFamily ) ; 
 + oldCf . addAll ( columnFamily ) ; 
 int newSize = oldCf . size ( ) ; 
 int newObjectCount = oldCf . getColumnCount ( ) ; 
 resolveSize ( oldSize , newSize ) ; 
 diff - - git a / src / java / org / apache / cassandra / io / CompactionIterator . java b / src / java / org / apache / cassandra / io / CompactionIterator . java 
 new file mode 100644 
 index 0000000 . . b65e132 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / io / CompactionIterator . java 
 @ @ - 0 , 0 + 1 , 113 @ @ 
 + package org . apache . cassandra . io ; 
 + 
 + import java . io . Closeable ; 
 + import java . io . IOException ; 
 + import java . util . List ; 
 + import java . util . ArrayList ; 
 + import java . util . Comparator ; 
 + 
 + import org . apache . commons . collections . iterators . CollatingIterator ; 
 + 
 + import org . apache . cassandra . utils . ReducingIterator ; 
 + import org . apache . cassandra . db . ColumnFamily ; 
 + 
 + public class CompactionIterator extends ReducingIterator < IteratingRow , CompactionIterator . CompactedRow > implements Closeable 
 + { 
 + private final List < IteratingRow > rows = new ArrayList < IteratingRow > ( ) ; 
 + 
 + @ SuppressWarnings ( " unchecked " ) 
 + public CompactionIterator ( Iterable < SSTableReader > sstables ) throws IOException 
 + { 
 + super ( getCollatingIterator ( sstables ) ) ; 
 + } 
 + 
 + @ SuppressWarnings ( " unchecked " ) 
 + private static CollatingIterator getCollatingIterator ( Iterable < SSTableReader > sstables ) throws IOException 
 + { 
 + / / CollatingIterator has a bug that causes NPE when you try to use default comparator . : ( 
 + CollatingIterator iter = new CollatingIterator ( new Comparator ( ) 
 + { 
 + public int compare ( Object o1 , Object o2 ) 
 + { 
 + return ( ( Comparable ) o1 ) . compareTo ( o2 ) ; 
 + } 
 + } ) ; 
 + for ( SSTableReader sstable : sstables ) 
 + { 
 + iter . addIterator ( sstable . getScanner ( ) ) ; 
 + } 
 + return iter ; 
 + } 
 + 
 + @ Override 
 + protected boolean isEqual ( IteratingRow o1 , IteratingRow o2 ) 
 + { 
 + return o1 . getKey ( ) . equals ( o2 . getKey ( ) ) ; 
 + } 
 + 
 + public void reduce ( IteratingRow current ) 
 + { 
 + rows . add ( current ) ; 
 + } 
 + 
 + protected CompactedRow getReduced ( ) 
 + { 
 + try 
 + { 
 + return getReducedRaw ( ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new RuntimeException ( e ) ; 
 + } 
 + } 
 + 
 + protected CompactedRow getReducedRaw ( ) throws IOException 
 + { 
 + DataOutputBuffer buffer = new DataOutputBuffer ( ) ; 
 + String key = rows . get ( 0 ) . getKey ( ) ; 
 + if ( rows . size ( ) > 1 ) 
 + { 
 + ColumnFamily cf = null ; 
 + for ( IteratingRow row : rows ) 
 + { 
 + if ( cf = = null ) 
 + { 
 + cf = row . getColumnFamily ( ) ; 
 + } 
 + else 
 + { 
 + cf . addAll ( row . getColumnFamily ( ) ) ; 
 + } 
 + } 
 + ColumnFamily . serializer ( ) . serializeWithIndexes ( cf , buffer ) ; 
 + } 
 + else 
 + { 
 + assert rows . size ( ) = = 1 ; 
 + rows . get ( 0 ) . echoData ( buffer ) ; 
 + } 
 + rows . clear ( ) ; 
 + return new CompactedRow ( key , buffer ) ; 
 + } 
 + 
 + public void close ( ) throws IOException 
 + { 
 + for ( Object o : ( ( CollatingIterator ) source ) . getIterators ( ) ) 
 + { 
 + ( ( SSTableScanner ) o ) . close ( ) ; 
 + } 
 + } 
 + 
 + public static class CompactedRow 
 + { 
 + public final String key ; 
 + public final DataOutputBuffer buffer ; 
 + 
 + public CompactedRow ( String key , DataOutputBuffer buffer ) 
 + { 
 + this . key = key ; 
 + this . buffer = buffer ; 
 + } 
 + } 
 + } 
 diff - - git a / src / java / org / apache / cassandra / io / FileStruct . java b / src / java / org / apache / cassandra / io / FileStruct . java 
 deleted file mode 100644 
 index b561239 . . 0000000 
 - - - a / src / java / org / apache / cassandra / io / FileStruct . java 
 + + + / dev / null 
 @ @ - 1 , 195 + 0 , 0 @ @ 
 - / * * 
 - * Licensed to the Apache Software Foundation ( ASF ) under one 
 - * or more contributor license agreements . See the NOTICE file 
 - * distributed with this work for additional information 
 - * regarding copyright ownership . The ASF licenses this file 
 - * to you under the Apache License , Version 2 . 0 ( the 
 - * " License " ) ; you may not use this file except in compliance 
 - * with the License . You may obtain a copy of the License at 
 - * 
 - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 - * 
 - * Unless required by applicable law or agreed to in writing , software 
 - * distributed under the License is distributed on an " AS IS " BASIS , 
 - * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 - * See the License for the specific language governing permissions and 
 - * limitations under the License . 
 - * / 
 - 
 - package org . apache . cassandra . io ; 
 - 
 - import java . io . IOException ; 
 - import java . io . File ; 
 - import java . util . Iterator ; 
 - 
 - import org . apache . cassandra . db . IColumn ; 
 - import org . apache . cassandra . db . ColumnFamily ; 
 - import org . apache . cassandra . config . DatabaseDescriptor ; 
 - 
 - import org . apache . log4j . Logger ; 
 - import com . google . common . collect . AbstractIterator ; 
 - 
 - 
 - public class FileStruct implements Comparable < FileStruct > , Iterator < String > 
 - { 
 - private static Logger logger = Logger . getLogger ( FileStruct . class ) ; 
 - 
 - private IteratingRow row ; 
 - private boolean exhausted = false ; 
 - private BufferedRandomAccessFile file ; 
 - private SSTableReader sstable ; 
 - private FileStructIterator iterator ; 
 - 
 - FileStruct ( SSTableReader sstable ) throws IOException 
 - { 
 - / / TODO this is used for both compactions and key ranges . the buffer sizes we want 
 - / / to use for these ops are very different . here we are leaning towards the key - range 
 - / / use case since that is more common . What we really want is to split those 
 - / / two uses of this class up . 
 - this . file = new BufferedRandomAccessFile ( sstable . getFilename ( ) , " r " , 256 * 1024 ) ; 
 - this . sstable = sstable ; 
 - } 
 - 
 - public String getFileName ( ) 
 - { 
 - return file . getPath ( ) ; 
 - } 
 - 
 - public void close ( ) throws IOException 
 - { 
 - file . close ( ) ; 
 - } 
 - 
 - public boolean isExhausted ( ) 
 - { 
 - return exhausted ; 
 - } 
 - 
 - public String getKey ( ) 
 - { 
 - return row . getKey ( ) ; 
 - } 
 - 
 - public ColumnFamily getColumnFamily ( ) 
 - { 
 - return row . getEmptyColumnFamily ( ) ; 
 - } 
 - 
 - public int compareTo ( FileStruct f ) 
 - { 
 - return sstable . getPartitioner ( ) . getDecoratedKeyComparator ( ) . compare ( getKey ( ) , f . getKey ( ) ) ; 
 - } 
 - 
 - public void seekTo ( String seekKey ) 
 - { 
 - try 
 - { 
 - long position = sstable . getNearestPosition ( seekKey ) ; 
 - if ( position < 0 ) 
 - { 
 - exhausted = true ; 
 - return ; 
 - } 
 - file . seek ( position ) ; 
 - advance ( false ) ; 
 - } 
 - catch ( IOException e ) 
 - { 
 - throw new RuntimeException ( " corrupt sstable " , e ) ; 
 - } 
 - } 
 - 
 - / * 
 - * Read the next key from the data file . 
 - * Caller must check isExhausted after each call to see if further 
 - * reads are valid . 
 - * Do not mix with calls to the iterator interface ( next / hasnext ) . 
 - * @ deprecated - - prefer the iterator interface . 
 - * / 
 - public void advance ( boolean materialize ) throws IOException 
 - { 
 - / / TODO r / m materialize option - - use iterableness ! 
 - if ( exhausted ) 
 - { 
 - throw new IndexOutOfBoundsException ( ) ; 
 - } 
 - 
 - if ( file . isEOF ( ) ) 
 - { 
 - file . close ( ) ; 
 - exhausted = true ; 
 - return ; 
 - } 
 - 
 - row = new IteratingRow ( file , sstable ) ; 
 - if ( materialize ) 
 - { 
 - while ( row . hasNext ( ) ) 
 - { 
 - IColumn column = row . next ( ) ; 
 - row . getEmptyColumnFamily ( ) . addColumn ( column ) ; 
 - } 
 - } 
 - else 
 - { 
 - row . skipRemaining ( ) ; 
 - } 
 - } 
 - 
 - public boolean hasNext ( ) 
 - { 
 - if ( iterator = = null ) 
 - iterator = new FileStructIterator ( ) ; 
 - return iterator . hasNext ( ) ; 
 - } 
 - 
 - / * * do not mix with manual calls to advance ( ) . * / 
 - public String next ( ) 
 - { 
 - if ( iterator = = null ) 
 - iterator = new FileStructIterator ( ) ; 
 - return iterator . next ( ) ; 
 - } 
 - 
 - public void remove ( ) 
 - { 
 - throw new UnsupportedOperationException ( ) ; 
 - } 
 - 
 - private class FileStructIterator extends AbstractIterator < String > 
 - { 
 - public FileStructIterator ( ) 
 - { 
 - if ( row = = null ) 
 - { 
 - if ( ! isExhausted ( ) ) 
 - { 
 - forward ( ) ; 
 - } 
 - } 
 - } 
 - 
 - private void forward ( ) 
 - { 
 - try 
 - { 
 - advance ( false ) ; 
 - } 
 - catch ( IOException e ) 
 - { 
 - throw new RuntimeException ( e ) ; 
 - } 
 - } 
 - 
 - protected String computeNext ( ) 
 - { 
 - if ( isExhausted ( ) ) 
 - { 
 - return endOfData ( ) ; 
 - } 
 - String oldKey = getKey ( ) ; 
 - forward ( ) ; 
 - return oldKey ; 
 - } 
 - } 
 - } 
 diff - - git a / src / java / org / apache / cassandra / io / IteratingRow . java b / src / java / org / apache / cassandra / io / IteratingRow . java 
 index 5ace95f . . 628fe50 100644 
 - - - a / src / java / org / apache / cassandra / io / IteratingRow . java 
 + + + b / src / java / org / apache / cassandra / io / IteratingRow . java 
 @ @ - 37 , 7 + 37 , 6 @ @ public class IteratingRow extends AbstractIterator < IColumn > implements Comparabl 
 { 
 private final String key ; 
 private final long finishedAt ; 
 - private final ColumnFamily emptyColumnFamily ; 
 private final BufferedRandomAccessFile file ; 
 private SSTableReader sstable ; 
 private long dataStart ; 
 @ @ - 51 , 10 + 50 , 6 @ @ public class IteratingRow extends AbstractIterator < IColumn > implements Comparabl 
 int dataSize = file . readInt ( ) ; 
 dataStart = file . getFilePointer ( ) ; 
 finishedAt = dataStart + dataSize ; 
 - / / legacy stuff to support FileStruct : 
 - IndexHelper . skipBloomFilterAndIndex ( file ) ; 
 - emptyColumnFamily = ColumnFamily . serializer ( ) . deserializeFromSSTableNoColumns ( sstable . makeColumnFamily ( ) , file ) ; 
 - file . readInt ( ) ; 
 } 
 
 public String getKey ( ) 
 @ @ - 62 , 11 + 57 , 6 @ @ public class IteratingRow extends AbstractIterator < IColumn > implements Comparabl 
 return key ; 
 } 
 
 - public ColumnFamily getEmptyColumnFamily ( ) 
 - { 
 - return emptyColumnFamily ; 
 - } 
 - 
 public void echoData ( DataOutput out ) throws IOException 
 { 
 file . seek ( dataStart ) ; 
 diff - - git a / src / java / org / apache / cassandra / io / SSTableReader . java b / src / java / org / apache / cassandra / io / SSTableReader . java 
 index fc94fca . . 81a71fd 100644 
 - - - a / src / java / org / apache / cassandra / io / SSTableReader . java 
 + + + b / src / java / org / apache / cassandra / io / SSTableReader . java 
 @ @ - 333 , 11 + 333 , 6 @ @ public class SSTableReader extends SSTable implements Comparable < SSTableReader > 
 return partitioner ; 
 } 
 
 - public FileStruct getFileStruct ( ) throws IOException 
 - { 
 - return new FileStruct ( this ) ; 
 - } 
 - 
 public SSTableScanner getScanner ( ) throws IOException 
 { 
 return new SSTableScanner ( this ) ; 
 diff - - git a / test / unit / org / apache / cassandra / db / ColumnFamilyTest . java b / test / unit / org / apache / cassandra / db / ColumnFamilyTest . java 
 index 40e5889 . . 4219ff9 100644 
 - - - a / test / unit / org / apache / cassandra / db / ColumnFamilyTest . java 
 + + + b / test / unit / org / apache / cassandra / db / ColumnFamilyTest . java 
 @ @ - 20 , 8 + 20 , 6 @ @ package org . apache . cassandra . db ; 
 
 import java . io . IOException ; 
 import java . util . Arrays ; 
 - import java . util . HashSet ; 
 - import java . util . Random ; 
 import java . util . TreeMap ; 
 
 import org . junit . Test ; 
 @ @ - 125 , 8 + 123 , 8 @ @ public class ColumnFamilyTest 
 cf _ old . addColumn ( QueryPath . column ( " col2 " . getBytes ( ) ) , val2 , 1 ) ; 
 cf _ old . addColumn ( QueryPath . column ( " col3 " . getBytes ( ) ) , val2 , 2 ) ; 
 
 - cf _ result . addColumns ( cf _ new ) ; 
 - cf _ result . addColumns ( cf _ old ) ; 
 + cf _ result . addAll ( cf _ new ) ; 
 + cf _ result . addAll ( cf _ old ) ; 
 
 assert 3 = = cf _ result . getColumnCount ( ) : " Count is " + cf _ new . getColumnCount ( ) ; 
 / / addcolumns will only add if timestamp > = old timestamp
