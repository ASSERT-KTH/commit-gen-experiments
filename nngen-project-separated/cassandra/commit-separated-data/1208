BLEU SCORE: 0.03089055318156698

TEST MSG: Don ' t account for unconsumed data when checking if past sstable index
GENERATED MSG: replace compactionlock use in schema migration by checking CFS . isInvalidD

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 5fdeae5 . . 1ff2fdb 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 3 . 0 <nl> + * Fix reading of legacy sstables ( CASSANDRA - 10590 ) <nl> * Use CQL type names in schema metadata tables ( CASSANDRA - 10365 ) <nl> * Guard batchlog replay against integer division by zero ( CASSANDRA - 9223 ) <nl> * Fix bug when adding a column to thrift with the same name than a primary key ( CASSANDRA - 10608 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java b / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java <nl> index 52de159 . . 66f6b71 100644 <nl> - - - a / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java <nl> + + + b / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java <nl> @ @ - 29 , 6 + 29 , 7 @ @ import org . slf4j . LoggerFactory ; <nl> import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . db . rows . * ; <nl> import org . apache . cassandra . io . util . DataInputPlus ; <nl> + import org . apache . cassandra . io . util . FileDataInput ; <nl> import org . apache . cassandra . net . MessagingService ; <nl> <nl> / * * <nl> @ @ - 107 , 6 + 108 , 20 @ @ public abstract class UnfilteredDeserializer <nl> * / <nl> public abstract void skipNext ( ) throws IOException ; <nl> <nl> + <nl> + / * * <nl> + * For the legacy layout deserializer , we have to deal with the fact that a row can span multiple index blocks and that <nl> + * the call to hasNext ( ) reads the next element upfront . We must take that into account when we check in AbstractSSTableIterator if <nl> + * we ' re past the end of an index block boundary as that check expect to account for only consumed data ( that is , if hasNext has <nl> + * been called and made us cross an index boundary but neither readNext ( ) or skipNext ( ) as yet been called , we shouldn ' t consider <nl> + * the index block boundary crossed yet ) . <nl> + * <nl> + * TODO : we don ' t care about this for the current file format because a row can never span multiple index blocks ( further , hasNext ( ) <nl> + * only just basically read 2 bytes from disk in that case ) . So once we drop backward compatibility with pre - 3 . 0 sstable , we should <nl> + * remove this . <nl> + * / <nl> + public abstract long bytesReadForUnconsumedData ( ) ; <nl> + <nl> private static class CurrentDeserializer extends UnfilteredDeserializer <nl> { <nl> private final ClusteringPrefix . Deserializer clusteringDeserializer ; <nl> @ @ - 216 , 6 + 231 , 13 @ @ public abstract class UnfilteredDeserializer <nl> isReady = false ; <nl> isDone = false ; <nl> } <nl> + <nl> + public long bytesReadForUnconsumedData ( ) <nl> + { <nl> + / / In theory , hasNext ( ) does consume 2 - 3 bytes , but we don ' t care about this for the current file format so returning <nl> + / / 0 to mean " do nothing " . <nl> + return 0 ; <nl> + } <nl> } <nl> <nl> public static class OldFormatDeserializer extends UnfilteredDeserializer <nl> @ @ - 233 , 8 + 255 , 8 @ @ public abstract class UnfilteredDeserializer <nl> / / The Unfiltered as read from the old format input <nl> private final UnfilteredIterator iterator ; <nl> <nl> - / / Tracks which tombstone are opened at any given point of the deserialization . Note that this <nl> - / / is directly populated by UnfilteredIterator . <nl> + / / The position in the input after the last data consumption ( readNext / skipNext ) . <nl> + private long lastConsumedPosition ; <nl> <nl> private OldFormatDeserializer ( CFMetaData metadata , <nl> DataInputPlus in , <nl> @ @ - 245 , 6 + 267 , 7 @ @ public abstract class UnfilteredDeserializer <nl> super ( metadata , in , helper ) ; <nl> this . iterator = new UnfilteredIterator ( partitionDeletion ) ; <nl> this . readAllAsDynamic = readAllAsDynamic ; <nl> + this . lastConsumedPosition = currentPosition ( ) ; <nl> } <nl> <nl> public void setSkipStatic ( ) <nl> @ @ - 322 , 12 + 345 , 20 @ @ public abstract class UnfilteredDeserializer <nl> return nextIsRow ( ) & & ( ( Row ) next ) . isStatic ( ) ; <nl> } <nl> <nl> + private long currentPosition ( ) <nl> + { <nl> + / / We return a bogus value if the input is not file based , but check we never rely <nl> + / / on that value in that case in bytesReadForUnconsumedData <nl> + return in instanceof FileDataInput ? ( ( FileDataInput ) in ) . getFilePointer ( ) : 0 ; <nl> + } <nl> + <nl> public Unfiltered readNext ( ) throws IOException <nl> { <nl> if ( ! hasNext ( ) ) <nl> throw new IllegalStateException ( ) ; <nl> Unfiltered toReturn = next ; <nl> next = null ; <nl> + lastConsumedPosition = currentPosition ( ) ; <nl> return toReturn ; <nl> } <nl> <nl> @ @ - 336 , 6 + 367 , 15 @ @ public abstract class UnfilteredDeserializer <nl> if ( ! hasNext ( ) ) <nl> throw new UnsupportedOperationException ( ) ; <nl> next = null ; <nl> + lastConsumedPosition = currentPosition ( ) ; <nl> + } <nl> + <nl> + public long bytesReadForUnconsumedData ( ) <nl> + { <nl> + if ( ! ( in instanceof FileDataInput ) ) <nl> + throw new AssertionError ( ) ; <nl> + <nl> + return currentPosition ( ) - lastConsumedPosition ; <nl> } <nl> <nl> public void clearState ( ) <nl> @ @ - 343 , 6 + 383 , 7 @ @ public abstract class UnfilteredDeserializer <nl> next = null ; <nl> saved = null ; <nl> iterator . clearState ( ) ; <nl> + lastConsumedPosition = currentPosition ( ) ; <nl> } <nl> <nl> / / Groups atoms from the input into proper Unfiltered . <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / AbstractSSTableIterator . java b / src / java / org / apache / cassandra / db / columniterator / AbstractSSTableIterator . java <nl> index 8900b31 . . 5f280d7 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / AbstractSSTableIterator . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / AbstractSSTableIterator . java <nl> @ @ - 486 , 7 + 486 , 9 @ @ abstract class AbstractSSTableIterator implements SliceableUnfilteredRowIterator <nl> / / Check if we ' ve crossed an index boundary ( based on the mark on the beginning of the index block ) . <nl> public boolean isPastCurrentBlock ( ) <nl> { <nl> - return reader . file . bytesPastMark ( mark ) > = currentIndex ( ) . width ; <nl> + assert reader . deserializer ! = null ; <nl> + long correction = reader . deserializer . bytesReadForUnconsumedData ( ) ; <nl> + return reader . file . bytesPastMark ( mark ) - correction > = currentIndex ( ) . width ; <nl> } <nl> <nl> public int currentBlockIdx ( ) <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java <nl> index 01a8fb2 . . 66c32ee 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java <nl> @ @ - 155 , 23 + 155 , 17 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> buffer . reset ( ) ; <nl> <nl> boolean isFirst = true ; <nl> - boolean isDone = false ; <nl> <nl> / / If the start might be in this block , skip everything that comes before it . <nl> if ( start ! = null ) <nl> { <nl> - while ( ! isDone & & deserializer . hasNext ( ) & & deserializer . compareNextTo ( start ) < = 0 ) <nl> + while ( deserializer . hasNext ( ) & & deserializer . compareNextTo ( start ) < = 0 & & ! stopReadingDisk ( ) ) <nl> { <nl> isFirst = false ; <nl> if ( deserializer . nextIsRow ( ) ) <nl> deserializer . skipNext ( ) ; <nl> else <nl> updateOpenMarker ( ( RangeTombstoneMarker ) deserializer . readNext ( ) ) ; <nl> - <nl> - / / Note that because ' deserializer . hasNext ( ) ' may advance our file pointer , we need to always check stopReadingDisk ( ) before any call to it , <nl> - / / i . e . just after we ' ve called readNext / skipNext <nl> - if ( stopReadingDisk ( ) ) <nl> - isDone = true ; <nl> } <nl> } <nl> <nl> @ @ - 183 , 17 + 177 , 14 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> } <nl> <nl> / / Now deserialize everything until we reach our requested end ( if we have one ) <nl> - while ( ! isDone <nl> - & & deserializer . hasNext ( ) <nl> - & & ( end = = null | | deserializer . compareNextTo ( end ) < = 0 ) ) <nl> + while ( deserializer . hasNext ( ) <nl> + & & ( end = = null | | deserializer . compareNextTo ( end ) < = 0 ) <nl> + & & ! stopReadingDisk ( ) ) <nl> { <nl> Unfiltered unfiltered = deserializer . readNext ( ) ; <nl> if ( ! isFirst | | includeFirst ) <nl> buffer . add ( unfiltered ) ; <nl> <nl> - if ( stopReadingDisk ( ) ) <nl> - isDone = true ; <nl> - <nl> isFirst = false ; <nl> <nl> if ( unfiltered . isRangeTombstoneMarker ( ) )
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index dc86de1 . . 7512c9d 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 3 , 6 + 3 , 8 @ @ <nl> * cleanup usage of StorageService . setMode ( ) ( CASANDRA - 3388 ) <nl> * Add timing information to cassandra - cli GET / SET / LIST queries ( CASSANDRA - 3326 ) <nl> * Cache for CompressionMetadata objects ( CASSANDRA - 3427 ) <nl> + * synchronize BiMap of bootstrapping tokens ( CASSANDRA - 3417 ) <nl> + <nl> <nl> 1 . 0 . 1 <nl> * acquire references during index build to prevent delete problems <nl> diff - - git a / conf / cassandra - env . sh b / conf / cassandra - env . sh <nl> index c21b363 . . 1c3c0ed 100644 <nl> - - - a / conf / cassandra - env . sh <nl> + + + b / conf / cassandra - env . sh <nl> @ @ - 165 , 6 + 165 , 7 @ @ JVM _ OPTS = " $ JVM _ OPTS - XX : + UseCMSInitiatingOccupancyOnly " <nl> # GC logging options - - uncomment to enable <nl> # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintGCDetails " <nl> # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintGCTimeStamps " <nl> + # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintHeapAtGC " <nl> # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintTenuringDistribution " <nl> # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintGCApplicationStoppedTime " <nl> # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintPromotionFailure " <nl> diff - - git a / src / java / org / apache / cassandra / locator / TokenMetadata . java b / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> index 196e15e . . b648656 100644 <nl> - - - a / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> + + + b / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> @ @ - 67 , 7 + 67 , 7 @ @ public class TokenMetadata <nl> / / Finally , note that recording the tokens of joining nodes in bootstrapTokens also <nl> / / means we can detect and reject the addition of multiple nodes at the same token <nl> / / before one becomes part of the ring . <nl> - private BiMap < Token , InetAddress > bootstrapTokens = HashBiMap . create ( ) ; <nl> + private BiMap < Token , InetAddress > bootstrapTokens = Maps . synchronizedBiMap ( HashBiMap . < Token , InetAddress > create ( ) ) ; <nl> / / ( don ' t need to record Token here since it ' s still part of tokenToEndpointMap until it ' s done leaving ) <nl> private Set < InetAddress > leavingEndpoints = new HashSet < InetAddress > ( ) ; <nl> / / this is a cache of the calculation from { tokenToEndpointMap , bootstrapTokens , leavingEndpoints }

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 5fdeae5 . . 1ff2fdb 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 3 . 0 
 + * Fix reading of legacy sstables ( CASSANDRA - 10590 ) 
 * Use CQL type names in schema metadata tables ( CASSANDRA - 10365 ) 
 * Guard batchlog replay against integer division by zero ( CASSANDRA - 9223 ) 
 * Fix bug when adding a column to thrift with the same name than a primary key ( CASSANDRA - 10608 ) 
 diff - - git a / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java b / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java 
 index 52de159 . . 66f6b71 100644 
 - - - a / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java 
 + + + b / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java 
 @ @ - 29 , 6 + 29 , 7 @ @ import org . slf4j . LoggerFactory ; 
 import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . db . rows . * ; 
 import org . apache . cassandra . io . util . DataInputPlus ; 
 + import org . apache . cassandra . io . util . FileDataInput ; 
 import org . apache . cassandra . net . MessagingService ; 
 
 / * * 
 @ @ - 107 , 6 + 108 , 20 @ @ public abstract class UnfilteredDeserializer 
 * / 
 public abstract void skipNext ( ) throws IOException ; 
 
 + 
 + / * * 
 + * For the legacy layout deserializer , we have to deal with the fact that a row can span multiple index blocks and that 
 + * the call to hasNext ( ) reads the next element upfront . We must take that into account when we check in AbstractSSTableIterator if 
 + * we ' re past the end of an index block boundary as that check expect to account for only consumed data ( that is , if hasNext has 
 + * been called and made us cross an index boundary but neither readNext ( ) or skipNext ( ) as yet been called , we shouldn ' t consider 
 + * the index block boundary crossed yet ) . 
 + * 
 + * TODO : we don ' t care about this for the current file format because a row can never span multiple index blocks ( further , hasNext ( ) 
 + * only just basically read 2 bytes from disk in that case ) . So once we drop backward compatibility with pre - 3 . 0 sstable , we should 
 + * remove this . 
 + * / 
 + public abstract long bytesReadForUnconsumedData ( ) ; 
 + 
 private static class CurrentDeserializer extends UnfilteredDeserializer 
 { 
 private final ClusteringPrefix . Deserializer clusteringDeserializer ; 
 @ @ - 216 , 6 + 231 , 13 @ @ public abstract class UnfilteredDeserializer 
 isReady = false ; 
 isDone = false ; 
 } 
 + 
 + public long bytesReadForUnconsumedData ( ) 
 + { 
 + / / In theory , hasNext ( ) does consume 2 - 3 bytes , but we don ' t care about this for the current file format so returning 
 + / / 0 to mean " do nothing " . 
 + return 0 ; 
 + } 
 } 
 
 public static class OldFormatDeserializer extends UnfilteredDeserializer 
 @ @ - 233 , 8 + 255 , 8 @ @ public abstract class UnfilteredDeserializer 
 / / The Unfiltered as read from the old format input 
 private final UnfilteredIterator iterator ; 
 
 - / / Tracks which tombstone are opened at any given point of the deserialization . Note that this 
 - / / is directly populated by UnfilteredIterator . 
 + / / The position in the input after the last data consumption ( readNext / skipNext ) . 
 + private long lastConsumedPosition ; 
 
 private OldFormatDeserializer ( CFMetaData metadata , 
 DataInputPlus in , 
 @ @ - 245 , 6 + 267 , 7 @ @ public abstract class UnfilteredDeserializer 
 super ( metadata , in , helper ) ; 
 this . iterator = new UnfilteredIterator ( partitionDeletion ) ; 
 this . readAllAsDynamic = readAllAsDynamic ; 
 + this . lastConsumedPosition = currentPosition ( ) ; 
 } 
 
 public void setSkipStatic ( ) 
 @ @ - 322 , 12 + 345 , 20 @ @ public abstract class UnfilteredDeserializer 
 return nextIsRow ( ) & & ( ( Row ) next ) . isStatic ( ) ; 
 } 
 
 + private long currentPosition ( ) 
 + { 
 + / / We return a bogus value if the input is not file based , but check we never rely 
 + / / on that value in that case in bytesReadForUnconsumedData 
 + return in instanceof FileDataInput ? ( ( FileDataInput ) in ) . getFilePointer ( ) : 0 ; 
 + } 
 + 
 public Unfiltered readNext ( ) throws IOException 
 { 
 if ( ! hasNext ( ) ) 
 throw new IllegalStateException ( ) ; 
 Unfiltered toReturn = next ; 
 next = null ; 
 + lastConsumedPosition = currentPosition ( ) ; 
 return toReturn ; 
 } 
 
 @ @ - 336 , 6 + 367 , 15 @ @ public abstract class UnfilteredDeserializer 
 if ( ! hasNext ( ) ) 
 throw new UnsupportedOperationException ( ) ; 
 next = null ; 
 + lastConsumedPosition = currentPosition ( ) ; 
 + } 
 + 
 + public long bytesReadForUnconsumedData ( ) 
 + { 
 + if ( ! ( in instanceof FileDataInput ) ) 
 + throw new AssertionError ( ) ; 
 + 
 + return currentPosition ( ) - lastConsumedPosition ; 
 } 
 
 public void clearState ( ) 
 @ @ - 343 , 6 + 383 , 7 @ @ public abstract class UnfilteredDeserializer 
 next = null ; 
 saved = null ; 
 iterator . clearState ( ) ; 
 + lastConsumedPosition = currentPosition ( ) ; 
 } 
 
 / / Groups atoms from the input into proper Unfiltered . 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / AbstractSSTableIterator . java b / src / java / org / apache / cassandra / db / columniterator / AbstractSSTableIterator . java 
 index 8900b31 . . 5f280d7 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / AbstractSSTableIterator . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / AbstractSSTableIterator . java 
 @ @ - 486 , 7 + 486 , 9 @ @ abstract class AbstractSSTableIterator implements SliceableUnfilteredRowIterator 
 / / Check if we ' ve crossed an index boundary ( based on the mark on the beginning of the index block ) . 
 public boolean isPastCurrentBlock ( ) 
 { 
 - return reader . file . bytesPastMark ( mark ) > = currentIndex ( ) . width ; 
 + assert reader . deserializer ! = null ; 
 + long correction = reader . deserializer . bytesReadForUnconsumedData ( ) ; 
 + return reader . file . bytesPastMark ( mark ) - correction > = currentIndex ( ) . width ; 
 } 
 
 public int currentBlockIdx ( ) 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java 
 index 01a8fb2 . . 66c32ee 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java 
 @ @ - 155 , 23 + 155 , 17 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 buffer . reset ( ) ; 
 
 boolean isFirst = true ; 
 - boolean isDone = false ; 
 
 / / If the start might be in this block , skip everything that comes before it . 
 if ( start ! = null ) 
 { 
 - while ( ! isDone & & deserializer . hasNext ( ) & & deserializer . compareNextTo ( start ) < = 0 ) 
 + while ( deserializer . hasNext ( ) & & deserializer . compareNextTo ( start ) < = 0 & & ! stopReadingDisk ( ) ) 
 { 
 isFirst = false ; 
 if ( deserializer . nextIsRow ( ) ) 
 deserializer . skipNext ( ) ; 
 else 
 updateOpenMarker ( ( RangeTombstoneMarker ) deserializer . readNext ( ) ) ; 
 - 
 - / / Note that because ' deserializer . hasNext ( ) ' may advance our file pointer , we need to always check stopReadingDisk ( ) before any call to it , 
 - / / i . e . just after we ' ve called readNext / skipNext 
 - if ( stopReadingDisk ( ) ) 
 - isDone = true ; 
 } 
 } 
 
 @ @ - 183 , 17 + 177 , 14 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 } 
 
 / / Now deserialize everything until we reach our requested end ( if we have one ) 
 - while ( ! isDone 
 - & & deserializer . hasNext ( ) 
 - & & ( end = = null | | deserializer . compareNextTo ( end ) < = 0 ) ) 
 + while ( deserializer . hasNext ( ) 
 + & & ( end = = null | | deserializer . compareNextTo ( end ) < = 0 ) 
 + & & ! stopReadingDisk ( ) ) 
 { 
 Unfiltered unfiltered = deserializer . readNext ( ) ; 
 if ( ! isFirst | | includeFirst ) 
 buffer . add ( unfiltered ) ; 
 
 - if ( stopReadingDisk ( ) ) 
 - isDone = true ; 
 - 
 isFirst = false ; 
 
 if ( unfiltered . isRangeTombstoneMarker ( ) )

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index dc86de1 . . 7512c9d 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 3 , 6 + 3 , 8 @ @ 
 * cleanup usage of StorageService . setMode ( ) ( CASANDRA - 3388 ) 
 * Add timing information to cassandra - cli GET / SET / LIST queries ( CASSANDRA - 3326 ) 
 * Cache for CompressionMetadata objects ( CASSANDRA - 3427 ) 
 + * synchronize BiMap of bootstrapping tokens ( CASSANDRA - 3417 ) 
 + 
 
 1 . 0 . 1 
 * acquire references during index build to prevent delete problems 
 diff - - git a / conf / cassandra - env . sh b / conf / cassandra - env . sh 
 index c21b363 . . 1c3c0ed 100644 
 - - - a / conf / cassandra - env . sh 
 + + + b / conf / cassandra - env . sh 
 @ @ - 165 , 6 + 165 , 7 @ @ JVM _ OPTS = " $ JVM _ OPTS - XX : + UseCMSInitiatingOccupancyOnly " 
 # GC logging options - - uncomment to enable 
 # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintGCDetails " 
 # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintGCTimeStamps " 
 + # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintHeapAtGC " 
 # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintTenuringDistribution " 
 # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintGCApplicationStoppedTime " 
 # JVM _ OPTS = " $ JVM _ OPTS - XX : + PrintPromotionFailure " 
 diff - - git a / src / java / org / apache / cassandra / locator / TokenMetadata . java b / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 index 196e15e . . b648656 100644 
 - - - a / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 + + + b / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 @ @ - 67 , 7 + 67 , 7 @ @ public class TokenMetadata 
 / / Finally , note that recording the tokens of joining nodes in bootstrapTokens also 
 / / means we can detect and reject the addition of multiple nodes at the same token 
 / / before one becomes part of the ring . 
 - private BiMap < Token , InetAddress > bootstrapTokens = HashBiMap . create ( ) ; 
 + private BiMap < Token , InetAddress > bootstrapTokens = Maps . synchronizedBiMap ( HashBiMap . < Token , InetAddress > create ( ) ) ; 
 / / ( don ' t need to record Token here since it ' s still part of tokenToEndpointMap until it ' s done leaving ) 
 private Set < InetAddress > leavingEndpoints = new HashSet < InetAddress > ( ) ; 
 / / this is a cache of the calculation from { tokenToEndpointMap , bootstrapTokens , leavingEndpoints }
