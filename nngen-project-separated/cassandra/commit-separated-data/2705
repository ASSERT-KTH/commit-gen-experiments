BLEU SCORE: 0.02383853510228548

TEST MSG: Disallow post - query re - ordering when paging
GENERATED MSG: drain method

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index a5e1016 . . b25ff47 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 20 , 6 + 20 , 7 @ @ <nl> * Fix replaying pre - 2 . 0 commit logs ( CASSANDRA - 6714 ) <nl> * Add static columns to CQL3 ( CASSANDRA - 6561 ) <nl> * Optimize single partition batch statements ( CASSANDRA - 6737 ) <nl> + * Disallow post - query re - ordering when paging ( CASSANDRA - 6722 ) <nl> Merged from 1 . 2 : <nl> * Catch memtable flush exceptions during shutdown ( CASSANDRA - 6735 ) <nl> * Fix broken streams when replacing with same IP ( CASSANDRA - 6622 ) <nl> diff - - git a / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java b / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java <nl> index 2636c83 . . 9fbed03 100644 <nl> - - - a / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java <nl> + + + b / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java <nl> @ @ - 219 , 6 + 219 , 11 @ @ public class SelectStatement implements CQLStatement , MeasurableForPreparedCache <nl> if ( parameters . isCount ) <nl> return pageCountQuery ( pager , variables , pageSize , now ) ; <nl> <nl> + / / We can ' t properly do post - query ordering if we page ( see # 6722 ) <nl> + if ( needsPostQueryOrdering ( ) ) <nl> + throw new InvalidRequestException ( " Cannot page queries with both ORDER BY and a IN restriction on the partition key ; you must either remove the " <nl> + + " ORDER BY or the IN and sort client side , or disable paging for this query " ) ; <nl> + <nl> List < Row > page = pager . fetchPage ( pageSize ) ; <nl> ResultMessage . Rows msg = processResults ( page , variables , limit , now ) ; <nl> if ( ! pager . isExhausted ( ) ) <nl> @ @ - 931 , 56 + 936 , 6 @ @ public class SelectStatement implements CQLStatement , MeasurableForPreparedCache <nl> return expressions ; <nl> } <nl> <nl> - private Iterable < Column > columnsInOrder ( final ColumnFamily cf , final List < ByteBuffer > variables ) throws InvalidRequestException <nl> - { <nl> - if ( columnRestrictions . length = = 0 ) <nl> - return cf . getSortedColumns ( ) ; <nl> - <nl> - / / If the restriction for the last column alias is an IN , respect <nl> - / / requested order <nl> - Restriction last = columnRestrictions [ columnRestrictions . length - 1 ] ; <nl> - if ( last = = null | | last . isSlice ( ) ) <nl> - return cf . getSortedColumns ( ) ; <nl> - <nl> - ColumnNameBuilder builder = cfDef . getColumnNameBuilder ( ) ; <nl> - for ( int i = 0 ; i < columnRestrictions . length - 1 ; i + + ) <nl> - builder . add ( columnRestrictions [ i ] . values ( variables ) . get ( 0 ) ) ; <nl> - <nl> - <nl> - List < ByteBuffer > values = last . values ( variables ) ; <nl> - final List < ByteBuffer > requested = new ArrayList < ByteBuffer > ( values . size ( ) ) ; <nl> - Iterator < ByteBuffer > iter = values . iterator ( ) ; <nl> - while ( iter . hasNext ( ) ) <nl> - { <nl> - ByteBuffer t = iter . next ( ) ; <nl> - ColumnNameBuilder b = iter . hasNext ( ) ? builder . copy ( ) : builder ; <nl> - requested . add ( b . add ( t ) . build ( ) ) ; <nl> - } <nl> - <nl> - return new Iterable < Column > ( ) <nl> - { <nl> - public Iterator < Column > iterator ( ) <nl> - { <nl> - return new AbstractIterator < Column > ( ) <nl> - { <nl> - / / If the query is reversed , we ' ll reverse everything in the end , so return the <nl> - / / requested in reversed order so we do return values in requested order in the end <nl> - Iterator < ByteBuffer > iter = ( isReversed ? Lists . reverse ( requested ) : requested ) . iterator ( ) ; <nl> - public Column computeNext ( ) <nl> - { <nl> - while ( iter . hasNext ( ) ) <nl> - { <nl> - Column column = cf . getColumn ( iter . next ( ) ) ; <nl> - if ( column ! = null ) <nl> - return column ; <nl> - } <nl> - return endOfData ( ) ; <nl> - } <nl> - } ; <nl> - } <nl> - } ; <nl> - } <nl> - <nl> private ResultSet process ( List < Row > rows , List < ByteBuffer > variables , int limit , long now ) throws InvalidRequestException <nl> { <nl> Selection . ResultSetBuilder result = selection . resultSetBuilder ( now ) ; <nl> @ @ - 1027 , 7 + 982 , 7 @ @ public class SelectStatement implements CQLStatement , MeasurableForPreparedCache <nl> else if ( cfDef . isCompact ) <nl> { <nl> / / One cqlRow per column <nl> - for ( Column c : columnsInOrder ( cf , variables ) ) <nl> + for ( Column c : cf ) <nl> { <nl> if ( c . isMarkedForDelete ( now ) ) <nl> continue ; <nl> @ @ - 1144 , 16 + 1099 , 18 @ @ public class SelectStatement implements CQLStatement , MeasurableForPreparedCache <nl> return true ; <nl> } <nl> <nl> + private boolean needsPostQueryOrdering ( ) <nl> + { <nl> + / / We need post - query ordering only for queries with IN on the partition key and an ORDER BY . <nl> + return keyIsInRelation & & ! parameters . orderings . isEmpty ( ) ; <nl> + } <nl> + <nl> / * * <nl> * Orders results when multiple keys are selected ( using IN ) <nl> * / <nl> private void orderResults ( ResultSet cqlRows ) <nl> { <nl> - / / There is nothing to do if <nl> - / / a . there are no results , <nl> - / / b . no ordering information where given , <nl> - / / c . key restriction is a Range or not an IN expression <nl> - if ( cqlRows . size ( ) = = 0 | | parameters . orderings . isEmpty ( ) | | isKeyRange | | ! keyIsInRelation ) <nl> + if ( cqlRows . size ( ) = = 0 | | ! needsPostQueryOrdering ( ) ) <nl> return ; <nl> <nl> assert orderingIndexes ! = null ;
NEAREST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java <nl> index 6c20cd0 . . a1a6d15 100644 <nl> - - - a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java <nl> + + + b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java <nl> @ @ - 39 , 6 + 39 , 7 @ @ import org . slf4j . LoggerFactory ; <nl> <nl> import java . io . * ; <nl> import java . util . * ; <nl> + import java . util . concurrent . atomic . AtomicInteger ; <nl> import java . util . zip . Checksum ; <nl> import java . util . zip . CRC32 ; <nl> import java . util . concurrent . Callable ; <nl> @ @ - 173 , 12 + 174 , 10 @ @ public class CommitLog <nl> logger . info ( " Log replay complete " ) ; <nl> } <nl> <nl> - <nl> public static void recover ( File [ ] clogs ) throws IOException <nl> { <nl> Set < Table > tablesRecovered = new HashSet < Table > ( ) ; <nl> - assert StageManager . getStage ( StageManager . MUTATION _ STAGE ) . getCompletedTaskCount ( ) = = 0 ; <nl> - int rows = 0 ; <nl> + final AtomicInteger counter = new AtomicInteger ( 0 ) ; <nl> for ( File file : clogs ) <nl> { <nl> int bufferSize = ( int ) Math . min ( file . length ( ) , 32 * 1024 * 1024 ) ; <nl> @ @ - 263 , 16 + 262 , 17 @ @ public class CommitLog <nl> { <nl> Table . open ( newRm . getTable ( ) ) . apply ( newRm , null , false ) ; <nl> } <nl> + counter . decrementAndGet ( ) ; <nl> } <nl> } ; <nl> - StageManager . getStage ( StageManager . MUTATION _ STAGE ) . execute ( runnable ) ; <nl> - rows + + ; <nl> + counter . incrementAndGet ( ) ; <nl> + StageManager . getStage ( StageManager . MUTATION _ STAGE ) . submit ( runnable ) ; <nl> } <nl> reader . close ( ) ; <nl> } <nl> <nl> / / wait for all the writes to finish on the mutation stage <nl> - while ( StageManager . getStage ( StageManager . MUTATION _ STAGE ) . getCompletedTaskCount ( ) < rows ) <nl> + while ( counter . get ( ) > 0 ) <nl> { <nl> try <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / io / DeletionService . java b / src / java / org / apache / cassandra / io / DeletionService . java <nl> index 9a534fe . . ae8a271 100644 <nl> - - - a / src / java / org / apache / cassandra / io / DeletionService . java <nl> + + + b / src / java / org / apache / cassandra / io / DeletionService . java <nl> @ @ - 23 , 6 + 23 , 7 @ @ package org . apache . cassandra . io ; <nl> <nl> import java . io . File ; <nl> import java . io . IOException ; <nl> + import java . util . concurrent . ExecutionException ; <nl> import java . util . concurrent . ExecutorService ; <nl> <nl> import org . apache . cassandra . concurrent . JMXEnabledThreadPoolExecutor ; <nl> @ @ - 48 , 6 + 49 , 11 @ @ public class DeletionService <nl> } ; <nl> executor . submit ( deleter ) ; <nl> } <nl> + <nl> + public static void waitFor ( ) throws InterruptedException , ExecutionException <nl> + { <nl> + executor . submit ( new Runnable ( ) { public void run ( ) { } } ) . get ( ) ; <nl> + } <nl> <nl> public static void submitDeleteWithRetry ( String file ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java <nl> index 02453f1 . . 79a4458 100644 <nl> - - - a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java <nl> + + + b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java <nl> @ @ - 164 , 7 + 164 , 7 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> { <nl> if ( syncNeeded _ ) <nl> { <nl> - flush ( ) ; <nl> + flushBuffer ( ) ; <nl> getChannel ( ) . force ( true ) ; / / true , because file length counts as " metadata " <nl> syncNeeded _ = false ; <nl> } <nl> @ @ - 172 , 20 + 172 , 11 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> <nl> public void close ( ) throws IOException <nl> { <nl> - this . flush ( ) ; <nl> + sync ( ) ; <nl> this . buff _ = null ; <nl> super . close ( ) ; <nl> } <nl> <nl> - / * * <nl> - * Flush any bytes in the file ' s buffer that have not yet been written to <nl> - * disk . If the file was created read - only , this method is a no - op . <nl> - * / <nl> - public void flush ( ) throws IOException <nl> - { <nl> - this . flushBuffer ( ) ; <nl> - } <nl> - <nl> / * Flush any dirty bytes in the buffer to disk . * / <nl> private void flushBuffer ( ) throws IOException <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / net / MessagingService . java b / src / java / org / apache / cassandra / net / MessagingService . java <nl> index 409a21e . . e0329c7 100644 <nl> - - - a / src / java / org / apache / cassandra / net / MessagingService . java <nl> + + + b / src / java / org / apache / cassandra / net / MessagingService . java <nl> @ @ - 32 , 12 + 32 , 14 @ @ import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> + import java . io . IOError ; <nl> import java . io . IOException ; <nl> import java . net . ServerSocket ; <nl> import java . net . InetAddress ; <nl> import java . net . InetSocketAddress ; <nl> import java . net . Socket ; <nl> import java . nio . ByteBuffer ; <nl> + import java . nio . channels . AsynchronousCloseException ; <nl> import java . nio . channels . ServerSocketChannel ; <nl> import java . security . MessageDigest ; <nl> import java . util . * ; <nl> @ @ - 74 , 6 + 76 , 8 @ @ public class MessagingService implements IFailureDetectionEventListener <nl> private static Logger logger _ = LoggerFactory . getLogger ( MessagingService . class ) ; <nl> <nl> public static final MessagingService instance = new MessagingService ( ) ; <nl> + <nl> + private SocketThread socketThread ; <nl> <nl> public static int getVersion ( ) <nl> { <nl> @ @ - 141 , 25 + 145 , 9 @ @ public class MessagingService implements IFailureDetectionEventListener <nl> final ServerSocket ss = serverChannel . socket ( ) ; <nl> ss . setReuseAddress ( true ) ; <nl> ss . bind ( new InetSocketAddress ( localEp , DatabaseDescriptor . getStoragePort ( ) ) ) ; <nl> + socketThread = new SocketThread ( ss , " ACCEPT - " + localEp ) ; <nl> + socketThread . start ( ) ; <nl> <nl> - new Thread ( new Runnable ( ) <nl> - { <nl> - public void run ( ) <nl> - { <nl> - while ( true ) <nl> - { <nl> - try <nl> - { <nl> - Socket socket = ss . accept ( ) ; <nl> - new IncomingTcpConnection ( socket ) . start ( ) ; <nl> - } <nl> - catch ( IOException e ) <nl> - { <nl> - throw new RuntimeException ( e ) ; <nl> - } <nl> - } <nl> - } <nl> - } , " ACCEPT - " + localEp ) . start ( ) ; <nl> } <nl> <nl> public static OutboundTcpConnectionPool getConnectionPool ( InetAddress to ) <nl> @ @ - 338 , 14 + 326 , 31 @ @ public class MessagingService implements IFailureDetectionEventListener <nl> Runnable streamingTask = new FileStreamTask ( file , startPosition , endPosition , from , to ) ; <nl> streamExecutor _ . execute ( streamingTask ) ; <nl> } <nl> + <nl> + / * * blocks until the processing pools are empty and done . * / <nl> + public static void waitFor ( ) throws InterruptedException <nl> + { <nl> + while ( ! messageDeserializerExecutor _ . isTerminated ( ) ) <nl> + messageDeserializerExecutor _ . awaitTermination ( 5 , TimeUnit . SECONDS ) ; <nl> + while ( ! streamExecutor _ . isTerminated ( ) ) <nl> + streamExecutor _ . awaitTermination ( 5 , TimeUnit . SECONDS ) ; <nl> + } <nl> <nl> public static void shutdown ( ) <nl> { <nl> - logger _ . info ( " Shutting down . . . " ) ; <nl> + logger _ . info ( " Shutting down MessageService . . . " ) ; <nl> + <nl> + try <nl> + { <nl> + instance . socketThread . close ( ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new IOError ( e ) ; <nl> + } <nl> <nl> messageDeserializerExecutor _ . shutdownNow ( ) ; <nl> streamExecutor _ . shutdownNow ( ) ; <nl> - StageManager . shutdownNow ( ) ; <nl> <nl> / * shut down the cachetables * / <nl> taskCompletionMap _ . shutdown ( ) ; <nl> @ @ - 467 , 4 + 472 , 42 @ @ public class MessagingService implements IFailureDetectionEventListener <nl> buffer . flip ( ) ; <nl> return buffer ; <nl> } <nl> + <nl> + private class SocketThread extends Thread <nl> + { <nl> + private final ServerSocket server ; <nl> + <nl> + SocketThread ( ServerSocket server , String name ) <nl> + { <nl> + super ( name ) ; <nl> + this . server = server ; <nl> + } <nl> + <nl> + public void run ( ) <nl> + { <nl> + while ( true ) <nl> + { <nl> + try <nl> + { <nl> + Socket socket = server . accept ( ) ; <nl> + new IncomingTcpConnection ( socket ) . start ( ) ; <nl> + } <nl> + catch ( AsynchronousCloseException e ) <nl> + { <nl> + / / this happens when another thread calls close ( ) . <nl> + logger _ . info ( " MessagingService shutting down server thread . " ) ; <nl> + break ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + void close ( ) throws IOException <nl> + { <nl> + server . close ( ) ; <nl> + } <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index f1404f6 . . 713ae51 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 37 , 8 + 37 , 10 @ @ import com . google . common . collect . Multimaps ; <nl> import org . apache . cassandra . concurrent . * ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . db . * ; <nl> + import org . apache . cassandra . db . commitlog . CommitLog ; <nl> import org . apache . cassandra . dht . * ; <nl> import org . apache . cassandra . gms . * ; <nl> + import org . apache . cassandra . io . DeletionService ; <nl> import org . apache . cassandra . io . sstable . SSTable ; <nl> import org . apache . cassandra . io . sstable . SSTableReader ; <nl> import org . apache . cassandra . locator . * ; <nl> @ @ - 273 , 6 + 275 , 7 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe <nl> Gossiper . instance . unregister ( this ) ; <nl> Gossiper . instance . stop ( ) ; <nl> MessagingService . shutdown ( ) ; <nl> + StageManager . shutdownNow ( ) ; <nl> } <nl> <nl> public synchronized void initClient ( ) throws IOException <nl> @ @ - 1301 , 6 + 1304 , 7 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe <nl> { <nl> Gossiper . instance . stop ( ) ; <nl> MessagingService . shutdown ( ) ; <nl> + StageManager . shutdownNow ( ) ; <nl> setMode ( " Decommissioned " , true ) ; <nl> / / let op be responsible for killing the process <nl> } <nl> @ @ - 1525 , 4 + 1529 , 43 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe <nl> tokenMetadata _ = tmd ; <nl> return old ; <nl> } <nl> + <nl> + / * * shuts node off to writes , empties memtables and the commit log . * / <nl> + public synchronized void drain ( ) throws IOException , InterruptedException , ExecutionException <nl> + { <nl> + ExecutorService mutationStage = StageManager . getStage ( StageManager . MUTATION _ STAGE ) ; <nl> + if ( mutationStage . isTerminated ( ) ) <nl> + { <nl> + logger _ . warn ( " Cannot drain node ( did it already happen ? ) " ) ; <nl> + return ; <nl> + } <nl> + setMode ( " Starting drain process " , true ) ; <nl> + Gossiper . instance . stop ( ) ; <nl> + setMode ( " Draining : shutting down MessageService " , false ) ; <nl> + MessagingService . shutdown ( ) ; <nl> + setMode ( " Draining : emptying MessageService pools " , false ) ; <nl> + MessagingService . waitFor ( ) ; <nl> + <nl> + / / lets flush . <nl> + setMode ( " Draining : flushing column families " , false ) ; <nl> + for ( String tableName : DatabaseDescriptor . getNonSystemTables ( ) ) <nl> + for ( Future f : Table . open ( tableName ) . flush ( ) ) <nl> + f . get ( ) ; <nl> + <nl> + <nl> + setMode ( " Draining : replaying commit log " , false ) ; <nl> + CommitLog . instance ( ) . forceNewSegment ( ) ; <nl> + / / want to make sure that any segments deleted as a result of flushing are gone . <nl> + DeletionService . waitFor ( ) ; <nl> + CommitLog . recover ( ) ; <nl> + <nl> + / / commit log recovery just sends work to the mutation stage . ( there could have already been work there anyway . <nl> + / / Either way , we need to let this one drain naturally , and then we ' re finished . <nl> + setMode ( " Draining : clearing mutation stage " , false ) ; <nl> + mutationStage . shutdown ( ) ; <nl> + while ( ! mutationStage . isTerminated ( ) ) <nl> + mutationStage . awaitTermination ( 5 , TimeUnit . SECONDS ) ; <nl> + <nl> + setMode ( " Node is drained " , true ) ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> index 638430e . . dc1e8b5 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> @ @ - 23 , 6 + 23 , 7 @ @ import java . net . UnknownHostException ; <nl> import java . util . List ; <nl> import java . util . Map ; <nl> import java . util . Set ; <nl> + import java . util . concurrent . ExecutionException ; <nl> import java . util . concurrent . FutureTask ; <nl> <nl> import org . apache . cassandra . dht . Range ; <nl> @ @ - 165 , 4 + 166 , 7 @ @ public interface StorageServiceMBean <nl> <nl> / * * get the operational mode ( leaving , joining , normal , decommissioned , client ) * * / <nl> public String getOperationMode ( ) ; <nl> + <nl> + / * * makes node unavailable for writes , flushes memtables and replays commitlog . * / <nl> + public void drain ( ) throws IOException , InterruptedException , ExecutionException ; <nl> }

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index a5e1016 . . b25ff47 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 20 , 6 + 20 , 7 @ @ 
 * Fix replaying pre - 2 . 0 commit logs ( CASSANDRA - 6714 ) 
 * Add static columns to CQL3 ( CASSANDRA - 6561 ) 
 * Optimize single partition batch statements ( CASSANDRA - 6737 ) 
 + * Disallow post - query re - ordering when paging ( CASSANDRA - 6722 ) 
 Merged from 1 . 2 : 
 * Catch memtable flush exceptions during shutdown ( CASSANDRA - 6735 ) 
 * Fix broken streams when replacing with same IP ( CASSANDRA - 6622 ) 
 diff - - git a / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java b / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java 
 index 2636c83 . . 9fbed03 100644 
 - - - a / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java 
 + + + b / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java 
 @ @ - 219 , 6 + 219 , 11 @ @ public class SelectStatement implements CQLStatement , MeasurableForPreparedCache 
 if ( parameters . isCount ) 
 return pageCountQuery ( pager , variables , pageSize , now ) ; 
 
 + / / We can ' t properly do post - query ordering if we page ( see # 6722 ) 
 + if ( needsPostQueryOrdering ( ) ) 
 + throw new InvalidRequestException ( " Cannot page queries with both ORDER BY and a IN restriction on the partition key ; you must either remove the " 
 + + " ORDER BY or the IN and sort client side , or disable paging for this query " ) ; 
 + 
 List < Row > page = pager . fetchPage ( pageSize ) ; 
 ResultMessage . Rows msg = processResults ( page , variables , limit , now ) ; 
 if ( ! pager . isExhausted ( ) ) 
 @ @ - 931 , 56 + 936 , 6 @ @ public class SelectStatement implements CQLStatement , MeasurableForPreparedCache 
 return expressions ; 
 } 
 
 - private Iterable < Column > columnsInOrder ( final ColumnFamily cf , final List < ByteBuffer > variables ) throws InvalidRequestException 
 - { 
 - if ( columnRestrictions . length = = 0 ) 
 - return cf . getSortedColumns ( ) ; 
 - 
 - / / If the restriction for the last column alias is an IN , respect 
 - / / requested order 
 - Restriction last = columnRestrictions [ columnRestrictions . length - 1 ] ; 
 - if ( last = = null | | last . isSlice ( ) ) 
 - return cf . getSortedColumns ( ) ; 
 - 
 - ColumnNameBuilder builder = cfDef . getColumnNameBuilder ( ) ; 
 - for ( int i = 0 ; i < columnRestrictions . length - 1 ; i + + ) 
 - builder . add ( columnRestrictions [ i ] . values ( variables ) . get ( 0 ) ) ; 
 - 
 - 
 - List < ByteBuffer > values = last . values ( variables ) ; 
 - final List < ByteBuffer > requested = new ArrayList < ByteBuffer > ( values . size ( ) ) ; 
 - Iterator < ByteBuffer > iter = values . iterator ( ) ; 
 - while ( iter . hasNext ( ) ) 
 - { 
 - ByteBuffer t = iter . next ( ) ; 
 - ColumnNameBuilder b = iter . hasNext ( ) ? builder . copy ( ) : builder ; 
 - requested . add ( b . add ( t ) . build ( ) ) ; 
 - } 
 - 
 - return new Iterable < Column > ( ) 
 - { 
 - public Iterator < Column > iterator ( ) 
 - { 
 - return new AbstractIterator < Column > ( ) 
 - { 
 - / / If the query is reversed , we ' ll reverse everything in the end , so return the 
 - / / requested in reversed order so we do return values in requested order in the end 
 - Iterator < ByteBuffer > iter = ( isReversed ? Lists . reverse ( requested ) : requested ) . iterator ( ) ; 
 - public Column computeNext ( ) 
 - { 
 - while ( iter . hasNext ( ) ) 
 - { 
 - Column column = cf . getColumn ( iter . next ( ) ) ; 
 - if ( column ! = null ) 
 - return column ; 
 - } 
 - return endOfData ( ) ; 
 - } 
 - } ; 
 - } 
 - } ; 
 - } 
 - 
 private ResultSet process ( List < Row > rows , List < ByteBuffer > variables , int limit , long now ) throws InvalidRequestException 
 { 
 Selection . ResultSetBuilder result = selection . resultSetBuilder ( now ) ; 
 @ @ - 1027 , 7 + 982 , 7 @ @ public class SelectStatement implements CQLStatement , MeasurableForPreparedCache 
 else if ( cfDef . isCompact ) 
 { 
 / / One cqlRow per column 
 - for ( Column c : columnsInOrder ( cf , variables ) ) 
 + for ( Column c : cf ) 
 { 
 if ( c . isMarkedForDelete ( now ) ) 
 continue ; 
 @ @ - 1144 , 16 + 1099 , 18 @ @ public class SelectStatement implements CQLStatement , MeasurableForPreparedCache 
 return true ; 
 } 
 
 + private boolean needsPostQueryOrdering ( ) 
 + { 
 + / / We need post - query ordering only for queries with IN on the partition key and an ORDER BY . 
 + return keyIsInRelation & & ! parameters . orderings . isEmpty ( ) ; 
 + } 
 + 
 / * * 
 * Orders results when multiple keys are selected ( using IN ) 
 * / 
 private void orderResults ( ResultSet cqlRows ) 
 { 
 - / / There is nothing to do if 
 - / / a . there are no results , 
 - / / b . no ordering information where given , 
 - / / c . key restriction is a Range or not an IN expression 
 - if ( cqlRows . size ( ) = = 0 | | parameters . orderings . isEmpty ( ) | | isKeyRange | | ! keyIsInRelation ) 
 + if ( cqlRows . size ( ) = = 0 | | ! needsPostQueryOrdering ( ) ) 
 return ; 
 
 assert orderingIndexes ! = null ;

NEAREST DIFF:
diff - - git a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java 
 index 6c20cd0 . . a1a6d15 100644 
 - - - a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java 
 + + + b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java 
 @ @ - 39 , 6 + 39 , 7 @ @ import org . slf4j . LoggerFactory ; 
 
 import java . io . * ; 
 import java . util . * ; 
 + import java . util . concurrent . atomic . AtomicInteger ; 
 import java . util . zip . Checksum ; 
 import java . util . zip . CRC32 ; 
 import java . util . concurrent . Callable ; 
 @ @ - 173 , 12 + 174 , 10 @ @ public class CommitLog 
 logger . info ( " Log replay complete " ) ; 
 } 
 
 - 
 public static void recover ( File [ ] clogs ) throws IOException 
 { 
 Set < Table > tablesRecovered = new HashSet < Table > ( ) ; 
 - assert StageManager . getStage ( StageManager . MUTATION _ STAGE ) . getCompletedTaskCount ( ) = = 0 ; 
 - int rows = 0 ; 
 + final AtomicInteger counter = new AtomicInteger ( 0 ) ; 
 for ( File file : clogs ) 
 { 
 int bufferSize = ( int ) Math . min ( file . length ( ) , 32 * 1024 * 1024 ) ; 
 @ @ - 263 , 16 + 262 , 17 @ @ public class CommitLog 
 { 
 Table . open ( newRm . getTable ( ) ) . apply ( newRm , null , false ) ; 
 } 
 + counter . decrementAndGet ( ) ; 
 } 
 } ; 
 - StageManager . getStage ( StageManager . MUTATION _ STAGE ) . execute ( runnable ) ; 
 - rows + + ; 
 + counter . incrementAndGet ( ) ; 
 + StageManager . getStage ( StageManager . MUTATION _ STAGE ) . submit ( runnable ) ; 
 } 
 reader . close ( ) ; 
 } 
 
 / / wait for all the writes to finish on the mutation stage 
 - while ( StageManager . getStage ( StageManager . MUTATION _ STAGE ) . getCompletedTaskCount ( ) < rows ) 
 + while ( counter . get ( ) > 0 ) 
 { 
 try 
 { 
 diff - - git a / src / java / org / apache / cassandra / io / DeletionService . java b / src / java / org / apache / cassandra / io / DeletionService . java 
 index 9a534fe . . ae8a271 100644 
 - - - a / src / java / org / apache / cassandra / io / DeletionService . java 
 + + + b / src / java / org / apache / cassandra / io / DeletionService . java 
 @ @ - 23 , 6 + 23 , 7 @ @ package org . apache . cassandra . io ; 
 
 import java . io . File ; 
 import java . io . IOException ; 
 + import java . util . concurrent . ExecutionException ; 
 import java . util . concurrent . ExecutorService ; 
 
 import org . apache . cassandra . concurrent . JMXEnabledThreadPoolExecutor ; 
 @ @ - 48 , 6 + 49 , 11 @ @ public class DeletionService 
 } ; 
 executor . submit ( deleter ) ; 
 } 
 + 
 + public static void waitFor ( ) throws InterruptedException , ExecutionException 
 + { 
 + executor . submit ( new Runnable ( ) { public void run ( ) { } } ) . get ( ) ; 
 + } 
 
 public static void submitDeleteWithRetry ( String file ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java 
 index 02453f1 . . 79a4458 100644 
 - - - a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java 
 + + + b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java 
 @ @ - 164 , 7 + 164 , 7 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 { 
 if ( syncNeeded _ ) 
 { 
 - flush ( ) ; 
 + flushBuffer ( ) ; 
 getChannel ( ) . force ( true ) ; / / true , because file length counts as " metadata " 
 syncNeeded _ = false ; 
 } 
 @ @ - 172 , 20 + 172 , 11 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 
 public void close ( ) throws IOException 
 { 
 - this . flush ( ) ; 
 + sync ( ) ; 
 this . buff _ = null ; 
 super . close ( ) ; 
 } 
 
 - / * * 
 - * Flush any bytes in the file ' s buffer that have not yet been written to 
 - * disk . If the file was created read - only , this method is a no - op . 
 - * / 
 - public void flush ( ) throws IOException 
 - { 
 - this . flushBuffer ( ) ; 
 - } 
 - 
 / * Flush any dirty bytes in the buffer to disk . * / 
 private void flushBuffer ( ) throws IOException 
 { 
 diff - - git a / src / java / org / apache / cassandra / net / MessagingService . java b / src / java / org / apache / cassandra / net / MessagingService . java 
 index 409a21e . . e0329c7 100644 
 - - - a / src / java / org / apache / cassandra / net / MessagingService . java 
 + + + b / src / java / org / apache / cassandra / net / MessagingService . java 
 @ @ - 32 , 12 + 32 , 14 @ @ import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 + import java . io . IOError ; 
 import java . io . IOException ; 
 import java . net . ServerSocket ; 
 import java . net . InetAddress ; 
 import java . net . InetSocketAddress ; 
 import java . net . Socket ; 
 import java . nio . ByteBuffer ; 
 + import java . nio . channels . AsynchronousCloseException ; 
 import java . nio . channels . ServerSocketChannel ; 
 import java . security . MessageDigest ; 
 import java . util . * ; 
 @ @ - 74 , 6 + 76 , 8 @ @ public class MessagingService implements IFailureDetectionEventListener 
 private static Logger logger _ = LoggerFactory . getLogger ( MessagingService . class ) ; 
 
 public static final MessagingService instance = new MessagingService ( ) ; 
 + 
 + private SocketThread socketThread ; 
 
 public static int getVersion ( ) 
 { 
 @ @ - 141 , 25 + 145 , 9 @ @ public class MessagingService implements IFailureDetectionEventListener 
 final ServerSocket ss = serverChannel . socket ( ) ; 
 ss . setReuseAddress ( true ) ; 
 ss . bind ( new InetSocketAddress ( localEp , DatabaseDescriptor . getStoragePort ( ) ) ) ; 
 + socketThread = new SocketThread ( ss , " ACCEPT - " + localEp ) ; 
 + socketThread . start ( ) ; 
 
 - new Thread ( new Runnable ( ) 
 - { 
 - public void run ( ) 
 - { 
 - while ( true ) 
 - { 
 - try 
 - { 
 - Socket socket = ss . accept ( ) ; 
 - new IncomingTcpConnection ( socket ) . start ( ) ; 
 - } 
 - catch ( IOException e ) 
 - { 
 - throw new RuntimeException ( e ) ; 
 - } 
 - } 
 - } 
 - } , " ACCEPT - " + localEp ) . start ( ) ; 
 } 
 
 public static OutboundTcpConnectionPool getConnectionPool ( InetAddress to ) 
 @ @ - 338 , 14 + 326 , 31 @ @ public class MessagingService implements IFailureDetectionEventListener 
 Runnable streamingTask = new FileStreamTask ( file , startPosition , endPosition , from , to ) ; 
 streamExecutor _ . execute ( streamingTask ) ; 
 } 
 + 
 + / * * blocks until the processing pools are empty and done . * / 
 + public static void waitFor ( ) throws InterruptedException 
 + { 
 + while ( ! messageDeserializerExecutor _ . isTerminated ( ) ) 
 + messageDeserializerExecutor _ . awaitTermination ( 5 , TimeUnit . SECONDS ) ; 
 + while ( ! streamExecutor _ . isTerminated ( ) ) 
 + streamExecutor _ . awaitTermination ( 5 , TimeUnit . SECONDS ) ; 
 + } 
 
 public static void shutdown ( ) 
 { 
 - logger _ . info ( " Shutting down . . . " ) ; 
 + logger _ . info ( " Shutting down MessageService . . . " ) ; 
 + 
 + try 
 + { 
 + instance . socketThread . close ( ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new IOError ( e ) ; 
 + } 
 
 messageDeserializerExecutor _ . shutdownNow ( ) ; 
 streamExecutor _ . shutdownNow ( ) ; 
 - StageManager . shutdownNow ( ) ; 
 
 / * shut down the cachetables * / 
 taskCompletionMap _ . shutdown ( ) ; 
 @ @ - 467 , 4 + 472 , 42 @ @ public class MessagingService implements IFailureDetectionEventListener 
 buffer . flip ( ) ; 
 return buffer ; 
 } 
 + 
 + private class SocketThread extends Thread 
 + { 
 + private final ServerSocket server ; 
 + 
 + SocketThread ( ServerSocket server , String name ) 
 + { 
 + super ( name ) ; 
 + this . server = server ; 
 + } 
 + 
 + public void run ( ) 
 + { 
 + while ( true ) 
 + { 
 + try 
 + { 
 + Socket socket = server . accept ( ) ; 
 + new IncomingTcpConnection ( socket ) . start ( ) ; 
 + } 
 + catch ( AsynchronousCloseException e ) 
 + { 
 + / / this happens when another thread calls close ( ) . 
 + logger _ . info ( " MessagingService shutting down server thread . " ) ; 
 + break ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new RuntimeException ( e ) ; 
 + } 
 + } 
 + } 
 + 
 + void close ( ) throws IOException 
 + { 
 + server . close ( ) ; 
 + } 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index f1404f6 . . 713ae51 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 37 , 8 + 37 , 10 @ @ import com . google . common . collect . Multimaps ; 
 import org . apache . cassandra . concurrent . * ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . db . * ; 
 + import org . apache . cassandra . db . commitlog . CommitLog ; 
 import org . apache . cassandra . dht . * ; 
 import org . apache . cassandra . gms . * ; 
 + import org . apache . cassandra . io . DeletionService ; 
 import org . apache . cassandra . io . sstable . SSTable ; 
 import org . apache . cassandra . io . sstable . SSTableReader ; 
 import org . apache . cassandra . locator . * ; 
 @ @ - 273 , 6 + 275 , 7 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe 
 Gossiper . instance . unregister ( this ) ; 
 Gossiper . instance . stop ( ) ; 
 MessagingService . shutdown ( ) ; 
 + StageManager . shutdownNow ( ) ; 
 } 
 
 public synchronized void initClient ( ) throws IOException 
 @ @ - 1301 , 6 + 1304 , 7 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe 
 { 
 Gossiper . instance . stop ( ) ; 
 MessagingService . shutdown ( ) ; 
 + StageManager . shutdownNow ( ) ; 
 setMode ( " Decommissioned " , true ) ; 
 / / let op be responsible for killing the process 
 } 
 @ @ - 1525 , 4 + 1529 , 43 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe 
 tokenMetadata _ = tmd ; 
 return old ; 
 } 
 + 
 + / * * shuts node off to writes , empties memtables and the commit log . * / 
 + public synchronized void drain ( ) throws IOException , InterruptedException , ExecutionException 
 + { 
 + ExecutorService mutationStage = StageManager . getStage ( StageManager . MUTATION _ STAGE ) ; 
 + if ( mutationStage . isTerminated ( ) ) 
 + { 
 + logger _ . warn ( " Cannot drain node ( did it already happen ? ) " ) ; 
 + return ; 
 + } 
 + setMode ( " Starting drain process " , true ) ; 
 + Gossiper . instance . stop ( ) ; 
 + setMode ( " Draining : shutting down MessageService " , false ) ; 
 + MessagingService . shutdown ( ) ; 
 + setMode ( " Draining : emptying MessageService pools " , false ) ; 
 + MessagingService . waitFor ( ) ; 
 + 
 + / / lets flush . 
 + setMode ( " Draining : flushing column families " , false ) ; 
 + for ( String tableName : DatabaseDescriptor . getNonSystemTables ( ) ) 
 + for ( Future f : Table . open ( tableName ) . flush ( ) ) 
 + f . get ( ) ; 
 + 
 + 
 + setMode ( " Draining : replaying commit log " , false ) ; 
 + CommitLog . instance ( ) . forceNewSegment ( ) ; 
 + / / want to make sure that any segments deleted as a result of flushing are gone . 
 + DeletionService . waitFor ( ) ; 
 + CommitLog . recover ( ) ; 
 + 
 + / / commit log recovery just sends work to the mutation stage . ( there could have already been work there anyway . 
 + / / Either way , we need to let this one drain naturally , and then we ' re finished . 
 + setMode ( " Draining : clearing mutation stage " , false ) ; 
 + mutationStage . shutdown ( ) ; 
 + while ( ! mutationStage . isTerminated ( ) ) 
 + mutationStage . awaitTermination ( 5 , TimeUnit . SECONDS ) ; 
 + 
 + setMode ( " Node is drained " , true ) ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 index 638430e . . dc1e8b5 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 @ @ - 23 , 6 + 23 , 7 @ @ import java . net . UnknownHostException ; 
 import java . util . List ; 
 import java . util . Map ; 
 import java . util . Set ; 
 + import java . util . concurrent . ExecutionException ; 
 import java . util . concurrent . FutureTask ; 
 
 import org . apache . cassandra . dht . Range ; 
 @ @ - 165 , 4 + 166 , 7 @ @ public interface StorageServiceMBean 
 
 / * * get the operational mode ( leaving , joining , normal , decommissioned , client ) * * / 
 public String getOperationMode ( ) ; 
 + 
 + / * * makes node unavailable for writes , flushes memtables and replays commitlog . * / 
 + public void drain ( ) throws IOException , InterruptedException , ExecutionException ; 
 }
