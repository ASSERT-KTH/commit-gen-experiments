BLEU SCORE: 0.016932492841722675

TEST MSG: Require forceful decommission if number of nodes is less than replication factor
GENERATED MSG: r / m nodetool loadbalance

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 4cb3c45 . . c5fcec8 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 3 . 12 <nl> + * Require forceful decommission if number of nodes is less than replication factor ( CASSANDRA - 12510 ) <nl> * Allow IN restrictions on column families with collections ( CASSANDRA - 12654 ) <nl> * Move to FastThreadLocalThread and FastThreadLocal ( CASSANDRA - 13034 ) <nl> * nodetool stopdaemon errors out ( CASSANDRA - 13030 ) <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index 5dfac21 . . 834008d 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 3864 , 14 + 3864 , 18 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> PendingRangeCalculatorService . instance . update ( ) ; <nl> } <nl> <nl> - public void decommission ( ) throws InterruptedException <nl> - { <nl> - if ( ! tokenMetadata . isMember ( FBUtilities . getBroadcastAddress ( ) ) ) <nl> - throw new UnsupportedOperationException ( " local node is not a member of the token ring yet " ) ; <nl> - if ( tokenMetadata . cloneAfterAllLeft ( ) . sortedTokens ( ) . size ( ) < 2 ) <nl> - throw new UnsupportedOperationException ( " no other normal nodes in the ring ; decommission would be pointless " ) ; <nl> - if ( operationMode ! = Mode . LEAVING & & operationMode ! = Mode . NORMAL ) <nl> - throw new UnsupportedOperationException ( " Node in " + operationMode + " state ; wait for status to become normal or restart " ) ; <nl> + public void decommission ( boolean force ) throws InterruptedException <nl> + { <nl> + TokenMetadata metadata = tokenMetadata . cloneAfterAllLeft ( ) ; <nl> + if ( operationMode ! = Mode . LEAVING ) <nl> + { <nl> + if ( ! tokenMetadata . isMember ( FBUtilities . getBroadcastAddress ( ) ) ) <nl> + throw new UnsupportedOperationException ( " local node is not a member of the token ring yet " ) ; <nl> + if ( metadata . getAllEndpoints ( ) . size ( ) < 2 ) <nl> + throw new UnsupportedOperationException ( " no other normal nodes in the ring ; decommission would be pointless " ) ; <nl> + if ( operationMode ! = Mode . NORMAL ) <nl> + throw new UnsupportedOperationException ( " Node in " + operationMode + " state ; wait for status to become normal or restart " ) ; <nl> + } <nl> if ( isDecommissioning . compareAndSet ( true , true ) ) <nl> throw new IllegalStateException ( " Node is still decommissioning . Check nodetool netstats . " ) ; <nl> <nl> @ @ - 3881 , 10 + 3885 , 37 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> try <nl> { <nl> PendingRangeCalculatorService . instance . blockUntilFinished ( ) ; <nl> - for ( String keyspaceName : Schema . instance . getNonLocalStrategyKeyspaces ( ) ) <nl> + <nl> + String dc = DatabaseDescriptor . getEndpointSnitch ( ) . getDatacenter ( FBUtilities . getBroadcastAddress ( ) ) ; <nl> + <nl> + if ( operationMode ! = Mode . LEAVING ) / / If we ' re already decommissioning there is no point checking RF / pending ranges <nl> { <nl> - if ( tokenMetadata . getPendingRanges ( keyspaceName , FBUtilities . getBroadcastAddress ( ) ) . size ( ) > 0 ) <nl> - throw new UnsupportedOperationException ( " data is currently moving to this node ; unable to leave the ring " ) ; <nl> + int rf , numNodes ; <nl> + for ( String keyspaceName : Schema . instance . getNonLocalStrategyKeyspaces ( ) ) <nl> + { <nl> + if ( ! force ) <nl> + { <nl> + Keyspace keyspace = Keyspace . open ( keyspaceName ) ; <nl> + if ( keyspace . getReplicationStrategy ( ) instanceof NetworkTopologyStrategy ) <nl> + { <nl> + NetworkTopologyStrategy strategy = ( NetworkTopologyStrategy ) keyspace . getReplicationStrategy ( ) ; <nl> + rf = strategy . getReplicationFactor ( dc ) ; <nl> + numNodes = metadata . getTopology ( ) . getDatacenterEndpoints ( ) . get ( dc ) . size ( ) ; <nl> + } <nl> + else <nl> + { <nl> + numNodes = metadata . getAllEndpoints ( ) . size ( ) ; <nl> + rf = keyspace . getReplicationStrategy ( ) . getReplicationFactor ( ) ; <nl> + } <nl> + <nl> + if ( numNodes < = rf ) <nl> + throw new UnsupportedOperationException ( " Not enough live nodes to maintain replication factor in keyspace " <nl> + + keyspaceName + " ( RF = " + rf + " , N = " + numNodes + " ) . " <nl> + + " Perform a forceful decommission to ignore . " ) ; <nl> + } <nl> + if ( tokenMetadata . getPendingRanges ( keyspaceName , FBUtilities . getBroadcastAddress ( ) ) . size ( ) > 0 ) <nl> + throw new UnsupportedOperationException ( " data is currently moving to this node ; unable to leave the ring " ) ; <nl> + } <nl> } <nl> <nl> startLeaving ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> index 339b991 . . 92a35e6 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> @ @ - 375 , 8 + 375 , 9 @ @ public interface StorageServiceMBean extends NotificationEmitter <nl> <nl> / * * <nl> * transfer this node ' s data to other machines and remove it from service . <nl> + * @ param force Decommission even if this will reduce N to be less than RF . <nl> * / <nl> - public void decommission ( ) throws InterruptedException ; <nl> + public void decommission ( boolean force ) throws InterruptedException ; <nl> <nl> / * * <nl> * @ param newToken token to move this node to . <nl> diff - - git a / src / java / org / apache / cassandra / tools / NodeProbe . java b / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> index a48baf8 . . da438cb 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> + + + b / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> @ @ - 640 , 9 + 640 , 9 @ @ public class NodeProbe implements AutoCloseable <nl> ssProxy . joinRing ( ) ; <nl> } <nl> <nl> - public void decommission ( ) throws InterruptedException <nl> + public void decommission ( boolean force ) throws InterruptedException <nl> { <nl> - ssProxy . decommission ( ) ; <nl> + ssProxy . decommission ( force ) ; <nl> } <nl> <nl> public void move ( String newToken ) throws IOException <nl> diff - - git a / src / java / org / apache / cassandra / tools / nodetool / Decommission . java b / src / java / org / apache / cassandra / tools / nodetool / Decommission . java <nl> index 34890e0 . . 294fe07 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / nodetool / Decommission . java <nl> + + + b / src / java / org / apache / cassandra / tools / nodetool / Decommission . java <nl> @ @ - 18 , 6 + 18 , 7 @ @ <nl> package org . apache . cassandra . tools . nodetool ; <nl> <nl> import io . airlift . command . Command ; <nl> + import io . airlift . command . Option ; <nl> <nl> import org . apache . cassandra . tools . NodeProbe ; <nl> import org . apache . cassandra . tools . NodeTool . NodeToolCmd ; <nl> @ @ - 25 , 12 + 26 , 18 @ @ import org . apache . cassandra . tools . NodeTool . NodeToolCmd ; <nl> @ Command ( name = " decommission " , description = " Decommission the * node I am connecting to * " ) <nl> public class Decommission extends NodeToolCmd <nl> { <nl> + <nl> + @ Option ( title = " force " , <nl> + name = { " - f " , " - - force " } , <nl> + description = " Force decommission of this node even when it reduces the number of replicas to below configured RF " ) <nl> + private boolean force = false ; <nl> + <nl> @ Override <nl> public void execute ( NodeProbe probe ) <nl> { <nl> try <nl> { <nl> - probe . decommission ( ) ; <nl> + probe . decommission ( force ) ; <nl> } catch ( InterruptedException e ) <nl> { <nl> throw new RuntimeException ( " Error decommissioning node " , e ) ;
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 04c4696 . . 6dd1fcb 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 7 + 1 , 7 @ @ <nl> 0 . 8 - dev <nl> * remove Avro RPC support ( CASSANDRA - 926 ) <nl> * adds support for columns that act as incr / decr counters <nl> - ( CASSANDRA - 1072 , 1937 , 1944 , 1936 , 2101 , 2093 , 2288 , 2105 , 2384 , 2236 ) <nl> + ( CASSANDRA - 1072 , 1937 , 1944 , 1936 , 2101 , 2093 , 2288 , 2105 , 2384 , 2236 , 2342 ) <nl> * CQL ( CASSANDRA - 1703 , 1704 , 1705 , 1706 , 1707 , 1708 , 1710 , 1711 , 1940 , <nl> 2124 , 2302 , 2277 ) <nl> * avoid double RowMutation serialization on write path ( CASSANDRA - 1800 ) <nl> diff - - git a / src / java / org / apache / cassandra / cli / CliClient . java b / src / java / org / apache / cassandra / cli / CliClient . java <nl> index e632420 . . f4aeb27 100644 <nl> - - - a / src / java / org / apache / cassandra / cli / CliClient . java <nl> + + + b / src / java / org / apache / cassandra / cli / CliClient . java <nl> @ @ - 2206 , 6 + 2206 , 24 @ @ public class CliClient extends CliUserHelp <nl> <nl> sessionState . out . println ( " ) " ) ; <nl> } <nl> + else if ( columnOrSuperColumn . counter _ column ! = null ) <nl> + { <nl> + CounterColumn col = columnOrSuperColumn . counter _ column ; <nl> + <nl> + sessionState . out . printf ( " = > ( counter = % s , value = % s ) % n " , formatColumnName ( keySpace , columnFamilyName , col . name ) , col . value ) ; <nl> + } <nl> + else if ( columnOrSuperColumn . counter _ super _ column ! = null ) <nl> + { <nl> + CounterSuperColumn superCol = columnOrSuperColumn . counter _ super _ column ; <nl> + sessionState . out . printf ( " = > ( super _ column = % s , " , formatColumnName ( keySpace , columnFamilyName , superCol . name ) ) ; <nl> + <nl> + for ( CounterColumn col : superCol . columns ) <nl> + { <nl> + sessionState . out . printf ( " % n ( counter = % s , value = % s ) " , formatSubcolumnName ( keySpace , columnFamilyName , col . name ) , col . value ) ; <nl> + } <nl> + <nl> + sessionState . out . println ( " ) " ) ; <nl> + } <nl> } <nl> } <nl> <nl> diff - - git a / src / java / org / apache / cassandra / thrift / CassandraServer . java b / src / java / org / apache / cassandra / thrift / CassandraServer . java <nl> index 8f52579 . . dd1e77e 100644 <nl> - - - a / src / java / org / apache / cassandra / thrift / CassandraServer . java <nl> + + + b / src / java / org / apache / cassandra / thrift / CassandraServer . java <nl> @ @ - 575 , 7 + 575 , 7 @ @ public class CassandraServer implements Cassandra . Iface <nl> String keyspace = state ( ) . getKeyspace ( ) ; <nl> state ( ) . hasColumnFamilyAccess ( column _ parent . column _ family , Permission . READ ) ; <nl> <nl> - CFMetaData metadata = ThriftValidation . validateColumnFamily ( keyspace , column _ parent . column _ family , false ) ; <nl> + CFMetaData metadata = ThriftValidation . validateColumnFamily ( keyspace , column _ parent . column _ family ) ; <nl> ThriftValidation . validateColumnParent ( metadata , column _ parent ) ; <nl> ThriftValidation . validatePredicate ( metadata , column _ parent , predicate ) ; <nl> ThriftValidation . validateKeyRange ( range ) ; <nl> diff - - git a / test / system / test _ thrift _ server . py b / test / system / test _ thrift _ server . py <nl> index a40554b . . 9a398a7 100644 <nl> - - - a / test / system / test _ thrift _ server . py <nl> + + + b / test / system / test _ thrift _ server . py <nl> @ @ - 105 , 6 + 105 , 12 @ @ def _ insert _ range ( ) : <nl> client . insert ( ' key1 ' , ColumnParent ( ' Standard1 ' ) , Column ( ' c3 ' , ' value3 ' , 0 ) , ConsistencyLevel . ONE ) <nl> time . sleep ( 0 . 1 ) <nl> <nl> + def _ insert _ counter _ range ( ) : <nl> + client . add ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , CounterColumn ( ' c1 ' , 1 ) , ConsistencyLevel . ONE ) <nl> + client . add ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , CounterColumn ( ' c2 ' , 2 ) , ConsistencyLevel . ONE ) <nl> + client . add ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , CounterColumn ( ' c3 ' , 3 ) , ConsistencyLevel . ONE ) <nl> + time . sleep ( 0 . 1 ) <nl> + <nl> def _ verify _ range ( ) : <nl> p = SlicePredicate ( slice _ range = SliceRange ( ' c1 ' , ' c2 ' , False , 1000 ) ) <nl> result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Standard1 ' ) , p , ConsistencyLevel . ONE ) <nl> @ @ - 126 , 6 + 132 , 27 @ @ def _ verify _ range ( ) : <nl> result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Standard1 ' ) , p , ConsistencyLevel . ONE ) <nl> assert len ( result ) = = 2 , result <nl> <nl> + def _ verify _ counter _ range ( ) : <nl> + p = SlicePredicate ( slice _ range = SliceRange ( ' c1 ' , ' c2 ' , False , 1000 ) ) <nl> + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , p , ConsistencyLevel . ONE ) <nl> + assert len ( result ) = = 2 <nl> + assert result [ 0 ] . counter _ column . name = = ' c1 ' <nl> + assert result [ 1 ] . counter _ column . name = = ' c2 ' <nl> + <nl> + p = SlicePredicate ( slice _ range = SliceRange ( ' c3 ' , ' c2 ' , True , 1000 ) ) <nl> + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , p , ConsistencyLevel . ONE ) <nl> + assert len ( result ) = = 2 <nl> + assert result [ 0 ] . counter _ column . name = = ' c3 ' <nl> + assert result [ 1 ] . counter _ column . name = = ' c2 ' <nl> + <nl> + p = SlicePredicate ( slice _ range = SliceRange ( ' a ' , ' z ' , False , 1000 ) ) <nl> + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , p , ConsistencyLevel . ONE ) <nl> + assert len ( result ) = = 3 , result <nl> + <nl> + p = SlicePredicate ( slice _ range = SliceRange ( ' a ' , ' z ' , False , 2 ) ) <nl> + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , p , ConsistencyLevel . ONE ) <nl> + assert len ( result ) = = 2 , result <nl> + <nl> def _ set _ keyspace ( keyspace ) : <nl> client . set _ keyspace ( keyspace ) <nl> <nl> @ @ - 136 , 6 + 163 , 13 @ @ def _ insert _ super _ range ( ) : <nl> client . insert ( ' key1 ' , ColumnParent ( ' Super1 ' , ' sc3 ' ) , Column ( _ i64 ( 7 ) , ' value7 ' , 0 ) , ConsistencyLevel . ONE ) <nl> time . sleep ( 0 . 1 ) <nl> <nl> + def _ insert _ counter _ super _ range ( ) : <nl> + client . add ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' , ' sc1 ' ) , CounterColumn ( _ i64 ( 4 ) , 4 ) , ConsistencyLevel . ONE ) <nl> + client . add ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' , ' sc2 ' ) , CounterColumn ( _ i64 ( 5 ) , 5 ) , ConsistencyLevel . ONE ) <nl> + client . add ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' , ' sc2 ' ) , CounterColumn ( _ i64 ( 6 ) , 6 ) , ConsistencyLevel . ONE ) <nl> + client . add ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' , ' sc3 ' ) , CounterColumn ( _ i64 ( 7 ) , 7 ) , ConsistencyLevel . ONE ) <nl> + time . sleep ( 0 . 1 ) <nl> + <nl> def _ verify _ super _ range ( ) : <nl> p = SlicePredicate ( slice _ range = SliceRange ( ' sc2 ' , ' sc3 ' , False , 2 ) ) <nl> result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Super1 ' ) , p , ConsistencyLevel . ONE ) <nl> @ @ - 149 , 6 + 183 , 19 @ @ def _ verify _ super _ range ( ) : <nl> assert result [ 0 ] . super _ column . name = = ' sc3 ' <nl> assert result [ 1 ] . super _ column . name = = ' sc2 ' <nl> <nl> + def _ verify _ counter _ super _ range ( ) : <nl> + p = SlicePredicate ( slice _ range = SliceRange ( ' sc2 ' , ' sc3 ' , False , 2 ) ) <nl> + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' ) , p , ConsistencyLevel . ONE ) <nl> + assert len ( result ) = = 2 <nl> + assert result [ 0 ] . counter _ super _ column . name = = ' sc2 ' <nl> + assert result [ 1 ] . counter _ super _ column . name = = ' sc3 ' <nl> + <nl> + p = SlicePredicate ( slice _ range = SliceRange ( ' sc3 ' , ' sc2 ' , True , 2 ) ) <nl> + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' ) , p , ConsistencyLevel . ONE ) <nl> + assert len ( result ) = = 2 <nl> + assert result [ 0 ] . counter _ super _ column . name = = ' sc3 ' <nl> + assert result [ 1 ] . counter _ super _ column . name = = ' sc2 ' <nl> + <nl> def _ verify _ super ( supercf = ' Super1 ' , key = ' key1 ' ) : <nl> assert client . get ( key , ColumnPath ( supercf , ' sc1 ' , _ i64 ( 4 ) ) , ConsistencyLevel . ONE ) . column = = Column ( _ i64 ( 4 ) , ' value4 ' , 0 ) <nl> slice = [ result . super _ column <nl> @ @ - 1742 , 6 + 1789 , 16 @ @ class TestMutations ( ThriftTester ) : <nl> assert counters [ ' key2 ' ] [ 0 ] . counter _ column . value = = d1 + d2 <nl> assert counters [ ' key2 ' ] [ 1 ] . counter _ column . value = = d1 <nl> <nl> + def test _ counter _ get _ slice _ range ( self ) : <nl> + _ set _ keyspace ( ' Keyspace1 ' ) <nl> + _ insert _ counter _ range ( ) <nl> + _ verify _ counter _ range ( ) <nl> + <nl> + def test _ counter _ get _ slice _ super _ range ( self ) : <nl> + _ set _ keyspace ( ' Keyspace1 ' ) <nl> + _ insert _ counter _ super _ range ( ) <nl> + _ verify _ counter _ super _ range ( ) <nl> + <nl> def test _ index _ scan ( self ) : <nl> _ set _ keyspace ( ' Keyspace1 ' ) <nl> client . insert ( ' key1 ' , ColumnParent ( ' Indexed1 ' ) , Column ( ' birthdate ' , _ i64 ( 1 ) , 0 ) , ConsistencyLevel . ONE )

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 4cb3c45 . . c5fcec8 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 3 . 12 
 + * Require forceful decommission if number of nodes is less than replication factor ( CASSANDRA - 12510 ) 
 * Allow IN restrictions on column families with collections ( CASSANDRA - 12654 ) 
 * Move to FastThreadLocalThread and FastThreadLocal ( CASSANDRA - 13034 ) 
 * nodetool stopdaemon errors out ( CASSANDRA - 13030 ) 
 diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index 5dfac21 . . 834008d 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 3864 , 14 + 3864 , 18 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 PendingRangeCalculatorService . instance . update ( ) ; 
 } 
 
 - public void decommission ( ) throws InterruptedException 
 - { 
 - if ( ! tokenMetadata . isMember ( FBUtilities . getBroadcastAddress ( ) ) ) 
 - throw new UnsupportedOperationException ( " local node is not a member of the token ring yet " ) ; 
 - if ( tokenMetadata . cloneAfterAllLeft ( ) . sortedTokens ( ) . size ( ) < 2 ) 
 - throw new UnsupportedOperationException ( " no other normal nodes in the ring ; decommission would be pointless " ) ; 
 - if ( operationMode ! = Mode . LEAVING & & operationMode ! = Mode . NORMAL ) 
 - throw new UnsupportedOperationException ( " Node in " + operationMode + " state ; wait for status to become normal or restart " ) ; 
 + public void decommission ( boolean force ) throws InterruptedException 
 + { 
 + TokenMetadata metadata = tokenMetadata . cloneAfterAllLeft ( ) ; 
 + if ( operationMode ! = Mode . LEAVING ) 
 + { 
 + if ( ! tokenMetadata . isMember ( FBUtilities . getBroadcastAddress ( ) ) ) 
 + throw new UnsupportedOperationException ( " local node is not a member of the token ring yet " ) ; 
 + if ( metadata . getAllEndpoints ( ) . size ( ) < 2 ) 
 + throw new UnsupportedOperationException ( " no other normal nodes in the ring ; decommission would be pointless " ) ; 
 + if ( operationMode ! = Mode . NORMAL ) 
 + throw new UnsupportedOperationException ( " Node in " + operationMode + " state ; wait for status to become normal or restart " ) ; 
 + } 
 if ( isDecommissioning . compareAndSet ( true , true ) ) 
 throw new IllegalStateException ( " Node is still decommissioning . Check nodetool netstats . " ) ; 
 
 @ @ - 3881 , 10 + 3885 , 37 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 try 
 { 
 PendingRangeCalculatorService . instance . blockUntilFinished ( ) ; 
 - for ( String keyspaceName : Schema . instance . getNonLocalStrategyKeyspaces ( ) ) 
 + 
 + String dc = DatabaseDescriptor . getEndpointSnitch ( ) . getDatacenter ( FBUtilities . getBroadcastAddress ( ) ) ; 
 + 
 + if ( operationMode ! = Mode . LEAVING ) / / If we ' re already decommissioning there is no point checking RF / pending ranges 
 { 
 - if ( tokenMetadata . getPendingRanges ( keyspaceName , FBUtilities . getBroadcastAddress ( ) ) . size ( ) > 0 ) 
 - throw new UnsupportedOperationException ( " data is currently moving to this node ; unable to leave the ring " ) ; 
 + int rf , numNodes ; 
 + for ( String keyspaceName : Schema . instance . getNonLocalStrategyKeyspaces ( ) ) 
 + { 
 + if ( ! force ) 
 + { 
 + Keyspace keyspace = Keyspace . open ( keyspaceName ) ; 
 + if ( keyspace . getReplicationStrategy ( ) instanceof NetworkTopologyStrategy ) 
 + { 
 + NetworkTopologyStrategy strategy = ( NetworkTopologyStrategy ) keyspace . getReplicationStrategy ( ) ; 
 + rf = strategy . getReplicationFactor ( dc ) ; 
 + numNodes = metadata . getTopology ( ) . getDatacenterEndpoints ( ) . get ( dc ) . size ( ) ; 
 + } 
 + else 
 + { 
 + numNodes = metadata . getAllEndpoints ( ) . size ( ) ; 
 + rf = keyspace . getReplicationStrategy ( ) . getReplicationFactor ( ) ; 
 + } 
 + 
 + if ( numNodes < = rf ) 
 + throw new UnsupportedOperationException ( " Not enough live nodes to maintain replication factor in keyspace " 
 + + keyspaceName + " ( RF = " + rf + " , N = " + numNodes + " ) . " 
 + + " Perform a forceful decommission to ignore . " ) ; 
 + } 
 + if ( tokenMetadata . getPendingRanges ( keyspaceName , FBUtilities . getBroadcastAddress ( ) ) . size ( ) > 0 ) 
 + throw new UnsupportedOperationException ( " data is currently moving to this node ; unable to leave the ring " ) ; 
 + } 
 } 
 
 startLeaving ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 index 339b991 . . 92a35e6 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 @ @ - 375 , 8 + 375 , 9 @ @ public interface StorageServiceMBean extends NotificationEmitter 
 
 / * * 
 * transfer this node ' s data to other machines and remove it from service . 
 + * @ param force Decommission even if this will reduce N to be less than RF . 
 * / 
 - public void decommission ( ) throws InterruptedException ; 
 + public void decommission ( boolean force ) throws InterruptedException ; 
 
 / * * 
 * @ param newToken token to move this node to . 
 diff - - git a / src / java / org / apache / cassandra / tools / NodeProbe . java b / src / java / org / apache / cassandra / tools / NodeProbe . java 
 index a48baf8 . . da438cb 100644 
 - - - a / src / java / org / apache / cassandra / tools / NodeProbe . java 
 + + + b / src / java / org / apache / cassandra / tools / NodeProbe . java 
 @ @ - 640 , 9 + 640 , 9 @ @ public class NodeProbe implements AutoCloseable 
 ssProxy . joinRing ( ) ; 
 } 
 
 - public void decommission ( ) throws InterruptedException 
 + public void decommission ( boolean force ) throws InterruptedException 
 { 
 - ssProxy . decommission ( ) ; 
 + ssProxy . decommission ( force ) ; 
 } 
 
 public void move ( String newToken ) throws IOException 
 diff - - git a / src / java / org / apache / cassandra / tools / nodetool / Decommission . java b / src / java / org / apache / cassandra / tools / nodetool / Decommission . java 
 index 34890e0 . . 294fe07 100644 
 - - - a / src / java / org / apache / cassandra / tools / nodetool / Decommission . java 
 + + + b / src / java / org / apache / cassandra / tools / nodetool / Decommission . java 
 @ @ - 18 , 6 + 18 , 7 @ @ 
 package org . apache . cassandra . tools . nodetool ; 
 
 import io . airlift . command . Command ; 
 + import io . airlift . command . Option ; 
 
 import org . apache . cassandra . tools . NodeProbe ; 
 import org . apache . cassandra . tools . NodeTool . NodeToolCmd ; 
 @ @ - 25 , 12 + 26 , 18 @ @ import org . apache . cassandra . tools . NodeTool . NodeToolCmd ; 
 @ Command ( name = " decommission " , description = " Decommission the * node I am connecting to * " ) 
 public class Decommission extends NodeToolCmd 
 { 
 + 
 + @ Option ( title = " force " , 
 + name = { " - f " , " - - force " } , 
 + description = " Force decommission of this node even when it reduces the number of replicas to below configured RF " ) 
 + private boolean force = false ; 
 + 
 @ Override 
 public void execute ( NodeProbe probe ) 
 { 
 try 
 { 
 - probe . decommission ( ) ; 
 + probe . decommission ( force ) ; 
 } catch ( InterruptedException e ) 
 { 
 throw new RuntimeException ( " Error decommissioning node " , e ) ;

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 04c4696 . . 6dd1fcb 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 7 + 1 , 7 @ @ 
 0 . 8 - dev 
 * remove Avro RPC support ( CASSANDRA - 926 ) 
 * adds support for columns that act as incr / decr counters 
 - ( CASSANDRA - 1072 , 1937 , 1944 , 1936 , 2101 , 2093 , 2288 , 2105 , 2384 , 2236 ) 
 + ( CASSANDRA - 1072 , 1937 , 1944 , 1936 , 2101 , 2093 , 2288 , 2105 , 2384 , 2236 , 2342 ) 
 * CQL ( CASSANDRA - 1703 , 1704 , 1705 , 1706 , 1707 , 1708 , 1710 , 1711 , 1940 , 
 2124 , 2302 , 2277 ) 
 * avoid double RowMutation serialization on write path ( CASSANDRA - 1800 ) 
 diff - - git a / src / java / org / apache / cassandra / cli / CliClient . java b / src / java / org / apache / cassandra / cli / CliClient . java 
 index e632420 . . f4aeb27 100644 
 - - - a / src / java / org / apache / cassandra / cli / CliClient . java 
 + + + b / src / java / org / apache / cassandra / cli / CliClient . java 
 @ @ - 2206 , 6 + 2206 , 24 @ @ public class CliClient extends CliUserHelp 
 
 sessionState . out . println ( " ) " ) ; 
 } 
 + else if ( columnOrSuperColumn . counter _ column ! = null ) 
 + { 
 + CounterColumn col = columnOrSuperColumn . counter _ column ; 
 + 
 + sessionState . out . printf ( " = > ( counter = % s , value = % s ) % n " , formatColumnName ( keySpace , columnFamilyName , col . name ) , col . value ) ; 
 + } 
 + else if ( columnOrSuperColumn . counter _ super _ column ! = null ) 
 + { 
 + CounterSuperColumn superCol = columnOrSuperColumn . counter _ super _ column ; 
 + sessionState . out . printf ( " = > ( super _ column = % s , " , formatColumnName ( keySpace , columnFamilyName , superCol . name ) ) ; 
 + 
 + for ( CounterColumn col : superCol . columns ) 
 + { 
 + sessionState . out . printf ( " % n ( counter = % s , value = % s ) " , formatSubcolumnName ( keySpace , columnFamilyName , col . name ) , col . value ) ; 
 + } 
 + 
 + sessionState . out . println ( " ) " ) ; 
 + } 
 } 
 } 
 
 diff - - git a / src / java / org / apache / cassandra / thrift / CassandraServer . java b / src / java / org / apache / cassandra / thrift / CassandraServer . java 
 index 8f52579 . . dd1e77e 100644 
 - - - a / src / java / org / apache / cassandra / thrift / CassandraServer . java 
 + + + b / src / java / org / apache / cassandra / thrift / CassandraServer . java 
 @ @ - 575 , 7 + 575 , 7 @ @ public class CassandraServer implements Cassandra . Iface 
 String keyspace = state ( ) . getKeyspace ( ) ; 
 state ( ) . hasColumnFamilyAccess ( column _ parent . column _ family , Permission . READ ) ; 
 
 - CFMetaData metadata = ThriftValidation . validateColumnFamily ( keyspace , column _ parent . column _ family , false ) ; 
 + CFMetaData metadata = ThriftValidation . validateColumnFamily ( keyspace , column _ parent . column _ family ) ; 
 ThriftValidation . validateColumnParent ( metadata , column _ parent ) ; 
 ThriftValidation . validatePredicate ( metadata , column _ parent , predicate ) ; 
 ThriftValidation . validateKeyRange ( range ) ; 
 diff - - git a / test / system / test _ thrift _ server . py b / test / system / test _ thrift _ server . py 
 index a40554b . . 9a398a7 100644 
 - - - a / test / system / test _ thrift _ server . py 
 + + + b / test / system / test _ thrift _ server . py 
 @ @ - 105 , 6 + 105 , 12 @ @ def _ insert _ range ( ) : 
 client . insert ( ' key1 ' , ColumnParent ( ' Standard1 ' ) , Column ( ' c3 ' , ' value3 ' , 0 ) , ConsistencyLevel . ONE ) 
 time . sleep ( 0 . 1 ) 
 
 + def _ insert _ counter _ range ( ) : 
 + client . add ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , CounterColumn ( ' c1 ' , 1 ) , ConsistencyLevel . ONE ) 
 + client . add ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , CounterColumn ( ' c2 ' , 2 ) , ConsistencyLevel . ONE ) 
 + client . add ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , CounterColumn ( ' c3 ' , 3 ) , ConsistencyLevel . ONE ) 
 + time . sleep ( 0 . 1 ) 
 + 
 def _ verify _ range ( ) : 
 p = SlicePredicate ( slice _ range = SliceRange ( ' c1 ' , ' c2 ' , False , 1000 ) ) 
 result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Standard1 ' ) , p , ConsistencyLevel . ONE ) 
 @ @ - 126 , 6 + 132 , 27 @ @ def _ verify _ range ( ) : 
 result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Standard1 ' ) , p , ConsistencyLevel . ONE ) 
 assert len ( result ) = = 2 , result 
 
 + def _ verify _ counter _ range ( ) : 
 + p = SlicePredicate ( slice _ range = SliceRange ( ' c1 ' , ' c2 ' , False , 1000 ) ) 
 + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , p , ConsistencyLevel . ONE ) 
 + assert len ( result ) = = 2 
 + assert result [ 0 ] . counter _ column . name = = ' c1 ' 
 + assert result [ 1 ] . counter _ column . name = = ' c2 ' 
 + 
 + p = SlicePredicate ( slice _ range = SliceRange ( ' c3 ' , ' c2 ' , True , 1000 ) ) 
 + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , p , ConsistencyLevel . ONE ) 
 + assert len ( result ) = = 2 
 + assert result [ 0 ] . counter _ column . name = = ' c3 ' 
 + assert result [ 1 ] . counter _ column . name = = ' c2 ' 
 + 
 + p = SlicePredicate ( slice _ range = SliceRange ( ' a ' , ' z ' , False , 1000 ) ) 
 + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , p , ConsistencyLevel . ONE ) 
 + assert len ( result ) = = 3 , result 
 + 
 + p = SlicePredicate ( slice _ range = SliceRange ( ' a ' , ' z ' , False , 2 ) ) 
 + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Counter1 ' ) , p , ConsistencyLevel . ONE ) 
 + assert len ( result ) = = 2 , result 
 + 
 def _ set _ keyspace ( keyspace ) : 
 client . set _ keyspace ( keyspace ) 
 
 @ @ - 136 , 6 + 163 , 13 @ @ def _ insert _ super _ range ( ) : 
 client . insert ( ' key1 ' , ColumnParent ( ' Super1 ' , ' sc3 ' ) , Column ( _ i64 ( 7 ) , ' value7 ' , 0 ) , ConsistencyLevel . ONE ) 
 time . sleep ( 0 . 1 ) 
 
 + def _ insert _ counter _ super _ range ( ) : 
 + client . add ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' , ' sc1 ' ) , CounterColumn ( _ i64 ( 4 ) , 4 ) , ConsistencyLevel . ONE ) 
 + client . add ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' , ' sc2 ' ) , CounterColumn ( _ i64 ( 5 ) , 5 ) , ConsistencyLevel . ONE ) 
 + client . add ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' , ' sc2 ' ) , CounterColumn ( _ i64 ( 6 ) , 6 ) , ConsistencyLevel . ONE ) 
 + client . add ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' , ' sc3 ' ) , CounterColumn ( _ i64 ( 7 ) , 7 ) , ConsistencyLevel . ONE ) 
 + time . sleep ( 0 . 1 ) 
 + 
 def _ verify _ super _ range ( ) : 
 p = SlicePredicate ( slice _ range = SliceRange ( ' sc2 ' , ' sc3 ' , False , 2 ) ) 
 result = client . get _ slice ( ' key1 ' , ColumnParent ( ' Super1 ' ) , p , ConsistencyLevel . ONE ) 
 @ @ - 149 , 6 + 183 , 19 @ @ def _ verify _ super _ range ( ) : 
 assert result [ 0 ] . super _ column . name = = ' sc3 ' 
 assert result [ 1 ] . super _ column . name = = ' sc2 ' 
 
 + def _ verify _ counter _ super _ range ( ) : 
 + p = SlicePredicate ( slice _ range = SliceRange ( ' sc2 ' , ' sc3 ' , False , 2 ) ) 
 + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' ) , p , ConsistencyLevel . ONE ) 
 + assert len ( result ) = = 2 
 + assert result [ 0 ] . counter _ super _ column . name = = ' sc2 ' 
 + assert result [ 1 ] . counter _ super _ column . name = = ' sc3 ' 
 + 
 + p = SlicePredicate ( slice _ range = SliceRange ( ' sc3 ' , ' sc2 ' , True , 2 ) ) 
 + result = client . get _ slice ( ' key1 ' , ColumnParent ( ' SuperCounter1 ' ) , p , ConsistencyLevel . ONE ) 
 + assert len ( result ) = = 2 
 + assert result [ 0 ] . counter _ super _ column . name = = ' sc3 ' 
 + assert result [ 1 ] . counter _ super _ column . name = = ' sc2 ' 
 + 
 def _ verify _ super ( supercf = ' Super1 ' , key = ' key1 ' ) : 
 assert client . get ( key , ColumnPath ( supercf , ' sc1 ' , _ i64 ( 4 ) ) , ConsistencyLevel . ONE ) . column = = Column ( _ i64 ( 4 ) , ' value4 ' , 0 ) 
 slice = [ result . super _ column 
 @ @ - 1742 , 6 + 1789 , 16 @ @ class TestMutations ( ThriftTester ) : 
 assert counters [ ' key2 ' ] [ 0 ] . counter _ column . value = = d1 + d2 
 assert counters [ ' key2 ' ] [ 1 ] . counter _ column . value = = d1 
 
 + def test _ counter _ get _ slice _ range ( self ) : 
 + _ set _ keyspace ( ' Keyspace1 ' ) 
 + _ insert _ counter _ range ( ) 
 + _ verify _ counter _ range ( ) 
 + 
 + def test _ counter _ get _ slice _ super _ range ( self ) : 
 + _ set _ keyspace ( ' Keyspace1 ' ) 
 + _ insert _ counter _ super _ range ( ) 
 + _ verify _ counter _ super _ range ( ) 
 + 
 def test _ index _ scan ( self ) : 
 _ set _ keyspace ( ' Keyspace1 ' ) 
 client . insert ( ' key1 ' , ColumnParent ( ' Indexed1 ' ) , Column ( ' birthdate ' , _ i64 ( 1 ) , 0 ) , ConsistencyLevel . ONE )
