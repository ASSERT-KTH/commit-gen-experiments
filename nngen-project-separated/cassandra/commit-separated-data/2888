BLEU SCORE: 0.016932492841722675

TEST MSG: clarify that we only collect row - level tombstone in LCR constructor
GENERATED MSG: remove unused compaction controller field from Unwrapper iterator

TEST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / db / compaction / LazilyCompactedRow . java b / src / java / org / apache / cassandra / db / compaction / LazilyCompactedRow . java <nl> index 3b7a3d4 . . 0d33b22 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / LazilyCompactedRow . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / LazilyCompactedRow . java <nl> @ @ - 58 , 8 + 58 , 7 @ @ public class LazilyCompactedRow extends AbstractCompactedRow implements Iterable <nl> private boolean closed ; <nl> private ColumnIndex . Builder indexBuilder ; <nl> private final SecondaryIndexManager . Updater indexer ; <nl> - private long maxTombstoneTimestamp ; <nl> - private DeletionInfo deletionInfo ; <nl> + private DeletionTime maxRowTombstone ; <nl> <nl> public LazilyCompactedRow ( CompactionController controller , List < ? extends OnDiskAtomIterator > rows ) <nl> { <nl> @ @ - 70 , 23 + 69 , 23 @ @ public class LazilyCompactedRow extends AbstractCompactedRow implements Iterable <nl> <nl> / / Combine top - level tombstones , keeping the one with the highest markedForDeleteAt timestamp . This may be <nl> / / purged ( depending on gcBefore ) , but we need to remember it to properly delete columns during the merge <nl> - deletionInfo = DeletionInfo . live ( ) ; <nl> - maxTombstoneTimestamp = Long . MIN _ VALUE ; <nl> + maxRowTombstone = DeletionTime . LIVE ; <nl> for ( OnDiskAtomIterator row : rows ) <nl> { <nl> - DeletionInfo delInfo = row . getColumnFamily ( ) . deletionInfo ( ) ; <nl> - maxTombstoneTimestamp = Math . max ( maxTombstoneTimestamp , delInfo . maxTimestamp ( ) ) ; <nl> - deletionInfo = deletionInfo . add ( delInfo ) ; <nl> + DeletionTime rowTombstone = row . getColumnFamily ( ) . deletionInfo ( ) . getTopLevelDeletion ( ) ; <nl> + if ( maxRowTombstone . compareTo ( rowTombstone ) < 0 ) <nl> + maxRowTombstone = rowTombstone ; <nl> } <nl> <nl> + <nl> / / Don ' t pass maxTombstoneTimestamp to shouldPurge since we might well have cells with <nl> / / tombstones newer than the row - level tombstones we ' ve seen - - but we won ' t know that <nl> / / until we iterate over them . By passing MAX _ VALUE we will only purge if there are <nl> / / no other versions of this row present . <nl> this . shouldPurge = controller . shouldPurge ( key , Long . MAX _ VALUE ) ; <nl> <nl> - emptyColumnFamily = ArrayBackedSortedColumns . factory . create ( controller . cfs . metadata ) ; <nl> - emptyColumnFamily . setDeletionInfo ( deletionInfo . copy ( ) ) ; <nl> + emptyColumnFamily = EmptyColumns . factory . create ( controller . cfs . metadata ) ; <nl> + emptyColumnFamily . delete ( maxRowTombstone ) ; <nl> if ( shouldPurge ) <nl> emptyColumnFamily . purgeTombstones ( controller . gcBefore ) ; <nl> } <nl> @ @ - 113 , 7 + 112 , 7 @ @ public class LazilyCompactedRow extends AbstractCompactedRow implements Iterable <nl> / / ( however , if there are zero columns , iterator ( ) will not be called by ColumnIndexer and reducer will be null ) <nl> columnStats = new ColumnStats ( reducer = = null ? 0 : reducer . columns , <nl> reducer = = null ? Long . MAX _ VALUE : reducer . minTimestampSeen , <nl> - reducer = = null ? maxTombstoneTimestamp : Math . max ( maxTombstoneTimestamp , reducer . maxTimestampSeen ) , <nl> + reducer = = null ? maxRowTombstone . markedForDeleteAt : Math . max ( maxRowTombstone . markedForDeleteAt , reducer . maxTimestampSeen ) , <nl> reducer = = null ? Integer . MIN _ VALUE : reducer . maxLocalDeletionTimeSeen , <nl> reducer = = null ? new StreamingHistogram ( SSTable . TOMBSTONE _ HISTOGRAM _ BIN _ SIZE ) : reducer . tombstones , <nl> reducer = = null ? Collections . < ByteBuffer > emptyList ( ) : reducer . minColumnNameSeen , <nl> @ @ - 193 , 8 + 192 , 9 @ @ public class LazilyCompactedRow extends AbstractCompactedRow implements Iterable <nl> private class Reducer extends MergeIterator . Reducer < OnDiskAtom , OnDiskAtom > <nl> { <nl> / / all columns reduced together will have the same name , so there will only be one column <nl> - / / in the container ; we just want to leverage the conflict resolution code from CF <nl> - ColumnFamily container = emptyColumnFamily . cloneMeShallow ( ArrayBackedSortedColumns . factory , false ) ; <nl> + / / in the container ; we just want to leverage the conflict resolution code from CF . <nl> + / / ( Note that we add the row tombstone in getReduced . ) <nl> + final ColumnFamily container = ArrayBackedSortedColumns . factory . create ( emptyColumnFamily . metadata ( ) ) ; <nl> <nl> / / tombstone reference ; will be reconciled w / column during getReduced . Note that the top - level ( row ) tombstone <nl> / / is held by LCR . deletionInfo . <nl> @ @ - 258 , 7 + 258 , 7 @ @ public class LazilyCompactedRow extends AbstractCompactedRow implements Iterable <nl> else <nl> { <nl> / / when we clear ( ) the container , it removes the deletion info , so this needs to be reset each time <nl> - container . setDeletionInfo ( deletionInfo ) ; <nl> + container . delete ( maxRowTombstone ) ; <nl> ColumnFamily purged = PrecompactedRow . removeDeletedAndOldShards ( key , shouldPurge , controller , container ) ; <nl> if ( purged = = null | | ! purged . iterator ( ) . hasNext ( ) ) <nl> {
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 80c9b44 . . 7fc93f4 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 8 , 6 + 8 , 8 @ @ <nl> * Fix SemanticVersion . isSupportedBy minor / patch handling ( CASSANDRA - 5496 ) <nl> Merged from 1 . 1 <nl> * Add retry mechanism to OTC for non - droppable _ verbs ( CASSANDRA - 5393 ) <nl> + * Use allocator information to improve memtable memory usage estimate <nl> + ( CASSANDRA - 5497 ) <nl> * Fix trying to load deleted row into row cache on startup ( CASSANDRA - 4463 ) <nl> <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / Memtable . java b / src / java / org / apache / cassandra / db / Memtable . java <nl> index 301c297 . . 282acd2 100644 <nl> - - - a / src / java / org / apache / cassandra / db / Memtable . java <nl> + + + b / src / java / org / apache / cassandra / db / Memtable . java <nl> @ @ - 150 , 7 + 150 , 15 @ @ public class Memtable <nl> <nl> public long getLiveSize ( ) <nl> { <nl> - return ( long ) ( currentSize . get ( ) * cfs . liveRatio ) ; <nl> + long estimatedSize = ( long ) ( currentSize . get ( ) * cfs . liveRatio ) ; <nl> + <nl> + / / cap the estimate at both ends by what the allocator can tell us <nl> + if ( estimatedSize < allocator . getMinimumSize ( ) ) <nl> + return allocator . getMinimumSize ( ) ; <nl> + if ( estimatedSize > allocator . getMaximumSize ( ) ) <nl> + return allocator . getMaximumSize ( ) ; <nl> + <nl> + return estimatedSize ; <nl> } <nl> <nl> public long getSerializedSize ( ) <nl> @ @ - 228 , 7 + 236 , 7 @ @ public class Memtable <nl> cfs . liveRatio = ( cfs . liveRatio + newRatio ) / 2 . 0 ; <nl> <nl> logger . info ( " { } liveRatio is { } ( just - counted was { } ) . calculation took { } ms for { } columns " , <nl> - new Object [ ] { cfs , cfs . liveRatio , newRatio , System . currentTimeMillis ( ) - start , objects } ) ; <nl> + cfs , cfs . liveRatio , newRatio , System . currentTimeMillis ( ) - start , objects ) ; <nl> activelyMeasuring = null ; <nl> } <nl> finally <nl> diff - - git a / src / java / org / apache / cassandra / utils / SlabAllocator . java b / src / java / org / apache / cassandra / utils / SlabAllocator . java <nl> index 9d273e2 . . c50e8c4 100644 <nl> - - - a / src / java / org / apache / cassandra / utils / SlabAllocator . java <nl> + + + b / src / java / org / apache / cassandra / utils / SlabAllocator . java <nl> @ @ - 19 , 6 + 19 , 7 @ @ package org . apache . cassandra . utils ; <nl> <nl> import java . nio . ByteBuffer ; <nl> import java . util . concurrent . atomic . AtomicInteger ; <nl> + import java . util . concurrent . atomic . AtomicLong ; <nl> import java . util . concurrent . atomic . AtomicReference ; <nl> <nl> import com . google . common . base . Preconditions ; <nl> @ @ - 47 , 7 + 48 , 8 @ @ public class SlabAllocator extends Allocator <nl> private final static int MAX _ CLONED _ SIZE = 128 * 1024 ; / / bigger than this don ' t go in the region <nl> <nl> private final AtomicReference < Region > currentRegion = new AtomicReference < Region > ( ) ; <nl> - private volatile int regionCount ; <nl> + private volatile int regionCount = 0 ; <nl> + private AtomicLong unslabbed = new AtomicLong ( 0 ) ; <nl> <nl> public ByteBuffer allocate ( int size ) <nl> { <nl> @ @ - 58 , 7 + 60 , 10 @ @ public class SlabAllocator extends Allocator <nl> / / satisfy large allocations directly from JVM since they don ' t cause fragmentation <nl> / / as badly , and fill up our regions quickly <nl> if ( size > MAX _ CLONED _ SIZE ) <nl> + { <nl> + unslabbed . addAndGet ( size ) ; <nl> return ByteBuffer . allocate ( size ) ; <nl> + } <nl> <nl> while ( true ) <nl> { <nl> @ @ - 104 , 6 + 109 , 22 @ @ public class SlabAllocator extends Allocator <nl> } <nl> <nl> / * * <nl> + * @ return a lower bound on how much space has been allocated <nl> + * / <nl> + public long getMinimumSize ( ) <nl> + { <nl> + return unslabbed . get ( ) + ( regionCount - 1 ) * REGION _ SIZE ; <nl> + } <nl> + <nl> + / * * <nl> + * @ return an upper bound on how much space has been allocated <nl> + * / <nl> + public long getMaximumSize ( ) <nl> + { <nl> + return unslabbed . get ( ) + regionCount * REGION _ SIZE ; <nl> + } <nl> + <nl> + / * * <nl> * A region of memory out of which allocations are sliced . <nl> * <nl> * This serves two purposes :

TEST DIFF:
diff - - git a / src / java / org / apache / cassandra / db / compaction / LazilyCompactedRow . java b / src / java / org / apache / cassandra / db / compaction / LazilyCompactedRow . java 
 index 3b7a3d4 . . 0d33b22 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / LazilyCompactedRow . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / LazilyCompactedRow . java 
 @ @ - 58 , 8 + 58 , 7 @ @ public class LazilyCompactedRow extends AbstractCompactedRow implements Iterable 
 private boolean closed ; 
 private ColumnIndex . Builder indexBuilder ; 
 private final SecondaryIndexManager . Updater indexer ; 
 - private long maxTombstoneTimestamp ; 
 - private DeletionInfo deletionInfo ; 
 + private DeletionTime maxRowTombstone ; 
 
 public LazilyCompactedRow ( CompactionController controller , List < ? extends OnDiskAtomIterator > rows ) 
 { 
 @ @ - 70 , 23 + 69 , 23 @ @ public class LazilyCompactedRow extends AbstractCompactedRow implements Iterable 
 
 / / Combine top - level tombstones , keeping the one with the highest markedForDeleteAt timestamp . This may be 
 / / purged ( depending on gcBefore ) , but we need to remember it to properly delete columns during the merge 
 - deletionInfo = DeletionInfo . live ( ) ; 
 - maxTombstoneTimestamp = Long . MIN _ VALUE ; 
 + maxRowTombstone = DeletionTime . LIVE ; 
 for ( OnDiskAtomIterator row : rows ) 
 { 
 - DeletionInfo delInfo = row . getColumnFamily ( ) . deletionInfo ( ) ; 
 - maxTombstoneTimestamp = Math . max ( maxTombstoneTimestamp , delInfo . maxTimestamp ( ) ) ; 
 - deletionInfo = deletionInfo . add ( delInfo ) ; 
 + DeletionTime rowTombstone = row . getColumnFamily ( ) . deletionInfo ( ) . getTopLevelDeletion ( ) ; 
 + if ( maxRowTombstone . compareTo ( rowTombstone ) < 0 ) 
 + maxRowTombstone = rowTombstone ; 
 } 
 
 + 
 / / Don ' t pass maxTombstoneTimestamp to shouldPurge since we might well have cells with 
 / / tombstones newer than the row - level tombstones we ' ve seen - - but we won ' t know that 
 / / until we iterate over them . By passing MAX _ VALUE we will only purge if there are 
 / / no other versions of this row present . 
 this . shouldPurge = controller . shouldPurge ( key , Long . MAX _ VALUE ) ; 
 
 - emptyColumnFamily = ArrayBackedSortedColumns . factory . create ( controller . cfs . metadata ) ; 
 - emptyColumnFamily . setDeletionInfo ( deletionInfo . copy ( ) ) ; 
 + emptyColumnFamily = EmptyColumns . factory . create ( controller . cfs . metadata ) ; 
 + emptyColumnFamily . delete ( maxRowTombstone ) ; 
 if ( shouldPurge ) 
 emptyColumnFamily . purgeTombstones ( controller . gcBefore ) ; 
 } 
 @ @ - 113 , 7 + 112 , 7 @ @ public class LazilyCompactedRow extends AbstractCompactedRow implements Iterable 
 / / ( however , if there are zero columns , iterator ( ) will not be called by ColumnIndexer and reducer will be null ) 
 columnStats = new ColumnStats ( reducer = = null ? 0 : reducer . columns , 
 reducer = = null ? Long . MAX _ VALUE : reducer . minTimestampSeen , 
 - reducer = = null ? maxTombstoneTimestamp : Math . max ( maxTombstoneTimestamp , reducer . maxTimestampSeen ) , 
 + reducer = = null ? maxRowTombstone . markedForDeleteAt : Math . max ( maxRowTombstone . markedForDeleteAt , reducer . maxTimestampSeen ) , 
 reducer = = null ? Integer . MIN _ VALUE : reducer . maxLocalDeletionTimeSeen , 
 reducer = = null ? new StreamingHistogram ( SSTable . TOMBSTONE _ HISTOGRAM _ BIN _ SIZE ) : reducer . tombstones , 
 reducer = = null ? Collections . < ByteBuffer > emptyList ( ) : reducer . minColumnNameSeen , 
 @ @ - 193 , 8 + 192 , 9 @ @ public class LazilyCompactedRow extends AbstractCompactedRow implements Iterable 
 private class Reducer extends MergeIterator . Reducer < OnDiskAtom , OnDiskAtom > 
 { 
 / / all columns reduced together will have the same name , so there will only be one column 
 - / / in the container ; we just want to leverage the conflict resolution code from CF 
 - ColumnFamily container = emptyColumnFamily . cloneMeShallow ( ArrayBackedSortedColumns . factory , false ) ; 
 + / / in the container ; we just want to leverage the conflict resolution code from CF . 
 + / / ( Note that we add the row tombstone in getReduced . ) 
 + final ColumnFamily container = ArrayBackedSortedColumns . factory . create ( emptyColumnFamily . metadata ( ) ) ; 
 
 / / tombstone reference ; will be reconciled w / column during getReduced . Note that the top - level ( row ) tombstone 
 / / is held by LCR . deletionInfo . 
 @ @ - 258 , 7 + 258 , 7 @ @ public class LazilyCompactedRow extends AbstractCompactedRow implements Iterable 
 else 
 { 
 / / when we clear ( ) the container , it removes the deletion info , so this needs to be reset each time 
 - container . setDeletionInfo ( deletionInfo ) ; 
 + container . delete ( maxRowTombstone ) ; 
 ColumnFamily purged = PrecompactedRow . removeDeletedAndOldShards ( key , shouldPurge , controller , container ) ; 
 if ( purged = = null | | ! purged . iterator ( ) . hasNext ( ) ) 
 {

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 80c9b44 . . 7fc93f4 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 8 , 6 + 8 , 8 @ @ 
 * Fix SemanticVersion . isSupportedBy minor / patch handling ( CASSANDRA - 5496 ) 
 Merged from 1 . 1 
 * Add retry mechanism to OTC for non - droppable _ verbs ( CASSANDRA - 5393 ) 
 + * Use allocator information to improve memtable memory usage estimate 
 + ( CASSANDRA - 5497 ) 
 * Fix trying to load deleted row into row cache on startup ( CASSANDRA - 4463 ) 
 
 
 diff - - git a / src / java / org / apache / cassandra / db / Memtable . java b / src / java / org / apache / cassandra / db / Memtable . java 
 index 301c297 . . 282acd2 100644 
 - - - a / src / java / org / apache / cassandra / db / Memtable . java 
 + + + b / src / java / org / apache / cassandra / db / Memtable . java 
 @ @ - 150 , 7 + 150 , 15 @ @ public class Memtable 
 
 public long getLiveSize ( ) 
 { 
 - return ( long ) ( currentSize . get ( ) * cfs . liveRatio ) ; 
 + long estimatedSize = ( long ) ( currentSize . get ( ) * cfs . liveRatio ) ; 
 + 
 + / / cap the estimate at both ends by what the allocator can tell us 
 + if ( estimatedSize < allocator . getMinimumSize ( ) ) 
 + return allocator . getMinimumSize ( ) ; 
 + if ( estimatedSize > allocator . getMaximumSize ( ) ) 
 + return allocator . getMaximumSize ( ) ; 
 + 
 + return estimatedSize ; 
 } 
 
 public long getSerializedSize ( ) 
 @ @ - 228 , 7 + 236 , 7 @ @ public class Memtable 
 cfs . liveRatio = ( cfs . liveRatio + newRatio ) / 2 . 0 ; 
 
 logger . info ( " { } liveRatio is { } ( just - counted was { } ) . calculation took { } ms for { } columns " , 
 - new Object [ ] { cfs , cfs . liveRatio , newRatio , System . currentTimeMillis ( ) - start , objects } ) ; 
 + cfs , cfs . liveRatio , newRatio , System . currentTimeMillis ( ) - start , objects ) ; 
 activelyMeasuring = null ; 
 } 
 finally 
 diff - - git a / src / java / org / apache / cassandra / utils / SlabAllocator . java b / src / java / org / apache / cassandra / utils / SlabAllocator . java 
 index 9d273e2 . . c50e8c4 100644 
 - - - a / src / java / org / apache / cassandra / utils / SlabAllocator . java 
 + + + b / src / java / org / apache / cassandra / utils / SlabAllocator . java 
 @ @ - 19 , 6 + 19 , 7 @ @ package org . apache . cassandra . utils ; 
 
 import java . nio . ByteBuffer ; 
 import java . util . concurrent . atomic . AtomicInteger ; 
 + import java . util . concurrent . atomic . AtomicLong ; 
 import java . util . concurrent . atomic . AtomicReference ; 
 
 import com . google . common . base . Preconditions ; 
 @ @ - 47 , 7 + 48 , 8 @ @ public class SlabAllocator extends Allocator 
 private final static int MAX _ CLONED _ SIZE = 128 * 1024 ; / / bigger than this don ' t go in the region 
 
 private final AtomicReference < Region > currentRegion = new AtomicReference < Region > ( ) ; 
 - private volatile int regionCount ; 
 + private volatile int regionCount = 0 ; 
 + private AtomicLong unslabbed = new AtomicLong ( 0 ) ; 
 
 public ByteBuffer allocate ( int size ) 
 { 
 @ @ - 58 , 7 + 60 , 10 @ @ public class SlabAllocator extends Allocator 
 / / satisfy large allocations directly from JVM since they don ' t cause fragmentation 
 / / as badly , and fill up our regions quickly 
 if ( size > MAX _ CLONED _ SIZE ) 
 + { 
 + unslabbed . addAndGet ( size ) ; 
 return ByteBuffer . allocate ( size ) ; 
 + } 
 
 while ( true ) 
 { 
 @ @ - 104 , 6 + 109 , 22 @ @ public class SlabAllocator extends Allocator 
 } 
 
 / * * 
 + * @ return a lower bound on how much space has been allocated 
 + * / 
 + public long getMinimumSize ( ) 
 + { 
 + return unslabbed . get ( ) + ( regionCount - 1 ) * REGION _ SIZE ; 
 + } 
 + 
 + / * * 
 + * @ return an upper bound on how much space has been allocated 
 + * / 
 + public long getMaximumSize ( ) 
 + { 
 + return unslabbed . get ( ) + regionCount * REGION _ SIZE ; 
 + } 
 + 
 + / * * 
 * A region of memory out of which allocations are sliced . 
 * 
 * This serves two purposes :
