BLEU SCORE: 0.11044795567078944

TEST MSG: Revert flush directory ( CASSANDRA - 6357 )
GENERATED MSG: Add flush directory distinct from compaction directories

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 3b09b7d . . 6854392 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 1 . 0 - rc1 <nl> + * Revert flush directory ( CASSANDRA - 6357 ) <nl> * More efficient executor service for fast operations ( CASSANDRA - 4718 ) <nl> * Move less common tools into a new cassandra - tools package ( CASSANDRA - 7160 ) <nl> * Support more concurrent requests in native protocol ( CASSANDRA - 7231 ) <nl> diff - - git a / conf / cassandra . yaml b / conf / cassandra . yaml <nl> index b9964ed . . 561c7ff 100644 <nl> - - - a / conf / cassandra . yaml <nl> + + + b / conf / cassandra . yaml <nl> @ @ - 100 , 12 + 100 , 6 @ @ data _ file _ directories : <nl> # separate spindle than the data directories . <nl> commitlog _ directory : / var / lib / cassandra / commitlog <nl> <nl> - # location to write flushing sstables to . Ideally , this will also be <nl> - # a separate spindle in HDD deployments . If you only have two spindles , <nl> - # have it share with the data spindle . By default , this will point at the data <nl> - # directory . <nl> - # flush _ directory : / var / lib / cassandra / flush <nl> - <nl> # policy for data disk failures : <nl> # stop _ paranoid : shut down gossip and Thrift even for single - sstable errors . <nl> # stop : shut down gossip and Thrift , leaving the node effectively dead , but <nl> @ @ - 299 , 8 + 293 , 8 @ @ memtable _ allocation _ type : heap _ buffers <nl> # This sets the amount of memtable flush writer threads . These will <nl> # be blocked by disk io , and each one will hold a memtable in memory <nl> # while blocked . If your flush directory is backed by SSD , you may <nl> - # want to increase this ; by default it will be set to 2 . <nl> - # memtable _ flush _ writers : 2 <nl> + # want to increase this . <nl> + memtable _ flush _ writers : 2 <nl> <nl> # A fixed memory pool size in MB for for SSTable index summaries . If left <nl> # empty , this will default to 5 % of the heap size . If the memory usage of <nl> diff - - git a / src / java / org / apache / cassandra / config / Config . java b / src / java / org / apache / cassandra / config / Config . java <nl> index 07d0a59 . . 4069b15 100644 <nl> - - - a / src / java / org / apache / cassandra / config / Config . java <nl> + + + b / src / java / org / apache / cassandra / config / Config . java <nl> @ @ - 141 , 7 + 141 , 6 @ @ public class Config <nl> public volatile Integer inter _ dc _ stream _ throughput _ outbound _ megabits _ per _ sec = 0 ; <nl> <nl> public String [ ] data _ file _ directories ; <nl> - public String flush _ directory ; <nl> <nl> public String saved _ caches _ directory ; <nl> <nl> diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> index c916fea . . 5b227ae 100644 <nl> - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> @ @ - 461 , 9 + 461 , 6 @ @ public class DatabaseDescriptor <nl> / * data file and commit log directories . they get created later , when they ' re needed . * / <nl> if ( conf . commitlog _ directory ! = null & & conf . data _ file _ directories ! = null & & conf . saved _ caches _ directory ! = null ) <nl> { <nl> - if ( conf . flush _ directory = = null ) <nl> - conf . flush _ directory = conf . data _ file _ directories [ 0 ] ; <nl> - <nl> for ( String datadir : conf . data _ file _ directories ) <nl> { <nl> if ( datadir . equals ( conf . commitlog _ directory ) ) <nl> @ @ - 670 , 8 + 667 , 6 @ @ public class DatabaseDescriptor <nl> throw new ConfigurationException ( " saved _ caches _ directory must be specified " ) ; <nl> <nl> FileUtils . createDirectory ( conf . saved _ caches _ directory ) ; <nl> - <nl> - FileUtils . createDirectory ( conf . flush _ directory ) ; <nl> } <nl> catch ( ConfigurationException e ) <nl> { <nl> @ @ - 1523 , 9 + 1518 , 4 @ @ public class DatabaseDescriptor <nl> String arch = System . getProperty ( " os . arch " ) ; <nl> return arch . contains ( " 64 " ) | | arch . contains ( " sparcv9 " ) ; <nl> } <nl> - <nl> - public static String getFlushLocation ( ) <nl> - { <nl> - return conf . flush _ directory ; <nl> - } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / Directories . java b / src / java / org / apache / cassandra / db / Directories . java <nl> index a146855 . . 4319481 100644 <nl> - - - a / src / java / org / apache / cassandra / db / Directories . java <nl> + + + b / src / java / org / apache / cassandra / db / Directories . java <nl> @ @ - 17 , 6 + 17 , 8 @ @ <nl> * / <nl> package org . apache . cassandra . db ; <nl> <nl> + import static com . google . common . collect . Sets . newHashSet ; <nl> + <nl> import java . io . File ; <nl> import java . io . FileFilter ; <nl> import java . io . IOError ; <nl> @ @ - 39 , 26 + 41 , 20 @ @ import com . google . common . collect . ImmutableSet . Builder ; <nl> import com . google . common . collect . Iterables ; <nl> import com . google . common . primitives . Longs ; <nl> import com . google . common . util . concurrent . Uninterruptibles ; <nl> + <nl> import org . apache . commons . lang3 . StringUtils ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> - import org . apache . cassandra . config . CFMetaData ; <nl> - import org . apache . cassandra . config . Config ; <nl> - import org . apache . cassandra . config . DatabaseDescriptor ; <nl> + import org . apache . cassandra . config . * ; <nl> import org . apache . cassandra . io . FSError ; <nl> import org . apache . cassandra . io . FSWriteError ; <nl> - import org . apache . cassandra . io . sstable . Component ; <nl> - import org . apache . cassandra . io . sstable . Descriptor ; <nl> - import org . apache . cassandra . io . sstable . SSTable ; <nl> - import org . apache . cassandra . io . sstable . SSTableDeletingTask ; <nl> import org . apache . cassandra . io . util . FileUtils ; <nl> + import org . apache . cassandra . io . sstable . * ; <nl> import org . apache . cassandra . service . StorageService ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . apache . cassandra . utils . Pair ; <nl> <nl> - import static com . google . common . collect . Sets . newHashSet ; <nl> - <nl> / * * <nl> * Encapsulate handling of paths to the data files . <nl> * <nl> @ @ - 92 , 14 + 88 , 12 @ @ public class Directories <nl> public static final String SECONDARY _ INDEX _ NAME _ SEPARATOR = " . " ; <nl> <nl> public static final DataDirectory [ ] dataDirectories ; <nl> - public static final DataDirectory flushDirectory ; <nl> static <nl> { <nl> String [ ] locations = DatabaseDescriptor . getAllDataFileLocations ( ) ; <nl> dataDirectories = new DataDirectory [ locations . length ] ; <nl> for ( int i = 0 ; i < locations . length ; + + i ) <nl> dataDirectories [ i ] = new DataDirectory ( new File ( locations [ i ] ) ) ; <nl> - flushDirectory = new DataDirectory ( new File ( DatabaseDescriptor . getFlushLocation ( ) ) ) ; <nl> } <nl> <nl> <nl> @ @ - 178 , 7 + 172 , 6 @ @ public class Directories <nl> <nl> private final CFMetaData metadata ; <nl> private final File [ ] dataPaths ; <nl> - private final File flushPath ; <nl> <nl> / * * <nl> * Create Directories of given ColumnFamily . <nl> @ @ - 192 , 7 + 185 , 6 @ @ public class Directories <nl> if ( StorageService . instance . isClientMode ( ) ) <nl> { <nl> dataPaths = null ; <nl> - flushPath = null ; <nl> return ; <nl> } <nl> <nl> @ @ - 222 , 9 + 214 , 7 @ @ public class Directories <nl> dataPaths [ i ] = new File ( dataDirectories [ i ] . location , join ( metadata . ksName , directoryName ) ) ; <nl> } <nl> <nl> - flushPath = new File ( flushDirectory . location , join ( metadata . ksName , directoryName ) ) ; <nl> - <nl> - for ( File dir : allSSTablePaths ( ) ) <nl> + for ( File dir : dataPaths ) <nl> { <nl> try <nl> { <nl> @ @ - 240 , 26 + 230 , 6 @ @ public class Directories <nl> } <nl> <nl> / * * <nl> - * @ return an iterable of all possible sstable paths , including flush and post - compaction locations . <nl> - * Guaranteed to only return one copy of each path , even if there is no dedicated flush location and <nl> - * it shares with the others . <nl> - * / <nl> - private Iterable < File > allSSTablePaths ( ) <nl> - { <nl> - return ImmutableSet . < File > builder ( ) . add ( dataPaths ) . add ( flushPath ) . build ( ) ; <nl> - } <nl> - <nl> - / * * <nl> - * @ return an iterable of all possible sstable directories , including flush and post - compaction locations . <nl> - * Guaranteed to only return one copy of each directories , even if there is no dedicated flush location and <nl> - * it shares with the others . <nl> - * / <nl> - private static Iterable < DataDirectory > allSSTableDirectories ( ) <nl> - { <nl> - return ImmutableSet . < DataDirectory > builder ( ) . add ( dataDirectories ) . add ( flushDirectory ) . build ( ) ; <nl> - } <nl> - <nl> - / * * <nl> * Returns SSTable location which is inside given data directory . <nl> * <nl> * @ param dataDirectory <nl> @ @ - 267 , 7 + 237 , 7 @ @ public class Directories <nl> * / <nl> public File getLocationForDisk ( DataDirectory dataDirectory ) <nl> { <nl> - for ( File dir : allSSTablePaths ( ) ) <nl> + for ( File dir : dataPaths ) <nl> { <nl> if ( dir . getAbsolutePath ( ) . startsWith ( dataDirectory . location . getAbsolutePath ( ) ) ) <nl> return dir ; <nl> @ @ - 277 , 7 + 247 , 7 @ @ public class Directories <nl> <nl> public Descriptor find ( String filename ) <nl> { <nl> - for ( File dir : allSSTablePaths ( ) ) <nl> + for ( File dir : dataPaths ) <nl> { <nl> if ( new File ( dir , filename ) . exists ( ) ) <nl> return Descriptor . fromFilename ( dir , filename ) . left ; <nl> @ @ - 285 , 9 + 255 , 9 @ @ public class Directories <nl> return null ; <nl> } <nl> <nl> - public File getDirectoryForCompactedSSTables ( ) <nl> + public File getDirectoryForNewSSTables ( ) <nl> { <nl> - File path = getCompactionLocationAsFile ( ) ; <nl> + File path = getWriteableLocationAsFile ( ) ; <nl> <nl> / / Requesting GC has a chance to free space only if we ' re using mmap and a non SUN jvm <nl> if ( path = = null <nl> @ @ - 300 , 15 + 270 , 15 @ @ public class Directories <nl> / / Note : GCInspector will do this already , but only sun JVM supports GCInspector so far <nl> SSTableDeletingTask . rescheduleFailedTasks ( ) ; <nl> Uninterruptibles . sleepUninterruptibly ( 10 , TimeUnit . SECONDS ) ; <nl> - path = getCompactionLocationAsFile ( ) ; <nl> + path = getWriteableLocationAsFile ( ) ; <nl> } <nl> <nl> return path ; <nl> } <nl> <nl> - public File getCompactionLocationAsFile ( ) <nl> + public File getWriteableLocationAsFile ( ) <nl> { <nl> - return getLocationForDisk ( getCompactionLocation ( ) ) ; <nl> + return getLocationForDisk ( getWriteableLocation ( ) ) ; <nl> } <nl> <nl> / * * <nl> @ @ - 316 , 7 + 286 , 7 @ @ public class Directories <nl> * <nl> * @ throws IOError if all directories are blacklisted . <nl> * / <nl> - public DataDirectory getCompactionLocation ( ) <nl> + public DataDirectory getWriteableLocation ( ) <nl> { <nl> List < DataDirectory > candidates = new ArrayList < > ( ) ; <nl> <nl> @ @ - 346 , 13 + 316 , 6 @ @ public class Directories <nl> return candidates . get ( 0 ) ; <nl> } <nl> <nl> - public DataDirectory getFlushLocation ( ) <nl> - { <nl> - return BlacklistedDirectories . isUnwritable ( flushPath ) <nl> - ? getCompactionLocation ( ) <nl> - : flushDirectory ; <nl> - } <nl> - <nl> public static File getSnapshotDirectory ( Descriptor desc , String snapshotName ) <nl> { <nl> return getOrCreate ( desc . directory , SNAPSHOT _ SUBDIR , snapshotName ) ; <nl> @ @ - 360 , 7 + 323 , 7 @ @ public class Directories <nl> <nl> public File getSnapshotManifestFile ( String snapshotName ) <nl> { <nl> - return new File ( getDirectoryForCompactedSSTables ( ) , join ( SNAPSHOT _ SUBDIR , snapshotName , " manifest . json " ) ) ; <nl> + return new File ( getDirectoryForNewSSTables ( ) , join ( SNAPSHOT _ SUBDIR , snapshotName , " manifest . json " ) ) ; <nl> } <nl> <nl> public static File getBackupsDirectory ( Descriptor desc ) <nl> @ @ - 469 , 7 + 432 , 7 @ @ public class Directories <nl> if ( filtered ) <nl> return ; <nl> <nl> - for ( File location : allSSTablePaths ( ) ) <nl> + for ( File location : dataPaths ) <nl> { <nl> if ( BlacklistedDirectories . isUnreadable ( location ) ) <nl> continue ; <nl> @ @ - 531 , 7 + 494 , 7 @ @ public class Directories <nl> public Map < String , Pair < Long , Long > > getSnapshotDetails ( ) <nl> { <nl> final Map < String , Pair < Long , Long > > snapshotSpaceMap = new HashMap < > ( ) ; <nl> - for ( final File dir : allSSTablePaths ( ) ) <nl> + for ( final File dir : dataPaths ) <nl> { <nl> final File snapshotDir = new File ( dir , SNAPSHOT _ SUBDIR ) ; <nl> if ( snapshotDir . exists ( ) & & snapshotDir . isDirectory ( ) ) <nl> @ @ - 561 , 7 + 524 , 7 @ @ public class Directories <nl> } <nl> public boolean snapshotExists ( String snapshotName ) <nl> { <nl> - for ( File dir : allSSTablePaths ( ) ) <nl> + for ( File dir : dataPaths ) <nl> { <nl> File snapshotDir = new File ( dir , join ( SNAPSHOT _ SUBDIR , snapshotName ) ) ; <nl> if ( snapshotDir . exists ( ) ) <nl> @ @ - 589 , 7 + 552 , 7 @ @ public class Directories <nl> / / The snapshot must exist <nl> public long snapshotCreationTime ( String snapshotName ) <nl> { <nl> - for ( File dir : allSSTablePaths ( ) ) <nl> + for ( File dir : dataPaths ) <nl> { <nl> File snapshotDir = new File ( dir , join ( SNAPSHOT _ SUBDIR , snapshotName ) ) ; <nl> if ( snapshotDir . exists ( ) ) <nl> @ @ - 601 , 7 + 564 , 7 @ @ public class Directories <nl> public long trueSnapshotsSize ( ) <nl> { <nl> long result = 0L ; <nl> - for ( File dir : allSSTablePaths ( ) ) <nl> + for ( File dir : dataPaths ) <nl> result + = getTrueAllocatedSizeIn ( new File ( dir , join ( SNAPSHOT _ SUBDIR ) ) ) ; <nl> return result ; <nl> } <nl> @ @ - 633 , 7 + 596 , 7 @ @ public class Directories <nl> public static List < File > getKSChildDirectories ( String ksName ) <nl> { <nl> List < File > result = new ArrayList < > ( ) ; <nl> - for ( DataDirectory dataDirectory : allSSTableDirectories ( ) ) <nl> + for ( DataDirectory dataDirectory : dataDirectories ) <nl> { <nl> File ksDir = new File ( dataDirectory . location , ksName ) ; <nl> File [ ] cfDirs = ksDir . listFiles ( ) ; <nl> @ @ - 651 , 7 + 614 , 7 @ @ public class Directories <nl> public List < File > getCFDirectories ( ) <nl> { <nl> List < File > result = new ArrayList < > ( ) ; <nl> - for ( File dataDirectory : allSSTablePaths ( ) ) <nl> + for ( File dataDirectory : dataPaths ) <nl> { <nl> if ( dataDirectory . isDirectory ( ) ) <nl> result . add ( dataDirectory ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / Memtable . java b / src / java / org / apache / cassandra / db / Memtable . java <nl> index 6f4c1c7 . . 417b4a7 100644 <nl> - - - a / src / java / org / apache / cassandra / db / Memtable . java <nl> + + + b / src / java / org / apache / cassandra / db / Memtable . java <nl> @ @ - 302 , 11 + 302 , 6 @ @ public class Memtable <nl> * 1 . 2 ) ; / / bloom filter and row index overhead <nl> } <nl> <nl> - protected Directories . DataDirectory getWriteableLocation ( ) <nl> - { <nl> - return cfs . directories . getFlushLocation ( ) ; <nl> - } <nl> - <nl> public long getExpectedWriteSize ( ) <nl> { <nl> return estimatedSize ; <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionTask . java b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionTask . java <nl> index 5f9c7ae . . 59338f4 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionTask . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionTask . java <nl> @ @ - 49 , 11 + 49 , 6 @ @ public abstract class AbstractCompactionTask extends DiskAwareRunnable <nl> assert compacting . contains ( sstable ) : sstable . getFilename ( ) + " is not correctly marked compacting " ; <nl> } <nl> <nl> - protected Directories . DataDirectory getWriteableLocation ( ) <nl> - { <nl> - return cfs . directories . getCompactionLocation ( ) ; <nl> - } <nl> - <nl> / * * <nl> * executes the task and unmarks sstables compacting <nl> * / <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> index 7fc27ae . . 227f908 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> @ @ - 674 , 7 + 674 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> <nl> logger . info ( " Cleaning up { } " , sstable ) ; <nl> <nl> - File compactionFileLocation = cfs . directories . getDirectoryForCompactedSSTables ( ) ; <nl> + File compactionFileLocation = cfs . directories . getDirectoryForNewSSTables ( ) ; <nl> if ( compactionFileLocation = = null ) <nl> throw new IOException ( " disk full " ) ; <nl> <nl> @ @ - 953 , 7 + 953 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> Set < SSTableReader > sstableAsSet = new HashSet < > ( ) ; <nl> sstableAsSet . add ( sstable ) ; <nl> <nl> - File destination = cfs . directories . getDirectoryForCompactedSSTables ( ) ; <nl> + File destination = cfs . directories . getDirectoryForNewSSTables ( ) ; <nl> SSTableRewriter repairedSSTableWriter = new SSTableRewriter ( cfs , sstableAsSet , sstable . maxDataAge , OperationType . ANTICOMPACTION , false ) ; <nl> SSTableRewriter unRepairedSSTableWriter = new SSTableRewriter ( cfs , sstableAsSet , sstable . maxDataAge , OperationType . ANTICOMPACTION , false ) ; <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / Scrubber . java b / src / java / org / apache / cassandra / db / compaction / Scrubber . java <nl> index 399f96c . . 7303da1 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / Scrubber . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / Scrubber . java <nl> @ @ - 80 , 7 + 80 , 7 @ @ public class Scrubber implements Closeable <nl> this . isOffline = isOffline ; <nl> <nl> / / Calculate the expected compacted filesize <nl> - this . destination = cfs . directories . getDirectoryForCompactedSSTables ( ) ; <nl> + this . destination = cfs . directories . getDirectoryForNewSSTables ( ) ; <nl> if ( destination = = null ) <nl> throw new IOException ( " disk full " ) ; <nl> <nl> diff - - git a / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java b / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java <nl> index f0e2756 . . 198a88d 100644 <nl> - - - a / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java <nl> + + + b / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java <nl> @ @ - 34 , 7 + 34 , 7 @ @ public abstract class DiskAwareRunnable extends WrappedRunnable <nl> while ( true ) <nl> { <nl> writeSize = getExpectedWriteSize ( ) ; <nl> - directory = getWriteableLocation ( ) ; <nl> + directory = getDirectories ( ) . getWriteableLocation ( ) ; <nl> if ( directory ! = null | | ! reduceScopeForLimitedSpace ( ) ) <nl> break ; <nl> } <nl> @ @ - 54 , 8 + 54 , 6 @ @ public abstract class DiskAwareRunnable extends WrappedRunnable <nl> } <nl> } <nl> <nl> - protected abstract Directories . DataDirectory getWriteableLocation ( ) ; <nl> - <nl> / * * <nl> * Get sstable directories for the CF . <nl> * @ return Directories instance for the CF . <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamReader . java b / src / java / org / apache / cassandra / streaming / StreamReader . java <nl> index c26a61b . . d805bf3 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamReader . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamReader . java <nl> @ @ - 40 , 6 + 40 , 7 @ @ import org . apache . cassandra . db . Keyspace ; <nl> import org . apache . cassandra . io . sstable . Component ; <nl> import org . apache . cassandra . io . sstable . Descriptor ; <nl> import org . apache . cassandra . io . sstable . SSTableWriter ; <nl> + import org . apache . cassandra . service . ActiveRepairService ; <nl> import org . apache . cassandra . service . StorageService ; <nl> import org . apache . cassandra . streaming . messages . FileMessageHeader ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> @ @ - 110 , 7 + 111 , 7 @ @ public class StreamReader <nl> <nl> protected SSTableWriter createWriter ( ColumnFamilyStore cfs , long totalSize , long repairedAt ) throws IOException <nl> { <nl> - Directories . DataDirectory localDir = cfs . directories . getCompactionLocation ( ) ; <nl> + Directories . DataDirectory localDir = cfs . directories . getWriteableLocation ( ) ; <nl> if ( localDir = = null ) <nl> throw new IOException ( " Insufficient disk space to store " + totalSize + " bytes " ) ; <nl> desc = Descriptor . fromFilename ( cfs . getTempSSTablePath ( cfs . directories . getLocationForDisk ( localDir ) ) ) ; <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamReceiveTask . java b / src / java / org / apache / cassandra / streaming / StreamReceiveTask . java <nl> index e5ef691 . . b4d5392 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamReceiveTask . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamReceiveTask . java <nl> @ @ - 27 , 6 + 27 , 7 @ @ import org . apache . cassandra . db . ColumnFamilyStore ; <nl> import org . apache . cassandra . db . Keyspace ; <nl> import org . apache . cassandra . io . sstable . SSTableReader ; <nl> import org . apache . cassandra . io . sstable . SSTableWriter ; <nl> + import org . apache . cassandra . service . ActiveRepairService ; <nl> import org . apache . cassandra . service . StorageService ; <nl> import org . apache . cassandra . utils . Pair ; <nl> <nl> @ @ - 97 , 7 + 98 , 7 @ @ public class StreamReceiveTask extends StreamTask <nl> Pair < String , String > kscf = Schema . instance . getCF ( task . cfId ) ; <nl> ColumnFamilyStore cfs = Keyspace . open ( kscf . left ) . getColumnFamilyStore ( kscf . right ) ; <nl> <nl> - StreamLockfile lockfile = new StreamLockfile ( cfs . directories . getCompactionLocationAsFile ( ) , UUID . randomUUID ( ) ) ; <nl> + StreamLockfile lockfile = new StreamLockfile ( cfs . directories . getWriteableLocationAsFile ( ) , UUID . randomUUID ( ) ) ; <nl> lockfile . create ( task . sstables ) ; <nl> List < SSTableReader > readers = new ArrayList < > ( ) ; <nl> for ( SSTableWriter writer : task . sstables ) <nl> diff - - git a / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java b / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java <nl> index e792bf9 . . b178e48 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java <nl> @ @ - 954 , 7 + 954 , 7 @ @ public class ColumnFamilyStoreTest extends SchemaLoader <nl> <nl> for ( int version = 1 ; version < = 2 ; + + version ) <nl> { <nl> - Descriptor existing = new Descriptor ( cfs . directories . getDirectoryForCompactedSSTables ( ) , " Keyspace2 " , " Standard1 " , version , Descriptor . Type . FINAL ) ; <nl> + Descriptor existing = new Descriptor ( cfs . directories . getDirectoryForNewSSTables ( ) , " Keyspace2 " , " Standard1 " , version , Descriptor . Type . FINAL ) ; <nl> Descriptor desc = new Descriptor ( Directories . getBackupsDirectory ( existing ) , " Keyspace2 " , " Standard1 " , version , Descriptor . Type . FINAL ) ; <nl> for ( Component c : new Component [ ] { Component . DATA , Component . PRIMARY _ INDEX , Component . FILTER , Component . STATS } ) <nl> assertTrue ( " can not find backedup file : " + desc . filenameFor ( c ) , new File ( desc . filenameFor ( c ) ) . exists ( ) ) ; <nl> @ @ - 1662 , 7 + 1662 , 7 @ @ public class ColumnFamilyStoreTest extends SchemaLoader <nl> ByteBuffer key = bytes ( " key " ) ; <nl> <nl> / / 1st sstable <nl> - SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForCompactedSSTables ( ) , cfmeta , StorageService . getPartitioner ( ) ) ; <nl> + SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForNewSSTables ( ) , cfmeta , StorageService . getPartitioner ( ) ) ; <nl> writer . newRow ( key ) ; <nl> writer . addColumn ( bytes ( " col " ) , bytes ( " val " ) , 1 ) ; <nl> writer . close ( ) ; <nl> @ @ - 1674 , 7 + 1674 , 7 @ @ public class ColumnFamilyStoreTest extends SchemaLoader <nl> final SSTableReader sstable1 = SSTableReader . open ( sstableToOpen . getKey ( ) ) ; <nl> <nl> / / simulate incomplete compaction <nl> - writer = new SSTableSimpleWriter ( dir . getDirectoryForCompactedSSTables ( ) , <nl> + writer = new SSTableSimpleWriter ( dir . getDirectoryForNewSSTables ( ) , <nl> cfmeta , StorageService . getPartitioner ( ) ) <nl> { <nl> protected SSTableWriter getWriter ( ) <nl> @ @ - 1729 , 7 + 1729 , 7 @ @ public class ColumnFamilyStoreTest extends SchemaLoader <nl> <nl> / / Write SSTable generation 3 that has ancestors 1 and 2 <nl> final Set < Integer > ancestors = Sets . newHashSet ( 1 , 2 ) ; <nl> - SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForCompactedSSTables ( ) , <nl> + SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForNewSSTables ( ) , <nl> cfmeta , StorageService . getPartitioner ( ) ) <nl> { <nl> protected SSTableWriter getWriter ( ) <nl> @ @ - 1796 , 13 + 1796 , 13 @ @ public class ColumnFamilyStoreTest extends SchemaLoader <nl> <nl> ByteBuffer key = bytes ( " key " ) ; <nl> <nl> - SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForCompactedSSTables ( ) , <nl> - cfmeta , StorageService . getPartitioner ( ) ) ; <nl> + SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForNewSSTables ( ) , <nl> + cfmeta , StorageService . getPartitioner ( ) ) ; <nl> writer . newRow ( key ) ; <nl> writer . addColumn ( bytes ( " col " ) , bytes ( " val " ) , 1 ) ; <nl> writer . close ( ) ; <nl> <nl> - writer = new SSTableSimpleWriter ( dir . getDirectoryForCompactedSSTables ( ) , <nl> + writer = new SSTableSimpleWriter ( dir . getDirectoryForNewSSTables ( ) , <nl> cfmeta , StorageService . getPartitioner ( ) ) ; <nl> writer . newRow ( key ) ; <nl> writer . addColumn ( bytes ( " col " ) , bytes ( " val " ) , 1 ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / DirectoriesTest . java b / test / unit / org / apache / cassandra / db / DirectoriesTest . java <nl> index 1b9409a . . 9e6b26b 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / DirectoriesTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / DirectoriesTest . java <nl> @ @ - 30 , 7 + 30 , 6 @ @ import java . util . concurrent . Callable ; <nl> import java . util . concurrent . Executors ; <nl> import java . util . concurrent . Future ; <nl> <nl> - import com . google . common . collect . Lists ; <nl> import org . junit . AfterClass ; <nl> import org . junit . BeforeClass ; <nl> import org . junit . Test ; <nl> @ @ - 125 , 7 + 124 , 7 @ @ public class DirectoriesTest <nl> for ( CFMetaData cfm : CFM ) <nl> { <nl> Directories directories = new Directories ( cfm ) ; <nl> - assertEquals ( cfDir ( cfm ) , directories . getDirectoryForCompactedSSTables ( ) ) ; <nl> + assertEquals ( cfDir ( cfm ) , directories . getDirectoryForNewSSTables ( ) ) ; <nl> <nl> Descriptor desc = new Descriptor ( cfDir ( cfm ) , KS , cfm . cfName , 1 , Descriptor . Type . FINAL ) ; <nl> File snapshotDir = new File ( cfDir ( cfm ) , File . separator + Directories . SNAPSHOT _ SUBDIR + File . separator + " 42 " ) ; <nl> @ @ - 187 , 13 + 186 , 12 @ @ public class DirectoriesTest <nl> public void testDiskFailurePolicy _ best _ effort ( ) <nl> { <nl> DiskFailurePolicy origPolicy = DatabaseDescriptor . getDiskFailurePolicy ( ) ; <nl> - <nl> - List < DataDirectory > directories = Lists . asList ( Directories . flushDirectory , Directories . dataDirectories ) ; <nl> - try <nl> + <nl> + try <nl> { <nl> DatabaseDescriptor . setDiskFailurePolicy ( DiskFailurePolicy . best _ effort ) ; <nl> - <nl> - for ( DataDirectory dd : directories ) <nl> + <nl> + for ( DataDirectory dd : Directories . dataDirectories ) <nl> { <nl> dd . location . setExecutable ( false ) ; <nl> dd . location . setWritable ( false ) ; <nl> @ @ - 210 , 7 + 208 , 7 @ @ public class DirectoriesTest <nl> } <nl> finally <nl> { <nl> - for ( DataDirectory dd : directories ) <nl> + for ( DataDirectory dd : Directories . dataDirectories ) <nl> { <nl> dd . location . setExecutable ( true ) ; <nl> dd . location . setWritable ( true ) ; <nl> @ @ - 226 , 7 + 224 , 7 @ @ public class DirectoriesTest <nl> for ( final CFMetaData cfm : CFM ) <nl> { <nl> final Directories directories = new Directories ( cfm ) ; <nl> - assertEquals ( cfDir ( cfm ) , directories . getDirectoryForCompactedSSTables ( ) ) ; <nl> + assertEquals ( cfDir ( cfm ) , directories . getDirectoryForNewSSTables ( ) ) ; <nl> final String n = Long . toString ( System . nanoTime ( ) ) ; <nl> Callable < File > directoryGetter = new Callable < File > ( ) { <nl> public File call ( ) throws Exception { <nl> diff - - git a / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java b / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java <nl> index 5995fe3 . . 15980a4 100644 <nl> - - - a / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java <nl> + + + b / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java <nl> @ @ - 44 , 7 + 44 , 7 @ @ public class SSTableSimpleWriterTest extends SchemaLoader <nl> String cfname = " StandardInteger1 " ; <nl> <nl> Keyspace t = Keyspace . open ( keyspaceName ) ; / / make sure we create the directory <nl> - File dir = new Directories ( Schema . instance . getCFMetaData ( keyspaceName , cfname ) ) . getDirectoryForCompactedSSTables ( ) ; <nl> + File dir = new Directories ( Schema . instance . getCFMetaData ( keyspaceName , cfname ) ) . getDirectoryForNewSSTables ( ) ; <nl> assert dir . exists ( ) ; <nl> <nl> IPartitioner partitioner = StorageService . getPartitioner ( ) ;
NEAREST DIFF (one line): ELIMINATEDSENTENCE

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 3b09b7d . . 6854392 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 1 . 0 - rc1 
 + * Revert flush directory ( CASSANDRA - 6357 ) 
 * More efficient executor service for fast operations ( CASSANDRA - 4718 ) 
 * Move less common tools into a new cassandra - tools package ( CASSANDRA - 7160 ) 
 * Support more concurrent requests in native protocol ( CASSANDRA - 7231 ) 
 diff - - git a / conf / cassandra . yaml b / conf / cassandra . yaml 
 index b9964ed . . 561c7ff 100644 
 - - - a / conf / cassandra . yaml 
 + + + b / conf / cassandra . yaml 
 @ @ - 100 , 12 + 100 , 6 @ @ data _ file _ directories : 
 # separate spindle than the data directories . 
 commitlog _ directory : / var / lib / cassandra / commitlog 
 
 - # location to write flushing sstables to . Ideally , this will also be 
 - # a separate spindle in HDD deployments . If you only have two spindles , 
 - # have it share with the data spindle . By default , this will point at the data 
 - # directory . 
 - # flush _ directory : / var / lib / cassandra / flush 
 - 
 # policy for data disk failures : 
 # stop _ paranoid : shut down gossip and Thrift even for single - sstable errors . 
 # stop : shut down gossip and Thrift , leaving the node effectively dead , but 
 @ @ - 299 , 8 + 293 , 8 @ @ memtable _ allocation _ type : heap _ buffers 
 # This sets the amount of memtable flush writer threads . These will 
 # be blocked by disk io , and each one will hold a memtable in memory 
 # while blocked . If your flush directory is backed by SSD , you may 
 - # want to increase this ; by default it will be set to 2 . 
 - # memtable _ flush _ writers : 2 
 + # want to increase this . 
 + memtable _ flush _ writers : 2 
 
 # A fixed memory pool size in MB for for SSTable index summaries . If left 
 # empty , this will default to 5 % of the heap size . If the memory usage of 
 diff - - git a / src / java / org / apache / cassandra / config / Config . java b / src / java / org / apache / cassandra / config / Config . java 
 index 07d0a59 . . 4069b15 100644 
 - - - a / src / java / org / apache / cassandra / config / Config . java 
 + + + b / src / java / org / apache / cassandra / config / Config . java 
 @ @ - 141 , 7 + 141 , 6 @ @ public class Config 
 public volatile Integer inter _ dc _ stream _ throughput _ outbound _ megabits _ per _ sec = 0 ; 
 
 public String [ ] data _ file _ directories ; 
 - public String flush _ directory ; 
 
 public String saved _ caches _ directory ; 
 
 diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 index c916fea . . 5b227ae 100644 
 - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 @ @ - 461 , 9 + 461 , 6 @ @ public class DatabaseDescriptor 
 / * data file and commit log directories . they get created later , when they ' re needed . * / 
 if ( conf . commitlog _ directory ! = null & & conf . data _ file _ directories ! = null & & conf . saved _ caches _ directory ! = null ) 
 { 
 - if ( conf . flush _ directory = = null ) 
 - conf . flush _ directory = conf . data _ file _ directories [ 0 ] ; 
 - 
 for ( String datadir : conf . data _ file _ directories ) 
 { 
 if ( datadir . equals ( conf . commitlog _ directory ) ) 
 @ @ - 670 , 8 + 667 , 6 @ @ public class DatabaseDescriptor 
 throw new ConfigurationException ( " saved _ caches _ directory must be specified " ) ; 
 
 FileUtils . createDirectory ( conf . saved _ caches _ directory ) ; 
 - 
 - FileUtils . createDirectory ( conf . flush _ directory ) ; 
 } 
 catch ( ConfigurationException e ) 
 { 
 @ @ - 1523 , 9 + 1518 , 4 @ @ public class DatabaseDescriptor 
 String arch = System . getProperty ( " os . arch " ) ; 
 return arch . contains ( " 64 " ) | | arch . contains ( " sparcv9 " ) ; 
 } 
 - 
 - public static String getFlushLocation ( ) 
 - { 
 - return conf . flush _ directory ; 
 - } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / Directories . java b / src / java / org / apache / cassandra / db / Directories . java 
 index a146855 . . 4319481 100644 
 - - - a / src / java / org / apache / cassandra / db / Directories . java 
 + + + b / src / java / org / apache / cassandra / db / Directories . java 
 @ @ - 17 , 6 + 17 , 8 @ @ 
 * / 
 package org . apache . cassandra . db ; 
 
 + import static com . google . common . collect . Sets . newHashSet ; 
 + 
 import java . io . File ; 
 import java . io . FileFilter ; 
 import java . io . IOError ; 
 @ @ - 39 , 26 + 41 , 20 @ @ import com . google . common . collect . ImmutableSet . Builder ; 
 import com . google . common . collect . Iterables ; 
 import com . google . common . primitives . Longs ; 
 import com . google . common . util . concurrent . Uninterruptibles ; 
 + 
 import org . apache . commons . lang3 . StringUtils ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 - import org . apache . cassandra . config . CFMetaData ; 
 - import org . apache . cassandra . config . Config ; 
 - import org . apache . cassandra . config . DatabaseDescriptor ; 
 + import org . apache . cassandra . config . * ; 
 import org . apache . cassandra . io . FSError ; 
 import org . apache . cassandra . io . FSWriteError ; 
 - import org . apache . cassandra . io . sstable . Component ; 
 - import org . apache . cassandra . io . sstable . Descriptor ; 
 - import org . apache . cassandra . io . sstable . SSTable ; 
 - import org . apache . cassandra . io . sstable . SSTableDeletingTask ; 
 import org . apache . cassandra . io . util . FileUtils ; 
 + import org . apache . cassandra . io . sstable . * ; 
 import org . apache . cassandra . service . StorageService ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . apache . cassandra . utils . Pair ; 
 
 - import static com . google . common . collect . Sets . newHashSet ; 
 - 
 / * * 
 * Encapsulate handling of paths to the data files . 
 * 
 @ @ - 92 , 14 + 88 , 12 @ @ public class Directories 
 public static final String SECONDARY _ INDEX _ NAME _ SEPARATOR = " . " ; 
 
 public static final DataDirectory [ ] dataDirectories ; 
 - public static final DataDirectory flushDirectory ; 
 static 
 { 
 String [ ] locations = DatabaseDescriptor . getAllDataFileLocations ( ) ; 
 dataDirectories = new DataDirectory [ locations . length ] ; 
 for ( int i = 0 ; i < locations . length ; + + i ) 
 dataDirectories [ i ] = new DataDirectory ( new File ( locations [ i ] ) ) ; 
 - flushDirectory = new DataDirectory ( new File ( DatabaseDescriptor . getFlushLocation ( ) ) ) ; 
 } 
 
 
 @ @ - 178 , 7 + 172 , 6 @ @ public class Directories 
 
 private final CFMetaData metadata ; 
 private final File [ ] dataPaths ; 
 - private final File flushPath ; 
 
 / * * 
 * Create Directories of given ColumnFamily . 
 @ @ - 192 , 7 + 185 , 6 @ @ public class Directories 
 if ( StorageService . instance . isClientMode ( ) ) 
 { 
 dataPaths = null ; 
 - flushPath = null ; 
 return ; 
 } 
 
 @ @ - 222 , 9 + 214 , 7 @ @ public class Directories 
 dataPaths [ i ] = new File ( dataDirectories [ i ] . location , join ( metadata . ksName , directoryName ) ) ; 
 } 
 
 - flushPath = new File ( flushDirectory . location , join ( metadata . ksName , directoryName ) ) ; 
 - 
 - for ( File dir : allSSTablePaths ( ) ) 
 + for ( File dir : dataPaths ) 
 { 
 try 
 { 
 @ @ - 240 , 26 + 230 , 6 @ @ public class Directories 
 } 
 
 / * * 
 - * @ return an iterable of all possible sstable paths , including flush and post - compaction locations . 
 - * Guaranteed to only return one copy of each path , even if there is no dedicated flush location and 
 - * it shares with the others . 
 - * / 
 - private Iterable < File > allSSTablePaths ( ) 
 - { 
 - return ImmutableSet . < File > builder ( ) . add ( dataPaths ) . add ( flushPath ) . build ( ) ; 
 - } 
 - 
 - / * * 
 - * @ return an iterable of all possible sstable directories , including flush and post - compaction locations . 
 - * Guaranteed to only return one copy of each directories , even if there is no dedicated flush location and 
 - * it shares with the others . 
 - * / 
 - private static Iterable < DataDirectory > allSSTableDirectories ( ) 
 - { 
 - return ImmutableSet . < DataDirectory > builder ( ) . add ( dataDirectories ) . add ( flushDirectory ) . build ( ) ; 
 - } 
 - 
 - / * * 
 * Returns SSTable location which is inside given data directory . 
 * 
 * @ param dataDirectory 
 @ @ - 267 , 7 + 237 , 7 @ @ public class Directories 
 * / 
 public File getLocationForDisk ( DataDirectory dataDirectory ) 
 { 
 - for ( File dir : allSSTablePaths ( ) ) 
 + for ( File dir : dataPaths ) 
 { 
 if ( dir . getAbsolutePath ( ) . startsWith ( dataDirectory . location . getAbsolutePath ( ) ) ) 
 return dir ; 
 @ @ - 277 , 7 + 247 , 7 @ @ public class Directories 
 
 public Descriptor find ( String filename ) 
 { 
 - for ( File dir : allSSTablePaths ( ) ) 
 + for ( File dir : dataPaths ) 
 { 
 if ( new File ( dir , filename ) . exists ( ) ) 
 return Descriptor . fromFilename ( dir , filename ) . left ; 
 @ @ - 285 , 9 + 255 , 9 @ @ public class Directories 
 return null ; 
 } 
 
 - public File getDirectoryForCompactedSSTables ( ) 
 + public File getDirectoryForNewSSTables ( ) 
 { 
 - File path = getCompactionLocationAsFile ( ) ; 
 + File path = getWriteableLocationAsFile ( ) ; 
 
 / / Requesting GC has a chance to free space only if we ' re using mmap and a non SUN jvm 
 if ( path = = null 
 @ @ - 300 , 15 + 270 , 15 @ @ public class Directories 
 / / Note : GCInspector will do this already , but only sun JVM supports GCInspector so far 
 SSTableDeletingTask . rescheduleFailedTasks ( ) ; 
 Uninterruptibles . sleepUninterruptibly ( 10 , TimeUnit . SECONDS ) ; 
 - path = getCompactionLocationAsFile ( ) ; 
 + path = getWriteableLocationAsFile ( ) ; 
 } 
 
 return path ; 
 } 
 
 - public File getCompactionLocationAsFile ( ) 
 + public File getWriteableLocationAsFile ( ) 
 { 
 - return getLocationForDisk ( getCompactionLocation ( ) ) ; 
 + return getLocationForDisk ( getWriteableLocation ( ) ) ; 
 } 
 
 / * * 
 @ @ - 316 , 7 + 286 , 7 @ @ public class Directories 
 * 
 * @ throws IOError if all directories are blacklisted . 
 * / 
 - public DataDirectory getCompactionLocation ( ) 
 + public DataDirectory getWriteableLocation ( ) 
 { 
 List < DataDirectory > candidates = new ArrayList < > ( ) ; 
 
 @ @ - 346 , 13 + 316 , 6 @ @ public class Directories 
 return candidates . get ( 0 ) ; 
 } 
 
 - public DataDirectory getFlushLocation ( ) 
 - { 
 - return BlacklistedDirectories . isUnwritable ( flushPath ) 
 - ? getCompactionLocation ( ) 
 - : flushDirectory ; 
 - } 
 - 
 public static File getSnapshotDirectory ( Descriptor desc , String snapshotName ) 
 { 
 return getOrCreate ( desc . directory , SNAPSHOT _ SUBDIR , snapshotName ) ; 
 @ @ - 360 , 7 + 323 , 7 @ @ public class Directories 
 
 public File getSnapshotManifestFile ( String snapshotName ) 
 { 
 - return new File ( getDirectoryForCompactedSSTables ( ) , join ( SNAPSHOT _ SUBDIR , snapshotName , " manifest . json " ) ) ; 
 + return new File ( getDirectoryForNewSSTables ( ) , join ( SNAPSHOT _ SUBDIR , snapshotName , " manifest . json " ) ) ; 
 } 
 
 public static File getBackupsDirectory ( Descriptor desc ) 
 @ @ - 469 , 7 + 432 , 7 @ @ public class Directories 
 if ( filtered ) 
 return ; 
 
 - for ( File location : allSSTablePaths ( ) ) 
 + for ( File location : dataPaths ) 
 { 
 if ( BlacklistedDirectories . isUnreadable ( location ) ) 
 continue ; 
 @ @ - 531 , 7 + 494 , 7 @ @ public class Directories 
 public Map < String , Pair < Long , Long > > getSnapshotDetails ( ) 
 { 
 final Map < String , Pair < Long , Long > > snapshotSpaceMap = new HashMap < > ( ) ; 
 - for ( final File dir : allSSTablePaths ( ) ) 
 + for ( final File dir : dataPaths ) 
 { 
 final File snapshotDir = new File ( dir , SNAPSHOT _ SUBDIR ) ; 
 if ( snapshotDir . exists ( ) & & snapshotDir . isDirectory ( ) ) 
 @ @ - 561 , 7 + 524 , 7 @ @ public class Directories 
 } 
 public boolean snapshotExists ( String snapshotName ) 
 { 
 - for ( File dir : allSSTablePaths ( ) ) 
 + for ( File dir : dataPaths ) 
 { 
 File snapshotDir = new File ( dir , join ( SNAPSHOT _ SUBDIR , snapshotName ) ) ; 
 if ( snapshotDir . exists ( ) ) 
 @ @ - 589 , 7 + 552 , 7 @ @ public class Directories 
 / / The snapshot must exist 
 public long snapshotCreationTime ( String snapshotName ) 
 { 
 - for ( File dir : allSSTablePaths ( ) ) 
 + for ( File dir : dataPaths ) 
 { 
 File snapshotDir = new File ( dir , join ( SNAPSHOT _ SUBDIR , snapshotName ) ) ; 
 if ( snapshotDir . exists ( ) ) 
 @ @ - 601 , 7 + 564 , 7 @ @ public class Directories 
 public long trueSnapshotsSize ( ) 
 { 
 long result = 0L ; 
 - for ( File dir : allSSTablePaths ( ) ) 
 + for ( File dir : dataPaths ) 
 result + = getTrueAllocatedSizeIn ( new File ( dir , join ( SNAPSHOT _ SUBDIR ) ) ) ; 
 return result ; 
 } 
 @ @ - 633 , 7 + 596 , 7 @ @ public class Directories 
 public static List < File > getKSChildDirectories ( String ksName ) 
 { 
 List < File > result = new ArrayList < > ( ) ; 
 - for ( DataDirectory dataDirectory : allSSTableDirectories ( ) ) 
 + for ( DataDirectory dataDirectory : dataDirectories ) 
 { 
 File ksDir = new File ( dataDirectory . location , ksName ) ; 
 File [ ] cfDirs = ksDir . listFiles ( ) ; 
 @ @ - 651 , 7 + 614 , 7 @ @ public class Directories 
 public List < File > getCFDirectories ( ) 
 { 
 List < File > result = new ArrayList < > ( ) ; 
 - for ( File dataDirectory : allSSTablePaths ( ) ) 
 + for ( File dataDirectory : dataPaths ) 
 { 
 if ( dataDirectory . isDirectory ( ) ) 
 result . add ( dataDirectory ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / Memtable . java b / src / java / org / apache / cassandra / db / Memtable . java 
 index 6f4c1c7 . . 417b4a7 100644 
 - - - a / src / java / org / apache / cassandra / db / Memtable . java 
 + + + b / src / java / org / apache / cassandra / db / Memtable . java 
 @ @ - 302 , 11 + 302 , 6 @ @ public class Memtable 
 * 1 . 2 ) ; / / bloom filter and row index overhead 
 } 
 
 - protected Directories . DataDirectory getWriteableLocation ( ) 
 - { 
 - return cfs . directories . getFlushLocation ( ) ; 
 - } 
 - 
 public long getExpectedWriteSize ( ) 
 { 
 return estimatedSize ; 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionTask . java b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionTask . java 
 index 5f9c7ae . . 59338f4 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionTask . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionTask . java 
 @ @ - 49 , 11 + 49 , 6 @ @ public abstract class AbstractCompactionTask extends DiskAwareRunnable 
 assert compacting . contains ( sstable ) : sstable . getFilename ( ) + " is not correctly marked compacting " ; 
 } 
 
 - protected Directories . DataDirectory getWriteableLocation ( ) 
 - { 
 - return cfs . directories . getCompactionLocation ( ) ; 
 - } 
 - 
 / * * 
 * executes the task and unmarks sstables compacting 
 * / 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 index 7fc27ae . . 227f908 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 @ @ - 674 , 7 + 674 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 
 logger . info ( " Cleaning up { } " , sstable ) ; 
 
 - File compactionFileLocation = cfs . directories . getDirectoryForCompactedSSTables ( ) ; 
 + File compactionFileLocation = cfs . directories . getDirectoryForNewSSTables ( ) ; 
 if ( compactionFileLocation = = null ) 
 throw new IOException ( " disk full " ) ; 
 
 @ @ - 953 , 7 + 953 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 Set < SSTableReader > sstableAsSet = new HashSet < > ( ) ; 
 sstableAsSet . add ( sstable ) ; 
 
 - File destination = cfs . directories . getDirectoryForCompactedSSTables ( ) ; 
 + File destination = cfs . directories . getDirectoryForNewSSTables ( ) ; 
 SSTableRewriter repairedSSTableWriter = new SSTableRewriter ( cfs , sstableAsSet , sstable . maxDataAge , OperationType . ANTICOMPACTION , false ) ; 
 SSTableRewriter unRepairedSSTableWriter = new SSTableRewriter ( cfs , sstableAsSet , sstable . maxDataAge , OperationType . ANTICOMPACTION , false ) ; 
 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / Scrubber . java b / src / java / org / apache / cassandra / db / compaction / Scrubber . java 
 index 399f96c . . 7303da1 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / Scrubber . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / Scrubber . java 
 @ @ - 80 , 7 + 80 , 7 @ @ public class Scrubber implements Closeable 
 this . isOffline = isOffline ; 
 
 / / Calculate the expected compacted filesize 
 - this . destination = cfs . directories . getDirectoryForCompactedSSTables ( ) ; 
 + this . destination = cfs . directories . getDirectoryForNewSSTables ( ) ; 
 if ( destination = = null ) 
 throw new IOException ( " disk full " ) ; 
 
 diff - - git a / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java b / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java 
 index f0e2756 . . 198a88d 100644 
 - - - a / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java 
 + + + b / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java 
 @ @ - 34 , 7 + 34 , 7 @ @ public abstract class DiskAwareRunnable extends WrappedRunnable 
 while ( true ) 
 { 
 writeSize = getExpectedWriteSize ( ) ; 
 - directory = getWriteableLocation ( ) ; 
 + directory = getDirectories ( ) . getWriteableLocation ( ) ; 
 if ( directory ! = null | | ! reduceScopeForLimitedSpace ( ) ) 
 break ; 
 } 
 @ @ - 54 , 8 + 54 , 6 @ @ public abstract class DiskAwareRunnable extends WrappedRunnable 
 } 
 } 
 
 - protected abstract Directories . DataDirectory getWriteableLocation ( ) ; 
 - 
 / * * 
 * Get sstable directories for the CF . 
 * @ return Directories instance for the CF . 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamReader . java b / src / java / org / apache / cassandra / streaming / StreamReader . java 
 index c26a61b . . d805bf3 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamReader . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamReader . java 
 @ @ - 40 , 6 + 40 , 7 @ @ import org . apache . cassandra . db . Keyspace ; 
 import org . apache . cassandra . io . sstable . Component ; 
 import org . apache . cassandra . io . sstable . Descriptor ; 
 import org . apache . cassandra . io . sstable . SSTableWriter ; 
 + import org . apache . cassandra . service . ActiveRepairService ; 
 import org . apache . cassandra . service . StorageService ; 
 import org . apache . cassandra . streaming . messages . FileMessageHeader ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 @ @ - 110 , 7 + 111 , 7 @ @ public class StreamReader 
 
 protected SSTableWriter createWriter ( ColumnFamilyStore cfs , long totalSize , long repairedAt ) throws IOException 
 { 
 - Directories . DataDirectory localDir = cfs . directories . getCompactionLocation ( ) ; 
 + Directories . DataDirectory localDir = cfs . directories . getWriteableLocation ( ) ; 
 if ( localDir = = null ) 
 throw new IOException ( " Insufficient disk space to store " + totalSize + " bytes " ) ; 
 desc = Descriptor . fromFilename ( cfs . getTempSSTablePath ( cfs . directories . getLocationForDisk ( localDir ) ) ) ; 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamReceiveTask . java b / src / java / org / apache / cassandra / streaming / StreamReceiveTask . java 
 index e5ef691 . . b4d5392 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamReceiveTask . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamReceiveTask . java 
 @ @ - 27 , 6 + 27 , 7 @ @ import org . apache . cassandra . db . ColumnFamilyStore ; 
 import org . apache . cassandra . db . Keyspace ; 
 import org . apache . cassandra . io . sstable . SSTableReader ; 
 import org . apache . cassandra . io . sstable . SSTableWriter ; 
 + import org . apache . cassandra . service . ActiveRepairService ; 
 import org . apache . cassandra . service . StorageService ; 
 import org . apache . cassandra . utils . Pair ; 
 
 @ @ - 97 , 7 + 98 , 7 @ @ public class StreamReceiveTask extends StreamTask 
 Pair < String , String > kscf = Schema . instance . getCF ( task . cfId ) ; 
 ColumnFamilyStore cfs = Keyspace . open ( kscf . left ) . getColumnFamilyStore ( kscf . right ) ; 
 
 - StreamLockfile lockfile = new StreamLockfile ( cfs . directories . getCompactionLocationAsFile ( ) , UUID . randomUUID ( ) ) ; 
 + StreamLockfile lockfile = new StreamLockfile ( cfs . directories . getWriteableLocationAsFile ( ) , UUID . randomUUID ( ) ) ; 
 lockfile . create ( task . sstables ) ; 
 List < SSTableReader > readers = new ArrayList < > ( ) ; 
 for ( SSTableWriter writer : task . sstables ) 
 diff - - git a / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java b / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java 
 index e792bf9 . . b178e48 100644 
 - - - a / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java 
 + + + b / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java 
 @ @ - 954 , 7 + 954 , 7 @ @ public class ColumnFamilyStoreTest extends SchemaLoader 
 
 for ( int version = 1 ; version < = 2 ; + + version ) 
 { 
 - Descriptor existing = new Descriptor ( cfs . directories . getDirectoryForCompactedSSTables ( ) , " Keyspace2 " , " Standard1 " , version , Descriptor . Type . FINAL ) ; 
 + Descriptor existing = new Descriptor ( cfs . directories . getDirectoryForNewSSTables ( ) , " Keyspace2 " , " Standard1 " , version , Descriptor . Type . FINAL ) ; 
 Descriptor desc = new Descriptor ( Directories . getBackupsDirectory ( existing ) , " Keyspace2 " , " Standard1 " , version , Descriptor . Type . FINAL ) ; 
 for ( Component c : new Component [ ] { Component . DATA , Component . PRIMARY _ INDEX , Component . FILTER , Component . STATS } ) 
 assertTrue ( " can not find backedup file : " + desc . filenameFor ( c ) , new File ( desc . filenameFor ( c ) ) . exists ( ) ) ; 
 @ @ - 1662 , 7 + 1662 , 7 @ @ public class ColumnFamilyStoreTest extends SchemaLoader 
 ByteBuffer key = bytes ( " key " ) ; 
 
 / / 1st sstable 
 - SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForCompactedSSTables ( ) , cfmeta , StorageService . getPartitioner ( ) ) ; 
 + SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForNewSSTables ( ) , cfmeta , StorageService . getPartitioner ( ) ) ; 
 writer . newRow ( key ) ; 
 writer . addColumn ( bytes ( " col " ) , bytes ( " val " ) , 1 ) ; 
 writer . close ( ) ; 
 @ @ - 1674 , 7 + 1674 , 7 @ @ public class ColumnFamilyStoreTest extends SchemaLoader 
 final SSTableReader sstable1 = SSTableReader . open ( sstableToOpen . getKey ( ) ) ; 
 
 / / simulate incomplete compaction 
 - writer = new SSTableSimpleWriter ( dir . getDirectoryForCompactedSSTables ( ) , 
 + writer = new SSTableSimpleWriter ( dir . getDirectoryForNewSSTables ( ) , 
 cfmeta , StorageService . getPartitioner ( ) ) 
 { 
 protected SSTableWriter getWriter ( ) 
 @ @ - 1729 , 7 + 1729 , 7 @ @ public class ColumnFamilyStoreTest extends SchemaLoader 
 
 / / Write SSTable generation 3 that has ancestors 1 and 2 
 final Set < Integer > ancestors = Sets . newHashSet ( 1 , 2 ) ; 
 - SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForCompactedSSTables ( ) , 
 + SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForNewSSTables ( ) , 
 cfmeta , StorageService . getPartitioner ( ) ) 
 { 
 protected SSTableWriter getWriter ( ) 
 @ @ - 1796 , 13 + 1796 , 13 @ @ public class ColumnFamilyStoreTest extends SchemaLoader 
 
 ByteBuffer key = bytes ( " key " ) ; 
 
 - SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForCompactedSSTables ( ) , 
 - cfmeta , StorageService . getPartitioner ( ) ) ; 
 + SSTableSimpleWriter writer = new SSTableSimpleWriter ( dir . getDirectoryForNewSSTables ( ) , 
 + cfmeta , StorageService . getPartitioner ( ) ) ; 
 writer . newRow ( key ) ; 
 writer . addColumn ( bytes ( " col " ) , bytes ( " val " ) , 1 ) ; 
 writer . close ( ) ; 
 
 - writer = new SSTableSimpleWriter ( dir . getDirectoryForCompactedSSTables ( ) , 
 + writer = new SSTableSimpleWriter ( dir . getDirectoryForNewSSTables ( ) , 
 cfmeta , StorageService . getPartitioner ( ) ) ; 
 writer . newRow ( key ) ; 
 writer . addColumn ( bytes ( " col " ) , bytes ( " val " ) , 1 ) ; 
 diff - - git a / test / unit / org / apache / cassandra / db / DirectoriesTest . java b / test / unit / org / apache / cassandra / db / DirectoriesTest . java 
 index 1b9409a . . 9e6b26b 100644 
 - - - a / test / unit / org / apache / cassandra / db / DirectoriesTest . java 
 + + + b / test / unit / org / apache / cassandra / db / DirectoriesTest . java 
 @ @ - 30 , 7 + 30 , 6 @ @ import java . util . concurrent . Callable ; 
 import java . util . concurrent . Executors ; 
 import java . util . concurrent . Future ; 
 
 - import com . google . common . collect . Lists ; 
 import org . junit . AfterClass ; 
 import org . junit . BeforeClass ; 
 import org . junit . Test ; 
 @ @ - 125 , 7 + 124 , 7 @ @ public class DirectoriesTest 
 for ( CFMetaData cfm : CFM ) 
 { 
 Directories directories = new Directories ( cfm ) ; 
 - assertEquals ( cfDir ( cfm ) , directories . getDirectoryForCompactedSSTables ( ) ) ; 
 + assertEquals ( cfDir ( cfm ) , directories . getDirectoryForNewSSTables ( ) ) ; 
 
 Descriptor desc = new Descriptor ( cfDir ( cfm ) , KS , cfm . cfName , 1 , Descriptor . Type . FINAL ) ; 
 File snapshotDir = new File ( cfDir ( cfm ) , File . separator + Directories . SNAPSHOT _ SUBDIR + File . separator + " 42 " ) ; 
 @ @ - 187 , 13 + 186 , 12 @ @ public class DirectoriesTest 
 public void testDiskFailurePolicy _ best _ effort ( ) 
 { 
 DiskFailurePolicy origPolicy = DatabaseDescriptor . getDiskFailurePolicy ( ) ; 
 - 
 - List < DataDirectory > directories = Lists . asList ( Directories . flushDirectory , Directories . dataDirectories ) ; 
 - try 
 + 
 + try 
 { 
 DatabaseDescriptor . setDiskFailurePolicy ( DiskFailurePolicy . best _ effort ) ; 
 - 
 - for ( DataDirectory dd : directories ) 
 + 
 + for ( DataDirectory dd : Directories . dataDirectories ) 
 { 
 dd . location . setExecutable ( false ) ; 
 dd . location . setWritable ( false ) ; 
 @ @ - 210 , 7 + 208 , 7 @ @ public class DirectoriesTest 
 } 
 finally 
 { 
 - for ( DataDirectory dd : directories ) 
 + for ( DataDirectory dd : Directories . dataDirectories ) 
 { 
 dd . location . setExecutable ( true ) ; 
 dd . location . setWritable ( true ) ; 
 @ @ - 226 , 7 + 224 , 7 @ @ public class DirectoriesTest 
 for ( final CFMetaData cfm : CFM ) 
 { 
 final Directories directories = new Directories ( cfm ) ; 
 - assertEquals ( cfDir ( cfm ) , directories . getDirectoryForCompactedSSTables ( ) ) ; 
 + assertEquals ( cfDir ( cfm ) , directories . getDirectoryForNewSSTables ( ) ) ; 
 final String n = Long . toString ( System . nanoTime ( ) ) ; 
 Callable < File > directoryGetter = new Callable < File > ( ) { 
 public File call ( ) throws Exception { 
 diff - - git a / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java b / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java 
 index 5995fe3 . . 15980a4 100644 
 - - - a / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java 
 + + + b / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java 
 @ @ - 44 , 7 + 44 , 7 @ @ public class SSTableSimpleWriterTest extends SchemaLoader 
 String cfname = " StandardInteger1 " ; 
 
 Keyspace t = Keyspace . open ( keyspaceName ) ; / / make sure we create the directory 
 - File dir = new Directories ( Schema . instance . getCFMetaData ( keyspaceName , cfname ) ) . getDirectoryForCompactedSSTables ( ) ; 
 + File dir = new Directories ( Schema . instance . getCFMetaData ( keyspaceName , cfname ) ) . getDirectoryForNewSSTables ( ) ; 
 assert dir . exists ( ) ; 
 
 IPartitioner partitioner = StorageService . getPartitioner ( ) ;

NEAREST DIFF:
ELIMINATEDSENTENCE
