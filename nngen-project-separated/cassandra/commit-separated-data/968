BLEU SCORE: 0.4111336169005197

TEST MSG: Add backpressure to compressed or encrypted commit log
GENERATED MSG: Add backpressure to compressed commit log

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 1ff4e6d . . ffd0b24 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 5 + 1 , 6 @ @ <nl> 3 . 5 <nl> Merged from 3 . 0 : <nl> + * Add backpressure to compressed or encrypted commit log ( CASSANDRA - 10971 ) <nl> * SSTableExport supports secondary index tables ( CASSANDRA - 11330 ) <nl> * Fix sstabledump to include missing info in debug output ( CASSANDRA - 11321 ) <nl> * Establish and implement canonical bulk reading workload ( s ) ( CASSANDRA - 10331 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / commitlog / AbstractCommitLogService . java b / src / java / org / apache / cassandra / db / commitlog / AbstractCommitLogService . java <nl> index 557bf50 . . 113d1ba 100644 <nl> - - - a / src / java / org / apache / cassandra / db / commitlog / AbstractCommitLogService . java <nl> + + + b / src / java / org / apache / cassandra / db / commitlog / AbstractCommitLogService . java <nl> @ @ - 89 , 6 + 89 , 7 @ @ public abstract class AbstractCommitLogService <nl> <nl> / / sync and signal <nl> long syncStarted = System . currentTimeMillis ( ) ; <nl> + / / This is a target for Byteman in CommitLogSegmentManagerTest <nl> commitLog . sync ( shutdown ) ; <nl> lastSyncedAt = syncStarted ; <nl> syncComplete . signalAll ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / commitlog / CommitLogSegment . java b / src / java / org / apache / cassandra / db / commitlog / CommitLogSegment . java <nl> index 5e99a07 . . f2d8f92 100644 <nl> - - - a / src / java / org / apache / cassandra / db / commitlog / CommitLogSegment . java <nl> + + + b / src / java / org / apache / cassandra / db / commitlog / CommitLogSegment . java <nl> @ @ - 119 , 15 + 119 , 26 @ @ public abstract class CommitLogSegment <nl> final CommitLog commitLog ; <nl> public final CommitLogDescriptor descriptor ; <nl> <nl> - static CommitLogSegment createSegment ( CommitLog commitLog ) <nl> + static CommitLogSegment createSegment ( CommitLog commitLog , Runnable onClose ) <nl> { <nl> - CommitLogSegment segment = commitLog . encryptionContext . isEnabled ( ) ? new EncryptedSegment ( commitLog , commitLog . encryptionContext ) : <nl> - commitLog . compressor ! = null ? new CompressedSegment ( commitLog ) : <nl> - new MemoryMappedSegment ( commitLog ) ; <nl> + CommitLogSegment segment = commitLog . encryptionContext . isEnabled ( ) ? new EncryptedSegment ( commitLog , commitLog . encryptionContext , onClose ) : <nl> + commitLog . compressor ! = null ? new CompressedSegment ( commitLog , onClose ) : <nl> + new MemoryMappedSegment ( commitLog ) ; <nl> segment . writeLogHeader ( ) ; <nl> return segment ; <nl> } <nl> <nl> + / * * <nl> + * Checks if the segments use a buffer pool . <nl> + * <nl> + * @ param commitLog the commit log <nl> + * @ return < code > true < / code > if the segments use a buffer pool , < code > false < / code > otherwise . <nl> + * / <nl> + static boolean usesBufferPool ( CommitLog commitLog ) <nl> + { <nl> + return commitLog . encryptionContext . isEnabled ( ) | | commitLog . compressor ! = null ; <nl> + } <nl> + <nl> static long getNextId ( ) <nl> { <nl> return idBase + nextId . getAndIncrement ( ) ; <nl> @ @ - 152 , 7 + 163 , 7 @ @ public abstract class CommitLogSegment <nl> { <nl> throw new FSWriteError ( e , logFile ) ; <nl> } <nl> - <nl> + <nl> buffer = createBuffer ( commitLog ) ; <nl> } <nl> <nl> @ @ - 276 , 7 + 287 , 7 @ @ public abstract class CommitLogSegment <nl> / / Note : Even if the very first allocation of this sync section failed , we still want to enter this <nl> / / to ensure the segment is closed . As allocatePosition is set to 1 beyond the capacity of the buffer , <nl> / / this will always be entered when a mutation allocation has been attempted after the marker allocation <nl> - / / succeeded in the previous sync . <nl> + / / succeeded in the previous sync . <nl> assert buffer ! = null ; / / Only close once . <nl> <nl> int startMarker = lastSyncedOffset ; <nl> diff - - git a / src / java / org / apache / cassandra / db / commitlog / CommitLogSegmentManager . java b / src / java / org / apache / cassandra / db / commitlog / CommitLogSegmentManager . java <nl> index acc93c9 . . c4357bd 100644 <nl> - - - a / src / java / org / apache / cassandra / db / commitlog / CommitLogSegmentManager . java <nl> + + + b / src / java / org / apache / cassandra / db / commitlog / CommitLogSegmentManager . java <nl> @ @ - 114 , 11 + 114 , 11 @ @ public class CommitLogSegmentManager <nl> if ( task = = null ) <nl> { <nl> / / if we have no more work to do , check if we should create a new segment <nl> - if ( availableSegments . isEmpty ( ) & & ( activeSegments . isEmpty ( ) | | createReserveSegments ) ) <nl> + if ( ! atSegmentLimit ( ) & & availableSegments . isEmpty ( ) & & ( activeSegments . isEmpty ( ) | | createReserveSegments ) ) <nl> { <nl> logger . trace ( " No segments in reserve ; creating a fresh one " ) ; <nl> / / TODO : some error handling in case we fail to create a new segment <nl> - availableSegments . add ( CommitLogSegment . createSegment ( commitLog ) ) ; <nl> + availableSegments . add ( CommitLogSegment . createSegment ( commitLog , ( ) - > wakeManager ( ) ) ) ; <nl> hasAvailableSegments . signalAll ( ) ; <nl> } <nl> <nl> @ @ - 163 , 6 + 163 , 12 @ @ public class CommitLogSegmentManager <nl> } <nl> } <nl> } <nl> + <nl> + private boolean atSegmentLimit ( ) <nl> + { <nl> + return CommitLogSegment . usesBufferPool ( commitLog ) & & CompressedSegment . hasReachedPoolLimit ( ) ; <nl> + } <nl> + <nl> } ; <nl> <nl> run = true ; <nl> @ @ - 553 , 5 + 559 , 6 @ @ public class CommitLogSegmentManager <nl> { <nl> return Collections . unmodifiableCollection ( activeSegments ) ; <nl> } <nl> + <nl> } <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / commitlog / CompressedSegment . java b / src / java / org / apache / cassandra / db / commitlog / CompressedSegment . java <nl> index 6b25ab7 . . 573428a 100644 <nl> - - - a / src / java / org / apache / cassandra / db / commitlog / CompressedSegment . java <nl> + + + b / src / java / org / apache / cassandra / db / commitlog / CompressedSegment . java <nl> @ @ - 44 , 9 + 44 , 9 @ @ public class CompressedSegment extends FileDirectSegment <nl> / * * <nl> * Constructs a new segment file . <nl> * / <nl> - CompressedSegment ( CommitLog commitLog ) <nl> + CompressedSegment ( CommitLog commitLog , Runnable onClose ) <nl> { <nl> - super ( commitLog ) ; <nl> + super ( commitLog , onClose ) ; <nl> this . compressor = commitLog . compressor ; <nl> } <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / commitlog / EncryptedSegment . java b / src / java / org / apache / cassandra / db / commitlog / EncryptedSegment . java <nl> index 46969ac . . 731dea4 100644 <nl> - - - a / src / java / org / apache / cassandra / db / commitlog / EncryptedSegment . java <nl> + + + b / src / java / org / apache / cassandra / db / commitlog / EncryptedSegment . java <nl> @ @ - 65 , 9 + 65 , 9 @ @ public class EncryptedSegment extends FileDirectSegment <nl> private final EncryptionContext encryptionContext ; <nl> private final Cipher cipher ; <nl> <nl> - public EncryptedSegment ( CommitLog commitLog , EncryptionContext encryptionContext ) <nl> + public EncryptedSegment ( CommitLog commitLog , EncryptionContext encryptionContext , Runnable onClose ) <nl> { <nl> - super ( commitLog ) ; <nl> + super ( commitLog , onClose ) ; <nl> this . encryptionContext = encryptionContext ; <nl> <nl> try <nl> diff - - git a / src / java / org / apache / cassandra / db / commitlog / FileDirectSegment . java b / src / java / org / apache / cassandra / db / commitlog / FileDirectSegment . java <nl> index 75a7fc0 . . ec4aa91 100644 <nl> - - - a / src / java / org / apache / cassandra / db / commitlog / FileDirectSegment . java <nl> + + + b / src / java / org / apache / cassandra / db / commitlog / FileDirectSegment . java <nl> @ @ - 21 , 11 + 21 , 11 @ @ import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . Queue ; <nl> import java . util . concurrent . ConcurrentLinkedQueue ; <nl> + import java . util . concurrent . atomic . AtomicInteger ; <nl> <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . io . FSWriteError ; <nl> import org . apache . cassandra . io . compress . BufferType ; <nl> - import org . apache . cassandra . io . compress . ICompressor ; <nl> import org . apache . cassandra . io . util . FileUtils ; <nl> <nl> / * * <nl> @ @ - 51 , 11 + 51 , 19 @ @ public abstract class FileDirectSegment extends CommitLogSegment <nl> * / <nl> static final int MAX _ BUFFERPOOL _ SIZE = DatabaseDescriptor . getCommitLogMaxCompressionBuffersInPool ( ) ; <nl> <nl> + / * * <nl> + * The number of buffers in use <nl> + * / <nl> + private static AtomicInteger usedBuffers = new AtomicInteger ( 0 ) ; <nl> + <nl> volatile long lastWrittenPos = 0 ; <nl> <nl> - FileDirectSegment ( CommitLog commitLog ) <nl> + private final Runnable onClose ; <nl> + <nl> + FileDirectSegment ( CommitLog commitLog , Runnable onClose ) <nl> { <nl> super ( commitLog ) ; <nl> + this . onClose = onClose ; <nl> } <nl> <nl> void writeLogHeader ( ) <nl> @ @ - 74 , 6 + 82 , 7 @ @ public abstract class FileDirectSegment extends CommitLogSegment <nl> <nl> ByteBuffer createBuffer ( BufferType bufferType ) <nl> { <nl> + usedBuffers . incrementAndGet ( ) ; <nl> ByteBuffer buf = bufferPool . poll ( ) ; <nl> if ( buf ! = null ) <nl> { <nl> @ @ - 87 , 16 + 96 , 35 @ @ public abstract class FileDirectSegment extends CommitLogSegment <nl> @ Override <nl> protected void internalClose ( ) <nl> { <nl> - if ( bufferPool . size ( ) < MAX _ BUFFERPOOL _ SIZE ) <nl> - bufferPool . add ( buffer ) ; <nl> - else <nl> - FileUtils . clean ( buffer ) ; <nl> + usedBuffers . decrementAndGet ( ) ; <nl> <nl> - super . internalClose ( ) ; <nl> + try <nl> + { <nl> + if ( bufferPool . size ( ) < MAX _ BUFFERPOOL _ SIZE ) <nl> + bufferPool . add ( buffer ) ; <nl> + else <nl> + FileUtils . clean ( buffer ) ; <nl> + super . internalClose ( ) ; <nl> + } <nl> + finally <nl> + { <nl> + onClose . run ( ) ; <nl> + } <nl> } <nl> <nl> static void shutdown ( ) <nl> { <nl> bufferPool . clear ( ) ; <nl> } <nl> + <nl> + / * * <nl> + * Checks if the number of buffers in use is greater or equals to the maximum number of buffers allowed in the pool . <nl> + * <nl> + * @ return < code > true < / code > if the number of buffers in use is greater or equals to the maximum number of buffers <nl> + * allowed in the pool , < code > false < / code > otherwise . <nl> + * / <nl> + static boolean hasReachedPoolLimit ( ) <nl> + { <nl> + return usedBuffers . get ( ) > = MAX _ BUFFERPOOL _ SIZE ; <nl> + } <nl> } <nl> diff - - git a / test / unit / org / apache / cassandra / db / commitlog / CommitLogSegmentManagerTest . java b / test / unit / org / apache / cassandra / db / commitlog / CommitLogSegmentManagerTest . java <nl> new file mode 100644 <nl> index 0000000 . . b5c2f41 <nl> - - - / dev / null <nl> + + + b / test / unit / org / apache / cassandra / db / commitlog / CommitLogSegmentManagerTest . java <nl> @ @ - 0 , 0 + 1 , 100 @ @ <nl> + package org . apache . cassandra . db . commitlog ; <nl> + <nl> + import java . nio . ByteBuffer ; <nl> + import java . util . Random ; <nl> + import java . util . concurrent . Semaphore ; <nl> + <nl> + import javax . naming . ConfigurationException ; <nl> + <nl> + import org . apache . cassandra . SchemaLoader ; <nl> + import org . apache . cassandra . Util ; <nl> + import org . apache . cassandra . config . Config . CommitLogSync ; <nl> + import org . apache . cassandra . config . DatabaseDescriptor ; <nl> + import org . apache . cassandra . config . ParameterizedClass ; <nl> + import org . apache . cassandra . db . ColumnFamilyStore ; <nl> + import org . apache . cassandra . db . Keyspace ; <nl> + import org . apache . cassandra . db . Mutation ; <nl> + import org . apache . cassandra . db . RowUpdateBuilder ; <nl> + import org . apache . cassandra . db . compaction . CompactionManager ; <nl> + import org . apache . cassandra . db . marshal . AsciiType ; <nl> + import org . apache . cassandra . db . marshal . BytesType ; <nl> + import org . apache . cassandra . schema . KeyspaceParams ; <nl> + import org . jboss . byteman . contrib . bmunit . BMRule ; <nl> + import org . jboss . byteman . contrib . bmunit . BMUnitRunner ; <nl> + import org . junit . Assert ; <nl> + import org . junit . BeforeClass ; <nl> + import org . junit . Test ; <nl> + import org . junit . runner . RunWith ; <nl> + <nl> + import com . google . common . collect . ImmutableMap ; <nl> + <nl> + @ RunWith ( BMUnitRunner . class ) <nl> + public class CommitLogSegmentManagerTest <nl> + { <nl> + / / Block commit log service from syncing <nl> + private static final Semaphore allowSync = new Semaphore ( 0 ) ; <nl> + <nl> + private static final String KEYSPACE1 = " CommitLogTest " ; <nl> + private static final String STANDARD1 = " Standard1 " ; <nl> + private static final String STANDARD2 = " Standard2 " ; <nl> + <nl> + private final static byte [ ] entropy = new byte [ 1024 * 256 ] ; <nl> + @ BeforeClass <nl> + public static void defineSchema ( ) throws ConfigurationException <nl> + { <nl> + new Random ( ) . nextBytes ( entropy ) ; <nl> + DatabaseDescriptor . setCommitLogCompression ( new ParameterizedClass ( " LZ4Compressor " , ImmutableMap . of ( ) ) ) ; <nl> + DatabaseDescriptor . setCommitLogSegmentSize ( 1 ) ; <nl> + DatabaseDescriptor . setCommitLogSync ( CommitLogSync . periodic ) ; <nl> + DatabaseDescriptor . setCommitLogSyncPeriod ( 10 * 1000 ) ; <nl> + SchemaLoader . prepareServer ( ) ; <nl> + SchemaLoader . createKeyspace ( KEYSPACE1 , <nl> + KeyspaceParams . simple ( 1 ) , <nl> + SchemaLoader . standardCFMD ( KEYSPACE1 , STANDARD1 , 0 , AsciiType . instance , BytesType . instance ) , <nl> + SchemaLoader . standardCFMD ( KEYSPACE1 , STANDARD2 , 0 , AsciiType . instance , BytesType . instance ) ) ; <nl> + <nl> + CompactionManager . instance . disableAutoCompaction ( ) ; <nl> + } <nl> + <nl> + @ Test <nl> + @ BMRule ( name = " Block AbstractCommitLogSegment segment flushing " , <nl> + targetClass = " AbstractCommitLogService $ 1 " , <nl> + targetMethod = " run " , <nl> + targetLocation = " AT INVOKE org . apache . cassandra . db . commitlog . CommitLog . sync " , <nl> + action = " org . apache . cassandra . db . commitlog . CommitLogSegmentManagerTest . allowSync . acquire ( ) " ) <nl> + public void testCompressedCommitLogBackpressure ( ) throws Throwable <nl> + { <nl> + CommitLog . instance . resetUnsafe ( true ) ; <nl> + ColumnFamilyStore cfs1 = Keyspace . open ( KEYSPACE1 ) . getColumnFamilyStore ( STANDARD1 ) ; <nl> + <nl> + final Mutation m = new RowUpdateBuilder ( cfs1 . metadata , 0 , " k " ) <nl> + . clustering ( " bytes " ) <nl> + . add ( " val " , ByteBuffer . wrap ( entropy ) ) <nl> + . build ( ) ; <nl> + <nl> + Thread dummyThread = new Thread ( ( ) - > <nl> + { <nl> + for ( int i = 0 ; i < 20 ; i + + ) <nl> + CommitLog . instance . add ( m ) ; <nl> + } ) ; <nl> + dummyThread . start ( ) ; <nl> + <nl> + CommitLogSegmentManager clsm = CommitLog . instance . allocator ; <nl> + <nl> + / / Protect against delay , but still break out as fast as possible <nl> + long start = System . currentTimeMillis ( ) ; <nl> + while ( System . currentTimeMillis ( ) - start < 5000 ) <nl> + { <nl> + if ( clsm . getActiveSegments ( ) . size ( ) > = 3 ) <nl> + break ; <nl> + } <nl> + Thread . sleep ( 1000 ) ; <nl> + <nl> + / / Should only be able to create 3 segments not 7 because it blocks waiting for truncation that never comes <nl> + Assert . assertEquals ( 3 , clsm . getActiveSegments ( ) . size ( ) ) ; <nl> + <nl> + clsm . getActiveSegments ( ) . forEach ( segment - > clsm . recycleSegment ( segment ) ) ; <nl> + <nl> + Util . spinAssertEquals ( 3 , ( ) - > clsm . getActiveSegments ( ) . size ( ) , 5 ) ; <nl> + } <nl> + } <nl> \ No newline at end of file <nl> diff - - git a / test / unit / org / apache / cassandra / db / commitlog / CommitLogTest . java b / test / unit / org / apache / cassandra / db / commitlog / CommitLogTest . java <nl> index 91a25e1 . . b5cbf8b 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / commitlog / CommitLogTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / commitlog / CommitLogTest . java <nl> @ @ - 18 , 20 + 18 , 9 @ @ <nl> * / <nl> package org . apache . cassandra . db . commitlog ; <nl> <nl> - import java . io . ByteArrayOutputStream ; <nl> - import java . io . DataOutputStream ; <nl> - import java . io . File ; <nl> - import java . io . FileOutputStream ; <nl> - import java . io . IOException ; <nl> - import java . io . OutputStream ; <nl> - import java . io . RandomAccessFile ; <nl> + import java . io . * ; <nl> import java . nio . ByteBuffer ; <nl> - import java . util . Collections ; <nl> - import java . util . HashMap ; <nl> - import java . util . List ; <nl> - import java . util . Map ; <nl> - import java . util . Random ; <nl> - import java . util . UUID ; <nl> + import java . util . * ; <nl> import java . util . concurrent . Callable ; <nl> import java . util . concurrent . ExecutionException ; <nl> import java . util . zip . CRC32 ; <nl> @ @ - 39 , 19 + 28 , 17 @ @ import java . util . zip . Checksum ; <nl> <nl> import com . google . common . collect . Iterables ; <nl> <nl> - import org . apache . cassandra . db . ColumnFamilyStore ; <nl> - import org . apache . cassandra . db . Keyspace ; <nl> - import org . apache . cassandra . db . Mutation ; <nl> - import org . apache . cassandra . db . RowUpdateBuilder ; <nl> - import org . apache . cassandra . db . marshal . AsciiType ; <nl> - import org . apache . cassandra . db . marshal . BytesType ; <nl> + import org . junit . * ; <nl> <nl> import org . apache . cassandra . SchemaLoader ; <nl> import org . apache . cassandra . Util ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . config . ParameterizedClass ; <nl> + import org . apache . cassandra . db . * ; <nl> import org . apache . cassandra . db . commitlog . CommitLogReplayer . CommitLogReplayException ; <nl> import org . apache . cassandra . db . compaction . CompactionManager ; <nl> + import org . apache . cassandra . db . marshal . AsciiType ; <nl> + import org . apache . cassandra . db . marshal . BytesType ; <nl> import org . apache . cassandra . db . partitions . PartitionUpdate ; <nl> import org . apache . cassandra . db . rows . Row ; <nl> import org . apache . cassandra . db . rows . SerializationHelper ; <nl> @ @ - 61 , 22 + 48 , 13 @ @ import org . apache . cassandra . io . compress . LZ4Compressor ; <nl> import org . apache . cassandra . io . compress . SnappyCompressor ; <nl> import org . apache . cassandra . io . util . DataInputPlus ; <nl> import org . apache . cassandra . io . util . FastByteArrayInputStream ; <nl> - import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . net . MessagingService ; <nl> import org . apache . cassandra . schema . KeyspaceParams ; <nl> - import org . apache . cassandra . utils . JVMStabilityInspector ; <nl> - import org . apache . cassandra . utils . KillerForTests ; <nl> import org . apache . cassandra . security . EncryptionContext ; <nl> import org . apache . cassandra . security . EncryptionContextGenerator ; <nl> - import org . apache . cassandra . utils . Hex ; <nl> - import org . apache . cassandra . utils . Pair ; <nl> + import org . apache . cassandra . utils . * ; <nl> import org . apache . cassandra . utils . vint . VIntCoding ; <nl> <nl> - import org . junit . Assert ; <nl> - import org . junit . Before ; <nl> - import org . junit . BeforeClass ; <nl> - import org . junit . Test ; <nl> - <nl> import static org . apache . cassandra . utils . ByteBufferUtil . bytes ; <nl> import static org . junit . Assert . assertEquals ; <nl> import static org . junit . Assert . assertTrue ; <nl> @ @ - 106 , 7 + 84 , 7 @ @ public class CommitLogTest <nl> } <nl> <nl> @ Before <nl> - public void setup ( ) <nl> + public void setup ( ) throws IOException <nl> { <nl> logDirectory = DatabaseDescriptor . getCommitLogLocation ( ) + " / unit " ; <nl> new File ( logDirectory ) . mkdirs ( ) ; <nl> @ @ - 575 , 11 + 553 , 22 @ @ public class CommitLogTest <nl> @ Test <nl> public void replay _ StandardMmapped ( ) throws IOException <nl> { <nl> - DatabaseDescriptor . setCommitLogCompression ( null ) ; <nl> - DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createDisabledContext ( ) ) ; <nl> - CommitLog commitLog = new CommitLog ( logDirectory , CommitLogArchiver . disabled ( ) ) . start ( ) ; <nl> - replaySimple ( commitLog ) ; <nl> - replayWithDiscard ( commitLog ) ; <nl> + ParameterizedClass originalCompression = DatabaseDescriptor . getCommitLogCompression ( ) ; <nl> + EncryptionContext originalEncryptionContext = DatabaseDescriptor . getEncryptionContext ( ) ; <nl> + try <nl> + { <nl> + DatabaseDescriptor . setCommitLogCompression ( null ) ; <nl> + DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createDisabledContext ( ) ) ; <nl> + CommitLog . instance . resetUnsafe ( true ) ; <nl> + replaySimple ( CommitLog . instance ) ; <nl> + replayWithDiscard ( CommitLog . instance ) ; <nl> + } <nl> + finally <nl> + { <nl> + DatabaseDescriptor . setCommitLogCompression ( originalCompression ) ; <nl> + DatabaseDescriptor . setEncryptionContext ( originalEncryptionContext ) ; <nl> + CommitLog . instance . resetUnsafe ( true ) ; <nl> + } <nl> } <nl> <nl> @ Test <nl> @ @ - 602 , 29 + 591 , 44 @ @ public class CommitLogTest <nl> <nl> private void replay _ Compressed ( ParameterizedClass parameterizedClass ) throws IOException <nl> { <nl> - DatabaseDescriptor . setCommitLogCompression ( parameterizedClass ) ; <nl> - DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createDisabledContext ( ) ) ; <nl> - CommitLog commitLog = new CommitLog ( logDirectory , CommitLogArchiver . disabled ( ) ) . start ( ) ; <nl> - replaySimple ( commitLog ) ; <nl> - replayWithDiscard ( commitLog ) ; <nl> + ParameterizedClass originalCompression = DatabaseDescriptor . getCommitLogCompression ( ) ; <nl> + EncryptionContext originalEncryptionContext = DatabaseDescriptor . getEncryptionContext ( ) ; <nl> + try <nl> + { <nl> + DatabaseDescriptor . setCommitLogCompression ( parameterizedClass ) ; <nl> + DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createDisabledContext ( ) ) ; <nl> + CommitLog . instance . resetUnsafe ( true ) ; <nl> + <nl> + replaySimple ( CommitLog . instance ) ; <nl> + replayWithDiscard ( CommitLog . instance ) ; <nl> + } <nl> + finally <nl> + { <nl> + DatabaseDescriptor . setCommitLogCompression ( originalCompression ) ; <nl> + DatabaseDescriptor . setEncryptionContext ( originalEncryptionContext ) ; <nl> + CommitLog . instance . resetUnsafe ( true ) ; <nl> + } <nl> } <nl> <nl> @ Test <nl> public void replay _ Encrypted ( ) throws IOException <nl> { <nl> - DatabaseDescriptor . setCommitLogCompression ( null ) ; <nl> - DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createContext ( true ) ) ; <nl> - CommitLog commitLog = new CommitLog ( logDirectory , CommitLogArchiver . disabled ( ) ) . start ( ) ; <nl> - <nl> + ParameterizedClass originalCompression = DatabaseDescriptor . getCommitLogCompression ( ) ; <nl> + EncryptionContext originalEncryptionContext = DatabaseDescriptor . getEncryptionContext ( ) ; <nl> try <nl> { <nl> - replaySimple ( commitLog ) ; <nl> - replayWithDiscard ( commitLog ) ; <nl> + DatabaseDescriptor . setCommitLogCompression ( null ) ; <nl> + DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createContext ( true ) ) ; <nl> + CommitLog . instance . resetUnsafe ( true ) ; <nl> + <nl> + replaySimple ( CommitLog . instance ) ; <nl> + replayWithDiscard ( CommitLog . instance ) ; <nl> } <nl> finally <nl> { <nl> - for ( String file : commitLog . getActiveSegmentNames ( ) ) <nl> - FileUtils . delete ( new File ( commitLog . location , file ) ) ; <nl> + DatabaseDescriptor . setCommitLogCompression ( originalCompression ) ; <nl> + DatabaseDescriptor . setEncryptionContext ( originalEncryptionContext ) ; <nl> + CommitLog . instance . resetUnsafe ( true ) ; <nl> } <nl> } <nl> <nl> @ @ - 706 , 6 + 710 , 7 @ @ public class CommitLogTest <nl> this . filterPosition = filterPosition ; <nl> } <nl> <nl> + @ SuppressWarnings ( " resource " ) <nl> void replayMutation ( byte [ ] inputBuffer , int size , final long entryLocation , final CommitLogDescriptor desc ) throws IOException <nl> { <nl> if ( entryLocation < = filterPosition . position )
NEAREST DIFF (one line): ELIMINATEDSENTENCE

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 1ff4e6d . . ffd0b24 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 5 + 1 , 6 @ @ 
 3 . 5 
 Merged from 3 . 0 : 
 + * Add backpressure to compressed or encrypted commit log ( CASSANDRA - 10971 ) 
 * SSTableExport supports secondary index tables ( CASSANDRA - 11330 ) 
 * Fix sstabledump to include missing info in debug output ( CASSANDRA - 11321 ) 
 * Establish and implement canonical bulk reading workload ( s ) ( CASSANDRA - 10331 ) 
 diff - - git a / src / java / org / apache / cassandra / db / commitlog / AbstractCommitLogService . java b / src / java / org / apache / cassandra / db / commitlog / AbstractCommitLogService . java 
 index 557bf50 . . 113d1ba 100644 
 - - - a / src / java / org / apache / cassandra / db / commitlog / AbstractCommitLogService . java 
 + + + b / src / java / org / apache / cassandra / db / commitlog / AbstractCommitLogService . java 
 @ @ - 89 , 6 + 89 , 7 @ @ public abstract class AbstractCommitLogService 
 
 / / sync and signal 
 long syncStarted = System . currentTimeMillis ( ) ; 
 + / / This is a target for Byteman in CommitLogSegmentManagerTest 
 commitLog . sync ( shutdown ) ; 
 lastSyncedAt = syncStarted ; 
 syncComplete . signalAll ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / commitlog / CommitLogSegment . java b / src / java / org / apache / cassandra / db / commitlog / CommitLogSegment . java 
 index 5e99a07 . . f2d8f92 100644 
 - - - a / src / java / org / apache / cassandra / db / commitlog / CommitLogSegment . java 
 + + + b / src / java / org / apache / cassandra / db / commitlog / CommitLogSegment . java 
 @ @ - 119 , 15 + 119 , 26 @ @ public abstract class CommitLogSegment 
 final CommitLog commitLog ; 
 public final CommitLogDescriptor descriptor ; 
 
 - static CommitLogSegment createSegment ( CommitLog commitLog ) 
 + static CommitLogSegment createSegment ( CommitLog commitLog , Runnable onClose ) 
 { 
 - CommitLogSegment segment = commitLog . encryptionContext . isEnabled ( ) ? new EncryptedSegment ( commitLog , commitLog . encryptionContext ) : 
 - commitLog . compressor ! = null ? new CompressedSegment ( commitLog ) : 
 - new MemoryMappedSegment ( commitLog ) ; 
 + CommitLogSegment segment = commitLog . encryptionContext . isEnabled ( ) ? new EncryptedSegment ( commitLog , commitLog . encryptionContext , onClose ) : 
 + commitLog . compressor ! = null ? new CompressedSegment ( commitLog , onClose ) : 
 + new MemoryMappedSegment ( commitLog ) ; 
 segment . writeLogHeader ( ) ; 
 return segment ; 
 } 
 
 + / * * 
 + * Checks if the segments use a buffer pool . 
 + * 
 + * @ param commitLog the commit log 
 + * @ return < code > true < / code > if the segments use a buffer pool , < code > false < / code > otherwise . 
 + * / 
 + static boolean usesBufferPool ( CommitLog commitLog ) 
 + { 
 + return commitLog . encryptionContext . isEnabled ( ) | | commitLog . compressor ! = null ; 
 + } 
 + 
 static long getNextId ( ) 
 { 
 return idBase + nextId . getAndIncrement ( ) ; 
 @ @ - 152 , 7 + 163 , 7 @ @ public abstract class CommitLogSegment 
 { 
 throw new FSWriteError ( e , logFile ) ; 
 } 
 - 
 + 
 buffer = createBuffer ( commitLog ) ; 
 } 
 
 @ @ - 276 , 7 + 287 , 7 @ @ public abstract class CommitLogSegment 
 / / Note : Even if the very first allocation of this sync section failed , we still want to enter this 
 / / to ensure the segment is closed . As allocatePosition is set to 1 beyond the capacity of the buffer , 
 / / this will always be entered when a mutation allocation has been attempted after the marker allocation 
 - / / succeeded in the previous sync . 
 + / / succeeded in the previous sync . 
 assert buffer ! = null ; / / Only close once . 
 
 int startMarker = lastSyncedOffset ; 
 diff - - git a / src / java / org / apache / cassandra / db / commitlog / CommitLogSegmentManager . java b / src / java / org / apache / cassandra / db / commitlog / CommitLogSegmentManager . java 
 index acc93c9 . . c4357bd 100644 
 - - - a / src / java / org / apache / cassandra / db / commitlog / CommitLogSegmentManager . java 
 + + + b / src / java / org / apache / cassandra / db / commitlog / CommitLogSegmentManager . java 
 @ @ - 114 , 11 + 114 , 11 @ @ public class CommitLogSegmentManager 
 if ( task = = null ) 
 { 
 / / if we have no more work to do , check if we should create a new segment 
 - if ( availableSegments . isEmpty ( ) & & ( activeSegments . isEmpty ( ) | | createReserveSegments ) ) 
 + if ( ! atSegmentLimit ( ) & & availableSegments . isEmpty ( ) & & ( activeSegments . isEmpty ( ) | | createReserveSegments ) ) 
 { 
 logger . trace ( " No segments in reserve ; creating a fresh one " ) ; 
 / / TODO : some error handling in case we fail to create a new segment 
 - availableSegments . add ( CommitLogSegment . createSegment ( commitLog ) ) ; 
 + availableSegments . add ( CommitLogSegment . createSegment ( commitLog , ( ) - > wakeManager ( ) ) ) ; 
 hasAvailableSegments . signalAll ( ) ; 
 } 
 
 @ @ - 163 , 6 + 163 , 12 @ @ public class CommitLogSegmentManager 
 } 
 } 
 } 
 + 
 + private boolean atSegmentLimit ( ) 
 + { 
 + return CommitLogSegment . usesBufferPool ( commitLog ) & & CompressedSegment . hasReachedPoolLimit ( ) ; 
 + } 
 + 
 } ; 
 
 run = true ; 
 @ @ - 553 , 5 + 559 , 6 @ @ public class CommitLogSegmentManager 
 { 
 return Collections . unmodifiableCollection ( activeSegments ) ; 
 } 
 + 
 } 
 
 diff - - git a / src / java / org / apache / cassandra / db / commitlog / CompressedSegment . java b / src / java / org / apache / cassandra / db / commitlog / CompressedSegment . java 
 index 6b25ab7 . . 573428a 100644 
 - - - a / src / java / org / apache / cassandra / db / commitlog / CompressedSegment . java 
 + + + b / src / java / org / apache / cassandra / db / commitlog / CompressedSegment . java 
 @ @ - 44 , 9 + 44 , 9 @ @ public class CompressedSegment extends FileDirectSegment 
 / * * 
 * Constructs a new segment file . 
 * / 
 - CompressedSegment ( CommitLog commitLog ) 
 + CompressedSegment ( CommitLog commitLog , Runnable onClose ) 
 { 
 - super ( commitLog ) ; 
 + super ( commitLog , onClose ) ; 
 this . compressor = commitLog . compressor ; 
 } 
 
 diff - - git a / src / java / org / apache / cassandra / db / commitlog / EncryptedSegment . java b / src / java / org / apache / cassandra / db / commitlog / EncryptedSegment . java 
 index 46969ac . . 731dea4 100644 
 - - - a / src / java / org / apache / cassandra / db / commitlog / EncryptedSegment . java 
 + + + b / src / java / org / apache / cassandra / db / commitlog / EncryptedSegment . java 
 @ @ - 65 , 9 + 65 , 9 @ @ public class EncryptedSegment extends FileDirectSegment 
 private final EncryptionContext encryptionContext ; 
 private final Cipher cipher ; 
 
 - public EncryptedSegment ( CommitLog commitLog , EncryptionContext encryptionContext ) 
 + public EncryptedSegment ( CommitLog commitLog , EncryptionContext encryptionContext , Runnable onClose ) 
 { 
 - super ( commitLog ) ; 
 + super ( commitLog , onClose ) ; 
 this . encryptionContext = encryptionContext ; 
 
 try 
 diff - - git a / src / java / org / apache / cassandra / db / commitlog / FileDirectSegment . java b / src / java / org / apache / cassandra / db / commitlog / FileDirectSegment . java 
 index 75a7fc0 . . ec4aa91 100644 
 - - - a / src / java / org / apache / cassandra / db / commitlog / FileDirectSegment . java 
 + + + b / src / java / org / apache / cassandra / db / commitlog / FileDirectSegment . java 
 @ @ - 21 , 11 + 21 , 11 @ @ import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 import java . util . Queue ; 
 import java . util . concurrent . ConcurrentLinkedQueue ; 
 + import java . util . concurrent . atomic . AtomicInteger ; 
 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . io . FSWriteError ; 
 import org . apache . cassandra . io . compress . BufferType ; 
 - import org . apache . cassandra . io . compress . ICompressor ; 
 import org . apache . cassandra . io . util . FileUtils ; 
 
 / * * 
 @ @ - 51 , 11 + 51 , 19 @ @ public abstract class FileDirectSegment extends CommitLogSegment 
 * / 
 static final int MAX _ BUFFERPOOL _ SIZE = DatabaseDescriptor . getCommitLogMaxCompressionBuffersInPool ( ) ; 
 
 + / * * 
 + * The number of buffers in use 
 + * / 
 + private static AtomicInteger usedBuffers = new AtomicInteger ( 0 ) ; 
 + 
 volatile long lastWrittenPos = 0 ; 
 
 - FileDirectSegment ( CommitLog commitLog ) 
 + private final Runnable onClose ; 
 + 
 + FileDirectSegment ( CommitLog commitLog , Runnable onClose ) 
 { 
 super ( commitLog ) ; 
 + this . onClose = onClose ; 
 } 
 
 void writeLogHeader ( ) 
 @ @ - 74 , 6 + 82 , 7 @ @ public abstract class FileDirectSegment extends CommitLogSegment 
 
 ByteBuffer createBuffer ( BufferType bufferType ) 
 { 
 + usedBuffers . incrementAndGet ( ) ; 
 ByteBuffer buf = bufferPool . poll ( ) ; 
 if ( buf ! = null ) 
 { 
 @ @ - 87 , 16 + 96 , 35 @ @ public abstract class FileDirectSegment extends CommitLogSegment 
 @ Override 
 protected void internalClose ( ) 
 { 
 - if ( bufferPool . size ( ) < MAX _ BUFFERPOOL _ SIZE ) 
 - bufferPool . add ( buffer ) ; 
 - else 
 - FileUtils . clean ( buffer ) ; 
 + usedBuffers . decrementAndGet ( ) ; 
 
 - super . internalClose ( ) ; 
 + try 
 + { 
 + if ( bufferPool . size ( ) < MAX _ BUFFERPOOL _ SIZE ) 
 + bufferPool . add ( buffer ) ; 
 + else 
 + FileUtils . clean ( buffer ) ; 
 + super . internalClose ( ) ; 
 + } 
 + finally 
 + { 
 + onClose . run ( ) ; 
 + } 
 } 
 
 static void shutdown ( ) 
 { 
 bufferPool . clear ( ) ; 
 } 
 + 
 + / * * 
 + * Checks if the number of buffers in use is greater or equals to the maximum number of buffers allowed in the pool . 
 + * 
 + * @ return < code > true < / code > if the number of buffers in use is greater or equals to the maximum number of buffers 
 + * allowed in the pool , < code > false < / code > otherwise . 
 + * / 
 + static boolean hasReachedPoolLimit ( ) 
 + { 
 + return usedBuffers . get ( ) > = MAX _ BUFFERPOOL _ SIZE ; 
 + } 
 } 
 diff - - git a / test / unit / org / apache / cassandra / db / commitlog / CommitLogSegmentManagerTest . java b / test / unit / org / apache / cassandra / db / commitlog / CommitLogSegmentManagerTest . java 
 new file mode 100644 
 index 0000000 . . b5c2f41 
 - - - / dev / null 
 + + + b / test / unit / org / apache / cassandra / db / commitlog / CommitLogSegmentManagerTest . java 
 @ @ - 0 , 0 + 1 , 100 @ @ 
 + package org . apache . cassandra . db . commitlog ; 
 + 
 + import java . nio . ByteBuffer ; 
 + import java . util . Random ; 
 + import java . util . concurrent . Semaphore ; 
 + 
 + import javax . naming . ConfigurationException ; 
 + 
 + import org . apache . cassandra . SchemaLoader ; 
 + import org . apache . cassandra . Util ; 
 + import org . apache . cassandra . config . Config . CommitLogSync ; 
 + import org . apache . cassandra . config . DatabaseDescriptor ; 
 + import org . apache . cassandra . config . ParameterizedClass ; 
 + import org . apache . cassandra . db . ColumnFamilyStore ; 
 + import org . apache . cassandra . db . Keyspace ; 
 + import org . apache . cassandra . db . Mutation ; 
 + import org . apache . cassandra . db . RowUpdateBuilder ; 
 + import org . apache . cassandra . db . compaction . CompactionManager ; 
 + import org . apache . cassandra . db . marshal . AsciiType ; 
 + import org . apache . cassandra . db . marshal . BytesType ; 
 + import org . apache . cassandra . schema . KeyspaceParams ; 
 + import org . jboss . byteman . contrib . bmunit . BMRule ; 
 + import org . jboss . byteman . contrib . bmunit . BMUnitRunner ; 
 + import org . junit . Assert ; 
 + import org . junit . BeforeClass ; 
 + import org . junit . Test ; 
 + import org . junit . runner . RunWith ; 
 + 
 + import com . google . common . collect . ImmutableMap ; 
 + 
 + @ RunWith ( BMUnitRunner . class ) 
 + public class CommitLogSegmentManagerTest 
 + { 
 + / / Block commit log service from syncing 
 + private static final Semaphore allowSync = new Semaphore ( 0 ) ; 
 + 
 + private static final String KEYSPACE1 = " CommitLogTest " ; 
 + private static final String STANDARD1 = " Standard1 " ; 
 + private static final String STANDARD2 = " Standard2 " ; 
 + 
 + private final static byte [ ] entropy = new byte [ 1024 * 256 ] ; 
 + @ BeforeClass 
 + public static void defineSchema ( ) throws ConfigurationException 
 + { 
 + new Random ( ) . nextBytes ( entropy ) ; 
 + DatabaseDescriptor . setCommitLogCompression ( new ParameterizedClass ( " LZ4Compressor " , ImmutableMap . of ( ) ) ) ; 
 + DatabaseDescriptor . setCommitLogSegmentSize ( 1 ) ; 
 + DatabaseDescriptor . setCommitLogSync ( CommitLogSync . periodic ) ; 
 + DatabaseDescriptor . setCommitLogSyncPeriod ( 10 * 1000 ) ; 
 + SchemaLoader . prepareServer ( ) ; 
 + SchemaLoader . createKeyspace ( KEYSPACE1 , 
 + KeyspaceParams . simple ( 1 ) , 
 + SchemaLoader . standardCFMD ( KEYSPACE1 , STANDARD1 , 0 , AsciiType . instance , BytesType . instance ) , 
 + SchemaLoader . standardCFMD ( KEYSPACE1 , STANDARD2 , 0 , AsciiType . instance , BytesType . instance ) ) ; 
 + 
 + CompactionManager . instance . disableAutoCompaction ( ) ; 
 + } 
 + 
 + @ Test 
 + @ BMRule ( name = " Block AbstractCommitLogSegment segment flushing " , 
 + targetClass = " AbstractCommitLogService $ 1 " , 
 + targetMethod = " run " , 
 + targetLocation = " AT INVOKE org . apache . cassandra . db . commitlog . CommitLog . sync " , 
 + action = " org . apache . cassandra . db . commitlog . CommitLogSegmentManagerTest . allowSync . acquire ( ) " ) 
 + public void testCompressedCommitLogBackpressure ( ) throws Throwable 
 + { 
 + CommitLog . instance . resetUnsafe ( true ) ; 
 + ColumnFamilyStore cfs1 = Keyspace . open ( KEYSPACE1 ) . getColumnFamilyStore ( STANDARD1 ) ; 
 + 
 + final Mutation m = new RowUpdateBuilder ( cfs1 . metadata , 0 , " k " ) 
 + . clustering ( " bytes " ) 
 + . add ( " val " , ByteBuffer . wrap ( entropy ) ) 
 + . build ( ) ; 
 + 
 + Thread dummyThread = new Thread ( ( ) - > 
 + { 
 + for ( int i = 0 ; i < 20 ; i + + ) 
 + CommitLog . instance . add ( m ) ; 
 + } ) ; 
 + dummyThread . start ( ) ; 
 + 
 + CommitLogSegmentManager clsm = CommitLog . instance . allocator ; 
 + 
 + / / Protect against delay , but still break out as fast as possible 
 + long start = System . currentTimeMillis ( ) ; 
 + while ( System . currentTimeMillis ( ) - start < 5000 ) 
 + { 
 + if ( clsm . getActiveSegments ( ) . size ( ) > = 3 ) 
 + break ; 
 + } 
 + Thread . sleep ( 1000 ) ; 
 + 
 + / / Should only be able to create 3 segments not 7 because it blocks waiting for truncation that never comes 
 + Assert . assertEquals ( 3 , clsm . getActiveSegments ( ) . size ( ) ) ; 
 + 
 + clsm . getActiveSegments ( ) . forEach ( segment - > clsm . recycleSegment ( segment ) ) ; 
 + 
 + Util . spinAssertEquals ( 3 , ( ) - > clsm . getActiveSegments ( ) . size ( ) , 5 ) ; 
 + } 
 + } 
 \ No newline at end of file 
 diff - - git a / test / unit / org / apache / cassandra / db / commitlog / CommitLogTest . java b / test / unit / org / apache / cassandra / db / commitlog / CommitLogTest . java 
 index 91a25e1 . . b5cbf8b 100644 
 - - - a / test / unit / org / apache / cassandra / db / commitlog / CommitLogTest . java 
 + + + b / test / unit / org / apache / cassandra / db / commitlog / CommitLogTest . java 
 @ @ - 18 , 20 + 18 , 9 @ @ 
 * / 
 package org . apache . cassandra . db . commitlog ; 
 
 - import java . io . ByteArrayOutputStream ; 
 - import java . io . DataOutputStream ; 
 - import java . io . File ; 
 - import java . io . FileOutputStream ; 
 - import java . io . IOException ; 
 - import java . io . OutputStream ; 
 - import java . io . RandomAccessFile ; 
 + import java . io . * ; 
 import java . nio . ByteBuffer ; 
 - import java . util . Collections ; 
 - import java . util . HashMap ; 
 - import java . util . List ; 
 - import java . util . Map ; 
 - import java . util . Random ; 
 - import java . util . UUID ; 
 + import java . util . * ; 
 import java . util . concurrent . Callable ; 
 import java . util . concurrent . ExecutionException ; 
 import java . util . zip . CRC32 ; 
 @ @ - 39 , 19 + 28 , 17 @ @ import java . util . zip . Checksum ; 
 
 import com . google . common . collect . Iterables ; 
 
 - import org . apache . cassandra . db . ColumnFamilyStore ; 
 - import org . apache . cassandra . db . Keyspace ; 
 - import org . apache . cassandra . db . Mutation ; 
 - import org . apache . cassandra . db . RowUpdateBuilder ; 
 - import org . apache . cassandra . db . marshal . AsciiType ; 
 - import org . apache . cassandra . db . marshal . BytesType ; 
 + import org . junit . * ; 
 
 import org . apache . cassandra . SchemaLoader ; 
 import org . apache . cassandra . Util ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . config . ParameterizedClass ; 
 + import org . apache . cassandra . db . * ; 
 import org . apache . cassandra . db . commitlog . CommitLogReplayer . CommitLogReplayException ; 
 import org . apache . cassandra . db . compaction . CompactionManager ; 
 + import org . apache . cassandra . db . marshal . AsciiType ; 
 + import org . apache . cassandra . db . marshal . BytesType ; 
 import org . apache . cassandra . db . partitions . PartitionUpdate ; 
 import org . apache . cassandra . db . rows . Row ; 
 import org . apache . cassandra . db . rows . SerializationHelper ; 
 @ @ - 61 , 22 + 48 , 13 @ @ import org . apache . cassandra . io . compress . LZ4Compressor ; 
 import org . apache . cassandra . io . compress . SnappyCompressor ; 
 import org . apache . cassandra . io . util . DataInputPlus ; 
 import org . apache . cassandra . io . util . FastByteArrayInputStream ; 
 - import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . net . MessagingService ; 
 import org . apache . cassandra . schema . KeyspaceParams ; 
 - import org . apache . cassandra . utils . JVMStabilityInspector ; 
 - import org . apache . cassandra . utils . KillerForTests ; 
 import org . apache . cassandra . security . EncryptionContext ; 
 import org . apache . cassandra . security . EncryptionContextGenerator ; 
 - import org . apache . cassandra . utils . Hex ; 
 - import org . apache . cassandra . utils . Pair ; 
 + import org . apache . cassandra . utils . * ; 
 import org . apache . cassandra . utils . vint . VIntCoding ; 
 
 - import org . junit . Assert ; 
 - import org . junit . Before ; 
 - import org . junit . BeforeClass ; 
 - import org . junit . Test ; 
 - 
 import static org . apache . cassandra . utils . ByteBufferUtil . bytes ; 
 import static org . junit . Assert . assertEquals ; 
 import static org . junit . Assert . assertTrue ; 
 @ @ - 106 , 7 + 84 , 7 @ @ public class CommitLogTest 
 } 
 
 @ Before 
 - public void setup ( ) 
 + public void setup ( ) throws IOException 
 { 
 logDirectory = DatabaseDescriptor . getCommitLogLocation ( ) + " / unit " ; 
 new File ( logDirectory ) . mkdirs ( ) ; 
 @ @ - 575 , 11 + 553 , 22 @ @ public class CommitLogTest 
 @ Test 
 public void replay _ StandardMmapped ( ) throws IOException 
 { 
 - DatabaseDescriptor . setCommitLogCompression ( null ) ; 
 - DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createDisabledContext ( ) ) ; 
 - CommitLog commitLog = new CommitLog ( logDirectory , CommitLogArchiver . disabled ( ) ) . start ( ) ; 
 - replaySimple ( commitLog ) ; 
 - replayWithDiscard ( commitLog ) ; 
 + ParameterizedClass originalCompression = DatabaseDescriptor . getCommitLogCompression ( ) ; 
 + EncryptionContext originalEncryptionContext = DatabaseDescriptor . getEncryptionContext ( ) ; 
 + try 
 + { 
 + DatabaseDescriptor . setCommitLogCompression ( null ) ; 
 + DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createDisabledContext ( ) ) ; 
 + CommitLog . instance . resetUnsafe ( true ) ; 
 + replaySimple ( CommitLog . instance ) ; 
 + replayWithDiscard ( CommitLog . instance ) ; 
 + } 
 + finally 
 + { 
 + DatabaseDescriptor . setCommitLogCompression ( originalCompression ) ; 
 + DatabaseDescriptor . setEncryptionContext ( originalEncryptionContext ) ; 
 + CommitLog . instance . resetUnsafe ( true ) ; 
 + } 
 } 
 
 @ Test 
 @ @ - 602 , 29 + 591 , 44 @ @ public class CommitLogTest 
 
 private void replay _ Compressed ( ParameterizedClass parameterizedClass ) throws IOException 
 { 
 - DatabaseDescriptor . setCommitLogCompression ( parameterizedClass ) ; 
 - DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createDisabledContext ( ) ) ; 
 - CommitLog commitLog = new CommitLog ( logDirectory , CommitLogArchiver . disabled ( ) ) . start ( ) ; 
 - replaySimple ( commitLog ) ; 
 - replayWithDiscard ( commitLog ) ; 
 + ParameterizedClass originalCompression = DatabaseDescriptor . getCommitLogCompression ( ) ; 
 + EncryptionContext originalEncryptionContext = DatabaseDescriptor . getEncryptionContext ( ) ; 
 + try 
 + { 
 + DatabaseDescriptor . setCommitLogCompression ( parameterizedClass ) ; 
 + DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createDisabledContext ( ) ) ; 
 + CommitLog . instance . resetUnsafe ( true ) ; 
 + 
 + replaySimple ( CommitLog . instance ) ; 
 + replayWithDiscard ( CommitLog . instance ) ; 
 + } 
 + finally 
 + { 
 + DatabaseDescriptor . setCommitLogCompression ( originalCompression ) ; 
 + DatabaseDescriptor . setEncryptionContext ( originalEncryptionContext ) ; 
 + CommitLog . instance . resetUnsafe ( true ) ; 
 + } 
 } 
 
 @ Test 
 public void replay _ Encrypted ( ) throws IOException 
 { 
 - DatabaseDescriptor . setCommitLogCompression ( null ) ; 
 - DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createContext ( true ) ) ; 
 - CommitLog commitLog = new CommitLog ( logDirectory , CommitLogArchiver . disabled ( ) ) . start ( ) ; 
 - 
 + ParameterizedClass originalCompression = DatabaseDescriptor . getCommitLogCompression ( ) ; 
 + EncryptionContext originalEncryptionContext = DatabaseDescriptor . getEncryptionContext ( ) ; 
 try 
 { 
 - replaySimple ( commitLog ) ; 
 - replayWithDiscard ( commitLog ) ; 
 + DatabaseDescriptor . setCommitLogCompression ( null ) ; 
 + DatabaseDescriptor . setEncryptionContext ( EncryptionContextGenerator . createContext ( true ) ) ; 
 + CommitLog . instance . resetUnsafe ( true ) ; 
 + 
 + replaySimple ( CommitLog . instance ) ; 
 + replayWithDiscard ( CommitLog . instance ) ; 
 } 
 finally 
 { 
 - for ( String file : commitLog . getActiveSegmentNames ( ) ) 
 - FileUtils . delete ( new File ( commitLog . location , file ) ) ; 
 + DatabaseDescriptor . setCommitLogCompression ( originalCompression ) ; 
 + DatabaseDescriptor . setEncryptionContext ( originalEncryptionContext ) ; 
 + CommitLog . instance . resetUnsafe ( true ) ; 
 } 
 } 
 
 @ @ - 706 , 6 + 710 , 7 @ @ public class CommitLogTest 
 this . filterPosition = filterPosition ; 
 } 
 
 + @ SuppressWarnings ( " resource " ) 
 void replayMutation ( byte [ ] inputBuffer , int size , final long entryLocation , final CommitLogDescriptor desc ) throws IOException 
 { 
 if ( entryLocation < = filterPosition . position )

NEAREST DIFF:
ELIMINATEDSENTENCE
