BLEU SCORE: 0.005774363155184915

TEST MSG: Remove dead code
GENERATED MSG: StorageProxy # cas ( ) doesn ' t order columns names correctly when querying

TEST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / db / AtomicSortedColumns . java b / src / java / org / apache / cassandra / db / AtomicSortedColumns . java <nl> index b44d8bf . . 1c0bf1b 100644 <nl> - - - a / src / java / org / apache / cassandra / db / AtomicSortedColumns . java <nl> + + + b / src / java / org / apache / cassandra / db / AtomicSortedColumns . java <nl> @ @ - 330 , 12 + 330 , 7 @ @ public class AtomicSortedColumns extends ColumnFamily <nl> Column reconciledColumn = column . reconcile ( oldColumn , allocator ) ; <nl> if ( map . replace ( name , oldColumn , reconciledColumn ) ) <nl> { <nl> - / / for memtable updates we only care about oldcolumn , reconciledcolumn , but when compacting <nl> - / / we need to make sure we update indexes no matter the order we merge <nl> - if ( reconciledColumn = = column ) <nl> - indexer . update ( oldColumn , reconciledColumn ) ; <nl> - else <nl> - indexer . update ( column , reconciledColumn ) ; <nl> + indexer . update ( oldColumn , reconciledColumn ) ; <nl> return reconciledColumn . dataSize ( ) - oldColumn . dataSize ( ) ; <nl> } <nl> / / We failed to replace column due to a concurrent update or a concurrent removal . Keep trying .
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 5e2f062 . . f7beb5e 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 17 , 6 + 17 , 7 @ @ <nl> * Update deletion timestamp in Commit # updatesWithPaxosTime ( CASSANDRA - 5787 ) <nl> * Thrift cas ( ) method crashes if input columns are not sorted ( CASSANDRA - 5786 ) <nl> * Order columns names correctly when querying for CAS ( CASSANDRA - 5788 ) <nl> + * Fix streaming retry ( CASSANDRA - 5775 ) <nl> <nl> <nl> 2 . 0 . 0 - beta1 <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamReader . java b / src / java / org / apache / cassandra / streaming / StreamReader . java <nl> index 5c19eb1 . . 862f5a2 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamReader . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamReader . java <nl> @ @ - 20 , 6 + 20 , 7 @ @ package org . apache . cassandra . streaming ; <nl> import java . io . DataInput ; <nl> import java . io . DataInputStream ; <nl> import java . io . IOException ; <nl> + import java . io . InputStream ; <nl> import java . nio . channels . Channels ; <nl> import java . nio . channels . ReadableByteChannel ; <nl> import java . util . Collection ; <nl> @ @ - 76 , 17 + 77 , 12 @ @ public class StreamReader <nl> <nl> Pair < String , String > kscf = Schema . instance . getCF ( cfId ) ; <nl> ColumnFamilyStore cfs = Keyspace . open ( kscf . left ) . getColumnFamilyStore ( kscf . right ) ; <nl> - Directories . DataDirectory localDir = cfs . directories . getLocationCapableOfSize ( totalSize ) ; <nl> - if ( localDir = = null ) <nl> - throw new IOException ( " Insufficient disk space to store " + totalSize + " bytes " ) ; <nl> - desc = Descriptor . fromFilename ( cfs . getTempSSTablePath ( cfs . directories . getLocationForDisk ( localDir ) ) ) ; <nl> <nl> - SSTableWriter writer = new SSTableWriter ( desc . filenameFor ( Component . DATA ) , estimatedKeys ) ; <nl> + SSTableWriter writer = createWriter ( cfs , totalSize ) ; <nl> + DataInputStream dis = new DataInputStream ( new LZFInputStream ( Channels . newInputStream ( channel ) ) ) ; <nl> + BytesReadTracker in = new BytesReadTracker ( dis ) ; <nl> try <nl> { <nl> - DataInputStream dis = new DataInputStream ( new LZFInputStream ( Channels . newInputStream ( channel ) ) ) ; <nl> - BytesReadTracker in = new BytesReadTracker ( dis ) ; <nl> - <nl> while ( in . getBytesRead ( ) < totalSize ) <nl> { <nl> writeRow ( writer , in , cfs ) ; <nl> @ @ - 98 , 6 + 94 , 7 @ @ public class StreamReader <nl> catch ( Throwable e ) <nl> { <nl> writer . abort ( ) ; <nl> + drain ( dis , in . getBytesRead ( ) ) ; <nl> if ( e instanceof IOException ) <nl> throw ( IOException ) e ; <nl> else <nl> @ @ - 105 , 6 + 102 , 24 @ @ public class StreamReader <nl> } <nl> } <nl> <nl> + protected SSTableWriter createWriter ( ColumnFamilyStore cfs , long totalSize ) throws IOException <nl> + { <nl> + Directories . DataDirectory localDir = cfs . directories . getLocationCapableOfSize ( totalSize ) ; <nl> + if ( localDir = = null ) <nl> + throw new IOException ( " Insufficient disk space to store " + totalSize + " bytes " ) ; <nl> + desc = Descriptor . fromFilename ( cfs . getTempSSTablePath ( cfs . directories . getLocationForDisk ( localDir ) ) ) ; <nl> + <nl> + return new SSTableWriter ( desc . filenameFor ( Component . DATA ) , estimatedKeys ) ; <nl> + } <nl> + <nl> + protected void drain ( InputStream dis , long bytesRead ) throws IOException <nl> + { <nl> + long toSkip = totalSize ( ) - bytesRead ; <nl> + toSkip = toSkip - dis . skip ( toSkip ) ; <nl> + while ( toSkip > 0 ) <nl> + toSkip = toSkip - dis . skip ( toSkip ) ; <nl> + } <nl> + <nl> protected long totalSize ( ) <nl> { <nl> long size = 0 ; <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamSession . java b / src / java / org / apache / cassandra / streaming / StreamSession . java <nl> index aeb4419 . . 2c4b47d 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamSession . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamSession . java <nl> @ @ - 19 , 7 + 19 , 6 @ @ package org . apache . cassandra . streaming ; <nl> <nl> import java . io . IOException ; <nl> import java . net . InetAddress ; <nl> - import java . net . Socket ; <nl> import java . util . * ; <nl> import java . util . concurrent . Future ; <nl> <nl> @ @ - 359 , 7 + 358 , 12 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe <nl> break ; <nl> <nl> case FILE : <nl> - received ( ( FileMessage ) message ) ; <nl> + receive ( ( FileMessage ) message ) ; <nl> + break ; <nl> + <nl> + case RECEIVED : <nl> + ReceivedMessage received = ( ReceivedMessage ) message ; <nl> + received ( received . cfId , received . sequenceNumber ) ; <nl> break ; <nl> <nl> case RETRY : <nl> @ @ - 455 , 7 + 459 , 6 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe <nl> { <nl> StreamingMetrics . totalOutgoingBytes . inc ( header . size ( ) ) ; <nl> metrics . outgoingBytes . inc ( header . size ( ) ) ; <nl> - transfers . get ( header . cfId ) . complete ( header . sequenceNumber ) ; <nl> } <nl> <nl> / * * <nl> @ @ - 463 , 10 + 466 , 12 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe <nl> * <nl> * @ param message received file <nl> * / <nl> - public void received ( FileMessage message ) <nl> + public void receive ( FileMessage message ) <nl> { <nl> StreamingMetrics . totalIncomingBytes . inc ( message . header . size ( ) ) ; <nl> metrics . incomingBytes . inc ( message . header . size ( ) ) ; <nl> + / / send back file received message <nl> + handler . sendMessage ( new ReceivedMessage ( message . header . cfId , message . header . sequenceNumber ) ) ; <nl> receivers . get ( message . header . cfId ) . received ( message . sstable ) ; <nl> } <nl> <nl> @ @ - 476 , 6 + 481 , 11 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe <nl> streamResult . handleProgress ( progress ) ; <nl> } <nl> <nl> + public void received ( UUID cfId , int sequenceNumber ) <nl> + { <nl> + transfers . get ( cfId ) . complete ( sequenceNumber ) ; <nl> + } <nl> + <nl> / * * <nl> * Call back on receiving { @ code StreamMessage . Type . RETRY } message . <nl> * <nl> @ @ - 513 , 6 + 523 , 7 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe <nl> <nl> public void doRetry ( FileMessageHeader header , Throwable e ) <nl> { <nl> + logger . warn ( " retrying for following error " , e ) ; <nl> / / retry <nl> retries + + ; <nl> if ( retries > DatabaseDescriptor . getMaxStreamingRetries ( ) ) <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamTransferTask . java b / src / java / org / apache / cassandra / streaming / StreamTransferTask . java <nl> index 956692d . . 61ad058 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamTransferTask . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamTransferTask . java <nl> @ @ - 49 , 9 + 49 , 9 @ @ public class StreamTransferTask extends StreamTask <nl> } <nl> <nl> / * * <nl> - * Complete sending file . <nl> + * Received ACK for file at { @ code sequenceNumber } . <nl> * <nl> - * @ param sequenceNumber sequence number of completed file transfer <nl> + * @ param sequenceNumber sequence number of file <nl> * / <nl> public void complete ( int sequenceNumber ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java b / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java <nl> index 1e8308f . . da290c3 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java <nl> + + + b / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java <nl> @ @ - 61 , 20 + 61 , 16 @ @ public class CompressedStreamReader extends StreamReader <nl> public SSTableReader read ( ReadableByteChannel channel ) throws IOException <nl> { <nl> long totalSize = totalSize ( ) ; <nl> - CompressedInputStream cis = new CompressedInputStream ( Channels . newInputStream ( channel ) , compressionInfo ) ; <nl> <nl> Pair < String , String > kscf = Schema . instance . getCF ( cfId ) ; <nl> ColumnFamilyStore cfs = Keyspace . open ( kscf . left ) . getColumnFamilyStore ( kscf . right ) ; <nl> - Directories . DataDirectory localDir = cfs . directories . getLocationCapableOfSize ( totalSize ) ; <nl> - if ( localDir = = null ) <nl> - throw new IOException ( " Insufficient disk space to store " + totalSize + " bytes " ) ; <nl> - desc = Descriptor . fromFilename ( cfs . getTempSSTablePath ( cfs . directories . getLocationForDisk ( localDir ) ) ) ; <nl> <nl> - SSTableWriter writer = new SSTableWriter ( desc . filenameFor ( Component . DATA ) , estimatedKeys ) ; <nl> + SSTableWriter writer = createWriter ( cfs , totalSize ) ; <nl> + <nl> + CompressedInputStream cis = new CompressedInputStream ( Channels . newInputStream ( channel ) , compressionInfo ) ; <nl> + BytesReadTracker in = new BytesReadTracker ( new DataInputStream ( cis ) ) ; <nl> try <nl> { <nl> - BytesReadTracker in = new BytesReadTracker ( new DataInputStream ( cis ) ) ; <nl> - <nl> for ( Pair < Long , Long > section : sections ) <nl> { <nl> long length = section . right - section . left ; <nl> @ @ - 93 , 6 + 89 , 7 @ @ public class CompressedStreamReader extends StreamReader <nl> catch ( Throwable e ) <nl> { <nl> writer . abort ( ) ; <nl> + drain ( cis , in . getBytesRead ( ) ) ; <nl> if ( e instanceof IOException ) <nl> throw ( IOException ) e ; <nl> else <nl> diff - - git a / src / java / org / apache / cassandra / streaming / messages / ReceivedMessage . java b / src / java / org / apache / cassandra / streaming / messages / ReceivedMessage . java <nl> new file mode 100644 <nl> index 0000000 . . daf8bf1 <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / streaming / messages / ReceivedMessage . java <nl> @ @ - 0 , 0 + 1 , 57 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an " AS IS " BASIS , <nl> + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + * See the License for the specific language governing permissions and <nl> + * limitations under the License . <nl> + * / <nl> + package org . apache . cassandra . streaming . messages ; <nl> + <nl> + import java . io . * ; <nl> + import java . nio . channels . Channels ; <nl> + import java . nio . channels . ReadableByteChannel ; <nl> + import java . nio . channels . WritableByteChannel ; <nl> + import java . util . UUID ; <nl> + <nl> + import org . apache . cassandra . net . MessagingService ; <nl> + import org . apache . cassandra . streaming . StreamSession ; <nl> + import org . apache . cassandra . utils . UUIDSerializer ; <nl> + <nl> + public class ReceivedMessage extends StreamMessage <nl> + { <nl> + public static Serializer < ReceivedMessage > serializer = new Serializer < ReceivedMessage > ( ) <nl> + { <nl> + public ReceivedMessage deserialize ( ReadableByteChannel in , int version , StreamSession session ) throws IOException <nl> + { <nl> + DataInput input = new DataInputStream ( Channels . newInputStream ( in ) ) ; <nl> + return new ReceivedMessage ( UUIDSerializer . serializer . deserialize ( input , MessagingService . current _ version ) , input . readInt ( ) ) ; <nl> + } <nl> + <nl> + public void serialize ( ReceivedMessage message , WritableByteChannel out , int version , StreamSession session ) throws IOException <nl> + { <nl> + DataOutput output = new DataOutputStream ( Channels . newOutputStream ( out ) ) ; <nl> + UUIDSerializer . serializer . serialize ( message . cfId , output , MessagingService . current _ version ) ; <nl> + output . writeInt ( message . sequenceNumber ) ; <nl> + } <nl> + } ; <nl> + <nl> + public final UUID cfId ; <nl> + public final int sequenceNumber ; <nl> + <nl> + public ReceivedMessage ( UUID cfId , int sequenceNumber ) <nl> + { <nl> + super ( Type . RECEIVED ) ; <nl> + this . cfId = cfId ; <nl> + this . sequenceNumber = sequenceNumber ; <nl> + } <nl> + } <nl> diff - - git a / src / java / org / apache / cassandra / streaming / messages / StreamMessage . java b / src / java / org / apache / cassandra / streaming / messages / StreamMessage . java <nl> index f737675 . . 11e9955 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / messages / StreamMessage . java <nl> + + + b / src / java / org / apache / cassandra / streaming / messages / StreamMessage . java <nl> @ @ - 65 , 9 + 65 , 10 @ @ public abstract class StreamMessage <nl> { <nl> PREPARE ( 1 , 5 , PrepareMessage . serializer ) , <nl> FILE ( 2 , 0 , FileMessage . serializer ) , <nl> - RETRY ( 3 , 1 , RetryMessage . serializer ) , <nl> - COMPLETE ( 4 , 4 , CompleteMessage . serializer ) , <nl> - SESSION _ FAILED ( 5 , 5 , SessionFailedMessage . serializer ) ; <nl> + RECEIVED ( 3 , 1 , ReceivedMessage . serializer ) , <nl> + RETRY ( 4 , 1 , RetryMessage . serializer ) , <nl> + COMPLETE ( 5 , 4 , CompleteMessage . serializer ) , <nl> + SESSION _ FAILED ( 6 , 5 , SessionFailedMessage . serializer ) ; <nl> <nl> public static Type get ( byte type ) <nl> {

TEST DIFF:
diff - - git a / src / java / org / apache / cassandra / db / AtomicSortedColumns . java b / src / java / org / apache / cassandra / db / AtomicSortedColumns . java 
 index b44d8bf . . 1c0bf1b 100644 
 - - - a / src / java / org / apache / cassandra / db / AtomicSortedColumns . java 
 + + + b / src / java / org / apache / cassandra / db / AtomicSortedColumns . java 
 @ @ - 330 , 12 + 330 , 7 @ @ public class AtomicSortedColumns extends ColumnFamily 
 Column reconciledColumn = column . reconcile ( oldColumn , allocator ) ; 
 if ( map . replace ( name , oldColumn , reconciledColumn ) ) 
 { 
 - / / for memtable updates we only care about oldcolumn , reconciledcolumn , but when compacting 
 - / / we need to make sure we update indexes no matter the order we merge 
 - if ( reconciledColumn = = column ) 
 - indexer . update ( oldColumn , reconciledColumn ) ; 
 - else 
 - indexer . update ( column , reconciledColumn ) ; 
 + indexer . update ( oldColumn , reconciledColumn ) ; 
 return reconciledColumn . dataSize ( ) - oldColumn . dataSize ( ) ; 
 } 
 / / We failed to replace column due to a concurrent update or a concurrent removal . Keep trying .

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 5e2f062 . . f7beb5e 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 17 , 6 + 17 , 7 @ @ 
 * Update deletion timestamp in Commit # updatesWithPaxosTime ( CASSANDRA - 5787 ) 
 * Thrift cas ( ) method crashes if input columns are not sorted ( CASSANDRA - 5786 ) 
 * Order columns names correctly when querying for CAS ( CASSANDRA - 5788 ) 
 + * Fix streaming retry ( CASSANDRA - 5775 ) 
 
 
 2 . 0 . 0 - beta1 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamReader . java b / src / java / org / apache / cassandra / streaming / StreamReader . java 
 index 5c19eb1 . . 862f5a2 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamReader . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamReader . java 
 @ @ - 20 , 6 + 20 , 7 @ @ package org . apache . cassandra . streaming ; 
 import java . io . DataInput ; 
 import java . io . DataInputStream ; 
 import java . io . IOException ; 
 + import java . io . InputStream ; 
 import java . nio . channels . Channels ; 
 import java . nio . channels . ReadableByteChannel ; 
 import java . util . Collection ; 
 @ @ - 76 , 17 + 77 , 12 @ @ public class StreamReader 
 
 Pair < String , String > kscf = Schema . instance . getCF ( cfId ) ; 
 ColumnFamilyStore cfs = Keyspace . open ( kscf . left ) . getColumnFamilyStore ( kscf . right ) ; 
 - Directories . DataDirectory localDir = cfs . directories . getLocationCapableOfSize ( totalSize ) ; 
 - if ( localDir = = null ) 
 - throw new IOException ( " Insufficient disk space to store " + totalSize + " bytes " ) ; 
 - desc = Descriptor . fromFilename ( cfs . getTempSSTablePath ( cfs . directories . getLocationForDisk ( localDir ) ) ) ; 
 
 - SSTableWriter writer = new SSTableWriter ( desc . filenameFor ( Component . DATA ) , estimatedKeys ) ; 
 + SSTableWriter writer = createWriter ( cfs , totalSize ) ; 
 + DataInputStream dis = new DataInputStream ( new LZFInputStream ( Channels . newInputStream ( channel ) ) ) ; 
 + BytesReadTracker in = new BytesReadTracker ( dis ) ; 
 try 
 { 
 - DataInputStream dis = new DataInputStream ( new LZFInputStream ( Channels . newInputStream ( channel ) ) ) ; 
 - BytesReadTracker in = new BytesReadTracker ( dis ) ; 
 - 
 while ( in . getBytesRead ( ) < totalSize ) 
 { 
 writeRow ( writer , in , cfs ) ; 
 @ @ - 98 , 6 + 94 , 7 @ @ public class StreamReader 
 catch ( Throwable e ) 
 { 
 writer . abort ( ) ; 
 + drain ( dis , in . getBytesRead ( ) ) ; 
 if ( e instanceof IOException ) 
 throw ( IOException ) e ; 
 else 
 @ @ - 105 , 6 + 102 , 24 @ @ public class StreamReader 
 } 
 } 
 
 + protected SSTableWriter createWriter ( ColumnFamilyStore cfs , long totalSize ) throws IOException 
 + { 
 + Directories . DataDirectory localDir = cfs . directories . getLocationCapableOfSize ( totalSize ) ; 
 + if ( localDir = = null ) 
 + throw new IOException ( " Insufficient disk space to store " + totalSize + " bytes " ) ; 
 + desc = Descriptor . fromFilename ( cfs . getTempSSTablePath ( cfs . directories . getLocationForDisk ( localDir ) ) ) ; 
 + 
 + return new SSTableWriter ( desc . filenameFor ( Component . DATA ) , estimatedKeys ) ; 
 + } 
 + 
 + protected void drain ( InputStream dis , long bytesRead ) throws IOException 
 + { 
 + long toSkip = totalSize ( ) - bytesRead ; 
 + toSkip = toSkip - dis . skip ( toSkip ) ; 
 + while ( toSkip > 0 ) 
 + toSkip = toSkip - dis . skip ( toSkip ) ; 
 + } 
 + 
 protected long totalSize ( ) 
 { 
 long size = 0 ; 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamSession . java b / src / java / org / apache / cassandra / streaming / StreamSession . java 
 index aeb4419 . . 2c4b47d 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamSession . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamSession . java 
 @ @ - 19 , 7 + 19 , 6 @ @ package org . apache . cassandra . streaming ; 
 
 import java . io . IOException ; 
 import java . net . InetAddress ; 
 - import java . net . Socket ; 
 import java . util . * ; 
 import java . util . concurrent . Future ; 
 
 @ @ - 359 , 7 + 358 , 12 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe 
 break ; 
 
 case FILE : 
 - received ( ( FileMessage ) message ) ; 
 + receive ( ( FileMessage ) message ) ; 
 + break ; 
 + 
 + case RECEIVED : 
 + ReceivedMessage received = ( ReceivedMessage ) message ; 
 + received ( received . cfId , received . sequenceNumber ) ; 
 break ; 
 
 case RETRY : 
 @ @ - 455 , 7 + 459 , 6 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe 
 { 
 StreamingMetrics . totalOutgoingBytes . inc ( header . size ( ) ) ; 
 metrics . outgoingBytes . inc ( header . size ( ) ) ; 
 - transfers . get ( header . cfId ) . complete ( header . sequenceNumber ) ; 
 } 
 
 / * * 
 @ @ - 463 , 10 + 466 , 12 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe 
 * 
 * @ param message received file 
 * / 
 - public void received ( FileMessage message ) 
 + public void receive ( FileMessage message ) 
 { 
 StreamingMetrics . totalIncomingBytes . inc ( message . header . size ( ) ) ; 
 metrics . incomingBytes . inc ( message . header . size ( ) ) ; 
 + / / send back file received message 
 + handler . sendMessage ( new ReceivedMessage ( message . header . cfId , message . header . sequenceNumber ) ) ; 
 receivers . get ( message . header . cfId ) . received ( message . sstable ) ; 
 } 
 
 @ @ - 476 , 6 + 481 , 11 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe 
 streamResult . handleProgress ( progress ) ; 
 } 
 
 + public void received ( UUID cfId , int sequenceNumber ) 
 + { 
 + transfers . get ( cfId ) . complete ( sequenceNumber ) ; 
 + } 
 + 
 / * * 
 * Call back on receiving { @ code StreamMessage . Type . RETRY } message . 
 * 
 @ @ - 513 , 6 + 523 , 7 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe 
 
 public void doRetry ( FileMessageHeader header , Throwable e ) 
 { 
 + logger . warn ( " retrying for following error " , e ) ; 
 / / retry 
 retries + + ; 
 if ( retries > DatabaseDescriptor . getMaxStreamingRetries ( ) ) 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamTransferTask . java b / src / java / org / apache / cassandra / streaming / StreamTransferTask . java 
 index 956692d . . 61ad058 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamTransferTask . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamTransferTask . java 
 @ @ - 49 , 9 + 49 , 9 @ @ public class StreamTransferTask extends StreamTask 
 } 
 
 / * * 
 - * Complete sending file . 
 + * Received ACK for file at { @ code sequenceNumber } . 
 * 
 - * @ param sequenceNumber sequence number of completed file transfer 
 + * @ param sequenceNumber sequence number of file 
 * / 
 public void complete ( int sequenceNumber ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java b / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java 
 index 1e8308f . . da290c3 100644 
 - - - a / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java 
 + + + b / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java 
 @ @ - 61 , 20 + 61 , 16 @ @ public class CompressedStreamReader extends StreamReader 
 public SSTableReader read ( ReadableByteChannel channel ) throws IOException 
 { 
 long totalSize = totalSize ( ) ; 
 - CompressedInputStream cis = new CompressedInputStream ( Channels . newInputStream ( channel ) , compressionInfo ) ; 
 
 Pair < String , String > kscf = Schema . instance . getCF ( cfId ) ; 
 ColumnFamilyStore cfs = Keyspace . open ( kscf . left ) . getColumnFamilyStore ( kscf . right ) ; 
 - Directories . DataDirectory localDir = cfs . directories . getLocationCapableOfSize ( totalSize ) ; 
 - if ( localDir = = null ) 
 - throw new IOException ( " Insufficient disk space to store " + totalSize + " bytes " ) ; 
 - desc = Descriptor . fromFilename ( cfs . getTempSSTablePath ( cfs . directories . getLocationForDisk ( localDir ) ) ) ; 
 
 - SSTableWriter writer = new SSTableWriter ( desc . filenameFor ( Component . DATA ) , estimatedKeys ) ; 
 + SSTableWriter writer = createWriter ( cfs , totalSize ) ; 
 + 
 + CompressedInputStream cis = new CompressedInputStream ( Channels . newInputStream ( channel ) , compressionInfo ) ; 
 + BytesReadTracker in = new BytesReadTracker ( new DataInputStream ( cis ) ) ; 
 try 
 { 
 - BytesReadTracker in = new BytesReadTracker ( new DataInputStream ( cis ) ) ; 
 - 
 for ( Pair < Long , Long > section : sections ) 
 { 
 long length = section . right - section . left ; 
 @ @ - 93 , 6 + 89 , 7 @ @ public class CompressedStreamReader extends StreamReader 
 catch ( Throwable e ) 
 { 
 writer . abort ( ) ; 
 + drain ( cis , in . getBytesRead ( ) ) ; 
 if ( e instanceof IOException ) 
 throw ( IOException ) e ; 
 else 
 diff - - git a / src / java / org / apache / cassandra / streaming / messages / ReceivedMessage . java b / src / java / org / apache / cassandra / streaming / messages / ReceivedMessage . java 
 new file mode 100644 
 index 0000000 . . daf8bf1 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / streaming / messages / ReceivedMessage . java 
 @ @ - 0 , 0 + 1 , 57 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , software 
 + * distributed under the License is distributed on an " AS IS " BASIS , 
 + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + * See the License for the specific language governing permissions and 
 + * limitations under the License . 
 + * / 
 + package org . apache . cassandra . streaming . messages ; 
 + 
 + import java . io . * ; 
 + import java . nio . channels . Channels ; 
 + import java . nio . channels . ReadableByteChannel ; 
 + import java . nio . channels . WritableByteChannel ; 
 + import java . util . UUID ; 
 + 
 + import org . apache . cassandra . net . MessagingService ; 
 + import org . apache . cassandra . streaming . StreamSession ; 
 + import org . apache . cassandra . utils . UUIDSerializer ; 
 + 
 + public class ReceivedMessage extends StreamMessage 
 + { 
 + public static Serializer < ReceivedMessage > serializer = new Serializer < ReceivedMessage > ( ) 
 + { 
 + public ReceivedMessage deserialize ( ReadableByteChannel in , int version , StreamSession session ) throws IOException 
 + { 
 + DataInput input = new DataInputStream ( Channels . newInputStream ( in ) ) ; 
 + return new ReceivedMessage ( UUIDSerializer . serializer . deserialize ( input , MessagingService . current _ version ) , input . readInt ( ) ) ; 
 + } 
 + 
 + public void serialize ( ReceivedMessage message , WritableByteChannel out , int version , StreamSession session ) throws IOException 
 + { 
 + DataOutput output = new DataOutputStream ( Channels . newOutputStream ( out ) ) ; 
 + UUIDSerializer . serializer . serialize ( message . cfId , output , MessagingService . current _ version ) ; 
 + output . writeInt ( message . sequenceNumber ) ; 
 + } 
 + } ; 
 + 
 + public final UUID cfId ; 
 + public final int sequenceNumber ; 
 + 
 + public ReceivedMessage ( UUID cfId , int sequenceNumber ) 
 + { 
 + super ( Type . RECEIVED ) ; 
 + this . cfId = cfId ; 
 + this . sequenceNumber = sequenceNumber ; 
 + } 
 + } 
 diff - - git a / src / java / org / apache / cassandra / streaming / messages / StreamMessage . java b / src / java / org / apache / cassandra / streaming / messages / StreamMessage . java 
 index f737675 . . 11e9955 100644 
 - - - a / src / java / org / apache / cassandra / streaming / messages / StreamMessage . java 
 + + + b / src / java / org / apache / cassandra / streaming / messages / StreamMessage . java 
 @ @ - 65 , 9 + 65 , 10 @ @ public abstract class StreamMessage 
 { 
 PREPARE ( 1 , 5 , PrepareMessage . serializer ) , 
 FILE ( 2 , 0 , FileMessage . serializer ) , 
 - RETRY ( 3 , 1 , RetryMessage . serializer ) , 
 - COMPLETE ( 4 , 4 , CompleteMessage . serializer ) , 
 - SESSION _ FAILED ( 5 , 5 , SessionFailedMessage . serializer ) ; 
 + RECEIVED ( 3 , 1 , ReceivedMessage . serializer ) , 
 + RETRY ( 4 , 1 , RetryMessage . serializer ) , 
 + COMPLETE ( 5 , 4 , CompleteMessage . serializer ) , 
 + SESSION _ FAILED ( 6 , 5 , SessionFailedMessage . serializer ) ; 
 
 public static Type get ( byte type ) 
 {
