BLEU SCORE: 0.02383853510228548

TEST MSG: Abort startup and print txn log info when corrupted
GENERATED MSG: Make compaction , flush JBOD - aware

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index aad9834 . . 3682647 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 6 @ @ <nl> 3 . 6 <nl> + * Refuse to start and print txn log information in case of disk <nl> + corruption ( CASSANDRA - 10112 ) <nl> * Resolve some eclipse - warnings ( CASSANDRA - 11086 ) <nl> * ( cqlsh ) Show static columns in a different color ( CASSANDRA - 11059 ) <nl> * Allow to remove TTLs on table with default _ time _ to _ live ( CASSANDRA - 11207 ) <nl> diff - - git a / NEWS . txt b / NEWS . txt <nl> index 74490a8 . . cc3e9c2 100644 <nl> - - - a / NEWS . txt <nl> + + + b / NEWS . txt <nl> @ @ - 18 , 8 + 18 , 11 @ @ using the provided ' sstableupgrade ' tool . <nl> <nl> New features <nl> - - - - - - - - - - - - <nl> - - for tables having a default _ time _ to _ live specifying a TTL of 0 will remove the TTL <nl> + - For tables having a default _ time _ to _ live specifying a TTL of 0 will remove the TTL <nl> from the inserted or updated values . <nl> + - Startup is now aborted if corrupted transaction log files are found . The details <nl> + of the affected log files are now logged , allowing the operator to decide how <nl> + to resolve the situation . <nl> <nl> 3 . 4 <nl> = = = = = <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index 3b5e745 . . 12a5f62 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 56 , 6 + 56 , 7 @ @ import org . apache . cassandra . db . rows . CellPath ; <nl> import org . apache . cassandra . dht . * ; <nl> import org . apache . cassandra . dht . Range ; <nl> import org . apache . cassandra . exceptions . ConfigurationException ; <nl> + import org . apache . cassandra . exceptions . StartupException ; <nl> import org . apache . cassandra . index . SecondaryIndexManager ; <nl> import org . apache . cassandra . index . internal . CassandraIndex ; <nl> import org . apache . cassandra . index . transactions . UpdateTransaction ; <nl> @ @ - 581 , 7 + 582 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> * Removes unnecessary files from the cf directory at startup : these include temp files , orphans , zero - length files <nl> * and compacted sstables . Files that cannot be recognized will be ignored . <nl> * / <nl> - public static void scrubDataDirectories ( CFMetaData metadata ) <nl> + public static void scrubDataDirectories ( CFMetaData metadata ) throws StartupException <nl> { <nl> Directories directories = new Directories ( metadata ) ; <nl> <nl> @ @ - 589 , 7 + 590 , 12 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> clearEphemeralSnapshots ( directories ) ; <nl> <nl> logger . trace ( " Removing temporary or obsoleted files from unfinished operations for table { } " , metadata . cfName ) ; <nl> - LifecycleTransaction . removeUnfinishedLeftovers ( metadata ) ; <nl> + if ( ! LifecycleTransaction . removeUnfinishedLeftovers ( metadata ) ) <nl> + throw new StartupException ( StartupException . ERR _ WRONG _ DISK _ STATE , <nl> + String . format ( " Cannot remove temporary or obsoleted files for % s . % s due to a problem with transaction " + <nl> + " log files . Please check records with problems in the log messages above and fix them . " + <nl> + " Refer to the 3 . 0 upgrading instructions in NEWS . txt " + <nl> + " for a description of transaction log files . " , metadata . ksName , metadata . cfName ) ) ; <nl> <nl> logger . trace ( " Further extra check for orphan sstable files for { } " , metadata . cfName ) ; <nl> for ( Map . Entry < Descriptor , Set < Component > > sstableFiles : directories . sstableLister ( Directories . OnTxnErr . IGNORE ) . list ( ) . entrySet ( ) ) <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LifecycleTransaction . java b / src / java / org / apache / cassandra / db / lifecycle / LifecycleTransaction . java <nl> index a5eb01f . . 7ce4a08 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / LifecycleTransaction . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / LifecycleTransaction . java <nl> @ @ - 522 , 9 + 522 , 9 @ @ public class LifecycleTransaction extends Transactional . AbstractTransactional <nl> log . untrackNew ( table ) ; <nl> } <nl> <nl> - public static void removeUnfinishedLeftovers ( CFMetaData metadata ) <nl> + public static boolean removeUnfinishedLeftovers ( CFMetaData metadata ) <nl> { <nl> - LogTransaction . removeUnfinishedLeftovers ( metadata ) ; <nl> + return LogTransaction . removeUnfinishedLeftovers ( metadata ) ; <nl> } <nl> <nl> / * * <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogFile . java b / src / java / org / apache / cassandra / db / lifecycle / LogFile . java <nl> index 9064e5f . . 3074842 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / LogFile . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / LogFile . java <nl> @ @ - 73 , 9 + 73 , 9 @ @ final class LogFile <nl> return new LogFile ( operationType , id , logReplicas ) ; <nl> } <nl> <nl> - Throwable syncFolder ( Throwable accumulate ) <nl> + Throwable syncDirectory ( Throwable accumulate ) <nl> { <nl> - return replicas . syncFolder ( accumulate ) ; <nl> + return replicas . syncDirectory ( accumulate ) ; <nl> } <nl> <nl> OperationType type ( ) <nl> @ @ - 94 , 9 + 94 , 9 @ @ final class LogFile <nl> { <nl> deleteFilesForRecordsOfType ( committed ( ) ? Type . REMOVE : Type . ADD ) ; <nl> <nl> - / / we sync the parent folders between contents and log deletion <nl> + / / we sync the parent directories between contents and log deletion <nl> / / to ensure there is a happens before edge between them <nl> - Throwables . maybeFail ( syncFolder ( accumulate ) ) ; <nl> + Throwables . maybeFail ( syncDirectory ( accumulate ) ) ; <nl> <nl> accumulate = replicas . delete ( accumulate ) ; <nl> } <nl> @ @ - 130 , 7 + 130 , 7 @ @ final class LogFile <nl> records . clear ( ) ; <nl> if ( ! replicas . readRecords ( records ) ) <nl> { <nl> - logger . error ( " Failed to read records from { } " , replicas ) ; <nl> + logger . error ( " Failed to read records for transaction log { } " , this ) ; <nl> return false ; <nl> } <nl> <nl> @ @ - 143 , 7 + 143 , 7 @ @ final class LogFile <nl> LogRecord failedOn = firstInvalid . get ( ) ; <nl> if ( getLastRecord ( ) ! = failedOn ) <nl> { <nl> - logError ( failedOn ) ; <nl> + setErrorInReplicas ( failedOn ) ; <nl> return false ; <nl> } <nl> <nl> @ @ - 151 , 10 + 151 , 10 @ @ final class LogFile <nl> if ( records . stream ( ) <nl> . filter ( ( r ) - > r ! = failedOn ) <nl> . filter ( LogRecord : : isInvalid ) <nl> - . map ( LogFile : : logError ) <nl> + . map ( this : : setErrorInReplicas ) <nl> . findFirst ( ) . isPresent ( ) ) <nl> { <nl> - logError ( failedOn ) ; <nl> + setErrorInReplicas ( failedOn ) ; <nl> return false ; <nl> } <nl> <nl> @ @ - 167 , 9 + 167 , 9 @ @ final class LogFile <nl> return true ; <nl> } <nl> <nl> - static LogRecord logError ( LogRecord record ) <nl> + LogRecord setErrorInReplicas ( LogRecord record ) <nl> { <nl> - logger . error ( " { } " , record . error ( ) ) ; <nl> + replicas . setErrorInReplicas ( record ) ; <nl> return record ; <nl> } <nl> <nl> @ @ - 177 , 9 + 177 , 8 @ @ final class LogFile <nl> { <nl> if ( record . checksum ! = record . computeChecksum ( ) ) <nl> { <nl> - record . setError ( String . format ( " Invalid checksum for sstable [ % s ] , record [ % s ] : [ % d ] should have been [ % d ] " , <nl> + record . setError ( String . format ( " Invalid checksum for sstable [ % s ] : [ % d ] should have been [ % d ] " , <nl> record . fileName ( ) , <nl> - record , <nl> record . checksum , <nl> record . computeChecksum ( ) ) ) ; <nl> return ; <nl> @ @ - 197 , 10 + 196 , 9 @ @ final class LogFile <nl> record . status . onDiskRecord = record . withExistingFiles ( ) ; <nl> if ( record . updateTime ! = record . status . onDiskRecord . updateTime & & record . status . onDiskRecord . numFiles > 0 ) <nl> { <nl> - record . setError ( String . format ( " Unexpected files detected for sstable [ % s ] , " + <nl> - " record [ % s ] : last update time [ % tT ] should have been [ % tT ] " , <nl> + record . setError ( String . format ( " Unexpected files detected for sstable [ % s ] : " + <nl> + " last update time [ % tT ] should have been [ % tT ] " , <nl> record . fileName ( ) , <nl> - record , <nl> record . status . onDiskRecord . updateTime , <nl> record . updateTime ) ) ; <nl> <nl> @ @ - 212 , 11 + 210 , 9 @ @ final class LogFile <nl> if ( record . type = = Type . REMOVE & & record . status . onDiskRecord . numFiles < record . numFiles ) <nl> { / / if we found a corruption in the last record , then we continue only <nl> / / if the number of files matches exactly for all previous records . <nl> - record . setError ( String . format ( " Incomplete fileset detected for sstable [ % s ] , record [ % s ] : " + <nl> - " number of files [ % d ] should have been [ % d ] . Treating as unrecoverable " + <nl> - " due to corruption of the final record . " , <nl> + record . setError ( String . format ( " Incomplete fileset detected for sstable [ % s ] : " + <nl> + " number of files [ % d ] should have been [ % d ] . " , <nl> record . fileName ( ) , <nl> - record . raw , <nl> record . status . onDiskRecord . numFiles , <nl> record . numFiles ) ) ; <nl> } <nl> @ @ - 267 , 8 + 263 , 9 @ @ final class LogFile <nl> { <nl> assert type = = Type . ADD | | type = = Type . REMOVE ; <nl> <nl> - File folder = table . descriptor . directory ; <nl> - replicas . maybeCreateReplica ( folder , getFileName ( folder ) , records ) ; <nl> + File directory = table . descriptor . directory ; <nl> + String fileName = StringUtils . join ( directory , File . separator , getFileName ( ) ) ; <nl> + replicas . maybeCreateReplica ( directory , fileName , records ) ; <nl> return LogRecord . make ( type , table ) ; <nl> } <nl> <nl> @ @ - 351 , 7 + 348 , 25 @ @ final class LogFile <nl> @ Override <nl> public String toString ( ) <nl> { <nl> - return replicas . toString ( ) ; <nl> + return toString ( false ) ; <nl> + } <nl> + <nl> + public String toString ( boolean showContents ) <nl> + { <nl> + StringBuilder str = new StringBuilder ( ) ; <nl> + str . append ( ' [ ' ) ; <nl> + str . append ( getFileName ( ) ) ; <nl> + str . append ( " in " ) ; <nl> + str . append ( replicas . getDirectories ( ) ) ; <nl> + str . append ( ' ] ' ) ; <nl> + if ( showContents ) <nl> + { <nl> + str . append ( System . lineSeparator ( ) ) ; <nl> + str . append ( " Files and contents follow : " ) ; <nl> + str . append ( System . lineSeparator ( ) ) ; <nl> + replicas . printContentsWithAnyErrors ( str ) ; <nl> + } <nl> + return str . toString ( ) ; <nl> } <nl> <nl> @ VisibleForTesting <nl> @ @ - 366 , 16 + 381 , 15 @ @ final class LogFile <nl> return replicas . getFilePaths ( ) ; <nl> } <nl> <nl> - private String getFileName ( File folder ) <nl> + private String getFileName ( ) <nl> { <nl> - String fileName = StringUtils . join ( BigFormat . latestVersion , <nl> - LogFile . SEP , <nl> - " txn " , <nl> - LogFile . SEP , <nl> - type . fileName , <nl> - LogFile . SEP , <nl> - id . toString ( ) , <nl> - LogFile . EXT ) ; <nl> - return StringUtils . join ( folder , File . separator , fileName ) ; <nl> + return StringUtils . join ( BigFormat . latestVersion , <nl> + LogFile . SEP , <nl> + " txn " , <nl> + LogFile . SEP , <nl> + type . fileName , <nl> + LogFile . SEP , <nl> + id . toString ( ) , <nl> + LogFile . EXT ) ; <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java b / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java <nl> index 9e606fc . . b2c7038 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java <nl> @ @ - 105 , 11 + 105 , 13 @ @ final class LogRecord <nl> matcher . group ( 2 ) , <nl> Long . valueOf ( matcher . group ( 3 ) ) , <nl> Integer . valueOf ( matcher . group ( 4 ) ) , <nl> - Long . valueOf ( matcher . group ( 5 ) ) , line ) ; <nl> + Long . valueOf ( matcher . group ( 5 ) ) , <nl> + line ) ; <nl> } <nl> - catch ( Throwable t ) <nl> + catch ( IllegalArgumentException e ) <nl> { <nl> - return new LogRecord ( Type . UNKNOWN , null , 0 , 0 , 0 , line ) . setError ( t ) ; <nl> + return new LogRecord ( Type . UNKNOWN , null , 0 , 0 , 0 , line ) <nl> + . setError ( String . format ( " Failed to parse line : % s " , e . getMessage ( ) ) ) ; <nl> } <nl> } <nl> <nl> @ @ - 180 , 11 + 182 , 6 @ @ final class LogRecord <nl> } <nl> } <nl> <nl> - LogRecord setError ( Throwable t ) <nl> - { <nl> - return setError ( t . getMessage ( ) ) ; <nl> - } <nl> - <nl> LogRecord setError ( String error ) <nl> { <nl> status . setError ( error ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogReplica . java b / src / java / org / apache / cassandra / db / lifecycle / LogReplica . java <nl> index 79b9749 . . da90f88 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / LogReplica . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / LogReplica . java <nl> @ @ - 19 , 6 + 19 , 9 @ @ <nl> package org . apache . cassandra . db . lifecycle ; <nl> <nl> import java . io . File ; <nl> + import java . util . HashMap ; <nl> + import java . util . List ; <nl> + import java . util . Map ; <nl> <nl> import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . utils . CLibrary ; <nl> @ @ - 26 , 7 + 29 , 7 @ @ import org . apache . cassandra . utils . CLibrary ; <nl> / * * <nl> * Because a column family may have sstables on different disks and disks can <nl> * be removed , we duplicate log files into many replicas so as to have a file <nl> - * in each folder where sstables exist . <nl> + * in each directory where sstables exist . <nl> * <nl> * Each replica contains the exact same content but we do allow for final <nl> * partial records in case we crashed after writing to one replica but <nl> @ @ - 37 , 11 + 40 , 12 @ @ import org . apache . cassandra . utils . CLibrary ; <nl> final class LogReplica <nl> { <nl> private final File file ; <nl> - private int folderDescriptor ; <nl> + private int directoryDescriptor ; <nl> + private final Map < String , String > errors = new HashMap < > ( ) ; <nl> <nl> - static LogReplica create ( File folder , String fileName ) <nl> + static LogReplica create ( File directory , String fileName ) <nl> { <nl> - return new LogReplica ( new File ( fileName ) , CLibrary . tryOpenDirectory ( folder . getPath ( ) ) ) ; <nl> + return new LogReplica ( new File ( fileName ) , CLibrary . tryOpenDirectory ( directory . getPath ( ) ) ) ; <nl> } <nl> <nl> static LogReplica open ( File file ) <nl> @ @ - 49 , 10 + 53 , 10 @ @ final class LogReplica <nl> return new LogReplica ( file , CLibrary . tryOpenDirectory ( file . getParentFile ( ) . getPath ( ) ) ) ; <nl> } <nl> <nl> - LogReplica ( File file , int folderDescriptor ) <nl> + LogReplica ( File file , int directoryDescriptor ) <nl> { <nl> this . file = file ; <nl> - this . folderDescriptor = folderDescriptor ; <nl> + this . directoryDescriptor = directoryDescriptor ; <nl> } <nl> <nl> File file ( ) <nl> @ @ - 60 , 27 + 64 , 42 @ @ final class LogReplica <nl> return file ; <nl> } <nl> <nl> + List < String > readLines ( ) <nl> + { <nl> + return FileUtils . readLines ( file ) ; <nl> + } <nl> + <nl> + String getFileName ( ) <nl> + { <nl> + return file . getName ( ) ; <nl> + } <nl> + <nl> + String getDirectory ( ) <nl> + { <nl> + return file . getParent ( ) ; <nl> + } <nl> + <nl> void append ( LogRecord record ) <nl> { <nl> boolean existed = exists ( ) ; <nl> FileUtils . appendAndSync ( file , record . toString ( ) ) ; <nl> <nl> / / If the file did not exist before appending the first <nl> - / / line , then sync the folder as well since now it must exist <nl> + / / line , then sync the directory as well since now it must exist <nl> if ( ! existed ) <nl> - syncFolder ( ) ; <nl> + syncDirectory ( ) ; <nl> } <nl> <nl> - void syncFolder ( ) <nl> + void syncDirectory ( ) <nl> { <nl> - if ( folderDescriptor > = 0 ) <nl> - CLibrary . trySync ( folderDescriptor ) ; <nl> + if ( directoryDescriptor > = 0 ) <nl> + CLibrary . trySync ( directoryDescriptor ) ; <nl> } <nl> <nl> void delete ( ) <nl> { <nl> LogTransaction . delete ( file ) ; <nl> - syncFolder ( ) ; <nl> + syncDirectory ( ) ; <nl> } <nl> <nl> boolean exists ( ) <nl> @ @ - 90 , 10 + 109 , 10 @ @ final class LogReplica <nl> <nl> void close ( ) <nl> { <nl> - if ( folderDescriptor > = 0 ) <nl> + if ( directoryDescriptor > = 0 ) <nl> { <nl> - CLibrary . tryCloseFD ( folderDescriptor ) ; <nl> - folderDescriptor = - 1 ; <nl> + CLibrary . tryCloseFD ( directoryDescriptor ) ; <nl> + directoryDescriptor = - 1 ; <nl> } <nl> } <nl> <nl> @ @ - 102 , 4 + 121 , 31 @ @ final class LogReplica <nl> { <nl> return String . format ( " [ % s ] " , file ) ; <nl> } <nl> + <nl> + void setError ( String line , String error ) <nl> + { <nl> + errors . put ( line , error ) ; <nl> + } <nl> + <nl> + void printContentsWithAnyErrors ( StringBuilder str ) <nl> + { <nl> + str . append ( file . getPath ( ) ) ; <nl> + str . append ( System . lineSeparator ( ) ) ; <nl> + FileUtils . readLines ( file ) . forEach ( line - > printLineWithAnyError ( str , line ) ) ; <nl> + } <nl> + <nl> + private void printLineWithAnyError ( StringBuilder str , String line ) <nl> + { <nl> + str . append ( ' \ t ' ) ; <nl> + str . append ( line ) ; <nl> + str . append ( System . lineSeparator ( ) ) ; <nl> + <nl> + String error = errors . get ( line ) ; <nl> + if ( error ! = null ) <nl> + { <nl> + str . append ( " \ t \ t * * * " ) ; <nl> + str . append ( error ) ; <nl> + str . append ( System . lineSeparator ( ) ) ; <nl> + } <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogReplicaSet . java b / src / java / org / apache / cassandra / db / lifecycle / LogReplicaSet . java <nl> index c557bf2 . . 47a9901 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / LogReplicaSet . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / LogReplicaSet . java <nl> @ @ - 32 , 7 + 32 , 6 @ @ import com . google . common . annotations . VisibleForTesting ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> - import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . utils . Throwables ; <nl> <nl> / * * <nl> @ @ - 60 , 31 + 59 , 31 @ @ public class LogReplicaSet <nl> <nl> void addReplica ( File file ) <nl> { <nl> - File folder = file . getParentFile ( ) ; <nl> - assert ! replicasByFile . containsKey ( folder ) ; <nl> - replicasByFile . put ( folder , LogReplica . open ( file ) ) ; <nl> + File directory = file . getParentFile ( ) ; <nl> + assert ! replicasByFile . containsKey ( directory ) ; <nl> + replicasByFile . put ( directory , LogReplica . open ( file ) ) ; <nl> <nl> if ( logger . isTraceEnabled ( ) ) <nl> logger . trace ( " Added log file replica { } " , file ) ; <nl> } <nl> <nl> - void maybeCreateReplica ( File folder , String fileName , Set < LogRecord > records ) <nl> + void maybeCreateReplica ( File directory , String fileName , Set < LogRecord > records ) <nl> { <nl> - if ( replicasByFile . containsKey ( folder ) ) <nl> + if ( replicasByFile . containsKey ( directory ) ) <nl> return ; <nl> <nl> - final LogReplica replica = LogReplica . create ( folder , fileName ) ; <nl> + final LogReplica replica = LogReplica . create ( directory , fileName ) ; <nl> <nl> records . forEach ( replica : : append ) ; <nl> - replicasByFile . put ( folder , replica ) ; <nl> + replicasByFile . put ( directory , replica ) ; <nl> <nl> if ( logger . isTraceEnabled ( ) ) <nl> logger . trace ( " Created new file replica { } " , replica ) ; <nl> } <nl> <nl> - Throwable syncFolder ( Throwable accumulate ) <nl> + Throwable syncDirectory ( Throwable accumulate ) <nl> { <nl> - return Throwables . perform ( accumulate , replicas ( ) . stream ( ) . map ( s - > s : : syncFolder ) ) ; <nl> + return Throwables . perform ( accumulate , replicas ( ) . stream ( ) . map ( s - > s : : syncDirectory ) ) ; <nl> } <nl> <nl> Throwable delete ( Throwable accumulate ) <nl> @ @ - 101 , 15 + 100 , 18 @ @ public class LogReplicaSet <nl> <nl> boolean readRecords ( Set < LogRecord > records ) <nl> { <nl> - Map < File , List < String > > linesByReplica = replicas ( ) . stream ( ) <nl> - . map ( LogReplica : : file ) <nl> - . collect ( Collectors . toMap ( Function . < File > identity ( ) , FileUtils : : readLines ) ) ; <nl> + Map < LogReplica , List < String > > linesByReplica = replicas ( ) . stream ( ) <nl> + . collect ( Collectors . toMap ( Function . < LogReplica > identity ( ) , <nl> + LogReplica : : readLines , <nl> + ( k , v ) - > { throw new IllegalStateException ( " Duplicated key : " + k ) ; } , <nl> + LinkedHashMap : : new ) ) ; <nl> + <nl> int maxNumLines = linesByReplica . values ( ) . stream ( ) . map ( List : : size ) . reduce ( 0 , Integer : : max ) ; <nl> for ( int i = 0 ; i < maxNumLines ; i + + ) <nl> { <nl> String firstLine = null ; <nl> boolean partial = false ; <nl> - for ( Map . Entry < File , List < String > > entry : linesByReplica . entrySet ( ) ) <nl> + for ( Map . Entry < LogReplica , List < String > > entry : linesByReplica . entrySet ( ) ) <nl> { <nl> List < String > currentLines = entry . getValue ( ) ; <nl> if ( i > = currentLines . size ( ) ) <nl> @ @ - 125 , 9 + 127 , 10 @ @ public class LogReplicaSet <nl> if ( ! isPrefixMatch ( firstLine , currentLine ) ) <nl> { / / not a prefix match <nl> logger . error ( " Mismatched line in file { } : got ' { } ' expected ' { } ' , giving up " , <nl> - entry . getKey ( ) . getName ( ) , <nl> + entry . getKey ( ) . getFileName ( ) , <nl> currentLine , <nl> firstLine ) ; <nl> + entry . getKey ( ) . setError ( currentLine , String . format ( " Does not match < % s > in first replica file " , firstLine ) ) ; <nl> return false ; <nl> } <nl> <nl> @ @ - 136 , 7 + 139 , 7 @ @ public class LogReplicaSet <nl> if ( i = = currentLines . size ( ) - 1 ) <nl> { / / last record , just set record as invalid and move on <nl> logger . warn ( " Mismatched last line in file { } : ' { } ' not the same as ' { } ' " , <nl> - entry . getKey ( ) . getName ( ) , <nl> + entry . getKey ( ) . getFileName ( ) , <nl> currentLine , <nl> firstLine ) ; <nl> <nl> @ @ - 148 , 9 + 151 , 10 @ @ public class LogReplicaSet <nl> else <nl> { / / mismatched entry file has more lines , giving up <nl> logger . error ( " Mismatched line in file { } : got ' { } ' expected ' { } ' , giving up " , <nl> - entry . getKey ( ) . getName ( ) , <nl> + entry . getKey ( ) . getFileName ( ) , <nl> currentLine , <nl> firstLine ) ; <nl> + entry . getKey ( ) . setError ( currentLine , String . format ( " Does not match < % s > in first replica file " , firstLine ) ) ; <nl> return false ; <nl> } <nl> } <nl> @ @ - 160 , 6 + 164 , 7 @ @ public class LogReplicaSet <nl> if ( records . contains ( record ) ) <nl> { / / duplicate records <nl> logger . error ( " Found duplicate record { } for { } , giving up " , record , record . fileName ( ) ) ; <nl> + setError ( record , " Duplicated record " ) ; <nl> return false ; <nl> } <nl> <nl> @ @ - 171 , 6 + 176 , 7 @ @ public class LogReplicaSet <nl> if ( record . isFinal ( ) & & i ! = ( maxNumLines - 1 ) ) <nl> { / / too many final records <nl> logger . error ( " Found too many lines for { } , giving up " , record . fileName ( ) ) ; <nl> + setError ( record , " This record should have been the last one in all replicas " ) ; <nl> return false ; <nl> } <nl> } <nl> @ @ - 178 , 6 + 184 , 22 @ @ public class LogReplicaSet <nl> return true ; <nl> } <nl> <nl> + void setError ( LogRecord record , String error ) <nl> + { <nl> + record . setError ( error ) ; <nl> + setErrorInReplicas ( record ) ; <nl> + } <nl> + <nl> + void setErrorInReplicas ( LogRecord record ) <nl> + { <nl> + replicas ( ) . forEach ( r - > r . setError ( record . raw , record . error ( ) ) ) ; <nl> + } <nl> + <nl> + void printContentsWithAnyErrors ( StringBuilder str ) <nl> + { <nl> + replicas ( ) . forEach ( r - > r . printContentsWithAnyErrors ( str ) ) ; <nl> + } <nl> + <nl> / * * <nl> * Add the record to all the replicas : if it is a final record then we throw only if we fail to write it <nl> * to all , otherwise we throw if we fail to write it to any file , see CASSANDRA - 10421 for details <nl> @ @ - 216 , 6 + 238 , 11 @ @ public class LogReplicaSet <nl> : " [ - ] " ; <nl> } <nl> <nl> + String getDirectories ( ) <nl> + { <nl> + return String . join ( " , " , replicas ( ) . stream ( ) . map ( LogReplica : : getDirectory ) . collect ( Collectors . toList ( ) ) ) ; <nl> + } <nl> + <nl> @ VisibleForTesting <nl> List < File > getFiles ( ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java b / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java <nl> index ce76165 . . b441454 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java <nl> @ @ - 24 , 6 + 24 , 7 @ @ import java . nio . file . NoSuchFileException ; <nl> import java . util . * ; <nl> import java . util . concurrent . ConcurrentLinkedQueue ; <nl> import java . util . concurrent . TimeUnit ; <nl> + import java . util . function . Predicate ; <nl> <nl> import com . google . common . annotations . VisibleForTesting ; <nl> import com . google . common . util . concurrent . Runnables ; <nl> @ @ - 55 , 7 + 56 , 7 @ @ import org . apache . cassandra . utils . concurrent . Transactional ; <nl> * IMPORTANT : The transaction must complete ( commit or abort ) before any temporary files are deleted , even though the <nl> * txn log file itself will not be deleted until all tracked files are deleted . This is required by FileLister to ensure <nl> * a consistent disk state . LifecycleTransaction ensures this requirement , so this class should really never be used <nl> - * outside of LT . @ see FileLister . classifyFiles ( TransactionData txn ) <nl> + * outside of LT . @ see LogAwareFileLister . classifyFiles ( ) <nl> * <nl> * A class that tracks sstable files involved in a transaction across sstables : <nl> * if the transaction succeeds the old files should be deleted and the new ones kept ; vice - versa if it fails . <nl> @ @ - 67 , 8 + 68 , 7 @ @ import org . apache . cassandra . utils . concurrent . Transactional ; <nl> * <nl> * where sstable - 2 is a new sstable to be retained if the transaction succeeds and sstable - 1 is an old sstable to be <nl> * removed . CRC is an incremental CRC of the file content up to this point . For old sstable files we also log the <nl> - * last update time of all files for the sstable descriptor and a checksum of vital properties such as update times <nl> - * and file sizes . <nl> + * last update time of all files for the sstable descriptor and the number of sstable files . <nl> * <nl> * Upon commit we add a final line to the log file : <nl> * <nl> @ @ - 238 , 27 + 238 , 29 @ @ class LogTransaction extends Transactional . AbstractTransactional implements Tran <nl> public void run ( ) <nl> { <nl> if ( logger . isTraceEnabled ( ) ) <nl> - logger . trace ( " Removing files for transaction { } " , name ( ) ) ; <nl> + logger . trace ( " Removing files for transaction log { } " , data ) ; <nl> <nl> if ( ! data . completed ( ) ) <nl> { / / this happens if we forget to close a txn and the garbage collector closes it for us <nl> - logger . error ( " { } was not completed , trying to abort it now " , data ) ; <nl> + logger . error ( " Transaction log { } indicates txn was not completed , trying to abort it now " , data ) ; <nl> Throwable err = Throwables . perform ( ( Throwable ) null , data : : abort ) ; <nl> if ( err ! = null ) <nl> - logger . error ( " Failed to abort { } " , data , err ) ; <nl> + logger . error ( " Failed to abort transaction log { } " , data , err ) ; <nl> } <nl> <nl> Throwable err = data . removeUnfinishedLeftovers ( null ) ; <nl> <nl> if ( err ! = null ) <nl> { <nl> - logger . info ( " Failed deleting files for transaction { } , we ' ll retry after GC and on on server restart " , name ( ) , err ) ; <nl> + logger . info ( " Failed deleting files for transaction log { } , we ' ll retry after GC and on on server restart " , <nl> + data , <nl> + err ) ; <nl> failedDeletions . add ( this ) ; <nl> } <nl> else <nl> { <nl> if ( logger . isTraceEnabled ( ) ) <nl> - logger . trace ( " Closing file transaction { } " , name ( ) ) ; <nl> + logger . trace ( " Closing transaction log { } " , data ) ; <nl> <nl> data . close ( ) ; <nl> } <nl> @ @ - 360 , 7 + 362 , 7 @ @ class LogTransaction extends Transactional . AbstractTransactional implements Tran <nl> } <nl> catch ( Throwable t ) <nl> { <nl> - logger . error ( " Failed to complete file transaction { } " , id ( ) , t ) ; <nl> + logger . error ( " Failed to complete file transaction id { } " , id ( ) , t ) ; <nl> return Throwables . merge ( accumulate , t ) ; <nl> } <nl> } <nl> @ @ - 378 , 31 + 380 , 43 @ @ class LogTransaction extends Transactional . AbstractTransactional implements Tran <nl> protected void doPrepare ( ) { } <nl> <nl> / * * <nl> - * Called on startup to scan existing folders for any unfinished leftovers of <nl> - * operations that were ongoing when the process exited . Also called by the standalone <nl> - * sstableutil tool when the cleanup option is specified , @ see StandaloneSSTableUtil . <nl> + * Removes any leftovers from unifinished transactions as indicated by any transaction log files that <nl> + * are found in the table directories . This means that any old sstable files for transactions that were committed , <nl> + * or any new sstable files for transactions that were aborted or still in progress , should be removed * if <nl> + * it is safe to do so * . Refer to the checks in LogFile . verify for further details on the safety checks <nl> + * before removing transaction leftovers and refer to the comments at the beginning of this file or in NEWS . txt <nl> + * for further details on transaction logs . <nl> + * <nl> + * This method is called on startup and by the standalone sstableutil tool when the cleanup option is specified , <nl> + * @ see StandaloneSSTableUtil . <nl> + * <nl> + * @ return true if the leftovers of all transaction logs found were removed , false otherwise . <nl> * <nl> * / <nl> - static void removeUnfinishedLeftovers ( CFMetaData metadata ) <nl> + static boolean removeUnfinishedLeftovers ( CFMetaData metadata ) <nl> { <nl> - removeUnfinishedLeftovers ( new Directories ( metadata ) . getCFDirectories ( ) ) ; <nl> + return removeUnfinishedLeftovers ( new Directories ( metadata ) . getCFDirectories ( ) ) ; <nl> } <nl> <nl> @ VisibleForTesting <nl> - static void removeUnfinishedLeftovers ( List < File > folders ) <nl> + static boolean removeUnfinishedLeftovers ( List < File > directories ) <nl> { <nl> LogFilesByName logFiles = new LogFilesByName ( ) ; <nl> - folders . forEach ( logFiles : : list ) ; <nl> - logFiles . removeUnfinishedLeftovers ( ) ; <nl> + directories . forEach ( logFiles : : list ) ; <nl> + return logFiles . removeUnfinishedLeftovers ( ) ; <nl> } <nl> <nl> private static final class LogFilesByName <nl> { <nl> + / / This maps a transaction log file name to a list of physical files . Each sstable <nl> + / / can have multiple directories and a transaction is trakced by identical transaction log <nl> + / / files , one per directory . So for each transaction file name we can have multiple <nl> + / / physical files . <nl> Map < String , List < File > > files = new HashMap < > ( ) ; <nl> <nl> - void list ( File folder ) <nl> + void list ( File directory ) <nl> { <nl> - Arrays . stream ( folder . listFiles ( LogFile : : isLogFile ) ) . forEach ( this : : add ) ; <nl> + Arrays . stream ( directory . listFiles ( LogFile : : isLogFile ) ) . forEach ( this : : add ) ; <nl> } <nl> <nl> void add ( File file ) <nl> @ @ - 417 , 25 + 431 , 35 @ @ class LogTransaction extends Transactional . AbstractTransactional implements Tran <nl> filesByName . add ( file ) ; <nl> } <nl> <nl> - void removeUnfinishedLeftovers ( ) <nl> + boolean removeUnfinishedLeftovers ( ) <nl> { <nl> - files . forEach ( LogFilesByName : : removeUnfinishedLeftovers ) ; <nl> + return files . entrySet ( ) <nl> + . stream ( ) <nl> + . map ( LogFilesByName : : removeUnfinishedLeftovers ) <nl> + . allMatch ( Predicate . isEqual ( true ) ) ; <nl> } <nl> <nl> - static void removeUnfinishedLeftovers ( String name , List < File > logFiles ) <nl> + static boolean removeUnfinishedLeftovers ( Map . Entry < String , List < File > > entry ) <nl> { <nl> - LogFile txn = LogFile . make ( name , logFiles ) ; <nl> + LogFile txn = LogFile . make ( entry . getKey ( ) , entry . getValue ( ) ) ; <nl> try <nl> { <nl> if ( txn . verify ( ) ) <nl> { <nl> Throwable failure = txn . removeUnfinishedLeftovers ( null ) ; <nl> if ( failure ! = null ) <nl> - logger . error ( " Failed to remove unfinished transaction leftovers for txn { } " , txn , failure ) ; <nl> + { <nl> + logger . error ( " Failed to remove unfinished transaction leftovers for transaction log { } " , <nl> + txn . toString ( true ) , failure ) ; <nl> + return false ; <nl> + } <nl> + <nl> + return true ; <nl> } <nl> else <nl> { <nl> - logger . error ( " Unexpected disk state : failed to read transaction txn { } " , txn ) ; <nl> + logger . error ( " Unexpected disk state : failed to read transaction log { } " , txn . toString ( true ) ) ; <nl> + return false ; <nl> } <nl> } <nl> finally <nl> diff - - git a / src / java / org / apache / cassandra / exceptions / StartupException . java b / src / java / org / apache / cassandra / exceptions / StartupException . java <nl> index ec4890f . . 1513cf9 100644 <nl> - - - a / src / java / org / apache / cassandra / exceptions / StartupException . java <nl> + + + b / src / java / org / apache / cassandra / exceptions / StartupException . java <nl> @ @ - 23 , 6 + 23 , 10 @ @ package org . apache . cassandra . exceptions ; <nl> * / <nl> public class StartupException extends Exception <nl> { <nl> + public final static int ERR _ WRONG _ MACHINE _ STATE = 1 ; <nl> + public final static int ERR _ WRONG _ DISK _ STATE = 3 ; <nl> + public final static int ERR _ WRONG _ CONFIG = 100 ; <nl> + <nl> public final int returnCode ; <nl> <nl> public StartupException ( int returnCode , String message ) <nl> diff - - git a / src / java / org / apache / cassandra / service / CassandraDaemon . java b / src / java / org / apache / cassandra / service / CassandraDaemon . java <nl> index 183abf8 . . b84a5e3 100644 <nl> - - - a / src / java / org / apache / cassandra / service / CassandraDaemon . java <nl> + + + b / src / java / org / apache / cassandra / service / CassandraDaemon . java <nl> @ @ - 236 , 7 + 236 , 16 @ @ public class CassandraDaemon <nl> continue ; <nl> <nl> for ( CFMetaData cfm : Schema . instance . getTablesAndViews ( keyspaceName ) ) <nl> - ColumnFamilyStore . scrubDataDirectories ( cfm ) ; <nl> + { <nl> + try <nl> + { <nl> + ColumnFamilyStore . scrubDataDirectories ( cfm ) ; <nl> + } <nl> + catch ( StartupException e ) <nl> + { <nl> + exitOrFail ( e . returnCode , e . getMessage ( ) , e . getCause ( ) ) ; <nl> + } <nl> + } <nl> } <nl> <nl> Keyspace . setInitialized ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / service / StartupChecks . java b / src / java / org / apache / cassandra / service / StartupChecks . java <nl> index e903721 . . 7c6c91a 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StartupChecks . java <nl> + + + b / src / java / org / apache / cassandra / service / StartupChecks . java <nl> @ @ - 134 , 8 + 134 , 9 @ @ public class StartupChecks <nl> { <nl> long now = System . currentTimeMillis ( ) ; <nl> if ( now < EARLIEST _ LAUNCH _ DATE ) <nl> - throw new StartupException ( 1 , String . format ( " current machine time is % s , but that is seemingly incorrect . exiting now . " , <nl> - new Date ( now ) . toString ( ) ) ) ; <nl> + throw new StartupException ( StartupException . ERR _ WRONG _ MACHINE _ STATE , <nl> + String . format ( " current machine time is % s , but that is seemingly incorrect . exiting now . " , <nl> + new Date ( now ) . toString ( ) ) ) ; <nl> } <nl> } ; <nl> <nl> @ @ - 186 , 7 + 187 , 7 @ @ public class StartupChecks <nl> { <nl> / / Fail - fast if JNA is not available or failing to initialize properly <nl> if ( ! CLibrary . jnaAvailable ( ) ) <nl> - throw new StartupException ( 3 , " JNA failing to initialize properly . " ) ; <nl> + throw new StartupException ( StartupException . ERR _ WRONG _ MACHINE _ STATE , " JNA failing to initialize properly . " ) ; <nl> } <nl> } ; <nl> <nl> @ @ - 216 , 12 + 217 , 14 @ @ public class StartupChecks <nl> logger . warn ( " Directory { } doesn ' t exist " , dataDir ) ; <nl> / / if they don ' t , failing their creation , stop cassandra . <nl> if ( ! dir . mkdirs ( ) ) <nl> - throw new StartupException ( 3 , " Has no permission to create directory " + dataDir ) ; <nl> + throw new StartupException ( StartupException . ERR _ WRONG _ DISK _ STATE , <nl> + " Has no permission to create directory " + dataDir ) ; <nl> } <nl> <nl> / / if directories exist verify their permissions <nl> if ( ! Directories . verifyFullPermissions ( dir , dataDir ) ) <nl> - throw new StartupException ( 3 , " Insufficient permissions on directory " + dataDir ) ; <nl> + throw new StartupException ( StartupException . ERR _ WRONG _ DISK _ STATE , <nl> + " Insufficient permissions on directory " + dataDir ) ; <nl> } <nl> } ; <nl> <nl> @ @ - 272 , 11 + 275 , 12 @ @ public class StartupChecks <nl> } <nl> <nl> if ( ! invalid . isEmpty ( ) ) <nl> - throw new StartupException ( 3 , String . format ( " Detected unreadable sstables % s , please check " + <nl> - " NEWS . txt and ensure that you have upgraded through " + <nl> - " all required intermediate versions , running " + <nl> - " upgradesstables " , <nl> - Joiner . on ( " , " ) . join ( invalid ) ) ) ; <nl> + throw new StartupException ( StartupException . ERR _ WRONG _ DISK _ STATE , <nl> + String . format ( " Detected unreadable sstables % s , please check " + <nl> + " NEWS . txt and ensure that you have upgraded through " + <nl> + " all required intermediate versions , running " + <nl> + " upgradesstables " , <nl> + Joiner . on ( " , " ) . join ( invalid ) ) ) ; <nl> <nl> } <nl> } ; <nl> @ @ - 318 , 7 + 322 , 7 @ @ public class StartupChecks <nl> String formatMessage = " Cannot start node if snitch ' s data center ( % s ) differs from previous data center ( % s ) . " + <nl> " Please fix the snitch configuration , decommission and rebootstrap this node or use the flag - Dcassandra . ignore _ dc = true . " ; <nl> <nl> - throw new StartupException ( 100 , String . format ( formatMessage , currentDc , storedDc ) ) ; <nl> + throw new StartupException ( StartupException . ERR _ WRONG _ CONFIG , String . format ( formatMessage , currentDc , storedDc ) ) ; <nl> } <nl> } <nl> } <nl> @ @ - 340 , 7 + 344 , 7 @ @ public class StartupChecks <nl> String formatMessage = " Cannot start node if snitch ' s rack ( % s ) differs from previous rack ( % s ) . " + <nl> " Please fix the snitch configuration , decommission and rebootstrap this node or use the flag - Dcassandra . ignore _ rack = true . " ; <nl> <nl> - throw new StartupException ( 100 , String . format ( formatMessage , currentRack , storedRack ) ) ; <nl> + throw new StartupException ( StartupException . ERR _ WRONG _ CONFIG , String . format ( formatMessage , currentRack , storedRack ) ) ; <nl> } <nl> } <nl> } <nl> diff - - git a / test / unit / org / apache / cassandra / db / lifecycle / LogTransactionTest . java b / test / unit / org / apache / cassandra / db / lifecycle / LogTransactionTest . java <nl> index 4f2fc73 . . 59958bb 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / lifecycle / LogTransactionTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / lifecycle / LogTransactionTest . java <nl> @ @ - 519 , 7 + 519 , 7 @ @ public class LogTransactionTest extends AbstractTransactionalTest <nl> LogAwareFileLister . getTemporaryFiles ( dataFolder2 ) ) ; <nl> <nl> / / normally called at startup <nl> - LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ; <nl> + assertTrue ( LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ) ; <nl> <nl> / / new tables should be only table left <nl> assertFiles ( dataFolder1 . getPath ( ) , new HashSet < > ( sstables [ 1 ] . getAllFilePaths ( ) ) ) ; <nl> @ @ - 570 , 7 + 570 , 7 @ @ public class LogTransactionTest extends AbstractTransactionalTest <nl> LogAwareFileLister . getTemporaryFiles ( dataFolder2 ) ) ; <nl> <nl> / / normally called at startup <nl> - LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ; <nl> + assertTrue ( LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ) ; <nl> <nl> / / old tables should be only table left <nl> assertFiles ( dataFolder1 . getPath ( ) , new HashSet < > ( sstables [ 0 ] . getAllFilePaths ( ) ) ) ; <nl> @ @ - 735 , 7 + 735 , 8 @ @ public class LogTransactionTest extends AbstractTransactionalTest <nl> <nl> Arrays . stream ( sstables ) . forEach ( s - > s . selfRef ( ) . release ( ) ) ; <nl> <nl> - LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ; <nl> + / / if shouldCommit is true then it should remove the leftovers and return true , false otherwise <nl> + assertEquals ( shouldCommit , LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ) ; <nl> LogTransaction . waitForDeletions ( ) ; <nl> <nl> if ( shouldCommit ) <nl> @ @ - 862 , 7 + 863 , 7 @ @ public class LogTransactionTest extends AbstractTransactionalTest <nl> if ( filePath . endsWith ( " Data . db " ) ) <nl> { <nl> assertTrue ( FileUtils . delete ( filePath ) ) ; <nl> - assertNull ( t . txnFile ( ) . syncFolder ( null ) ) ; <nl> + assertNull ( t . txnFile ( ) . syncDirectory ( null ) ) ; <nl> break ; <nl> } <nl> }
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 2ea901f . . 3c7163a 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 1 . 1 . 5 <nl> + * increase stack size under Java7 to 180K <nl> * Log ( info ) schema changes ( CASSANDRA - 4547 ) <nl> <nl> <nl> diff - - git a / conf / cassandra - env . sh b / conf / cassandra - env . sh <nl> index 6ae28a0 . . ff3fc86 100644 <nl> - - - a / conf / cassandra - env . sh <nl> + + + b / conf / cassandra - env . sh <nl> @ @ - 186 , 7 + 186 , 7 @ @ if [ " ` uname ` " = " Linux " ] ; then <nl> # supported . <nl> if startswith " $ JVM _ VERSION " ' 1 . 7 . ' <nl> then <nl> - JVM _ OPTS = " $ JVM _ OPTS - Xss160k " <nl> + JVM _ OPTS = " $ JVM _ OPTS - Xss180k " <nl> else <nl> JVM _ OPTS = " $ JVM _ OPTS - Xss128k " <nl> fi

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index aad9834 . . 3682647 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 6 @ @ 
 3 . 6 
 + * Refuse to start and print txn log information in case of disk 
 + corruption ( CASSANDRA - 10112 ) 
 * Resolve some eclipse - warnings ( CASSANDRA - 11086 ) 
 * ( cqlsh ) Show static columns in a different color ( CASSANDRA - 11059 ) 
 * Allow to remove TTLs on table with default _ time _ to _ live ( CASSANDRA - 11207 ) 
 diff - - git a / NEWS . txt b / NEWS . txt 
 index 74490a8 . . cc3e9c2 100644 
 - - - a / NEWS . txt 
 + + + b / NEWS . txt 
 @ @ - 18 , 8 + 18 , 11 @ @ using the provided ' sstableupgrade ' tool . 
 
 New features 
 - - - - - - - - - - - - 
 - - for tables having a default _ time _ to _ live specifying a TTL of 0 will remove the TTL 
 + - For tables having a default _ time _ to _ live specifying a TTL of 0 will remove the TTL 
 from the inserted or updated values . 
 + - Startup is now aborted if corrupted transaction log files are found . The details 
 + of the affected log files are now logged , allowing the operator to decide how 
 + to resolve the situation . 
 
 3 . 4 
 = = = = = 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index 3b5e745 . . 12a5f62 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 56 , 6 + 56 , 7 @ @ import org . apache . cassandra . db . rows . CellPath ; 
 import org . apache . cassandra . dht . * ; 
 import org . apache . cassandra . dht . Range ; 
 import org . apache . cassandra . exceptions . ConfigurationException ; 
 + import org . apache . cassandra . exceptions . StartupException ; 
 import org . apache . cassandra . index . SecondaryIndexManager ; 
 import org . apache . cassandra . index . internal . CassandraIndex ; 
 import org . apache . cassandra . index . transactions . UpdateTransaction ; 
 @ @ - 581 , 7 + 582 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 * Removes unnecessary files from the cf directory at startup : these include temp files , orphans , zero - length files 
 * and compacted sstables . Files that cannot be recognized will be ignored . 
 * / 
 - public static void scrubDataDirectories ( CFMetaData metadata ) 
 + public static void scrubDataDirectories ( CFMetaData metadata ) throws StartupException 
 { 
 Directories directories = new Directories ( metadata ) ; 
 
 @ @ - 589 , 7 + 590 , 12 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 clearEphemeralSnapshots ( directories ) ; 
 
 logger . trace ( " Removing temporary or obsoleted files from unfinished operations for table { } " , metadata . cfName ) ; 
 - LifecycleTransaction . removeUnfinishedLeftovers ( metadata ) ; 
 + if ( ! LifecycleTransaction . removeUnfinishedLeftovers ( metadata ) ) 
 + throw new StartupException ( StartupException . ERR _ WRONG _ DISK _ STATE , 
 + String . format ( " Cannot remove temporary or obsoleted files for % s . % s due to a problem with transaction " + 
 + " log files . Please check records with problems in the log messages above and fix them . " + 
 + " Refer to the 3 . 0 upgrading instructions in NEWS . txt " + 
 + " for a description of transaction log files . " , metadata . ksName , metadata . cfName ) ) ; 
 
 logger . trace ( " Further extra check for orphan sstable files for { } " , metadata . cfName ) ; 
 for ( Map . Entry < Descriptor , Set < Component > > sstableFiles : directories . sstableLister ( Directories . OnTxnErr . IGNORE ) . list ( ) . entrySet ( ) ) 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LifecycleTransaction . java b / src / java / org / apache / cassandra / db / lifecycle / LifecycleTransaction . java 
 index a5eb01f . . 7ce4a08 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / LifecycleTransaction . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / LifecycleTransaction . java 
 @ @ - 522 , 9 + 522 , 9 @ @ public class LifecycleTransaction extends Transactional . AbstractTransactional 
 log . untrackNew ( table ) ; 
 } 
 
 - public static void removeUnfinishedLeftovers ( CFMetaData metadata ) 
 + public static boolean removeUnfinishedLeftovers ( CFMetaData metadata ) 
 { 
 - LogTransaction . removeUnfinishedLeftovers ( metadata ) ; 
 + return LogTransaction . removeUnfinishedLeftovers ( metadata ) ; 
 } 
 
 / * * 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogFile . java b / src / java / org / apache / cassandra / db / lifecycle / LogFile . java 
 index 9064e5f . . 3074842 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / LogFile . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / LogFile . java 
 @ @ - 73 , 9 + 73 , 9 @ @ final class LogFile 
 return new LogFile ( operationType , id , logReplicas ) ; 
 } 
 
 - Throwable syncFolder ( Throwable accumulate ) 
 + Throwable syncDirectory ( Throwable accumulate ) 
 { 
 - return replicas . syncFolder ( accumulate ) ; 
 + return replicas . syncDirectory ( accumulate ) ; 
 } 
 
 OperationType type ( ) 
 @ @ - 94 , 9 + 94 , 9 @ @ final class LogFile 
 { 
 deleteFilesForRecordsOfType ( committed ( ) ? Type . REMOVE : Type . ADD ) ; 
 
 - / / we sync the parent folders between contents and log deletion 
 + / / we sync the parent directories between contents and log deletion 
 / / to ensure there is a happens before edge between them 
 - Throwables . maybeFail ( syncFolder ( accumulate ) ) ; 
 + Throwables . maybeFail ( syncDirectory ( accumulate ) ) ; 
 
 accumulate = replicas . delete ( accumulate ) ; 
 } 
 @ @ - 130 , 7 + 130 , 7 @ @ final class LogFile 
 records . clear ( ) ; 
 if ( ! replicas . readRecords ( records ) ) 
 { 
 - logger . error ( " Failed to read records from { } " , replicas ) ; 
 + logger . error ( " Failed to read records for transaction log { } " , this ) ; 
 return false ; 
 } 
 
 @ @ - 143 , 7 + 143 , 7 @ @ final class LogFile 
 LogRecord failedOn = firstInvalid . get ( ) ; 
 if ( getLastRecord ( ) ! = failedOn ) 
 { 
 - logError ( failedOn ) ; 
 + setErrorInReplicas ( failedOn ) ; 
 return false ; 
 } 
 
 @ @ - 151 , 10 + 151 , 10 @ @ final class LogFile 
 if ( records . stream ( ) 
 . filter ( ( r ) - > r ! = failedOn ) 
 . filter ( LogRecord : : isInvalid ) 
 - . map ( LogFile : : logError ) 
 + . map ( this : : setErrorInReplicas ) 
 . findFirst ( ) . isPresent ( ) ) 
 { 
 - logError ( failedOn ) ; 
 + setErrorInReplicas ( failedOn ) ; 
 return false ; 
 } 
 
 @ @ - 167 , 9 + 167 , 9 @ @ final class LogFile 
 return true ; 
 } 
 
 - static LogRecord logError ( LogRecord record ) 
 + LogRecord setErrorInReplicas ( LogRecord record ) 
 { 
 - logger . error ( " { } " , record . error ( ) ) ; 
 + replicas . setErrorInReplicas ( record ) ; 
 return record ; 
 } 
 
 @ @ - 177 , 9 + 177 , 8 @ @ final class LogFile 
 { 
 if ( record . checksum ! = record . computeChecksum ( ) ) 
 { 
 - record . setError ( String . format ( " Invalid checksum for sstable [ % s ] , record [ % s ] : [ % d ] should have been [ % d ] " , 
 + record . setError ( String . format ( " Invalid checksum for sstable [ % s ] : [ % d ] should have been [ % d ] " , 
 record . fileName ( ) , 
 - record , 
 record . checksum , 
 record . computeChecksum ( ) ) ) ; 
 return ; 
 @ @ - 197 , 10 + 196 , 9 @ @ final class LogFile 
 record . status . onDiskRecord = record . withExistingFiles ( ) ; 
 if ( record . updateTime ! = record . status . onDiskRecord . updateTime & & record . status . onDiskRecord . numFiles > 0 ) 
 { 
 - record . setError ( String . format ( " Unexpected files detected for sstable [ % s ] , " + 
 - " record [ % s ] : last update time [ % tT ] should have been [ % tT ] " , 
 + record . setError ( String . format ( " Unexpected files detected for sstable [ % s ] : " + 
 + " last update time [ % tT ] should have been [ % tT ] " , 
 record . fileName ( ) , 
 - record , 
 record . status . onDiskRecord . updateTime , 
 record . updateTime ) ) ; 
 
 @ @ - 212 , 11 + 210 , 9 @ @ final class LogFile 
 if ( record . type = = Type . REMOVE & & record . status . onDiskRecord . numFiles < record . numFiles ) 
 { / / if we found a corruption in the last record , then we continue only 
 / / if the number of files matches exactly for all previous records . 
 - record . setError ( String . format ( " Incomplete fileset detected for sstable [ % s ] , record [ % s ] : " + 
 - " number of files [ % d ] should have been [ % d ] . Treating as unrecoverable " + 
 - " due to corruption of the final record . " , 
 + record . setError ( String . format ( " Incomplete fileset detected for sstable [ % s ] : " + 
 + " number of files [ % d ] should have been [ % d ] . " , 
 record . fileName ( ) , 
 - record . raw , 
 record . status . onDiskRecord . numFiles , 
 record . numFiles ) ) ; 
 } 
 @ @ - 267 , 8 + 263 , 9 @ @ final class LogFile 
 { 
 assert type = = Type . ADD | | type = = Type . REMOVE ; 
 
 - File folder = table . descriptor . directory ; 
 - replicas . maybeCreateReplica ( folder , getFileName ( folder ) , records ) ; 
 + File directory = table . descriptor . directory ; 
 + String fileName = StringUtils . join ( directory , File . separator , getFileName ( ) ) ; 
 + replicas . maybeCreateReplica ( directory , fileName , records ) ; 
 return LogRecord . make ( type , table ) ; 
 } 
 
 @ @ - 351 , 7 + 348 , 25 @ @ final class LogFile 
 @ Override 
 public String toString ( ) 
 { 
 - return replicas . toString ( ) ; 
 + return toString ( false ) ; 
 + } 
 + 
 + public String toString ( boolean showContents ) 
 + { 
 + StringBuilder str = new StringBuilder ( ) ; 
 + str . append ( ' [ ' ) ; 
 + str . append ( getFileName ( ) ) ; 
 + str . append ( " in " ) ; 
 + str . append ( replicas . getDirectories ( ) ) ; 
 + str . append ( ' ] ' ) ; 
 + if ( showContents ) 
 + { 
 + str . append ( System . lineSeparator ( ) ) ; 
 + str . append ( " Files and contents follow : " ) ; 
 + str . append ( System . lineSeparator ( ) ) ; 
 + replicas . printContentsWithAnyErrors ( str ) ; 
 + } 
 + return str . toString ( ) ; 
 } 
 
 @ VisibleForTesting 
 @ @ - 366 , 16 + 381 , 15 @ @ final class LogFile 
 return replicas . getFilePaths ( ) ; 
 } 
 
 - private String getFileName ( File folder ) 
 + private String getFileName ( ) 
 { 
 - String fileName = StringUtils . join ( BigFormat . latestVersion , 
 - LogFile . SEP , 
 - " txn " , 
 - LogFile . SEP , 
 - type . fileName , 
 - LogFile . SEP , 
 - id . toString ( ) , 
 - LogFile . EXT ) ; 
 - return StringUtils . join ( folder , File . separator , fileName ) ; 
 + return StringUtils . join ( BigFormat . latestVersion , 
 + LogFile . SEP , 
 + " txn " , 
 + LogFile . SEP , 
 + type . fileName , 
 + LogFile . SEP , 
 + id . toString ( ) , 
 + LogFile . EXT ) ; 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java b / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java 
 index 9e606fc . . b2c7038 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java 
 @ @ - 105 , 11 + 105 , 13 @ @ final class LogRecord 
 matcher . group ( 2 ) , 
 Long . valueOf ( matcher . group ( 3 ) ) , 
 Integer . valueOf ( matcher . group ( 4 ) ) , 
 - Long . valueOf ( matcher . group ( 5 ) ) , line ) ; 
 + Long . valueOf ( matcher . group ( 5 ) ) , 
 + line ) ; 
 } 
 - catch ( Throwable t ) 
 + catch ( IllegalArgumentException e ) 
 { 
 - return new LogRecord ( Type . UNKNOWN , null , 0 , 0 , 0 , line ) . setError ( t ) ; 
 + return new LogRecord ( Type . UNKNOWN , null , 0 , 0 , 0 , line ) 
 + . setError ( String . format ( " Failed to parse line : % s " , e . getMessage ( ) ) ) ; 
 } 
 } 
 
 @ @ - 180 , 11 + 182 , 6 @ @ final class LogRecord 
 } 
 } 
 
 - LogRecord setError ( Throwable t ) 
 - { 
 - return setError ( t . getMessage ( ) ) ; 
 - } 
 - 
 LogRecord setError ( String error ) 
 { 
 status . setError ( error ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogReplica . java b / src / java / org / apache / cassandra / db / lifecycle / LogReplica . java 
 index 79b9749 . . da90f88 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / LogReplica . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / LogReplica . java 
 @ @ - 19 , 6 + 19 , 9 @ @ 
 package org . apache . cassandra . db . lifecycle ; 
 
 import java . io . File ; 
 + import java . util . HashMap ; 
 + import java . util . List ; 
 + import java . util . Map ; 
 
 import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . utils . CLibrary ; 
 @ @ - 26 , 7 + 29 , 7 @ @ import org . apache . cassandra . utils . CLibrary ; 
 / * * 
 * Because a column family may have sstables on different disks and disks can 
 * be removed , we duplicate log files into many replicas so as to have a file 
 - * in each folder where sstables exist . 
 + * in each directory where sstables exist . 
 * 
 * Each replica contains the exact same content but we do allow for final 
 * partial records in case we crashed after writing to one replica but 
 @ @ - 37 , 11 + 40 , 12 @ @ import org . apache . cassandra . utils . CLibrary ; 
 final class LogReplica 
 { 
 private final File file ; 
 - private int folderDescriptor ; 
 + private int directoryDescriptor ; 
 + private final Map < String , String > errors = new HashMap < > ( ) ; 
 
 - static LogReplica create ( File folder , String fileName ) 
 + static LogReplica create ( File directory , String fileName ) 
 { 
 - return new LogReplica ( new File ( fileName ) , CLibrary . tryOpenDirectory ( folder . getPath ( ) ) ) ; 
 + return new LogReplica ( new File ( fileName ) , CLibrary . tryOpenDirectory ( directory . getPath ( ) ) ) ; 
 } 
 
 static LogReplica open ( File file ) 
 @ @ - 49 , 10 + 53 , 10 @ @ final class LogReplica 
 return new LogReplica ( file , CLibrary . tryOpenDirectory ( file . getParentFile ( ) . getPath ( ) ) ) ; 
 } 
 
 - LogReplica ( File file , int folderDescriptor ) 
 + LogReplica ( File file , int directoryDescriptor ) 
 { 
 this . file = file ; 
 - this . folderDescriptor = folderDescriptor ; 
 + this . directoryDescriptor = directoryDescriptor ; 
 } 
 
 File file ( ) 
 @ @ - 60 , 27 + 64 , 42 @ @ final class LogReplica 
 return file ; 
 } 
 
 + List < String > readLines ( ) 
 + { 
 + return FileUtils . readLines ( file ) ; 
 + } 
 + 
 + String getFileName ( ) 
 + { 
 + return file . getName ( ) ; 
 + } 
 + 
 + String getDirectory ( ) 
 + { 
 + return file . getParent ( ) ; 
 + } 
 + 
 void append ( LogRecord record ) 
 { 
 boolean existed = exists ( ) ; 
 FileUtils . appendAndSync ( file , record . toString ( ) ) ; 
 
 / / If the file did not exist before appending the first 
 - / / line , then sync the folder as well since now it must exist 
 + / / line , then sync the directory as well since now it must exist 
 if ( ! existed ) 
 - syncFolder ( ) ; 
 + syncDirectory ( ) ; 
 } 
 
 - void syncFolder ( ) 
 + void syncDirectory ( ) 
 { 
 - if ( folderDescriptor > = 0 ) 
 - CLibrary . trySync ( folderDescriptor ) ; 
 + if ( directoryDescriptor > = 0 ) 
 + CLibrary . trySync ( directoryDescriptor ) ; 
 } 
 
 void delete ( ) 
 { 
 LogTransaction . delete ( file ) ; 
 - syncFolder ( ) ; 
 + syncDirectory ( ) ; 
 } 
 
 boolean exists ( ) 
 @ @ - 90 , 10 + 109 , 10 @ @ final class LogReplica 
 
 void close ( ) 
 { 
 - if ( folderDescriptor > = 0 ) 
 + if ( directoryDescriptor > = 0 ) 
 { 
 - CLibrary . tryCloseFD ( folderDescriptor ) ; 
 - folderDescriptor = - 1 ; 
 + CLibrary . tryCloseFD ( directoryDescriptor ) ; 
 + directoryDescriptor = - 1 ; 
 } 
 } 
 
 @ @ - 102 , 4 + 121 , 31 @ @ final class LogReplica 
 { 
 return String . format ( " [ % s ] " , file ) ; 
 } 
 + 
 + void setError ( String line , String error ) 
 + { 
 + errors . put ( line , error ) ; 
 + } 
 + 
 + void printContentsWithAnyErrors ( StringBuilder str ) 
 + { 
 + str . append ( file . getPath ( ) ) ; 
 + str . append ( System . lineSeparator ( ) ) ; 
 + FileUtils . readLines ( file ) . forEach ( line - > printLineWithAnyError ( str , line ) ) ; 
 + } 
 + 
 + private void printLineWithAnyError ( StringBuilder str , String line ) 
 + { 
 + str . append ( ' \ t ' ) ; 
 + str . append ( line ) ; 
 + str . append ( System . lineSeparator ( ) ) ; 
 + 
 + String error = errors . get ( line ) ; 
 + if ( error ! = null ) 
 + { 
 + str . append ( " \ t \ t * * * " ) ; 
 + str . append ( error ) ; 
 + str . append ( System . lineSeparator ( ) ) ; 
 + } 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogReplicaSet . java b / src / java / org / apache / cassandra / db / lifecycle / LogReplicaSet . java 
 index c557bf2 . . 47a9901 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / LogReplicaSet . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / LogReplicaSet . java 
 @ @ - 32 , 7 + 32 , 6 @ @ import com . google . common . annotations . VisibleForTesting ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 - import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . utils . Throwables ; 
 
 / * * 
 @ @ - 60 , 31 + 59 , 31 @ @ public class LogReplicaSet 
 
 void addReplica ( File file ) 
 { 
 - File folder = file . getParentFile ( ) ; 
 - assert ! replicasByFile . containsKey ( folder ) ; 
 - replicasByFile . put ( folder , LogReplica . open ( file ) ) ; 
 + File directory = file . getParentFile ( ) ; 
 + assert ! replicasByFile . containsKey ( directory ) ; 
 + replicasByFile . put ( directory , LogReplica . open ( file ) ) ; 
 
 if ( logger . isTraceEnabled ( ) ) 
 logger . trace ( " Added log file replica { } " , file ) ; 
 } 
 
 - void maybeCreateReplica ( File folder , String fileName , Set < LogRecord > records ) 
 + void maybeCreateReplica ( File directory , String fileName , Set < LogRecord > records ) 
 { 
 - if ( replicasByFile . containsKey ( folder ) ) 
 + if ( replicasByFile . containsKey ( directory ) ) 
 return ; 
 
 - final LogReplica replica = LogReplica . create ( folder , fileName ) ; 
 + final LogReplica replica = LogReplica . create ( directory , fileName ) ; 
 
 records . forEach ( replica : : append ) ; 
 - replicasByFile . put ( folder , replica ) ; 
 + replicasByFile . put ( directory , replica ) ; 
 
 if ( logger . isTraceEnabled ( ) ) 
 logger . trace ( " Created new file replica { } " , replica ) ; 
 } 
 
 - Throwable syncFolder ( Throwable accumulate ) 
 + Throwable syncDirectory ( Throwable accumulate ) 
 { 
 - return Throwables . perform ( accumulate , replicas ( ) . stream ( ) . map ( s - > s : : syncFolder ) ) ; 
 + return Throwables . perform ( accumulate , replicas ( ) . stream ( ) . map ( s - > s : : syncDirectory ) ) ; 
 } 
 
 Throwable delete ( Throwable accumulate ) 
 @ @ - 101 , 15 + 100 , 18 @ @ public class LogReplicaSet 
 
 boolean readRecords ( Set < LogRecord > records ) 
 { 
 - Map < File , List < String > > linesByReplica = replicas ( ) . stream ( ) 
 - . map ( LogReplica : : file ) 
 - . collect ( Collectors . toMap ( Function . < File > identity ( ) , FileUtils : : readLines ) ) ; 
 + Map < LogReplica , List < String > > linesByReplica = replicas ( ) . stream ( ) 
 + . collect ( Collectors . toMap ( Function . < LogReplica > identity ( ) , 
 + LogReplica : : readLines , 
 + ( k , v ) - > { throw new IllegalStateException ( " Duplicated key : " + k ) ; } , 
 + LinkedHashMap : : new ) ) ; 
 + 
 int maxNumLines = linesByReplica . values ( ) . stream ( ) . map ( List : : size ) . reduce ( 0 , Integer : : max ) ; 
 for ( int i = 0 ; i < maxNumLines ; i + + ) 
 { 
 String firstLine = null ; 
 boolean partial = false ; 
 - for ( Map . Entry < File , List < String > > entry : linesByReplica . entrySet ( ) ) 
 + for ( Map . Entry < LogReplica , List < String > > entry : linesByReplica . entrySet ( ) ) 
 { 
 List < String > currentLines = entry . getValue ( ) ; 
 if ( i > = currentLines . size ( ) ) 
 @ @ - 125 , 9 + 127 , 10 @ @ public class LogReplicaSet 
 if ( ! isPrefixMatch ( firstLine , currentLine ) ) 
 { / / not a prefix match 
 logger . error ( " Mismatched line in file { } : got ' { } ' expected ' { } ' , giving up " , 
 - entry . getKey ( ) . getName ( ) , 
 + entry . getKey ( ) . getFileName ( ) , 
 currentLine , 
 firstLine ) ; 
 + entry . getKey ( ) . setError ( currentLine , String . format ( " Does not match < % s > in first replica file " , firstLine ) ) ; 
 return false ; 
 } 
 
 @ @ - 136 , 7 + 139 , 7 @ @ public class LogReplicaSet 
 if ( i = = currentLines . size ( ) - 1 ) 
 { / / last record , just set record as invalid and move on 
 logger . warn ( " Mismatched last line in file { } : ' { } ' not the same as ' { } ' " , 
 - entry . getKey ( ) . getName ( ) , 
 + entry . getKey ( ) . getFileName ( ) , 
 currentLine , 
 firstLine ) ; 
 
 @ @ - 148 , 9 + 151 , 10 @ @ public class LogReplicaSet 
 else 
 { / / mismatched entry file has more lines , giving up 
 logger . error ( " Mismatched line in file { } : got ' { } ' expected ' { } ' , giving up " , 
 - entry . getKey ( ) . getName ( ) , 
 + entry . getKey ( ) . getFileName ( ) , 
 currentLine , 
 firstLine ) ; 
 + entry . getKey ( ) . setError ( currentLine , String . format ( " Does not match < % s > in first replica file " , firstLine ) ) ; 
 return false ; 
 } 
 } 
 @ @ - 160 , 6 + 164 , 7 @ @ public class LogReplicaSet 
 if ( records . contains ( record ) ) 
 { / / duplicate records 
 logger . error ( " Found duplicate record { } for { } , giving up " , record , record . fileName ( ) ) ; 
 + setError ( record , " Duplicated record " ) ; 
 return false ; 
 } 
 
 @ @ - 171 , 6 + 176 , 7 @ @ public class LogReplicaSet 
 if ( record . isFinal ( ) & & i ! = ( maxNumLines - 1 ) ) 
 { / / too many final records 
 logger . error ( " Found too many lines for { } , giving up " , record . fileName ( ) ) ; 
 + setError ( record , " This record should have been the last one in all replicas " ) ; 
 return false ; 
 } 
 } 
 @ @ - 178 , 6 + 184 , 22 @ @ public class LogReplicaSet 
 return true ; 
 } 
 
 + void setError ( LogRecord record , String error ) 
 + { 
 + record . setError ( error ) ; 
 + setErrorInReplicas ( record ) ; 
 + } 
 + 
 + void setErrorInReplicas ( LogRecord record ) 
 + { 
 + replicas ( ) . forEach ( r - > r . setError ( record . raw , record . error ( ) ) ) ; 
 + } 
 + 
 + void printContentsWithAnyErrors ( StringBuilder str ) 
 + { 
 + replicas ( ) . forEach ( r - > r . printContentsWithAnyErrors ( str ) ) ; 
 + } 
 + 
 / * * 
 * Add the record to all the replicas : if it is a final record then we throw only if we fail to write it 
 * to all , otherwise we throw if we fail to write it to any file , see CASSANDRA - 10421 for details 
 @ @ - 216 , 6 + 238 , 11 @ @ public class LogReplicaSet 
 : " [ - ] " ; 
 } 
 
 + String getDirectories ( ) 
 + { 
 + return String . join ( " , " , replicas ( ) . stream ( ) . map ( LogReplica : : getDirectory ) . collect ( Collectors . toList ( ) ) ) ; 
 + } 
 + 
 @ VisibleForTesting 
 List < File > getFiles ( ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java b / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java 
 index ce76165 . . b441454 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java 
 @ @ - 24 , 6 + 24 , 7 @ @ import java . nio . file . NoSuchFileException ; 
 import java . util . * ; 
 import java . util . concurrent . ConcurrentLinkedQueue ; 
 import java . util . concurrent . TimeUnit ; 
 + import java . util . function . Predicate ; 
 
 import com . google . common . annotations . VisibleForTesting ; 
 import com . google . common . util . concurrent . Runnables ; 
 @ @ - 55 , 7 + 56 , 7 @ @ import org . apache . cassandra . utils . concurrent . Transactional ; 
 * IMPORTANT : The transaction must complete ( commit or abort ) before any temporary files are deleted , even though the 
 * txn log file itself will not be deleted until all tracked files are deleted . This is required by FileLister to ensure 
 * a consistent disk state . LifecycleTransaction ensures this requirement , so this class should really never be used 
 - * outside of LT . @ see FileLister . classifyFiles ( TransactionData txn ) 
 + * outside of LT . @ see LogAwareFileLister . classifyFiles ( ) 
 * 
 * A class that tracks sstable files involved in a transaction across sstables : 
 * if the transaction succeeds the old files should be deleted and the new ones kept ; vice - versa if it fails . 
 @ @ - 67 , 8 + 68 , 7 @ @ import org . apache . cassandra . utils . concurrent . Transactional ; 
 * 
 * where sstable - 2 is a new sstable to be retained if the transaction succeeds and sstable - 1 is an old sstable to be 
 * removed . CRC is an incremental CRC of the file content up to this point . For old sstable files we also log the 
 - * last update time of all files for the sstable descriptor and a checksum of vital properties such as update times 
 - * and file sizes . 
 + * last update time of all files for the sstable descriptor and the number of sstable files . 
 * 
 * Upon commit we add a final line to the log file : 
 * 
 @ @ - 238 , 27 + 238 , 29 @ @ class LogTransaction extends Transactional . AbstractTransactional implements Tran 
 public void run ( ) 
 { 
 if ( logger . isTraceEnabled ( ) ) 
 - logger . trace ( " Removing files for transaction { } " , name ( ) ) ; 
 + logger . trace ( " Removing files for transaction log { } " , data ) ; 
 
 if ( ! data . completed ( ) ) 
 { / / this happens if we forget to close a txn and the garbage collector closes it for us 
 - logger . error ( " { } was not completed , trying to abort it now " , data ) ; 
 + logger . error ( " Transaction log { } indicates txn was not completed , trying to abort it now " , data ) ; 
 Throwable err = Throwables . perform ( ( Throwable ) null , data : : abort ) ; 
 if ( err ! = null ) 
 - logger . error ( " Failed to abort { } " , data , err ) ; 
 + logger . error ( " Failed to abort transaction log { } " , data , err ) ; 
 } 
 
 Throwable err = data . removeUnfinishedLeftovers ( null ) ; 
 
 if ( err ! = null ) 
 { 
 - logger . info ( " Failed deleting files for transaction { } , we ' ll retry after GC and on on server restart " , name ( ) , err ) ; 
 + logger . info ( " Failed deleting files for transaction log { } , we ' ll retry after GC and on on server restart " , 
 + data , 
 + err ) ; 
 failedDeletions . add ( this ) ; 
 } 
 else 
 { 
 if ( logger . isTraceEnabled ( ) ) 
 - logger . trace ( " Closing file transaction { } " , name ( ) ) ; 
 + logger . trace ( " Closing transaction log { } " , data ) ; 
 
 data . close ( ) ; 
 } 
 @ @ - 360 , 7 + 362 , 7 @ @ class LogTransaction extends Transactional . AbstractTransactional implements Tran 
 } 
 catch ( Throwable t ) 
 { 
 - logger . error ( " Failed to complete file transaction { } " , id ( ) , t ) ; 
 + logger . error ( " Failed to complete file transaction id { } " , id ( ) , t ) ; 
 return Throwables . merge ( accumulate , t ) ; 
 } 
 } 
 @ @ - 378 , 31 + 380 , 43 @ @ class LogTransaction extends Transactional . AbstractTransactional implements Tran 
 protected void doPrepare ( ) { } 
 
 / * * 
 - * Called on startup to scan existing folders for any unfinished leftovers of 
 - * operations that were ongoing when the process exited . Also called by the standalone 
 - * sstableutil tool when the cleanup option is specified , @ see StandaloneSSTableUtil . 
 + * Removes any leftovers from unifinished transactions as indicated by any transaction log files that 
 + * are found in the table directories . This means that any old sstable files for transactions that were committed , 
 + * or any new sstable files for transactions that were aborted or still in progress , should be removed * if 
 + * it is safe to do so * . Refer to the checks in LogFile . verify for further details on the safety checks 
 + * before removing transaction leftovers and refer to the comments at the beginning of this file or in NEWS . txt 
 + * for further details on transaction logs . 
 + * 
 + * This method is called on startup and by the standalone sstableutil tool when the cleanup option is specified , 
 + * @ see StandaloneSSTableUtil . 
 + * 
 + * @ return true if the leftovers of all transaction logs found were removed , false otherwise . 
 * 
 * / 
 - static void removeUnfinishedLeftovers ( CFMetaData metadata ) 
 + static boolean removeUnfinishedLeftovers ( CFMetaData metadata ) 
 { 
 - removeUnfinishedLeftovers ( new Directories ( metadata ) . getCFDirectories ( ) ) ; 
 + return removeUnfinishedLeftovers ( new Directories ( metadata ) . getCFDirectories ( ) ) ; 
 } 
 
 @ VisibleForTesting 
 - static void removeUnfinishedLeftovers ( List < File > folders ) 
 + static boolean removeUnfinishedLeftovers ( List < File > directories ) 
 { 
 LogFilesByName logFiles = new LogFilesByName ( ) ; 
 - folders . forEach ( logFiles : : list ) ; 
 - logFiles . removeUnfinishedLeftovers ( ) ; 
 + directories . forEach ( logFiles : : list ) ; 
 + return logFiles . removeUnfinishedLeftovers ( ) ; 
 } 
 
 private static final class LogFilesByName 
 { 
 + / / This maps a transaction log file name to a list of physical files . Each sstable 
 + / / can have multiple directories and a transaction is trakced by identical transaction log 
 + / / files , one per directory . So for each transaction file name we can have multiple 
 + / / physical files . 
 Map < String , List < File > > files = new HashMap < > ( ) ; 
 
 - void list ( File folder ) 
 + void list ( File directory ) 
 { 
 - Arrays . stream ( folder . listFiles ( LogFile : : isLogFile ) ) . forEach ( this : : add ) ; 
 + Arrays . stream ( directory . listFiles ( LogFile : : isLogFile ) ) . forEach ( this : : add ) ; 
 } 
 
 void add ( File file ) 
 @ @ - 417 , 25 + 431 , 35 @ @ class LogTransaction extends Transactional . AbstractTransactional implements Tran 
 filesByName . add ( file ) ; 
 } 
 
 - void removeUnfinishedLeftovers ( ) 
 + boolean removeUnfinishedLeftovers ( ) 
 { 
 - files . forEach ( LogFilesByName : : removeUnfinishedLeftovers ) ; 
 + return files . entrySet ( ) 
 + . stream ( ) 
 + . map ( LogFilesByName : : removeUnfinishedLeftovers ) 
 + . allMatch ( Predicate . isEqual ( true ) ) ; 
 } 
 
 - static void removeUnfinishedLeftovers ( String name , List < File > logFiles ) 
 + static boolean removeUnfinishedLeftovers ( Map . Entry < String , List < File > > entry ) 
 { 
 - LogFile txn = LogFile . make ( name , logFiles ) ; 
 + LogFile txn = LogFile . make ( entry . getKey ( ) , entry . getValue ( ) ) ; 
 try 
 { 
 if ( txn . verify ( ) ) 
 { 
 Throwable failure = txn . removeUnfinishedLeftovers ( null ) ; 
 if ( failure ! = null ) 
 - logger . error ( " Failed to remove unfinished transaction leftovers for txn { } " , txn , failure ) ; 
 + { 
 + logger . error ( " Failed to remove unfinished transaction leftovers for transaction log { } " , 
 + txn . toString ( true ) , failure ) ; 
 + return false ; 
 + } 
 + 
 + return true ; 
 } 
 else 
 { 
 - logger . error ( " Unexpected disk state : failed to read transaction txn { } " , txn ) ; 
 + logger . error ( " Unexpected disk state : failed to read transaction log { } " , txn . toString ( true ) ) ; 
 + return false ; 
 } 
 } 
 finally 
 diff - - git a / src / java / org / apache / cassandra / exceptions / StartupException . java b / src / java / org / apache / cassandra / exceptions / StartupException . java 
 index ec4890f . . 1513cf9 100644 
 - - - a / src / java / org / apache / cassandra / exceptions / StartupException . java 
 + + + b / src / java / org / apache / cassandra / exceptions / StartupException . java 
 @ @ - 23 , 6 + 23 , 10 @ @ package org . apache . cassandra . exceptions ; 
 * / 
 public class StartupException extends Exception 
 { 
 + public final static int ERR _ WRONG _ MACHINE _ STATE = 1 ; 
 + public final static int ERR _ WRONG _ DISK _ STATE = 3 ; 
 + public final static int ERR _ WRONG _ CONFIG = 100 ; 
 + 
 public final int returnCode ; 
 
 public StartupException ( int returnCode , String message ) 
 diff - - git a / src / java / org / apache / cassandra / service / CassandraDaemon . java b / src / java / org / apache / cassandra / service / CassandraDaemon . java 
 index 183abf8 . . b84a5e3 100644 
 - - - a / src / java / org / apache / cassandra / service / CassandraDaemon . java 
 + + + b / src / java / org / apache / cassandra / service / CassandraDaemon . java 
 @ @ - 236 , 7 + 236 , 16 @ @ public class CassandraDaemon 
 continue ; 
 
 for ( CFMetaData cfm : Schema . instance . getTablesAndViews ( keyspaceName ) ) 
 - ColumnFamilyStore . scrubDataDirectories ( cfm ) ; 
 + { 
 + try 
 + { 
 + ColumnFamilyStore . scrubDataDirectories ( cfm ) ; 
 + } 
 + catch ( StartupException e ) 
 + { 
 + exitOrFail ( e . returnCode , e . getMessage ( ) , e . getCause ( ) ) ; 
 + } 
 + } 
 } 
 
 Keyspace . setInitialized ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / service / StartupChecks . java b / src / java / org / apache / cassandra / service / StartupChecks . java 
 index e903721 . . 7c6c91a 100644 
 - - - a / src / java / org / apache / cassandra / service / StartupChecks . java 
 + + + b / src / java / org / apache / cassandra / service / StartupChecks . java 
 @ @ - 134 , 8 + 134 , 9 @ @ public class StartupChecks 
 { 
 long now = System . currentTimeMillis ( ) ; 
 if ( now < EARLIEST _ LAUNCH _ DATE ) 
 - throw new StartupException ( 1 , String . format ( " current machine time is % s , but that is seemingly incorrect . exiting now . " , 
 - new Date ( now ) . toString ( ) ) ) ; 
 + throw new StartupException ( StartupException . ERR _ WRONG _ MACHINE _ STATE , 
 + String . format ( " current machine time is % s , but that is seemingly incorrect . exiting now . " , 
 + new Date ( now ) . toString ( ) ) ) ; 
 } 
 } ; 
 
 @ @ - 186 , 7 + 187 , 7 @ @ public class StartupChecks 
 { 
 / / Fail - fast if JNA is not available or failing to initialize properly 
 if ( ! CLibrary . jnaAvailable ( ) ) 
 - throw new StartupException ( 3 , " JNA failing to initialize properly . " ) ; 
 + throw new StartupException ( StartupException . ERR _ WRONG _ MACHINE _ STATE , " JNA failing to initialize properly . " ) ; 
 } 
 } ; 
 
 @ @ - 216 , 12 + 217 , 14 @ @ public class StartupChecks 
 logger . warn ( " Directory { } doesn ' t exist " , dataDir ) ; 
 / / if they don ' t , failing their creation , stop cassandra . 
 if ( ! dir . mkdirs ( ) ) 
 - throw new StartupException ( 3 , " Has no permission to create directory " + dataDir ) ; 
 + throw new StartupException ( StartupException . ERR _ WRONG _ DISK _ STATE , 
 + " Has no permission to create directory " + dataDir ) ; 
 } 
 
 / / if directories exist verify their permissions 
 if ( ! Directories . verifyFullPermissions ( dir , dataDir ) ) 
 - throw new StartupException ( 3 , " Insufficient permissions on directory " + dataDir ) ; 
 + throw new StartupException ( StartupException . ERR _ WRONG _ DISK _ STATE , 
 + " Insufficient permissions on directory " + dataDir ) ; 
 } 
 } ; 
 
 @ @ - 272 , 11 + 275 , 12 @ @ public class StartupChecks 
 } 
 
 if ( ! invalid . isEmpty ( ) ) 
 - throw new StartupException ( 3 , String . format ( " Detected unreadable sstables % s , please check " + 
 - " NEWS . txt and ensure that you have upgraded through " + 
 - " all required intermediate versions , running " + 
 - " upgradesstables " , 
 - Joiner . on ( " , " ) . join ( invalid ) ) ) ; 
 + throw new StartupException ( StartupException . ERR _ WRONG _ DISK _ STATE , 
 + String . format ( " Detected unreadable sstables % s , please check " + 
 + " NEWS . txt and ensure that you have upgraded through " + 
 + " all required intermediate versions , running " + 
 + " upgradesstables " , 
 + Joiner . on ( " , " ) . join ( invalid ) ) ) ; 
 
 } 
 } ; 
 @ @ - 318 , 7 + 322 , 7 @ @ public class StartupChecks 
 String formatMessage = " Cannot start node if snitch ' s data center ( % s ) differs from previous data center ( % s ) . " + 
 " Please fix the snitch configuration , decommission and rebootstrap this node or use the flag - Dcassandra . ignore _ dc = true . " ; 
 
 - throw new StartupException ( 100 , String . format ( formatMessage , currentDc , storedDc ) ) ; 
 + throw new StartupException ( StartupException . ERR _ WRONG _ CONFIG , String . format ( formatMessage , currentDc , storedDc ) ) ; 
 } 
 } 
 } 
 @ @ - 340 , 7 + 344 , 7 @ @ public class StartupChecks 
 String formatMessage = " Cannot start node if snitch ' s rack ( % s ) differs from previous rack ( % s ) . " + 
 " Please fix the snitch configuration , decommission and rebootstrap this node or use the flag - Dcassandra . ignore _ rack = true . " ; 
 
 - throw new StartupException ( 100 , String . format ( formatMessage , currentRack , storedRack ) ) ; 
 + throw new StartupException ( StartupException . ERR _ WRONG _ CONFIG , String . format ( formatMessage , currentRack , storedRack ) ) ; 
 } 
 } 
 } 
 diff - - git a / test / unit / org / apache / cassandra / db / lifecycle / LogTransactionTest . java b / test / unit / org / apache / cassandra / db / lifecycle / LogTransactionTest . java 
 index 4f2fc73 . . 59958bb 100644 
 - - - a / test / unit / org / apache / cassandra / db / lifecycle / LogTransactionTest . java 
 + + + b / test / unit / org / apache / cassandra / db / lifecycle / LogTransactionTest . java 
 @ @ - 519 , 7 + 519 , 7 @ @ public class LogTransactionTest extends AbstractTransactionalTest 
 LogAwareFileLister . getTemporaryFiles ( dataFolder2 ) ) ; 
 
 / / normally called at startup 
 - LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ; 
 + assertTrue ( LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ) ; 
 
 / / new tables should be only table left 
 assertFiles ( dataFolder1 . getPath ( ) , new HashSet < > ( sstables [ 1 ] . getAllFilePaths ( ) ) ) ; 
 @ @ - 570 , 7 + 570 , 7 @ @ public class LogTransactionTest extends AbstractTransactionalTest 
 LogAwareFileLister . getTemporaryFiles ( dataFolder2 ) ) ; 
 
 / / normally called at startup 
 - LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ; 
 + assertTrue ( LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ) ; 
 
 / / old tables should be only table left 
 assertFiles ( dataFolder1 . getPath ( ) , new HashSet < > ( sstables [ 0 ] . getAllFilePaths ( ) ) ) ; 
 @ @ - 735 , 7 + 735 , 8 @ @ public class LogTransactionTest extends AbstractTransactionalTest 
 
 Arrays . stream ( sstables ) . forEach ( s - > s . selfRef ( ) . release ( ) ) ; 
 
 - LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ; 
 + / / if shouldCommit is true then it should remove the leftovers and return true , false otherwise 
 + assertEquals ( shouldCommit , LogTransaction . removeUnfinishedLeftovers ( Arrays . asList ( dataFolder1 , dataFolder2 ) ) ) ; 
 LogTransaction . waitForDeletions ( ) ; 
 
 if ( shouldCommit ) 
 @ @ - 862 , 7 + 863 , 7 @ @ public class LogTransactionTest extends AbstractTransactionalTest 
 if ( filePath . endsWith ( " Data . db " ) ) 
 { 
 assertTrue ( FileUtils . delete ( filePath ) ) ; 
 - assertNull ( t . txnFile ( ) . syncFolder ( null ) ) ; 
 + assertNull ( t . txnFile ( ) . syncDirectory ( null ) ) ; 
 break ; 
 } 
 }

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 2ea901f . . 3c7163a 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 1 . 1 . 5 
 + * increase stack size under Java7 to 180K 
 * Log ( info ) schema changes ( CASSANDRA - 4547 ) 
 
 
 diff - - git a / conf / cassandra - env . sh b / conf / cassandra - env . sh 
 index 6ae28a0 . . ff3fc86 100644 
 - - - a / conf / cassandra - env . sh 
 + + + b / conf / cassandra - env . sh 
 @ @ - 186 , 7 + 186 , 7 @ @ if [ " ` uname ` " = " Linux " ] ; then 
 # supported . 
 if startswith " $ JVM _ VERSION " ' 1 . 7 . ' 
 then 
 - JVM _ OPTS = " $ JVM _ OPTS - Xss160k " 
 + JVM _ OPTS = " $ JVM _ OPTS - Xss180k " 
 else 
 JVM _ OPTS = " $ JVM _ OPTS - Xss128k " 
 fi
