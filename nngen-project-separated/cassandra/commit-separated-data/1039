BLEU SCORE: 0.016932492841722675

TEST MSG: test _ bulk _ round _ trip _ blogposts is failing occasionally
GENERATED MSG: python CQL driver result decoding

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index e3e53d8 . . 1793c32 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 1 . 13 <nl> + * test _ bulk _ round _ trip _ blogposts is failing occasionally ( CASSANDRA - 10938 ) <nl> * Fix isJoined return true only after becoming cluster member ( CASANDRA - 11007 ) <nl> * Fix bad gossip generation seen in long - running clusters ( CASSANDRA - 10969 ) <nl> * Avoid NPE when incremental repair fails ( CASSANDRA - 10909 ) <nl> diff - - git a / pylib / cqlshlib / copyutil . py b / pylib / cqlshlib / copyutil . py <nl> index b015a77 . . f9e4a85 100644 <nl> - - - a / pylib / cqlshlib / copyutil . py <nl> + + + b / pylib / cqlshlib / copyutil . py <nl> @ @ - 1106 , 7 + 1106 , 7 @ @ class ExportSession ( object ) : <nl> session . default _ timeout = export _ process . options . copy [ ' pagetimeout ' ] <nl> <nl> export _ process . printdebugmsg ( " Created connection to % s with page size % d and timeout % d seconds per page " <nl> - % ( session . hosts , session . default _ fetch _ size , session . default _ timeout ) ) <nl> + % ( cluster . contact _ points , session . default _ fetch _ size , session . default _ timeout ) ) <nl> <nl> self . cluster = cluster <nl> self . session = session <nl> @ @ - 1175 , 16 + 1175 , 20 @ @ class ExportProcess ( ChildProcess ) : <nl> token _ range , info = self . inmsg . get ( ) <nl> self . start _ request ( token _ range , info ) <nl> <nl> - def report _ error ( self , err , token _ range = None ) : <nl> + @ staticmethod <nl> + def get _ error _ message ( err , print _ traceback = False ) : <nl> if isinstance ( err , str ) : <nl> msg = err <nl> elif isinstance ( err , BaseException ) : <nl> msg = " % s - % s " % ( err . _ _ class _ _ . _ _ name _ _ , err ) <nl> - if self . debug : <nl> + if print _ traceback : <nl> traceback . print _ exc ( err ) <nl> else : <nl> msg = str ( err ) <nl> + return msg <nl> <nl> + def report _ error ( self , err , token _ range = None ) : <nl> + msg = self . get _ error _ message ( err , print _ traceback = self . debug ) <nl> self . printdebugmsg ( msg ) <nl> self . outmsg . put ( ( token _ range , Exception ( msg ) ) ) <nl> <nl> @ @ - 1193 , 48 + 1197 , 67 @ @ class ExportProcess ( ChildProcess ) : <nl> Begin querying a range by executing an async query that <nl> will later on invoke the callbacks attached in attach _ callbacks . <nl> " " " <nl> - session = self . get _ session ( info [ ' hosts ' ] ) <nl> - metadata = session . cluster . metadata . keyspaces [ self . ks ] . tables [ self . table ] <nl> - query = self . prepare _ query ( metadata . partition _ key , token _ range , info [ ' attempts ' ] ) <nl> - future = session . execute _ async ( query ) <nl> - self . attach _ callbacks ( token _ range , future , session ) <nl> + session = self . get _ session ( info [ ' hosts ' ] , token _ range ) <nl> + if session : <nl> + metadata = session . cluster . metadata . keyspaces [ self . ks ] . tables [ self . table ] <nl> + query = self . prepare _ query ( metadata . partition _ key , token _ range , info [ ' attempts ' ] ) <nl> + future = session . execute _ async ( query ) <nl> + self . attach _ callbacks ( token _ range , future , session ) <nl> <nl> def num _ requests ( self ) : <nl> return sum ( session . num _ requests ( ) for session in self . hosts _ to _ sessions . values ( ) ) <nl> <nl> - def get _ session ( self , hosts ) : <nl> + def get _ session ( self , hosts , token _ range ) : <nl> " " " <nl> - We select a host to connect to . If we have no connections to one of the hosts <nl> - yet then we select this host , else we pick the one with the smallest number <nl> - of requests . <nl> + We return a session connected to one of the hosts passed in , which are valid replicas for <nl> + the token range . We sort replicas by favouring those without any active requests yet or with the <nl> + smallest number of requests . If we fail to connect we report an error so that the token will <nl> + be retried again later . <nl> <nl> : return : An ExportSession connected to the chosen host . <nl> " " " <nl> - new _ hosts = [ h for h in hosts if h not in self . hosts _ to _ sessions ] <nl> - if new _ hosts : <nl> - host = new _ hosts [ 0 ] <nl> - new _ cluster = Cluster ( <nl> - contact _ points = ( host , ) , <nl> - port = self . port , <nl> - cql _ version = self . cql _ version , <nl> - protocol _ version = self . protocol _ version , <nl> - auth _ provider = self . auth _ provider , <nl> - ssl _ options = ssl _ settings ( host , self . config _ file ) if self . ssl else None , <nl> - load _ balancing _ policy = TokenAwarePolicy ( WhiteListRoundRobinPolicy ( hosts ) ) , <nl> - default _ retry _ policy = ExpBackoffRetryPolicy ( self ) , <nl> - compression = None , <nl> - control _ connection _ timeout = self . connect _ timeout , <nl> - connect _ timeout = self . connect _ timeout ) <nl> + # sorted replicas favouring those with no connections yet <nl> + hosts = sorted ( hosts , <nl> + key = lambda hh : 0 if hh not in self . hosts _ to _ sessions else self . hosts _ to _ sessions [ hh ] . requests ) <nl> <nl> - session = ExportSession ( new _ cluster , self ) <nl> - self . hosts _ to _ sessions [ host ] = session <nl> - return session <nl> - else : <nl> - host = min ( hosts , key = lambda hh : self . hosts _ to _ sessions [ hh ] . requests ) <nl> + errors = [ ] <nl> + ret = None <nl> + for host in hosts : <nl> + try : <nl> + ret = self . connect ( host ) <nl> + except Exception , e : <nl> + errors . append ( self . get _ error _ message ( e ) ) <nl> + <nl> + if ret : <nl> + if errors : <nl> + self . printdebugmsg ( " Warning : failed to connect to some replicas : % s " % ( errors , ) ) <nl> + return ret <nl> + <nl> + self . report _ error ( " Failed to connect to all replicas % s for % s , errors : % s " % ( hosts , token _ range , errors ) ) <nl> + return None <nl> + <nl> + def connect ( self , host ) : <nl> + if host in self . hosts _ to _ sessions . keys ( ) : <nl> session = self . hosts _ to _ sessions [ host ] <nl> session . add _ request ( ) <nl> return session <nl> <nl> + new _ cluster = Cluster ( <nl> + contact _ points = ( host , ) , <nl> + port = self . port , <nl> + cql _ version = self . cql _ version , <nl> + protocol _ version = self . protocol _ version , <nl> + auth _ provider = self . auth _ provider , <nl> + ssl _ options = ssl _ settings ( host , self . config _ file ) if self . ssl else None , <nl> + load _ balancing _ policy = WhiteListRoundRobinPolicy ( [ host ] ) , <nl> + default _ retry _ policy = ExpBackoffRetryPolicy ( self ) , <nl> + compression = None , <nl> + control _ connection _ timeout = self . connect _ timeout , <nl> + connect _ timeout = self . connect _ timeout ) <nl> + session = ExportSession ( new _ cluster , self ) <nl> + self . hosts _ to _ sessions [ host ] = session <nl> + return session <nl> + <nl> def attach _ callbacks ( self , token _ range , future , session ) : <nl> def result _ callback ( rows ) : <nl> if future . has _ more _ pages : <nl> diff - - git a / src / java / org / apache / cassandra / transport / ServerConnection . java b / src / java / org / apache / cassandra / transport / ServerConnection . java <nl> index 5991b33 . . ce4d164 100644 <nl> - - - a / src / java / org / apache / cassandra / transport / ServerConnection . java <nl> + + + b / src / java / org / apache / cassandra / transport / ServerConnection . java <nl> @ @ - 17 , 6 + 17 , 7 @ @ <nl> * / <nl> package org . apache . cassandra . transport ; <nl> <nl> + import java . util . concurrent . ConcurrentHashMap ; <nl> import java . util . concurrent . ConcurrentMap ; <nl> <nl> import io . netty . channel . Channel ; <nl> @ @ - 28 , 8 + 29 , 6 @ @ import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . service . ClientState ; <nl> import org . apache . cassandra . service . QueryState ; <nl> <nl> - import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; <nl> - <nl> public class ServerConnection extends Connection <nl> { <nl> private enum State { UNINITIALIZED , AUTHENTICATION , READY } <nl> @ @ - 38 , 7 + 37 , 7 @ @ public class ServerConnection extends Connection <nl> private final ClientState clientState ; <nl> private volatile State state ; <nl> <nl> - private final ConcurrentMap < Integer , QueryState > queryStates = new NonBlockingHashMap < > ( ) ; <nl> + private final ConcurrentMap < Integer , QueryState > queryStates = new ConcurrentHashMap < > ( ) ; <nl> <nl> public ServerConnection ( Channel channel , int version , Connection . Tracker tracker ) <nl> {
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 7cfd8ac . . 649c843 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 12 , 6 + 12 , 8 @ @ <nl> * validate index names for \ w + ( CASSANDRA - 2196 ) <nl> * Fix Cassandra cli to respect timeout if schema does not settle ( CASSANDRA - 2187 ) <nl> * update memtable _ throughput to be a long ( CASSANDRA - 2158 ) <nl> + * fix for cleanup writing old - format data into new - version sstable <nl> + ( CASSANRDRA - 2211 ) <nl> <nl> <nl> 0 . 7 . 2 <nl> diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> index b730b9c . . 8ded7e9 100644 <nl> - - - a / src / java / org / apache / cassandra / db / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> @ @ - 41 , 9 + 41 , 7 @ @ import org . slf4j . LoggerFactory ; <nl> import org . apache . cassandra . concurrent . DebuggableThreadPoolExecutor ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . dht . Range ; <nl> - import org . apache . cassandra . io . AbstractCompactedRow ; <nl> - import org . apache . cassandra . io . CompactionIterator ; <nl> - import org . apache . cassandra . io . ICompactionInfo ; <nl> + import org . apache . cassandra . io . * ; <nl> import org . apache . cassandra . io . sstable . * ; <nl> import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . service . AntiEntropyService ; <nl> @ @ - 119 , 7 + 117 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> Collections . sort ( sstables ) ; <nl> int gcBefore = cfs . isIndex ( ) <nl> ? Integer . MAX _ VALUE <nl> - : ( int ) ( System . currentTimeMillis ( ) / 1000 ) - cfs . metadata . getGcGraceSeconds ( ) ; <nl> + : getDefaultGcBefore ( cfs ) ; <nl> return doCompaction ( cfs , <nl> sstables . subList ( 0 , Math . min ( sstables . size ( ) , maxThreshold ) ) , <nl> gcBefore ) ; <nl> @ @ - 183 , 7 + 181 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> <nl> public void performMajor ( final ColumnFamilyStore cfStore ) throws InterruptedException , ExecutionException <nl> { <nl> - submitMajor ( cfStore , 0 , ( int ) ( System . currentTimeMillis ( ) / 1000 ) - cfStore . metadata . getGcGraceSeconds ( ) ) . get ( ) ; <nl> + submitMajor ( cfStore , 0 , getDefaultGcBefore ( cfStore ) ) . get ( ) ; <nl> } <nl> <nl> public Future < Object > submitMajor ( final ColumnFamilyStore cfStore , final long skip , final int gcBefore ) <nl> @ @ - 256 , 7 + 254 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> } <nl> <nl> ColumnFamilyStore cfs = Table . open ( ksname ) . getColumnFamilyStore ( cfname ) ; <nl> - submitUserDefined ( cfs , descriptors , ( int ) ( System . currentTimeMillis ( ) / 1000 ) - cfs . metadata . getGcGraceSeconds ( ) ) ; <nl> + submitUserDefined ( cfs , descriptors , getDefaultGcBefore ( cfs ) ) ; <nl> } <nl> <nl> private Future < Object > submitUserDefined ( final ColumnFamilyStore cfs , final Collection < Descriptor > dataFiles , final int gcBefore ) <nl> @ @ - 515 , 7 + 513 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> if ( Range . isTokenInRanges ( row . getKey ( ) . token , ranges ) ) <nl> { <nl> writer = maybeCreateWriter ( cfs , compactionFileLocation , expectedBloomFilterSize , writer ) ; <nl> - writer . append ( new EchoedRow ( row ) ) ; <nl> + writer . append ( getCompactedRow ( row , cfs , sstable . descriptor ) ) ; <nl> totalkeysWritten + + ; <nl> } <nl> else <nl> @ @ - 568 , 6 + 566 , 21 @ @ public class CompactionManager implements CompactionManagerMBean <nl> } <nl> } <nl> <nl> + / * * <nl> + * @ return an AbstractCompactedRow implementation to write the row in question . <nl> + * If the data is from a current - version sstable , write it unchanged . Otherwise , <nl> + * re - serialize it in the latest version . <nl> + * / <nl> + private AbstractCompactedRow getCompactedRow ( SSTableIdentityIterator row , ColumnFamilyStore cfs , Descriptor descriptor ) <nl> + { <nl> + if ( descriptor . isLatestVersion ) <nl> + return new EchoedRow ( row ) ; <nl> + <nl> + return row . dataSize > DatabaseDescriptor . getInMemoryCompactionLimit ( ) <nl> + ? new LazilyCompactedRow ( cfs , Arrays . asList ( row ) , false , getDefaultGcBefore ( cfs ) ) <nl> + : new PrecompactedRow ( cfs , Arrays . asList ( row ) , false , getDefaultGcBefore ( cfs ) ) ; <nl> + } <nl> + <nl> private SSTableWriter maybeCreateWriter ( ColumnFamilyStore cfs , String compactionFileLocation , int expectedBloomFilterSize , SSTableWriter writer ) <nl> throws IOException <nl> { <nl> @ @ - 752 , 11 + 765 , 16 @ @ public class CompactionManager implements CompactionManagerMBean <nl> return executor . submit ( runnable ) ; <nl> } <nl> <nl> + private static int getDefaultGcBefore ( ColumnFamilyStore cfs ) <nl> + { <nl> + return ( int ) ( System . currentTimeMillis ( ) / 1000 ) - cfs . metadata . getGcGraceSeconds ( ) ; <nl> + } <nl> + <nl> private static class ValidationCompactionIterator extends CompactionIterator <nl> { <nl> public ValidationCompactionIterator ( ColumnFamilyStore cfs ) throws IOException <nl> { <nl> - super ( cfs , cfs . getSSTables ( ) , ( int ) ( System . currentTimeMillis ( ) / 1000 ) - cfs . metadata . getGcGraceSeconds ( ) , true ) ; <nl> + super ( cfs , cfs . getSSTables ( ) , getDefaultGcBefore ( cfs ) , true ) ; <nl> } <nl> <nl> @ Override

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index e3e53d8 . . 1793c32 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 1 . 13 
 + * test _ bulk _ round _ trip _ blogposts is failing occasionally ( CASSANDRA - 10938 ) 
 * Fix isJoined return true only after becoming cluster member ( CASANDRA - 11007 ) 
 * Fix bad gossip generation seen in long - running clusters ( CASSANDRA - 10969 ) 
 * Avoid NPE when incremental repair fails ( CASSANDRA - 10909 ) 
 diff - - git a / pylib / cqlshlib / copyutil . py b / pylib / cqlshlib / copyutil . py 
 index b015a77 . . f9e4a85 100644 
 - - - a / pylib / cqlshlib / copyutil . py 
 + + + b / pylib / cqlshlib / copyutil . py 
 @ @ - 1106 , 7 + 1106 , 7 @ @ class ExportSession ( object ) : 
 session . default _ timeout = export _ process . options . copy [ ' pagetimeout ' ] 
 
 export _ process . printdebugmsg ( " Created connection to % s with page size % d and timeout % d seconds per page " 
 - % ( session . hosts , session . default _ fetch _ size , session . default _ timeout ) ) 
 + % ( cluster . contact _ points , session . default _ fetch _ size , session . default _ timeout ) ) 
 
 self . cluster = cluster 
 self . session = session 
 @ @ - 1175 , 16 + 1175 , 20 @ @ class ExportProcess ( ChildProcess ) : 
 token _ range , info = self . inmsg . get ( ) 
 self . start _ request ( token _ range , info ) 
 
 - def report _ error ( self , err , token _ range = None ) : 
 + @ staticmethod 
 + def get _ error _ message ( err , print _ traceback = False ) : 
 if isinstance ( err , str ) : 
 msg = err 
 elif isinstance ( err , BaseException ) : 
 msg = " % s - % s " % ( err . _ _ class _ _ . _ _ name _ _ , err ) 
 - if self . debug : 
 + if print _ traceback : 
 traceback . print _ exc ( err ) 
 else : 
 msg = str ( err ) 
 + return msg 
 
 + def report _ error ( self , err , token _ range = None ) : 
 + msg = self . get _ error _ message ( err , print _ traceback = self . debug ) 
 self . printdebugmsg ( msg ) 
 self . outmsg . put ( ( token _ range , Exception ( msg ) ) ) 
 
 @ @ - 1193 , 48 + 1197 , 67 @ @ class ExportProcess ( ChildProcess ) : 
 Begin querying a range by executing an async query that 
 will later on invoke the callbacks attached in attach _ callbacks . 
 " " " 
 - session = self . get _ session ( info [ ' hosts ' ] ) 
 - metadata = session . cluster . metadata . keyspaces [ self . ks ] . tables [ self . table ] 
 - query = self . prepare _ query ( metadata . partition _ key , token _ range , info [ ' attempts ' ] ) 
 - future = session . execute _ async ( query ) 
 - self . attach _ callbacks ( token _ range , future , session ) 
 + session = self . get _ session ( info [ ' hosts ' ] , token _ range ) 
 + if session : 
 + metadata = session . cluster . metadata . keyspaces [ self . ks ] . tables [ self . table ] 
 + query = self . prepare _ query ( metadata . partition _ key , token _ range , info [ ' attempts ' ] ) 
 + future = session . execute _ async ( query ) 
 + self . attach _ callbacks ( token _ range , future , session ) 
 
 def num _ requests ( self ) : 
 return sum ( session . num _ requests ( ) for session in self . hosts _ to _ sessions . values ( ) ) 
 
 - def get _ session ( self , hosts ) : 
 + def get _ session ( self , hosts , token _ range ) : 
 " " " 
 - We select a host to connect to . If we have no connections to one of the hosts 
 - yet then we select this host , else we pick the one with the smallest number 
 - of requests . 
 + We return a session connected to one of the hosts passed in , which are valid replicas for 
 + the token range . We sort replicas by favouring those without any active requests yet or with the 
 + smallest number of requests . If we fail to connect we report an error so that the token will 
 + be retried again later . 
 
 : return : An ExportSession connected to the chosen host . 
 " " " 
 - new _ hosts = [ h for h in hosts if h not in self . hosts _ to _ sessions ] 
 - if new _ hosts : 
 - host = new _ hosts [ 0 ] 
 - new _ cluster = Cluster ( 
 - contact _ points = ( host , ) , 
 - port = self . port , 
 - cql _ version = self . cql _ version , 
 - protocol _ version = self . protocol _ version , 
 - auth _ provider = self . auth _ provider , 
 - ssl _ options = ssl _ settings ( host , self . config _ file ) if self . ssl else None , 
 - load _ balancing _ policy = TokenAwarePolicy ( WhiteListRoundRobinPolicy ( hosts ) ) , 
 - default _ retry _ policy = ExpBackoffRetryPolicy ( self ) , 
 - compression = None , 
 - control _ connection _ timeout = self . connect _ timeout , 
 - connect _ timeout = self . connect _ timeout ) 
 + # sorted replicas favouring those with no connections yet 
 + hosts = sorted ( hosts , 
 + key = lambda hh : 0 if hh not in self . hosts _ to _ sessions else self . hosts _ to _ sessions [ hh ] . requests ) 
 
 - session = ExportSession ( new _ cluster , self ) 
 - self . hosts _ to _ sessions [ host ] = session 
 - return session 
 - else : 
 - host = min ( hosts , key = lambda hh : self . hosts _ to _ sessions [ hh ] . requests ) 
 + errors = [ ] 
 + ret = None 
 + for host in hosts : 
 + try : 
 + ret = self . connect ( host ) 
 + except Exception , e : 
 + errors . append ( self . get _ error _ message ( e ) ) 
 + 
 + if ret : 
 + if errors : 
 + self . printdebugmsg ( " Warning : failed to connect to some replicas : % s " % ( errors , ) ) 
 + return ret 
 + 
 + self . report _ error ( " Failed to connect to all replicas % s for % s , errors : % s " % ( hosts , token _ range , errors ) ) 
 + return None 
 + 
 + def connect ( self , host ) : 
 + if host in self . hosts _ to _ sessions . keys ( ) : 
 session = self . hosts _ to _ sessions [ host ] 
 session . add _ request ( ) 
 return session 
 
 + new _ cluster = Cluster ( 
 + contact _ points = ( host , ) , 
 + port = self . port , 
 + cql _ version = self . cql _ version , 
 + protocol _ version = self . protocol _ version , 
 + auth _ provider = self . auth _ provider , 
 + ssl _ options = ssl _ settings ( host , self . config _ file ) if self . ssl else None , 
 + load _ balancing _ policy = WhiteListRoundRobinPolicy ( [ host ] ) , 
 + default _ retry _ policy = ExpBackoffRetryPolicy ( self ) , 
 + compression = None , 
 + control _ connection _ timeout = self . connect _ timeout , 
 + connect _ timeout = self . connect _ timeout ) 
 + session = ExportSession ( new _ cluster , self ) 
 + self . hosts _ to _ sessions [ host ] = session 
 + return session 
 + 
 def attach _ callbacks ( self , token _ range , future , session ) : 
 def result _ callback ( rows ) : 
 if future . has _ more _ pages : 
 diff - - git a / src / java / org / apache / cassandra / transport / ServerConnection . java b / src / java / org / apache / cassandra / transport / ServerConnection . java 
 index 5991b33 . . ce4d164 100644 
 - - - a / src / java / org / apache / cassandra / transport / ServerConnection . java 
 + + + b / src / java / org / apache / cassandra / transport / ServerConnection . java 
 @ @ - 17 , 6 + 17 , 7 @ @ 
 * / 
 package org . apache . cassandra . transport ; 
 
 + import java . util . concurrent . ConcurrentHashMap ; 
 import java . util . concurrent . ConcurrentMap ; 
 
 import io . netty . channel . Channel ; 
 @ @ - 28 , 8 + 29 , 6 @ @ import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . service . ClientState ; 
 import org . apache . cassandra . service . QueryState ; 
 
 - import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; 
 - 
 public class ServerConnection extends Connection 
 { 
 private enum State { UNINITIALIZED , AUTHENTICATION , READY } 
 @ @ - 38 , 7 + 37 , 7 @ @ public class ServerConnection extends Connection 
 private final ClientState clientState ; 
 private volatile State state ; 
 
 - private final ConcurrentMap < Integer , QueryState > queryStates = new NonBlockingHashMap < > ( ) ; 
 + private final ConcurrentMap < Integer , QueryState > queryStates = new ConcurrentHashMap < > ( ) ; 
 
 public ServerConnection ( Channel channel , int version , Connection . Tracker tracker ) 
 {

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 7cfd8ac . . 649c843 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 12 , 6 + 12 , 8 @ @ 
 * validate index names for \ w + ( CASSANDRA - 2196 ) 
 * Fix Cassandra cli to respect timeout if schema does not settle ( CASSANDRA - 2187 ) 
 * update memtable _ throughput to be a long ( CASSANDRA - 2158 ) 
 + * fix for cleanup writing old - format data into new - version sstable 
 + ( CASSANRDRA - 2211 ) 
 
 
 0 . 7 . 2 
 diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java 
 index b730b9c . . 8ded7e9 100644 
 - - - a / src / java / org / apache / cassandra / db / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / CompactionManager . java 
 @ @ - 41 , 9 + 41 , 7 @ @ import org . slf4j . LoggerFactory ; 
 import org . apache . cassandra . concurrent . DebuggableThreadPoolExecutor ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . dht . Range ; 
 - import org . apache . cassandra . io . AbstractCompactedRow ; 
 - import org . apache . cassandra . io . CompactionIterator ; 
 - import org . apache . cassandra . io . ICompactionInfo ; 
 + import org . apache . cassandra . io . * ; 
 import org . apache . cassandra . io . sstable . * ; 
 import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . service . AntiEntropyService ; 
 @ @ - 119 , 7 + 117 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 Collections . sort ( sstables ) ; 
 int gcBefore = cfs . isIndex ( ) 
 ? Integer . MAX _ VALUE 
 - : ( int ) ( System . currentTimeMillis ( ) / 1000 ) - cfs . metadata . getGcGraceSeconds ( ) ; 
 + : getDefaultGcBefore ( cfs ) ; 
 return doCompaction ( cfs , 
 sstables . subList ( 0 , Math . min ( sstables . size ( ) , maxThreshold ) ) , 
 gcBefore ) ; 
 @ @ - 183 , 7 + 181 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 
 public void performMajor ( final ColumnFamilyStore cfStore ) throws InterruptedException , ExecutionException 
 { 
 - submitMajor ( cfStore , 0 , ( int ) ( System . currentTimeMillis ( ) / 1000 ) - cfStore . metadata . getGcGraceSeconds ( ) ) . get ( ) ; 
 + submitMajor ( cfStore , 0 , getDefaultGcBefore ( cfStore ) ) . get ( ) ; 
 } 
 
 public Future < Object > submitMajor ( final ColumnFamilyStore cfStore , final long skip , final int gcBefore ) 
 @ @ - 256 , 7 + 254 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 } 
 
 ColumnFamilyStore cfs = Table . open ( ksname ) . getColumnFamilyStore ( cfname ) ; 
 - submitUserDefined ( cfs , descriptors , ( int ) ( System . currentTimeMillis ( ) / 1000 ) - cfs . metadata . getGcGraceSeconds ( ) ) ; 
 + submitUserDefined ( cfs , descriptors , getDefaultGcBefore ( cfs ) ) ; 
 } 
 
 private Future < Object > submitUserDefined ( final ColumnFamilyStore cfs , final Collection < Descriptor > dataFiles , final int gcBefore ) 
 @ @ - 515 , 7 + 513 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 if ( Range . isTokenInRanges ( row . getKey ( ) . token , ranges ) ) 
 { 
 writer = maybeCreateWriter ( cfs , compactionFileLocation , expectedBloomFilterSize , writer ) ; 
 - writer . append ( new EchoedRow ( row ) ) ; 
 + writer . append ( getCompactedRow ( row , cfs , sstable . descriptor ) ) ; 
 totalkeysWritten + + ; 
 } 
 else 
 @ @ - 568 , 6 + 566 , 21 @ @ public class CompactionManager implements CompactionManagerMBean 
 } 
 } 
 
 + / * * 
 + * @ return an AbstractCompactedRow implementation to write the row in question . 
 + * If the data is from a current - version sstable , write it unchanged . Otherwise , 
 + * re - serialize it in the latest version . 
 + * / 
 + private AbstractCompactedRow getCompactedRow ( SSTableIdentityIterator row , ColumnFamilyStore cfs , Descriptor descriptor ) 
 + { 
 + if ( descriptor . isLatestVersion ) 
 + return new EchoedRow ( row ) ; 
 + 
 + return row . dataSize > DatabaseDescriptor . getInMemoryCompactionLimit ( ) 
 + ? new LazilyCompactedRow ( cfs , Arrays . asList ( row ) , false , getDefaultGcBefore ( cfs ) ) 
 + : new PrecompactedRow ( cfs , Arrays . asList ( row ) , false , getDefaultGcBefore ( cfs ) ) ; 
 + } 
 + 
 private SSTableWriter maybeCreateWriter ( ColumnFamilyStore cfs , String compactionFileLocation , int expectedBloomFilterSize , SSTableWriter writer ) 
 throws IOException 
 { 
 @ @ - 752 , 11 + 765 , 16 @ @ public class CompactionManager implements CompactionManagerMBean 
 return executor . submit ( runnable ) ; 
 } 
 
 + private static int getDefaultGcBefore ( ColumnFamilyStore cfs ) 
 + { 
 + return ( int ) ( System . currentTimeMillis ( ) / 1000 ) - cfs . metadata . getGcGraceSeconds ( ) ; 
 + } 
 + 
 private static class ValidationCompactionIterator extends CompactionIterator 
 { 
 public ValidationCompactionIterator ( ColumnFamilyStore cfs ) throws IOException 
 { 
 - super ( cfs , cfs . getSSTables ( ) , ( int ) ( System . currentTimeMillis ( ) / 1000 ) - cfs . metadata . getGcGraceSeconds ( ) , true ) ; 
 + super ( cfs , cfs . getSSTables ( ) , getDefaultGcBefore ( cfs ) , true ) ; 
 } 
 
 @ Override
