BLEU SCORE: 0.13950796967929133

TEST MSG: Fix cassandra - stress user - mode truncation of partition generation
GENERATED MSG: cassandra - stress simultaneous inserts over same seed

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 8f71269 . . 0c2bab8 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 1 . 3 <nl> + * Fix cassandra - stress user - mode truncation of partition generation ( CASSANDRA - 8608 ) <nl> * Only stream from unrepaired sstables during inc repair ( CASSANDRA - 8267 ) <nl> * Don ' t allow starting multiple inc repairs on the same sstables ( CASSANDRA - 8316 ) <nl> * Invalidate prepared BATCH statements when related tables <nl> diff - - git a / tools / stress / src / org / apache / cassandra / stress / Operation . java b / tools / stress / src / org / apache / cassandra / stress / Operation . java <nl> index edf3a54 . . 05045f8 100644 <nl> - - - a / tools / stress / src / org / apache / cassandra / stress / Operation . java <nl> + + + b / tools / stress / src / org / apache / cassandra / stress / Operation . java <nl> @ @ - 105 , 9 + 105 , 9 @ @ public abstract class Operation <nl> break ; <nl> <nl> if ( spec . useRatio = = null ) <nl> - success = partitionCache . get ( i ) . reset ( seed , spec . targetCount , this ) ; <nl> + success = partitionCache . get ( i ) . reset ( seed , spec . targetCount , isWrite ( ) ) ; <nl> else <nl> - success = partitionCache . get ( i ) . reset ( seed , spec . useRatio . next ( ) , this ) ; <nl> + success = partitionCache . get ( i ) . reset ( seed , spec . useRatio . next ( ) , isWrite ( ) ) ; <nl> } <nl> } <nl> partitionCount = i ; <nl> diff - - git a / tools / stress / src / org / apache / cassandra / stress / generate / PartitionIterator . java b / tools / stress / src / org / apache / cassandra / stress / generate / PartitionIterator . java <nl> index 0d0cba1 . . 0466edb 100644 <nl> - - - a / tools / stress / src / org / apache / cassandra / stress / generate / PartitionIterator . java <nl> + + + b / tools / stress / src / org / apache / cassandra / stress / generate / PartitionIterator . java <nl> @ @ - 50 , 14 + 50 , 16 @ @ import org . apache . cassandra . stress . generate . values . Generator ; <nl> public abstract class PartitionIterator implements Iterator < Row > <nl> { <nl> <nl> - / / we reuse the row object to save garbage <nl> - abstract boolean reset ( double useChance , int targetCount , Operation op ) ; <nl> + abstract boolean reset ( double useChance , int targetCount , boolean isWrite ) ; <nl> <nl> long idseed ; <nl> Seed seed ; <nl> - final Object [ ] partitionKey ; <nl> + <nl> final PartitionGenerator generator ; <nl> final SeedManager seedManager ; <nl> + <nl> + / / we reuse these objects to save garbage <nl> + final Object [ ] partitionKey ; <nl> final Row row ; <nl> <nl> public static PartitionIterator get ( PartitionGenerator generator , SeedManager seedManager ) <nl> @ @ - 93 , 16 + 95 , 16 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> this . idseed = idseed ; <nl> } <nl> <nl> - public boolean reset ( Seed seed , double useChance , Operation op ) <nl> + public boolean reset ( Seed seed , double useChance , boolean isWrite ) <nl> { <nl> setSeed ( seed ) ; <nl> - return reset ( useChance , 0 , op ) ; <nl> + return reset ( useChance , 0 , isWrite ) ; <nl> } <nl> <nl> - public boolean reset ( Seed seed , int targetCount , Operation op ) <nl> + public boolean reset ( Seed seed , int targetCount , boolean isWrite ) <nl> { <nl> setSeed ( seed ) ; <nl> - return reset ( Double . NaN , targetCount , op ) ; <nl> + return reset ( Double . NaN , targetCount , isWrite ) ; <nl> } <nl> <nl> static class SingleRowIterator extends PartitionIterator <nl> @ @ - 115 , 10 + 117 , 10 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> super ( generator , seedManager ) ; <nl> } <nl> <nl> - boolean reset ( double useChance , int targetCount , Operation op ) <nl> + boolean reset ( double useChance , int targetCount , boolean isWrite ) <nl> { <nl> done = false ; <nl> - isWrite = op . isWrite ( ) ; <nl> + this . isWrite = isWrite ; <nl> return true ; <nl> } <nl> <nl> @ @ - 155 , 24 + 157 , 22 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> / / TODO : support first / last row , and constraining reads to rows we know are populated <nl> static class MultiRowIterator extends PartitionIterator <nl> { <nl> - <nl> - / / probability any single row will be generated in this iteration <nl> - double useChance ; <nl> - <nl> / / the seed used to generate the current values for the clustering components at each depth ; <nl> / / used to save recalculating it for each row , so we only need to recalc from prior row . <nl> final long [ ] clusteringSeeds = new long [ generator . clusteringComponents . size ( ) ] ; <nl> / / the components remaining to be visited for each level of the current stack <nl> final Deque < Object > [ ] clusteringComponents = new ArrayDeque [ generator . clusteringComponents . size ( ) ] ; <nl> <nl> + / / probability any single row will be generated in this iteration <nl> + double useChance ; <nl> / / we want our chance of selection to be applied uniformly , so we compound the roll we make at each level <nl> / / so that we know with what chance we reached there , and we adjust our roll at that level by that amount <nl> final double [ ] chancemodifier = new double [ generator . clusteringComponents . size ( ) ] ; <nl> final double [ ] rollmodifier = new double [ generator . clusteringComponents . size ( ) ] ; <nl> <nl> / / track where in the partition we are , and where we are limited to <nl> - final int [ ] position = new int [ generator . clusteringComponents . size ( ) ] ; <nl> - final int [ ] limit = new int [ position . length ] ; <nl> + final int [ ] currentRow = new int [ generator . clusteringComponents . size ( ) ] ; <nl> + final int [ ] lastRow = new int [ currentRow . length ] ; <nl> boolean hasNext , isFirstWrite , isWrite ; <nl> <nl> / / reusable collections for generating unique and sorted clustering components <nl> @ @ - 188 , 10 + 188 , 22 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> chancemodifier [ 0 ] = generator . clusteringDescendantAverages [ 0 ] ; <nl> } <nl> <nl> - / / if we ' re a write , the expected behaviour is that the requested batch count is compounded with the seed ' s visit <nl> - / / count to decide how much we should return in one iteration <nl> - boolean reset ( double useChance , int targetCount , Operation op ) <nl> + / * * <nl> + * initialise the iterator state <nl> + * <nl> + * if we ' re a write , the expected behaviour is that the requested <nl> + * batch count is compounded with the seed ' s visit count to decide <nl> + * how much we should return in one iteration <nl> + * <nl> + * @ param useChance uniform chance of visiting any single row ( NaN if targetCount provided ) <nl> + * @ param targetCount number of rows we would like to visit ( 0 if useChance provided ) <nl> + * @ param isWrite true if the action requires write semantics <nl> + * <nl> + * @ return true if there is data to return , false otherwise <nl> + * / <nl> + boolean reset ( double useChance , int targetCount , boolean isWrite ) <nl> { <nl> + this . isWrite = isWrite ; <nl> if ( this . useChance < 1d ) <nl> { <nl> / / we clear our prior roll - modifiers if the use chance was previously less - than zero <nl> @ @ - 207 , 14 + 219 , 13 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> int expectedRowCount ; <nl> <nl> int position = seed . position ( ) ; <nl> - isWrite = op . isWrite ( ) ; <nl> <nl> if ( isWrite ) <nl> expectedRowCount = firstComponentCount * generator . clusteringDescendantAverages [ 0 ] ; <nl> else if ( position ! = 0 ) <nl> - expectedRowCount = setLimit ( position ) ; <nl> + expectedRowCount = setLastRow ( position - 1 ) ; <nl> else <nl> - expectedRowCount = setNoLimit ( firstComponentCount ) ; <nl> + expectedRowCount = setNoLastRow ( firstComponentCount ) ; <nl> <nl> if ( Double . isNaN ( useChance ) ) <nl> useChance = Math . max ( 0d , Math . min ( 1d , targetCount / ( double ) expectedRowCount ) ) ; <nl> @ @ - 222 , 38 + 233 , 84 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> <nl> while ( true ) <nl> { <nl> - / / TODO : we could avoid repopulating these each loop , by tracking our prior position <nl> + / / we loop in case we have picked an entirely non - existent range , in which case <nl> + / / we will reset the seed ' s position , then try again ( until we exhaust it or find <nl> + / / some real range ) <nl> + <nl> for ( Queue < ? > q : clusteringComponents ) <nl> q . clear ( ) ; <nl> clusteringSeeds [ 0 ] = idseed ; <nl> fill ( clusteringComponents [ 0 ] , firstComponentCount , generator . clusteringComponents . get ( 0 ) ) ; <nl> <nl> - / / we loop in case we have picked an entirely non - existent range , in which case <nl> - / / we will reset the seed ' s position , then try again ( until we exhaust it or find <nl> - / / some real range ) - this only happens for writes , so we only keep this logic in the loop <nl> - <nl> - if ( isWrite ) <nl> + if ( ! isWrite ) <nl> { <nl> - position = seed . moveForwards ( Math . max ( 1 , expectedRowCount / seed . visits ) ) ; <nl> - isFirstWrite = position = = 0 ; <nl> + if ( seek ( 0 ) ! = State . SUCCESS ) <nl> + throw new IllegalStateException ( ) ; <nl> + return true ; <nl> } <nl> <nl> + <nl> + int count = Math . max ( 1 , expectedRowCount / seed . visits ) ; <nl> + position = seed . moveForwards ( count ) ; <nl> + isFirstWrite = position = = 0 ; <nl> + setLastRow ( position + count - 1 ) ; <nl> + <nl> / / seek to our start position <nl> - switch ( seek ( isWrite ? position : 0 ) ) <nl> + switch ( seek ( position ) ) <nl> { <nl> case END _ OF _ PARTITION : <nl> return false ; <nl> case SUCCESS : <nl> return true ; <nl> } <nl> + } <nl> + } <nl> <nl> - if ( ! isWrite ) <nl> - throw new IllegalStateException ( ) ; <nl> + / / returns expected row count <nl> + private int setNoLastRow ( int firstComponentCount ) <nl> + { <nl> + Arrays . fill ( lastRow , Integer . MAX _ VALUE ) ; <nl> + return firstComponentCount * generator . clusteringDescendantAverages [ 0 ] ; <nl> + } <nl> <nl> - / / TODO : recompose our real position into the nearest scalar position , and ensure the seed position is > = this <nl> + / / sets the last row we will visit <nl> + / / returns expected distance from zero <nl> + private int setLastRow ( int position ) <nl> + { <nl> + if ( position < 0 ) <nl> + throw new IllegalStateException ( ) ; <nl> + <nl> + decompose ( position , lastRow ) ; <nl> + int expectedRowCount = 0 ; <nl> + for ( int i = 0 ; i < lastRow . length ; i + + ) <nl> + { <nl> + int l = lastRow [ i ] ; <nl> + expectedRowCount + = l * generator . clusteringDescendantAverages [ i ] ; <nl> } <nl> + return expectedRowCount + 1 ; <nl> } <nl> <nl> + / / returns 0 if we are currently on the last row we are allocated to visit ; 1 if it is after , - 1 if it is before <nl> + / / this is defined by _ limit _ , which is wired up from expected ( mean ) row counts <nl> + / / the last row is where position = = lastRow , except the last index is 1 less ; <nl> + / / OR if that row does not exist , it is the last row prior to it <nl> + private int compareToLastRow ( int depth ) <nl> + { <nl> + for ( int i = 0 ; i < = depth ; i + + ) <nl> + { <nl> + int p = currentRow [ i ] , l = lastRow [ i ] , r = clusteringComponents [ i ] . size ( ) ; <nl> + if ( ( p = = l ) | ( r = = 1 ) ) <nl> + continue ; <nl> + return p - l ; <nl> + } <nl> + return 0 ; <nl> + } <nl> + <nl> + / * * <nl> + * Translate the scalar position into a tiered position based on mean expected counts <nl> + * @ param scalar scalar position <nl> + * @ param decomposed target container <nl> + * / <nl> private void decompose ( int scalar , int [ ] decomposed ) <nl> { <nl> for ( int i = 0 ; i < decomposed . length ; i + + ) <nl> @ @ - 262 , 7 + 319 , 7 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> decomposed [ i ] = scalar / avg ; <nl> scalar % = avg ; <nl> } <nl> - for ( int i = limit . length - 1 ; i > 0 ; i - - ) <nl> + for ( int i = lastRow . length - 1 ; i > 0 ; i - - ) <nl> { <nl> int avg = generator . clusteringComponentAverages [ i ] ; <nl> if ( decomposed [ i ] > = avg ) <nl> @ @ - 273 , 42 + 330 , 28 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> } <nl> } <nl> <nl> - private int setNoLimit ( int firstComponentCount ) <nl> - { <nl> - Arrays . fill ( limit , Integer . MAX _ VALUE ) ; <nl> - return firstComponentCount * generator . clusteringDescendantAverages [ 0 ] ; <nl> - } <nl> - <nl> - private int setLimit ( int position ) <nl> - { <nl> - decompose ( position , limit ) ; <nl> - int expectedRowCount = 0 ; <nl> - for ( int i = 0 ; i < limit . length ; i + + ) <nl> - { <nl> - int l = limit [ i ] ; <nl> - expectedRowCount + = l * generator . clusteringDescendantAverages [ i ] ; <nl> - } <nl> - return expectedRowCount ; <nl> - } <nl> - <nl> static enum State <nl> { <nl> END _ OF _ PARTITION , AFTER _ LIMIT , SUCCESS ; <nl> } <nl> <nl> - / / seek to the provided position ( or the first entry if null ) <nl> + / * * <nl> + * seek to the provided position to initialise the iterator <nl> + * <nl> + * @ param scalar scalar position <nl> + * @ return resultant iterator state <nl> + * / <nl> private State seek ( int scalar ) <nl> { <nl> if ( scalar = = 0 ) <nl> { <nl> - this . position [ 0 ] = - 1 ; <nl> + this . currentRow [ 0 ] = - 1 ; <nl> clusteringComponents [ 0 ] . addFirst ( this ) ; <nl> return setHasNext ( advance ( 0 , true ) ) ; <nl> } <nl> <nl> - int [ ] position = this . position ; <nl> + int [ ] position = this . currentRow ; <nl> decompose ( scalar , position ) ; <nl> - boolean incremented = false ; <nl> for ( int i = 0 ; i < position . length ; i + + ) <nl> { <nl> if ( i ! = 0 ) <nl> @ @ - 321 , 39 + 364 , 36 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> if ( clusteringComponents [ i ] . isEmpty ( ) ) <nl> { <nl> int j = i ; <nl> - while ( - - j > = 0 ) <nl> + while ( true ) <nl> { <nl> + / / if we ' ve exhausted the whole partition , we ' re done <nl> + if ( - - j < 0 ) <nl> + return setHasNext ( false ) ; <nl> + <nl> clusteringComponents [ j ] . poll ( ) ; <nl> if ( ! clusteringComponents [ j ] . isEmpty ( ) ) <nl> break ; <nl> } <nl> <nl> - / / if we ' ve exhausted the whole partition , we ' re done <nl> - if ( j < 0 ) <nl> - return setHasNext ( false ) ; <nl> - <nl> - / / we don ' t check here to see if we ' ve exceeded our limit , <nl> - / / because if we came to a non - existent position and generated a limit <nl> + / / we don ' t check here to see if we ' ve exceeded our lastRow , <nl> + / / because if we came to a non - existent position and generated a lastRow <nl> / / we want to at least find the next real position , and set it on the seed <nl> / / in this case we do then yield false and select a different seed to continue with <nl> position [ j ] + + ; <nl> Arrays . fill ( position , j + 1 , position . length , 0 ) ; <nl> while ( j < i ) <nl> fill ( + + j ) ; <nl> - incremented = true ; <nl> } <nl> - if ( clusteringComponents [ i ] . isEmpty ( ) ) <nl> - throw new IllegalStateException ( ) ; <nl> + <nl> row . row [ i ] = clusteringComponents [ i ] . peek ( ) ; <nl> } <nl> <nl> - if ( incremented & & compareToLastRow ( ) > 0 ) <nl> + if ( compareToLastRow ( currentRow . length - 1 ) > 0 ) <nl> return setHasNext ( false ) ; <nl> <nl> - position [ position . length - 1 ] - - ; <nl> / / call advance so we honour any select chance <nl> + position [ position . length - 1 ] - - ; <nl> clusteringComponents [ position . length - 1 ] . addFirst ( this ) ; <nl> - <nl> return setHasNext ( advance ( position . length - 1 , true ) ) ; <nl> } <nl> <nl> @ @ - 384 , 7 + 424 , 7 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> ThreadLocalRandom random = ThreadLocalRandom . current ( ) ; <nl> / / advance the leaf component <nl> clusteringComponents [ depth ] . poll ( ) ; <nl> - position [ depth ] + + ; <nl> + currentRow [ depth ] + + ; <nl> while ( true ) <nl> { <nl> if ( clusteringComponents [ depth ] . isEmpty ( ) ) <nl> @ @ - 394 , 15 + 434 , 18 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> return false ; <nl> depth - - ; <nl> clusteringComponents [ depth ] . poll ( ) ; <nl> - if ( + + position [ depth ] > limit [ depth ] ) <nl> + if ( + + currentRow [ depth ] > lastRow [ depth ] ) <nl> return false ; <nl> continue ; <nl> } <nl> <nl> - int compareToLastRow = compareToLastRow ( ) ; <nl> - if ( compareToLastRow > 0 & & ! first ) <nl> + int compareToLastRow = compareToLastRow ( depth ) ; <nl> + if ( compareToLastRow > 0 ) <nl> + { <nl> + assert ! first ; <nl> return false ; <nl> - boolean forceReturnOne = first & & compareToLastRow > = 0 ; <nl> + } <nl> + boolean forceReturnOne = first & & compareToLastRow = = 0 ; <nl> <nl> / / the chance of descending is the uniform usechance , multiplied by the number of children <nl> / / we would on average generate ( so if we have a 0 . 1 use chance , but should generate 10 children <nl> @ @ - 424 , 7 + 467 , 7 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> rollmodifier [ depth ] = rollmodifier [ depth - 1 ] / Math . min ( 1d , thischance ) ; <nl> chancemodifier [ depth ] = generator . clusteringDescendantAverages [ depth ] * rollmodifier [ depth ] ; <nl> } <nl> - position [ depth ] = 0 ; <nl> + currentRow [ depth ] = 0 ; <nl> fill ( depth ) ; <nl> continue ; <nl> } <nl> @ @ - 434 , 32 + 477 , 8 @ @ public abstract class PartitionIterator implements Iterator < Row > <nl> <nl> / / if we don ' t descend , we remove the clustering suffix we ' ve skipped and continue <nl> clusteringComponents [ depth ] . poll ( ) ; <nl> - position [ depth ] + + ; <nl> - } <nl> - } <nl> - <nl> - private static int compare ( int [ ] a , int [ ] b ) <nl> - { <nl> - for ( int i = 0 ; i ! = a . length ; i + + ) <nl> - if ( a [ i ] ! = b [ i ] ) <nl> - return Integer . compare ( a [ i ] , b [ i ] ) ; <nl> - return 0 ; <nl> - } <nl> - <nl> - private int compareToLastRow ( ) <nl> - { <nl> - int c = position . length - 1 ; <nl> - for ( int i = 0 ; i < = c ; i + + ) <nl> - { <nl> - int p = position [ i ] , l = limit [ i ] , r = clusteringComponents [ i ] . size ( ) ; <nl> - if ( i = = c & & p = = l - 1 ) <nl> - return 0 ; <nl> - if ( ( p < l ) & ( r > 1 ) ) <nl> - return - 1 ; <nl> - if ( p > l ) <nl> - return 1 ; <nl> + currentRow [ depth ] + + ; <nl> } <nl> - return 1 ; <nl> } <nl> <nl> / / generate the clustering components for the provided depth ; requires preceding components
NEAREST DIFF (one line): ELIMINATEDSENTENCE

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 8f71269 . . 0c2bab8 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 1 . 3 
 + * Fix cassandra - stress user - mode truncation of partition generation ( CASSANDRA - 8608 ) 
 * Only stream from unrepaired sstables during inc repair ( CASSANDRA - 8267 ) 
 * Don ' t allow starting multiple inc repairs on the same sstables ( CASSANDRA - 8316 ) 
 * Invalidate prepared BATCH statements when related tables 
 diff - - git a / tools / stress / src / org / apache / cassandra / stress / Operation . java b / tools / stress / src / org / apache / cassandra / stress / Operation . java 
 index edf3a54 . . 05045f8 100644 
 - - - a / tools / stress / src / org / apache / cassandra / stress / Operation . java 
 + + + b / tools / stress / src / org / apache / cassandra / stress / Operation . java 
 @ @ - 105 , 9 + 105 , 9 @ @ public abstract class Operation 
 break ; 
 
 if ( spec . useRatio = = null ) 
 - success = partitionCache . get ( i ) . reset ( seed , spec . targetCount , this ) ; 
 + success = partitionCache . get ( i ) . reset ( seed , spec . targetCount , isWrite ( ) ) ; 
 else 
 - success = partitionCache . get ( i ) . reset ( seed , spec . useRatio . next ( ) , this ) ; 
 + success = partitionCache . get ( i ) . reset ( seed , spec . useRatio . next ( ) , isWrite ( ) ) ; 
 } 
 } 
 partitionCount = i ; 
 diff - - git a / tools / stress / src / org / apache / cassandra / stress / generate / PartitionIterator . java b / tools / stress / src / org / apache / cassandra / stress / generate / PartitionIterator . java 
 index 0d0cba1 . . 0466edb 100644 
 - - - a / tools / stress / src / org / apache / cassandra / stress / generate / PartitionIterator . java 
 + + + b / tools / stress / src / org / apache / cassandra / stress / generate / PartitionIterator . java 
 @ @ - 50 , 14 + 50 , 16 @ @ import org . apache . cassandra . stress . generate . values . Generator ; 
 public abstract class PartitionIterator implements Iterator < Row > 
 { 
 
 - / / we reuse the row object to save garbage 
 - abstract boolean reset ( double useChance , int targetCount , Operation op ) ; 
 + abstract boolean reset ( double useChance , int targetCount , boolean isWrite ) ; 
 
 long idseed ; 
 Seed seed ; 
 - final Object [ ] partitionKey ; 
 + 
 final PartitionGenerator generator ; 
 final SeedManager seedManager ; 
 + 
 + / / we reuse these objects to save garbage 
 + final Object [ ] partitionKey ; 
 final Row row ; 
 
 public static PartitionIterator get ( PartitionGenerator generator , SeedManager seedManager ) 
 @ @ - 93 , 16 + 95 , 16 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 this . idseed = idseed ; 
 } 
 
 - public boolean reset ( Seed seed , double useChance , Operation op ) 
 + public boolean reset ( Seed seed , double useChance , boolean isWrite ) 
 { 
 setSeed ( seed ) ; 
 - return reset ( useChance , 0 , op ) ; 
 + return reset ( useChance , 0 , isWrite ) ; 
 } 
 
 - public boolean reset ( Seed seed , int targetCount , Operation op ) 
 + public boolean reset ( Seed seed , int targetCount , boolean isWrite ) 
 { 
 setSeed ( seed ) ; 
 - return reset ( Double . NaN , targetCount , op ) ; 
 + return reset ( Double . NaN , targetCount , isWrite ) ; 
 } 
 
 static class SingleRowIterator extends PartitionIterator 
 @ @ - 115 , 10 + 117 , 10 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 super ( generator , seedManager ) ; 
 } 
 
 - boolean reset ( double useChance , int targetCount , Operation op ) 
 + boolean reset ( double useChance , int targetCount , boolean isWrite ) 
 { 
 done = false ; 
 - isWrite = op . isWrite ( ) ; 
 + this . isWrite = isWrite ; 
 return true ; 
 } 
 
 @ @ - 155 , 24 + 157 , 22 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 / / TODO : support first / last row , and constraining reads to rows we know are populated 
 static class MultiRowIterator extends PartitionIterator 
 { 
 - 
 - / / probability any single row will be generated in this iteration 
 - double useChance ; 
 - 
 / / the seed used to generate the current values for the clustering components at each depth ; 
 / / used to save recalculating it for each row , so we only need to recalc from prior row . 
 final long [ ] clusteringSeeds = new long [ generator . clusteringComponents . size ( ) ] ; 
 / / the components remaining to be visited for each level of the current stack 
 final Deque < Object > [ ] clusteringComponents = new ArrayDeque [ generator . clusteringComponents . size ( ) ] ; 
 
 + / / probability any single row will be generated in this iteration 
 + double useChance ; 
 / / we want our chance of selection to be applied uniformly , so we compound the roll we make at each level 
 / / so that we know with what chance we reached there , and we adjust our roll at that level by that amount 
 final double [ ] chancemodifier = new double [ generator . clusteringComponents . size ( ) ] ; 
 final double [ ] rollmodifier = new double [ generator . clusteringComponents . size ( ) ] ; 
 
 / / track where in the partition we are , and where we are limited to 
 - final int [ ] position = new int [ generator . clusteringComponents . size ( ) ] ; 
 - final int [ ] limit = new int [ position . length ] ; 
 + final int [ ] currentRow = new int [ generator . clusteringComponents . size ( ) ] ; 
 + final int [ ] lastRow = new int [ currentRow . length ] ; 
 boolean hasNext , isFirstWrite , isWrite ; 
 
 / / reusable collections for generating unique and sorted clustering components 
 @ @ - 188 , 10 + 188 , 22 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 chancemodifier [ 0 ] = generator . clusteringDescendantAverages [ 0 ] ; 
 } 
 
 - / / if we ' re a write , the expected behaviour is that the requested batch count is compounded with the seed ' s visit 
 - / / count to decide how much we should return in one iteration 
 - boolean reset ( double useChance , int targetCount , Operation op ) 
 + / * * 
 + * initialise the iterator state 
 + * 
 + * if we ' re a write , the expected behaviour is that the requested 
 + * batch count is compounded with the seed ' s visit count to decide 
 + * how much we should return in one iteration 
 + * 
 + * @ param useChance uniform chance of visiting any single row ( NaN if targetCount provided ) 
 + * @ param targetCount number of rows we would like to visit ( 0 if useChance provided ) 
 + * @ param isWrite true if the action requires write semantics 
 + * 
 + * @ return true if there is data to return , false otherwise 
 + * / 
 + boolean reset ( double useChance , int targetCount , boolean isWrite ) 
 { 
 + this . isWrite = isWrite ; 
 if ( this . useChance < 1d ) 
 { 
 / / we clear our prior roll - modifiers if the use chance was previously less - than zero 
 @ @ - 207 , 14 + 219 , 13 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 int expectedRowCount ; 
 
 int position = seed . position ( ) ; 
 - isWrite = op . isWrite ( ) ; 
 
 if ( isWrite ) 
 expectedRowCount = firstComponentCount * generator . clusteringDescendantAverages [ 0 ] ; 
 else if ( position ! = 0 ) 
 - expectedRowCount = setLimit ( position ) ; 
 + expectedRowCount = setLastRow ( position - 1 ) ; 
 else 
 - expectedRowCount = setNoLimit ( firstComponentCount ) ; 
 + expectedRowCount = setNoLastRow ( firstComponentCount ) ; 
 
 if ( Double . isNaN ( useChance ) ) 
 useChance = Math . max ( 0d , Math . min ( 1d , targetCount / ( double ) expectedRowCount ) ) ; 
 @ @ - 222 , 38 + 233 , 84 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 
 while ( true ) 
 { 
 - / / TODO : we could avoid repopulating these each loop , by tracking our prior position 
 + / / we loop in case we have picked an entirely non - existent range , in which case 
 + / / we will reset the seed ' s position , then try again ( until we exhaust it or find 
 + / / some real range ) 
 + 
 for ( Queue < ? > q : clusteringComponents ) 
 q . clear ( ) ; 
 clusteringSeeds [ 0 ] = idseed ; 
 fill ( clusteringComponents [ 0 ] , firstComponentCount , generator . clusteringComponents . get ( 0 ) ) ; 
 
 - / / we loop in case we have picked an entirely non - existent range , in which case 
 - / / we will reset the seed ' s position , then try again ( until we exhaust it or find 
 - / / some real range ) - this only happens for writes , so we only keep this logic in the loop 
 - 
 - if ( isWrite ) 
 + if ( ! isWrite ) 
 { 
 - position = seed . moveForwards ( Math . max ( 1 , expectedRowCount / seed . visits ) ) ; 
 - isFirstWrite = position = = 0 ; 
 + if ( seek ( 0 ) ! = State . SUCCESS ) 
 + throw new IllegalStateException ( ) ; 
 + return true ; 
 } 
 
 + 
 + int count = Math . max ( 1 , expectedRowCount / seed . visits ) ; 
 + position = seed . moveForwards ( count ) ; 
 + isFirstWrite = position = = 0 ; 
 + setLastRow ( position + count - 1 ) ; 
 + 
 / / seek to our start position 
 - switch ( seek ( isWrite ? position : 0 ) ) 
 + switch ( seek ( position ) ) 
 { 
 case END _ OF _ PARTITION : 
 return false ; 
 case SUCCESS : 
 return true ; 
 } 
 + } 
 + } 
 
 - if ( ! isWrite ) 
 - throw new IllegalStateException ( ) ; 
 + / / returns expected row count 
 + private int setNoLastRow ( int firstComponentCount ) 
 + { 
 + Arrays . fill ( lastRow , Integer . MAX _ VALUE ) ; 
 + return firstComponentCount * generator . clusteringDescendantAverages [ 0 ] ; 
 + } 
 
 - / / TODO : recompose our real position into the nearest scalar position , and ensure the seed position is > = this 
 + / / sets the last row we will visit 
 + / / returns expected distance from zero 
 + private int setLastRow ( int position ) 
 + { 
 + if ( position < 0 ) 
 + throw new IllegalStateException ( ) ; 
 + 
 + decompose ( position , lastRow ) ; 
 + int expectedRowCount = 0 ; 
 + for ( int i = 0 ; i < lastRow . length ; i + + ) 
 + { 
 + int l = lastRow [ i ] ; 
 + expectedRowCount + = l * generator . clusteringDescendantAverages [ i ] ; 
 } 
 + return expectedRowCount + 1 ; 
 } 
 
 + / / returns 0 if we are currently on the last row we are allocated to visit ; 1 if it is after , - 1 if it is before 
 + / / this is defined by _ limit _ , which is wired up from expected ( mean ) row counts 
 + / / the last row is where position = = lastRow , except the last index is 1 less ; 
 + / / OR if that row does not exist , it is the last row prior to it 
 + private int compareToLastRow ( int depth ) 
 + { 
 + for ( int i = 0 ; i < = depth ; i + + ) 
 + { 
 + int p = currentRow [ i ] , l = lastRow [ i ] , r = clusteringComponents [ i ] . size ( ) ; 
 + if ( ( p = = l ) | ( r = = 1 ) ) 
 + continue ; 
 + return p - l ; 
 + } 
 + return 0 ; 
 + } 
 + 
 + / * * 
 + * Translate the scalar position into a tiered position based on mean expected counts 
 + * @ param scalar scalar position 
 + * @ param decomposed target container 
 + * / 
 private void decompose ( int scalar , int [ ] decomposed ) 
 { 
 for ( int i = 0 ; i < decomposed . length ; i + + ) 
 @ @ - 262 , 7 + 319 , 7 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 decomposed [ i ] = scalar / avg ; 
 scalar % = avg ; 
 } 
 - for ( int i = limit . length - 1 ; i > 0 ; i - - ) 
 + for ( int i = lastRow . length - 1 ; i > 0 ; i - - ) 
 { 
 int avg = generator . clusteringComponentAverages [ i ] ; 
 if ( decomposed [ i ] > = avg ) 
 @ @ - 273 , 42 + 330 , 28 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 } 
 } 
 
 - private int setNoLimit ( int firstComponentCount ) 
 - { 
 - Arrays . fill ( limit , Integer . MAX _ VALUE ) ; 
 - return firstComponentCount * generator . clusteringDescendantAverages [ 0 ] ; 
 - } 
 - 
 - private int setLimit ( int position ) 
 - { 
 - decompose ( position , limit ) ; 
 - int expectedRowCount = 0 ; 
 - for ( int i = 0 ; i < limit . length ; i + + ) 
 - { 
 - int l = limit [ i ] ; 
 - expectedRowCount + = l * generator . clusteringDescendantAverages [ i ] ; 
 - } 
 - return expectedRowCount ; 
 - } 
 - 
 static enum State 
 { 
 END _ OF _ PARTITION , AFTER _ LIMIT , SUCCESS ; 
 } 
 
 - / / seek to the provided position ( or the first entry if null ) 
 + / * * 
 + * seek to the provided position to initialise the iterator 
 + * 
 + * @ param scalar scalar position 
 + * @ return resultant iterator state 
 + * / 
 private State seek ( int scalar ) 
 { 
 if ( scalar = = 0 ) 
 { 
 - this . position [ 0 ] = - 1 ; 
 + this . currentRow [ 0 ] = - 1 ; 
 clusteringComponents [ 0 ] . addFirst ( this ) ; 
 return setHasNext ( advance ( 0 , true ) ) ; 
 } 
 
 - int [ ] position = this . position ; 
 + int [ ] position = this . currentRow ; 
 decompose ( scalar , position ) ; 
 - boolean incremented = false ; 
 for ( int i = 0 ; i < position . length ; i + + ) 
 { 
 if ( i ! = 0 ) 
 @ @ - 321 , 39 + 364 , 36 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 if ( clusteringComponents [ i ] . isEmpty ( ) ) 
 { 
 int j = i ; 
 - while ( - - j > = 0 ) 
 + while ( true ) 
 { 
 + / / if we ' ve exhausted the whole partition , we ' re done 
 + if ( - - j < 0 ) 
 + return setHasNext ( false ) ; 
 + 
 clusteringComponents [ j ] . poll ( ) ; 
 if ( ! clusteringComponents [ j ] . isEmpty ( ) ) 
 break ; 
 } 
 
 - / / if we ' ve exhausted the whole partition , we ' re done 
 - if ( j < 0 ) 
 - return setHasNext ( false ) ; 
 - 
 - / / we don ' t check here to see if we ' ve exceeded our limit , 
 - / / because if we came to a non - existent position and generated a limit 
 + / / we don ' t check here to see if we ' ve exceeded our lastRow , 
 + / / because if we came to a non - existent position and generated a lastRow 
 / / we want to at least find the next real position , and set it on the seed 
 / / in this case we do then yield false and select a different seed to continue with 
 position [ j ] + + ; 
 Arrays . fill ( position , j + 1 , position . length , 0 ) ; 
 while ( j < i ) 
 fill ( + + j ) ; 
 - incremented = true ; 
 } 
 - if ( clusteringComponents [ i ] . isEmpty ( ) ) 
 - throw new IllegalStateException ( ) ; 
 + 
 row . row [ i ] = clusteringComponents [ i ] . peek ( ) ; 
 } 
 
 - if ( incremented & & compareToLastRow ( ) > 0 ) 
 + if ( compareToLastRow ( currentRow . length - 1 ) > 0 ) 
 return setHasNext ( false ) ; 
 
 - position [ position . length - 1 ] - - ; 
 / / call advance so we honour any select chance 
 + position [ position . length - 1 ] - - ; 
 clusteringComponents [ position . length - 1 ] . addFirst ( this ) ; 
 - 
 return setHasNext ( advance ( position . length - 1 , true ) ) ; 
 } 
 
 @ @ - 384 , 7 + 424 , 7 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 ThreadLocalRandom random = ThreadLocalRandom . current ( ) ; 
 / / advance the leaf component 
 clusteringComponents [ depth ] . poll ( ) ; 
 - position [ depth ] + + ; 
 + currentRow [ depth ] + + ; 
 while ( true ) 
 { 
 if ( clusteringComponents [ depth ] . isEmpty ( ) ) 
 @ @ - 394 , 15 + 434 , 18 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 return false ; 
 depth - - ; 
 clusteringComponents [ depth ] . poll ( ) ; 
 - if ( + + position [ depth ] > limit [ depth ] ) 
 + if ( + + currentRow [ depth ] > lastRow [ depth ] ) 
 return false ; 
 continue ; 
 } 
 
 - int compareToLastRow = compareToLastRow ( ) ; 
 - if ( compareToLastRow > 0 & & ! first ) 
 + int compareToLastRow = compareToLastRow ( depth ) ; 
 + if ( compareToLastRow > 0 ) 
 + { 
 + assert ! first ; 
 return false ; 
 - boolean forceReturnOne = first & & compareToLastRow > = 0 ; 
 + } 
 + boolean forceReturnOne = first & & compareToLastRow = = 0 ; 
 
 / / the chance of descending is the uniform usechance , multiplied by the number of children 
 / / we would on average generate ( so if we have a 0 . 1 use chance , but should generate 10 children 
 @ @ - 424 , 7 + 467 , 7 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 rollmodifier [ depth ] = rollmodifier [ depth - 1 ] / Math . min ( 1d , thischance ) ; 
 chancemodifier [ depth ] = generator . clusteringDescendantAverages [ depth ] * rollmodifier [ depth ] ; 
 } 
 - position [ depth ] = 0 ; 
 + currentRow [ depth ] = 0 ; 
 fill ( depth ) ; 
 continue ; 
 } 
 @ @ - 434 , 32 + 477 , 8 @ @ public abstract class PartitionIterator implements Iterator < Row > 
 
 / / if we don ' t descend , we remove the clustering suffix we ' ve skipped and continue 
 clusteringComponents [ depth ] . poll ( ) ; 
 - position [ depth ] + + ; 
 - } 
 - } 
 - 
 - private static int compare ( int [ ] a , int [ ] b ) 
 - { 
 - for ( int i = 0 ; i ! = a . length ; i + + ) 
 - if ( a [ i ] ! = b [ i ] ) 
 - return Integer . compare ( a [ i ] , b [ i ] ) ; 
 - return 0 ; 
 - } 
 - 
 - private int compareToLastRow ( ) 
 - { 
 - int c = position . length - 1 ; 
 - for ( int i = 0 ; i < = c ; i + + ) 
 - { 
 - int p = position [ i ] , l = limit [ i ] , r = clusteringComponents [ i ] . size ( ) ; 
 - if ( i = = c & & p = = l - 1 ) 
 - return 0 ; 
 - if ( ( p < l ) & ( r > 1 ) ) 
 - return - 1 ; 
 - if ( p > l ) 
 - return 1 ; 
 + currentRow [ depth ] + + ; 
 } 
 - return 1 ; 
 } 
 
 / / generate the clustering components for the provided depth ; requires preceding components

NEAREST DIFF:
ELIMINATEDSENTENCE
