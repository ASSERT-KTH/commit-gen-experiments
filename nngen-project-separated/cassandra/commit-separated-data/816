BLEU SCORE: 0.05341087579952926

TEST MSG: Add Metrics / Monitoring docs
GENERATED MSG: add wordcount hadoop example

TEST DIFF (one line): diff - - git a / doc / source / _ static / extra . css b / doc / source / _ static / extra . css <nl> index ec6aa3f . . ff9f1d1 100644 <nl> - - - a / doc / source / _ static / extra . css <nl> + + + b / doc / source / _ static / extra . css <nl> @ @ - 17 , 3 + 17 , 15 @ @ a . reference . internal code . literal { <nl> a . reference . internal : visited code . literal { <nl> color : # 9B59B6 ; <nl> } <nl> + <nl> + <nl> + / * override table width restrictions * / <nl> + . wy - table - responsive table td , . wy - table - responsive table th { <nl> + white - space : normal ; <nl> + } <nl> + <nl> + . wy - table - responsive { <nl> + margin - bottom : 24px ; <nl> + max - width : 100 % ; <nl> + overflow : visible ; <nl> + } <nl> diff - - git a / doc / source / operations . rst b / doc / source / operations . rst <nl> index d7fcafb . . 31ecc35 100644 <nl> - - - a / doc / source / operations . rst <nl> + + + b / doc / source / operations . rst <nl> @ @ - 833 , 13 + 833 , 604 @ @ Backups <nl> Monitoring <nl> - - - - - - - - - - <nl> <nl> + Metrics in Cassandra are managed using the ` Dropwizard Metrics < http : / / metrics . dropwizard . io > ` _ _ library . These metrics <nl> + can be queried via JMX or pushed to external monitoring systems using a number of ` built in <nl> + < http : / / metrics . dropwizard . io / 3 . 1 . 0 / getting - started / # other - reporting > ` _ _ and ` third party <nl> + < http : / / metrics . dropwizard . io / 3 . 1 . 0 / manual / third - party / > ` _ _ reporter plugins . <nl> + <nl> + Metrics are collected for a single node . It ' s up to the operator to use an external monitoring system to aggregate them . <nl> + <nl> + Metric Types <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + All metrics reported by cassandra fit into one of the following types . <nl> + <nl> + ` ` Gauge ` ` <nl> + An instantaneous measurement of a value . <nl> + <nl> + ` ` Counter ` ` <nl> + A gauge for an ` ` AtomicLong ` ` instance . Typically this is consumed by monitoring the change since the last call to <nl> + see if there is a large increase compared to the norm . <nl> + <nl> + ` ` Histogram ` ` <nl> + Measures the statistical distribution of values in a stream of data . <nl> + <nl> + In addition to minimum , maximum , mean , etc . , it also measures median , 75th , 90th , 95th , 98th , 99th , and 99 . 9th <nl> + percentiles . <nl> + <nl> + ` ` Timer ` ` <nl> + Measures both the rate that a particular piece of code is called and the histogram of its duration . <nl> + <nl> + ` ` Latency ` ` <nl> + Special type that tracks latency ( in microseconds ) with a ` ` Timer ` ` plus a ` ` Counter ` ` that tracks the total latency <nl> + accrued since starting . The former is useful if you track the change in total latency since the last check . Each <nl> + metric name of this type will have ' Latency ' and ' TotalLatency ' appended to it . <nl> + <nl> + ` ` Meter ` ` <nl> + A meter metric which measures mean throughput and one - , five - , and fifteen - minute exponentially - weighted moving <nl> + average throughputs . <nl> + <nl> + Table Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Each table in Cassandra has metrics responsible for tracking its state and performance . <nl> + <nl> + The metric names are all appended with the specific ` ` Keyspace ` ` and ` ` Table ` ` name . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . Table . { { MetricName } } . { { Keyspace } } . { { Table } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = Table keyspace = { { Keyspace } scope = { { Table } } name = { { MetricName } } ` ` <nl> + <nl> + . . NOTE : : <nl> + There is a special table called ' ` ` all ` ` ' without a keyspace . This represents the aggregation of metrics across <nl> + * * all * * tables and keyspaces on the node . <nl> + <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + MemtableOnHeapSize Gauge < Long > Total amount of data stored in the memtable that resides * * on * * - heap , including column related overhead and partitions overwritten . <nl> + MemtableOffHeapSize Gauge < Long > Total amount of data stored in the memtable that resides * * off * * - heap , including column related overhead and partitions overwritten . <nl> + MemtableLiveDataSize Gauge < Long > Total amount of live data stored in the memtable , excluding any data structure overhead . <nl> + AllMemtablesOnHeapSize Gauge < Long > Total amount of data stored in the memtables ( 2i and pending flush memtables included ) that resides * * on * * - heap . <nl> + AllMemtablesOffHeapSize Gauge < Long > Total amount of data stored in the memtables ( 2i and pending flush memtables included ) that resides * * off * * - heap . <nl> + AllMemtablesLiveDataSize Gauge < Long > Total amount of live data stored in the memtables ( 2i and pending flush memtables included ) that resides off - heap , excluding any data structure overhead . <nl> + MemtableColumnsCount Gauge < Long > Total number of columns present in the memtable . <nl> + MemtableSwitchCount Counter Number of times flush has resulted in the memtable being switched out . <nl> + CompressionRatio Gauge < Double > Current compression ratio for all SSTables . <nl> + EstimatedPartitionSizeHistogram Gauge < long [ ] > Histogram of estimated partition size ( in bytes ) . <nl> + EstimatedPartitionCount Gauge < Long > Approximate number of keys in table . <nl> + EstimatedColumnCountHistogram Gauge < long [ ] > Histogram of estimated number of columns . <nl> + SSTablesPerReadHistogram Histogram Histogram of the number of sstable data files accessed per read . <nl> + ReadLatency Latency Local read latency for this table . <nl> + RangeLatency Latency Local range scan latency for this table . <nl> + WriteLatency Latency Local write latency for this table . <nl> + CoordinatorReadLatency Timer Coordinator read latency for this table . <nl> + CoordinatorScanLatency Timer Coordinator range scan latency for this table . <nl> + PendingFlushes Counter Estimated number of flush tasks pending for this table . <nl> + BytesFlushed Counter Total number of bytes flushed since server [ re ] start . <nl> + CompactionBytesWritten Counter Total number of bytes written by compaction since server [ re ] start . <nl> + PendingCompactions Gauge < Integer > Estimate of number of pending compactions for this table . <nl> + LiveSSTableCount Gauge < Integer > Number of SSTables on disk for this table . <nl> + LiveDiskSpaceUsed Counter Disk space used by SSTables belonging to this table ( in bytes ) . <nl> + TotalDiskSpaceUsed Counter Total disk space used by SSTables belonging to this table , including obsolete ones waiting to be GC ' d . <nl> + MinPartitionSize Gauge < Long > Size of the smallest compacted partition ( in bytes ) . <nl> + MaxPartitionSize Gauge < Long > Size of the largest compacted partition ( in bytes ) . <nl> + MeanPartitionSize Gauge < Long > Size of the average compacted partition ( in bytes ) . <nl> + BloomFilterFalsePositives Gauge < Long > Number of false positives on table ' s bloom filter . <nl> + BloomFilterFalseRatio Gauge < Double > False positive ratio of table ' s bloom filter . <nl> + BloomFilterDiskSpaceUsed Gauge < Long > Disk space used by bloom filter ( in bytes ) . <nl> + BloomFilterOffHeapMemoryUsed Gauge < Long > Off - heap memory used by bloom filter . <nl> + IndexSummaryOffHeapMemoryUsed Gauge < Long > Off - heap memory used by index summary . <nl> + CompressionMetadataOffHeapMemoryUsed Gauge < Long > Off - heap memory used by compression meta data . <nl> + KeyCacheHitRate Gauge < Double > Key cache hit rate for this table . <nl> + TombstoneScannedHistogram Histogram Histogram of tombstones scanned in queries on this table . <nl> + LiveScannedHistogram Histogram Histogram of live cells scanned in queries on this table . <nl> + ColUpdateTimeDeltaHistogram Histogram Histogram of column update time delta on this table . <nl> + ViewLockAcquireTime Timer Time taken acquiring a partition lock for materialized view updates on this table . <nl> + ViewReadTime Timer Time taken during the local read of a materialized view update . <nl> + TrueSnapshotsSize Gauge < Long > Disk space used by snapshots of this table including all SSTable components . <nl> + RowCacheHitOutOfRange Counter Number of table row cache hits that do not satisfy the query filter , thus went to disk . <nl> + RowCacheHit Counter Number of table row cache hits . <nl> + RowCacheMiss Counter Number of table row cache misses . <nl> + CasPrepare Latency Latency of paxos prepare round . <nl> + CasPropose Latency Latency of paxos propose round . <nl> + CasCommit Latency Latency of paxos commit round . <nl> + PercentRepaired Gauge < Double > Percent of table data that is repaired on disk . <nl> + SpeculativeRetries Counter Number of times speculative retries were sent for this table . <nl> + WaitingOnFreeMemtableSpace Histogram Histogram of time spent waiting for free memtable space , either on - or off - heap . <nl> + DroppedMutations Counter Number of dropped mutations on this table . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + Keyspace Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + Each keyspace in Cassandra has metrics responsible for tracking its state and performance . <nl> + <nl> + These metrics are the same as the ` ` Table Metrics ` ` above , only they are aggregated at the Keyspace level . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . keyspace . { { MetricName } } . { { Keyspace } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = Keyspace scope = { { Keyspace } } name = { { MetricName } } ` ` <nl> + <nl> + ThreadPool Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Cassandra splits work of a particular type into its own thread pool . This provides back - pressure and asynchrony for <nl> + requests on a node . It ' s important to monitor the state of these thread pools since they can tell you how saturated a <nl> + node is . <nl> + <nl> + The metric names are all appended with the specific ` ` ThreadPool ` ` name . The thread pools are also categorized under a <nl> + specific type . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . ThreadPools . { { MetricName } } . { { Path } } . { { ThreadPoolName } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = ThreadPools scope = { { ThreadPoolName } } type = { { Type } } name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + ActiveTasks Gauge < Integer > Number of tasks being actively worked on by this pool . <nl> + PendingTasks Gauge < Integer > Number of queued tasks queued up on this pool . <nl> + CompletedTasks Counter Number of tasks completed . <nl> + TotalBlockedTasks Counter Number of tasks that were blocked due to queue saturation . <nl> + CurrentlyBlockedTask Counter Number of tasks that are currently blocked due to queue saturation but on retry will become unblocked . <nl> + MaxPoolSize Gauge < Integer > The maximum number of threads in this pool . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + The following thread pools can be monitored . <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Native - Transport - Requests transport Handles client CQL requests <nl> + CounterMutationStage request Responsible for counter writes <nl> + ViewMutationStage request Responsible for materialized view writes <nl> + MutationStage request Responsible for all other writes <nl> + ReadRepairStage request ReadRepair happens on this thread pool <nl> + ReadStage request Local reads run on this thread pool <nl> + RequestResponseStage request Coordinator requests to the cluster run on this thread pool <nl> + AntiEntropyStage internal Builds merkle tree for repairs <nl> + CacheCleanupExecutor internal Cache maintenance performed on this thread pool <nl> + CompactionExecutor internal Compactions are run on these threads <nl> + GossipStage internal Handles gossip requests <nl> + HintsDispatcher internal Performs hinted handoff <nl> + InternalResponseStage internal Responsible for intra - cluster callbacks <nl> + MemtableFlushWriter internal Writes memtables to disk <nl> + MemtablePostFlush internal Cleans up commit log after memtable is written to disk <nl> + MemtableReclaimMemory internal Memtable recycling <nl> + MigrationStage internal Runs schema migrations <nl> + MiscStage internal Misceleneous tasks run here <nl> + PendingRangeCalculator internal Calculates token range <nl> + PerDiskMemtableFlushWriter _ 0 internal Responsible for writing a spec ( there is one of these per disk 0 - N ) <nl> + Sampler internal Responsible for re - sampling the index summaries of SStables <nl> + SecondaryIndexManagement internal Performs updates to secondary indexes <nl> + ValidationExecutor internal Performs validation compaction or scrubbing <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + . . | nbsp | unicode : : 0xA0 . . nonbreaking space <nl> + <nl> + Client Request Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Client requests have their own set of metrics that encapsulate the work happening at coordinator level . <nl> + <nl> + Different types of client requests are broken down by ` ` RequestType ` ` . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . ClientRequest . { { MetricName } } . { { RequestType } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = ClientRequest scope = { { RequestType } } name = { { MetricName } } ` ` <nl> + <nl> + <nl> + : RequestType : CASRead <nl> + : Description : Metrics related to transactional read requests . <nl> + : Metrics : <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Timeouts Counter Number of timeouts encountered . <nl> + Failures Counter Number of transaction failures encountered . <nl> + | nbsp | Latency Transaction read latency . <nl> + Unavailables Counter Number of unavailable exceptions encountered . <nl> + UnfinishedCommit Counter Number of transactions that were committed on read . <nl> + ConditionNotMet Counter Number of transaction preconditions did not match current values . <nl> + ContentionHistogram Histogram How many contended reads were encountered <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + : RequestType : CASWrite <nl> + : Description : Metrics related to transactional write requests . <nl> + : Metrics : <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Timeouts Counter Number of timeouts encountered . <nl> + Failures Counter Number of transaction failures encountered . <nl> + | nbsp | Latency Transaction write latency . <nl> + UnfinishedCommit Counter Number of transactions that were committed on write . <nl> + ConditionNotMet Counter Number of transaction preconditions did not match current values . <nl> + ContentionHistogram Histogram How many contended writes were encountered <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + <nl> + : RequestType : Read <nl> + : Description : Metrics related to standard read requests . <nl> + : Metrics : <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Timeouts Counter Number of timeouts encountered . <nl> + Failures Counter Number of read failures encountered . <nl> + | nbsp | Latency Read latency . <nl> + Unavailables Counter Number of unavailable exceptions encountered . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + : RequestType : RangeSlice <nl> + : Description : Metrics related to token range read requests . <nl> + : Metrics : <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Timeouts Counter Number of timeouts encountered . <nl> + Failures Counter Number of range query failures encountered . <nl> + | nbsp | Latency Range query latency . <nl> + Unavailables Counter Number of unavailable exceptions encountered . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + : RequestType : Write <nl> + : Description : Metrics related to regular write requests . <nl> + : Metrics : <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Timeouts Counter Number of timeouts encountered . <nl> + Failures Counter Number of write failures encountered . <nl> + | nbsp | Latency Write latency . <nl> + Unavailables Counter Number of unavailable exceptions encountered . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + <nl> + : RequestType : ViewWrite <nl> + : Description : Metrics related to materialized view write wrtes . <nl> + : Metrics : <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Timeouts Counter Number of timeouts encountered . <nl> + Failures Counter Number of transaction failures encountered . <nl> + Unavailables Counter Number of unavailable exceptions encountered . <nl> + ViewReplicasAttempted Counter Total number of attempted view replica writes . <nl> + ViewReplicasSuccess Counter Total number of succeded view replica writes . <nl> + ViewPendingMutations Gauge < Long > ViewReplicasAttempted - ViewReplicasSuccess . <nl> + ViewWriteLatency Timer Time between when mutation is applied to base table and when CL . ONE is achieved on view . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + Cache Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Cassandra caches have metrics to track the effectivness of the caches . Though the ` ` Table Metrics ` ` might be more useful . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . Cache . { { MetricName } } . { { CacheName } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = Cache scope = { { CacheName } } name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Capacity Gauge < Long > Cache capacity in bytes . <nl> + Entries Gauge < Integer > Total number of cache entries . <nl> + FifteenMinuteCacheHitRate Gauge < Double > 15m cache hit rate . <nl> + FiveMinuteCacheHitRate Gauge < Double > 5m cache hit rate . <nl> + OneMinuteCacheHitRate Gauge < Double > 1m cache hit rate . <nl> + HitRate Gauge < Double > All time cache hit rate . <nl> + Hits Meter Total number of cache hits . <nl> + Misses Meter Total number of cache misses . <nl> + MissLatency Timer Latency of misses . <nl> + Requests Gauge < Long > Total number of cache requests . <nl> + Size Gauge < Long > Total size of occupied cache , in bytes . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + The following caches are covered : <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + CounterCache Keeps hot counters in memory for performance . <nl> + ChunkCache In process uncompressed page cache . <nl> + KeyCache Cache for partition to sstable offsets . <nl> + RowCache Cache for rows kept in memory . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + . . NOTE : : <nl> + Misses and MissLatency are only defined for the ChunkCache <nl> + <nl> + CQL Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Metrics specific to CQL prepared statement caching . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . CQL . { { MetricName } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = CQL name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + PreparedStatementsCount Gauge < Integer > Number of cached prepared statements . <nl> + PreparedStatementsEvicted Counter Number of prepared statements evicted from the prepared statement cache <nl> + PreparedStatementsExecuted Counter Number of prepared statements executed . <nl> + RegularStatementsExecuted Counter Number of * * non * * prepared statements executed . <nl> + PreparedStatementsRatio Gauge < Double > Percentage of statements that are prepared vs unprepared . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + <nl> + DroppedMessage Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Metrics specific to tracking dropped messages for different types of requests . <nl> + Dropped writes are stored and retried by ` ` Hinted Handoff ` ` <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . DroppedMessages . { { MetricName } } . { { Type } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = DroppedMetrics scope = { { Type } } name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + CrossNodeDroppedLatency Timer The dropped latency across nodes . <nl> + InternalDroppedLatency Timer The dropped latency within node . <nl> + Dropped Meter Number of dropped messages . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + The different types of messages tracked are : <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + BATCH _ STORE Batchlog write <nl> + BATCH _ REMOVE Batchlog cleanup ( after succesfully applied ) <nl> + COUNTER _ MUTATION Counter writes <nl> + HINT Hint replay <nl> + MUTATION Regular writes <nl> + READ Regular reads <nl> + READ _ REPAIR Read repair <nl> + PAGED _ SLICE Paged read <nl> + RANGE _ SLICE Token range read <nl> + REQUEST _ RESPONSE RPC Callbacks <nl> + _ TRACE Tracing writes <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + Streaming Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Metrics reported during ` ` Streaming ` ` operations , such as repair , bootstrap , rebuild . <nl> + <nl> + These metrics are specific to a peer endpoint , with the source node being the node you are pulling the metrics from . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . Streaming . { { MetricName } } . { { PeerIP } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = Streaming scope = { { PeerIP } } name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + IncomingBytes Counter Number of bytes streamed to this node from the peer . <nl> + OutgoingBytes Counter Number of bytes streamed to the peer endpoint from this node . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + <nl> + Compaction Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Metrics specific to ` ` Compaction ` ` work . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . Compaction . { { MetricName } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = Compaction name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + BytesCompacted Counter Total number of bytes compacted since server [ re ] start . <nl> + PendingTasks Gauge < Integer > Estimated number of compactions remaining to perform . <nl> + CompletedTasks Gauge < Long > Number of completed compactions since server [ re ] start . <nl> + TotalCompactionsCompleted Meter Throughput of completed compactions since server [ re ] start . <nl> + PendingTasksByTableName Gauge < Map < String , Map < String , Integer > > > Estimated number of compactions remaining to perform , grouped by keyspace and then table name . This info is also kept in ` ` Table Metrics ` ` . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + CommitLog Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Metrics specific to the ` ` CommitLog ` ` <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . CommitLog . { { MetricName } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = CommitLog name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + CompletedTasks Gauge < Long > Total number of commit log messages written since [ re ] start . <nl> + PendingTasks Gauge < Long > Number of commit log messages written but yet to be fsync ' d . <nl> + TotalCommitLogSize Gauge < Long > Current size , in bytes , used by all the commit log segments . <nl> + WaitingOnSegmentAllocation Timer Time spent waiting for a CommitLogSegment to be allocated - under normal conditions this should be zero . <nl> + WaitingOnCommit Timer The time spent waiting on CL fsync ; for Periodic this is only occurs when the sync is lagging its sync interval . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + Storage Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Metrics specific to the storage engine . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . Storage . { { MetricName } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = Storage name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Exceptions Counter Number of internal exceptions caught . Under normal exceptions this should be zero . <nl> + Load Counter Size , in bytes , of the on disk data size this node manages . <nl> + TotalHints Counter Number of hint messages written to this node since [ re ] start . Includes one entry for each host to be hinted per hint . <nl> + TotalHintsInProgress Counter Number of hints attemping to be sent currently . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + HintedHandoff Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Metrics specific to Hinted Handoff . There are also some metrics related to hints tracked in ` ` Storage Metrics ` ` <nl> + <nl> + These metrics include the peer endpoint * * in the metric name * * <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . HintedHandOffManager . { { MetricName } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = HintedHandOffManager name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Hints _ created - { { PeerIP } } Counter Number of hints on disk for this peer . <nl> + Hints _ not _ stored - { { PeerIP } } Counter Number of hints not stored for this peer , due to being down past the configured hint window . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + SSTable Index Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Metrics specific to the SSTable index metadata . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . Index . { { MetricName } } . RowIndexEntry ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = Index scope = RowIndexEntry name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + IndexedEntrySize Histogram Histogram of the on - heap size , in bytes , of the index across all SSTables . <nl> + IndexInfoCount Histogram Histogram of the number of on - heap index entries managed across all SSTables . <nl> + IndexInfoGets Histogram Histogram of the number index seeks performed per SSTable . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + BufferPool Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Metrics specific to the internal recycled buffer pool Cassandra manages . This pool is meant to keep allocations and GC <nl> + lower by recycling on and off heap buffers . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . BufferPool . { { MetricName } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = BufferPool name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Size Gauge < Long > Size , in bytes , of the managed buffer pool <nl> + Misses Meter The rate of misses in the pool . The higher this is the more allocations incurred . <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + <nl> + Client Metrics <nl> + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + <nl> + Metrics specifc to client managment . <nl> + <nl> + Reported name format : <nl> + <nl> + * * Metric Name * * <nl> + ` ` org . apache . cassandra . metrics . Client . { { MetricName } } ` ` <nl> + <nl> + * * JMX MBean * * <nl> + ` ` org . apache . cassandra . metrics : type = Client name = { { MetricName } } ` ` <nl> + <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + Name Type Description <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + connectedNativeClients Counter Number of clients connected to this nodes native protocol server <nl> + connectedThriftClients Counter Number of clients connected to this nodes thrift protocol server <nl> + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> + <nl> JMX <nl> ^ ^ ^ <nl> - . . todo : : todo <nl> + <nl> + Any JMX based client can access metrics from cassandra . <nl> + <nl> + If you wish to access JMX metrics over http it ' s possible to download ` Mx4jTool < http : / / mx4j . sourceforge . net / > ` _ _ and <nl> + place ` ` mx4j - tools . jar ` ` into the classpath . On startup you will see in the log : : <nl> + <nl> + HttpAdaptor version 3 . 0 . 2 started on port 8081 <nl> + <nl> + To choose a different port ( 8081 is the default ) or a different listen address ( 0 . 0 . 0 . 0 is not the default ) edit <nl> + ` ` conf / cassandra - env . sh ` ` and uncomment : : <nl> + <nl> + # MX4J _ ADDRESS = " - Dmx4jaddress = 0 . 0 . 0 . 0 " <nl> + <nl> + # MX4J _ PORT = " - Dmx4jport = 8081 " <nl> + <nl> <nl> Metric Reporters <nl> ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> - . . todo : : todo <nl> + <nl> + As mentioned at the top of this section on monitoring the Cassandra metrics can be exported to a number of monitoring <nl> + system a number of ` built in < http : / / metrics . dropwizard . io / 3 . 1 . 0 / getting - started / # other - reporting > ` _ _ and ` third party <nl> + < http : / / metrics . dropwizard . io / 3 . 1 . 0 / manual / third - party / > ` _ _ reporter plugins . <nl> + <nl> + The configuration of these plugins is managed by the ` metrics reporter config project <nl> + < https : / / github . com / addthis / metrics - reporter - config > ` _ _ . There is a sample configuration file located at <nl> + ` ` conf / metrics - reporter - config - sample . yaml ` ` . <nl> + <nl> + Once configured , you simply start cassandra with the flag <nl> + ` ` - Dcassandra . metricsReporterConfigFile = metrics - reporter - config . yaml ` ` . The specified . yaml file plus any 3rd party <nl> + reporter jars must all be in Cassandra ' s classpath . <nl> <nl> Security <nl> - - - - - - - -
NEAREST DIFF (one line): diff - - git a / contrib / word _ count / README . txt b / contrib / word _ count / README . txt <nl> new file mode 100644 <nl> index 0000000 . . f46e2e2 <nl> - - - / dev / null <nl> + + + b / contrib / word _ count / README . txt <nl> @ @ - 0 , 0 + 1 , 18 @ @ <nl> + WordCount hadoop example : Inserts a bunch of words across multiple rows , <nl> + and counts them , with RandomPartitioner . <nl> + <nl> + The scripts in bin / assume you are running with cwd of contrib / word _ count . <nl> + <nl> + First build and start a Cassandra server with the default configuration * , <nl> + then run <nl> + <nl> + contrib / word _ count $ ant <nl> + contrib / word _ count $ bin / word _ count _ setup <nl> + contrib / word _ count $ bin / word _ count <nl> + <nl> + Output will be in / tmp / word _ count * . <nl> + <nl> + Read the code in src / for more details . <nl> + <nl> + * If you want to point wordcount at a real cluster , modify the seed <nl> + and listenaddress settings in storage - conf . xml accordingly . <nl> diff - - git a / contrib / word _ count / bin / word _ count b / contrib / word _ count / bin / word _ count <nl> new file mode 100644 <nl> index 0000000 . . a4eafc6 <nl> - - - / dev / null <nl> + + + b / contrib / word _ count / bin / word _ count <nl> @ @ - 0 , 0 + 1 , 53 @ @ <nl> + # ! / bin / sh <nl> + <nl> + # Licensed to the Apache Software Foundation ( ASF ) under one <nl> + # or more contributor license agreements . See the NOTICE file <nl> + # distributed with this work for additional information <nl> + # regarding copyright ownership . The ASF licenses this file <nl> + # to you under the Apache License , Version 2 . 0 ( the <nl> + # " License " ) ; you may not use this file except in compliance <nl> + # with the License . You may obtain a copy of the License at <nl> + # <nl> + # http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + # <nl> + # Unless required by applicable law or agreed to in writing , software <nl> + # distributed under the License is distributed on an " AS IS " BASIS , <nl> + # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + # See the License for the specific language governing permissions and <nl> + # limitations under the License . <nl> + <nl> + cwd = ` dirname $ 0 ` <nl> + <nl> + # Cassandra class files . <nl> + if [ ! - d $ cwd / . . / . . / . . / build / classes ] ; then <nl> + echo " Unable to locate cassandra class files " > & 2 <nl> + exit 1 <nl> + fi <nl> + <nl> + # word _ count Jar . <nl> + if [ ! - e $ cwd / . . / build / * . jar ] ; then <nl> + echo " Unable to locate word _ count jar " > & 2 <nl> + exit 1 <nl> + fi <nl> + <nl> + CLASSPATH = $ CLASSPATH : ` ls - 1 $ cwd / . . / build / * . jar ` <nl> + CLASSPATH = $ CLASSPATH : . : $ cwd / . . / . . / . . / build / classes <nl> + for jar in $ cwd / . . / . . / . . / lib / * . jar ; do <nl> + CLASSPATH = $ CLASSPATH : $ jar <nl> + done <nl> + for jar in $ cwd / . . / . . / . . / build / lib / jars / * . jar ; do <nl> + CLASSPATH = $ CLASSPATH : $ jar <nl> + done <nl> + <nl> + if [ - x $ JAVA _ HOME / bin / java ] ; then <nl> + JAVA = $ JAVA _ HOME / bin / java <nl> + else <nl> + JAVA = ` which java ` <nl> + fi <nl> + <nl> + if [ " x $ JAVA " = " x " ] ; then <nl> + echo " Java executable not found ( hint : set JAVA _ HOME ) " > & 2 <nl> + exit 1 <nl> + fi <nl> + <nl> + $ JAVA - Xmx1G - ea - cp $ CLASSPATH WordCount <nl> diff - - git a / contrib / word _ count / bin / word _ count _ setup b / contrib / word _ count / bin / word _ count _ setup <nl> new file mode 100644 <nl> index 0000000 . . 9af6562 <nl> - - - / dev / null <nl> + + + b / contrib / word _ count / bin / word _ count _ setup <nl> @ @ - 0 , 0 + 1 , 53 @ @ <nl> + # ! / bin / sh <nl> + <nl> + # Licensed to the Apache Software Foundation ( ASF ) under one <nl> + # or more contributor license agreements . See the NOTICE file <nl> + # distributed with this work for additional information <nl> + # regarding copyright ownership . The ASF licenses this file <nl> + # to you under the Apache License , Version 2 . 0 ( the <nl> + # " License " ) ; you may not use this file except in compliance <nl> + # with the License . You may obtain a copy of the License at <nl> + # <nl> + # http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + # <nl> + # Unless required by applicable law or agreed to in writing , software <nl> + # distributed under the License is distributed on an " AS IS " BASIS , <nl> + # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + # See the License for the specific language governing permissions and <nl> + # limitations under the License . <nl> + <nl> + cwd = ` dirname $ 0 ` <nl> + <nl> + # Cassandra class files . <nl> + if [ ! - d $ cwd / . . / . . / . . / build / classes ] ; then <nl> + echo " Unable to locate cassandra class files " > & 2 <nl> + exit 1 <nl> + fi <nl> + <nl> + # word _ count Jar . <nl> + if [ ! - e $ cwd / . . / build / * . jar ] ; then <nl> + echo " Unable to locate word _ count jar " > & 2 <nl> + exit 1 <nl> + fi <nl> + <nl> + CLASSPATH = $ CLASSPATH : ` ls - 1 $ cwd / . . / build / * . jar ` <nl> + CLASSPATH = $ CLASSPATH : . : $ cwd / . . / . . / . . / build / classes <nl> + for jar in $ cwd / . . / . . / . . / lib / * . jar ; do <nl> + CLASSPATH = $ CLASSPATH : $ jar <nl> + done <nl> + for jar in $ cwd / . . / . . / . . / build / lib / jars / * . jar ; do <nl> + CLASSPATH = $ CLASSPATH : $ jar <nl> + done <nl> + <nl> + if [ - x $ JAVA _ HOME / bin / java ] ; then <nl> + JAVA = $ JAVA _ HOME / bin / java <nl> + else <nl> + JAVA = ` which java ` <nl> + fi <nl> + <nl> + if [ " x $ JAVA " = " x " ] ; then <nl> + echo " Java executable not found ( hint : set JAVA _ HOME ) " > & 2 <nl> + exit 1 <nl> + fi <nl> + <nl> + $ JAVA - Xmx1G - ea - cp $ CLASSPATH WordCountSetup <nl> diff - - git a / contrib / word _ count / build . xml b / contrib / word _ count / build . xml <nl> new file mode 100644 <nl> index 0000000 . . e80dd10 <nl> - - - / dev / null <nl> + + + b / contrib / word _ count / build . xml <nl> @ @ - 0 , 0 + 1 , 65 @ @ <nl> + < ? xml version = " 1 . 0 " encoding = " UTF - 8 " ? > <nl> + < ! - - <nl> + ~ Licensed to the Apache Software Foundation ( ASF ) under one <nl> + ~ or more contributor license agreements . See the NOTICE file <nl> + ~ distributed with this work for additional information <nl> + ~ regarding copyright ownership . The ASF licenses this file <nl> + ~ to you under the Apache License , Version 2 . 0 ( the <nl> + ~ " License " ) ; you may not use this file except in compliance <nl> + ~ with the License . You may obtain a copy of the License at <nl> + ~ <nl> + ~ http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + ~ <nl> + ~ Unless required by applicable law or agreed to in writing , <nl> + ~ software distributed under the License is distributed on an <nl> + ~ " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY <nl> + ~ KIND , either express or implied . See the License for the <nl> + ~ specific language governing permissions and limitations <nl> + ~ under the License . <nl> + - - > <nl> + < project basedir = " . " default = " jar " name = " word _ count " > <nl> + < property name = " cassandra . dir " value = " . . / . . " / > <nl> + < property name = " cassandra . lib " value = " " / > <nl> + < property name = " cassandra . classes " value = " $ { cassandra . dir } / build / classes " / > <nl> + < property name = " build . src " value = " $ { basedir } / src " / > <nl> + < property name = " build . out " value = " $ { basedir } / build " / > <nl> + < property name = " build . classes " value = " $ { build . out } / classes " / > <nl> + < property name = " final . name " value = " word _ count " / > <nl> + <nl> + < target name = " init " > <nl> + < mkdir dir = " $ { build . classes } " / > <nl> + < / target > <nl> + <nl> + < target depends = " init " name = " build " > <nl> + < javac destdir = " $ { build . classes } " > <nl> + < src path = " $ { build . src } " / > <nl> + < classpath > <nl> + < path > <nl> + < fileset dir = " $ { cassandra . dir } / lib " > <nl> + < include name = " * * / * . jar " / > <nl> + < / fileset > <nl> + < fileset dir = " $ { cassandra . dir } / build / lib / jars " > <nl> + < include name = " * * / * . jar " / > <nl> + < / fileset > <nl> + < pathelement location = " $ { cassandra . classes } " / > <nl> + < / path > <nl> + < / classpath > <nl> + < / javac > <nl> + < / target > <nl> + <nl> + < target name = " jar " depends = " build " > <nl> + < mkdir dir = " $ { build . classes } / META - INF " / > <nl> + < jar jarfile = " $ { build . out } / $ { final . name } . jar " > <nl> + < fileset dir = " $ { build . classes } " / > <nl> + < fileset dir = " $ { cassandra . classes } " / > <nl> + < fileset dir = " $ { cassandra . dir } " > <nl> + < include name = " lib / * * / * . jar " / > <nl> + < / fileset > <nl> + < fileset file = " $ { basedir } / storage - conf . xml " / > <nl> + < / jar > <nl> + < / target > <nl> + <nl> + < target name = " clean " > <nl> + < delete dir = " $ { build . out } " / > <nl> + < / target > <nl> + < / project > <nl> diff - - git a / contrib / word _ count / src / WordCount . java b / contrib / word _ count / src / WordCount . java <nl> new file mode 100644 <nl> index 0000000 . . bcd30f9 <nl> - - - / dev / null <nl> + + + b / contrib / word _ count / src / WordCount . java <nl> @ @ - 0 , 0 + 1 , 107 @ @ <nl> + import java . io . IOException ; <nl> + import java . util . SortedMap ; <nl> + import java . util . StringTokenizer ; <nl> + <nl> + import org . apache . log4j . Logger ; <nl> + <nl> + import org . apache . cassandra . db . IColumn ; <nl> + import org . apache . cassandra . hadoop . ColumnFamilyInputFormat ; <nl> + import org . apache . hadoop . conf . Configuration ; <nl> + import org . apache . hadoop . conf . Configured ; <nl> + import org . apache . hadoop . fs . Path ; <nl> + import org . apache . hadoop . io . IntWritable ; <nl> + import org . apache . hadoop . io . Text ; <nl> + import org . apache . hadoop . mapreduce . Job ; <nl> + import org . apache . hadoop . mapreduce . Mapper ; <nl> + import org . apache . hadoop . mapreduce . Reducer ; <nl> + import org . apache . hadoop . mapreduce . lib . output . FileOutputFormat ; <nl> + import org . apache . hadoop . util . Tool ; <nl> + import org . apache . hadoop . util . ToolRunner ; <nl> + <nl> + / * * <nl> + * This counts the occurrences of words in ColumnFamily Standard1 , that has a single column ( that we care about ) <nl> + * " text " containing a sequence of words . <nl> + * <nl> + * For each word , we output the total number of occurrences across all texts . <nl> + * / <nl> + public class WordCount extends Configured implements Tool <nl> + { <nl> + private static final Logger logger = Logger . getLogger ( WordCount . class ) ; <nl> + <nl> + static final String KEYSPACE = " Keyspace1 " ; <nl> + static final String COLUMN _ FAMILY = " Standard1 " ; <nl> + private static String columnName ; <nl> + private static final String OUTPUT _ PATH _ PREFIX = " / tmp / word _ count " ; <nl> + static final int RING _ DELAY = 3000 ; / / this is enough for testing a single server node ; may need more for a real cluster <nl> + <nl> + public static void main ( String [ ] args ) throws Exception <nl> + { <nl> + / / Let ToolRunner handle generic command - line options <nl> + ToolRunner . run ( new Configuration ( ) , new WordCount ( ) , args ) ; <nl> + System . exit ( 0 ) ; <nl> + } <nl> + <nl> + public static class TokenizerMapper extends Mapper < String , SortedMap < byte [ ] , IColumn > , Text , IntWritable > <nl> + { <nl> + private final static IntWritable one = new IntWritable ( 1 ) ; <nl> + private Text word = new Text ( ) ; <nl> + <nl> + public void map ( String key , SortedMap < byte [ ] , IColumn > columns , Context context ) throws IOException , InterruptedException <nl> + { <nl> + if ( columns = = null ) <nl> + return ; <nl> + IColumn column = columns . get ( columnName . getBytes ( ) ) ; <nl> + String value = new String ( column . value ( ) ) ; <nl> + logger . debug ( " read " + key + " : " + value + " from " + context . getInputSplit ( ) ) ; <nl> + <nl> + StringTokenizer itr = new StringTokenizer ( value ) ; <nl> + while ( itr . hasMoreTokens ( ) ) <nl> + { <nl> + word . set ( itr . nextToken ( ) ) ; <nl> + context . write ( word , one ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + public static class IntSumReducer extends Reducer < Text , IntWritable , Text , IntWritable > <nl> + { <nl> + private IntWritable result = new IntWritable ( ) ; <nl> + <nl> + public void reduce ( Text key , Iterable < IntWritable > values , Context context ) throws IOException , InterruptedException <nl> + { <nl> + int sum = 0 ; <nl> + for ( IntWritable val : values ) <nl> + { <nl> + sum + = val . get ( ) ; <nl> + } <nl> + <nl> + result . set ( sum ) ; <nl> + context . write ( key , result ) ; <nl> + } <nl> + } <nl> + <nl> + public int run ( String [ ] args ) throws Exception <nl> + { <nl> + Configuration conf = getConf ( ) ; <nl> + <nl> + for ( int i = 0 ; i < WordCountSetup . TEST _ COUNT ; i + + ) <nl> + { <nl> + columnName = " text " + i ; <nl> + Job job = new Job ( conf , " wordcount " ) ; <nl> + job . setJarByClass ( WordCount . class ) ; <nl> + job . setMapperClass ( TokenizerMapper . class ) ; <nl> + job . setCombinerClass ( IntSumReducer . class ) ; <nl> + job . setReducerClass ( IntSumReducer . class ) ; <nl> + job . setOutputKeyClass ( Text . class ) ; <nl> + job . setOutputValueClass ( IntWritable . class ) ; <nl> + <nl> + job . setInputFormatClass ( ColumnFamilyInputFormat . class ) ; <nl> + FileOutputFormat . setOutputPath ( job , new Path ( OUTPUT _ PATH _ PREFIX + i ) ) ; <nl> + <nl> + ColumnFamilyInputFormat . setColumnFamily ( job , KEYSPACE , COLUMN _ FAMILY ) ; <nl> + <nl> + job . waitForCompletion ( true ) ; <nl> + } <nl> + return 0 ; <nl> + } <nl> + } <nl> \ No newline at end of file <nl> diff - - git a / contrib / word _ count / src / WordCountSetup . java b / contrib / word _ count / src / WordCountSetup . java <nl> new file mode 100644 <nl> index 0000000 . . 74ab87a <nl> - - - / dev / null <nl> + + + b / contrib / word _ count / src / WordCountSetup . java <nl> @ @ - 0 , 0 + 1 , 61 @ @ <nl> + import java . util . Arrays ; <nl> + <nl> + import org . apache . log4j . Logger ; <nl> + <nl> + import org . apache . cassandra . db . * ; <nl> + import org . apache . cassandra . service . StorageProxy ; <nl> + import org . apache . cassandra . service . StorageService ; <nl> + import org . apache . cassandra . thrift . ConsistencyLevel ; <nl> + <nl> + public class WordCountSetup <nl> + { <nl> + private static final Logger logger = Logger . getLogger ( WordCountSetup . class ) ; <nl> + <nl> + public static final int TEST _ COUNT = 4 ; <nl> + <nl> + public static void main ( String [ ] args ) throws Exception <nl> + { <nl> + StorageService . instance . initClient ( ) ; <nl> + logger . info ( " Sleeping " + WordCount . RING _ DELAY ) ; <nl> + Thread . sleep ( WordCount . RING _ DELAY ) ; <nl> + assert ! StorageService . instance . getLiveNodes ( ) . isEmpty ( ) ; <nl> + <nl> + RowMutation rm ; <nl> + ColumnFamily cf ; <nl> + byte [ ] columnName ; <nl> + <nl> + / / text0 : no rows <nl> + <nl> + / / text1 : 1 row , 1 word <nl> + columnName = " text1 " . getBytes ( ) ; <nl> + rm = new RowMutation ( WordCount . KEYSPACE , " Key0 " ) ; <nl> + cf = ColumnFamily . create ( WordCount . KEYSPACE , WordCount . COLUMN _ FAMILY ) ; <nl> + cf . addColumn ( new Column ( columnName , " word1 " . getBytes ( ) , 0 ) ) ; <nl> + rm . add ( cf ) ; <nl> + StorageProxy . mutateBlocking ( Arrays . asList ( rm ) , ConsistencyLevel . ONE ) ; <nl> + logger . info ( " added text1 " ) ; <nl> + <nl> + / / text2 : 1 row , 2 words <nl> + columnName = " text2 " . getBytes ( ) ; <nl> + rm = new RowMutation ( WordCount . KEYSPACE , " Key0 " ) ; <nl> + cf = ColumnFamily . create ( WordCount . KEYSPACE , WordCount . COLUMN _ FAMILY ) ; <nl> + cf . addColumn ( new Column ( columnName , " word1 word2 " . getBytes ( ) , 0 ) ) ; <nl> + rm . add ( cf ) ; <nl> + StorageProxy . mutateBlocking ( Arrays . asList ( rm ) , ConsistencyLevel . ONE ) ; <nl> + logger . info ( " added text2 " ) ; <nl> + <nl> + / / text3 : 1000 rows , 1 word <nl> + columnName = " text3 " . getBytes ( ) ; <nl> + for ( int i = 0 ; i < 1000 ; i + + ) <nl> + { <nl> + rm = new RowMutation ( WordCount . KEYSPACE , " Key " + i ) ; <nl> + cf = ColumnFamily . create ( WordCount . KEYSPACE , WordCount . COLUMN _ FAMILY ) ; <nl> + cf . addColumn ( new Column ( columnName , " word1 " . getBytes ( ) , 0 ) ) ; <nl> + rm . add ( cf ) ; <nl> + StorageProxy . mutateBlocking ( Arrays . asList ( rm ) , ConsistencyLevel . ONE ) ; <nl> + } <nl> + logger . info ( " added text3 " ) ; <nl> + <nl> + System . exit ( 0 ) ; <nl> + } <nl> + } <nl> diff - - git a / contrib / word _ count / storage - conf . xml b / contrib / word _ count / storage - conf . xml <nl> new file mode 100644 <nl> index 0000000 . . 0d591d9 <nl> - - - / dev / null <nl> + + + b / contrib / word _ count / storage - conf . xml <nl> @ @ - 0 , 0 + 1 , 369 @ @ <nl> + < ! - - <nl> + ~ Licensed to the Apache Software Foundation ( ASF ) under one <nl> + ~ or more contributor license agreements . See the NOTICE file <nl> + ~ distributed with this work for additional information <nl> + ~ regarding copyright ownership . The ASF licenses this file <nl> + ~ to you under the Apache License , Version 2 . 0 ( the <nl> + ~ " License " ) ; you may not use this file except in compliance <nl> + ~ with the License . You may obtain a copy of the License at <nl> + ~ <nl> + ~ http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + ~ <nl> + ~ Unless required by applicable law or agreed to in writing , <nl> + ~ software distributed under the License is distributed on an <nl> + ~ " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY <nl> + ~ KIND , either express or implied . See the License for the <nl> + ~ specific language governing permissions and limitations <nl> + ~ under the License . <nl> + - - > <nl> + < Storage > <nl> + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> + < ! - - Basic Configuration - - > <nl> + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> + <nl> + < ! - - <nl> + ~ The name of this cluster . This is mainly used to prevent machines in <nl> + ~ one logical cluster from joining another . <nl> + - - > <nl> + < ClusterName > Test Cluster < / ClusterName > <nl> + <nl> + < ! - - <nl> + ~ Turn on to make new [ non - seed ] nodes automatically migrate the right data <nl> + ~ to themselves . ( If no InitialToken is specified , they will pick one <nl> + ~ such that they will get half the range of the most - loaded node . ) <nl> + ~ If a node starts up without bootstrapping , it will mark itself bootstrapped <nl> + ~ so that you can ' t subsequently accidently bootstrap a node with <nl> + ~ data on it . ( You can reset this by wiping your data and commitlog <nl> + ~ directories . ) <nl> + ~ <nl> + ~ Off by default so that new clusters and upgraders from 0 . 4 don ' t <nl> + ~ bootstrap immediately . You should turn this on when you start adding <nl> + ~ new nodes to a cluster that already has data on it . ( If you are upgrading <nl> + ~ from 0 . 4 , start your cluster with it off once before changing it to true . <nl> + ~ Otherwise , no data will be lost but you will incur a lot of unnecessary <nl> + ~ I / O before your cluster starts up . ) <nl> + - - > <nl> + < AutoBootstrap > false < / AutoBootstrap > <nl> + <nl> + < ! - - <nl> + ~ Keyspaces and ColumnFamilies : <nl> + ~ A ColumnFamily is the Cassandra concept closest to a relational <nl> + ~ table . Keyspaces are separate groups of ColumnFamilies . Except in <nl> + ~ very unusual circumstances you will have one Keyspace per application . <nl> + <nl> + ~ There is an implicit keyspace named ' system ' for Cassandra internals . <nl> + - - > <nl> + < Keyspaces > <nl> + < Keyspace Name = " Keyspace1 " > <nl> + < ! - - <nl> + ~ ColumnFamily definitions have one required attribute ( Name ) <nl> + ~ and several optional ones . <nl> + ~ <nl> + ~ The CompareWith attribute tells Cassandra how to sort the columns <nl> + ~ for slicing operations . The default is BytesType , which is a <nl> + ~ straightforward lexical comparison of the bytes in each column . <nl> + ~ Other options are AsciiType , UTF8Type , LexicalUUIDType , TimeUUIDType , <nl> + ~ and LongType . You can also specify the fully - qualified class <nl> + ~ name to a class of your choice extending <nl> + ~ org . apache . cassandra . db . marshal . AbstractType . <nl> + ~ <nl> + ~ SuperColumns have a similar CompareSubcolumnsWith attribute . <nl> + ~ <nl> + ~ BytesType : Simple sort by byte value . No validation is performed . <nl> + ~ AsciiType : Like BytesType , but validates that the input can be <nl> + ~ parsed as US - ASCII . <nl> + ~ UTF8Type : A string encoded as UTF8 <nl> + ~ LongType : A 64bit long <nl> + ~ LexicalUUIDType : A 128bit UUID , compared lexically ( by byte value ) <nl> + ~ TimeUUIDType : a 128bit version 1 UUID , compared by timestamp <nl> + ~ <nl> + ~ ( To get the closest approximation to 0 . 3 - style supercolumns , you <nl> + ~ would use CompareWith = UTF8Type CompareSubcolumnsWith = LongType . ) <nl> + ~ <nl> + ~ An optional ` Comment ` attribute may be used to attach additional <nl> + ~ human - readable information about the column family to its definition . <nl> + ~ <nl> + ~ The optional KeysCachedFraction attribute specifies <nl> + ~ The fraction of keys per sstable whose locations we keep in <nl> + ~ memory in " mostly LRU " order . ( JUST the key locations , NOT any <nl> + ~ column values . ) The amount of memory used by the default setting of <nl> + ~ 0 . 01 is comparable to the amount used by the internal per - sstable key <nl> + ~ index . Consider increasing this if you have fewer , wider rows . <nl> + ~ Set to 0 to disable entirely . <nl> + ~ <nl> + ~ The optional RowsCached attribute specifies the number of rows <nl> + ~ whose entire contents we cache in memory , either as a fixed number <nl> + ~ of rows or as a percent of rows in the ColumnFamily . <nl> + ~ Do not use this on ColumnFamilies with large rows , or <nl> + ~ ColumnFamilies with high write : read ratios . As with key caching , <nl> + ~ valid values are from 0 to 1 . The default 0 disables it entirely . <nl> + - - > <nl> + < ColumnFamily CompareWith = " BytesType " <nl> + Name = " Standard1 " <nl> + RowsCached = " 10 % " <nl> + KeysCachedFraction = " 0 " / > <nl> + < ColumnFamily CompareWith = " UTF8Type " Name = " Standard2 " / > <nl> + < ColumnFamily CompareWith = " TimeUUIDType " Name = " StandardByUUID1 " / > <nl> + < ColumnFamily ColumnType = " Super " <nl> + CompareWith = " UTF8Type " <nl> + CompareSubcolumnsWith = " UTF8Type " <nl> + Name = " Super1 " <nl> + RowsCached = " 1000 " <nl> + KeysCachedFraction = " 0 " <nl> + Comment = " A column family with supercolumns , whose column and subcolumn names are UTF8 strings " / > <nl> + <nl> + < ! - - <nl> + ~ Strategy : Setting this to the class that implements <nl> + ~ IReplicaPlacementStrategy will change the way the node picker works . <nl> + ~ Out of the box , Cassandra provides <nl> + ~ org . apache . cassandra . locator . RackUnawareStrategy and <nl> + ~ org . apache . cassandra . locator . RackAwareStrategy ( place one replica in <nl> + ~ a different datacenter , and the others on different racks in the same <nl> + ~ one . ) <nl> + - - > <nl> + < ReplicaPlacementStrategy > org . apache . cassandra . locator . RackUnawareStrategy < / ReplicaPlacementStrategy > <nl> + <nl> + < ! - - Number of replicas of the data - - > <nl> + < ReplicationFactor > 1 < / ReplicationFactor > <nl> + <nl> + < ! - - <nl> + ~ EndPointSnitch : Setting this to the class that implements <nl> + ~ AbstractEndpointSnitch , which lets Cassandra know enough <nl> + ~ about your network topology to route requests efficiently . <nl> + ~ Out of the box , Cassandra provides org . apache . cassandra . locator . EndPointSnitch , <nl> + ~ and PropertyFileEndPointSnitch is available in contrib / . <nl> + - - > <nl> + < EndPointSnitch > org . apache . cassandra . locator . EndPointSnitch < / EndPointSnitch > <nl> + < / Keyspace > <nl> + < / Keyspaces > <nl> + <nl> + < ! - - <nl> + ~ Authenticator : any IAuthenticator may be used , including your own as long <nl> + ~ as it is on the classpath . Out of the box , Cassandra provides <nl> + ~ org . apache . cassandra . auth . AllowAllAuthenticator and , <nl> + ~ org . apache . cassandra . auth . SimpleAuthenticator <nl> + ~ ( SimpleAuthenticator uses access . properties and passwd . properties by <nl> + ~ default ) . <nl> + ~ <nl> + ~ If you don ' t specify an authenticator , AllowAllAuthenticator is used . <nl> + - - > <nl> + < Authenticator > org . apache . cassandra . auth . AllowAllAuthenticator < / Authenticator > <nl> + <nl> + < ! - - <nl> + ~ Partitioner : any IPartitioner may be used , including your own as long <nl> + ~ as it is on the classpath . Out of the box , Cassandra provides <nl> + ~ org . apache . cassandra . dht . RandomPartitioner , <nl> + ~ org . apache . cassandra . dht . OrderPreservingPartitioner , and <nl> + ~ org . apache . cassandra . dht . CollatingOrderPreservingPartitioner . <nl> + ~ ( CollatingOPP colates according to EN , US rules , not naive byte <nl> + ~ ordering . Use this as an example if you need locale - aware collation . ) <nl> + ~ Range queries require using an order - preserving partitioner . <nl> + ~ <nl> + ~ Achtung ! Changing this parameter requires wiping your data <nl> + ~ directories , since the partitioner can modify the sstable on - disk <nl> + ~ format . <nl> + - - > <nl> + < Partitioner > org . apache . cassandra . dht . RandomPartitioner < / Partitioner > <nl> + <nl> + < ! - - <nl> + ~ If you are using an order - preserving partitioner and you know your key <nl> + ~ distribution , you can specify the token for this node to use . ( Keys <nl> + ~ are sent to the node with the " closest " token , so distributing your <nl> + ~ tokens equally along the key distribution space will spread keys <nl> + ~ evenly across your cluster . ) This setting is only checked the first <nl> + ~ time a node is started . <nl> + <nl> + ~ This can also be useful with RandomPartitioner to force equal spacing <nl> + ~ of tokens around the hash space , especially for clusters with a small <nl> + ~ number of nodes . <nl> + - - > <nl> + < InitialToken > < / InitialToken > <nl> + <nl> + < ! - - <nl> + ~ Directories : Specify where Cassandra should store different data on <nl> + ~ disk . Keep the data disks and the CommitLog disks separate for best <nl> + ~ performance <nl> + - - > <nl> + < CommitLogDirectory > / var / lib / cassandra / commitlog < / CommitLogDirectory > <nl> + < DataFileDirectories > <nl> + < DataFileDirectory > / var / lib / cassandra / data < / DataFileDirectory > <nl> + < / DataFileDirectories > <nl> + < CalloutLocation > / var / lib / cassandra / callouts < / CalloutLocation > <nl> + < StagingFileDirectory > / var / lib / cassandra / staging < / StagingFileDirectory > <nl> + <nl> + <nl> + < ! - - <nl> + ~ Addresses of hosts that are deemed contact points . Cassandra nodes <nl> + ~ use this list of hosts to find each other and learn the topology of <nl> + ~ the ring . You must change this if you are running multiple nodes ! <nl> + - - > <nl> + < Seeds > <nl> + < Seed > 127 . 0 . 0 . 1 < / Seed > <nl> + < / Seeds > <nl> + <nl> + <nl> + < ! - - Miscellaneous - - > <nl> + <nl> + < ! - - Time to wait for a reply from other nodes before failing the command - - > <nl> + < RpcTimeoutInMillis > 5000 < / RpcTimeoutInMillis > <nl> + < ! - - Size to allow commitlog to grow to before creating a new segment - - > <nl> + < CommitLogRotationThresholdInMB > 128 < / CommitLogRotationThresholdInMB > <nl> + <nl> + <nl> + < ! - - Local hosts and ports - - > <nl> + <nl> + < ! - - <nl> + ~ Address to bind to and tell other nodes to connect to . You _ must _ <nl> + ~ change this if you want multiple nodes to be able to communicate ! <nl> + ~ <nl> + ~ Leaving it blank leaves it up to InetAddress . getLocalHost ( ) . This <nl> + ~ will always do the Right Thing * if * the node is properly configured <nl> + ~ ( hostname , name resolution , etc ) , and the Right Thing is to use the <nl> + ~ address associated with the hostname ( it might not be ) . <nl> + - - > <nl> + < ListenAddress > 127 . 0 . 0 . 2 < / ListenAddress > <nl> + < ! - - internal communications port - - > <nl> + < StoragePort > 7000 < / StoragePort > <nl> + <nl> + < ! - - <nl> + ~ The address to bind the Thrift RPC service to . Unlike ListenAddress <nl> + ~ above , you * can * specify 0 . 0 . 0 . 0 here if you want Thrift to listen on <nl> + ~ all interfaces . <nl> + ~ <nl> + ~ Leaving this blank has the same effect it does for ListenAddress , <nl> + ~ ( i . e . it will be based on the configured hostname of the node ) . <nl> + - - > <nl> + < ThriftAddress > 127 . 0 . 0 . 2 < / ThriftAddress > <nl> + < ! - - Thrift RPC port ( the port clients connect to ) . - - > <nl> + < ThriftPort > 9160 < / ThriftPort > <nl> + < ! - - <nl> + ~ Whether or not to use a framed transport for Thrift . If this option <nl> + ~ is set to true then you must also use a framed transport on the <nl> + ~ client - side , ( framed and non - framed transports are not compatible ) . <nl> + - - > <nl> + < ThriftFramedTransport > false < / ThriftFramedTransport > <nl> + <nl> + <nl> + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> + < ! - - Memory , Disk , and Performance - - > <nl> + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> + <nl> + < ! - - <nl> + ~ Access mode . mmapped i / o is substantially faster , but only practical on <nl> + ~ a 64bit machine ( which notably does not include EC2 " small " instances ) <nl> + ~ or relatively small datasets . " auto " , the safe choice , will enable <nl> + ~ mmapping on a 64bit JVM . Other values are " mmap " , " mmap _ index _ only " <nl> + ~ ( which may allow you to get part of the benefits of mmap on a 32bit <nl> + ~ machine by mmapping only index files ) and " standard " . <nl> + ~ ( The buffer size settings that follow only apply to standard , <nl> + ~ non - mmapped i / o . ) <nl> + - - > <nl> + < DiskAccessMode > auto < / DiskAccessMode > <nl> + <nl> + < ! - - <nl> + ~ Buffer size to use when performing contiguous column slices . Increase <nl> + ~ this to the size of the column slices you typically perform . <nl> + ~ ( Name - based queries are performed with a buffer size of <nl> + ~ ColumnIndexSizeInKB . ) <nl> + - - > <nl> + < SlicedBufferSizeInKB > 64 < / SlicedBufferSizeInKB > <nl> + <nl> + < ! - - <nl> + ~ Buffer size to use when flushing memtables to disk . ( Only one <nl> + ~ memtable is ever flushed at a time . ) Increase ( decrease ) the index <nl> + ~ buffer size relative to the data buffer if you have few ( many ) <nl> + ~ columns per key . Bigger is only better _ if _ your memtables get large <nl> + ~ enough to use the space . ( Check in your data directory after your <nl> + ~ app has been running long enough . ) - - > <nl> + < FlushDataBufferSizeInMB > 32 < / FlushDataBufferSizeInMB > <nl> + < FlushIndexBufferSizeInMB > 8 < / FlushIndexBufferSizeInMB > <nl> + <nl> + < ! - - <nl> + ~ Add column indexes to a row after its contents reach this size . <nl> + ~ Increase if your column values are large , or if you have a very large <nl> + ~ number of columns . The competing causes are , Cassandra has to <nl> + ~ deserialize this much of the row to read a single column , so you want <nl> + ~ it to be small - at least if you do many partial - row reads - but all <nl> + ~ the index data is read for each access , so you don ' t want to generate <nl> + ~ that wastefully either . <nl> + - - > <nl> + < ColumnIndexSizeInKB > 64 < / ColumnIndexSizeInKB > <nl> + <nl> + < ! - - <nl> + ~ Flush memtable after this much data has been inserted , including <nl> + ~ overwritten data . There is one memtable per column family , and <nl> + ~ this threshold is based solely on the amount of data stored , not <nl> + ~ actual heap memory usage ( there is some overhead in indexing the <nl> + ~ columns ) . <nl> + - - > <nl> + < MemtableThroughputInMB > 64 < / MemtableThroughputInMB > <nl> + < ! - - <nl> + ~ Throughput setting for Binary Memtables . Typically these are <nl> + ~ used for bulk load so you want them to be larger . <nl> + - - > <nl> + < BinaryMemtableThroughputInMB > 256 < / BinaryMemtableThroughputInMB > <nl> + < ! - - <nl> + ~ The maximum number of columns in millions to store in memory per <nl> + ~ ColumnFamily before flushing to disk . This is also a per - memtable <nl> + ~ setting . Use with MemtableThroughputInMB to tune memory usage . <nl> + - - > <nl> + < MemtableOperationsInMillions > 0 . 1 < / MemtableOperationsInMillions > <nl> + < ! - - <nl> + ~ The maximum time to leave a dirty memtable unflushed . <nl> + ~ ( While any affected columnfamilies have unflushed data from a <nl> + ~ commit log segment , that segment cannot be deleted . ) <nl> + ~ This needs to be large enough that it won ' t cause a flush storm <nl> + ~ of all your memtables flushing at once because none has hit <nl> + ~ the size or count thresholds yet . For production , a larger <nl> + ~ value such as 1440 is recommended . <nl> + - - > <nl> + < MemtableFlushAfterMinutes > 60 < / MemtableFlushAfterMinutes > <nl> + <nl> + < ! - - <nl> + ~ Unlike most systems , in Cassandra writes are faster than reads , so <nl> + ~ you can afford more of those in parallel . A good rule of thumb is 2 <nl> + ~ concurrent reads per processor core . Increase ConcurrentWrites to <nl> + ~ the number of clients writing at once if you enable CommitLogSync + <nl> + ~ CommitLogSyncDelay . - - > <nl> + < ConcurrentReads > 8 < / ConcurrentReads > <nl> + < ConcurrentWrites > 32 < / ConcurrentWrites > <nl> + <nl> + < ! - - <nl> + ~ CommitLogSync may be either " periodic " or " batch . " When in batch <nl> + ~ mode , Cassandra won ' t ack writes until the commit log has been <nl> + ~ fsynced to disk . It will wait up to CommitLogSyncBatchWindowInMS <nl> + ~ milliseconds for other writes , before performing the sync . <nl> + <nl> + ~ This is less necessary in Cassandra than in traditional databases <nl> + ~ since replication reduces the odds of losing data from a failure <nl> + ~ after writing the log entry but before it actually reaches the disk . <nl> + ~ So the other option is " timed , " where writes may be acked immediately <nl> + ~ and the CommitLog is simply synced every CommitLogSyncPeriodInMS <nl> + ~ milliseconds . <nl> + - - > <nl> + < CommitLogSync > periodic < / CommitLogSync > <nl> + < ! - - <nl> + ~ Interval at which to perform syncs of the CommitLog in periodic mode . <nl> + ~ Usually the default of 10000ms is fine ; increase it if your i / o <nl> + ~ load is such that syncs are taking excessively long times . <nl> + - - > <nl> + < CommitLogSyncPeriodInMS > 10000 < / CommitLogSyncPeriodInMS > <nl> + < ! - - <nl> + ~ Delay ( in milliseconds ) during which additional commit log entries <nl> + ~ may be written before fsync in batch mode . This will increase <nl> + ~ latency slightly , but can vastly improve throughput where there are <nl> + ~ many writers . Set to zero to disable ( each entry will be synced <nl> + ~ individually ) . Reasonable values range from a minimal 0 . 1 to 10 or <nl> + ~ even more if throughput matters more than latency . <nl> + - - > <nl> + < ! - - < CommitLogSyncBatchWindowInMS > 1 < / CommitLogSyncBatchWindowInMS > - - > <nl> + <nl> + < ! - - <nl> + ~ Time to wait before garbage - collection deletion markers . Set this to <nl> + ~ a large enough value that you are confident that the deletion marker <nl> + ~ will be propagated to all replicas by the time this many seconds has <nl> + ~ elapsed , even in the face of hardware failures . The default value is <nl> + ~ ten days . <nl> + - - > <nl> + < GCGraceSeconds > 864000 < / GCGraceSeconds > <nl> + < / Storage > <nl> diff - - git a / ivy . xml b / ivy . xml <nl> index b85534c . . 02a264d 100644 <nl> - - - a / ivy . xml <nl> + + + b / ivy . xml <nl> @ @ - 19 , 8 + 19 , 11 @ @ <nl> < ivy - module version = " 2 . 0 " > <nl> < info organisation = " apache - cassandra " module = " cassandra " / > <nl> < dependencies > <nl> - < dependency org = " org . apache . mahout . hadoop " <nl> - name = " hadoop - core " rev = " 0 . 20 . 1 " / > <nl> + < ! - - for hadoop - - > <nl> + < dependency org = " commons - logging " name = " commons - logging " rev = " 1 . 1 . 1 " / > <nl> + < dependency org = " org . apache . mahout . hadoop " name = " hadoop - core " rev = " 0 . 20 . 1 " / > <nl> + < dependency org = " commons - httpclient " name = " commons - httpclient " rev = " 3 . 1 " / > <nl> + <nl> < ! - - FIXME : paranamer and jackson can be dropped after we ' re depending <nl> on avro ( since it depends on them ) . - - > <nl> < dependency org = " com . thoughtworks . paranamer " <nl> diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> index d3898b1 . . a83bdf0 100644 <nl> - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> @ @ - 42 , 6 + 42 , 7 @ @ import java . lang . reflect . InvocationTargetException ; <nl> import java . util . * ; <nl> import java . net . InetAddress ; <nl> import java . net . UnknownHostException ; <nl> + import java . net . URL ; <nl> <nl> public class DatabaseDescriptor <nl> { <nl> @ @ - 145 , 11 + 146 , 29 @ @ public class DatabaseDescriptor <nl> <nl> private static IAuthenticator authenticator = new AllowAllAuthenticator ( ) ; <nl> <nl> + private final static String STORAGE _ CONF _ FILE = " storage - conf . xml " ; <nl> + <nl> + / * * <nl> + * Try the storage - config system property , and then inspect the classpath . <nl> + * / <nl> + static String getStorageConfigPath ( ) <nl> + { <nl> + String scp = System . getProperty ( " storage - config " ) + File . separator + STORAGE _ CONF _ FILE ; <nl> + if ( new File ( scp ) . exists ( ) ) <nl> + return scp ; <nl> + / / try the classpath <nl> + ClassLoader loader = DatabaseDescriptor . class . getClassLoader ( ) ; <nl> + URL scpurl = loader . getResource ( STORAGE _ CONF _ FILE ) ; <nl> + if ( scpurl ! = null ) <nl> + return scpurl . getFile ( ) ; <nl> + throw new RuntimeException ( " Cannot locate " + STORAGE _ CONF _ FILE + " via storage - config system property or classpath lookup . " ) ; <nl> + } <nl> + <nl> static <nl> { <nl> try <nl> { <nl> - configFileName _ = System . getProperty ( " storage - config " ) + File . separator + " storage - conf . xml " ; <nl> + configFileName _ = getStorageConfigPath ( ) ; <nl> if ( logger _ . isDebugEnabled ( ) ) <nl> logger _ . debug ( " Loading settings from " + configFileName _ ) ; <nl> XMLUtils xmlUtils = new XMLUtils ( configFileName _ ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / RangeSliceCommand . java b / src / java / org / apache / cassandra / db / RangeSliceCommand . java <nl> index d279f62 . . 07fd5e0 100644 <nl> - - - a / src / java / org / apache / cassandra / db / RangeSliceCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / RangeSliceCommand . java <nl> @ @ - 39 , 7 + 39 , 6 @ @ package org . apache . cassandra . db ; <nl> import org . apache . cassandra . concurrent . StageManager ; <nl> <nl> import org . apache . cassandra . dht . AbstractBounds ; <nl> - import org . apache . cassandra . dht . Bounds ; <nl> import org . apache . cassandra . io . util . DataOutputBuffer ; <nl> import org . apache . cassandra . io . ICompactSerializer ; <nl> import org . apache . cassandra . net . Message ; <nl> @ @ - 129 , 7 + 128 , 7 @ @ class RangeSliceCommandSerializer implements ICompactSerializer < RangeSliceComman <nl> <nl> TSerializer ser = new TSerializer ( new TBinaryProtocol . Factory ( ) ) ; <nl> FBUtilities . serialize ( ser , sliceCommand . predicate , dos ) ; <nl> - Bounds . serializer ( ) . serialize ( sliceCommand . range , dos ) ; <nl> + AbstractBounds . serializer ( ) . serialize ( sliceCommand . range , dos ) ; <nl> dos . writeInt ( sliceCommand . max _ keys ) ; <nl> } <nl>

TEST DIFF:
diff - - git a / doc / source / _ static / extra . css b / doc / source / _ static / extra . css 
 index ec6aa3f . . ff9f1d1 100644 
 - - - a / doc / source / _ static / extra . css 
 + + + b / doc / source / _ static / extra . css 
 @ @ - 17 , 3 + 17 , 15 @ @ a . reference . internal code . literal { 
 a . reference . internal : visited code . literal { 
 color : # 9B59B6 ; 
 } 
 + 
 + 
 + / * override table width restrictions * / 
 + . wy - table - responsive table td , . wy - table - responsive table th { 
 + white - space : normal ; 
 + } 
 + 
 + . wy - table - responsive { 
 + margin - bottom : 24px ; 
 + max - width : 100 % ; 
 + overflow : visible ; 
 + } 
 diff - - git a / doc / source / operations . rst b / doc / source / operations . rst 
 index d7fcafb . . 31ecc35 100644 
 - - - a / doc / source / operations . rst 
 + + + b / doc / source / operations . rst 
 @ @ - 833 , 13 + 833 , 604 @ @ Backups 
 Monitoring 
 - - - - - - - - - - 
 
 + Metrics in Cassandra are managed using the ` Dropwizard Metrics < http : / / metrics . dropwizard . io > ` _ _ library . These metrics 
 + can be queried via JMX or pushed to external monitoring systems using a number of ` built in 
 + < http : / / metrics . dropwizard . io / 3 . 1 . 0 / getting - started / # other - reporting > ` _ _ and ` third party 
 + < http : / / metrics . dropwizard . io / 3 . 1 . 0 / manual / third - party / > ` _ _ reporter plugins . 
 + 
 + Metrics are collected for a single node . It ' s up to the operator to use an external monitoring system to aggregate them . 
 + 
 + Metric Types 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + All metrics reported by cassandra fit into one of the following types . 
 + 
 + ` ` Gauge ` ` 
 + An instantaneous measurement of a value . 
 + 
 + ` ` Counter ` ` 
 + A gauge for an ` ` AtomicLong ` ` instance . Typically this is consumed by monitoring the change since the last call to 
 + see if there is a large increase compared to the norm . 
 + 
 + ` ` Histogram ` ` 
 + Measures the statistical distribution of values in a stream of data . 
 + 
 + In addition to minimum , maximum , mean , etc . , it also measures median , 75th , 90th , 95th , 98th , 99th , and 99 . 9th 
 + percentiles . 
 + 
 + ` ` Timer ` ` 
 + Measures both the rate that a particular piece of code is called and the histogram of its duration . 
 + 
 + ` ` Latency ` ` 
 + Special type that tracks latency ( in microseconds ) with a ` ` Timer ` ` plus a ` ` Counter ` ` that tracks the total latency 
 + accrued since starting . The former is useful if you track the change in total latency since the last check . Each 
 + metric name of this type will have ' Latency ' and ' TotalLatency ' appended to it . 
 + 
 + ` ` Meter ` ` 
 + A meter metric which measures mean throughput and one - , five - , and fifteen - minute exponentially - weighted moving 
 + average throughputs . 
 + 
 + Table Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Each table in Cassandra has metrics responsible for tracking its state and performance . 
 + 
 + The metric names are all appended with the specific ` ` Keyspace ` ` and ` ` Table ` ` name . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . Table . { { MetricName } } . { { Keyspace } } . { { Table } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = Table keyspace = { { Keyspace } scope = { { Table } } name = { { MetricName } } ` ` 
 + 
 + . . NOTE : : 
 + There is a special table called ' ` ` all ` ` ' without a keyspace . This represents the aggregation of metrics across 
 + * * all * * tables and keyspaces on the node . 
 + 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + MemtableOnHeapSize Gauge < Long > Total amount of data stored in the memtable that resides * * on * * - heap , including column related overhead and partitions overwritten . 
 + MemtableOffHeapSize Gauge < Long > Total amount of data stored in the memtable that resides * * off * * - heap , including column related overhead and partitions overwritten . 
 + MemtableLiveDataSize Gauge < Long > Total amount of live data stored in the memtable , excluding any data structure overhead . 
 + AllMemtablesOnHeapSize Gauge < Long > Total amount of data stored in the memtables ( 2i and pending flush memtables included ) that resides * * on * * - heap . 
 + AllMemtablesOffHeapSize Gauge < Long > Total amount of data stored in the memtables ( 2i and pending flush memtables included ) that resides * * off * * - heap . 
 + AllMemtablesLiveDataSize Gauge < Long > Total amount of live data stored in the memtables ( 2i and pending flush memtables included ) that resides off - heap , excluding any data structure overhead . 
 + MemtableColumnsCount Gauge < Long > Total number of columns present in the memtable . 
 + MemtableSwitchCount Counter Number of times flush has resulted in the memtable being switched out . 
 + CompressionRatio Gauge < Double > Current compression ratio for all SSTables . 
 + EstimatedPartitionSizeHistogram Gauge < long [ ] > Histogram of estimated partition size ( in bytes ) . 
 + EstimatedPartitionCount Gauge < Long > Approximate number of keys in table . 
 + EstimatedColumnCountHistogram Gauge < long [ ] > Histogram of estimated number of columns . 
 + SSTablesPerReadHistogram Histogram Histogram of the number of sstable data files accessed per read . 
 + ReadLatency Latency Local read latency for this table . 
 + RangeLatency Latency Local range scan latency for this table . 
 + WriteLatency Latency Local write latency for this table . 
 + CoordinatorReadLatency Timer Coordinator read latency for this table . 
 + CoordinatorScanLatency Timer Coordinator range scan latency for this table . 
 + PendingFlushes Counter Estimated number of flush tasks pending for this table . 
 + BytesFlushed Counter Total number of bytes flushed since server [ re ] start . 
 + CompactionBytesWritten Counter Total number of bytes written by compaction since server [ re ] start . 
 + PendingCompactions Gauge < Integer > Estimate of number of pending compactions for this table . 
 + LiveSSTableCount Gauge < Integer > Number of SSTables on disk for this table . 
 + LiveDiskSpaceUsed Counter Disk space used by SSTables belonging to this table ( in bytes ) . 
 + TotalDiskSpaceUsed Counter Total disk space used by SSTables belonging to this table , including obsolete ones waiting to be GC ' d . 
 + MinPartitionSize Gauge < Long > Size of the smallest compacted partition ( in bytes ) . 
 + MaxPartitionSize Gauge < Long > Size of the largest compacted partition ( in bytes ) . 
 + MeanPartitionSize Gauge < Long > Size of the average compacted partition ( in bytes ) . 
 + BloomFilterFalsePositives Gauge < Long > Number of false positives on table ' s bloom filter . 
 + BloomFilterFalseRatio Gauge < Double > False positive ratio of table ' s bloom filter . 
 + BloomFilterDiskSpaceUsed Gauge < Long > Disk space used by bloom filter ( in bytes ) . 
 + BloomFilterOffHeapMemoryUsed Gauge < Long > Off - heap memory used by bloom filter . 
 + IndexSummaryOffHeapMemoryUsed Gauge < Long > Off - heap memory used by index summary . 
 + CompressionMetadataOffHeapMemoryUsed Gauge < Long > Off - heap memory used by compression meta data . 
 + KeyCacheHitRate Gauge < Double > Key cache hit rate for this table . 
 + TombstoneScannedHistogram Histogram Histogram of tombstones scanned in queries on this table . 
 + LiveScannedHistogram Histogram Histogram of live cells scanned in queries on this table . 
 + ColUpdateTimeDeltaHistogram Histogram Histogram of column update time delta on this table . 
 + ViewLockAcquireTime Timer Time taken acquiring a partition lock for materialized view updates on this table . 
 + ViewReadTime Timer Time taken during the local read of a materialized view update . 
 + TrueSnapshotsSize Gauge < Long > Disk space used by snapshots of this table including all SSTable components . 
 + RowCacheHitOutOfRange Counter Number of table row cache hits that do not satisfy the query filter , thus went to disk . 
 + RowCacheHit Counter Number of table row cache hits . 
 + RowCacheMiss Counter Number of table row cache misses . 
 + CasPrepare Latency Latency of paxos prepare round . 
 + CasPropose Latency Latency of paxos propose round . 
 + CasCommit Latency Latency of paxos commit round . 
 + PercentRepaired Gauge < Double > Percent of table data that is repaired on disk . 
 + SpeculativeRetries Counter Number of times speculative retries were sent for this table . 
 + WaitingOnFreeMemtableSpace Histogram Histogram of time spent waiting for free memtable space , either on - or off - heap . 
 + DroppedMutations Counter Number of dropped mutations on this table . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + Keyspace Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + Each keyspace in Cassandra has metrics responsible for tracking its state and performance . 
 + 
 + These metrics are the same as the ` ` Table Metrics ` ` above , only they are aggregated at the Keyspace level . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . keyspace . { { MetricName } } . { { Keyspace } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = Keyspace scope = { { Keyspace } } name = { { MetricName } } ` ` 
 + 
 + ThreadPool Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Cassandra splits work of a particular type into its own thread pool . This provides back - pressure and asynchrony for 
 + requests on a node . It ' s important to monitor the state of these thread pools since they can tell you how saturated a 
 + node is . 
 + 
 + The metric names are all appended with the specific ` ` ThreadPool ` ` name . The thread pools are also categorized under a 
 + specific type . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . ThreadPools . { { MetricName } } . { { Path } } . { { ThreadPoolName } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = ThreadPools scope = { { ThreadPoolName } } type = { { Type } } name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + ActiveTasks Gauge < Integer > Number of tasks being actively worked on by this pool . 
 + PendingTasks Gauge < Integer > Number of queued tasks queued up on this pool . 
 + CompletedTasks Counter Number of tasks completed . 
 + TotalBlockedTasks Counter Number of tasks that were blocked due to queue saturation . 
 + CurrentlyBlockedTask Counter Number of tasks that are currently blocked due to queue saturation but on retry will become unblocked . 
 + MaxPoolSize Gauge < Integer > The maximum number of threads in this pool . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + The following thread pools can be monitored . 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Native - Transport - Requests transport Handles client CQL requests 
 + CounterMutationStage request Responsible for counter writes 
 + ViewMutationStage request Responsible for materialized view writes 
 + MutationStage request Responsible for all other writes 
 + ReadRepairStage request ReadRepair happens on this thread pool 
 + ReadStage request Local reads run on this thread pool 
 + RequestResponseStage request Coordinator requests to the cluster run on this thread pool 
 + AntiEntropyStage internal Builds merkle tree for repairs 
 + CacheCleanupExecutor internal Cache maintenance performed on this thread pool 
 + CompactionExecutor internal Compactions are run on these threads 
 + GossipStage internal Handles gossip requests 
 + HintsDispatcher internal Performs hinted handoff 
 + InternalResponseStage internal Responsible for intra - cluster callbacks 
 + MemtableFlushWriter internal Writes memtables to disk 
 + MemtablePostFlush internal Cleans up commit log after memtable is written to disk 
 + MemtableReclaimMemory internal Memtable recycling 
 + MigrationStage internal Runs schema migrations 
 + MiscStage internal Misceleneous tasks run here 
 + PendingRangeCalculator internal Calculates token range 
 + PerDiskMemtableFlushWriter _ 0 internal Responsible for writing a spec ( there is one of these per disk 0 - N ) 
 + Sampler internal Responsible for re - sampling the index summaries of SStables 
 + SecondaryIndexManagement internal Performs updates to secondary indexes 
 + ValidationExecutor internal Performs validation compaction or scrubbing 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + . . | nbsp | unicode : : 0xA0 . . nonbreaking space 
 + 
 + Client Request Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Client requests have their own set of metrics that encapsulate the work happening at coordinator level . 
 + 
 + Different types of client requests are broken down by ` ` RequestType ` ` . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . ClientRequest . { { MetricName } } . { { RequestType } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = ClientRequest scope = { { RequestType } } name = { { MetricName } } ` ` 
 + 
 + 
 + : RequestType : CASRead 
 + : Description : Metrics related to transactional read requests . 
 + : Metrics : 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Timeouts Counter Number of timeouts encountered . 
 + Failures Counter Number of transaction failures encountered . 
 + | nbsp | Latency Transaction read latency . 
 + Unavailables Counter Number of unavailable exceptions encountered . 
 + UnfinishedCommit Counter Number of transactions that were committed on read . 
 + ConditionNotMet Counter Number of transaction preconditions did not match current values . 
 + ContentionHistogram Histogram How many contended reads were encountered 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + : RequestType : CASWrite 
 + : Description : Metrics related to transactional write requests . 
 + : Metrics : 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Timeouts Counter Number of timeouts encountered . 
 + Failures Counter Number of transaction failures encountered . 
 + | nbsp | Latency Transaction write latency . 
 + UnfinishedCommit Counter Number of transactions that were committed on write . 
 + ConditionNotMet Counter Number of transaction preconditions did not match current values . 
 + ContentionHistogram Histogram How many contended writes were encountered 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + 
 + : RequestType : Read 
 + : Description : Metrics related to standard read requests . 
 + : Metrics : 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Timeouts Counter Number of timeouts encountered . 
 + Failures Counter Number of read failures encountered . 
 + | nbsp | Latency Read latency . 
 + Unavailables Counter Number of unavailable exceptions encountered . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + : RequestType : RangeSlice 
 + : Description : Metrics related to token range read requests . 
 + : Metrics : 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Timeouts Counter Number of timeouts encountered . 
 + Failures Counter Number of range query failures encountered . 
 + | nbsp | Latency Range query latency . 
 + Unavailables Counter Number of unavailable exceptions encountered . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + : RequestType : Write 
 + : Description : Metrics related to regular write requests . 
 + : Metrics : 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Timeouts Counter Number of timeouts encountered . 
 + Failures Counter Number of write failures encountered . 
 + | nbsp | Latency Write latency . 
 + Unavailables Counter Number of unavailable exceptions encountered . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + 
 + : RequestType : ViewWrite 
 + : Description : Metrics related to materialized view write wrtes . 
 + : Metrics : 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Timeouts Counter Number of timeouts encountered . 
 + Failures Counter Number of transaction failures encountered . 
 + Unavailables Counter Number of unavailable exceptions encountered . 
 + ViewReplicasAttempted Counter Total number of attempted view replica writes . 
 + ViewReplicasSuccess Counter Total number of succeded view replica writes . 
 + ViewPendingMutations Gauge < Long > ViewReplicasAttempted - ViewReplicasSuccess . 
 + ViewWriteLatency Timer Time between when mutation is applied to base table and when CL . ONE is achieved on view . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + Cache Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Cassandra caches have metrics to track the effectivness of the caches . Though the ` ` Table Metrics ` ` might be more useful . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . Cache . { { MetricName } } . { { CacheName } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = Cache scope = { { CacheName } } name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Capacity Gauge < Long > Cache capacity in bytes . 
 + Entries Gauge < Integer > Total number of cache entries . 
 + FifteenMinuteCacheHitRate Gauge < Double > 15m cache hit rate . 
 + FiveMinuteCacheHitRate Gauge < Double > 5m cache hit rate . 
 + OneMinuteCacheHitRate Gauge < Double > 1m cache hit rate . 
 + HitRate Gauge < Double > All time cache hit rate . 
 + Hits Meter Total number of cache hits . 
 + Misses Meter Total number of cache misses . 
 + MissLatency Timer Latency of misses . 
 + Requests Gauge < Long > Total number of cache requests . 
 + Size Gauge < Long > Total size of occupied cache , in bytes . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + The following caches are covered : 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + CounterCache Keeps hot counters in memory for performance . 
 + ChunkCache In process uncompressed page cache . 
 + KeyCache Cache for partition to sstable offsets . 
 + RowCache Cache for rows kept in memory . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + . . NOTE : : 
 + Misses and MissLatency are only defined for the ChunkCache 
 + 
 + CQL Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Metrics specific to CQL prepared statement caching . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . CQL . { { MetricName } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = CQL name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + PreparedStatementsCount Gauge < Integer > Number of cached prepared statements . 
 + PreparedStatementsEvicted Counter Number of prepared statements evicted from the prepared statement cache 
 + PreparedStatementsExecuted Counter Number of prepared statements executed . 
 + RegularStatementsExecuted Counter Number of * * non * * prepared statements executed . 
 + PreparedStatementsRatio Gauge < Double > Percentage of statements that are prepared vs unprepared . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + 
 + DroppedMessage Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Metrics specific to tracking dropped messages for different types of requests . 
 + Dropped writes are stored and retried by ` ` Hinted Handoff ` ` 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . DroppedMessages . { { MetricName } } . { { Type } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = DroppedMetrics scope = { { Type } } name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + CrossNodeDroppedLatency Timer The dropped latency across nodes . 
 + InternalDroppedLatency Timer The dropped latency within node . 
 + Dropped Meter Number of dropped messages . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + The different types of messages tracked are : 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + BATCH _ STORE Batchlog write 
 + BATCH _ REMOVE Batchlog cleanup ( after succesfully applied ) 
 + COUNTER _ MUTATION Counter writes 
 + HINT Hint replay 
 + MUTATION Regular writes 
 + READ Regular reads 
 + READ _ REPAIR Read repair 
 + PAGED _ SLICE Paged read 
 + RANGE _ SLICE Token range read 
 + REQUEST _ RESPONSE RPC Callbacks 
 + _ TRACE Tracing writes 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + Streaming Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Metrics reported during ` ` Streaming ` ` operations , such as repair , bootstrap , rebuild . 
 + 
 + These metrics are specific to a peer endpoint , with the source node being the node you are pulling the metrics from . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . Streaming . { { MetricName } } . { { PeerIP } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = Streaming scope = { { PeerIP } } name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + IncomingBytes Counter Number of bytes streamed to this node from the peer . 
 + OutgoingBytes Counter Number of bytes streamed to the peer endpoint from this node . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + 
 + Compaction Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Metrics specific to ` ` Compaction ` ` work . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . Compaction . { { MetricName } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = Compaction name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + BytesCompacted Counter Total number of bytes compacted since server [ re ] start . 
 + PendingTasks Gauge < Integer > Estimated number of compactions remaining to perform . 
 + CompletedTasks Gauge < Long > Number of completed compactions since server [ re ] start . 
 + TotalCompactionsCompleted Meter Throughput of completed compactions since server [ re ] start . 
 + PendingTasksByTableName Gauge < Map < String , Map < String , Integer > > > Estimated number of compactions remaining to perform , grouped by keyspace and then table name . This info is also kept in ` ` Table Metrics ` ` . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + CommitLog Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Metrics specific to the ` ` CommitLog ` ` 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . CommitLog . { { MetricName } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = CommitLog name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + CompletedTasks Gauge < Long > Total number of commit log messages written since [ re ] start . 
 + PendingTasks Gauge < Long > Number of commit log messages written but yet to be fsync ' d . 
 + TotalCommitLogSize Gauge < Long > Current size , in bytes , used by all the commit log segments . 
 + WaitingOnSegmentAllocation Timer Time spent waiting for a CommitLogSegment to be allocated - under normal conditions this should be zero . 
 + WaitingOnCommit Timer The time spent waiting on CL fsync ; for Periodic this is only occurs when the sync is lagging its sync interval . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + Storage Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Metrics specific to the storage engine . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . Storage . { { MetricName } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = Storage name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Exceptions Counter Number of internal exceptions caught . Under normal exceptions this should be zero . 
 + Load Counter Size , in bytes , of the on disk data size this node manages . 
 + TotalHints Counter Number of hint messages written to this node since [ re ] start . Includes one entry for each host to be hinted per hint . 
 + TotalHintsInProgress Counter Number of hints attemping to be sent currently . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + HintedHandoff Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Metrics specific to Hinted Handoff . There are also some metrics related to hints tracked in ` ` Storage Metrics ` ` 
 + 
 + These metrics include the peer endpoint * * in the metric name * * 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . HintedHandOffManager . { { MetricName } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = HintedHandOffManager name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Hints _ created - { { PeerIP } } Counter Number of hints on disk for this peer . 
 + Hints _ not _ stored - { { PeerIP } } Counter Number of hints not stored for this peer , due to being down past the configured hint window . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + SSTable Index Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Metrics specific to the SSTable index metadata . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . Index . { { MetricName } } . RowIndexEntry ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = Index scope = RowIndexEntry name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + IndexedEntrySize Histogram Histogram of the on - heap size , in bytes , of the index across all SSTables . 
 + IndexInfoCount Histogram Histogram of the number of on - heap index entries managed across all SSTables . 
 + IndexInfoGets Histogram Histogram of the number index seeks performed per SSTable . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + BufferPool Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Metrics specific to the internal recycled buffer pool Cassandra manages . This pool is meant to keep allocations and GC 
 + lower by recycling on and off heap buffers . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . BufferPool . { { MetricName } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = BufferPool name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Size Gauge < Long > Size , in bytes , of the managed buffer pool 
 + Misses Meter The rate of misses in the pool . The higher this is the more allocations incurred . 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 + 
 + Client Metrics 
 + ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 + 
 + Metrics specifc to client managment . 
 + 
 + Reported name format : 
 + 
 + * * Metric Name * * 
 + ` ` org . apache . cassandra . metrics . Client . { { MetricName } } ` ` 
 + 
 + * * JMX MBean * * 
 + ` ` org . apache . cassandra . metrics : type = Client name = { { MetricName } } ` ` 
 + 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + Name Type Description 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + connectedNativeClients Counter Number of clients connected to this nodes native protocol server 
 + connectedThriftClients Counter Number of clients connected to this nodes thrift protocol server 
 + = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 
 + 
 JMX 
 ^ ^ ^ 
 - . . todo : : todo 
 + 
 + Any JMX based client can access metrics from cassandra . 
 + 
 + If you wish to access JMX metrics over http it ' s possible to download ` Mx4jTool < http : / / mx4j . sourceforge . net / > ` _ _ and 
 + place ` ` mx4j - tools . jar ` ` into the classpath . On startup you will see in the log : : 
 + 
 + HttpAdaptor version 3 . 0 . 2 started on port 8081 
 + 
 + To choose a different port ( 8081 is the default ) or a different listen address ( 0 . 0 . 0 . 0 is not the default ) edit 
 + ` ` conf / cassandra - env . sh ` ` and uncomment : : 
 + 
 + # MX4J _ ADDRESS = " - Dmx4jaddress = 0 . 0 . 0 . 0 " 
 + 
 + # MX4J _ PORT = " - Dmx4jport = 8081 " 
 + 
 
 Metric Reporters 
 ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 - . . todo : : todo 
 + 
 + As mentioned at the top of this section on monitoring the Cassandra metrics can be exported to a number of monitoring 
 + system a number of ` built in < http : / / metrics . dropwizard . io / 3 . 1 . 0 / getting - started / # other - reporting > ` _ _ and ` third party 
 + < http : / / metrics . dropwizard . io / 3 . 1 . 0 / manual / third - party / > ` _ _ reporter plugins . 
 + 
 + The configuration of these plugins is managed by the ` metrics reporter config project 
 + < https : / / github . com / addthis / metrics - reporter - config > ` _ _ . There is a sample configuration file located at 
 + ` ` conf / metrics - reporter - config - sample . yaml ` ` . 
 + 
 + Once configured , you simply start cassandra with the flag 
 + ` ` - Dcassandra . metricsReporterConfigFile = metrics - reporter - config . yaml ` ` . The specified . yaml file plus any 3rd party 
 + reporter jars must all be in Cassandra ' s classpath . 
 
 Security 
 - - - - - - - -

NEAREST DIFF:
diff - - git a / contrib / word _ count / README . txt b / contrib / word _ count / README . txt 
 new file mode 100644 
 index 0000000 . . f46e2e2 
 - - - / dev / null 
 + + + b / contrib / word _ count / README . txt 
 @ @ - 0 , 0 + 1 , 18 @ @ 
 + WordCount hadoop example : Inserts a bunch of words across multiple rows , 
 + and counts them , with RandomPartitioner . 
 + 
 + The scripts in bin / assume you are running with cwd of contrib / word _ count . 
 + 
 + First build and start a Cassandra server with the default configuration * , 
 + then run 
 + 
 + contrib / word _ count $ ant 
 + contrib / word _ count $ bin / word _ count _ setup 
 + contrib / word _ count $ bin / word _ count 
 + 
 + Output will be in / tmp / word _ count * . 
 + 
 + Read the code in src / for more details . 
 + 
 + * If you want to point wordcount at a real cluster , modify the seed 
 + and listenaddress settings in storage - conf . xml accordingly . 
 diff - - git a / contrib / word _ count / bin / word _ count b / contrib / word _ count / bin / word _ count 
 new file mode 100644 
 index 0000000 . . a4eafc6 
 - - - / dev / null 
 + + + b / contrib / word _ count / bin / word _ count 
 @ @ - 0 , 0 + 1 , 53 @ @ 
 + # ! / bin / sh 
 + 
 + # Licensed to the Apache Software Foundation ( ASF ) under one 
 + # or more contributor license agreements . See the NOTICE file 
 + # distributed with this work for additional information 
 + # regarding copyright ownership . The ASF licenses this file 
 + # to you under the Apache License , Version 2 . 0 ( the 
 + # " License " ) ; you may not use this file except in compliance 
 + # with the License . You may obtain a copy of the License at 
 + # 
 + # http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + # 
 + # Unless required by applicable law or agreed to in writing , software 
 + # distributed under the License is distributed on an " AS IS " BASIS , 
 + # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + # See the License for the specific language governing permissions and 
 + # limitations under the License . 
 + 
 + cwd = ` dirname $ 0 ` 
 + 
 + # Cassandra class files . 
 + if [ ! - d $ cwd / . . / . . / . . / build / classes ] ; then 
 + echo " Unable to locate cassandra class files " > & 2 
 + exit 1 
 + fi 
 + 
 + # word _ count Jar . 
 + if [ ! - e $ cwd / . . / build / * . jar ] ; then 
 + echo " Unable to locate word _ count jar " > & 2 
 + exit 1 
 + fi 
 + 
 + CLASSPATH = $ CLASSPATH : ` ls - 1 $ cwd / . . / build / * . jar ` 
 + CLASSPATH = $ CLASSPATH : . : $ cwd / . . / . . / . . / build / classes 
 + for jar in $ cwd / . . / . . / . . / lib / * . jar ; do 
 + CLASSPATH = $ CLASSPATH : $ jar 
 + done 
 + for jar in $ cwd / . . / . . / . . / build / lib / jars / * . jar ; do 
 + CLASSPATH = $ CLASSPATH : $ jar 
 + done 
 + 
 + if [ - x $ JAVA _ HOME / bin / java ] ; then 
 + JAVA = $ JAVA _ HOME / bin / java 
 + else 
 + JAVA = ` which java ` 
 + fi 
 + 
 + if [ " x $ JAVA " = " x " ] ; then 
 + echo " Java executable not found ( hint : set JAVA _ HOME ) " > & 2 
 + exit 1 
 + fi 
 + 
 + $ JAVA - Xmx1G - ea - cp $ CLASSPATH WordCount 
 diff - - git a / contrib / word _ count / bin / word _ count _ setup b / contrib / word _ count / bin / word _ count _ setup 
 new file mode 100644 
 index 0000000 . . 9af6562 
 - - - / dev / null 
 + + + b / contrib / word _ count / bin / word _ count _ setup 
 @ @ - 0 , 0 + 1 , 53 @ @ 
 + # ! / bin / sh 
 + 
 + # Licensed to the Apache Software Foundation ( ASF ) under one 
 + # or more contributor license agreements . See the NOTICE file 
 + # distributed with this work for additional information 
 + # regarding copyright ownership . The ASF licenses this file 
 + # to you under the Apache License , Version 2 . 0 ( the 
 + # " License " ) ; you may not use this file except in compliance 
 + # with the License . You may obtain a copy of the License at 
 + # 
 + # http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + # 
 + # Unless required by applicable law or agreed to in writing , software 
 + # distributed under the License is distributed on an " AS IS " BASIS , 
 + # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + # See the License for the specific language governing permissions and 
 + # limitations under the License . 
 + 
 + cwd = ` dirname $ 0 ` 
 + 
 + # Cassandra class files . 
 + if [ ! - d $ cwd / . . / . . / . . / build / classes ] ; then 
 + echo " Unable to locate cassandra class files " > & 2 
 + exit 1 
 + fi 
 + 
 + # word _ count Jar . 
 + if [ ! - e $ cwd / . . / build / * . jar ] ; then 
 + echo " Unable to locate word _ count jar " > & 2 
 + exit 1 
 + fi 
 + 
 + CLASSPATH = $ CLASSPATH : ` ls - 1 $ cwd / . . / build / * . jar ` 
 + CLASSPATH = $ CLASSPATH : . : $ cwd / . . / . . / . . / build / classes 
 + for jar in $ cwd / . . / . . / . . / lib / * . jar ; do 
 + CLASSPATH = $ CLASSPATH : $ jar 
 + done 
 + for jar in $ cwd / . . / . . / . . / build / lib / jars / * . jar ; do 
 + CLASSPATH = $ CLASSPATH : $ jar 
 + done 
 + 
 + if [ - x $ JAVA _ HOME / bin / java ] ; then 
 + JAVA = $ JAVA _ HOME / bin / java 
 + else 
 + JAVA = ` which java ` 
 + fi 
 + 
 + if [ " x $ JAVA " = " x " ] ; then 
 + echo " Java executable not found ( hint : set JAVA _ HOME ) " > & 2 
 + exit 1 
 + fi 
 + 
 + $ JAVA - Xmx1G - ea - cp $ CLASSPATH WordCountSetup 
 diff - - git a / contrib / word _ count / build . xml b / contrib / word _ count / build . xml 
 new file mode 100644 
 index 0000000 . . e80dd10 
 - - - / dev / null 
 + + + b / contrib / word _ count / build . xml 
 @ @ - 0 , 0 + 1 , 65 @ @ 
 + < ? xml version = " 1 . 0 " encoding = " UTF - 8 " ? > 
 + < ! - - 
 + ~ Licensed to the Apache Software Foundation ( ASF ) under one 
 + ~ or more contributor license agreements . See the NOTICE file 
 + ~ distributed with this work for additional information 
 + ~ regarding copyright ownership . The ASF licenses this file 
 + ~ to you under the Apache License , Version 2 . 0 ( the 
 + ~ " License " ) ; you may not use this file except in compliance 
 + ~ with the License . You may obtain a copy of the License at 
 + ~ 
 + ~ http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + ~ 
 + ~ Unless required by applicable law or agreed to in writing , 
 + ~ software distributed under the License is distributed on an 
 + ~ " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY 
 + ~ KIND , either express or implied . See the License for the 
 + ~ specific language governing permissions and limitations 
 + ~ under the License . 
 + - - > 
 + < project basedir = " . " default = " jar " name = " word _ count " > 
 + < property name = " cassandra . dir " value = " . . / . . " / > 
 + < property name = " cassandra . lib " value = " " / > 
 + < property name = " cassandra . classes " value = " $ { cassandra . dir } / build / classes " / > 
 + < property name = " build . src " value = " $ { basedir } / src " / > 
 + < property name = " build . out " value = " $ { basedir } / build " / > 
 + < property name = " build . classes " value = " $ { build . out } / classes " / > 
 + < property name = " final . name " value = " word _ count " / > 
 + 
 + < target name = " init " > 
 + < mkdir dir = " $ { build . classes } " / > 
 + < / target > 
 + 
 + < target depends = " init " name = " build " > 
 + < javac destdir = " $ { build . classes } " > 
 + < src path = " $ { build . src } " / > 
 + < classpath > 
 + < path > 
 + < fileset dir = " $ { cassandra . dir } / lib " > 
 + < include name = " * * / * . jar " / > 
 + < / fileset > 
 + < fileset dir = " $ { cassandra . dir } / build / lib / jars " > 
 + < include name = " * * / * . jar " / > 
 + < / fileset > 
 + < pathelement location = " $ { cassandra . classes } " / > 
 + < / path > 
 + < / classpath > 
 + < / javac > 
 + < / target > 
 + 
 + < target name = " jar " depends = " build " > 
 + < mkdir dir = " $ { build . classes } / META - INF " / > 
 + < jar jarfile = " $ { build . out } / $ { final . name } . jar " > 
 + < fileset dir = " $ { build . classes } " / > 
 + < fileset dir = " $ { cassandra . classes } " / > 
 + < fileset dir = " $ { cassandra . dir } " > 
 + < include name = " lib / * * / * . jar " / > 
 + < / fileset > 
 + < fileset file = " $ { basedir } / storage - conf . xml " / > 
 + < / jar > 
 + < / target > 
 + 
 + < target name = " clean " > 
 + < delete dir = " $ { build . out } " / > 
 + < / target > 
 + < / project > 
 diff - - git a / contrib / word _ count / src / WordCount . java b / contrib / word _ count / src / WordCount . java 
 new file mode 100644 
 index 0000000 . . bcd30f9 
 - - - / dev / null 
 + + + b / contrib / word _ count / src / WordCount . java 
 @ @ - 0 , 0 + 1 , 107 @ @ 
 + import java . io . IOException ; 
 + import java . util . SortedMap ; 
 + import java . util . StringTokenizer ; 
 + 
 + import org . apache . log4j . Logger ; 
 + 
 + import org . apache . cassandra . db . IColumn ; 
 + import org . apache . cassandra . hadoop . ColumnFamilyInputFormat ; 
 + import org . apache . hadoop . conf . Configuration ; 
 + import org . apache . hadoop . conf . Configured ; 
 + import org . apache . hadoop . fs . Path ; 
 + import org . apache . hadoop . io . IntWritable ; 
 + import org . apache . hadoop . io . Text ; 
 + import org . apache . hadoop . mapreduce . Job ; 
 + import org . apache . hadoop . mapreduce . Mapper ; 
 + import org . apache . hadoop . mapreduce . Reducer ; 
 + import org . apache . hadoop . mapreduce . lib . output . FileOutputFormat ; 
 + import org . apache . hadoop . util . Tool ; 
 + import org . apache . hadoop . util . ToolRunner ; 
 + 
 + / * * 
 + * This counts the occurrences of words in ColumnFamily Standard1 , that has a single column ( that we care about ) 
 + * " text " containing a sequence of words . 
 + * 
 + * For each word , we output the total number of occurrences across all texts . 
 + * / 
 + public class WordCount extends Configured implements Tool 
 + { 
 + private static final Logger logger = Logger . getLogger ( WordCount . class ) ; 
 + 
 + static final String KEYSPACE = " Keyspace1 " ; 
 + static final String COLUMN _ FAMILY = " Standard1 " ; 
 + private static String columnName ; 
 + private static final String OUTPUT _ PATH _ PREFIX = " / tmp / word _ count " ; 
 + static final int RING _ DELAY = 3000 ; / / this is enough for testing a single server node ; may need more for a real cluster 
 + 
 + public static void main ( String [ ] args ) throws Exception 
 + { 
 + / / Let ToolRunner handle generic command - line options 
 + ToolRunner . run ( new Configuration ( ) , new WordCount ( ) , args ) ; 
 + System . exit ( 0 ) ; 
 + } 
 + 
 + public static class TokenizerMapper extends Mapper < String , SortedMap < byte [ ] , IColumn > , Text , IntWritable > 
 + { 
 + private final static IntWritable one = new IntWritable ( 1 ) ; 
 + private Text word = new Text ( ) ; 
 + 
 + public void map ( String key , SortedMap < byte [ ] , IColumn > columns , Context context ) throws IOException , InterruptedException 
 + { 
 + if ( columns = = null ) 
 + return ; 
 + IColumn column = columns . get ( columnName . getBytes ( ) ) ; 
 + String value = new String ( column . value ( ) ) ; 
 + logger . debug ( " read " + key + " : " + value + " from " + context . getInputSplit ( ) ) ; 
 + 
 + StringTokenizer itr = new StringTokenizer ( value ) ; 
 + while ( itr . hasMoreTokens ( ) ) 
 + { 
 + word . set ( itr . nextToken ( ) ) ; 
 + context . write ( word , one ) ; 
 + } 
 + } 
 + } 
 + 
 + public static class IntSumReducer extends Reducer < Text , IntWritable , Text , IntWritable > 
 + { 
 + private IntWritable result = new IntWritable ( ) ; 
 + 
 + public void reduce ( Text key , Iterable < IntWritable > values , Context context ) throws IOException , InterruptedException 
 + { 
 + int sum = 0 ; 
 + for ( IntWritable val : values ) 
 + { 
 + sum + = val . get ( ) ; 
 + } 
 + 
 + result . set ( sum ) ; 
 + context . write ( key , result ) ; 
 + } 
 + } 
 + 
 + public int run ( String [ ] args ) throws Exception 
 + { 
 + Configuration conf = getConf ( ) ; 
 + 
 + for ( int i = 0 ; i < WordCountSetup . TEST _ COUNT ; i + + ) 
 + { 
 + columnName = " text " + i ; 
 + Job job = new Job ( conf , " wordcount " ) ; 
 + job . setJarByClass ( WordCount . class ) ; 
 + job . setMapperClass ( TokenizerMapper . class ) ; 
 + job . setCombinerClass ( IntSumReducer . class ) ; 
 + job . setReducerClass ( IntSumReducer . class ) ; 
 + job . setOutputKeyClass ( Text . class ) ; 
 + job . setOutputValueClass ( IntWritable . class ) ; 
 + 
 + job . setInputFormatClass ( ColumnFamilyInputFormat . class ) ; 
 + FileOutputFormat . setOutputPath ( job , new Path ( OUTPUT _ PATH _ PREFIX + i ) ) ; 
 + 
 + ColumnFamilyInputFormat . setColumnFamily ( job , KEYSPACE , COLUMN _ FAMILY ) ; 
 + 
 + job . waitForCompletion ( true ) ; 
 + } 
 + return 0 ; 
 + } 
 + } 
 \ No newline at end of file 
 diff - - git a / contrib / word _ count / src / WordCountSetup . java b / contrib / word _ count / src / WordCountSetup . java 
 new file mode 100644 
 index 0000000 . . 74ab87a 
 - - - / dev / null 
 + + + b / contrib / word _ count / src / WordCountSetup . java 
 @ @ - 0 , 0 + 1 , 61 @ @ 
 + import java . util . Arrays ; 
 + 
 + import org . apache . log4j . Logger ; 
 + 
 + import org . apache . cassandra . db . * ; 
 + import org . apache . cassandra . service . StorageProxy ; 
 + import org . apache . cassandra . service . StorageService ; 
 + import org . apache . cassandra . thrift . ConsistencyLevel ; 
 + 
 + public class WordCountSetup 
 + { 
 + private static final Logger logger = Logger . getLogger ( WordCountSetup . class ) ; 
 + 
 + public static final int TEST _ COUNT = 4 ; 
 + 
 + public static void main ( String [ ] args ) throws Exception 
 + { 
 + StorageService . instance . initClient ( ) ; 
 + logger . info ( " Sleeping " + WordCount . RING _ DELAY ) ; 
 + Thread . sleep ( WordCount . RING _ DELAY ) ; 
 + assert ! StorageService . instance . getLiveNodes ( ) . isEmpty ( ) ; 
 + 
 + RowMutation rm ; 
 + ColumnFamily cf ; 
 + byte [ ] columnName ; 
 + 
 + / / text0 : no rows 
 + 
 + / / text1 : 1 row , 1 word 
 + columnName = " text1 " . getBytes ( ) ; 
 + rm = new RowMutation ( WordCount . KEYSPACE , " Key0 " ) ; 
 + cf = ColumnFamily . create ( WordCount . KEYSPACE , WordCount . COLUMN _ FAMILY ) ; 
 + cf . addColumn ( new Column ( columnName , " word1 " . getBytes ( ) , 0 ) ) ; 
 + rm . add ( cf ) ; 
 + StorageProxy . mutateBlocking ( Arrays . asList ( rm ) , ConsistencyLevel . ONE ) ; 
 + logger . info ( " added text1 " ) ; 
 + 
 + / / text2 : 1 row , 2 words 
 + columnName = " text2 " . getBytes ( ) ; 
 + rm = new RowMutation ( WordCount . KEYSPACE , " Key0 " ) ; 
 + cf = ColumnFamily . create ( WordCount . KEYSPACE , WordCount . COLUMN _ FAMILY ) ; 
 + cf . addColumn ( new Column ( columnName , " word1 word2 " . getBytes ( ) , 0 ) ) ; 
 + rm . add ( cf ) ; 
 + StorageProxy . mutateBlocking ( Arrays . asList ( rm ) , ConsistencyLevel . ONE ) ; 
 + logger . info ( " added text2 " ) ; 
 + 
 + / / text3 : 1000 rows , 1 word 
 + columnName = " text3 " . getBytes ( ) ; 
 + for ( int i = 0 ; i < 1000 ; i + + ) 
 + { 
 + rm = new RowMutation ( WordCount . KEYSPACE , " Key " + i ) ; 
 + cf = ColumnFamily . create ( WordCount . KEYSPACE , WordCount . COLUMN _ FAMILY ) ; 
 + cf . addColumn ( new Column ( columnName , " word1 " . getBytes ( ) , 0 ) ) ; 
 + rm . add ( cf ) ; 
 + StorageProxy . mutateBlocking ( Arrays . asList ( rm ) , ConsistencyLevel . ONE ) ; 
 + } 
 + logger . info ( " added text3 " ) ; 
 + 
 + System . exit ( 0 ) ; 
 + } 
 + } 
 diff - - git a / contrib / word _ count / storage - conf . xml b / contrib / word _ count / storage - conf . xml 
 new file mode 100644 
 index 0000000 . . 0d591d9 
 - - - / dev / null 
 + + + b / contrib / word _ count / storage - conf . xml 
 @ @ - 0 , 0 + 1 , 369 @ @ 
 + < ! - - 
 + ~ Licensed to the Apache Software Foundation ( ASF ) under one 
 + ~ or more contributor license agreements . See the NOTICE file 
 + ~ distributed with this work for additional information 
 + ~ regarding copyright ownership . The ASF licenses this file 
 + ~ to you under the Apache License , Version 2 . 0 ( the 
 + ~ " License " ) ; you may not use this file except in compliance 
 + ~ with the License . You may obtain a copy of the License at 
 + ~ 
 + ~ http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + ~ 
 + ~ Unless required by applicable law or agreed to in writing , 
 + ~ software distributed under the License is distributed on an 
 + ~ " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY 
 + ~ KIND , either express or implied . See the License for the 
 + ~ specific language governing permissions and limitations 
 + ~ under the License . 
 + - - > 
 + < Storage > 
 + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 + < ! - - Basic Configuration - - > 
 + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 + 
 + < ! - - 
 + ~ The name of this cluster . This is mainly used to prevent machines in 
 + ~ one logical cluster from joining another . 
 + - - > 
 + < ClusterName > Test Cluster < / ClusterName > 
 + 
 + < ! - - 
 + ~ Turn on to make new [ non - seed ] nodes automatically migrate the right data 
 + ~ to themselves . ( If no InitialToken is specified , they will pick one 
 + ~ such that they will get half the range of the most - loaded node . ) 
 + ~ If a node starts up without bootstrapping , it will mark itself bootstrapped 
 + ~ so that you can ' t subsequently accidently bootstrap a node with 
 + ~ data on it . ( You can reset this by wiping your data and commitlog 
 + ~ directories . ) 
 + ~ 
 + ~ Off by default so that new clusters and upgraders from 0 . 4 don ' t 
 + ~ bootstrap immediately . You should turn this on when you start adding 
 + ~ new nodes to a cluster that already has data on it . ( If you are upgrading 
 + ~ from 0 . 4 , start your cluster with it off once before changing it to true . 
 + ~ Otherwise , no data will be lost but you will incur a lot of unnecessary 
 + ~ I / O before your cluster starts up . ) 
 + - - > 
 + < AutoBootstrap > false < / AutoBootstrap > 
 + 
 + < ! - - 
 + ~ Keyspaces and ColumnFamilies : 
 + ~ A ColumnFamily is the Cassandra concept closest to a relational 
 + ~ table . Keyspaces are separate groups of ColumnFamilies . Except in 
 + ~ very unusual circumstances you will have one Keyspace per application . 
 + 
 + ~ There is an implicit keyspace named ' system ' for Cassandra internals . 
 + - - > 
 + < Keyspaces > 
 + < Keyspace Name = " Keyspace1 " > 
 + < ! - - 
 + ~ ColumnFamily definitions have one required attribute ( Name ) 
 + ~ and several optional ones . 
 + ~ 
 + ~ The CompareWith attribute tells Cassandra how to sort the columns 
 + ~ for slicing operations . The default is BytesType , which is a 
 + ~ straightforward lexical comparison of the bytes in each column . 
 + ~ Other options are AsciiType , UTF8Type , LexicalUUIDType , TimeUUIDType , 
 + ~ and LongType . You can also specify the fully - qualified class 
 + ~ name to a class of your choice extending 
 + ~ org . apache . cassandra . db . marshal . AbstractType . 
 + ~ 
 + ~ SuperColumns have a similar CompareSubcolumnsWith attribute . 
 + ~ 
 + ~ BytesType : Simple sort by byte value . No validation is performed . 
 + ~ AsciiType : Like BytesType , but validates that the input can be 
 + ~ parsed as US - ASCII . 
 + ~ UTF8Type : A string encoded as UTF8 
 + ~ LongType : A 64bit long 
 + ~ LexicalUUIDType : A 128bit UUID , compared lexically ( by byte value ) 
 + ~ TimeUUIDType : a 128bit version 1 UUID , compared by timestamp 
 + ~ 
 + ~ ( To get the closest approximation to 0 . 3 - style supercolumns , you 
 + ~ would use CompareWith = UTF8Type CompareSubcolumnsWith = LongType . ) 
 + ~ 
 + ~ An optional ` Comment ` attribute may be used to attach additional 
 + ~ human - readable information about the column family to its definition . 
 + ~ 
 + ~ The optional KeysCachedFraction attribute specifies 
 + ~ The fraction of keys per sstable whose locations we keep in 
 + ~ memory in " mostly LRU " order . ( JUST the key locations , NOT any 
 + ~ column values . ) The amount of memory used by the default setting of 
 + ~ 0 . 01 is comparable to the amount used by the internal per - sstable key 
 + ~ index . Consider increasing this if you have fewer , wider rows . 
 + ~ Set to 0 to disable entirely . 
 + ~ 
 + ~ The optional RowsCached attribute specifies the number of rows 
 + ~ whose entire contents we cache in memory , either as a fixed number 
 + ~ of rows or as a percent of rows in the ColumnFamily . 
 + ~ Do not use this on ColumnFamilies with large rows , or 
 + ~ ColumnFamilies with high write : read ratios . As with key caching , 
 + ~ valid values are from 0 to 1 . The default 0 disables it entirely . 
 + - - > 
 + < ColumnFamily CompareWith = " BytesType " 
 + Name = " Standard1 " 
 + RowsCached = " 10 % " 
 + KeysCachedFraction = " 0 " / > 
 + < ColumnFamily CompareWith = " UTF8Type " Name = " Standard2 " / > 
 + < ColumnFamily CompareWith = " TimeUUIDType " Name = " StandardByUUID1 " / > 
 + < ColumnFamily ColumnType = " Super " 
 + CompareWith = " UTF8Type " 
 + CompareSubcolumnsWith = " UTF8Type " 
 + Name = " Super1 " 
 + RowsCached = " 1000 " 
 + KeysCachedFraction = " 0 " 
 + Comment = " A column family with supercolumns , whose column and subcolumn names are UTF8 strings " / > 
 + 
 + < ! - - 
 + ~ Strategy : Setting this to the class that implements 
 + ~ IReplicaPlacementStrategy will change the way the node picker works . 
 + ~ Out of the box , Cassandra provides 
 + ~ org . apache . cassandra . locator . RackUnawareStrategy and 
 + ~ org . apache . cassandra . locator . RackAwareStrategy ( place one replica in 
 + ~ a different datacenter , and the others on different racks in the same 
 + ~ one . ) 
 + - - > 
 + < ReplicaPlacementStrategy > org . apache . cassandra . locator . RackUnawareStrategy < / ReplicaPlacementStrategy > 
 + 
 + < ! - - Number of replicas of the data - - > 
 + < ReplicationFactor > 1 < / ReplicationFactor > 
 + 
 + < ! - - 
 + ~ EndPointSnitch : Setting this to the class that implements 
 + ~ AbstractEndpointSnitch , which lets Cassandra know enough 
 + ~ about your network topology to route requests efficiently . 
 + ~ Out of the box , Cassandra provides org . apache . cassandra . locator . EndPointSnitch , 
 + ~ and PropertyFileEndPointSnitch is available in contrib / . 
 + - - > 
 + < EndPointSnitch > org . apache . cassandra . locator . EndPointSnitch < / EndPointSnitch > 
 + < / Keyspace > 
 + < / Keyspaces > 
 + 
 + < ! - - 
 + ~ Authenticator : any IAuthenticator may be used , including your own as long 
 + ~ as it is on the classpath . Out of the box , Cassandra provides 
 + ~ org . apache . cassandra . auth . AllowAllAuthenticator and , 
 + ~ org . apache . cassandra . auth . SimpleAuthenticator 
 + ~ ( SimpleAuthenticator uses access . properties and passwd . properties by 
 + ~ default ) . 
 + ~ 
 + ~ If you don ' t specify an authenticator , AllowAllAuthenticator is used . 
 + - - > 
 + < Authenticator > org . apache . cassandra . auth . AllowAllAuthenticator < / Authenticator > 
 + 
 + < ! - - 
 + ~ Partitioner : any IPartitioner may be used , including your own as long 
 + ~ as it is on the classpath . Out of the box , Cassandra provides 
 + ~ org . apache . cassandra . dht . RandomPartitioner , 
 + ~ org . apache . cassandra . dht . OrderPreservingPartitioner , and 
 + ~ org . apache . cassandra . dht . CollatingOrderPreservingPartitioner . 
 + ~ ( CollatingOPP colates according to EN , US rules , not naive byte 
 + ~ ordering . Use this as an example if you need locale - aware collation . ) 
 + ~ Range queries require using an order - preserving partitioner . 
 + ~ 
 + ~ Achtung ! Changing this parameter requires wiping your data 
 + ~ directories , since the partitioner can modify the sstable on - disk 
 + ~ format . 
 + - - > 
 + < Partitioner > org . apache . cassandra . dht . RandomPartitioner < / Partitioner > 
 + 
 + < ! - - 
 + ~ If you are using an order - preserving partitioner and you know your key 
 + ~ distribution , you can specify the token for this node to use . ( Keys 
 + ~ are sent to the node with the " closest " token , so distributing your 
 + ~ tokens equally along the key distribution space will spread keys 
 + ~ evenly across your cluster . ) This setting is only checked the first 
 + ~ time a node is started . 
 + 
 + ~ This can also be useful with RandomPartitioner to force equal spacing 
 + ~ of tokens around the hash space , especially for clusters with a small 
 + ~ number of nodes . 
 + - - > 
 + < InitialToken > < / InitialToken > 
 + 
 + < ! - - 
 + ~ Directories : Specify where Cassandra should store different data on 
 + ~ disk . Keep the data disks and the CommitLog disks separate for best 
 + ~ performance 
 + - - > 
 + < CommitLogDirectory > / var / lib / cassandra / commitlog < / CommitLogDirectory > 
 + < DataFileDirectories > 
 + < DataFileDirectory > / var / lib / cassandra / data < / DataFileDirectory > 
 + < / DataFileDirectories > 
 + < CalloutLocation > / var / lib / cassandra / callouts < / CalloutLocation > 
 + < StagingFileDirectory > / var / lib / cassandra / staging < / StagingFileDirectory > 
 + 
 + 
 + < ! - - 
 + ~ Addresses of hosts that are deemed contact points . Cassandra nodes 
 + ~ use this list of hosts to find each other and learn the topology of 
 + ~ the ring . You must change this if you are running multiple nodes ! 
 + - - > 
 + < Seeds > 
 + < Seed > 127 . 0 . 0 . 1 < / Seed > 
 + < / Seeds > 
 + 
 + 
 + < ! - - Miscellaneous - - > 
 + 
 + < ! - - Time to wait for a reply from other nodes before failing the command - - > 
 + < RpcTimeoutInMillis > 5000 < / RpcTimeoutInMillis > 
 + < ! - - Size to allow commitlog to grow to before creating a new segment - - > 
 + < CommitLogRotationThresholdInMB > 128 < / CommitLogRotationThresholdInMB > 
 + 
 + 
 + < ! - - Local hosts and ports - - > 
 + 
 + < ! - - 
 + ~ Address to bind to and tell other nodes to connect to . You _ must _ 
 + ~ change this if you want multiple nodes to be able to communicate ! 
 + ~ 
 + ~ Leaving it blank leaves it up to InetAddress . getLocalHost ( ) . This 
 + ~ will always do the Right Thing * if * the node is properly configured 
 + ~ ( hostname , name resolution , etc ) , and the Right Thing is to use the 
 + ~ address associated with the hostname ( it might not be ) . 
 + - - > 
 + < ListenAddress > 127 . 0 . 0 . 2 < / ListenAddress > 
 + < ! - - internal communications port - - > 
 + < StoragePort > 7000 < / StoragePort > 
 + 
 + < ! - - 
 + ~ The address to bind the Thrift RPC service to . Unlike ListenAddress 
 + ~ above , you * can * specify 0 . 0 . 0 . 0 here if you want Thrift to listen on 
 + ~ all interfaces . 
 + ~ 
 + ~ Leaving this blank has the same effect it does for ListenAddress , 
 + ~ ( i . e . it will be based on the configured hostname of the node ) . 
 + - - > 
 + < ThriftAddress > 127 . 0 . 0 . 2 < / ThriftAddress > 
 + < ! - - Thrift RPC port ( the port clients connect to ) . - - > 
 + < ThriftPort > 9160 < / ThriftPort > 
 + < ! - - 
 + ~ Whether or not to use a framed transport for Thrift . If this option 
 + ~ is set to true then you must also use a framed transport on the 
 + ~ client - side , ( framed and non - framed transports are not compatible ) . 
 + - - > 
 + < ThriftFramedTransport > false < / ThriftFramedTransport > 
 + 
 + 
 + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 + < ! - - Memory , Disk , and Performance - - > 
 + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 + 
 + < ! - - 
 + ~ Access mode . mmapped i / o is substantially faster , but only practical on 
 + ~ a 64bit machine ( which notably does not include EC2 " small " instances ) 
 + ~ or relatively small datasets . " auto " , the safe choice , will enable 
 + ~ mmapping on a 64bit JVM . Other values are " mmap " , " mmap _ index _ only " 
 + ~ ( which may allow you to get part of the benefits of mmap on a 32bit 
 + ~ machine by mmapping only index files ) and " standard " . 
 + ~ ( The buffer size settings that follow only apply to standard , 
 + ~ non - mmapped i / o . ) 
 + - - > 
 + < DiskAccessMode > auto < / DiskAccessMode > 
 + 
 + < ! - - 
 + ~ Buffer size to use when performing contiguous column slices . Increase 
 + ~ this to the size of the column slices you typically perform . 
 + ~ ( Name - based queries are performed with a buffer size of 
 + ~ ColumnIndexSizeInKB . ) 
 + - - > 
 + < SlicedBufferSizeInKB > 64 < / SlicedBufferSizeInKB > 
 + 
 + < ! - - 
 + ~ Buffer size to use when flushing memtables to disk . ( Only one 
 + ~ memtable is ever flushed at a time . ) Increase ( decrease ) the index 
 + ~ buffer size relative to the data buffer if you have few ( many ) 
 + ~ columns per key . Bigger is only better _ if _ your memtables get large 
 + ~ enough to use the space . ( Check in your data directory after your 
 + ~ app has been running long enough . ) - - > 
 + < FlushDataBufferSizeInMB > 32 < / FlushDataBufferSizeInMB > 
 + < FlushIndexBufferSizeInMB > 8 < / FlushIndexBufferSizeInMB > 
 + 
 + < ! - - 
 + ~ Add column indexes to a row after its contents reach this size . 
 + ~ Increase if your column values are large , or if you have a very large 
 + ~ number of columns . The competing causes are , Cassandra has to 
 + ~ deserialize this much of the row to read a single column , so you want 
 + ~ it to be small - at least if you do many partial - row reads - but all 
 + ~ the index data is read for each access , so you don ' t want to generate 
 + ~ that wastefully either . 
 + - - > 
 + < ColumnIndexSizeInKB > 64 < / ColumnIndexSizeInKB > 
 + 
 + < ! - - 
 + ~ Flush memtable after this much data has been inserted , including 
 + ~ overwritten data . There is one memtable per column family , and 
 + ~ this threshold is based solely on the amount of data stored , not 
 + ~ actual heap memory usage ( there is some overhead in indexing the 
 + ~ columns ) . 
 + - - > 
 + < MemtableThroughputInMB > 64 < / MemtableThroughputInMB > 
 + < ! - - 
 + ~ Throughput setting for Binary Memtables . Typically these are 
 + ~ used for bulk load so you want them to be larger . 
 + - - > 
 + < BinaryMemtableThroughputInMB > 256 < / BinaryMemtableThroughputInMB > 
 + < ! - - 
 + ~ The maximum number of columns in millions to store in memory per 
 + ~ ColumnFamily before flushing to disk . This is also a per - memtable 
 + ~ setting . Use with MemtableThroughputInMB to tune memory usage . 
 + - - > 
 + < MemtableOperationsInMillions > 0 . 1 < / MemtableOperationsInMillions > 
 + < ! - - 
 + ~ The maximum time to leave a dirty memtable unflushed . 
 + ~ ( While any affected columnfamilies have unflushed data from a 
 + ~ commit log segment , that segment cannot be deleted . ) 
 + ~ This needs to be large enough that it won ' t cause a flush storm 
 + ~ of all your memtables flushing at once because none has hit 
 + ~ the size or count thresholds yet . For production , a larger 
 + ~ value such as 1440 is recommended . 
 + - - > 
 + < MemtableFlushAfterMinutes > 60 < / MemtableFlushAfterMinutes > 
 + 
 + < ! - - 
 + ~ Unlike most systems , in Cassandra writes are faster than reads , so 
 + ~ you can afford more of those in parallel . A good rule of thumb is 2 
 + ~ concurrent reads per processor core . Increase ConcurrentWrites to 
 + ~ the number of clients writing at once if you enable CommitLogSync + 
 + ~ CommitLogSyncDelay . - - > 
 + < ConcurrentReads > 8 < / ConcurrentReads > 
 + < ConcurrentWrites > 32 < / ConcurrentWrites > 
 + 
 + < ! - - 
 + ~ CommitLogSync may be either " periodic " or " batch . " When in batch 
 + ~ mode , Cassandra won ' t ack writes until the commit log has been 
 + ~ fsynced to disk . It will wait up to CommitLogSyncBatchWindowInMS 
 + ~ milliseconds for other writes , before performing the sync . 
 + 
 + ~ This is less necessary in Cassandra than in traditional databases 
 + ~ since replication reduces the odds of losing data from a failure 
 + ~ after writing the log entry but before it actually reaches the disk . 
 + ~ So the other option is " timed , " where writes may be acked immediately 
 + ~ and the CommitLog is simply synced every CommitLogSyncPeriodInMS 
 + ~ milliseconds . 
 + - - > 
 + < CommitLogSync > periodic < / CommitLogSync > 
 + < ! - - 
 + ~ Interval at which to perform syncs of the CommitLog in periodic mode . 
 + ~ Usually the default of 10000ms is fine ; increase it if your i / o 
 + ~ load is such that syncs are taking excessively long times . 
 + - - > 
 + < CommitLogSyncPeriodInMS > 10000 < / CommitLogSyncPeriodInMS > 
 + < ! - - 
 + ~ Delay ( in milliseconds ) during which additional commit log entries 
 + ~ may be written before fsync in batch mode . This will increase 
 + ~ latency slightly , but can vastly improve throughput where there are 
 + ~ many writers . Set to zero to disable ( each entry will be synced 
 + ~ individually ) . Reasonable values range from a minimal 0 . 1 to 10 or 
 + ~ even more if throughput matters more than latency . 
 + - - > 
 + < ! - - < CommitLogSyncBatchWindowInMS > 1 < / CommitLogSyncBatchWindowInMS > - - > 
 + 
 + < ! - - 
 + ~ Time to wait before garbage - collection deletion markers . Set this to 
 + ~ a large enough value that you are confident that the deletion marker 
 + ~ will be propagated to all replicas by the time this many seconds has 
 + ~ elapsed , even in the face of hardware failures . The default value is 
 + ~ ten days . 
 + - - > 
 + < GCGraceSeconds > 864000 < / GCGraceSeconds > 
 + < / Storage > 
 diff - - git a / ivy . xml b / ivy . xml 
 index b85534c . . 02a264d 100644 
 - - - a / ivy . xml 
 + + + b / ivy . xml 
 @ @ - 19 , 8 + 19 , 11 @ @ 
 < ivy - module version = " 2 . 0 " > 
 < info organisation = " apache - cassandra " module = " cassandra " / > 
 < dependencies > 
 - < dependency org = " org . apache . mahout . hadoop " 
 - name = " hadoop - core " rev = " 0 . 20 . 1 " / > 
 + < ! - - for hadoop - - > 
 + < dependency org = " commons - logging " name = " commons - logging " rev = " 1 . 1 . 1 " / > 
 + < dependency org = " org . apache . mahout . hadoop " name = " hadoop - core " rev = " 0 . 20 . 1 " / > 
 + < dependency org = " commons - httpclient " name = " commons - httpclient " rev = " 3 . 1 " / > 
 + 
 < ! - - FIXME : paranamer and jackson can be dropped after we ' re depending 
 on avro ( since it depends on them ) . - - > 
 < dependency org = " com . thoughtworks . paranamer " 
 diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 index d3898b1 . . a83bdf0 100644 
 - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 @ @ - 42 , 6 + 42 , 7 @ @ import java . lang . reflect . InvocationTargetException ; 
 import java . util . * ; 
 import java . net . InetAddress ; 
 import java . net . UnknownHostException ; 
 + import java . net . URL ; 
 
 public class DatabaseDescriptor 
 { 
 @ @ - 145 , 11 + 146 , 29 @ @ public class DatabaseDescriptor 
 
 private static IAuthenticator authenticator = new AllowAllAuthenticator ( ) ; 
 
 + private final static String STORAGE _ CONF _ FILE = " storage - conf . xml " ; 
 + 
 + / * * 
 + * Try the storage - config system property , and then inspect the classpath . 
 + * / 
 + static String getStorageConfigPath ( ) 
 + { 
 + String scp = System . getProperty ( " storage - config " ) + File . separator + STORAGE _ CONF _ FILE ; 
 + if ( new File ( scp ) . exists ( ) ) 
 + return scp ; 
 + / / try the classpath 
 + ClassLoader loader = DatabaseDescriptor . class . getClassLoader ( ) ; 
 + URL scpurl = loader . getResource ( STORAGE _ CONF _ FILE ) ; 
 + if ( scpurl ! = null ) 
 + return scpurl . getFile ( ) ; 
 + throw new RuntimeException ( " Cannot locate " + STORAGE _ CONF _ FILE + " via storage - config system property or classpath lookup . " ) ; 
 + } 
 + 
 static 
 { 
 try 
 { 
 - configFileName _ = System . getProperty ( " storage - config " ) + File . separator + " storage - conf . xml " ; 
 + configFileName _ = getStorageConfigPath ( ) ; 
 if ( logger _ . isDebugEnabled ( ) ) 
 logger _ . debug ( " Loading settings from " + configFileName _ ) ; 
 XMLUtils xmlUtils = new XMLUtils ( configFileName _ ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / RangeSliceCommand . java b / src / java / org / apache / cassandra / db / RangeSliceCommand . java 
 index d279f62 . . 07fd5e0 100644 
 - - - a / src / java / org / apache / cassandra / db / RangeSliceCommand . java 
 + + + b / src / java / org / apache / cassandra / db / RangeSliceCommand . java 
 @ @ - 39 , 7 + 39 , 6 @ @ package org . apache . cassandra . db ; 
 import org . apache . cassandra . concurrent . StageManager ; 
 
 import org . apache . cassandra . dht . AbstractBounds ; 
 - import org . apache . cassandra . dht . Bounds ; 
 import org . apache . cassandra . io . util . DataOutputBuffer ; 
 import org . apache . cassandra . io . ICompactSerializer ; 
 import org . apache . cassandra . net . Message ; 
 @ @ - 129 , 7 + 128 , 7 @ @ class RangeSliceCommandSerializer implements ICompactSerializer < RangeSliceComman 
 
 TSerializer ser = new TSerializer ( new TBinaryProtocol . Factory ( ) ) ; 
 FBUtilities . serialize ( ser , sliceCommand . predicate , dos ) ; 
 - Bounds . serializer ( ) . serialize ( sliceCommand . range , dos ) ; 
 + AbstractBounds . serializer ( ) . serialize ( sliceCommand . range , dos ) ; 
 dos . writeInt ( sliceCommand . max _ keys ) ; 
 } 

