BLEU SCORE: 0.040583489434387374

TEST MSG: Avoid overlap with early compaction replacement
GENERATED MSG: wip

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index b323f18 . . 7352068 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 1 . 4 <nl> + * Avoid overlap with early compaction replacement ( CASSANDRA - 8683 ) <nl> * Safer Resource Management + + ( CASSANDRA - 8707 ) <nl> * Write partition size estimates into a system table ( CASSANDRA - 7688 ) <nl> * cqlsh : Fix keys ( ) and full ( ) collection indexes in DESCRIBE output <nl> diff - - git a / src / java / org / apache / cassandra / db / DataTracker . java b / src / java / org / apache / cassandra / db / DataTracker . java <nl> index acf9f92 . . 8224311 100644 <nl> - - - a / src / java / org / apache / cassandra / db / DataTracker . java <nl> + + + b / src / java / org / apache / cassandra / db / DataTracker . java <nl> @ @ - 379 , 6 + 379 , 7 @ @ public class DataTracker <nl> ImmutableList . < Memtable > of ( ) , <nl> Collections . < SSTableReader > emptySet ( ) , <nl> Collections . < SSTableReader > emptySet ( ) , <nl> + Collections . < SSTableReader > emptySet ( ) , <nl> SSTableIntervalTree . empty ( ) ) ) ; <nl> } <nl> <nl> @ @ - 612 , 10 + 613 , 14 @ @ public class DataTracker <nl> private final List < Memtable > flushingMemtables ; <nl> public final Set < SSTableReader > compacting ; <nl> public final Set < SSTableReader > sstables ; <nl> + <nl> + / / all sstables that are still in the live set , but have been completely shadowed by a replacement sstable <nl> + public final Set < SSTableReader > shadowed ; <nl> public final SSTableIntervalTree intervalTree ; <nl> <nl> - View ( List < Memtable > liveMemtables , List < Memtable > flushingMemtables , Set < SSTableReader > sstables , Set < SSTableReader > compacting , SSTableIntervalTree intervalTree ) <nl> + View ( List < Memtable > liveMemtables , List < Memtable > flushingMemtables , Set < SSTableReader > sstables , Set < SSTableReader > compacting , Set < SSTableReader > shadowed , SSTableIntervalTree intervalTree ) <nl> { <nl> + this . shadowed = shadowed ; <nl> assert liveMemtables ! = null ; <nl> assert flushingMemtables ! = null ; <nl> assert sstables ! = null ; <nl> @ @ - 664 , 7 + 669 , 7 @ @ public class DataTracker <nl> View switchMemtable ( Memtable newMemtable ) <nl> { <nl> List < Memtable > newLiveMemtables = ImmutableList . < Memtable > builder ( ) . addAll ( liveMemtables ) . add ( newMemtable ) . build ( ) ; <nl> - return new View ( newLiveMemtables , flushingMemtables , sstables , compacting , intervalTree ) ; <nl> + return new View ( newLiveMemtables , flushingMemtables , sstables , compacting , shadowed , intervalTree ) ; <nl> } <nl> <nl> View markFlushing ( Memtable toFlushMemtable ) <nl> @ @ - 691 , 7 + 696 , 7 @ @ public class DataTracker <nl> . addAll ( flushing . subList ( i , flushing . size ( ) ) ) <nl> . build ( ) ; <nl> <nl> - return new View ( newLive , newFlushing , sstables , compacting , intervalTree ) ; <nl> + return new View ( newLive , newFlushing , sstables , compacting , shadowed , intervalTree ) ; <nl> } <nl> <nl> View replaceFlushed ( Memtable flushedMemtable , SSTableReader newSSTable ) <nl> @ @ - 701 , 37 + 706 , 61 @ @ public class DataTracker <nl> . addAll ( flushingMemtables . subList ( 0 , index ) ) <nl> . addAll ( flushingMemtables . subList ( index + 1 , flushingMemtables . size ( ) ) ) <nl> . build ( ) ; <nl> - Set < SSTableReader > newSSTables = newSSTable = = null <nl> - ? sstables <nl> - : newSSTables ( newSSTable ) ; <nl> - SSTableIntervalTree intervalTree = buildIntervalTree ( newSSTables ) ; <nl> - return new View ( liveMemtables , newQueuedMemtables , newSSTables , compacting , intervalTree ) ; <nl> + Set < SSTableReader > newSSTables = sstables ; <nl> + SSTableIntervalTree intervalTree = this . intervalTree ; <nl> + if ( newSSTable ! = null ) <nl> + { <nl> + assert ! sstables . contains ( newSSTable ) ; <nl> + assert ! shadowed . contains ( newSSTable ) ; <nl> + newSSTables = ImmutableSet . < SSTableReader > builder ( ) . addAll ( sstables ) . add ( newSSTable ) . build ( ) ; <nl> + intervalTree = buildIntervalTree ( newSSTables ) ; <nl> + } <nl> + return new View ( liveMemtables , newQueuedMemtables , newSSTables , compacting , shadowed , intervalTree ) ; <nl> } <nl> <nl> View replace ( Collection < SSTableReader > oldSSTables , Iterable < SSTableReader > replacements ) <nl> { <nl> - Set < SSTableReader > newSSTables = newSSTables ( oldSSTables , replacements ) ; <nl> + ImmutableSet < SSTableReader > oldSet = ImmutableSet . copyOf ( oldSSTables ) ; <nl> + int newSSTablesSize = shadowed . size ( ) + sstables . size ( ) - oldSSTables . size ( ) + Iterables . size ( replacements ) ; <nl> + assert newSSTablesSize > = Iterables . size ( replacements ) : String . format ( " Incoherent new size % d replacing % s by % s in % s " , newSSTablesSize , oldSSTables , replacements , this ) ; <nl> + Set < SSTableReader > newSSTables = new HashSet < > ( newSSTablesSize ) ; <nl> + Set < SSTableReader > newShadowed = new HashSet < > ( shadowed . size ( ) ) ; <nl> + <nl> + for ( SSTableReader sstable : sstables ) <nl> + if ( ! oldSet . contains ( sstable ) ) <nl> + newSSTables . add ( sstable ) ; <nl> + <nl> + for ( SSTableReader sstable : shadowed ) <nl> + if ( ! oldSet . contains ( sstable ) ) <nl> + newShadowed . add ( sstable ) ; <nl> + <nl> + for ( SSTableReader replacement : replacements ) <nl> + { <nl> + if ( replacement . openReason = = SSTableReader . OpenReason . SHADOWED ) <nl> + newShadowed . add ( replacement ) ; <nl> + else <nl> + newSSTables . add ( replacement ) ; <nl> + } <nl> + <nl> + assert newSSTables . size ( ) + newShadowed . size ( ) = = newSSTablesSize : <nl> + String . format ( " Expecting new size of % d , got % d while replacing % s by % s in % s " , <nl> + newSSTablesSize , newSSTables . size ( ) + newShadowed . size ( ) , oldSSTables , replacements , this ) ; <nl> + newSSTables = ImmutableSet . copyOf ( newSSTables ) ; <nl> + newShadowed = ImmutableSet . copyOf ( newShadowed ) ; <nl> SSTableIntervalTree intervalTree = buildIntervalTree ( newSSTables ) ; <nl> - return new View ( liveMemtables , flushingMemtables , newSSTables , compacting , intervalTree ) ; <nl> + return new View ( liveMemtables , flushingMemtables , newSSTables , compacting , newShadowed , intervalTree ) ; <nl> } <nl> <nl> View markCompacting ( Collection < SSTableReader > tomark ) <nl> { <nl> Set < SSTableReader > compactingNew = ImmutableSet . < SSTableReader > builder ( ) . addAll ( compacting ) . addAll ( tomark ) . build ( ) ; <nl> - return new View ( liveMemtables , flushingMemtables , sstables , compactingNew , intervalTree ) ; <nl> + return new View ( liveMemtables , flushingMemtables , sstables , compactingNew , shadowed , intervalTree ) ; <nl> } <nl> <nl> View unmarkCompacting ( Iterable < SSTableReader > tounmark ) <nl> { <nl> Set < SSTableReader > compactingNew = ImmutableSet . copyOf ( Sets . difference ( compacting , ImmutableSet . copyOf ( tounmark ) ) ) ; <nl> - return new View ( liveMemtables , flushingMemtables , sstables , compactingNew , intervalTree ) ; <nl> - } <nl> - <nl> - private Set < SSTableReader > newSSTables ( SSTableReader newSSTable ) <nl> - { <nl> - assert newSSTable ! = null ; <nl> - / / not performance - sensitive , don ' t obsess over doing a selection merge here <nl> - return newSSTables ( Collections . < SSTableReader > emptyList ( ) , Collections . singletonList ( newSSTable ) ) ; <nl> + return new View ( liveMemtables , flushingMemtables , sstables , compactingNew , shadowed , intervalTree ) ; <nl> } <nl> <nl> private Set < SSTableReader > newSSTables ( Collection < SSTableReader > oldSSTables , Iterable < SSTableReader > replacements ) <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> index a28eb44 . . a588bff 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> @ @ - 215 , 7 + 215 , 8 @ @ public class SSTableReader extends SSTable implements RefCounted < SSTableReader > <nl> NORMAL , <nl> EARLY , <nl> METADATA _ CHANGE , <nl> - MOVED _ START <nl> + MOVED _ START , <nl> + SHADOWED / / = > MOVED _ START past end <nl> } <nl> <nl> public final OpenReason openReason ; <nl> @ @ - 884 , 42 + 885 , 54 @ @ public class SSTableReader extends SSTable implements RefCounted < SSTableReader > <nl> synchronized ( tidy . global ) <nl> { <nl> assert openReason ! = OpenReason . EARLY ; <nl> - <nl> - if ( newStart . compareTo ( this . first ) > 0 ) <nl> + SSTableReader replacement = new SSTableReader ( descriptor , components , metadata , partitioner , ifile . sharedCopy ( ) , <nl> + dfile . sharedCopy ( ) , indexSummary . sharedCopy ( ) , bf . sharedCopy ( ) , <nl> + maxDataAge , sstableMetadata , OpenReason . MOVED _ START ) ; <nl> + / / TODO : make data / index start accurate for compressed files <nl> + / / TODO : merge with caller ' s firstKeyBeyond ( ) work , to save time <nl> + if ( newStart . compareTo ( first ) > 0 ) <nl> { <nl> - if ( newStart . compareTo ( this . last ) > 0 ) <nl> + final long dataStart = getPosition ( newStart , Operator . EQ ) . position ; <nl> + final long indexStart = getIndexScanPosition ( newStart ) ; <nl> + this . tidy . runOnClose = new Runnable ( ) <nl> { <nl> - this . tidy . runOnClose = new Runnable ( ) <nl> + public void run ( ) <nl> { <nl> - public void run ( ) <nl> - { <nl> - CLibrary . trySkipCache ( dfile . path , 0 , 0 ) ; <nl> - CLibrary . trySkipCache ( ifile . path , 0 , 0 ) ; <nl> + CLibrary . trySkipCache ( dfile . path , 0 , dataStart ) ; <nl> + CLibrary . trySkipCache ( ifile . path , 0 , indexStart ) ; <nl> + if ( runOnClose ! = null ) <nl> runOnClose . run ( ) ; <nl> - } <nl> - } ; <nl> - } <nl> - else <nl> + } <nl> + } ; <nl> + } <nl> + <nl> + replacement . first = newStart ; <nl> + replacement . last = this . last ; <nl> + setReplacedBy ( replacement ) ; <nl> + return replacement ; <nl> + } <nl> + } <nl> + <nl> + public SSTableReader cloneAsShadowed ( final Runnable runOnClose ) <nl> + { <nl> + synchronized ( tidy . global ) <nl> + { <nl> + assert openReason ! = OpenReason . EARLY ; <nl> + this . tidy . runOnClose = new Runnable ( ) <nl> + { <nl> + public void run ( ) <nl> { <nl> - final long dataStart = getPosition ( newStart , Operator . GE ) . position ; <nl> - final long indexStart = getIndexScanPosition ( newStart ) ; <nl> - this . tidy . runOnClose = new Runnable ( ) <nl> - { <nl> - public void run ( ) <nl> - { <nl> - CLibrary . trySkipCache ( dfile . path , 0 , dataStart ) ; <nl> - CLibrary . trySkipCache ( ifile . path , 0 , indexStart ) ; <nl> - runOnClose . run ( ) ; <nl> - } <nl> - } ; <nl> + CLibrary . trySkipCache ( dfile . path , 0 , 0 ) ; <nl> + CLibrary . trySkipCache ( ifile . path , 0 , 0 ) ; <nl> + runOnClose . run ( ) ; <nl> } <nl> - } <nl> + } ; <nl> <nl> SSTableReader replacement = new SSTableReader ( descriptor , components , metadata , partitioner , ifile . sharedCopy ( ) , <nl> dfile . sharedCopy ( ) , indexSummary . sharedCopy ( ) , bf . sharedCopy ( ) , <nl> - maxDataAge , sstableMetadata , OpenReason . MOVED _ START ) ; <nl> - replacement . first = this . last . compareTo ( newStart ) > 0 ? newStart : this . last ; <nl> - replacement . last = this . last ; <nl> + maxDataAge , sstableMetadata , OpenReason . SHADOWED ) ; <nl> + replacement . first = first ; <nl> + replacement . last = last ; <nl> setReplacedBy ( replacement ) ; <nl> return replacement ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableRewriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableRewriter . java <nl> index 6356d4d . . e6e4343 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableRewriter . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableRewriter . java <nl> @ @ - 20 , 8 + 20 , 8 @ @ package org . apache . cassandra . io . sstable ; <nl> import java . util . * ; <nl> <nl> import com . google . common . annotations . VisibleForTesting ; <nl> - import com . google . common . base . Function ; <nl> import com . google . common . base . Functions ; <nl> + import com . google . common . collect . ImmutableList ; <nl> <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . db . ColumnFamilyStore ; <nl> @ @ - 168 , 7 + 168 , 7 @ @ public class SSTableRewriter <nl> replaceEarlyOpenedFile ( currentlyOpenedEarly , reader ) ; <nl> currentlyOpenedEarly = reader ; <nl> currentlyOpenedEarlyAt = writer . getFilePointer ( ) ; <nl> - moveStarts ( reader , Functions . constant ( reader . last ) , false ) ; <nl> + moveStarts ( reader , reader . last , false ) ; <nl> } <nl> } <nl> } <nl> @ @ - 177 , 7 + 177 , 7 @ @ public class SSTableRewriter <nl> public void abort ( ) <nl> { <nl> switchWriter ( null , true ) ; <nl> - moveStarts ( null , Functions . forMap ( originalStarts ) , true ) ; <nl> + moveStarts ( null , null , true ) ; <nl> <nl> / / remove already completed SSTables <nl> for ( SSTableReader sstable : finished ) <nl> @ @ - 213 , 10 + 213 , 10 @ @ public class SSTableRewriter <nl> * instance , we would get exceptions . <nl> * <nl> * @ param newReader the rewritten reader that replaces them for this region <nl> - * @ param newStarts a function mapping a reader ' s descriptor to their new start value <nl> + * @ param lowerbound if ! reset , must be non - null , and marks the exclusive lowerbound of the start for each sstable <nl> * @ param reset true iff we are restoring earlier starts ( increasing the range over which they are valid ) <nl> * / <nl> - private void moveStarts ( SSTableReader newReader , Function < ? super Descriptor , DecoratedKey > newStarts , boolean reset ) <nl> + private void moveStarts ( SSTableReader newReader , DecoratedKey lowerbound , boolean reset ) <nl> { <nl> if ( isOffline ) <nl> return ; <nl> @ @ - 229 , 31 + 229 , 56 @ @ public class SSTableRewriter <nl> for ( Map . Entry < DecoratedKey , RowIndexEntry > cacheKey : cachedKeys . entrySet ( ) ) <nl> newReader . cacheKey ( cacheKey . getKey ( ) , cacheKey . getValue ( ) ) ; <nl> } <nl> + <nl> cachedKeys = new HashMap < > ( ) ; <nl> - for ( final SSTableReader sstable : rewriting ) <nl> + for ( SSTableReader sstable : ImmutableList . copyOf ( rewriting ) ) <nl> { <nl> - DecoratedKey newStart = newStarts . apply ( sstable . descriptor ) ; <nl> - assert newStart ! = null ; <nl> - if ( sstable . first . compareTo ( newStart ) < 0 | | ( reset & & newStart ! = sstable . first ) ) <nl> + / / we call getCurrentReplacement ( ) to support multiple rewriters operating over the same source readers at once . <nl> + / / note : only one such writer should be written to at any moment <nl> + final SSTableReader latest = sstable . getCurrentReplacement ( ) ; <nl> + SSTableReader replacement ; <nl> + if ( reset ) <nl> + { <nl> + DecoratedKey newStart = originalStarts . get ( sstable . descriptor ) ; <nl> + replacement = latest . cloneWithNewStart ( newStart , null ) ; <nl> + } <nl> + else <nl> { <nl> - toReplace . add ( sstable ) ; <nl> - / / we call getCurrentReplacement ( ) to support multiple rewriters operating over the same source readers at once . <nl> - / / note : only one such writer should be written to at any moment <nl> - replaceWith . add ( sstable . getCurrentReplacement ( ) . cloneWithNewStart ( newStart , new Runnable ( ) <nl> + / / skip any sstables that we know to already be shadowed <nl> + if ( latest . openReason = = SSTableReader . OpenReason . SHADOWED ) <nl> + continue ; <nl> + if ( latest . first . compareTo ( lowerbound ) > 0 ) <nl> + continue ; <nl> + <nl> + final Runnable runOnClose = new Runnable ( ) <nl> { <nl> public void run ( ) <nl> { <nl> / / this is somewhat racey , in that we could theoretically be closing this old reader <nl> / / when an even older reader is still in use , but it ' s not likely to have any major impact <nl> for ( DecoratedKey key : invalidateKeys ) <nl> - sstable . invalidateCacheKey ( key ) ; <nl> + latest . invalidateCacheKey ( key ) ; <nl> } <nl> - } ) ) ; <nl> + } ; <nl> + <nl> + if ( lowerbound . compareTo ( latest . last ) > = 0 ) <nl> + { <nl> + replacement = latest . cloneAsShadowed ( runOnClose ) ; <nl> + } <nl> + else <nl> + { <nl> + DecoratedKey newStart = latest . firstKeyBeyond ( lowerbound ) ; <nl> + assert newStart ! = null ; <nl> + replacement = latest . cloneWithNewStart ( newStart , runOnClose ) ; <nl> + } <nl> } <nl> + <nl> + toReplace . add ( latest ) ; <nl> + replaceWith . add ( replacement ) ; <nl> + rewriting . remove ( sstable ) ; <nl> + rewriting . add ( replacement ) ; <nl> } <nl> cfs . getDataTracker ( ) . replaceWithNewInstances ( toReplace , replaceWith ) ; <nl> - rewriting . removeAll ( toReplace ) ; <nl> - rewriting . addAll ( replaceWith ) ; <nl> } <nl> <nl> private void replaceEarlyOpenedFile ( SSTableReader toReplace , SSTableReader replaceWith ) <nl> @ @ - 292 , 7 + 317 , 7 @ @ public class SSTableRewriter <nl> { <nl> SSTableReader reader = writer . finish ( SSTableWriter . FinishType . EARLY , maxAge , - 1 ) ; <nl> replaceEarlyOpenedFile ( currentlyOpenedEarly , reader ) ; <nl> - moveStarts ( reader , Functions . constant ( reader . last ) , false ) ; <nl> + moveStarts ( reader , reader . last , false ) ; <nl> finishedEarly . add ( new Finished ( writer , reader ) ) ; <nl> } <nl> else <nl> diff - - git a / test / unit / org / apache / cassandra / io / sstable / SSTableRewriterTest . java b / test / unit / org / apache / cassandra / io / sstable / SSTableRewriterTest . java <nl> index 2e11624 . . 4957e5a 100644 <nl> - - - a / test / unit / org / apache / cassandra / io / sstable / SSTableRewriterTest . java <nl> + + + b / test / unit / org / apache / cassandra / io / sstable / SSTableRewriterTest . java <nl> @ @ - 147 , 15 + 147 , 14 @ @ public class SSTableRewriterTest extends SchemaLoader <nl> if ( sstable . openReason = = SSTableReader . OpenReason . EARLY ) <nl> { <nl> SSTableReader c = sstables . iterator ( ) . next ( ) ; <nl> - long lastKeySize = sstable . getPosition ( sstable . last , SSTableReader . Operator . GT ) . position - sstable . getPosition ( sstable . last , SSTableReader . Operator . EQ ) . position ; <nl> Collection < Range < Token > > r = Arrays . asList ( new Range < > ( cfs . partitioner . getMinimumToken ( ) , cfs . partitioner . getMinimumToken ( ) ) ) ; <nl> List < Pair < Long , Long > > tmplinkPositions = sstable . getPositionsForRanges ( r ) ; <nl> List < Pair < Long , Long > > compactingPositions = c . getPositionsForRanges ( r ) ; <nl> assertEquals ( 1 , tmplinkPositions . size ( ) ) ; <nl> assertEquals ( 1 , compactingPositions . size ( ) ) ; <nl> assertEquals ( 0 , tmplinkPositions . get ( 0 ) . left . longValue ( ) ) ; <nl> - / / make sure we have one key overlap between the early opened file and the compacting one : <nl> - assertEquals ( tmplinkPositions . get ( 0 ) . right . longValue ( ) , compactingPositions . get ( 0 ) . left + lastKeySize ) ; <nl> + / / make sure we have no overlap between the early opened file and the compacting one : <nl> + assertEquals ( tmplinkPositions . get ( 0 ) . right . longValue ( ) , compactingPositions . get ( 0 ) . left . longValue ( ) ) ; <nl> assertEquals ( c . uncompressedLength ( ) , compactingPositions . get ( 0 ) . right . longValue ( ) ) ; <nl> } <nl> } <nl> @ @ - 288 , 9 + 287 , 11 @ @ public class SSTableRewriterTest extends SchemaLoader <nl> } <nl> List < SSTableReader > sstables = rewriter . finish ( ) ; <nl> assertEquals ( files , sstables . size ( ) ) ; <nl> - assertEquals ( files + 1 , cfs . getSSTables ( ) . size ( ) ) ; <nl> + assertEquals ( files , cfs . getSSTables ( ) . size ( ) ) ; <nl> + assertEquals ( 1 , cfs . getDataTracker ( ) . getView ( ) . shadowed . size ( ) ) ; <nl> cfs . getDataTracker ( ) . markCompactedSSTablesReplaced ( compacting , sstables , OperationType . COMPACTION ) ; <nl> assertEquals ( files , cfs . getSSTables ( ) . size ( ) ) ; <nl> + assertEquals ( 0 , cfs . getDataTracker ( ) . getView ( ) . shadowed . size ( ) ) ; <nl> Thread . sleep ( 1000 ) ; <nl> assertFileCounts ( s . descriptor . directory . list ( ) , 0 , 0 ) ; <nl> validateCFS ( cfs ) ;
NEAREST DIFF (one line): diff - - git a / NEWS . txt b / NEWS . txt <nl> index 14af273 . . 7900ce3 100644 <nl> - - - a / NEWS . txt <nl> + + + b / NEWS . txt <nl> @ @ - 11 , 8 + 11 , 10 @ @ Features <nl> - " cassandra . bat install " will install Cassandra as a Windows Service <nl> - SSTable compression can be enabled by setting options ? ? ? <nl> - Compressed SSTable blocks are checksummed to protect against bitrot <nl> - - New LevelDB - inspired compaction algorithm can be enabled by setting <nl> - option ? ? ? <nl> + - New LevelDB - inspired compaction algorithm can be enabled by setting the <nl> + Columnfamily compaction _ strategy = LeveledCompactionStrategy option . <nl> + Leveled compaction means you only need to keep a few MB of space free for <nl> + compaction instead of ( in the worst case ) 50 % . <nl> - Windows Service ( " cassandra . bat install " to enable ) <nl> <nl> Other

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index b323f18 . . 7352068 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 1 . 4 
 + * Avoid overlap with early compaction replacement ( CASSANDRA - 8683 ) 
 * Safer Resource Management + + ( CASSANDRA - 8707 ) 
 * Write partition size estimates into a system table ( CASSANDRA - 7688 ) 
 * cqlsh : Fix keys ( ) and full ( ) collection indexes in DESCRIBE output 
 diff - - git a / src / java / org / apache / cassandra / db / DataTracker . java b / src / java / org / apache / cassandra / db / DataTracker . java 
 index acf9f92 . . 8224311 100644 
 - - - a / src / java / org / apache / cassandra / db / DataTracker . java 
 + + + b / src / java / org / apache / cassandra / db / DataTracker . java 
 @ @ - 379 , 6 + 379 , 7 @ @ public class DataTracker 
 ImmutableList . < Memtable > of ( ) , 
 Collections . < SSTableReader > emptySet ( ) , 
 Collections . < SSTableReader > emptySet ( ) , 
 + Collections . < SSTableReader > emptySet ( ) , 
 SSTableIntervalTree . empty ( ) ) ) ; 
 } 
 
 @ @ - 612 , 10 + 613 , 14 @ @ public class DataTracker 
 private final List < Memtable > flushingMemtables ; 
 public final Set < SSTableReader > compacting ; 
 public final Set < SSTableReader > sstables ; 
 + 
 + / / all sstables that are still in the live set , but have been completely shadowed by a replacement sstable 
 + public final Set < SSTableReader > shadowed ; 
 public final SSTableIntervalTree intervalTree ; 
 
 - View ( List < Memtable > liveMemtables , List < Memtable > flushingMemtables , Set < SSTableReader > sstables , Set < SSTableReader > compacting , SSTableIntervalTree intervalTree ) 
 + View ( List < Memtable > liveMemtables , List < Memtable > flushingMemtables , Set < SSTableReader > sstables , Set < SSTableReader > compacting , Set < SSTableReader > shadowed , SSTableIntervalTree intervalTree ) 
 { 
 + this . shadowed = shadowed ; 
 assert liveMemtables ! = null ; 
 assert flushingMemtables ! = null ; 
 assert sstables ! = null ; 
 @ @ - 664 , 7 + 669 , 7 @ @ public class DataTracker 
 View switchMemtable ( Memtable newMemtable ) 
 { 
 List < Memtable > newLiveMemtables = ImmutableList . < Memtable > builder ( ) . addAll ( liveMemtables ) . add ( newMemtable ) . build ( ) ; 
 - return new View ( newLiveMemtables , flushingMemtables , sstables , compacting , intervalTree ) ; 
 + return new View ( newLiveMemtables , flushingMemtables , sstables , compacting , shadowed , intervalTree ) ; 
 } 
 
 View markFlushing ( Memtable toFlushMemtable ) 
 @ @ - 691 , 7 + 696 , 7 @ @ public class DataTracker 
 . addAll ( flushing . subList ( i , flushing . size ( ) ) ) 
 . build ( ) ; 
 
 - return new View ( newLive , newFlushing , sstables , compacting , intervalTree ) ; 
 + return new View ( newLive , newFlushing , sstables , compacting , shadowed , intervalTree ) ; 
 } 
 
 View replaceFlushed ( Memtable flushedMemtable , SSTableReader newSSTable ) 
 @ @ - 701 , 37 + 706 , 61 @ @ public class DataTracker 
 . addAll ( flushingMemtables . subList ( 0 , index ) ) 
 . addAll ( flushingMemtables . subList ( index + 1 , flushingMemtables . size ( ) ) ) 
 . build ( ) ; 
 - Set < SSTableReader > newSSTables = newSSTable = = null 
 - ? sstables 
 - : newSSTables ( newSSTable ) ; 
 - SSTableIntervalTree intervalTree = buildIntervalTree ( newSSTables ) ; 
 - return new View ( liveMemtables , newQueuedMemtables , newSSTables , compacting , intervalTree ) ; 
 + Set < SSTableReader > newSSTables = sstables ; 
 + SSTableIntervalTree intervalTree = this . intervalTree ; 
 + if ( newSSTable ! = null ) 
 + { 
 + assert ! sstables . contains ( newSSTable ) ; 
 + assert ! shadowed . contains ( newSSTable ) ; 
 + newSSTables = ImmutableSet . < SSTableReader > builder ( ) . addAll ( sstables ) . add ( newSSTable ) . build ( ) ; 
 + intervalTree = buildIntervalTree ( newSSTables ) ; 
 + } 
 + return new View ( liveMemtables , newQueuedMemtables , newSSTables , compacting , shadowed , intervalTree ) ; 
 } 
 
 View replace ( Collection < SSTableReader > oldSSTables , Iterable < SSTableReader > replacements ) 
 { 
 - Set < SSTableReader > newSSTables = newSSTables ( oldSSTables , replacements ) ; 
 + ImmutableSet < SSTableReader > oldSet = ImmutableSet . copyOf ( oldSSTables ) ; 
 + int newSSTablesSize = shadowed . size ( ) + sstables . size ( ) - oldSSTables . size ( ) + Iterables . size ( replacements ) ; 
 + assert newSSTablesSize > = Iterables . size ( replacements ) : String . format ( " Incoherent new size % d replacing % s by % s in % s " , newSSTablesSize , oldSSTables , replacements , this ) ; 
 + Set < SSTableReader > newSSTables = new HashSet < > ( newSSTablesSize ) ; 
 + Set < SSTableReader > newShadowed = new HashSet < > ( shadowed . size ( ) ) ; 
 + 
 + for ( SSTableReader sstable : sstables ) 
 + if ( ! oldSet . contains ( sstable ) ) 
 + newSSTables . add ( sstable ) ; 
 + 
 + for ( SSTableReader sstable : shadowed ) 
 + if ( ! oldSet . contains ( sstable ) ) 
 + newShadowed . add ( sstable ) ; 
 + 
 + for ( SSTableReader replacement : replacements ) 
 + { 
 + if ( replacement . openReason = = SSTableReader . OpenReason . SHADOWED ) 
 + newShadowed . add ( replacement ) ; 
 + else 
 + newSSTables . add ( replacement ) ; 
 + } 
 + 
 + assert newSSTables . size ( ) + newShadowed . size ( ) = = newSSTablesSize : 
 + String . format ( " Expecting new size of % d , got % d while replacing % s by % s in % s " , 
 + newSSTablesSize , newSSTables . size ( ) + newShadowed . size ( ) , oldSSTables , replacements , this ) ; 
 + newSSTables = ImmutableSet . copyOf ( newSSTables ) ; 
 + newShadowed = ImmutableSet . copyOf ( newShadowed ) ; 
 SSTableIntervalTree intervalTree = buildIntervalTree ( newSSTables ) ; 
 - return new View ( liveMemtables , flushingMemtables , newSSTables , compacting , intervalTree ) ; 
 + return new View ( liveMemtables , flushingMemtables , newSSTables , compacting , newShadowed , intervalTree ) ; 
 } 
 
 View markCompacting ( Collection < SSTableReader > tomark ) 
 { 
 Set < SSTableReader > compactingNew = ImmutableSet . < SSTableReader > builder ( ) . addAll ( compacting ) . addAll ( tomark ) . build ( ) ; 
 - return new View ( liveMemtables , flushingMemtables , sstables , compactingNew , intervalTree ) ; 
 + return new View ( liveMemtables , flushingMemtables , sstables , compactingNew , shadowed , intervalTree ) ; 
 } 
 
 View unmarkCompacting ( Iterable < SSTableReader > tounmark ) 
 { 
 Set < SSTableReader > compactingNew = ImmutableSet . copyOf ( Sets . difference ( compacting , ImmutableSet . copyOf ( tounmark ) ) ) ; 
 - return new View ( liveMemtables , flushingMemtables , sstables , compactingNew , intervalTree ) ; 
 - } 
 - 
 - private Set < SSTableReader > newSSTables ( SSTableReader newSSTable ) 
 - { 
 - assert newSSTable ! = null ; 
 - / / not performance - sensitive , don ' t obsess over doing a selection merge here 
 - return newSSTables ( Collections . < SSTableReader > emptyList ( ) , Collections . singletonList ( newSSTable ) ) ; 
 + return new View ( liveMemtables , flushingMemtables , sstables , compactingNew , shadowed , intervalTree ) ; 
 } 
 
 private Set < SSTableReader > newSSTables ( Collection < SSTableReader > oldSSTables , Iterable < SSTableReader > replacements ) 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 index a28eb44 . . a588bff 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 @ @ - 215 , 7 + 215 , 8 @ @ public class SSTableReader extends SSTable implements RefCounted < SSTableReader > 
 NORMAL , 
 EARLY , 
 METADATA _ CHANGE , 
 - MOVED _ START 
 + MOVED _ START , 
 + SHADOWED / / = > MOVED _ START past end 
 } 
 
 public final OpenReason openReason ; 
 @ @ - 884 , 42 + 885 , 54 @ @ public class SSTableReader extends SSTable implements RefCounted < SSTableReader > 
 synchronized ( tidy . global ) 
 { 
 assert openReason ! = OpenReason . EARLY ; 
 - 
 - if ( newStart . compareTo ( this . first ) > 0 ) 
 + SSTableReader replacement = new SSTableReader ( descriptor , components , metadata , partitioner , ifile . sharedCopy ( ) , 
 + dfile . sharedCopy ( ) , indexSummary . sharedCopy ( ) , bf . sharedCopy ( ) , 
 + maxDataAge , sstableMetadata , OpenReason . MOVED _ START ) ; 
 + / / TODO : make data / index start accurate for compressed files 
 + / / TODO : merge with caller ' s firstKeyBeyond ( ) work , to save time 
 + if ( newStart . compareTo ( first ) > 0 ) 
 { 
 - if ( newStart . compareTo ( this . last ) > 0 ) 
 + final long dataStart = getPosition ( newStart , Operator . EQ ) . position ; 
 + final long indexStart = getIndexScanPosition ( newStart ) ; 
 + this . tidy . runOnClose = new Runnable ( ) 
 { 
 - this . tidy . runOnClose = new Runnable ( ) 
 + public void run ( ) 
 { 
 - public void run ( ) 
 - { 
 - CLibrary . trySkipCache ( dfile . path , 0 , 0 ) ; 
 - CLibrary . trySkipCache ( ifile . path , 0 , 0 ) ; 
 + CLibrary . trySkipCache ( dfile . path , 0 , dataStart ) ; 
 + CLibrary . trySkipCache ( ifile . path , 0 , indexStart ) ; 
 + if ( runOnClose ! = null ) 
 runOnClose . run ( ) ; 
 - } 
 - } ; 
 - } 
 - else 
 + } 
 + } ; 
 + } 
 + 
 + replacement . first = newStart ; 
 + replacement . last = this . last ; 
 + setReplacedBy ( replacement ) ; 
 + return replacement ; 
 + } 
 + } 
 + 
 + public SSTableReader cloneAsShadowed ( final Runnable runOnClose ) 
 + { 
 + synchronized ( tidy . global ) 
 + { 
 + assert openReason ! = OpenReason . EARLY ; 
 + this . tidy . runOnClose = new Runnable ( ) 
 + { 
 + public void run ( ) 
 { 
 - final long dataStart = getPosition ( newStart , Operator . GE ) . position ; 
 - final long indexStart = getIndexScanPosition ( newStart ) ; 
 - this . tidy . runOnClose = new Runnable ( ) 
 - { 
 - public void run ( ) 
 - { 
 - CLibrary . trySkipCache ( dfile . path , 0 , dataStart ) ; 
 - CLibrary . trySkipCache ( ifile . path , 0 , indexStart ) ; 
 - runOnClose . run ( ) ; 
 - } 
 - } ; 
 + CLibrary . trySkipCache ( dfile . path , 0 , 0 ) ; 
 + CLibrary . trySkipCache ( ifile . path , 0 , 0 ) ; 
 + runOnClose . run ( ) ; 
 } 
 - } 
 + } ; 
 
 SSTableReader replacement = new SSTableReader ( descriptor , components , metadata , partitioner , ifile . sharedCopy ( ) , 
 dfile . sharedCopy ( ) , indexSummary . sharedCopy ( ) , bf . sharedCopy ( ) , 
 - maxDataAge , sstableMetadata , OpenReason . MOVED _ START ) ; 
 - replacement . first = this . last . compareTo ( newStart ) > 0 ? newStart : this . last ; 
 - replacement . last = this . last ; 
 + maxDataAge , sstableMetadata , OpenReason . SHADOWED ) ; 
 + replacement . first = first ; 
 + replacement . last = last ; 
 setReplacedBy ( replacement ) ; 
 return replacement ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableRewriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableRewriter . java 
 index 6356d4d . . e6e4343 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableRewriter . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableRewriter . java 
 @ @ - 20 , 8 + 20 , 8 @ @ package org . apache . cassandra . io . sstable ; 
 import java . util . * ; 
 
 import com . google . common . annotations . VisibleForTesting ; 
 - import com . google . common . base . Function ; 
 import com . google . common . base . Functions ; 
 + import com . google . common . collect . ImmutableList ; 
 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . db . ColumnFamilyStore ; 
 @ @ - 168 , 7 + 168 , 7 @ @ public class SSTableRewriter 
 replaceEarlyOpenedFile ( currentlyOpenedEarly , reader ) ; 
 currentlyOpenedEarly = reader ; 
 currentlyOpenedEarlyAt = writer . getFilePointer ( ) ; 
 - moveStarts ( reader , Functions . constant ( reader . last ) , false ) ; 
 + moveStarts ( reader , reader . last , false ) ; 
 } 
 } 
 } 
 @ @ - 177 , 7 + 177 , 7 @ @ public class SSTableRewriter 
 public void abort ( ) 
 { 
 switchWriter ( null , true ) ; 
 - moveStarts ( null , Functions . forMap ( originalStarts ) , true ) ; 
 + moveStarts ( null , null , true ) ; 
 
 / / remove already completed SSTables 
 for ( SSTableReader sstable : finished ) 
 @ @ - 213 , 10 + 213 , 10 @ @ public class SSTableRewriter 
 * instance , we would get exceptions . 
 * 
 * @ param newReader the rewritten reader that replaces them for this region 
 - * @ param newStarts a function mapping a reader ' s descriptor to their new start value 
 + * @ param lowerbound if ! reset , must be non - null , and marks the exclusive lowerbound of the start for each sstable 
 * @ param reset true iff we are restoring earlier starts ( increasing the range over which they are valid ) 
 * / 
 - private void moveStarts ( SSTableReader newReader , Function < ? super Descriptor , DecoratedKey > newStarts , boolean reset ) 
 + private void moveStarts ( SSTableReader newReader , DecoratedKey lowerbound , boolean reset ) 
 { 
 if ( isOffline ) 
 return ; 
 @ @ - 229 , 31 + 229 , 56 @ @ public class SSTableRewriter 
 for ( Map . Entry < DecoratedKey , RowIndexEntry > cacheKey : cachedKeys . entrySet ( ) ) 
 newReader . cacheKey ( cacheKey . getKey ( ) , cacheKey . getValue ( ) ) ; 
 } 
 + 
 cachedKeys = new HashMap < > ( ) ; 
 - for ( final SSTableReader sstable : rewriting ) 
 + for ( SSTableReader sstable : ImmutableList . copyOf ( rewriting ) ) 
 { 
 - DecoratedKey newStart = newStarts . apply ( sstable . descriptor ) ; 
 - assert newStart ! = null ; 
 - if ( sstable . first . compareTo ( newStart ) < 0 | | ( reset & & newStart ! = sstable . first ) ) 
 + / / we call getCurrentReplacement ( ) to support multiple rewriters operating over the same source readers at once . 
 + / / note : only one such writer should be written to at any moment 
 + final SSTableReader latest = sstable . getCurrentReplacement ( ) ; 
 + SSTableReader replacement ; 
 + if ( reset ) 
 + { 
 + DecoratedKey newStart = originalStarts . get ( sstable . descriptor ) ; 
 + replacement = latest . cloneWithNewStart ( newStart , null ) ; 
 + } 
 + else 
 { 
 - toReplace . add ( sstable ) ; 
 - / / we call getCurrentReplacement ( ) to support multiple rewriters operating over the same source readers at once . 
 - / / note : only one such writer should be written to at any moment 
 - replaceWith . add ( sstable . getCurrentReplacement ( ) . cloneWithNewStart ( newStart , new Runnable ( ) 
 + / / skip any sstables that we know to already be shadowed 
 + if ( latest . openReason = = SSTableReader . OpenReason . SHADOWED ) 
 + continue ; 
 + if ( latest . first . compareTo ( lowerbound ) > 0 ) 
 + continue ; 
 + 
 + final Runnable runOnClose = new Runnable ( ) 
 { 
 public void run ( ) 
 { 
 / / this is somewhat racey , in that we could theoretically be closing this old reader 
 / / when an even older reader is still in use , but it ' s not likely to have any major impact 
 for ( DecoratedKey key : invalidateKeys ) 
 - sstable . invalidateCacheKey ( key ) ; 
 + latest . invalidateCacheKey ( key ) ; 
 } 
 - } ) ) ; 
 + } ; 
 + 
 + if ( lowerbound . compareTo ( latest . last ) > = 0 ) 
 + { 
 + replacement = latest . cloneAsShadowed ( runOnClose ) ; 
 + } 
 + else 
 + { 
 + DecoratedKey newStart = latest . firstKeyBeyond ( lowerbound ) ; 
 + assert newStart ! = null ; 
 + replacement = latest . cloneWithNewStart ( newStart , runOnClose ) ; 
 + } 
 } 
 + 
 + toReplace . add ( latest ) ; 
 + replaceWith . add ( replacement ) ; 
 + rewriting . remove ( sstable ) ; 
 + rewriting . add ( replacement ) ; 
 } 
 cfs . getDataTracker ( ) . replaceWithNewInstances ( toReplace , replaceWith ) ; 
 - rewriting . removeAll ( toReplace ) ; 
 - rewriting . addAll ( replaceWith ) ; 
 } 
 
 private void replaceEarlyOpenedFile ( SSTableReader toReplace , SSTableReader replaceWith ) 
 @ @ - 292 , 7 + 317 , 7 @ @ public class SSTableRewriter 
 { 
 SSTableReader reader = writer . finish ( SSTableWriter . FinishType . EARLY , maxAge , - 1 ) ; 
 replaceEarlyOpenedFile ( currentlyOpenedEarly , reader ) ; 
 - moveStarts ( reader , Functions . constant ( reader . last ) , false ) ; 
 + moveStarts ( reader , reader . last , false ) ; 
 finishedEarly . add ( new Finished ( writer , reader ) ) ; 
 } 
 else 
 diff - - git a / test / unit / org / apache / cassandra / io / sstable / SSTableRewriterTest . java b / test / unit / org / apache / cassandra / io / sstable / SSTableRewriterTest . java 
 index 2e11624 . . 4957e5a 100644 
 - - - a / test / unit / org / apache / cassandra / io / sstable / SSTableRewriterTest . java 
 + + + b / test / unit / org / apache / cassandra / io / sstable / SSTableRewriterTest . java 
 @ @ - 147 , 15 + 147 , 14 @ @ public class SSTableRewriterTest extends SchemaLoader 
 if ( sstable . openReason = = SSTableReader . OpenReason . EARLY ) 
 { 
 SSTableReader c = sstables . iterator ( ) . next ( ) ; 
 - long lastKeySize = sstable . getPosition ( sstable . last , SSTableReader . Operator . GT ) . position - sstable . getPosition ( sstable . last , SSTableReader . Operator . EQ ) . position ; 
 Collection < Range < Token > > r = Arrays . asList ( new Range < > ( cfs . partitioner . getMinimumToken ( ) , cfs . partitioner . getMinimumToken ( ) ) ) ; 
 List < Pair < Long , Long > > tmplinkPositions = sstable . getPositionsForRanges ( r ) ; 
 List < Pair < Long , Long > > compactingPositions = c . getPositionsForRanges ( r ) ; 
 assertEquals ( 1 , tmplinkPositions . size ( ) ) ; 
 assertEquals ( 1 , compactingPositions . size ( ) ) ; 
 assertEquals ( 0 , tmplinkPositions . get ( 0 ) . left . longValue ( ) ) ; 
 - / / make sure we have one key overlap between the early opened file and the compacting one : 
 - assertEquals ( tmplinkPositions . get ( 0 ) . right . longValue ( ) , compactingPositions . get ( 0 ) . left + lastKeySize ) ; 
 + / / make sure we have no overlap between the early opened file and the compacting one : 
 + assertEquals ( tmplinkPositions . get ( 0 ) . right . longValue ( ) , compactingPositions . get ( 0 ) . left . longValue ( ) ) ; 
 assertEquals ( c . uncompressedLength ( ) , compactingPositions . get ( 0 ) . right . longValue ( ) ) ; 
 } 
 } 
 @ @ - 288 , 9 + 287 , 11 @ @ public class SSTableRewriterTest extends SchemaLoader 
 } 
 List < SSTableReader > sstables = rewriter . finish ( ) ; 
 assertEquals ( files , sstables . size ( ) ) ; 
 - assertEquals ( files + 1 , cfs . getSSTables ( ) . size ( ) ) ; 
 + assertEquals ( files , cfs . getSSTables ( ) . size ( ) ) ; 
 + assertEquals ( 1 , cfs . getDataTracker ( ) . getView ( ) . shadowed . size ( ) ) ; 
 cfs . getDataTracker ( ) . markCompactedSSTablesReplaced ( compacting , sstables , OperationType . COMPACTION ) ; 
 assertEquals ( files , cfs . getSSTables ( ) . size ( ) ) ; 
 + assertEquals ( 0 , cfs . getDataTracker ( ) . getView ( ) . shadowed . size ( ) ) ; 
 Thread . sleep ( 1000 ) ; 
 assertFileCounts ( s . descriptor . directory . list ( ) , 0 , 0 ) ; 
 validateCFS ( cfs ) ;

NEAREST DIFF:
diff - - git a / NEWS . txt b / NEWS . txt 
 index 14af273 . . 7900ce3 100644 
 - - - a / NEWS . txt 
 + + + b / NEWS . txt 
 @ @ - 11 , 8 + 11 , 10 @ @ Features 
 - " cassandra . bat install " will install Cassandra as a Windows Service 
 - SSTable compression can be enabled by setting options ? ? ? 
 - Compressed SSTable blocks are checksummed to protect against bitrot 
 - - New LevelDB - inspired compaction algorithm can be enabled by setting 
 - option ? ? ? 
 + - New LevelDB - inspired compaction algorithm can be enabled by setting the 
 + Columnfamily compaction _ strategy = LeveledCompactionStrategy option . 
 + Leveled compaction means you only need to keep a few MB of space free for 
 + compaction instead of ( in the worst case ) 50 % . 
 - Windows Service ( " cassandra . bat install " to enable ) 
 
 Other
