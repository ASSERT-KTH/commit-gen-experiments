BLEU SCORE: 0.03239902355122618

TEST MSG: Fix broken CQL . textile and " ant generate - cql - html "
GENERATED MSG: CASSANDRA - 373 re { format , factor } conf / storage - conf . xml

TEST DIFF (one line): diff - - git a / doc / cql3 / CQL . textile b / doc / cql3 / CQL . textile <nl> index 7fa333d . . ca09627 100644 <nl> - - - a / doc / cql3 / CQL . textile <nl> + + + b / doc / cql3 / CQL . textile <nl> @ @ - 1806 , 15 + 1806 , 18 @ @ The @ now @ function takes no arguments and generates a new unique timeuuid ( at th <nl> bc ( sample ) . <nl> SELECT * FROM myTable WHERE t = now ( ) <nl> <nl> + <nl> will never return any result by design , since the value returned by @ now ( ) @ is guaranteed to be unique . <nl> <nl> h4 . @ minTimeuuid @ and @ maxTimeuuid @ <nl> <nl> The @ minTimeuuid @ ( resp . @ maxTimeuuid @ ) function takes a @ timestamp @ value @ t @ ( which can be " either a timestamp or a date string " : # usingtimestamps ) and return a _ fake _ @ timeuuid @ corresponding to the _ smallest _ ( resp . _ biggest _ ) possible @ timeuuid @ having for timestamp @ t @ . So for instance : <nl> - <nl> + <nl> + <nl> bc ( sample ) . <nl> SELECT * FROM myTable WHERE t > maxTimeuuid ( ' 2013 - 01 - 01 00 : 05 + 0000 ' ) AND t < minTimeuuid ( ' 2013 - 02 - 02 10 : 00 + 0000 ' ) <nl> - <nl> + <nl> + <nl> will select all rows where the @ timeuuid @ column @ t @ is strictly older than ' 2013 - 01 - 01 00 : 05 + 0000 ' but strictly younger than ' 2013 - 02 - 02 10 : 00 + 0000 ' . Please note that @ t > = maxTimeuuid ( ' 2013 - 01 - 01 00 : 05 + 0000 ' ) @ would still _ not _ select a @ timeuuid @ generated exactly at ' 2013 - 01 - 01 00 : 05 + 0000 ' and is essentially equivalent to @ t > maxTimeuuid ( ' 2013 - 01 - 01 00 : 05 + 0000 ' ) @ . <nl> <nl> _ Warning _ : We called the values generated by @ minTimeuuid @ and @ maxTimeuuid @ _ fake _ UUID because they do no respect the Time - Based UUID generation process specified by the " RFC 4122 " : http : / / www . ietf . org / rfc / rfc4122 . txt . In particular , the value returned by these 2 methods will not be unique . This means you should only use those methods for querying ( as in the example above ) . Inserting the result of those methods is almost certainly _ a bad idea _ . <nl> @ @ - 1846 , 30 + 1849 , 36 @ @ h3 ( # countFct ) . Count <nl> <nl> The @ count @ function can be used to count the rows returned by a query . Example : <nl> <nl> - bc ( sample ) . <nl> + bc ( sample ) . <nl> SELECT COUNT ( * ) FROM plays ; <nl> SELECT COUNT ( 1 ) FROM plays ; <nl> <nl> It also can be used to count the non null value of a given column . Example : <nl> <nl> - bc ( sample ) . <nl> + bc ( sample ) . <nl> SELECT COUNT ( scores ) FROM plays ; <nl> <nl> h3 ( # maxMinFcts ) . Max and Min <nl> <nl> The @ max @ and @ min @ functions can be used to compute the maximum and the minimum value returned by a query for a given column . <nl> <nl> - bc ( sample ) . <nl> + bc ( sample ) . <nl> SELECT MIN ( players ) , MAX ( players ) FROM plays WHERE game = ' quake ' ; <nl> <nl> h3 ( # sumFct ) . Sum <nl> <nl> The @ sum @ function can be used to sum up all the values returned by a query for a given column . <nl> <nl> - h3 ( # sumFct ) . Avg <nl> + bc ( sample ) . <nl> + SELECT SUM ( players ) FROM plays ; <nl> + <nl> + h3 ( # avgFct ) . Avg <nl> <nl> The @ avg @ function can be used to compute the average of all the values returned by a query for a given column . <nl> <nl> + bc ( sample ) . <nl> + SELECT AVG ( players ) FROM plays ; <nl> + <nl> h2 ( # udfs ) . User - Defined Functions <nl> <nl> User - defined functions allow execution of user - provided code in Cassandra . By default , Cassandra supports defining functions in _ Java _ and _ JavaScript _ . Support for other JSR 223 compliant scripting languages ( such as Python , Ruby , and Scala ) can be added by adding a JAR to the classpath .
NEAREST DIFF (one line): diff - - git a / conf / storage - conf . xml b / conf / storage - conf . xml <nl> index 3728ade . . ef5e229 100644 <nl> - - - a / conf / storage - conf . xml <nl> + + + b / conf / storage - conf . xml <nl> @ @ - 15 , 272 + 15 , 297 @ @ <nl> ~ KIND , either express or implied . See the License for the <nl> ~ specific language governing permissions and limitations <nl> ~ under the License . <nl> - - - > <nl> + - - > <nl> < Storage > <nl> - < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> - < ! - - Basic Configuration - - > <nl> - < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> - <nl> - < ! - - The name of this cluster . This is mainly used to prevent machines in <nl> - one logical cluster from joining any other cluster . - - > <nl> - < ClusterName > Test Cluster < / ClusterName > <nl> - <nl> - < ! - - Keyspaces and ColumnFamilies <nl> - A ColumnFamily is the Cassandra concept closest to a relational table . <nl> - Keyspaces are separate groups of ColumnFamilies . Except in very <nl> - unusual circumstances you will have one Keyspace per application . <nl> - <nl> - There is an implicit keyspace named ' system ' for Cassandra internals . <nl> - <nl> - The default ColumnSort is Time for standard column families . <nl> - For super column families , specifying ColumnSort is not supported ; <nl> - the supercolumns themselves are always name - sorted and their subcolumns <nl> - are always time - sorted . <nl> - - - > <nl> - < Keyspaces > <nl> - < Keyspace Name = " Keyspace1 " > <nl> - < ! - - The fraction of keys per sstable whose locations we <nl> - keep in memory in " mostly LRU " order . ( JUST the key <nl> - locations , NOT any column values . ) <nl> - <nl> - The amount of memory used by the default setting of <nl> - 0 . 01 is comparable to the amount used by the internal <nl> - per - sstable key index . Consider increasing this is <nl> - fine if you have fewer , wider rows . Set to 0 to <nl> - disable entirely . <nl> - - - > <nl> - < KeysCachedFraction > 0 . 01 < / KeysCachedFraction > <nl> - < ! - - <nl> - The CompareWith attribute tells Cassandra how to sort the columns <nl> - for slicing operations . For backwards compatibility , the default <nl> - is to use AsciiType , which is probably NOT what you want . <nl> - Other options are BytesType , UTF8Type , LexicalUUIDType , TimeUUIDType , and LongType . <nl> - You can also specify the fully - qualified class name to a class <nl> - of your choice implementing org . apache . cassandra . db . marshal . IType . <nl> - <nl> - SuperColumns have a similar CompareSubcolumnsWith attribute . <nl> - <nl> - ByteType : simple sort by byte value . No validation is performed . <nl> - AsciiType : like BytesType , but validates that the input can be parsed as US - ASCII . <nl> - UTF8Type : A string encoded as UTF8 <nl> - LongType : A 64bit long <nl> - LexicalUUIDType : a 128bit UUID , compared lexically ( by byte value ) <nl> - TimeUUIDType : a 128bit version 1 UUID , compared by timestamp <nl> - <nl> - ( To get the closest approximation to 0 . 3 - style supercolumns , <nl> - you would use CompareWith = UTF8Type CompareSubcolumnsWith = LongType . ) <nl> - <nl> - if FlushPeriodInMinutes is configured and positive , it will be <nl> - flushed to disk with that period whether it is dirty or not . <nl> - This is intended for lightly - used columnfamilies so that they <nl> - do not prevent commitlog segments from being purged . <nl> - <nl> - - - > <nl> - < ColumnFamily CompareWith = " UTF8Type " Name = " Standard1 " FlushPeriodInMinutes = " 60 " / > <nl> - < ColumnFamily CompareWith = " UTF8Type " Name = " Standard2 " / > <nl> - < ColumnFamily CompareWith = " TimeUUIDType " Name = " StandardByUUID1 " / > <nl> - < ColumnFamily ColumnType = " Super " CompareWith = " UTF8Type " CompareSubcolumnsWith = " UTF8Type " Name = " Super1 " / > <nl> - < / Keyspace > <nl> - < / Keyspaces > <nl> - <nl> - < ! - - Partitioner : any IPartitioner may be used , including your own <nl> - as long as it is on the classpath . Out of the box , <nl> - Cassandra provides <nl> - org . apache . cassandra . dht . RandomPartitioner , <nl> - org . apache . cassandra . dht . OrderPreservingPartitioner , and <nl> - org . apache . cassandra . dht . CollatingOrderPreservingPartitioner . <nl> - ( CollatingOPP colates according to EN , US rules , not naive byte ordering . <nl> - Use this as an example if you need locale - aware collation . ) <nl> - Range queries require using OrderPreservingPartitioner or a subclass . <nl> - <nl> - Achtung ! Changing this parameter requires wiping your data directories , <nl> - since the partitioner can modify the sstable on - disk format . <nl> - - - > <nl> - < Partitioner > org . apache . cassandra . dht . RandomPartitioner < / Partitioner > <nl> - <nl> - < ! - - If you are using the OrderPreservingPartitioner and you know your key <nl> - distribution , you can specify the token for this node to use . <nl> - ( Keys are sent to the node with the " closest " token , so distributing <nl> - your tokens equally along the key distribution space will spread <nl> - keys evenly across your cluster . ) This setting is only checked the <nl> - first time a node is started . <nl> - <nl> - This can also be useful with RandomPartitioner to force equal <nl> - spacing of tokens around the hash space , especially for <nl> - clusters with a small number of nodes . - - > <nl> - < InitialToken > < / InitialToken > <nl> - <nl> - 	 <nl> - < ! - - EndPointSnitch : Setting this to the class that implements IEndPointSnitch <nl> - 	 which will see if two endpoints are in the same data center or on the same rack . <nl> - Out of the box , Cassandra provides <nl> - org . apache . cassandra . locator . EndPointSnitch <nl> - - - > <nl> - < EndPointSnitch > org . apache . cassandra . locator . EndPointSnitch < / EndPointSnitch > <nl> - <nl> - < ! - - Strategy : Setting this to the class that implements IReplicaPlacementStrategy <nl> - 	 will change the way the node picker works . <nl> - Out of the box , Cassandra provides <nl> - org . apache . cassandra . locator . RackUnawareStrategy <nl> - org . apache . cassandra . locator . RackAwareStrategy <nl> - 	 	 ( place one replica in a different datacenter , and the <nl> - others on different racks in the same one . ) <nl> - - - > <nl> - < ReplicaPlacementStrategy > org . apache . cassandra . locator . RackUnawareStrategy < / ReplicaPlacementStrategy > <nl> - <nl> - < ! - - Number of replicas of the data - - > <nl> - < ReplicationFactor > 1 < / ReplicationFactor > <nl> - <nl> - < ! - - Directories : Specify where Cassandra should store different data on disk <nl> - Keep the data disks and the CommitLog disks separate for best performance <nl> - - - > <nl> - < CommitLogDirectory > / var / cassandra / commitlog < / CommitLogDirectory > <nl> - < DataFileDirectories > <nl> - < DataFileDirectory > / var / cassandra / data < / DataFileDirectory > <nl> - < / DataFileDirectories > <nl> - < BootstrapFileDirectory > / var / cassandra / bootstrap < / BootstrapFileDirectory > <nl> - < StagingFileDirectory > / var / cassandra / staging < / StagingFileDirectory > <nl> - <nl> - <nl> - < ! - - Addresses of hosts that are deemed contact points . Cassandra nodes use <nl> - this list of hosts to find each other and learn the topology of the ring . <nl> - You must change this if you are running multiple nodes ! <nl> - - - > <nl> - < Seeds > <nl> - < Seed > 127 . 0 . 0 . 1 < / Seed > <nl> - < / Seeds > <nl> - <nl> - <nl> - < ! - - Miscellaneous - - > <nl> - <nl> - < ! - - time to wait for a reply from other nodes before failing the command - - > <nl> - < RpcTimeoutInMillis > 5000 < / RpcTimeoutInMillis > <nl> - < ! - - size to allow commitlog to grow to before creating a new segment - - > <nl> - < CommitLogRotationThresholdInMB > 128 < / CommitLogRotationThresholdInMB > <nl> - <nl> - <nl> - < ! - - Local hosts and ports - - > <nl> - <nl> - < ! - - Address to bind to and tell other nodes to connect to . <nl> - You _ must _ change this if you want multiple nodes to be able <nl> - to communicate ! <nl> - <nl> - Leaving it blank leaves it up to InetAddress . getLocalHost ( ) . <nl> - This will always do the Right Thing * if * the node is properly <nl> - configured ( hostname , name resolution , etc ) , and the Right <nl> - Thing is to use the address associated with the hostname ( it <nl> - might not be ) . - - > <nl> - < ListenAddress > localhost < / ListenAddress > <nl> - < ! - - TCP port , for commands and data - - > <nl> - < StoragePort > 7000 < / StoragePort > <nl> - < ! - - UDP port , for membership communications ( gossip ) - - > <nl> - < ControlPort > 7001 < / ControlPort > <nl> - <nl> - < ! - - The address to bind the Thrift RPC service to . Unlike <nl> - ListenAddress above , you * can * specify 0 . 0 . 0 . 0 here if you want <nl> - Thrift to listen on all interfaces . <nl> - <nl> - Leaving this blank has the same effect it does for ListenAddress , <nl> - ( i . e . it will be based on the configured hostname of the node ) . <nl> - - - > <nl> - < ThriftAddress > localhost < / ThriftAddress > <nl> - < ! - - Thrift RPC port ( the port clients connect to ) . - - > <nl> - < ThriftPort > 9160 < / ThriftPort > <nl> - < ! - - Whether or not to use a framed transport for Thrift . If this option <nl> - is set to true then you must also use a framed transport on the <nl> - client - side , ( framed and non - framed transports are not compatible ) . <nl> - - - > <nl> - < ThriftFramedTransport > false < / ThriftFramedTransport > <nl> - <nl> - <nl> - < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> - < ! - - Memory , Disk , and Performance - - > <nl> - < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> - <nl> - < ! - - Buffer size to use when performing contiguous column slices . <nl> - Increase this to the size of the column slices you typically <nl> - perform . ( Name - based queries are performed with a buffer size <nl> - of ColumnIndexSizeInKB . ) - - > <nl> - < SlicedBufferSizeInKB > 64 < / SlicedBufferSizeInKB > <nl> - <nl> - < ! - - Buffer size to use when flushing memtables to disk . <nl> - ( Only one memtable is ever flushed at a time . ) <nl> - Increase ( decrease ) the index buffer size relative to the data buffer <nl> - if you have few ( many ) columns per key . <nl> - Bigger is only better _ if _ your memtables get large enough to use the space . <nl> - ( Check in your data directory after your app has been running long enough . ) <nl> + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> + < ! - - Basic Configuration - - > <nl> + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> + <nl> + < ! - - <nl> + ~ The name of this cluster . This is mainly used to prevent machines in <nl> + ~ one logical cluster from joining another . <nl> + - - > <nl> + < ClusterName > Test Cluster < / ClusterName > <nl> + <nl> + < ! - - <nl> + ~ Keyspaces and ColumnFamilies : <nl> + ~ A ColumnFamily is the Cassandra concept closest to a relational <nl> + ~ table . Keyspaces are separate groups of ColumnFamilies . Except in <nl> + ~ very unusual circumstances you will have one Keyspace per application . <nl> + <nl> + ~ There is an implicit keyspace named ' system ' for Cassandra internals . <nl> + <nl> + ~ The default ColumnSort is Time for standard column families . For <nl> + ~ super column families , specifying ColumnSort is not supported ; the <nl> + ~ supercolumns themselves are always name - sorted and their subcolumns <nl> + ~ are always time - sorted . <nl> + - - > <nl> + < Keyspaces > <nl> + < Keyspace Name = " Keyspace1 " > <nl> + < ! - - <nl> + ~ The fraction of keys per sstable whose locations we keep in <nl> + ~ memory in " mostly LRU " order . ( JUST the key locations , NOT any <nl> + ~ column values . ) <nl> + <nl> + ~ The amount of memory used by the default setting of 0 . 01 is <nl> + ~ comparable to the amount used by the internal per - sstable key <nl> + ~ index . Consider increasing this if you have fewer , wider rows . <nl> + ~ Set to 0 to disable entirely . <nl> - - > <nl> - < FlushDataBufferSizeInMB > 32 < / FlushDataBufferSizeInMB > <nl> - < FlushIndexBufferSizeInMB > 8 < / FlushIndexBufferSizeInMB > <nl> - <nl> - < ! - - Add column indexes to a row after its contents reach this size . <nl> - Increase if your column values are large , or if you have a very large <nl> - number of columns . The competing causes are , Cassandra has to <nl> - deserialize this much of the row to read a single column , so you <nl> - want it to be small - at least if you do many partial - row reads <nl> - - but all the index data is read for each access , so <nl> - you don ' t want to generate that wastefully either . - - > <nl> - < ColumnIndexSizeInKB > 64 < / ColumnIndexSizeInKB > <nl> - <nl> - < ! - - <nl> - The maximum amount of data to store in memory per ColumnFamily before flushing to <nl> - disk . Note : There is one memtable per column family , and this threshold <nl> - is based solely on the amount of data stored , not actual heap memory <nl> - usage ( there is some overhead in indexing the columns ) . <nl> - - - > <nl> - < MemtableSizeInMB > 64 < / MemtableSizeInMB > <nl> - < ! - - <nl> - The maximum number of columns in millions to store in memory per ColumnFamily <nl> - before flushing to disk . This is also a per - memtable setting . <nl> - Use with MemtableSizeInMB to tune memory usage . <nl> - - - > <nl> - < MemtableObjectCountInMillions > 0 . 1 < / MemtableObjectCountInMillions > <nl> - <nl> - < ! - - Unlike most systems , in Cassandra writes are faster than <nl> - reads , so you can afford more of those in parallel . <nl> - 	 A good rule of thumb is 2 concurrent reads per processor core . <nl> - Increase ConcurrentWrites to the number of clients writing <nl> - at once if you enable CommitLogSync + CommitLogSyncDelay . - - > <nl> - < ConcurrentReads > 8 < / ConcurrentReads > <nl> - < ConcurrentWrites > 32 < / ConcurrentWrites > <nl> - <nl> - < ! - - CommitLogSync may be either " periodic " or " batch . " <nl> - When in batch mode , Cassandra won ' t ack writes until the commit log <nl> - has been fsynced to disk . It will wait up to CommitLogSyncBatchWindowInMS <nl> - milliseconds for other writes , before performing the sync . <nl> - <nl> - This is less necessary in Cassandra <nl> - than in traditional databases since replication reduces the <nl> - odds of losing data from a failure after writing the log <nl> - entry but before it actually reaches the disk . So the other <nl> - option is " timed , " where wirtes may be acked immediately <nl> - and the CommitLog is simply synced every CommitLogSyncPeriodInMS <nl> - milliseconds . <nl> - - - > <nl> - < CommitLogSync > periodic < / CommitLogSync > <nl> - < ! - - Interval at which to perform syncs of the CommitLog in periodic <nl> - mode . Usually the default of 1000ms is fine ; increase it <nl> - only if the CommitLog PendingTasks backlog in jmx shows that <nl> - you are frequently scheduling a second sync while the first <nl> - has not yet been processed . <nl> - - - > <nl> - < CommitLogSyncPeriodInMS > 1000 < / CommitLogSyncPeriodInMS > <nl> - < ! - - Delay ( in microseconds ) during which additional commit log <nl> - entries may be written before fsync in batch mode . This will increase <nl> - latency slightly , but can vastly improve throughput where <nl> - there are many writers . Set to zero to disable <nl> - ( each entry will be synced individually ) . <nl> - 	 Reasonable values range from a minimal 0 . 1 to 10 or even more <nl> - if throughput matters more than latency . <nl> - - - > <nl> - < ! - - < CommitLogSyncBatchWindowInMS > 1 < / CommitLogSyncBatchWindowInMS > - - > <nl> - <nl> - <nl> - < ! - - Time to wait before garbage - collection deletion markers . <nl> - Set this to a large enough value that you are confident <nl> - that the deletion marker will be propagated to all replicas <nl> - by the time this many seconds has elapsed , even in the <nl> - face of hardware failures . The default value is ten days . <nl> - - - > <nl> - < GCGraceSeconds > 864000 < / GCGraceSeconds > <nl> + < KeysCachedFraction > 0 . 01 < / KeysCachedFraction > <nl> + < ! - - <nl> + ~ The CompareWith attribute tells Cassandra how to sort the columns <nl> + ~ for slicing operations . For backwards compatibility , the default <nl> + ~ is to use AsciiType , which is probably NOT what you want . Other <nl> + ~ options are BytesType , UTF8Type , LexicalUUIDType , TimeUUIDType , <nl> + ~ and LongType . You can also specify the fully - qualified class <nl> + ~ name to a class of your choice implementing <nl> + ~ org . apache . cassandra . db . marshal . IType . <nl> + ~ <nl> + ~ SuperColumns have a similar CompareSubcolumnsWith attribute . <nl> + ~ <nl> + ~ ByteType : Simple sort by byte value . No validation is performed . <nl> + ~ AsciiType : Like BytesType , but validates that the input can be <nl> + ~ parsed as US - ASCII . <nl> + ~ UTF8Type : A string encoded as UTF8 <nl> + ~ LongType : A 64bit long <nl> + ~ LexicalUUIDType : A 128bit UUID , compared lexically ( by byte value ) <nl> + ~ TimeUUIDType : a 128bit version 1 UUID , compared by timestamp <nl> + ~ <nl> + ~ ( To get the closest approximation to 0 . 3 - style supercolumns , you <nl> + ~ would use CompareWith = UTF8Type CompareSubcolumnsWith = LongType . ) <nl> + <nl> + ~ If FlushPeriodInMinutes is configured and positive , it will be <nl> + ~ flushed to disk with that period whether it is dirty or not . This <nl> + ~ is intended for lightly - used columnfamilies so that they do not <nl> + ~ prevent commitlog segments from being purged . <nl> + - - > <nl> + < ColumnFamily CompareWith = " UTF8Type " <nl> + Name = " Standard1 " <nl> + FlushPeriodInMinutes = " 60 " / > <nl> + < ColumnFamily CompareWith = " UTF8Type " Name = " Standard2 " / > <nl> + < ColumnFamily CompareWith = " TimeUUIDType " Name = " StandardByUUID1 " / > <nl> + < ColumnFamily ColumnType = " Super " <nl> + CompareWith = " UTF8Type " <nl> + CompareSubcolumnsWith = " UTF8Type " <nl> + Name = " Super1 " / > <nl> + < / Keyspace > <nl> + < / Keyspaces > <nl> + <nl> + < ! - - <nl> + ~ Partitioner : any IPartitioner may be used , including your own as long <nl> + ~ as it is on the classpath . Out of the box , Cassandra provides <nl> + ~ org . apache . cassandra . dht . RandomPartitioner , <nl> + ~ org . apache . cassandra . dht . OrderPreservingPartitioner , and <nl> + ~ org . apache . cassandra . dht . CollatingOrderPreservingPartitioner . <nl> + ~ ( CollatingOPP colates according to EN , US rules , not naive byte <nl> + ~ ordering . Use this as an example if you need locale - aware collation . ) <nl> + ~ Range queries require using OrderPreservingPartitioner or a subclass . <nl> + <nl> + ~ Achtung ! Changing this parameter requires wiping your data <nl> + ~ directories , since the partitioner can modify the sstable on - disk <nl> + ~ format . <nl> + - - > <nl> + < Partitioner > org . apache . cassandra . dht . RandomPartitioner < / Partitioner > <nl> + <nl> + < ! - - <nl> + ~ If you are using the OrderPreservingPartitioner and you know your key <nl> + ~ distribution , you can specify the token for this node to use . ( Keys <nl> + ~ are sent to the node with the " closest " token , so distributing your <nl> + ~ tokens equally along the key distribution space will spread keys <nl> + ~ evenly across your cluster . ) This setting is only checked the first <nl> + ~ time a node is started . <nl> + <nl> + ~ This can also be useful with RandomPartitioner to force equal spacing <nl> + ~ of tokens around the hash space , especially for clusters with a small <nl> + ~ number of nodes . <nl> + - - > <nl> + < InitialToken > < / InitialToken > <nl> + <nl> + < ! - - <nl> + ~ EndPointSnitch : Setting this to the class that implements <nl> + ~ IEndPointSnitch which will see if two endpoints are in the same data <nl> + ~ center or on the same rack . Out of the box , Cassandra provides <nl> + ~ org . apache . cassandra . locator . EndPointSnitch <nl> + - - > <nl> + < EndPointSnitch > org . apache . cassandra . locator . EndPointSnitch < / EndPointSnitch > <nl> + <nl> + < ! - - <nl> + ~ Strategy : Setting this to the class that implements <nl> + ~ IReplicaPlacementStrategy will change the way the node picker works . <nl> + ~ Out of the box , Cassandra provides <nl> + ~ org . apache . cassandra . locator . RackUnawareStrategy and <nl> + ~ org . apache . cassandra . locator . RackAwareStrategy ( place one replica in <nl> + ~ a different datacenter , and the others on different racks in the same <nl> + ~ one . ) <nl> + - - > <nl> + < ReplicaPlacementStrategy > org . apache . cassandra . locator . RackUnawareStrategy < / ReplicaPlacementStrategy > <nl> + <nl> + < ! - - Number of replicas of the data - - > <nl> + < ReplicationFactor > 1 < / ReplicationFactor > <nl> + <nl> + < ! - - <nl> + ~ Directories : Specify where Cassandra should store different data on <nl> + ~ disk . Keep the data disks and the CommitLog disks separate for best <nl> + ~ performance <nl> + - - > <nl> + < CommitLogDirectory > / var / lib / cassandra / commitlog < / CommitLogDirectory > <nl> + < DataFileDirectories > <nl> + < DataFileDirectory > / var / lib / cassandra / data < / DataFileDirectory > <nl> + < / DataFileDirectories > <nl> + < CalloutLocation > / var / lib / cassandra / callouts < / CalloutLocation > <nl> + < BootstrapFileDirectory > / var / lib / cassandra / bootstrap < / BootstrapFileDirectory > <nl> + < StagingFileDirectory > / var / lib / cassandra / staging < / StagingFileDirectory > <nl> + <nl> + <nl> + < ! - - <nl> + ~ Addresses of hosts that are deemed contact points . Cassandra nodes <nl> + ~ use this list of hosts to find each other and learn the topology of <nl> + ~ the ring . You must change this if you are running multiple nodes ! <nl> + - - > <nl> + < Seeds > <nl> + < Seed > 127 . 0 . 0 . 1 < / Seed > <nl> + < / Seeds > <nl> + <nl> + <nl> + < ! - - Miscellaneous - - > <nl> + <nl> + < ! - - Time to wait for a reply from other nodes before failing the command - - > <nl> + < RpcTimeoutInMillis > 5000 < / RpcTimeoutInMillis > <nl> + < ! - - Size to allow commitlog to grow to before creating a new segment - - > <nl> + < CommitLogRotationThresholdInMB > 128 < / CommitLogRotationThresholdInMB > <nl> + <nl> + <nl> + < ! - - Local hosts and ports - - > <nl> + <nl> + < ! - - <nl> + ~ Address to bind to and tell other nodes to connect to . You _ must _ <nl> + ~ change this if you want multiple nodes to be able to communicate ! <nl> + ~ <nl> + ~ Leaving it blank leaves it up to InetAddress . getLocalHost ( ) . This <nl> + ~ will always do the Right Thing * if * the node is properly configured <nl> + ~ ( hostname , name resolution , etc ) , and the Right Thing is to use the <nl> + ~ address associated with the hostname ( it might not be ) . <nl> + - - > <nl> + < ListenAddress > localhost < / ListenAddress > <nl> + < ! - - TCP port , for commands and data - - > <nl> + < StoragePort > 7000 < / StoragePort > <nl> + < ! - - UDP port , for membership communications ( gossip ) - - > <nl> + < ControlPort > 7001 < / ControlPort > <nl> + <nl> + < ! - - <nl> + ~ The address to bind the Thrift RPC service to . Unlike ListenAddress <nl> + ~ above , you * can * specify 0 . 0 . 0 . 0 here if you want Thrift to listen on <nl> + ~ all interfaces . <nl> + ~ <nl> + ~ Leaving this blank has the same effect it does for ListenAddress , <nl> + ~ ( i . e . it will be based on the configured hostname of the node ) . <nl> + - - > <nl> + < ThriftAddress > localhost < / ThriftAddress > <nl> + < ! - - Thrift RPC port ( the port clients connect to ) . - - > <nl> + < ThriftPort > 9160 < / ThriftPort > <nl> + < ! - - <nl> + ~ Whether or not to use a framed transport for Thrift . If this option <nl> + ~ is set to true then you must also use a framed transport on the <nl> + ~ client - side , ( framed and non - framed transports are not compatible ) . <nl> + - - > <nl> + < ThriftFramedTransport > false < / ThriftFramedTransport > <nl> + <nl> + <nl> + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> + < ! - - Memory , Disk , and Performance - - > <nl> + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > <nl> + <nl> + < ! - - <nl> + ~ Buffer size to use when performing contiguous column slices . Increase <nl> + ~ this to the size of the column slices you typically perform . <nl> + ~ ( Name - based queries are performed with a buffer size of <nl> + ~ ColumnIndexSizeInKB . ) <nl> + - - > <nl> + < SlicedBufferSizeInKB > 64 < / SlicedBufferSizeInKB > <nl> + <nl> + < ! - - <nl> + ~ Buffer size to use when flushing memtables to disk . ( Only one <nl> + ~ memtable is ever flushed at a time . ) Increase ( decrease ) the index <nl> + ~ buffer size relative to the data buffer if you have few ( many ) <nl> + ~ columns per key . Bigger is only better _ if _ your memtables get large <nl> + ~ enough to use the space . ( Check in your data directory after your <nl> + ~ app has been running long enough . ) - - > <nl> + < FlushDataBufferSizeInMB > 32 < / FlushDataBufferSizeInMB > <nl> + < FlushIndexBufferSizeInMB > 8 < / FlushIndexBufferSizeInMB > <nl> + <nl> + < ! - - <nl> + ~ Add column indexes to a row after its contents reach this size . <nl> + ~ Increase if your column values are large , or if you have a very large <nl> + ~ number of columns . The competing causes are , Cassandra has to <nl> + ~ deserialize this much of the row to read a single column , so you want <nl> + ~ it to be small - at least if you do many partial - row reads - but all <nl> + ~ the index data is read for each access , so you don ' t want to generate <nl> + ~ that wastefully either . <nl> + - - > <nl> + < ColumnIndexSizeInKB > 64 < / ColumnIndexSizeInKB > <nl> + <nl> + < ! - - <nl> + ~ The maximum amount of data to store in memory per ColumnFamily before <nl> + ~ flushing to disk . Note : There is one memtable per column family , and <nl> + ~ this threshold is based solely on the amount of data stored , not <nl> + ~ actual heap memory usage ( there is some overhead in indexing the <nl> + ~ columns ) . <nl> + - - > <nl> + < MemtableSizeInMB > 64 < / MemtableSizeInMB > <nl> + < ! - - <nl> + ~ The maximum number of columns in millions to store in memory per <nl> + ~ ColumnFamily before flushing to disk . This is also a per - memtable <nl> + ~ setting . Use with MemtableSizeInMB to tune memory usage . <nl> + - - > <nl> + < MemtableObjectCountInMillions > 0 . 1 < / MemtableObjectCountInMillions > <nl> + <nl> + < ! - - <nl> + ~ Unlike most systems , in Cassandra writes are faster than reads , so <nl> + ~ you can afford more of those in parallel . A good rule of thumb is 2 <nl> + ~ concurrent reads per processor core . Increase ConcurrentWrites to <nl> + ~ the number of clients writing at once if you enable CommitLogSync + <nl> + ~ CommitLogSyncDelay . - - > <nl> + < ConcurrentReads > 8 < / ConcurrentReads > <nl> + < ConcurrentWrites > 32 < / ConcurrentWrites > <nl> + <nl> + < ! - - <nl> + ~ CommitLogSync may be either " periodic " or " batch . " When in batch <nl> + ~ mode , Cassandra won ' t ack writes until the commit log has been <nl> + ~ fsynced to disk . It will wait up to CommitLogSyncBatchWindowInMS <nl> + ~ milliseconds for other writes , before performing the sync . <nl> + <nl> + ~ This is less necessary in Cassandra than in traditional databases <nl> + ~ since replication reduces the odds of losing data from a failure <nl> + ~ after writing the log entry but before it actually reaches the disk . <nl> + ~ So the other option is " timed , " where writes may be acked immediately <nl> + ~ and the CommitLog is simply synced every CommitLogSyncPeriodInMS <nl> + ~ milliseconds . <nl> + - - > <nl> + < CommitLogSync > periodic < / CommitLogSync > <nl> + < ! - - <nl> + ~ Interval at which to perform syncs of the CommitLog in periodic mode . <nl> + ~ Usually the default of 1000ms is fine ; increase it only if the <nl> + ~ CommitLog PendingTasks backlog in jmx shows that you are frequently <nl> + ~ scheduling a second sync while the first has not yet been processed . <nl> + - - > <nl> + < CommitLogSyncPeriodInMS > 1000 < / CommitLogSyncPeriodInMS > <nl> + < ! - - <nl> + ~ Delay ( in milliseconds ) during which additional commit log entries <nl> + ~ may be written before fsync in batch mode . This will increase <nl> + ~ latency slightly , but can vastly improve throughput where there are <nl> + ~ many writers . Set to zero to disable ( each entry will be synced <nl> + ~ individually ) . Reasonable values range from a minimal 0 . 1 to 10 or <nl> + ~ even more if throughput matters more than latency . <nl> + - - > <nl> + < ! - - < CommitLogSyncBatchWindowInMS > 1 < / CommitLogSyncBatchWindowInMS > - - > <nl> + <nl> + < ! - - <nl> + ~ Time to wait before garbage - collection deletion markers . Set this to <nl> + ~ a large enough value that you are confident that the deletion marker <nl> + ~ will be propagated to all replicas by the time this many seconds has <nl> + ~ elapsed , even in the face of hardware failures . The default value is <nl> + ~ ten days . <nl> + - - > <nl> + < GCGraceSeconds > 864000 < / GCGraceSeconds > <nl> < / Storage >

TEST DIFF:
diff - - git a / doc / cql3 / CQL . textile b / doc / cql3 / CQL . textile 
 index 7fa333d . . ca09627 100644 
 - - - a / doc / cql3 / CQL . textile 
 + + + b / doc / cql3 / CQL . textile 
 @ @ - 1806 , 15 + 1806 , 18 @ @ The @ now @ function takes no arguments and generates a new unique timeuuid ( at th 
 bc ( sample ) . 
 SELECT * FROM myTable WHERE t = now ( ) 
 
 + 
 will never return any result by design , since the value returned by @ now ( ) @ is guaranteed to be unique . 
 
 h4 . @ minTimeuuid @ and @ maxTimeuuid @ 
 
 The @ minTimeuuid @ ( resp . @ maxTimeuuid @ ) function takes a @ timestamp @ value @ t @ ( which can be " either a timestamp or a date string " : # usingtimestamps ) and return a _ fake _ @ timeuuid @ corresponding to the _ smallest _ ( resp . _ biggest _ ) possible @ timeuuid @ having for timestamp @ t @ . So for instance : 
 - 
 + 
 + 
 bc ( sample ) . 
 SELECT * FROM myTable WHERE t > maxTimeuuid ( ' 2013 - 01 - 01 00 : 05 + 0000 ' ) AND t < minTimeuuid ( ' 2013 - 02 - 02 10 : 00 + 0000 ' ) 
 - 
 + 
 + 
 will select all rows where the @ timeuuid @ column @ t @ is strictly older than ' 2013 - 01 - 01 00 : 05 + 0000 ' but strictly younger than ' 2013 - 02 - 02 10 : 00 + 0000 ' . Please note that @ t > = maxTimeuuid ( ' 2013 - 01 - 01 00 : 05 + 0000 ' ) @ would still _ not _ select a @ timeuuid @ generated exactly at ' 2013 - 01 - 01 00 : 05 + 0000 ' and is essentially equivalent to @ t > maxTimeuuid ( ' 2013 - 01 - 01 00 : 05 + 0000 ' ) @ . 
 
 _ Warning _ : We called the values generated by @ minTimeuuid @ and @ maxTimeuuid @ _ fake _ UUID because they do no respect the Time - Based UUID generation process specified by the " RFC 4122 " : http : / / www . ietf . org / rfc / rfc4122 . txt . In particular , the value returned by these 2 methods will not be unique . This means you should only use those methods for querying ( as in the example above ) . Inserting the result of those methods is almost certainly _ a bad idea _ . 
 @ @ - 1846 , 30 + 1849 , 36 @ @ h3 ( # countFct ) . Count 
 
 The @ count @ function can be used to count the rows returned by a query . Example : 
 
 - bc ( sample ) . 
 + bc ( sample ) . 
 SELECT COUNT ( * ) FROM plays ; 
 SELECT COUNT ( 1 ) FROM plays ; 
 
 It also can be used to count the non null value of a given column . Example : 
 
 - bc ( sample ) . 
 + bc ( sample ) . 
 SELECT COUNT ( scores ) FROM plays ; 
 
 h3 ( # maxMinFcts ) . Max and Min 
 
 The @ max @ and @ min @ functions can be used to compute the maximum and the minimum value returned by a query for a given column . 
 
 - bc ( sample ) . 
 + bc ( sample ) . 
 SELECT MIN ( players ) , MAX ( players ) FROM plays WHERE game = ' quake ' ; 
 
 h3 ( # sumFct ) . Sum 
 
 The @ sum @ function can be used to sum up all the values returned by a query for a given column . 
 
 - h3 ( # sumFct ) . Avg 
 + bc ( sample ) . 
 + SELECT SUM ( players ) FROM plays ; 
 + 
 + h3 ( # avgFct ) . Avg 
 
 The @ avg @ function can be used to compute the average of all the values returned by a query for a given column . 
 
 + bc ( sample ) . 
 + SELECT AVG ( players ) FROM plays ; 
 + 
 h2 ( # udfs ) . User - Defined Functions 
 
 User - defined functions allow execution of user - provided code in Cassandra . By default , Cassandra supports defining functions in _ Java _ and _ JavaScript _ . Support for other JSR 223 compliant scripting languages ( such as Python , Ruby , and Scala ) can be added by adding a JAR to the classpath .

NEAREST DIFF:
diff - - git a / conf / storage - conf . xml b / conf / storage - conf . xml 
 index 3728ade . . ef5e229 100644 
 - - - a / conf / storage - conf . xml 
 + + + b / conf / storage - conf . xml 
 @ @ - 15 , 272 + 15 , 297 @ @ 
 ~ KIND , either express or implied . See the License for the 
 ~ specific language governing permissions and limitations 
 ~ under the License . 
 - - - > 
 + - - > 
 < Storage > 
 - < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 - < ! - - Basic Configuration - - > 
 - < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 - 
 - < ! - - The name of this cluster . This is mainly used to prevent machines in 
 - one logical cluster from joining any other cluster . - - > 
 - < ClusterName > Test Cluster < / ClusterName > 
 - 
 - < ! - - Keyspaces and ColumnFamilies 
 - A ColumnFamily is the Cassandra concept closest to a relational table . 
 - Keyspaces are separate groups of ColumnFamilies . Except in very 
 - unusual circumstances you will have one Keyspace per application . 
 - 
 - There is an implicit keyspace named ' system ' for Cassandra internals . 
 - 
 - The default ColumnSort is Time for standard column families . 
 - For super column families , specifying ColumnSort is not supported ; 
 - the supercolumns themselves are always name - sorted and their subcolumns 
 - are always time - sorted . 
 - - - > 
 - < Keyspaces > 
 - < Keyspace Name = " Keyspace1 " > 
 - < ! - - The fraction of keys per sstable whose locations we 
 - keep in memory in " mostly LRU " order . ( JUST the key 
 - locations , NOT any column values . ) 
 - 
 - The amount of memory used by the default setting of 
 - 0 . 01 is comparable to the amount used by the internal 
 - per - sstable key index . Consider increasing this is 
 - fine if you have fewer , wider rows . Set to 0 to 
 - disable entirely . 
 - - - > 
 - < KeysCachedFraction > 0 . 01 < / KeysCachedFraction > 
 - < ! - - 
 - The CompareWith attribute tells Cassandra how to sort the columns 
 - for slicing operations . For backwards compatibility , the default 
 - is to use AsciiType , which is probably NOT what you want . 
 - Other options are BytesType , UTF8Type , LexicalUUIDType , TimeUUIDType , and LongType . 
 - You can also specify the fully - qualified class name to a class 
 - of your choice implementing org . apache . cassandra . db . marshal . IType . 
 - 
 - SuperColumns have a similar CompareSubcolumnsWith attribute . 
 - 
 - ByteType : simple sort by byte value . No validation is performed . 
 - AsciiType : like BytesType , but validates that the input can be parsed as US - ASCII . 
 - UTF8Type : A string encoded as UTF8 
 - LongType : A 64bit long 
 - LexicalUUIDType : a 128bit UUID , compared lexically ( by byte value ) 
 - TimeUUIDType : a 128bit version 1 UUID , compared by timestamp 
 - 
 - ( To get the closest approximation to 0 . 3 - style supercolumns , 
 - you would use CompareWith = UTF8Type CompareSubcolumnsWith = LongType . ) 
 - 
 - if FlushPeriodInMinutes is configured and positive , it will be 
 - flushed to disk with that period whether it is dirty or not . 
 - This is intended for lightly - used columnfamilies so that they 
 - do not prevent commitlog segments from being purged . 
 - 
 - - - > 
 - < ColumnFamily CompareWith = " UTF8Type " Name = " Standard1 " FlushPeriodInMinutes = " 60 " / > 
 - < ColumnFamily CompareWith = " UTF8Type " Name = " Standard2 " / > 
 - < ColumnFamily CompareWith = " TimeUUIDType " Name = " StandardByUUID1 " / > 
 - < ColumnFamily ColumnType = " Super " CompareWith = " UTF8Type " CompareSubcolumnsWith = " UTF8Type " Name = " Super1 " / > 
 - < / Keyspace > 
 - < / Keyspaces > 
 - 
 - < ! - - Partitioner : any IPartitioner may be used , including your own 
 - as long as it is on the classpath . Out of the box , 
 - Cassandra provides 
 - org . apache . cassandra . dht . RandomPartitioner , 
 - org . apache . cassandra . dht . OrderPreservingPartitioner , and 
 - org . apache . cassandra . dht . CollatingOrderPreservingPartitioner . 
 - ( CollatingOPP colates according to EN , US rules , not naive byte ordering . 
 - Use this as an example if you need locale - aware collation . ) 
 - Range queries require using OrderPreservingPartitioner or a subclass . 
 - 
 - Achtung ! Changing this parameter requires wiping your data directories , 
 - since the partitioner can modify the sstable on - disk format . 
 - - - > 
 - < Partitioner > org . apache . cassandra . dht . RandomPartitioner < / Partitioner > 
 - 
 - < ! - - If you are using the OrderPreservingPartitioner and you know your key 
 - distribution , you can specify the token for this node to use . 
 - ( Keys are sent to the node with the " closest " token , so distributing 
 - your tokens equally along the key distribution space will spread 
 - keys evenly across your cluster . ) This setting is only checked the 
 - first time a node is started . 
 - 
 - This can also be useful with RandomPartitioner to force equal 
 - spacing of tokens around the hash space , especially for 
 - clusters with a small number of nodes . - - > 
 - < InitialToken > < / InitialToken > 
 - 
 - 	 
 - < ! - - EndPointSnitch : Setting this to the class that implements IEndPointSnitch 
 - 	 which will see if two endpoints are in the same data center or on the same rack . 
 - Out of the box , Cassandra provides 
 - org . apache . cassandra . locator . EndPointSnitch 
 - - - > 
 - < EndPointSnitch > org . apache . cassandra . locator . EndPointSnitch < / EndPointSnitch > 
 - 
 - < ! - - Strategy : Setting this to the class that implements IReplicaPlacementStrategy 
 - 	 will change the way the node picker works . 
 - Out of the box , Cassandra provides 
 - org . apache . cassandra . locator . RackUnawareStrategy 
 - org . apache . cassandra . locator . RackAwareStrategy 
 - 	 	 ( place one replica in a different datacenter , and the 
 - others on different racks in the same one . ) 
 - - - > 
 - < ReplicaPlacementStrategy > org . apache . cassandra . locator . RackUnawareStrategy < / ReplicaPlacementStrategy > 
 - 
 - < ! - - Number of replicas of the data - - > 
 - < ReplicationFactor > 1 < / ReplicationFactor > 
 - 
 - < ! - - Directories : Specify where Cassandra should store different data on disk 
 - Keep the data disks and the CommitLog disks separate for best performance 
 - - - > 
 - < CommitLogDirectory > / var / cassandra / commitlog < / CommitLogDirectory > 
 - < DataFileDirectories > 
 - < DataFileDirectory > / var / cassandra / data < / DataFileDirectory > 
 - < / DataFileDirectories > 
 - < BootstrapFileDirectory > / var / cassandra / bootstrap < / BootstrapFileDirectory > 
 - < StagingFileDirectory > / var / cassandra / staging < / StagingFileDirectory > 
 - 
 - 
 - < ! - - Addresses of hosts that are deemed contact points . Cassandra nodes use 
 - this list of hosts to find each other and learn the topology of the ring . 
 - You must change this if you are running multiple nodes ! 
 - - - > 
 - < Seeds > 
 - < Seed > 127 . 0 . 0 . 1 < / Seed > 
 - < / Seeds > 
 - 
 - 
 - < ! - - Miscellaneous - - > 
 - 
 - < ! - - time to wait for a reply from other nodes before failing the command - - > 
 - < RpcTimeoutInMillis > 5000 < / RpcTimeoutInMillis > 
 - < ! - - size to allow commitlog to grow to before creating a new segment - - > 
 - < CommitLogRotationThresholdInMB > 128 < / CommitLogRotationThresholdInMB > 
 - 
 - 
 - < ! - - Local hosts and ports - - > 
 - 
 - < ! - - Address to bind to and tell other nodes to connect to . 
 - You _ must _ change this if you want multiple nodes to be able 
 - to communicate ! 
 - 
 - Leaving it blank leaves it up to InetAddress . getLocalHost ( ) . 
 - This will always do the Right Thing * if * the node is properly 
 - configured ( hostname , name resolution , etc ) , and the Right 
 - Thing is to use the address associated with the hostname ( it 
 - might not be ) . - - > 
 - < ListenAddress > localhost < / ListenAddress > 
 - < ! - - TCP port , for commands and data - - > 
 - < StoragePort > 7000 < / StoragePort > 
 - < ! - - UDP port , for membership communications ( gossip ) - - > 
 - < ControlPort > 7001 < / ControlPort > 
 - 
 - < ! - - The address to bind the Thrift RPC service to . Unlike 
 - ListenAddress above , you * can * specify 0 . 0 . 0 . 0 here if you want 
 - Thrift to listen on all interfaces . 
 - 
 - Leaving this blank has the same effect it does for ListenAddress , 
 - ( i . e . it will be based on the configured hostname of the node ) . 
 - - - > 
 - < ThriftAddress > localhost < / ThriftAddress > 
 - < ! - - Thrift RPC port ( the port clients connect to ) . - - > 
 - < ThriftPort > 9160 < / ThriftPort > 
 - < ! - - Whether or not to use a framed transport for Thrift . If this option 
 - is set to true then you must also use a framed transport on the 
 - client - side , ( framed and non - framed transports are not compatible ) . 
 - - - > 
 - < ThriftFramedTransport > false < / ThriftFramedTransport > 
 - 
 - 
 - < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 - < ! - - Memory , Disk , and Performance - - > 
 - < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 - 
 - < ! - - Buffer size to use when performing contiguous column slices . 
 - Increase this to the size of the column slices you typically 
 - perform . ( Name - based queries are performed with a buffer size 
 - of ColumnIndexSizeInKB . ) - - > 
 - < SlicedBufferSizeInKB > 64 < / SlicedBufferSizeInKB > 
 - 
 - < ! - - Buffer size to use when flushing memtables to disk . 
 - ( Only one memtable is ever flushed at a time . ) 
 - Increase ( decrease ) the index buffer size relative to the data buffer 
 - if you have few ( many ) columns per key . 
 - Bigger is only better _ if _ your memtables get large enough to use the space . 
 - ( Check in your data directory after your app has been running long enough . ) 
 + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 + < ! - - Basic Configuration - - > 
 + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 + 
 + < ! - - 
 + ~ The name of this cluster . This is mainly used to prevent machines in 
 + ~ one logical cluster from joining another . 
 + - - > 
 + < ClusterName > Test Cluster < / ClusterName > 
 + 
 + < ! - - 
 + ~ Keyspaces and ColumnFamilies : 
 + ~ A ColumnFamily is the Cassandra concept closest to a relational 
 + ~ table . Keyspaces are separate groups of ColumnFamilies . Except in 
 + ~ very unusual circumstances you will have one Keyspace per application . 
 + 
 + ~ There is an implicit keyspace named ' system ' for Cassandra internals . 
 + 
 + ~ The default ColumnSort is Time for standard column families . For 
 + ~ super column families , specifying ColumnSort is not supported ; the 
 + ~ supercolumns themselves are always name - sorted and their subcolumns 
 + ~ are always time - sorted . 
 + - - > 
 + < Keyspaces > 
 + < Keyspace Name = " Keyspace1 " > 
 + < ! - - 
 + ~ The fraction of keys per sstable whose locations we keep in 
 + ~ memory in " mostly LRU " order . ( JUST the key locations , NOT any 
 + ~ column values . ) 
 + 
 + ~ The amount of memory used by the default setting of 0 . 01 is 
 + ~ comparable to the amount used by the internal per - sstable key 
 + ~ index . Consider increasing this if you have fewer , wider rows . 
 + ~ Set to 0 to disable entirely . 
 - - > 
 - < FlushDataBufferSizeInMB > 32 < / FlushDataBufferSizeInMB > 
 - < FlushIndexBufferSizeInMB > 8 < / FlushIndexBufferSizeInMB > 
 - 
 - < ! - - Add column indexes to a row after its contents reach this size . 
 - Increase if your column values are large , or if you have a very large 
 - number of columns . The competing causes are , Cassandra has to 
 - deserialize this much of the row to read a single column , so you 
 - want it to be small - at least if you do many partial - row reads 
 - - but all the index data is read for each access , so 
 - you don ' t want to generate that wastefully either . - - > 
 - < ColumnIndexSizeInKB > 64 < / ColumnIndexSizeInKB > 
 - 
 - < ! - - 
 - The maximum amount of data to store in memory per ColumnFamily before flushing to 
 - disk . Note : There is one memtable per column family , and this threshold 
 - is based solely on the amount of data stored , not actual heap memory 
 - usage ( there is some overhead in indexing the columns ) . 
 - - - > 
 - < MemtableSizeInMB > 64 < / MemtableSizeInMB > 
 - < ! - - 
 - The maximum number of columns in millions to store in memory per ColumnFamily 
 - before flushing to disk . This is also a per - memtable setting . 
 - Use with MemtableSizeInMB to tune memory usage . 
 - - - > 
 - < MemtableObjectCountInMillions > 0 . 1 < / MemtableObjectCountInMillions > 
 - 
 - < ! - - Unlike most systems , in Cassandra writes are faster than 
 - reads , so you can afford more of those in parallel . 
 - 	 A good rule of thumb is 2 concurrent reads per processor core . 
 - Increase ConcurrentWrites to the number of clients writing 
 - at once if you enable CommitLogSync + CommitLogSyncDelay . - - > 
 - < ConcurrentReads > 8 < / ConcurrentReads > 
 - < ConcurrentWrites > 32 < / ConcurrentWrites > 
 - 
 - < ! - - CommitLogSync may be either " periodic " or " batch . " 
 - When in batch mode , Cassandra won ' t ack writes until the commit log 
 - has been fsynced to disk . It will wait up to CommitLogSyncBatchWindowInMS 
 - milliseconds for other writes , before performing the sync . 
 - 
 - This is less necessary in Cassandra 
 - than in traditional databases since replication reduces the 
 - odds of losing data from a failure after writing the log 
 - entry but before it actually reaches the disk . So the other 
 - option is " timed , " where wirtes may be acked immediately 
 - and the CommitLog is simply synced every CommitLogSyncPeriodInMS 
 - milliseconds . 
 - - - > 
 - < CommitLogSync > periodic < / CommitLogSync > 
 - < ! - - Interval at which to perform syncs of the CommitLog in periodic 
 - mode . Usually the default of 1000ms is fine ; increase it 
 - only if the CommitLog PendingTasks backlog in jmx shows that 
 - you are frequently scheduling a second sync while the first 
 - has not yet been processed . 
 - - - > 
 - < CommitLogSyncPeriodInMS > 1000 < / CommitLogSyncPeriodInMS > 
 - < ! - - Delay ( in microseconds ) during which additional commit log 
 - entries may be written before fsync in batch mode . This will increase 
 - latency slightly , but can vastly improve throughput where 
 - there are many writers . Set to zero to disable 
 - ( each entry will be synced individually ) . 
 - 	 Reasonable values range from a minimal 0 . 1 to 10 or even more 
 - if throughput matters more than latency . 
 - - - > 
 - < ! - - < CommitLogSyncBatchWindowInMS > 1 < / CommitLogSyncBatchWindowInMS > - - > 
 - 
 - 
 - < ! - - Time to wait before garbage - collection deletion markers . 
 - Set this to a large enough value that you are confident 
 - that the deletion marker will be propagated to all replicas 
 - by the time this many seconds has elapsed , even in the 
 - face of hardware failures . The default value is ten days . 
 - - - > 
 - < GCGraceSeconds > 864000 < / GCGraceSeconds > 
 + < KeysCachedFraction > 0 . 01 < / KeysCachedFraction > 
 + < ! - - 
 + ~ The CompareWith attribute tells Cassandra how to sort the columns 
 + ~ for slicing operations . For backwards compatibility , the default 
 + ~ is to use AsciiType , which is probably NOT what you want . Other 
 + ~ options are BytesType , UTF8Type , LexicalUUIDType , TimeUUIDType , 
 + ~ and LongType . You can also specify the fully - qualified class 
 + ~ name to a class of your choice implementing 
 + ~ org . apache . cassandra . db . marshal . IType . 
 + ~ 
 + ~ SuperColumns have a similar CompareSubcolumnsWith attribute . 
 + ~ 
 + ~ ByteType : Simple sort by byte value . No validation is performed . 
 + ~ AsciiType : Like BytesType , but validates that the input can be 
 + ~ parsed as US - ASCII . 
 + ~ UTF8Type : A string encoded as UTF8 
 + ~ LongType : A 64bit long 
 + ~ LexicalUUIDType : A 128bit UUID , compared lexically ( by byte value ) 
 + ~ TimeUUIDType : a 128bit version 1 UUID , compared by timestamp 
 + ~ 
 + ~ ( To get the closest approximation to 0 . 3 - style supercolumns , you 
 + ~ would use CompareWith = UTF8Type CompareSubcolumnsWith = LongType . ) 
 + 
 + ~ If FlushPeriodInMinutes is configured and positive , it will be 
 + ~ flushed to disk with that period whether it is dirty or not . This 
 + ~ is intended for lightly - used columnfamilies so that they do not 
 + ~ prevent commitlog segments from being purged . 
 + - - > 
 + < ColumnFamily CompareWith = " UTF8Type " 
 + Name = " Standard1 " 
 + FlushPeriodInMinutes = " 60 " / > 
 + < ColumnFamily CompareWith = " UTF8Type " Name = " Standard2 " / > 
 + < ColumnFamily CompareWith = " TimeUUIDType " Name = " StandardByUUID1 " / > 
 + < ColumnFamily ColumnType = " Super " 
 + CompareWith = " UTF8Type " 
 + CompareSubcolumnsWith = " UTF8Type " 
 + Name = " Super1 " / > 
 + < / Keyspace > 
 + < / Keyspaces > 
 + 
 + < ! - - 
 + ~ Partitioner : any IPartitioner may be used , including your own as long 
 + ~ as it is on the classpath . Out of the box , Cassandra provides 
 + ~ org . apache . cassandra . dht . RandomPartitioner , 
 + ~ org . apache . cassandra . dht . OrderPreservingPartitioner , and 
 + ~ org . apache . cassandra . dht . CollatingOrderPreservingPartitioner . 
 + ~ ( CollatingOPP colates according to EN , US rules , not naive byte 
 + ~ ordering . Use this as an example if you need locale - aware collation . ) 
 + ~ Range queries require using OrderPreservingPartitioner or a subclass . 
 + 
 + ~ Achtung ! Changing this parameter requires wiping your data 
 + ~ directories , since the partitioner can modify the sstable on - disk 
 + ~ format . 
 + - - > 
 + < Partitioner > org . apache . cassandra . dht . RandomPartitioner < / Partitioner > 
 + 
 + < ! - - 
 + ~ If you are using the OrderPreservingPartitioner and you know your key 
 + ~ distribution , you can specify the token for this node to use . ( Keys 
 + ~ are sent to the node with the " closest " token , so distributing your 
 + ~ tokens equally along the key distribution space will spread keys 
 + ~ evenly across your cluster . ) This setting is only checked the first 
 + ~ time a node is started . 
 + 
 + ~ This can also be useful with RandomPartitioner to force equal spacing 
 + ~ of tokens around the hash space , especially for clusters with a small 
 + ~ number of nodes . 
 + - - > 
 + < InitialToken > < / InitialToken > 
 + 
 + < ! - - 
 + ~ EndPointSnitch : Setting this to the class that implements 
 + ~ IEndPointSnitch which will see if two endpoints are in the same data 
 + ~ center or on the same rack . Out of the box , Cassandra provides 
 + ~ org . apache . cassandra . locator . EndPointSnitch 
 + - - > 
 + < EndPointSnitch > org . apache . cassandra . locator . EndPointSnitch < / EndPointSnitch > 
 + 
 + < ! - - 
 + ~ Strategy : Setting this to the class that implements 
 + ~ IReplicaPlacementStrategy will change the way the node picker works . 
 + ~ Out of the box , Cassandra provides 
 + ~ org . apache . cassandra . locator . RackUnawareStrategy and 
 + ~ org . apache . cassandra . locator . RackAwareStrategy ( place one replica in 
 + ~ a different datacenter , and the others on different racks in the same 
 + ~ one . ) 
 + - - > 
 + < ReplicaPlacementStrategy > org . apache . cassandra . locator . RackUnawareStrategy < / ReplicaPlacementStrategy > 
 + 
 + < ! - - Number of replicas of the data - - > 
 + < ReplicationFactor > 1 < / ReplicationFactor > 
 + 
 + < ! - - 
 + ~ Directories : Specify where Cassandra should store different data on 
 + ~ disk . Keep the data disks and the CommitLog disks separate for best 
 + ~ performance 
 + - - > 
 + < CommitLogDirectory > / var / lib / cassandra / commitlog < / CommitLogDirectory > 
 + < DataFileDirectories > 
 + < DataFileDirectory > / var / lib / cassandra / data < / DataFileDirectory > 
 + < / DataFileDirectories > 
 + < CalloutLocation > / var / lib / cassandra / callouts < / CalloutLocation > 
 + < BootstrapFileDirectory > / var / lib / cassandra / bootstrap < / BootstrapFileDirectory > 
 + < StagingFileDirectory > / var / lib / cassandra / staging < / StagingFileDirectory > 
 + 
 + 
 + < ! - - 
 + ~ Addresses of hosts that are deemed contact points . Cassandra nodes 
 + ~ use this list of hosts to find each other and learn the topology of 
 + ~ the ring . You must change this if you are running multiple nodes ! 
 + - - > 
 + < Seeds > 
 + < Seed > 127 . 0 . 0 . 1 < / Seed > 
 + < / Seeds > 
 + 
 + 
 + < ! - - Miscellaneous - - > 
 + 
 + < ! - - Time to wait for a reply from other nodes before failing the command - - > 
 + < RpcTimeoutInMillis > 5000 < / RpcTimeoutInMillis > 
 + < ! - - Size to allow commitlog to grow to before creating a new segment - - > 
 + < CommitLogRotationThresholdInMB > 128 < / CommitLogRotationThresholdInMB > 
 + 
 + 
 + < ! - - Local hosts and ports - - > 
 + 
 + < ! - - 
 + ~ Address to bind to and tell other nodes to connect to . You _ must _ 
 + ~ change this if you want multiple nodes to be able to communicate ! 
 + ~ 
 + ~ Leaving it blank leaves it up to InetAddress . getLocalHost ( ) . This 
 + ~ will always do the Right Thing * if * the node is properly configured 
 + ~ ( hostname , name resolution , etc ) , and the Right Thing is to use the 
 + ~ address associated with the hostname ( it might not be ) . 
 + - - > 
 + < ListenAddress > localhost < / ListenAddress > 
 + < ! - - TCP port , for commands and data - - > 
 + < StoragePort > 7000 < / StoragePort > 
 + < ! - - UDP port , for membership communications ( gossip ) - - > 
 + < ControlPort > 7001 < / ControlPort > 
 + 
 + < ! - - 
 + ~ The address to bind the Thrift RPC service to . Unlike ListenAddress 
 + ~ above , you * can * specify 0 . 0 . 0 . 0 here if you want Thrift to listen on 
 + ~ all interfaces . 
 + ~ 
 + ~ Leaving this blank has the same effect it does for ListenAddress , 
 + ~ ( i . e . it will be based on the configured hostname of the node ) . 
 + - - > 
 + < ThriftAddress > localhost < / ThriftAddress > 
 + < ! - - Thrift RPC port ( the port clients connect to ) . - - > 
 + < ThriftPort > 9160 < / ThriftPort > 
 + < ! - - 
 + ~ Whether or not to use a framed transport for Thrift . If this option 
 + ~ is set to true then you must also use a framed transport on the 
 + ~ client - side , ( framed and non - framed transports are not compatible ) . 
 + - - > 
 + < ThriftFramedTransport > false < / ThriftFramedTransport > 
 + 
 + 
 + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 + < ! - - Memory , Disk , and Performance - - > 
 + < ! - - = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = - - > 
 + 
 + < ! - - 
 + ~ Buffer size to use when performing contiguous column slices . Increase 
 + ~ this to the size of the column slices you typically perform . 
 + ~ ( Name - based queries are performed with a buffer size of 
 + ~ ColumnIndexSizeInKB . ) 
 + - - > 
 + < SlicedBufferSizeInKB > 64 < / SlicedBufferSizeInKB > 
 + 
 + < ! - - 
 + ~ Buffer size to use when flushing memtables to disk . ( Only one 
 + ~ memtable is ever flushed at a time . ) Increase ( decrease ) the index 
 + ~ buffer size relative to the data buffer if you have few ( many ) 
 + ~ columns per key . Bigger is only better _ if _ your memtables get large 
 + ~ enough to use the space . ( Check in your data directory after your 
 + ~ app has been running long enough . ) - - > 
 + < FlushDataBufferSizeInMB > 32 < / FlushDataBufferSizeInMB > 
 + < FlushIndexBufferSizeInMB > 8 < / FlushIndexBufferSizeInMB > 
 + 
 + < ! - - 
 + ~ Add column indexes to a row after its contents reach this size . 
 + ~ Increase if your column values are large , or if you have a very large 
 + ~ number of columns . The competing causes are , Cassandra has to 
 + ~ deserialize this much of the row to read a single column , so you want 
 + ~ it to be small - at least if you do many partial - row reads - but all 
 + ~ the index data is read for each access , so you don ' t want to generate 
 + ~ that wastefully either . 
 + - - > 
 + < ColumnIndexSizeInKB > 64 < / ColumnIndexSizeInKB > 
 + 
 + < ! - - 
 + ~ The maximum amount of data to store in memory per ColumnFamily before 
 + ~ flushing to disk . Note : There is one memtable per column family , and 
 + ~ this threshold is based solely on the amount of data stored , not 
 + ~ actual heap memory usage ( there is some overhead in indexing the 
 + ~ columns ) . 
 + - - > 
 + < MemtableSizeInMB > 64 < / MemtableSizeInMB > 
 + < ! - - 
 + ~ The maximum number of columns in millions to store in memory per 
 + ~ ColumnFamily before flushing to disk . This is also a per - memtable 
 + ~ setting . Use with MemtableSizeInMB to tune memory usage . 
 + - - > 
 + < MemtableObjectCountInMillions > 0 . 1 < / MemtableObjectCountInMillions > 
 + 
 + < ! - - 
 + ~ Unlike most systems , in Cassandra writes are faster than reads , so 
 + ~ you can afford more of those in parallel . A good rule of thumb is 2 
 + ~ concurrent reads per processor core . Increase ConcurrentWrites to 
 + ~ the number of clients writing at once if you enable CommitLogSync + 
 + ~ CommitLogSyncDelay . - - > 
 + < ConcurrentReads > 8 < / ConcurrentReads > 
 + < ConcurrentWrites > 32 < / ConcurrentWrites > 
 + 
 + < ! - - 
 + ~ CommitLogSync may be either " periodic " or " batch . " When in batch 
 + ~ mode , Cassandra won ' t ack writes until the commit log has been 
 + ~ fsynced to disk . It will wait up to CommitLogSyncBatchWindowInMS 
 + ~ milliseconds for other writes , before performing the sync . 
 + 
 + ~ This is less necessary in Cassandra than in traditional databases 
 + ~ since replication reduces the odds of losing data from a failure 
 + ~ after writing the log entry but before it actually reaches the disk . 
 + ~ So the other option is " timed , " where writes may be acked immediately 
 + ~ and the CommitLog is simply synced every CommitLogSyncPeriodInMS 
 + ~ milliseconds . 
 + - - > 
 + < CommitLogSync > periodic < / CommitLogSync > 
 + < ! - - 
 + ~ Interval at which to perform syncs of the CommitLog in periodic mode . 
 + ~ Usually the default of 1000ms is fine ; increase it only if the 
 + ~ CommitLog PendingTasks backlog in jmx shows that you are frequently 
 + ~ scheduling a second sync while the first has not yet been processed . 
 + - - > 
 + < CommitLogSyncPeriodInMS > 1000 < / CommitLogSyncPeriodInMS > 
 + < ! - - 
 + ~ Delay ( in milliseconds ) during which additional commit log entries 
 + ~ may be written before fsync in batch mode . This will increase 
 + ~ latency slightly , but can vastly improve throughput where there are 
 + ~ many writers . Set to zero to disable ( each entry will be synced 
 + ~ individually ) . Reasonable values range from a minimal 0 . 1 to 10 or 
 + ~ even more if throughput matters more than latency . 
 + - - > 
 + < ! - - < CommitLogSyncBatchWindowInMS > 1 < / CommitLogSyncBatchWindowInMS > - - > 
 + 
 + < ! - - 
 + ~ Time to wait before garbage - collection deletion markers . Set this to 
 + ~ a large enough value that you are confident that the deletion marker 
 + ~ will be propagated to all replicas by the time this many seconds has 
 + ~ elapsed , even in the face of hardware failures . The default value is 
 + ~ ten days . 
 + - - > 
 + < GCGraceSeconds > 864000 < / GCGraceSeconds > 
 < / Storage >
