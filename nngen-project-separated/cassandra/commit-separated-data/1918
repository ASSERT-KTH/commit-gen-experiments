BLEU SCORE: 0.018738883683389617

TEST MSG: Fix DISTINCT queries w / limits / paging and tombstoned partitions
GENERATED MSG: merge from 0 . 6

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index adb374a . . 0c7e9a2 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 6 @ @ <nl> 2 . 0 . 12 : <nl> + * Fix DISTINCT queries with LIMITs or paging when some partitions <nl> + contain only tombstones ( CASSANDRA - 8490 ) <nl> * Introduce background cache refreshing to permissions cache <nl> ( CASSANDRA - 8194 ) <nl> * Fix race condition in StreamTransferTask that could lead to <nl> diff - - git a / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java b / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java <nl> index f08f6b8 . . 19615b6 100644 <nl> - - - a / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java <nl> + + + b / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java <nl> @ @ - 450 , 7 + 450 , 11 @ @ public class SelectStatement implements CQLStatement , MeasurableForPreparedCache <nl> / / For distinct , we only care about fetching the beginning of each partition . If we don ' t have <nl> / / static columns , we in fact only care about the first cell , so we query only that ( we don ' t " group " ) . <nl> / / If we do have static columns , we do need to fetch the first full group ( to have the static columns values ) . <nl> - return new SliceQueryFilter ( ColumnSlice . ALL _ COLUMNS _ ARRAY , false , 1 , selectsStaticColumns ? toGroup : - 1 ) ; <nl> + <nl> + / / See the comments on IGNORE _ TOMBSTONED _ PARTITIONS and CASSANDRA - 8490 for why we use a special value for <nl> + / / DISTINCT queries on the partition key only . <nl> + toGroup = selectsStaticColumns ? toGroup : SliceQueryFilter . IGNORE _ TOMBSTONED _ PARTITIONS ; <nl> + return new SliceQueryFilter ( ColumnSlice . ALL _ COLUMNS _ ARRAY , false , 1 , toGroup ) ; <nl> } <nl> else if ( isColumnRange ( ) ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / db / AbstractRangeCommand . java b / src / java / org / apache / cassandra / db / AbstractRangeCommand . java <nl> index 45302e2 . . 4ddcb8d 100644 <nl> - - - a / src / java / org / apache / cassandra / db / AbstractRangeCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / AbstractRangeCommand . java <nl> @ @ - 57 , 6 + 57 , 19 @ @ public abstract class AbstractRangeCommand implements IReadCommand <nl> <nl> public abstract int limit ( ) ; <nl> public abstract boolean countCQL3Rows ( ) ; <nl> + <nl> + / * * <nl> + * Returns true if tombstoned partitions should not be included in results or count towards the limit . <nl> + * See CASSANDRA - 8490 for more details on why this is needed ( and done this way ) . <nl> + * * / <nl> + public boolean ignoredTombstonedPartitions ( ) <nl> + { <nl> + if ( ! ( predicate instanceof SliceQueryFilter ) ) <nl> + return false ; <nl> + <nl> + return ( ( SliceQueryFilter ) predicate ) . compositesToGroup = = SliceQueryFilter . IGNORE _ TOMBSTONED _ PARTITIONS ; <nl> + } <nl> + <nl> public abstract List < Row > executeLocally ( ) ; <nl> <nl> public long getTimeout ( ) <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index 7bd2a59 . . e936473 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 1749 , 6 + 1749 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> List < Row > rows = new ArrayList < Row > ( ) ; <nl> int columnsCount = 0 ; <nl> int total = 0 , matched = 0 ; <nl> + boolean ignoreTombstonedPartitions = filter . ignoreTombstonedPartitions ( ) ; <nl> <nl> try <nl> { <nl> @ @ - 1784 , 7 + 1785 , 8 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> } <nl> <nl> rows . add ( new Row ( rawRow . key , data ) ) ; <nl> - matched + + ; <nl> + if ( ! ignoreTombstonedPartitions | | ! data . hasOnlyTombstones ( filter . timestamp ) ) <nl> + matched + + ; <nl> <nl> if ( data ! = null ) <nl> columnsCount + = filter . lastCounted ( data ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / DataRange . java b / src / java / org / apache / cassandra / db / DataRange . java <nl> index b8b8daf . . 774a3aa 100644 <nl> - - - a / src / java / org / apache / cassandra / db / DataRange . java <nl> + + + b / src / java / org / apache / cassandra / db / DataRange . java <nl> @ @ - 87 , 6 + 87 , 18 @ @ public class DataRange <nl> return keyRange . right ; <nl> } <nl> <nl> + / * * <nl> + * Returns true if tombstoned partitions should not be included in results or count towards the limit . <nl> + * See CASSANDRA - 8490 for more details on why this is needed ( and done this way ) . <nl> + * * / <nl> + public boolean ignoredTombstonedPartitions ( ) <nl> + { <nl> + if ( ! ( columnFilter instanceof SliceQueryFilter ) ) <nl> + return false ; <nl> + <nl> + return ( ( SliceQueryFilter ) columnFilter ) . compositesToGroup = = SliceQueryFilter . IGNORE _ TOMBSTONED _ PARTITIONS ; <nl> + } <nl> + <nl> / / Whether the bounds of this DataRange actually wraps around . <nl> public boolean isWrapAround ( ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / db / filter / ExtendedFilter . java b / src / java / org / apache / cassandra / db / filter / ExtendedFilter . java <nl> index 5c3662b . . 82e889d 100644 <nl> - - - a / src / java / org / apache / cassandra / db / filter / ExtendedFilter . java <nl> + + + b / src / java / org / apache / cassandra / db / filter / ExtendedFilter . java <nl> @ @ - 127 , 6 + 127 , 12 @ @ public abstract class ExtendedFilter <nl> * / <nl> public abstract ColumnFamily prune ( DecoratedKey key , ColumnFamily data ) ; <nl> <nl> + / * * Returns true if tombstoned partitions should not be included in results or count towards the limit , false otherwise . * / <nl> + public boolean ignoreTombstonedPartitions ( ) <nl> + { <nl> + return dataRange . ignoredTombstonedPartitions ( ) ; <nl> + } <nl> + <nl> / * * <nl> * @ return true if the provided data satisfies all the expressions from <nl> * the clause of this filter . <nl> diff - - git a / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java b / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java <nl> index 58a0303 . . 858578f 100644 <nl> - - - a / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java <nl> + + + b / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java <nl> @ @ - 42 , 6 + 42 , 12 @ @ public class SliceQueryFilter implements IDiskAtomFilter <nl> private static final Logger logger = LoggerFactory . getLogger ( SliceQueryFilter . class ) ; <nl> public static final Serializer serializer = new Serializer ( ) ; <nl> <nl> + / * * <nl> + * A special value for compositesToGroup that indicates that partitioned tombstones should not be included in results <nl> + * or count towards the limit . See CASSANDRA - 8490 for more details on why this is needed ( and done this way ) . <nl> + * * / <nl> + public static final int IGNORE _ TOMBSTONED _ PARTITIONS = - 2 ; <nl> + <nl> public final ColumnSlice [ ] slices ; <nl> public final boolean reversed ; <nl> public volatile int count ; <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageProxy . java b / src / java / org / apache / cassandra / service / StorageProxy . java <nl> index 1e1a2a3 . . 45af1c8 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageProxy . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageProxy . java <nl> @ @ - 1499 , 7 + 1499 , 8 @ @ public class StorageProxy implements StorageProxyMBean <nl> / / now scan until we have enough results <nl> try <nl> { <nl> - int cql3RowCount = 0 ; <nl> + int liveRowCount = 0 ; <nl> + boolean countLiveRows = command . countCQL3Rows ( ) | | command . ignoredTombstonedPartitions ( ) ; <nl> rows = new ArrayList < > ( ) ; <nl> <nl> / / when dealing with LocalStrategy keyspaces , we can skip the range splitting and merging ( which can be <nl> @ @ - 1594 , 8 + 1595 , 8 @ @ public class StorageProxy implements StorageProxyMBean <nl> for ( Row row : handler . get ( ) ) <nl> { <nl> rows . add ( row ) ; <nl> - if ( nodeCmd . countCQL3Rows ( ) ) <nl> - cql3RowCount + = row . getLiveCount ( command . predicate , command . timestamp ) ; <nl> + if ( countLiveRows ) <nl> + liveRowCount + = row . getLiveCount ( command . predicate , command . timestamp ) ; <nl> } <nl> FBUtilities . waitOnFutures ( resolver . repairResults , DatabaseDescriptor . getWriteRpcTimeout ( ) ) ; <nl> } <nl> @ @ - 1636 , 7 + 1637 , 7 @ @ public class StorageProxy implements StorageProxyMBean <nl> } <nl> <nl> / / if we ' re done , great , otherwise , move to the next range <nl> - int count = nodeCmd . countCQL3Rows ( ) ? cql3RowCount : rows . size ( ) ; <nl> + int count = countLiveRows ? liveRowCount : rows . size ( ) ; <nl> if ( count > = nodeCmd . limit ( ) ) <nl> break ; <nl> } <nl> @ @ - 1652 , 8 + 1653 , 8 @ @ public class StorageProxy implements StorageProxyMBean <nl> <nl> private static List < Row > trim ( AbstractRangeCommand command , List < Row > rows ) <nl> { <nl> - / / When maxIsColumns , we let the caller trim the result . <nl> - if ( command . countCQL3Rows ( ) ) <nl> + / / for CQL3 queries , let the caller trim the results <nl> + if ( command . countCQL3Rows ( ) | | command . ignoredTombstonedPartitions ( ) ) <nl> return rows ; <nl> else <nl> return rows . size ( ) > command . limit ( ) ? rows . subList ( 0 , command . limit ( ) ) : rows ;
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 8d9e2ea . . c97b17f 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 7 + 1 , 10 @ @ <nl> dev <nl> * sstable versioning ( CASSANDRA - 389 ) <nl> <nl> - 0 . 6 . 0 - dev <nl> + 0 . 6 . 0 - RC1 <nl> + * fix compaction bucketing bug ( CASSANDRA - 814 ) <nl> + <nl> + 0 . 6 . 0 - beta1 / beta2 <nl> * add batch _ mutate thrift command , deprecating batch _ insert ( CASSANDRA - 336 ) <nl> * remove get _ key _ range Thrift API , deprecated in 0 . 5 ( CASSANDRA - 710 ) <nl> * add optional login ( ) Thrift call for authentication ( CASSANDRA - 547 ) <nl> @ @ - 42 , 7 + 45 , 9 @ @ dev <nl> * allow larger numbers of keys ( > 140M ) in a sstable bloom filter <nl> ( CASSANDRA - 790 ) <nl> * include jvm argument improvements from CASSANDRA - 504 in debian package <nl> - * change streaming chunk size to 32MB ( was 64MB ) ( CASSANDRA - 795 ) <nl> + * change streaming chunk size to 32MB to accomodate Windows XP limitations <nl> + ( was 64MB ) ( CASSANDRA - 795 ) <nl> + * fix get _ range _ slice returning results in the wrong order ( CASSANDRA - 781 ) <nl> <nl> <nl> 0 . 5 . 0 final <nl> diff - - git a / build . xml b / build . xml <nl> index ea79876 . . 54ef12d 100644 <nl> - - - a / build . xml <nl> + + + b / build . xml <nl> @ @ - 314 , 6 + 314 , 7 @ @ <nl> < include name = " * * " / > <nl> < exclude name = " build / * * " / > <nl> < exclude name = " src / gen - java / * * " / > <nl> + < exclude name = " interface / avro / * * " / > <nl> < / tarfileset > <nl> < / tar > <nl> < / target > <nl> diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> index fbd5ebb . . 1b5b6b1 100644 <nl> - - - a / src / java / org / apache / cassandra / db / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> @ @ - 89 , 7 + 89 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> return 0 ; <nl> } <nl> logger . debug ( " Checking to see if compaction of " + cfs . columnFamily _ + " would be useful " ) ; <nl> - Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> + Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> updateEstimateFor ( cfs , buckets ) ; <nl> <nl> for ( List < SSTableReader > sstables : buckets ) <nl> @ @ - 441 , 7 + 441 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> / * <nl> * Group files of similar size into buckets . <nl> * / <nl> - static Set < List < SSTableReader > > getCompactionBuckets ( Iterable < SSTableReader > files , long min ) <nl> + static Set < List < SSTableReader > > getBuckets ( Iterable < SSTableReader > files , long min ) <nl> { <nl> Map < List < SSTableReader > , Long > buckets = new HashMap < List < SSTableReader > , Long > ( ) ; <nl> for ( SSTableReader sstable : files ) <nl> @ @ - 461 , 7 + 461 , 8 @ @ public class CompactionManager implements CompactionManagerMBean <nl> { <nl> / / remove and re - add because adding changes the hash <nl> buckets . remove ( bucket ) ; <nl> - averageSize = ( averageSize + size ) / 2 ; <nl> + long totalSize = bucket . size ( ) * averageSize ; <nl> + averageSize = ( totalSize + size ) / ( bucket . size ( ) + 1 ) ; <nl> bucket . add ( sstable ) ; <nl> buckets . put ( bucket , averageSize ) ; <nl> bFound = true ; <nl> @ @ - 538 , 7 + 539 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> public void run ( ) <nl> { <nl> logger . debug ( " Estimating compactions for " + cfs . columnFamily _ ) ; <nl> - final Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> + final Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> updateEstimateFor ( cfs , buckets ) ; <nl> } <nl> } ;

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index adb374a . . 0c7e9a2 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 6 @ @ 
 2 . 0 . 12 : 
 + * Fix DISTINCT queries with LIMITs or paging when some partitions 
 + contain only tombstones ( CASSANDRA - 8490 ) 
 * Introduce background cache refreshing to permissions cache 
 ( CASSANDRA - 8194 ) 
 * Fix race condition in StreamTransferTask that could lead to 
 diff - - git a / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java b / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java 
 index f08f6b8 . . 19615b6 100644 
 - - - a / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java 
 + + + b / src / java / org / apache / cassandra / cql3 / statements / SelectStatement . java 
 @ @ - 450 , 7 + 450 , 11 @ @ public class SelectStatement implements CQLStatement , MeasurableForPreparedCache 
 / / For distinct , we only care about fetching the beginning of each partition . If we don ' t have 
 / / static columns , we in fact only care about the first cell , so we query only that ( we don ' t " group " ) . 
 / / If we do have static columns , we do need to fetch the first full group ( to have the static columns values ) . 
 - return new SliceQueryFilter ( ColumnSlice . ALL _ COLUMNS _ ARRAY , false , 1 , selectsStaticColumns ? toGroup : - 1 ) ; 
 + 
 + / / See the comments on IGNORE _ TOMBSTONED _ PARTITIONS and CASSANDRA - 8490 for why we use a special value for 
 + / / DISTINCT queries on the partition key only . 
 + toGroup = selectsStaticColumns ? toGroup : SliceQueryFilter . IGNORE _ TOMBSTONED _ PARTITIONS ; 
 + return new SliceQueryFilter ( ColumnSlice . ALL _ COLUMNS _ ARRAY , false , 1 , toGroup ) ; 
 } 
 else if ( isColumnRange ( ) ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / db / AbstractRangeCommand . java b / src / java / org / apache / cassandra / db / AbstractRangeCommand . java 
 index 45302e2 . . 4ddcb8d 100644 
 - - - a / src / java / org / apache / cassandra / db / AbstractRangeCommand . java 
 + + + b / src / java / org / apache / cassandra / db / AbstractRangeCommand . java 
 @ @ - 57 , 6 + 57 , 19 @ @ public abstract class AbstractRangeCommand implements IReadCommand 
 
 public abstract int limit ( ) ; 
 public abstract boolean countCQL3Rows ( ) ; 
 + 
 + / * * 
 + * Returns true if tombstoned partitions should not be included in results or count towards the limit . 
 + * See CASSANDRA - 8490 for more details on why this is needed ( and done this way ) . 
 + * * / 
 + public boolean ignoredTombstonedPartitions ( ) 
 + { 
 + if ( ! ( predicate instanceof SliceQueryFilter ) ) 
 + return false ; 
 + 
 + return ( ( SliceQueryFilter ) predicate ) . compositesToGroup = = SliceQueryFilter . IGNORE _ TOMBSTONED _ PARTITIONS ; 
 + } 
 + 
 public abstract List < Row > executeLocally ( ) ; 
 
 public long getTimeout ( ) 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index 7bd2a59 . . e936473 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 1749 , 6 + 1749 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 List < Row > rows = new ArrayList < Row > ( ) ; 
 int columnsCount = 0 ; 
 int total = 0 , matched = 0 ; 
 + boolean ignoreTombstonedPartitions = filter . ignoreTombstonedPartitions ( ) ; 
 
 try 
 { 
 @ @ - 1784 , 7 + 1785 , 8 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 } 
 
 rows . add ( new Row ( rawRow . key , data ) ) ; 
 - matched + + ; 
 + if ( ! ignoreTombstonedPartitions | | ! data . hasOnlyTombstones ( filter . timestamp ) ) 
 + matched + + ; 
 
 if ( data ! = null ) 
 columnsCount + = filter . lastCounted ( data ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / DataRange . java b / src / java / org / apache / cassandra / db / DataRange . java 
 index b8b8daf . . 774a3aa 100644 
 - - - a / src / java / org / apache / cassandra / db / DataRange . java 
 + + + b / src / java / org / apache / cassandra / db / DataRange . java 
 @ @ - 87 , 6 + 87 , 18 @ @ public class DataRange 
 return keyRange . right ; 
 } 
 
 + / * * 
 + * Returns true if tombstoned partitions should not be included in results or count towards the limit . 
 + * See CASSANDRA - 8490 for more details on why this is needed ( and done this way ) . 
 + * * / 
 + public boolean ignoredTombstonedPartitions ( ) 
 + { 
 + if ( ! ( columnFilter instanceof SliceQueryFilter ) ) 
 + return false ; 
 + 
 + return ( ( SliceQueryFilter ) columnFilter ) . compositesToGroup = = SliceQueryFilter . IGNORE _ TOMBSTONED _ PARTITIONS ; 
 + } 
 + 
 / / Whether the bounds of this DataRange actually wraps around . 
 public boolean isWrapAround ( ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / db / filter / ExtendedFilter . java b / src / java / org / apache / cassandra / db / filter / ExtendedFilter . java 
 index 5c3662b . . 82e889d 100644 
 - - - a / src / java / org / apache / cassandra / db / filter / ExtendedFilter . java 
 + + + b / src / java / org / apache / cassandra / db / filter / ExtendedFilter . java 
 @ @ - 127 , 6 + 127 , 12 @ @ public abstract class ExtendedFilter 
 * / 
 public abstract ColumnFamily prune ( DecoratedKey key , ColumnFamily data ) ; 
 
 + / * * Returns true if tombstoned partitions should not be included in results or count towards the limit , false otherwise . * / 
 + public boolean ignoreTombstonedPartitions ( ) 
 + { 
 + return dataRange . ignoredTombstonedPartitions ( ) ; 
 + } 
 + 
 / * * 
 * @ return true if the provided data satisfies all the expressions from 
 * the clause of this filter . 
 diff - - git a / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java b / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java 
 index 58a0303 . . 858578f 100644 
 - - - a / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java 
 + + + b / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java 
 @ @ - 42 , 6 + 42 , 12 @ @ public class SliceQueryFilter implements IDiskAtomFilter 
 private static final Logger logger = LoggerFactory . getLogger ( SliceQueryFilter . class ) ; 
 public static final Serializer serializer = new Serializer ( ) ; 
 
 + / * * 
 + * A special value for compositesToGroup that indicates that partitioned tombstones should not be included in results 
 + * or count towards the limit . See CASSANDRA - 8490 for more details on why this is needed ( and done this way ) . 
 + * * / 
 + public static final int IGNORE _ TOMBSTONED _ PARTITIONS = - 2 ; 
 + 
 public final ColumnSlice [ ] slices ; 
 public final boolean reversed ; 
 public volatile int count ; 
 diff - - git a / src / java / org / apache / cassandra / service / StorageProxy . java b / src / java / org / apache / cassandra / service / StorageProxy . java 
 index 1e1a2a3 . . 45af1c8 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageProxy . java 
 + + + b / src / java / org / apache / cassandra / service / StorageProxy . java 
 @ @ - 1499 , 7 + 1499 , 8 @ @ public class StorageProxy implements StorageProxyMBean 
 / / now scan until we have enough results 
 try 
 { 
 - int cql3RowCount = 0 ; 
 + int liveRowCount = 0 ; 
 + boolean countLiveRows = command . countCQL3Rows ( ) | | command . ignoredTombstonedPartitions ( ) ; 
 rows = new ArrayList < > ( ) ; 
 
 / / when dealing with LocalStrategy keyspaces , we can skip the range splitting and merging ( which can be 
 @ @ - 1594 , 8 + 1595 , 8 @ @ public class StorageProxy implements StorageProxyMBean 
 for ( Row row : handler . get ( ) ) 
 { 
 rows . add ( row ) ; 
 - if ( nodeCmd . countCQL3Rows ( ) ) 
 - cql3RowCount + = row . getLiveCount ( command . predicate , command . timestamp ) ; 
 + if ( countLiveRows ) 
 + liveRowCount + = row . getLiveCount ( command . predicate , command . timestamp ) ; 
 } 
 FBUtilities . waitOnFutures ( resolver . repairResults , DatabaseDescriptor . getWriteRpcTimeout ( ) ) ; 
 } 
 @ @ - 1636 , 7 + 1637 , 7 @ @ public class StorageProxy implements StorageProxyMBean 
 } 
 
 / / if we ' re done , great , otherwise , move to the next range 
 - int count = nodeCmd . countCQL3Rows ( ) ? cql3RowCount : rows . size ( ) ; 
 + int count = countLiveRows ? liveRowCount : rows . size ( ) ; 
 if ( count > = nodeCmd . limit ( ) ) 
 break ; 
 } 
 @ @ - 1652 , 8 + 1653 , 8 @ @ public class StorageProxy implements StorageProxyMBean 
 
 private static List < Row > trim ( AbstractRangeCommand command , List < Row > rows ) 
 { 
 - / / When maxIsColumns , we let the caller trim the result . 
 - if ( command . countCQL3Rows ( ) ) 
 + / / for CQL3 queries , let the caller trim the results 
 + if ( command . countCQL3Rows ( ) | | command . ignoredTombstonedPartitions ( ) ) 
 return rows ; 
 else 
 return rows . size ( ) > command . limit ( ) ? rows . subList ( 0 , command . limit ( ) ) : rows ;

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 8d9e2ea . . c97b17f 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 7 + 1 , 10 @ @ 
 dev 
 * sstable versioning ( CASSANDRA - 389 ) 
 
 - 0 . 6 . 0 - dev 
 + 0 . 6 . 0 - RC1 
 + * fix compaction bucketing bug ( CASSANDRA - 814 ) 
 + 
 + 0 . 6 . 0 - beta1 / beta2 
 * add batch _ mutate thrift command , deprecating batch _ insert ( CASSANDRA - 336 ) 
 * remove get _ key _ range Thrift API , deprecated in 0 . 5 ( CASSANDRA - 710 ) 
 * add optional login ( ) Thrift call for authentication ( CASSANDRA - 547 ) 
 @ @ - 42 , 7 + 45 , 9 @ @ dev 
 * allow larger numbers of keys ( > 140M ) in a sstable bloom filter 
 ( CASSANDRA - 790 ) 
 * include jvm argument improvements from CASSANDRA - 504 in debian package 
 - * change streaming chunk size to 32MB ( was 64MB ) ( CASSANDRA - 795 ) 
 + * change streaming chunk size to 32MB to accomodate Windows XP limitations 
 + ( was 64MB ) ( CASSANDRA - 795 ) 
 + * fix get _ range _ slice returning results in the wrong order ( CASSANDRA - 781 ) 
 
 
 0 . 5 . 0 final 
 diff - - git a / build . xml b / build . xml 
 index ea79876 . . 54ef12d 100644 
 - - - a / build . xml 
 + + + b / build . xml 
 @ @ - 314 , 6 + 314 , 7 @ @ 
 < include name = " * * " / > 
 < exclude name = " build / * * " / > 
 < exclude name = " src / gen - java / * * " / > 
 + < exclude name = " interface / avro / * * " / > 
 < / tarfileset > 
 < / tar > 
 < / target > 
 diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java 
 index fbd5ebb . . 1b5b6b1 100644 
 - - - a / src / java / org / apache / cassandra / db / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / CompactionManager . java 
 @ @ - 89 , 7 + 89 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 return 0 ; 
 } 
 logger . debug ( " Checking to see if compaction of " + cfs . columnFamily _ + " would be useful " ) ; 
 - Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 + Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 updateEstimateFor ( cfs , buckets ) ; 
 
 for ( List < SSTableReader > sstables : buckets ) 
 @ @ - 441 , 7 + 441 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 / * 
 * Group files of similar size into buckets . 
 * / 
 - static Set < List < SSTableReader > > getCompactionBuckets ( Iterable < SSTableReader > files , long min ) 
 + static Set < List < SSTableReader > > getBuckets ( Iterable < SSTableReader > files , long min ) 
 { 
 Map < List < SSTableReader > , Long > buckets = new HashMap < List < SSTableReader > , Long > ( ) ; 
 for ( SSTableReader sstable : files ) 
 @ @ - 461 , 7 + 461 , 8 @ @ public class CompactionManager implements CompactionManagerMBean 
 { 
 / / remove and re - add because adding changes the hash 
 buckets . remove ( bucket ) ; 
 - averageSize = ( averageSize + size ) / 2 ; 
 + long totalSize = bucket . size ( ) * averageSize ; 
 + averageSize = ( totalSize + size ) / ( bucket . size ( ) + 1 ) ; 
 bucket . add ( sstable ) ; 
 buckets . put ( bucket , averageSize ) ; 
 bFound = true ; 
 @ @ - 538 , 7 + 539 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 public void run ( ) 
 { 
 logger . debug ( " Estimating compactions for " + cfs . columnFamily _ ) ; 
 - final Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 + final Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 updateEstimateFor ( cfs , buckets ) ; 
 } 
 } ;
