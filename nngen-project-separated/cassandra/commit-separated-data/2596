BLEU SCORE: 0.041961149062965476

TEST MSG: Remove 1 . 2 sstable support in 2 . 1
GENERATED MSG: Always record row - level tombstones in index component

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 196fa0d . . c224c8f 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 34 , 6 + 34 , 7 @ @ <nl> * Add multiple memory allocation options for memtables ( CASSANDRA - 6689 ) <nl> * Remove adjusted op rate from stress output ( CASSANDRA - 6921 ) <nl> * Add optimized CF . hasColumns ( ) implementations ( CASSANDRA - 6941 ) <nl> + * Properly remove 1 . 2 sstable support in 2 . 1 ( CASSANDRA - 6869 ) <nl> Merged from 2 . 0 : <nl> * Restrict Windows to parallel repairs ( CASSANDRA - 6907 ) <nl> * ( Hadoop ) Allow manually specifying start / end tokens in CFIF ( CASSANDRA - 6436 ) <nl> diff - - git a / NEWS . txt b / NEWS . txt <nl> index 23f6522 . . 7cb7565 100644 <nl> - - - a / NEWS . txt <nl> + + + b / NEWS . txt <nl> @ @ - 33 , 11 + 33 , 11 @ @ New features <nl> <nl> Upgrading <nl> - - - - - - - - - <nl> - - Rolling upgrades from anything pre - 2 . 0 . 6 is not supported . <nl> - - For leveled compaction users , 2 . 0 must be atleast started before <nl> - upgrading to 2 . 1 due to the fact that the old JSON leveled <nl> - manifest is migrated into the sstable metadata files on startup <nl> - in 2 . 0 and this code is gone from 2 . 1 . <nl> + - Rolling upgrades from anything pre - 2 . 0 . 6 is not supported . Furthermore <nl> + - Pre - 2 . 0 sstables are not supported . This means that before upgrading <nl> + a node a 2 . 1 , this node must be started on 2 . 0 and <nl> + ' nodetool upgdradesstables ' must be run ( and this even in the case <nl> + of no - rolling upgrades ) . <nl> - For size - tiered compaction users , Cassandra now defaults to ignoring <nl> the coldest 5 % of sstables . This can be customized with the <nl> cold _ reads _ to _ omit compaction option ; 0 . 0 omits nothing ( the old <nl> diff - - git a / src / java / org / apache / cassandra / config / CFMetaData . java b / src / java / org / apache / cassandra / config / CFMetaData . java <nl> index 8a4f147 . . 1ca9880 100644 <nl> - - - a / src / java / org / apache / cassandra / config / CFMetaData . java <nl> + + + b / src / java / org / apache / cassandra / config / CFMetaData . java <nl> @ @ - 1379 , 16 + 1379 , 14 @ @ public final class CFMetaData <nl> return ( cfName + " _ " + columnName + " _ idx " ) . replaceAll ( " \ \ W " , " " ) ; <nl> } <nl> <nl> - public Iterator < OnDiskAtom > getOnDiskIterator ( DataInput in , int count , Descriptor . Version version ) <nl> + public Iterator < OnDiskAtom > getOnDiskIterator ( DataInput in , Descriptor . Version version ) <nl> { <nl> - return getOnDiskIterator ( in , count , ColumnSerializer . Flag . LOCAL , Integer . MIN _ VALUE , version ) ; <nl> + return getOnDiskIterator ( in , ColumnSerializer . Flag . LOCAL , Integer . MIN _ VALUE , version ) ; <nl> } <nl> <nl> - public Iterator < OnDiskAtom > getOnDiskIterator ( DataInput in , int count , ColumnSerializer . Flag flag , int expireBefore , Descriptor . Version version ) <nl> + public Iterator < OnDiskAtom > getOnDiskIterator ( DataInput in , ColumnSerializer . Flag flag , int expireBefore , Descriptor . Version version ) <nl> { <nl> - if ( version . hasSuperColumns & & cfType = = ColumnFamilyType . Super ) <nl> - return SuperColumns . onDiskIterator ( in , count , flag , expireBefore , comparator ) ; <nl> - return Cell . onDiskIterator ( in , count , flag , expireBefore , version , comparator ) ; <nl> + return Cell . onDiskIterator ( in , flag , expireBefore , version , comparator ) ; <nl> } <nl> <nl> public AtomDeserializer getOnDiskDeserializer ( DataInput in , Descriptor . Version version ) <nl> diff - - git a / src / java / org / apache / cassandra / db / Cell . java b / src / java / org / apache / cassandra / db / Cell . java <nl> index e807a21 . . 8db9770 100644 <nl> - - - a / src / java / org / apache / cassandra / db / Cell . java <nl> + + + b / src / java / org / apache / cassandra / db / Cell . java <nl> @ @ - 48 , 12 + 48 , 7 @ @ public class Cell implements OnDiskAtom <nl> <nl> private static final long EMPTY _ SIZE = ObjectSizes . measure ( new Cell ( CellNames . simpleDense ( ByteBuffer . allocate ( 1 ) ) ) ) ; <nl> <nl> - / * * <nl> - * For 2 . 0 - formatted sstables ( where column count is not stored ) , @ param count should be Integer . MAX _ VALUE , <nl> - * and we will look for the end - of - row column name marker instead of relying on that . <nl> - * / <nl> public static Iterator < OnDiskAtom > onDiskIterator ( final DataInput in , <nl> - final int count , <nl> final ColumnSerializer . Flag flag , <nl> final int expireBefore , <nl> final Descriptor . Version version , <nl> @ @ - 61 , 13 + 56 , 8 @ @ public class Cell implements OnDiskAtom <nl> { <nl> return new AbstractIterator < OnDiskAtom > ( ) <nl> { <nl> - int i = 0 ; <nl> - <nl> protected OnDiskAtom computeNext ( ) <nl> { <nl> - if ( i + + > = count ) <nl> - return endOfData ( ) ; <nl> - <nl> OnDiskAtom atom ; <nl> try <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index d66c501 . . b9cab4d 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 454 , 7 + 454 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> Descriptor desc = entry . getKey ( ) ; <nl> generations . add ( desc . generation ) ; <nl> if ( ! desc . isCompatible ( ) ) <nl> - throw new RuntimeException ( String . format ( " Incompatible SSTable found . Current version % s is unable to read file : % s . Please run upgradesstables . " , <nl> + throw new RuntimeException ( String . format ( " Incompatible SSTable found . Current version % s is unable to read file : % s . Please run upgradesstables . " , <nl> Descriptor . Version . CURRENT , desc ) ) ; <nl> } <nl> Collections . sort ( generations ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java <nl> index 22fe5fa . . 7012321 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java <nl> @ @ - 26 , 7 + 26 , 6 @ @ import com . google . common . collect . AbstractIterator ; <nl> <nl> import org . apache . cassandra . db . * ; <nl> import org . apache . cassandra . db . composites . CellNameType ; <nl> - import org . apache . cassandra . db . composites . CellNames ; <nl> import org . apache . cassandra . db . composites . Composite ; <nl> import org . apache . cassandra . db . filter . ColumnSlice ; <nl> import org . apache . cassandra . io . sstable . CorruptSSTableException ; <nl> @ @ - 113 , 8 + 112 , 6 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> in . seek ( rowEntry . position ) ; <nl> } <nl> sstable . partitioner . decorateKey ( ByteBufferUtil . readWithShortLength ( file ) ) ; <nl> - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) <nl> - file . readLong ( ) ; <nl> } <nl> <nl> public ColumnFamily getColumnFamily ( ) <nl> @ @ - 179 , 34 + 176 , 6 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> } <nl> } <nl> <nl> - static int indexFor ( SSTableReader sstable , Composite name , List < IndexHelper . IndexInfo > indexes , CellNameType comparator , boolean reversed , int startIdx ) <nl> - { <nl> - / / If it ' s a super CF and the sstable is from the old format , then the index will contain old format info , i . e . non composite <nl> - / / SC names . So we need to 1 ) use only the SC name part of the comparator and 2 ) extract only that part from ' name ' <nl> - if ( sstable . metadata . isSuper ( ) & & sstable . descriptor . version . hasSuperColumns ) <nl> - { <nl> - CellNameType scComparator = SuperColumns . scNameType ( comparator ) ; <nl> - Composite scName = CellNames . simpleDense ( SuperColumns . scName ( name ) ) ; <nl> - return IndexHelper . indexFor ( scName , indexes , scComparator , reversed , startIdx ) ; <nl> - } <nl> - return IndexHelper . indexFor ( name , indexes , comparator , reversed , startIdx ) ; <nl> - } <nl> - <nl> - static Composite forIndexComparison ( SSTableReader sstable , Composite name ) <nl> - { <nl> - / / See indexFor above . <nl> - return sstable . metadata . isSuper ( ) & & sstable . descriptor . version . hasSuperColumns <nl> - ? CellNames . simpleDense ( SuperColumns . scName ( name ) ) <nl> - : name ; <nl> - } <nl> - <nl> - static CellNameType comparatorForIndex ( SSTableReader sstable , CellNameType comparator ) <nl> - { <nl> - return sstable . metadata . isSuper ( ) & & sstable . descriptor . version . hasSuperColumns <nl> - ? SuperColumns . scNameType ( comparator ) <nl> - : comparator ; <nl> - } <nl> - <nl> private abstract class BlockFetcher <nl> { <nl> protected int currentSliceIdx ; <nl> @ @ - 247 , 22 + 216 , 16 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> return ! start . isEmpty ( ) & & comparator . compare ( name , start ) < 0 ; <nl> } <nl> <nl> - protected boolean isIndexEntryBeforeSliceStart ( Composite name ) <nl> - { <nl> - Composite start = currentStart ( ) ; <nl> - return ! start . isEmpty ( ) & & comparatorForIndex ( sstable , comparator ) . compare ( name , forIndexComparison ( sstable , start ) ) < 0 ; <nl> - } <nl> - <nl> protected boolean isColumnBeforeSliceFinish ( OnDiskAtom column ) <nl> { <nl> Composite finish = currentFinish ( ) ; <nl> return finish . isEmpty ( ) | | comparator . compare ( column . name ( ) , finish ) < = 0 ; <nl> } <nl> <nl> - protected boolean isIndexEntryAfterSliceFinish ( Composite name ) <nl> + protected boolean isAfterSliceFinish ( Composite name ) <nl> { <nl> Composite finish = currentFinish ( ) ; <nl> - return ! finish . isEmpty ( ) & & comparatorForIndex ( sstable , comparator ) . compare ( name , forIndexComparison ( sstable , finish ) ) > 0 ; <nl> + return ! finish . isEmpty ( ) & & comparator . compare ( name , finish ) > 0 ; <nl> } <nl> } <nl> <nl> @ @ - 293 , 7 + 256 , 7 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> { <nl> while ( + + currentSliceIdx < slices . length ) <nl> { <nl> - nextIndexIdx = indexFor ( sstable , slices [ currentSliceIdx ] . start , indexes , comparator , reversed , nextIndexIdx ) ; <nl> + nextIndexIdx = IndexHelper . indexFor ( slices [ currentSliceIdx ] . start , indexes , comparator , reversed , nextIndexIdx ) ; <nl> if ( nextIndexIdx < 0 | | nextIndexIdx > = indexes . size ( ) ) <nl> / / no index block for that slice <nl> continue ; <nl> @ @ - 302 , 12 + 265 , 12 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> IndexInfo info = indexes . get ( nextIndexIdx ) ; <nl> if ( reversed ) <nl> { <nl> - if ( ! isIndexEntryBeforeSliceStart ( info . lastName ) ) <nl> + if ( ! isBeforeSliceStart ( info . lastName ) ) <nl> return true ; <nl> } <nl> else <nl> { <nl> - if ( ! isIndexEntryAfterSliceFinish ( info . firstName ) ) <nl> + if ( ! isAfterSliceFinish ( info . firstName ) ) <nl> return true ; <nl> } <nl> } <nl> @ @ - 480 , 10 + 443 , 8 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> / / We remenber when we are whithin a slice to avoid some comparison <nl> boolean inSlice = false ; <nl> <nl> - int columnCount = sstable . descriptor . version . hasRowSizeAndColumnCount ? file . readInt ( ) : Integer . MAX _ VALUE ; <nl> AtomDeserializer deserializer = emptyColumnFamily . metadata ( ) . getOnDiskDeserializer ( file , sstable . descriptor . version ) ; <nl> - int deserialized = 0 ; <nl> - while ( deserializer . hasNext ( ) & & deserialized < columnCount ) <nl> + while ( deserializer . hasNext ( ) ) <nl> { <nl> / / col is before slice <nl> / / ( If in slice , don ' t bother checking that until we change slice ) <nl> @ @ - 491 , 7 + 452 , 6 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> if ( ! inSlice & & ! start . isEmpty ( ) & & deserializer . compareNextTo ( start ) < 0 ) <nl> { <nl> deserializer . skipNext ( ) ; <nl> - + + deserialized ; <nl> continue ; <nl> } <nl> <nl> @ @ - 501 , 7 + 461 , 6 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> { <nl> inSlice = true ; <nl> addColumn ( deserializer . readNext ( ) ) ; <nl> - + + deserialized ; <nl> } <nl> / / col is after slice . more slices ? <nl> else <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java <nl> index 374dedb . . 224b63f 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java <nl> @ @ - 109 , 8 + 109 , 6 @ @ public class SSTableNamesIterator extends AbstractIterator < OnDiskAtom > implement <nl> <nl> DecoratedKey keyInDisk = sstable . partitioner . decorateKey ( ByteBufferUtil . readWithShortLength ( file ) ) ; <nl> assert keyInDisk . equals ( key ) : String . format ( " % s ! = % s in % s " , keyInDisk , key , file . getPath ( ) ) ; <nl> - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) <nl> - file . readLong ( ) ; <nl> } <nl> <nl> indexList = indexEntry . columnsIndex ( ) ; <nl> @ @ - 137 , 8 + 135 , 7 @ @ public class SSTableNamesIterator extends AbstractIterator < OnDiskAtom > implement <nl> List < OnDiskAtom > result = new ArrayList < OnDiskAtom > ( ) ; <nl> if ( indexList . isEmpty ( ) ) <nl> { <nl> - int columnCount = sstable . descriptor . version . hasRowSizeAndColumnCount ? file . readInt ( ) : Integer . MAX _ VALUE ; <nl> - readSimpleColumns ( file , columns , result , columnCount ) ; <nl> + readSimpleColumns ( file , columns , result ) ; <nl> } <nl> else <nl> { <nl> @ @ - 149 , 9 + 146 , 9 @ @ public class SSTableNamesIterator extends AbstractIterator < OnDiskAtom > implement <nl> iter = result . iterator ( ) ; <nl> } <nl> <nl> - private void readSimpleColumns ( FileDataInput file , SortedSet < CellName > columnNames , List < OnDiskAtom > result , int columnCount ) <nl> + private void readSimpleColumns ( FileDataInput file , SortedSet < CellName > columnNames , List < OnDiskAtom > result ) <nl> { <nl> - Iterator < OnDiskAtom > atomIterator = cf . metadata ( ) . getOnDiskIterator ( file , columnCount , sstable . descriptor . version ) ; <nl> + Iterator < OnDiskAtom > atomIterator = cf . metadata ( ) . getOnDiskIterator ( file , sstable . descriptor . version ) ; <nl> int n = 0 ; <nl> while ( atomIterator . hasNext ( ) ) <nl> { <nl> @ @ - 186 , 13 + 183 , 12 @ @ public class SSTableNamesIterator extends AbstractIterator < OnDiskAtom > implement <nl> int lastIndexIdx = - 1 ; <nl> for ( CellName name : columnNames ) <nl> { <nl> - int index = IndexedSliceReader . indexFor ( sstable , name , indexList , comparator , false , lastIndexIdx ) ; <nl> + int index = IndexHelper . indexFor ( name , indexList , comparator , false , lastIndexIdx ) ; <nl> if ( index < 0 | | index = = indexList . size ( ) ) <nl> continue ; <nl> IndexHelper . IndexInfo indexInfo = indexList . get ( index ) ; <nl> / / Check the index block does contain the column names and that we haven ' t inserted this block yet . <nl> - if ( IndexedSliceReader . comparatorForIndex ( sstable , comparator ) . compare ( IndexedSliceReader . forIndexComparison ( sstable , name ) , indexInfo . firstName ) < 0 <nl> - | | index = = lastIndexIdx ) <nl> + if ( comparator . compare ( name , indexInfo . firstName ) < 0 | | index = = lastIndexIdx ) <nl> continue ; <nl> <nl> ranges . add ( indexInfo ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java <nl> index 7fb48e3 . . 702bddc 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java <nl> @ @ - 64 , 17 + 64 , 12 @ @ class SimpleSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskAt <nl> this . needsClosing = false ; <nl> } <nl> <nl> - Descriptor . Version version = sstable . descriptor . version ; <nl> - <nl> / / Skip key and data size <nl> ByteBufferUtil . skipShortLength ( file ) ; <nl> - if ( version . hasRowSizeAndColumnCount ) <nl> - file . readLong ( ) ; <nl> <nl> emptyColumnFamily = ArrayBackedSortedColumns . factory . create ( sstable . metadata ) ; <nl> emptyColumnFamily . delete ( DeletionTime . serializer . deserialize ( file ) ) ; <nl> - int columnCount = version . hasRowSizeAndColumnCount ? file . readInt ( ) : Integer . MAX _ VALUE ; <nl> - atomIterator = emptyColumnFamily . metadata ( ) . getOnDiskIterator ( file , columnCount , sstable . descriptor . version ) ; <nl> + atomIterator = emptyColumnFamily . metadata ( ) . getOnDiskIterator ( file , sstable . descriptor . version ) ; <nl> } <nl> catch ( IOException e ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / Scrubber . java b / src / java / org / apache / cassandra / db / compaction / Scrubber . java <nl> index 0a1e8c4 . . 01da2e1 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / Scrubber . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / Scrubber . java <nl> @ @ - 130 , 11 + 130 , 6 @ @ public class Scrubber implements Closeable <nl> try <nl> { <nl> key = sstable . partitioner . decorateKey ( ByteBufferUtil . readWithShortLength ( dataFile ) ) ; <nl> - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) <nl> - { <nl> - dataSize = dataFile . readLong ( ) ; <nl> - outputHandler . debug ( String . format ( " row % s is % s bytes " , ByteBufferUtil . bytesToHex ( key . key ) , dataSize ) ) ; <nl> - } <nl> } <nl> catch ( Throwable th ) <nl> { <nl> @ @ - 162 , 22 + 157 , 12 @ @ public class Scrubber implements Closeable <nl> long dataStartFromIndex = currentIndexKey = = null <nl> ? - 1 <nl> : rowStart + 2 + currentIndexKey . remaining ( ) ; <nl> - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) <nl> - dataStartFromIndex + = 8 ; <nl> long dataSizeFromIndex = nextRowPositionFromIndex - dataStartFromIndex ; <nl> <nl> - if ( ! sstable . descriptor . version . hasRowSizeAndColumnCount ) <nl> - { <nl> - dataSize = dataSizeFromIndex ; <nl> - / / avoid an NPE if key is null <nl> - String keyName = key = = null ? " ( unreadable key ) " : ByteBufferUtil . bytesToHex ( key . key ) ; <nl> - outputHandler . debug ( String . format ( " row % s is % s bytes " , keyName , dataSize ) ) ; <nl> - } <nl> - else <nl> - { <nl> - if ( currentIndexKey ! = null ) <nl> - outputHandler . debug ( String . format ( " Index doublecheck : row % s is % s bytes " , ByteBufferUtil . bytesToHex ( currentIndexKey ) , dataSizeFromIndex ) ) ; <nl> - } <nl> + dataSize = dataSizeFromIndex ; <nl> + / / avoid an NPE if key is null <nl> + String keyName = key = = null ? " ( unreadable key ) " : ByteBufferUtil . bytesToHex ( key . key ) ; <nl> + outputHandler . debug ( String . format ( " row % s is % s bytes " , keyName , dataSize ) ) ; <nl> <nl> assert currentIndexKey ! = null | | indexFile . isEOF ( ) ; <nl> <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / Descriptor . java b / src / java / org / apache / cassandra / io / sstable / Descriptor . java <nl> index 4803ae7 . . db6f13a 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / Descriptor . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / Descriptor . java <nl> @ @ - 49 , 7 + 49 , 6 @ @ public class Descriptor <nl> / / This needs to be at the begining for initialization sake <nl> public static final String current _ version = " ka " ; <nl> <nl> - / / ic ( 1 . 2 . 5 ) : omits per - row bloom filter of column names <nl> / / ja ( 2 . 0 . 0 ) : super columns are serialized as composites ( note that there is no real format change , <nl> / / this is mostly a marker to know if we should expect super columns or not . We do need <nl> / / a major version bump however , because we should not allow streaming of super columns <nl> @ @ - 69 , 12 + 68 , 6 @ @ public class Descriptor <nl> private final String version ; <nl> <nl> public final boolean isLatestVersion ; <nl> - public final boolean hasSuperColumns ; <nl> - public final boolean tracksMaxLocalDeletionTime ; <nl> - public final boolean hasBloomFilterFPChance ; <nl> - public final boolean offHeapSummaries ; <nl> - public final boolean hasRowSizeAndColumnCount ; <nl> - public final boolean tracksMaxMinColumnNames ; <nl> public final boolean hasPostCompressionAdlerChecksums ; <nl> public final boolean hasSamplingLevel ; <nl> public final boolean newStatsFile ; <nl> @ @ - 84 , 13 + 77 , 7 @ @ public class Descriptor <nl> public Version ( String version ) <nl> { <nl> this . version = version ; <nl> - tracksMaxLocalDeletionTime = version . compareTo ( " ja " ) > = 0 ; <nl> isLatestVersion = version . compareTo ( current _ version ) = = 0 ; <nl> - hasSuperColumns = version . compareTo ( " ja " ) < 0 ; <nl> - hasBloomFilterFPChance = version . compareTo ( " ja " ) > = 0 ; <nl> - offHeapSummaries = version . compareTo ( " ja " ) > = 0 ; <nl> - hasRowSizeAndColumnCount = version . compareTo ( " ja " ) < 0 ; <nl> - tracksMaxMinColumnNames = version . compareTo ( " ja " ) > = 0 ; <nl> hasPostCompressionAdlerChecksums = version . compareTo ( " jb " ) > = 0 ; <nl> hasSamplingLevel = version . compareTo ( " ka " ) > = 0 ; <nl> newStatsFile = version . compareTo ( " ka " ) > = 0 ; <nl> @ @ - 110 , 7 + 97 , 7 @ @ public class Descriptor <nl> <nl> public boolean isCompatible ( ) <nl> { <nl> - return version . compareTo ( " ic " ) > = 0 & & version . charAt ( 0 ) < = CURRENT . version . charAt ( 0 ) ; <nl> + return version . compareTo ( " ja " ) > = 0 & & version . charAt ( 0 ) < = CURRENT . version . charAt ( 0 ) ; <nl> } <nl> <nl> @ Override <nl> @ @ - 249 , 7 + 236 , 7 @ @ public class Descriptor <nl> } <nl> <nl> if ( ! Version . validate ( nexttok ) ) <nl> - throw new UnsupportedOperationException ( " SSTable " + name + " is too old to open . Upgrade to 1 . 2 . 5 first , and run upgradesstables " ) ; <nl> + throw new UnsupportedOperationException ( " SSTable " + name + " is too old to open . Upgrade to 2 . 0 first , and run upgradesstables " ) ; <nl> Version version = new Version ( nexttok ) ; <nl> <nl> nexttok = st . nextToken ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java b / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java <nl> index ce4b670 . . b784a7e 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java <nl> @ @ - 89 , 8 + 89 , 7 @ @ public class SSTableIdentityIterator implements Comparable < SSTableIdentityIterat <nl> try <nl> { <nl> columnFamily . delete ( DeletionTime . serializer . deserialize ( in ) ) ; <nl> - int columnCount = dataVersion . hasRowSizeAndColumnCount ? in . readInt ( ) : Integer . MAX _ VALUE ; <nl> - atomIterator = columnFamily . metadata ( ) . getOnDiskIterator ( in , columnCount , flag , expireBefore , dataVersion ) ; <nl> + atomIterator = columnFamily . metadata ( ) . getOnDiskIterator ( in , flag , expireBefore , dataVersion ) ; <nl> } <nl> catch ( IOException e ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> index 94595b5 . . 82a0bc8 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> @ @ - 525 , 14 + 525 , 14 @ @ public class SSTableReader extends SSTable implements Closeable <nl> / / bf is enabled , but filter component is missing . <nl> load ( true , true ) ; <nl> } <nl> - else if ( descriptor . version . hasBloomFilterFPChance & & validation . bloomFilterFPChance ! = metadata . getBloomFilterFpChance ( ) ) <nl> + else if ( validation . bloomFilterFPChance ! = metadata . getBloomFilterFpChance ( ) ) <nl> { <nl> / / bf fp chance in sstable metadata and it has changed since compaction . <nl> load ( true , true ) ; <nl> } <nl> else <nl> { <nl> - / / bf is enabled , but fp chance isn ' t present in metadata ( pre - ja ) OR matches the currently configured value . <nl> + / / bf is enabled and fp chance matches the currently configured value . <nl> load ( false , true ) ; <nl> loadBloomFilter ( ) ; <nl> } <nl> @ @ - 655 , 7 + 655 , 7 @ @ public class SSTableReader extends SSTable implements Closeable <nl> public boolean loadSummary ( SegmentedFile . Builder ibuilder , SegmentedFile . Builder dbuilder ) <nl> { <nl> File summariesFile = new File ( descriptor . filenameFor ( Component . SUMMARY ) ) ; <nl> - if ( ! descriptor . version . offHeapSummaries | | ! summariesFile . exists ( ) ) <nl> + if ( ! summariesFile . exists ( ) ) <nl> return false ; <nl> <nl> DataInputStream iStream = null ; <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java b / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java <nl> index 911ef8c . . 2af68ae 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java <nl> @ @ - 261 , 8 + 261 , 6 @ @ public class SSTableScanner implements ICompactionScanner <nl> { <nl> dfile . seek ( currentEntry . position ) ; <nl> ByteBufferUtil . readWithShortLength ( dfile ) ; / / key <nl> - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) <nl> - dfile . readLong ( ) ; <nl> long dataSize = readEnd - dfile . getFilePointer ( ) ; <nl> return new SSTableIdentityIterator ( sstable , dfile , currentKey , dataSize ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> index e93deb5 . . 1dc2c98 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> @ @ - 229 , 19 + 229 , 10 @ @ public class SSTableWriter extends SSTable <nl> StreamingHistogram tombstones = new StreamingHistogram ( TOMBSTONE _ HISTOGRAM _ BIN _ SIZE ) ; <nl> ColumnFamily cf = ArrayBackedSortedColumns . factory . create ( metadata ) ; <nl> <nl> - / / skip row size for version < ja <nl> - if ( version . hasRowSizeAndColumnCount ) <nl> - FileUtils . skipBytesFully ( in , 8 ) ; <nl> - <nl> cf . delete ( DeletionTime . serializer . deserialize ( in ) ) ; <nl> <nl> ColumnIndex . Builder columnIndexer = new ColumnIndex . Builder ( cf , key . key , dataFile . stream ) ; <nl> <nl> - / / read column count for version < ja <nl> - int columnCount = Integer . MAX _ VALUE ; <nl> - if ( version . hasRowSizeAndColumnCount ) <nl> - columnCount = in . readInt ( ) ; <nl> - <nl> if ( cf . deletionInfo ( ) . getTopLevelDeletion ( ) . localDeletionTime < Integer . MAX _ VALUE ) <nl> tombstones . update ( cf . deletionInfo ( ) . getTopLevelDeletion ( ) . localDeletionTime ) ; <nl> <nl> @ @ - 252 , 7 + 243 , 7 @ @ public class SSTableWriter extends SSTable <nl> tombstones . update ( rangeTombstone . getLocalDeletionTime ( ) ) ; <nl> } <nl> <nl> - Iterator < OnDiskAtom > iter = metadata . getOnDiskIterator ( in , columnCount , ColumnSerializer . Flag . PRESERVE _ SIZE , Integer . MIN _ VALUE , version ) ; <nl> + Iterator < OnDiskAtom > iter = metadata . getOnDiskIterator ( in , ColumnSerializer . Flag . PRESERVE _ SIZE , Integer . MIN _ VALUE , version ) ; <nl> try <nl> { <nl> while ( iter . hasNext ( ) ) <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / metadata / LegacyMetadataSerializer . java b / src / java / org / apache / cassandra / io / sstable / metadata / LegacyMetadataSerializer . java <nl> index 9e97e2e . . 59f7be5 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / metadata / LegacyMetadataSerializer . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / metadata / LegacyMetadataSerializer . java <nl> @ @ - 38 , 8 + 38 , 6 @ @ import org . apache . cassandra . utils . StreamingHistogram ; <nl> @ Deprecated <nl> public class LegacyMetadataSerializer extends MetadataSerializer <nl> { <nl> - public static final double NO _ BLOOM _ FILTER _ FP _ CHANCE = - 1 . 0 ; <nl> - <nl> / * * <nl> * Legacy serialization is only used for SSTable level reset . <nl> * / <nl> @ @ - 96 , 8 + 94 , 8 @ @ public class LegacyMetadataSerializer extends MetadataSerializer <nl> ReplayPosition replayPosition = ReplayPosition . serializer . deserialize ( in ) ; <nl> long minTimestamp = in . readLong ( ) ; <nl> long maxTimestamp = in . readLong ( ) ; <nl> - int maxLocalDeletionTime = descriptor . version . tracksMaxLocalDeletionTime ? in . readInt ( ) : Integer . MAX _ VALUE ; <nl> - double bloomFilterFPChance = descriptor . version . hasBloomFilterFPChance ? in . readDouble ( ) : NO _ BLOOM _ FILTER _ FP _ CHANCE ; <nl> + int maxLocalDeletionTime = in . readInt ( ) ; <nl> + double bloomFilterFPChance = in . readDouble ( ) ; <nl> double compressionRatio = in . readDouble ( ) ; <nl> String partitioner = in . readUTF ( ) ; <nl> int nbAncestors = in . readInt ( ) ; <nl> @ @ - 109 , 28 + 107 , 15 @ @ public class LegacyMetadataSerializer extends MetadataSerializer <nl> if ( in . available ( ) > 0 ) <nl> sstableLevel = in . readInt ( ) ; <nl> <nl> - List < ByteBuffer > minColumnNames ; <nl> - List < ByteBuffer > maxColumnNames ; <nl> - if ( descriptor . version . tracksMaxMinColumnNames ) <nl> - { <nl> - int colCount = in . readInt ( ) ; <nl> - minColumnNames = new ArrayList < > ( colCount ) ; <nl> - for ( int i = 0 ; i < colCount ; i + + ) <nl> - { <nl> - minColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; <nl> - } <nl> - colCount = in . readInt ( ) ; <nl> - maxColumnNames = new ArrayList < > ( colCount ) ; <nl> - for ( int i = 0 ; i < colCount ; i + + ) <nl> - { <nl> - maxColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; <nl> - } <nl> - } <nl> - else <nl> - { <nl> - minColumnNames = Collections . emptyList ( ) ; <nl> - maxColumnNames = Collections . emptyList ( ) ; <nl> - } <nl> + int colCount = in . readInt ( ) ; <nl> + List < ByteBuffer > minColumnNames = new ArrayList < > ( colCount ) ; <nl> + for ( int i = 0 ; i < colCount ; i + + ) <nl> + minColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; <nl> + <nl> + colCount = in . readInt ( ) ; <nl> + List < ByteBuffer > maxColumnNames = new ArrayList < > ( colCount ) ; <nl> + for ( int i = 0 ; i < colCount ; i + + ) <nl> + maxColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; <nl> <nl> if ( types . contains ( MetadataType . VALIDATION ) ) <nl> components . put ( MetadataType . VALIDATION , <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / metadata / StatsMetadata . java b / src / java / org / apache / cassandra / io / sstable / metadata / StatsMetadata . java <nl> index 8568925 . . 1c3dfd5 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / metadata / StatsMetadata . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / metadata / StatsMetadata . java <nl> @ @ - 21 , 7 + 21 , 6 @ @ import java . io . DataInput ; <nl> import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . ArrayList ; <nl> - import java . util . Collections ; <nl> import java . util . List ; <nl> <nl> import org . apache . commons . lang3 . builder . EqualsBuilder ; <nl> @ @ - 234 , 35 + 233 , 24 @ @ public class StatsMetadata extends MetadataComponent <nl> ReplayPosition replayPosition = ReplayPosition . serializer . deserialize ( in ) ; <nl> long minTimestamp = in . readLong ( ) ; <nl> long maxTimestamp = in . readLong ( ) ; <nl> - int maxLocalDeletionTime = version . tracksMaxLocalDeletionTime ? in . readInt ( ) : Integer . MAX _ VALUE ; <nl> + int maxLocalDeletionTime = in . readInt ( ) ; <nl> double compressionRatio = in . readDouble ( ) ; <nl> StreamingHistogram tombstoneHistogram = StreamingHistogram . serializer . deserialize ( in ) ; <nl> int sstableLevel = in . readInt ( ) ; <nl> long repairedAt = 0 ; <nl> if ( version . hasRepairedAt ) <nl> repairedAt = in . readLong ( ) ; <nl> - List < ByteBuffer > minColumnNames ; <nl> - List < ByteBuffer > maxColumnNames ; <nl> - if ( version . tracksMaxMinColumnNames ) <nl> - { <nl> - int colCount = in . readInt ( ) ; <nl> - minColumnNames = new ArrayList < > ( colCount ) ; <nl> - for ( int i = 0 ; i < colCount ; i + + ) <nl> - { <nl> - minColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; <nl> - } <nl> - colCount = in . readInt ( ) ; <nl> - maxColumnNames = new ArrayList < > ( colCount ) ; <nl> - for ( int i = 0 ; i < colCount ; i + + ) <nl> - { <nl> - maxColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; <nl> - } <nl> - } <nl> - else <nl> - { <nl> - minColumnNames = Collections . emptyList ( ) ; <nl> - maxColumnNames = Collections . emptyList ( ) ; <nl> - } <nl> + <nl> + int colCount = in . readInt ( ) ; <nl> + List < ByteBuffer > minColumnNames = new ArrayList < > ( colCount ) ; <nl> + for ( int i = 0 ; i < colCount ; i + + ) <nl> + minColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; <nl> + <nl> + colCount = in . readInt ( ) ; <nl> + List < ByteBuffer > maxColumnNames = new ArrayList < > ( colCount ) ; <nl> + for ( int i = 0 ; i < colCount ; i + + ) <nl> + maxColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; <nl> + <nl> return new StatsMetadata ( rowSizes , <nl> columnCounts , <nl> replayPosition , <nl> diff - - git a / src / java / org / apache / cassandra / tools / SSTableExport . java b / src / java / org / apache / cassandra / tools / SSTableExport . java <nl> index cff6e71 . . bbc3494 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / SSTableExport . java <nl> + + + b / src / java / org / apache / cassandra / tools / SSTableExport . java <nl> @ @ - 308 , 12 + 308 , 8 @ @ public class SSTableExport <nl> <nl> dfile . seek ( entry . position ) ; <nl> ByteBufferUtil . readWithShortLength ( dfile ) ; / / row key <nl> - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) <nl> - dfile . readLong ( ) ; / / row size <nl> DeletionInfo deletionInfo = new DeletionInfo ( DeletionTime . serializer . deserialize ( dfile ) ) ; <nl> - int columnCount = sstable . descriptor . version . hasRowSizeAndColumnCount ? dfile . readInt ( ) : Integer . MAX _ VALUE ; <nl> - <nl> - Iterator < OnDiskAtom > atomIterator = sstable . metadata . getOnDiskIterator ( dfile , columnCount , sstable . descriptor . version ) ; <nl> + Iterator < OnDiskAtom > atomIterator = sstable . metadata . getOnDiskIterator ( dfile , sstable . descriptor . version ) ; <nl> <nl> checkStream ( outs ) ; <nl> <nl> diff - - git a / test / unit / org / apache / cassandra / io / sstable / LegacySSTableTest . java b / test / unit / org / apache / cassandra / io / sstable / LegacySSTableTest . java <nl> index ad9ce5b . . c0c9d41 100644 <nl> - - - a / test / unit / org / apache / cassandra / io / sstable / LegacySSTableTest . java <nl> + + + b / test / unit / org / apache / cassandra / io / sstable / LegacySSTableTest . java <nl> @ @ - 97 , 7 + 97 , 7 @ @ public class LegacySSTableTest extends SchemaLoader <nl> StorageService . instance . initServer ( ) ; <nl> <nl> for ( File version : LEGACY _ SSTABLE _ ROOT . listFiles ( ) ) <nl> - if ( Descriptor . Version . validate ( version . getName ( ) ) ) <nl> + if ( Descriptor . Version . validate ( version . getName ( ) ) & & new Descriptor . Version ( version . getName ( ) ) . isCompatible ( ) ) <nl> testStreaming ( version . getName ( ) ) ; <nl> } <nl> <nl> @ @ - 135 , 7 + 135 , 7 @ @ public class LegacySSTableTest extends SchemaLoader <nl> public void testVersions ( ) throws Throwable <nl> { <nl> for ( File version : LEGACY _ SSTABLE _ ROOT . listFiles ( ) ) <nl> - if ( Descriptor . Version . validate ( version . getName ( ) ) ) <nl> + if ( Descriptor . Version . validate ( version . getName ( ) ) & & new Descriptor . Version ( version . getName ( ) ) . isCompatible ( ) ) <nl> testVersion ( version . getName ( ) ) ; <nl> } <nl>
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 7dbb62a . . 7fc93f4 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 5 + 1 , 4 @ @ <nl> 1 . 2 . 5 <nl> - * Fix promoted row - level tombstone writing ( CASSANDRA - 5486 ) <nl> * Include fatal errors in trace events ( CASSANDRA - 5447 ) <nl> * Ensure that PerRowSecondaryIndex is notified of row - level deletes <nl> ( CASSANDRA - 5445 ) <nl> diff - - git a / build . xml b / build . xml <nl> index 2ddd43d . . 3491431 100644 <nl> - - - a / build . xml <nl> + + + b / build . xml <nl> @ @ - 519 , 7 + 519 , 7 @ @ <nl> < / artifact : pom > <nl> < / target > <nl> <nl> - < target name = " maven - ant - tasks - retrieve - build " depends = " maven - declare - dependencies " unless = " without . maven " > <nl> + < target name = " maven - ant - tasks - retrieve - build " depends = " maven - declare - dependencies " > <nl> < artifact : dependencies pomRefId = " build - deps - pom " <nl> filesetId = " build - dependency - jars " <nl> sourcesFilesetId = " build - dependency - sources " <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnIndex . java b / src / java / org / apache / cassandra / db / ColumnIndex . java <nl> index e2ac3e4 . . bcd0eef 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnIndex . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnIndex . java <nl> @ @ - 33 , 7 + 33 , 7 @ @ public class ColumnIndex <nl> public final List < IndexHelper . IndexInfo > columnsIndex ; <nl> public final IFilter bloomFilter ; <nl> <nl> - private static final ColumnIndex EMPTY = new ColumnIndex ( Collections . < IndexHelper . IndexInfo > emptyList ( ) , AlwaysPresentFilter . instance ) ; <nl> + private static final ColumnIndex EMPTY = new ColumnIndex ( Collections . < IndexHelper . IndexInfo > emptyList ( ) , new AlwaysPresentFilter ( ) ) ; <nl> <nl> private ColumnIndex ( int estimatedColumnCount ) <nl> { <nl> @ @ - 42 , 9 + 42 , 6 @ @ public class ColumnIndex <nl> <nl> private ColumnIndex ( List < IndexHelper . IndexInfo > columnsIndex , IFilter bloomFilter ) <nl> { <nl> - assert columnsIndex ! = null ; <nl> - assert bloomFilter ! = null ; <nl> - <nl> this . columnsIndex = columnsIndex ; <nl> this . bloomFilter = bloomFilter ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / RowIndexEntry . java b / src / java / org / apache / cassandra / db / RowIndexEntry . java <nl> index a60bf6d . . a831498 100644 <nl> - - - a / src / java / org / apache / cassandra / db / RowIndexEntry . java <nl> + + + b / src / java / org / apache / cassandra / db / RowIndexEntry . java <nl> @ @ - 28 , 7 + 28 , 6 @ @ import org . apache . cassandra . cache . IMeasurableMemory ; <nl> import org . apache . cassandra . io . sstable . Descriptor ; <nl> import org . apache . cassandra . io . sstable . IndexHelper ; <nl> import org . apache . cassandra . io . util . FileUtils ; <nl> - import org . apache . cassandra . utils . AlwaysPresentFilter ; <nl> import org . apache . cassandra . utils . IFilter ; <nl> import org . apache . cassandra . utils . FilterFactory ; <nl> import org . apache . cassandra . utils . ObjectSizes ; <nl> @ @ - 46 , 42 + 45 , 35 @ @ public class RowIndexEntry implements IMeasurableMemory <nl> <nl> public int serializedSize ( ) <nl> { <nl> - return TypeSizes . NATIVE . sizeof ( position ) + promotedSize ( ) ; <nl> + return TypeSizes . NATIVE . sizeof ( position ) ; <nl> } <nl> <nl> - public int promotedSize ( ) <nl> - { <nl> - return 0 ; <nl> - } <nl> - <nl> - / / TODO only store DeletionTime <nl> public static RowIndexEntry create ( long position , DeletionInfo deletionInfo , ColumnIndex index ) <nl> { <nl> - assert deletionInfo ! = null ; <nl> - assert index ! = null ; <nl> - <nl> - if ( index . columnsIndex . size ( ) > 1 | | deletionInfo . getTopLevelDeletion ( ) ! = DeletionTime . LIVE ) <nl> - return new IndexedEntry ( position , <nl> - deletionInfo , <nl> - index . columnsIndex . isEmpty ( ) ? Collections . < IndexHelper . IndexInfo > emptyList ( ) : index . columnsIndex , <nl> - index . columnsIndex . isEmpty ( ) ? AlwaysPresentFilter . instance : index . bloomFilter ) ; <nl> + if ( index ! = null & & index . columnsIndex ! = null & & index . columnsIndex . size ( ) > 1 ) <nl> + return new IndexedEntry ( position , deletionInfo , index . columnsIndex , index . bloomFilter ) ; <nl> else <nl> return new RowIndexEntry ( position ) ; <nl> } <nl> <nl> + public boolean isIndexed ( ) <nl> + { <nl> + return ! columnsIndex ( ) . isEmpty ( ) ; <nl> + } <nl> + <nl> public DeletionInfo deletionInfo ( ) <nl> { <nl> - return DeletionInfo . LIVE ; <nl> + throw new UnsupportedOperationException ( ) ; <nl> } <nl> <nl> public List < IndexHelper . IndexInfo > columnsIndex ( ) <nl> { <nl> - return Collections . emptyList ( ) ; <nl> + return Collections . < IndexHelper . IndexInfo > emptyList ( ) ; <nl> } <nl> <nl> public IFilter bloomFilter ( ) <nl> { <nl> - return AlwaysPresentFilter . instance ; <nl> + throw new UnsupportedOperationException ( ) ; <nl> } <nl> <nl> public long memorySize ( ) <nl> @ @ - 95 , 15 + 87 , 14 @ @ public class RowIndexEntry implements IMeasurableMemory <nl> public void serialize ( RowIndexEntry rie , DataOutput dos ) throws IOException <nl> { <nl> dos . writeLong ( rie . position ) ; <nl> - if ( ! rie . columnsIndex ( ) . isEmpty ( ) | | rie . deletionInfo ( ) . getTopLevelDeletion ( ) ! = DeletionTime . LIVE ) <nl> + if ( rie . isIndexed ( ) ) <nl> { <nl> - dos . writeInt ( rie . promotedSize ( ) ) ; <nl> + dos . writeInt ( ( ( IndexedEntry ) rie ) . serializedSize ( ) ) ; <nl> DeletionInfo . serializer ( ) . serializeForSSTable ( rie . deletionInfo ( ) , dos ) ; <nl> dos . writeInt ( rie . columnsIndex ( ) . size ( ) ) ; <nl> for ( IndexHelper . IndexInfo info : rie . columnsIndex ( ) ) <nl> info . serialize ( dos ) ; <nl> - if ( ! rie . columnsIndex ( ) . isEmpty ( ) ) <nl> - FilterFactory . serialize ( rie . bloomFilter ( ) , dos ) ; <nl> + FilterFactory . serialize ( rie . bloomFilter ( ) , dos ) ; <nl> } <nl> else <nl> { <nl> @ @ - 111 , 24 + 102 , 38 @ @ public class RowIndexEntry implements IMeasurableMemory <nl> } <nl> } <nl> <nl> - public RowIndexEntry deserialize ( DataInput dis , Descriptor . Version version ) throws IOException <nl> + public RowIndexEntry deserializePositionOnly ( DataInput dis , Descriptor . Version version ) throws IOException <nl> { <nl> long position = dis . readLong ( ) ; <nl> - if ( ! version . hasPromotedIndexes ) <nl> - return new RowIndexEntry ( position ) ; <nl> + if ( version . hasPromotedIndexes ) <nl> + { <nl> + int size = dis . readInt ( ) ; <nl> + if ( size > 0 ) <nl> + FileUtils . skipBytesFully ( dis , size ) ; <nl> + } <nl> + return new RowIndexEntry ( position ) ; <nl> + } <nl> <nl> - int size = dis . readInt ( ) ; <nl> - if ( size > 0 ) <nl> + public RowIndexEntry deserialize ( DataInput dis , Descriptor . Version version ) throws IOException <nl> + { <nl> + long position = dis . readLong ( ) ; <nl> + if ( version . hasPromotedIndexes ) <nl> { <nl> - DeletionInfo delInfo = DeletionInfo . serializer ( ) . deserializeFromSSTable ( dis , version ) ; <nl> - int entries = dis . readInt ( ) ; <nl> - List < IndexHelper . IndexInfo > columnsIndex = new ArrayList < IndexHelper . IndexInfo > ( entries ) ; <nl> - for ( int i = 0 ; i < entries ; i + + ) <nl> - columnsIndex . add ( IndexHelper . IndexInfo . deserialize ( dis ) ) ; <nl> - IFilter bf = entries = = 0 <nl> - ? AlwaysPresentFilter . instance <nl> - : FilterFactory . deserialize ( dis , version . filterType , false ) ; <nl> - return new IndexedEntry ( position , delInfo , columnsIndex , bf ) ; <nl> + int size = dis . readInt ( ) ; <nl> + if ( size > 0 ) <nl> + { <nl> + DeletionInfo delInfo = DeletionInfo . serializer ( ) . deserializeFromSSTable ( dis , version ) ; <nl> + int entries = dis . readInt ( ) ; <nl> + List < IndexHelper . IndexInfo > columnsIndex = new ArrayList < IndexHelper . IndexInfo > ( entries ) ; <nl> + for ( int i = 0 ; i < entries ; i + + ) <nl> + columnsIndex . add ( IndexHelper . IndexInfo . deserialize ( dis ) ) ; <nl> + IFilter bf = FilterFactory . deserialize ( dis , version . filterType , false ) ; <nl> + return new IndexedEntry ( position , delInfo , columnsIndex , bf ) ; <nl> + } <nl> + else <nl> + { <nl> + return new RowIndexEntry ( position ) ; <nl> + } <nl> } <nl> else <nl> { <nl> @ @ - 166 , 7 + 171 , 7 @ @ public class RowIndexEntry implements IMeasurableMemory <nl> { <nl> super ( position ) ; <nl> assert deletionInfo ! = null ; <nl> - assert columnsIndex ! = null ; <nl> + assert columnsIndex ! = null & & columnsIndex . size ( ) > 1 ; <nl> this . deletionInfo = deletionInfo ; <nl> this . columnsIndex = columnsIndex ; <nl> this . bloomFilter = bloomFilter ; <nl> @ @ - 191 , 7 + 196 , 7 @ @ public class RowIndexEntry implements IMeasurableMemory <nl> } <nl> <nl> @ Override <nl> - public int promotedSize ( ) <nl> + public int serializedSize ( ) <nl> { <nl> TypeSizes typeSizes = TypeSizes . NATIVE ; <nl> long size = DeletionTime . serializer . serializedSize ( deletionInfo . getTopLevelDeletion ( ) , typeSizes ) ; <nl> @ @ - 199 , 7 + 204 , 7 @ @ public class RowIndexEntry implements IMeasurableMemory <nl> for ( IndexHelper . IndexInfo info : columnsIndex ) <nl> size + = info . serializedSize ( typeSizes ) ; <nl> <nl> - size + = bloomFilter instanceof AlwaysPresentFilter ? 0 : FilterFactory . serializedSize ( bloomFilter ) ; <nl> + size + = FilterFactory . serializedSize ( bloomFilter ) ; <nl> assert size < = Integer . MAX _ VALUE ; <nl> return ( int ) size ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java <nl> index 61ae00e . . 7289ab0 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java <nl> @ @ - 65 , 7 + 65 , 7 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> * finish ( reverse start ) elements . i . e . forward : [ a , b ] , [ d , e ] , [ g , h ] reverse : [ h , g ] , [ e , d ] , [ b , a ] . This reader also <nl> * assumes that validation has been performed in terms of intervals ( no overlapping intervals ) . <nl> * / <nl> - public IndexedSliceReader ( SSTableReader sstable , RowIndexEntry rowEntry , FileDataInput input , ColumnSlice [ ] slices , boolean reversed ) <nl> + public IndexedSliceReader ( SSTableReader sstable , RowIndexEntry indexEntry , FileDataInput input , ColumnSlice [ ] slices , boolean reversed ) <nl> { <nl> this . sstable = sstable ; <nl> this . originalInput = input ; <nl> @ @ - 76 , 53 + 76 , 34 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> try <nl> { <nl> Descriptor . Version version = sstable . descriptor . version ; <nl> - emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; <nl> - <nl> - if ( version . hasPromotedRowTombstones & & ! rowEntry . columnsIndex ( ) . isEmpty ( ) ) <nl> - { <nl> - / / skip the row header entirely <nl> - indexes = rowEntry . columnsIndex ( ) ; <nl> - emptyColumnFamily . delete ( rowEntry . deletionInfo ( ) ) ; <nl> - fetcher = new IndexedBlockFetcher ( rowEntry . position ) ; <nl> - return ; <nl> - } <nl> - <nl> - / / skip up to bloom filter where things get a bit more interesting <nl> - if ( input = = null ) <nl> - { <nl> - file = sstable . getFileDataInput ( rowEntry . position ) ; <nl> - } <nl> - else <nl> - { <nl> - file = input ; <nl> - file . seek ( rowEntry . position ) ; <nl> - } <nl> - this . sstable . decodeKey ( ByteBufferUtil . readWithShortLength ( file ) ) ; <nl> - SSTableReader . readRowSize ( file , this . sstable . descriptor ) ; <nl> - <nl> - / / read the row header up to and including the row - level tombstones <nl> if ( version . hasPromotedIndexes ) <nl> { <nl> - indexes = rowEntry . columnsIndex ( ) ; <nl> - emptyColumnFamily . delete ( rowEntry . deletionInfo ( ) ) ; <nl> - } <nl> - else <nl> - { <nl> - IndexHelper . skipSSTableBloomFilter ( input , version ) ; <nl> - indexes = IndexHelper . deserializeIndex ( file ) ; <nl> - } <nl> - emptyColumnFamily . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , version ) ) ; <nl> - <nl> - if ( indexes . isEmpty ( ) ) <nl> - { <nl> - fetcher = new SimpleBlockFetcher ( ) ; <nl> + this . indexes = indexEntry . columnsIndex ( ) ; <nl> + if ( indexes . isEmpty ( ) ) <nl> + { <nl> + setToRowStart ( sstable , indexEntry , input ) ; <nl> + this . emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; <nl> + emptyColumnFamily . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , version ) ) ; <nl> + fetcher = new SimpleBlockFetcher ( ) ; <nl> + } <nl> + else <nl> + { <nl> + this . emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; <nl> + emptyColumnFamily . delete ( indexEntry . deletionInfo ( ) ) ; <nl> + fetcher = new IndexedBlockFetcher ( indexEntry . position ) ; <nl> + } <nl> } <nl> else <nl> { <nl> - / / index offsets changed to be based against the row key start in 1 . 2 <nl> - fetcher = version . hasPromotedIndexes <nl> - ? new IndexedBlockFetcher ( rowEntry . position ) <nl> - : new IndexedBlockFetcher ( file . getFilePointer ( ) + 4 ) ; / / + 4 to skip the int column count <nl> + setToRowStart ( sstable , indexEntry , input ) ; <nl> + IndexHelper . skipSSTableBloomFilter ( file , version ) ; <nl> + this . indexes = IndexHelper . deserializeIndex ( file ) ; <nl> + this . emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; <nl> + emptyColumnFamily . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , version ) ) ; <nl> + fetcher = indexes . isEmpty ( ) <nl> + ? new SimpleBlockFetcher ( ) <nl> + : new IndexedBlockFetcher ( file . getFilePointer ( ) + 4 ) ; / / We still have the column count to <nl> + / / skip to get the basePosition <nl> } <nl> } <nl> catch ( IOException e ) <nl> @ @ - 132 , 6 + 113 , 24 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> } <nl> } <nl> <nl> + / * * <nl> + * Sets the seek position to the start of the row for column scanning . <nl> + * / <nl> + private void setToRowStart ( SSTableReader reader , RowIndexEntry indexEntry , FileDataInput input ) throws IOException <nl> + { <nl> + if ( input = = null ) <nl> + { <nl> + this . file = sstable . getFileDataInput ( indexEntry . position ) ; <nl> + } <nl> + else <nl> + { <nl> + this . file = input ; <nl> + input . seek ( indexEntry . position ) ; <nl> + } <nl> + sstable . decodeKey ( ByteBufferUtil . readWithShortLength ( file ) ) ; <nl> + SSTableReader . readRowSize ( file , sstable . descriptor ) ; <nl> + } <nl> + <nl> public ColumnFamily getColumnFamily ( ) <nl> { <nl> return emptyColumnFamily ; <nl> @ @ - 198 , 6 + 197 , 8 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> return reversed ? slices [ currentSliceIdx ] . start : slices [ currentSliceIdx ] . finish ; <nl> } <nl> <nl> + protected abstract boolean setNextSlice ( ) ; <nl> + <nl> protected abstract boolean fetchMoreData ( ) ; <nl> <nl> protected boolean isColumnBeforeSliceStart ( OnDiskAtom column ) <nl> @ @ - 247 , 7 + 248 , 7 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> setNextSlice ( ) ; <nl> } <nl> <nl> - private boolean setNextSlice ( ) <nl> + protected boolean setNextSlice ( ) <nl> { <nl> while ( + + currentSliceIdx < slices . length ) <nl> { <nl> @ @ - 349 , 7 + 350 , 7 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> / * seek to the correct offset to the data , and calculate the data size * / <nl> long positionToSeek = basePosition + currentIndex . offset ; <nl> <nl> - / / With 1 . 2 promoted indexes , our first seek in the data file will happen at this point <nl> + / / With new promoted indexes , our first seek in the data file will happen at that point . <nl> if ( file = = null ) <nl> file = originalInput = = null ? sstable . getFileDataInput ( positionToSeek ) : originalInput ; <nl> <nl> @ @ - 463 , 7 + 464 , 7 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA <nl> } <nl> } <nl> <nl> - private boolean setNextSlice ( ) <nl> + protected boolean setNextSlice ( ) <nl> { <nl> if ( reversed ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java <nl> index 326447f . . da4631d 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java <nl> @ @ - 19 , 22 + 19 , 25 @ @ package org . apache . cassandra . db . columniterator ; <nl> <nl> import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> - import java . util . ArrayList ; <nl> - import java . util . Iterator ; <nl> - import java . util . List ; <nl> - import java . util . SortedSet ; <nl> + import java . util . * ; <nl> <nl> import org . apache . cassandra . config . CFMetaData ; <nl> - import org . apache . cassandra . db . * ; <nl> + import org . apache . cassandra . db . ColumnFamily ; <nl> + import org . apache . cassandra . db . ColumnFamilySerializer ; <nl> + import org . apache . cassandra . db . DecoratedKey ; <nl> + import org . apache . cassandra . db . DeletionInfo ; <nl> + import org . apache . cassandra . db . IColumn ; <nl> + import org . apache . cassandra . db . RowIndexEntry ; <nl> + import org . apache . cassandra . db . OnDiskAtom ; <nl> import org . apache . cassandra . db . marshal . AbstractType ; <nl> import org . apache . cassandra . io . sstable . CorruptSSTableException ; <nl> - import org . apache . cassandra . io . sstable . Descriptor ; <nl> import org . apache . cassandra . io . sstable . IndexHelper ; <nl> import org . apache . cassandra . io . sstable . SSTableReader ; <nl> import org . apache . cassandra . io . util . FileDataInput ; <nl> import org . apache . cassandra . io . util . FileMark ; <nl> import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> + import org . apache . cassandra . utils . IFilter ; <nl> <nl> public class SSTableNamesIterator extends SimpleAbstractColumnIterator implements ISSTableColumnIterator <nl> { <nl> @ @ - 52 , 13 + 55 , 13 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement <nl> this . columns = columns ; <nl> this . key = key ; <nl> <nl> - RowIndexEntry rowEntry = sstable . getPosition ( key , SSTableReader . Operator . EQ ) ; <nl> - if ( rowEntry = = null ) <nl> + RowIndexEntry indexEntry = sstable . getPosition ( key , SSTableReader . Operator . EQ ) ; <nl> + if ( indexEntry = = null ) <nl> return ; <nl> <nl> try <nl> { <nl> - read ( sstable , null , rowEntry ) ; <nl> + read ( sstable , null , indexEntry ) ; <nl> } <nl> catch ( IOException e ) <nl> { <nl> @ @ - 72 , 7 + 75 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement <nl> } <nl> } <nl> <nl> - public SSTableNamesIterator ( SSTableReader sstable , FileDataInput file , DecoratedKey key , SortedSet < ByteBuffer > columns , RowIndexEntry rowEntry ) <nl> + public SSTableNamesIterator ( SSTableReader sstable , FileDataInput file , DecoratedKey key , SortedSet < ByteBuffer > columns , RowIndexEntry indexEntry ) <nl> { <nl> assert columns ! = null ; <nl> this . sstable = sstable ; <nl> @ @ - 81 , 7 + 84 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement <nl> <nl> try <nl> { <nl> - read ( sstable , file , rowEntry ) ; <nl> + read ( sstable , file , indexEntry ) ; <nl> } <nl> catch ( IOException e ) <nl> { <nl> @ @ - 101 , 66 + 104 , 101 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement <nl> return sstable ; <nl> } <nl> <nl> - private void read ( SSTableReader sstable , FileDataInput file , RowIndexEntry rowEntry ) <nl> - throws IOException <nl> + private void read ( SSTableReader sstable , FileDataInput file , RowIndexEntry indexEntry ) <nl> + throws IOException <nl> { <nl> + IFilter bf ; <nl> List < IndexHelper . IndexInfo > indexList ; <nl> <nl> - Descriptor . Version version = sstable . descriptor . version ; <nl> - cf = ColumnFamily . create ( sstable . metadata ) ; <nl> - List < OnDiskAtom > result = new ArrayList < OnDiskAtom > ( columns . size ( ) ) ; <nl> - <nl> - if ( version . hasPromotedRowTombstones & & ! rowEntry . columnsIndex ( ) . isEmpty ( ) ) <nl> + / / If the entry is not indexed or the index is not promoted , read from the row start <nl> + if ( ! indexEntry . isIndexed ( ) ) <nl> { <nl> - / / skip the row header entirely <nl> - cf . delete ( rowEntry . deletionInfo ( ) ) ; <nl> + if ( file = = null ) <nl> + file = createFileDataInput ( indexEntry . position ) ; <nl> + else <nl> + file . seek ( indexEntry . position ) ; <nl> <nl> - readIndexedColumns ( sstable . metadata , file , columns , rowEntry . columnsIndex ( ) , rowEntry . position , result ) ; <nl> - iter = result . iterator ( ) ; <nl> - return ; <nl> + DecoratedKey keyInDisk = SSTableReader . decodeKey ( sstable . partitioner , <nl> + sstable . descriptor , <nl> + ByteBufferUtil . readWithShortLength ( file ) ) ; <nl> + assert keyInDisk . equals ( key ) : String . format ( " % s ! = % s in % s " , keyInDisk , key , file . getPath ( ) ) ; <nl> + SSTableReader . readRowSize ( file , sstable . descriptor ) ; <nl> } <nl> <nl> - if ( file = = null ) <nl> - file = createFileDataInput ( rowEntry . position ) ; <nl> - else <nl> - file . seek ( rowEntry . position ) ; <nl> - <nl> - DecoratedKey keyInDisk = SSTableReader . decodeKey ( sstable . partitioner , <nl> - sstable . descriptor , <nl> - ByteBufferUtil . readWithShortLength ( file ) ) ; <nl> - assert keyInDisk . equals ( key ) : String . format ( " % s ! = % s in % s " , keyInDisk , key , file . getPath ( ) ) ; <nl> - SSTableReader . readRowSize ( file , sstable . descriptor ) ; <nl> - <nl> if ( sstable . descriptor . version . hasPromotedIndexes ) <nl> { <nl> - indexList = rowEntry . columnsIndex ( ) ; <nl> - cf . delete ( rowEntry . deletionInfo ( ) ) ; <nl> + bf = indexEntry . isIndexed ( ) ? indexEntry . bloomFilter ( ) : null ; <nl> + indexList = indexEntry . columnsIndex ( ) ; <nl> } <nl> else <nl> { <nl> + assert file ! = null ; <nl> + bf = IndexHelper . defreezeBloomFilter ( file , sstable . descriptor . version . filterType ) ; <nl> indexList = IndexHelper . deserializeIndex ( file ) ; <nl> } <nl> <nl> - cf . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , sstable . descriptor . version ) ) ; <nl> + if ( ! indexEntry . isIndexed ( ) ) <nl> + { <nl> + / / we can stop early if bloom filter says none of the columns actually exist - - but , <nl> + / / we can ' t stop before initializing the cf above , in case there ' s a relevant tombstone <nl> + ColumnFamilySerializer serializer = ColumnFamily . serializer ; <nl> + try <nl> + { <nl> + cf = ColumnFamily . create ( sstable . metadata ) ; <nl> + cf . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , sstable . descriptor . version ) ) ; <nl> + } <nl> + catch ( Exception e ) <nl> + { <nl> + throw new IOException ( serializer + " failed to deserialize " + sstable . getColumnFamilyName ( ) + " with " + sstable . metadata + " from " + file , e ) ; <nl> + } <nl> + } <nl> + else <nl> + { <nl> + cf = ColumnFamily . create ( sstable . metadata ) ; <nl> + cf . delete ( indexEntry . deletionInfo ( ) ) ; <nl> + } <nl> + <nl> + List < OnDiskAtom > result = new ArrayList < OnDiskAtom > ( ) ; <nl> + List < ByteBuffer > filteredColumnNames = new ArrayList < ByteBuffer > ( columns . size ( ) ) ; <nl> + for ( ByteBuffer name : columns ) <nl> + { <nl> + if ( bf = = null | | bf . isPresent ( name ) ) <nl> + { <nl> + filteredColumnNames . add ( name ) ; <nl> + } <nl> + } <nl> + if ( filteredColumnNames . isEmpty ( ) ) <nl> + return ; <nl> <nl> if ( indexList . isEmpty ( ) ) <nl> { <nl> - readSimpleColumns ( file , columns , result ) ; <nl> + readSimpleColumns ( file , columns , filteredColumnNames , result ) ; <nl> } <nl> else <nl> { <nl> - long basePosition = version . hasPromotedIndexes ? rowEntry . position : file . getFilePointer ( ) + 4 ; <nl> - readIndexedColumns ( sstable . metadata , file , columns , indexList , basePosition , result ) ; <nl> + long basePosition ; <nl> + if ( sstable . descriptor . version . hasPromotedIndexes ) <nl> + { <nl> + basePosition = indexEntry . position ; <nl> + } <nl> + else <nl> + { <nl> + assert file ! = null ; <nl> + file . readInt ( ) ; / / column count <nl> + basePosition = file . getFilePointer ( ) ; <nl> + } <nl> + readIndexedColumns ( sstable . metadata , file , columns , filteredColumnNames , indexList , basePosition , result ) ; <nl> } <nl> <nl> / / create an iterator view of the columns we read <nl> iter = result . iterator ( ) ; <nl> } <nl> <nl> - private void readSimpleColumns ( FileDataInput file , SortedSet < ByteBuffer > columnNames , List < OnDiskAtom > result ) throws IOException <nl> + private void readSimpleColumns ( FileDataInput file , SortedSet < ByteBuffer > columnNames , List < ByteBuffer > filteredColumnNames , List < OnDiskAtom > result ) throws IOException <nl> { <nl> OnDiskAtom . Serializer atomSerializer = cf . getOnDiskSerializer ( ) ; <nl> int columns = file . readInt ( ) ; <nl> + int n = 0 ; <nl> for ( int i = 0 ; i < columns ; i + + ) <nl> { <nl> OnDiskAtom column = atomSerializer . deserializeFromSSTable ( file , sstable . descriptor . version ) ; <nl> @ @ - 169 , 7 + 207 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement <nl> if ( columnNames . contains ( column . name ( ) ) ) <nl> { <nl> result . add ( column ) ; <nl> - if ( result . size ( ) > = columnNames . size ( ) ) <nl> + if ( n + + > filteredColumnNames . size ( ) ) <nl> break ; <nl> } <nl> } <nl> @ @ - 183 , 16 + 221 , 17 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement <nl> private void readIndexedColumns ( CFMetaData metadata , <nl> FileDataInput file , <nl> SortedSet < ByteBuffer > columnNames , <nl> + List < ByteBuffer > filteredColumnNames , <nl> List < IndexHelper . IndexInfo > indexList , <nl> long basePosition , <nl> List < OnDiskAtom > result ) <nl> - throws IOException <nl> + throws IOException <nl> { <nl> / * get the various column ranges we have to read * / <nl> AbstractType < ? > comparator = metadata . comparator ; <nl> List < IndexHelper . IndexInfo > ranges = new ArrayList < IndexHelper . IndexInfo > ( ) ; <nl> int lastIndexIdx = - 1 ; <nl> - for ( ByteBuffer name : columnNames ) <nl> + for ( ByteBuffer name : filteredColumnNames ) <nl> { <nl> int index = IndexHelper . indexFor ( name , indexList , comparator , false , lastIndexIdx ) ; <nl> if ( index < 0 | | index = = indexList . size ( ) ) <nl> @ @ - 212 , 7 + 251 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement <nl> { <nl> long positionToSeek = basePosition + indexInfo . offset ; <nl> <nl> - / / With 1 . 2 promoted indexes , our first seek in the data file will happen at this point <nl> + / / With new promoted indexes , our first seek in the data file will happen at that point . <nl> if ( file = = null ) <nl> file = createFileDataInput ( positionToSeek ) ; <nl> <nl> @ @ - 223 , 6 + 262 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement <nl> while ( file . bytesPastMark ( mark ) < indexInfo . width ) <nl> { <nl> OnDiskAtom column = atomSerializer . deserializeFromSSTable ( file , sstable . descriptor . version ) ; <nl> + / / we check vs the original Set , not the filtered List , for efficiency <nl> if ( ! ( column instanceof IColumn ) | | columnNames . contains ( column . name ( ) ) ) <nl> result . add ( column ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java <nl> index 0cf9af6 . . b30d360 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java <nl> @ @ - 49 , 7 + 49 , 7 @ @ class SimpleSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskAt <nl> private FileMark mark ; <nl> private final OnDiskAtom . Serializer atomSerializer ; <nl> <nl> - public SimpleSliceReader ( SSTableReader sstable , RowIndexEntry rowEntry , FileDataInput input , ByteBuffer finishColumn ) <nl> + public SimpleSliceReader ( SSTableReader sstable , RowIndexEntry indexEntry , FileDataInput input , ByteBuffer finishColumn ) <nl> { <nl> this . sstable = sstable ; <nl> this . finishColumn = finishColumn ; <nl> @ @ - 58 , 13 + 58 , 13 @ @ class SimpleSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskAt <nl> { <nl> if ( input = = null ) <nl> { <nl> - this . file = sstable . getFileDataInput ( rowEntry . position ) ; <nl> + this . file = sstable . getFileDataInput ( indexEntry . position ) ; <nl> this . needsClosing = true ; <nl> } <nl> else <nl> { <nl> this . file = input ; <nl> - input . seek ( rowEntry . position ) ; <nl> + input . seek ( indexEntry . position ) ; <nl> this . needsClosing = false ; <nl> } <nl> <nl> @ @ - 72 , 19 + 72 , 14 @ @ class SimpleSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskAt <nl> ByteBufferUtil . skipShortLength ( file ) ; <nl> SSTableReader . readRowSize ( file , sstable . descriptor ) ; <nl> <nl> - emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; <nl> - <nl> Descriptor . Version version = sstable . descriptor . version ; <nl> - if ( version . hasPromotedIndexes ) <nl> - { <nl> - emptyColumnFamily . delete ( rowEntry . deletionInfo ( ) ) ; <nl> - } <nl> - else <nl> + if ( ! version . hasPromotedIndexes ) <nl> { <nl> IndexHelper . skipSSTableBloomFilter ( file , version ) ; <nl> IndexHelper . skipIndex ( file ) ; <nl> } <nl> <nl> + emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; <nl> emptyColumnFamily . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , version ) ) ; <nl> atomSerializer = emptyColumnFamily . getOnDiskSerializer ( ) ; <nl> columns = file . readInt ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / Descriptor . java b / src / java / org / apache / cassandra / io / sstable / Descriptor . java <nl> index 7b916cb . . f21a0d5 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / Descriptor . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / Descriptor . java <nl> @ @ - 47 , 7 + 47 , 7 @ @ public class Descriptor <nl> public static class Version <nl> { <nl> / / This needs to be at the begining for initialization sake <nl> - public static final String current _ version = " ic " ; <nl> + public static final String current _ version = " ib " ; <nl> <nl> public static final Version LEGACY = new Version ( " a " ) ; / / " pre - history " <nl> / / b ( 0 . 7 . 0 ) : added version to sstable filenames <nl> @ @ - 62 , 11 + 62 , 10 @ @ public class Descriptor <nl> / / hd ( 1 . 0 . 10 ) : includes row tombstones in maxtimestamp <nl> / / he ( 1 . 1 . 3 ) : includes ancestors generation in metadata component <nl> / / hf ( 1 . 1 . 6 ) : marker that replay position corresponds to 1 . 1 . 5 + millis - based id ( see CASSANDRA - 4782 ) <nl> - / / ia ( 1 . 2 . 0 ) : column indexes are promoted to the index file . ( this means index offsets are now against the start of the row key , rather than the start of columns data , since the former allows us to skip the row header ) <nl> + / / ia ( 1 . 2 . 0 ) : column indexes are promoted to the index file <nl> / / records estimated histogram of deletion times in tombstones <nl> / / bloom filter ( keys and columns ) upgraded to Murmur3 <nl> / / ib ( 1 . 2 . 1 ) : tracks min client timestamp in metadata component <nl> - / / ic ( 1 . 2 . 6 ) : always promotes row - level tombstones into index file ; previously this was unreliable <nl> <nl> public static final Version CURRENT = new Version ( current _ version ) ; <nl> <nl> @ @ - 84 , 7 + 83 , 6 @ @ public class Descriptor <nl> public final boolean hasPartitioner ; <nl> public final boolean tracksTombstones ; <nl> public final boolean hasPromotedIndexes ; <nl> - public final boolean hasPromotedRowTombstones ; <nl> public final FilterFactory . Type filterType ; <nl> public final boolean hasAncestors ; <nl> public final boolean hasBloomFilterSizeInHeader ; <nl> @ @ - 104 , 7 + 102 , 6 @ @ public class Descriptor <nl> metadataIncludesModernReplayPosition = version . compareTo ( " hf " ) > = 0 ; <nl> tracksTombstones = version . compareTo ( " ia " ) > = 0 ; <nl> hasPromotedIndexes = version . compareTo ( " ia " ) > = 0 ; <nl> - hasPromotedRowTombstones = version . compareTo ( " ic " ) > = 0 ; <nl> isLatestVersion = version . compareTo ( current _ version ) = = 0 ; <nl> if ( version . compareTo ( " f " ) < 0 ) <nl> filterType = FilterFactory . Type . SHA ; <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> index 61f505d . . 21a8673 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> @ @ - 323 , 7 + 323 , 7 @ @ public class SSTableReader extends SSTable <nl> { <nl> if ( ! components . contains ( Component . FILTER ) ) <nl> { <nl> - bf = AlwaysPresentFilter . instance ; <nl> + bf = new AlwaysPresentFilter ( ) ; <nl> return ; <nl> } <nl> <nl> diff - - git a / src / java / org / apache / cassandra / utils / AlwaysPresentFilter . java b / src / java / org / apache / cassandra / utils / AlwaysPresentFilter . java <nl> index 39b3d5d . . 67ac111 100644 <nl> - - - a / src / java / org / apache / cassandra / utils / AlwaysPresentFilter . java <nl> + + + b / src / java / org / apache / cassandra / utils / AlwaysPresentFilter . java <nl> @ @ - 26 , 10 + 26 , 6 @ @ import java . nio . ByteBuffer ; <nl> <nl> public class AlwaysPresentFilter implements IFilter <nl> { <nl> - public static final AlwaysPresentFilter instance = new AlwaysPresentFilter ( ) ; <nl> - <nl> - private AlwaysPresentFilter ( ) { } <nl> - <nl> public boolean isPresent ( ByteBuffer key ) <nl> { <nl> return true ; <nl> diff - - git a / src / java / org / apache / cassandra / utils / FilterFactory . java b / src / java / org / apache / cassandra / utils / FilterFactory . java <nl> index 1b9027d . . 88c8973 100644 <nl> - - - a / src / java / org / apache / cassandra / utils / FilterFactory . java <nl> + + + b / src / java / org / apache / cassandra / utils / FilterFactory . java <nl> @ @ - 131 , 7 + 131 , 7 @ @ public class FilterFactory <nl> { <nl> assert maxFalsePosProbability < = 1 . 0 : " Invalid probability " ; <nl> if ( maxFalsePosProbability = = 1 . 0 ) <nl> - return AlwaysPresentFilter . instance ; <nl> + return new AlwaysPresentFilter ( ) ; <nl> int bucketsPerElement = BloomCalculations . maxBucketsPerElement ( numElements ) ; <nl> BloomCalculations . BloomSpecification spec = BloomCalculations . computeBloomSpec ( bucketsPerElement , maxFalsePosProbability ) ; <nl> return createFilter ( spec . K , numElements , spec . bucketsPerElement , type , offheap ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java b / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java <nl> index c531461 . . 1bc846b 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java <nl> @ @ - 164 , 6 + 164 , 10 @ @ public class RangeTombstoneTest extends SchemaLoader <nl> return ByteBufferUtil . bytes ( i ) ; <nl> } <nl> <nl> + private static void insertData ( ColumnFamilyStore cfs , String key ) throws Exception <nl> + { <nl> + } <nl> + <nl> private static void add ( RowMutation rm , int value , long timestamp ) <nl> { <nl> rm . add ( new QueryPath ( CFNAME , null , b ( value ) ) , b ( value ) , timestamp ) ;

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 196fa0d . . c224c8f 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 34 , 6 + 34 , 7 @ @ 
 * Add multiple memory allocation options for memtables ( CASSANDRA - 6689 ) 
 * Remove adjusted op rate from stress output ( CASSANDRA - 6921 ) 
 * Add optimized CF . hasColumns ( ) implementations ( CASSANDRA - 6941 ) 
 + * Properly remove 1 . 2 sstable support in 2 . 1 ( CASSANDRA - 6869 ) 
 Merged from 2 . 0 : 
 * Restrict Windows to parallel repairs ( CASSANDRA - 6907 ) 
 * ( Hadoop ) Allow manually specifying start / end tokens in CFIF ( CASSANDRA - 6436 ) 
 diff - - git a / NEWS . txt b / NEWS . txt 
 index 23f6522 . . 7cb7565 100644 
 - - - a / NEWS . txt 
 + + + b / NEWS . txt 
 @ @ - 33 , 11 + 33 , 11 @ @ New features 
 
 Upgrading 
 - - - - - - - - - 
 - - Rolling upgrades from anything pre - 2 . 0 . 6 is not supported . 
 - - For leveled compaction users , 2 . 0 must be atleast started before 
 - upgrading to 2 . 1 due to the fact that the old JSON leveled 
 - manifest is migrated into the sstable metadata files on startup 
 - in 2 . 0 and this code is gone from 2 . 1 . 
 + - Rolling upgrades from anything pre - 2 . 0 . 6 is not supported . Furthermore 
 + - Pre - 2 . 0 sstables are not supported . This means that before upgrading 
 + a node a 2 . 1 , this node must be started on 2 . 0 and 
 + ' nodetool upgdradesstables ' must be run ( and this even in the case 
 + of no - rolling upgrades ) . 
 - For size - tiered compaction users , Cassandra now defaults to ignoring 
 the coldest 5 % of sstables . This can be customized with the 
 cold _ reads _ to _ omit compaction option ; 0 . 0 omits nothing ( the old 
 diff - - git a / src / java / org / apache / cassandra / config / CFMetaData . java b / src / java / org / apache / cassandra / config / CFMetaData . java 
 index 8a4f147 . . 1ca9880 100644 
 - - - a / src / java / org / apache / cassandra / config / CFMetaData . java 
 + + + b / src / java / org / apache / cassandra / config / CFMetaData . java 
 @ @ - 1379 , 16 + 1379 , 14 @ @ public final class CFMetaData 
 return ( cfName + " _ " + columnName + " _ idx " ) . replaceAll ( " \ \ W " , " " ) ; 
 } 
 
 - public Iterator < OnDiskAtom > getOnDiskIterator ( DataInput in , int count , Descriptor . Version version ) 
 + public Iterator < OnDiskAtom > getOnDiskIterator ( DataInput in , Descriptor . Version version ) 
 { 
 - return getOnDiskIterator ( in , count , ColumnSerializer . Flag . LOCAL , Integer . MIN _ VALUE , version ) ; 
 + return getOnDiskIterator ( in , ColumnSerializer . Flag . LOCAL , Integer . MIN _ VALUE , version ) ; 
 } 
 
 - public Iterator < OnDiskAtom > getOnDiskIterator ( DataInput in , int count , ColumnSerializer . Flag flag , int expireBefore , Descriptor . Version version ) 
 + public Iterator < OnDiskAtom > getOnDiskIterator ( DataInput in , ColumnSerializer . Flag flag , int expireBefore , Descriptor . Version version ) 
 { 
 - if ( version . hasSuperColumns & & cfType = = ColumnFamilyType . Super ) 
 - return SuperColumns . onDiskIterator ( in , count , flag , expireBefore , comparator ) ; 
 - return Cell . onDiskIterator ( in , count , flag , expireBefore , version , comparator ) ; 
 + return Cell . onDiskIterator ( in , flag , expireBefore , version , comparator ) ; 
 } 
 
 public AtomDeserializer getOnDiskDeserializer ( DataInput in , Descriptor . Version version ) 
 diff - - git a / src / java / org / apache / cassandra / db / Cell . java b / src / java / org / apache / cassandra / db / Cell . java 
 index e807a21 . . 8db9770 100644 
 - - - a / src / java / org / apache / cassandra / db / Cell . java 
 + + + b / src / java / org / apache / cassandra / db / Cell . java 
 @ @ - 48 , 12 + 48 , 7 @ @ public class Cell implements OnDiskAtom 
 
 private static final long EMPTY _ SIZE = ObjectSizes . measure ( new Cell ( CellNames . simpleDense ( ByteBuffer . allocate ( 1 ) ) ) ) ; 
 
 - / * * 
 - * For 2 . 0 - formatted sstables ( where column count is not stored ) , @ param count should be Integer . MAX _ VALUE , 
 - * and we will look for the end - of - row column name marker instead of relying on that . 
 - * / 
 public static Iterator < OnDiskAtom > onDiskIterator ( final DataInput in , 
 - final int count , 
 final ColumnSerializer . Flag flag , 
 final int expireBefore , 
 final Descriptor . Version version , 
 @ @ - 61 , 13 + 56 , 8 @ @ public class Cell implements OnDiskAtom 
 { 
 return new AbstractIterator < OnDiskAtom > ( ) 
 { 
 - int i = 0 ; 
 - 
 protected OnDiskAtom computeNext ( ) 
 { 
 - if ( i + + > = count ) 
 - return endOfData ( ) ; 
 - 
 OnDiskAtom atom ; 
 try 
 { 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index d66c501 . . b9cab4d 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 454 , 7 + 454 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 Descriptor desc = entry . getKey ( ) ; 
 generations . add ( desc . generation ) ; 
 if ( ! desc . isCompatible ( ) ) 
 - throw new RuntimeException ( String . format ( " Incompatible SSTable found . Current version % s is unable to read file : % s . Please run upgradesstables . " , 
 + throw new RuntimeException ( String . format ( " Incompatible SSTable found . Current version % s is unable to read file : % s . Please run upgradesstables . " , 
 Descriptor . Version . CURRENT , desc ) ) ; 
 } 
 Collections . sort ( generations ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java 
 index 22fe5fa . . 7012321 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java 
 @ @ - 26 , 7 + 26 , 6 @ @ import com . google . common . collect . AbstractIterator ; 
 
 import org . apache . cassandra . db . * ; 
 import org . apache . cassandra . db . composites . CellNameType ; 
 - import org . apache . cassandra . db . composites . CellNames ; 
 import org . apache . cassandra . db . composites . Composite ; 
 import org . apache . cassandra . db . filter . ColumnSlice ; 
 import org . apache . cassandra . io . sstable . CorruptSSTableException ; 
 @ @ - 113 , 8 + 112 , 6 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 in . seek ( rowEntry . position ) ; 
 } 
 sstable . partitioner . decorateKey ( ByteBufferUtil . readWithShortLength ( file ) ) ; 
 - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) 
 - file . readLong ( ) ; 
 } 
 
 public ColumnFamily getColumnFamily ( ) 
 @ @ - 179 , 34 + 176 , 6 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 } 
 } 
 
 - static int indexFor ( SSTableReader sstable , Composite name , List < IndexHelper . IndexInfo > indexes , CellNameType comparator , boolean reversed , int startIdx ) 
 - { 
 - / / If it ' s a super CF and the sstable is from the old format , then the index will contain old format info , i . e . non composite 
 - / / SC names . So we need to 1 ) use only the SC name part of the comparator and 2 ) extract only that part from ' name ' 
 - if ( sstable . metadata . isSuper ( ) & & sstable . descriptor . version . hasSuperColumns ) 
 - { 
 - CellNameType scComparator = SuperColumns . scNameType ( comparator ) ; 
 - Composite scName = CellNames . simpleDense ( SuperColumns . scName ( name ) ) ; 
 - return IndexHelper . indexFor ( scName , indexes , scComparator , reversed , startIdx ) ; 
 - } 
 - return IndexHelper . indexFor ( name , indexes , comparator , reversed , startIdx ) ; 
 - } 
 - 
 - static Composite forIndexComparison ( SSTableReader sstable , Composite name ) 
 - { 
 - / / See indexFor above . 
 - return sstable . metadata . isSuper ( ) & & sstable . descriptor . version . hasSuperColumns 
 - ? CellNames . simpleDense ( SuperColumns . scName ( name ) ) 
 - : name ; 
 - } 
 - 
 - static CellNameType comparatorForIndex ( SSTableReader sstable , CellNameType comparator ) 
 - { 
 - return sstable . metadata . isSuper ( ) & & sstable . descriptor . version . hasSuperColumns 
 - ? SuperColumns . scNameType ( comparator ) 
 - : comparator ; 
 - } 
 - 
 private abstract class BlockFetcher 
 { 
 protected int currentSliceIdx ; 
 @ @ - 247 , 22 + 216 , 16 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 return ! start . isEmpty ( ) & & comparator . compare ( name , start ) < 0 ; 
 } 
 
 - protected boolean isIndexEntryBeforeSliceStart ( Composite name ) 
 - { 
 - Composite start = currentStart ( ) ; 
 - return ! start . isEmpty ( ) & & comparatorForIndex ( sstable , comparator ) . compare ( name , forIndexComparison ( sstable , start ) ) < 0 ; 
 - } 
 - 
 protected boolean isColumnBeforeSliceFinish ( OnDiskAtom column ) 
 { 
 Composite finish = currentFinish ( ) ; 
 return finish . isEmpty ( ) | | comparator . compare ( column . name ( ) , finish ) < = 0 ; 
 } 
 
 - protected boolean isIndexEntryAfterSliceFinish ( Composite name ) 
 + protected boolean isAfterSliceFinish ( Composite name ) 
 { 
 Composite finish = currentFinish ( ) ; 
 - return ! finish . isEmpty ( ) & & comparatorForIndex ( sstable , comparator ) . compare ( name , forIndexComparison ( sstable , finish ) ) > 0 ; 
 + return ! finish . isEmpty ( ) & & comparator . compare ( name , finish ) > 0 ; 
 } 
 } 
 
 @ @ - 293 , 7 + 256 , 7 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 { 
 while ( + + currentSliceIdx < slices . length ) 
 { 
 - nextIndexIdx = indexFor ( sstable , slices [ currentSliceIdx ] . start , indexes , comparator , reversed , nextIndexIdx ) ; 
 + nextIndexIdx = IndexHelper . indexFor ( slices [ currentSliceIdx ] . start , indexes , comparator , reversed , nextIndexIdx ) ; 
 if ( nextIndexIdx < 0 | | nextIndexIdx > = indexes . size ( ) ) 
 / / no index block for that slice 
 continue ; 
 @ @ - 302 , 12 + 265 , 12 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 IndexInfo info = indexes . get ( nextIndexIdx ) ; 
 if ( reversed ) 
 { 
 - if ( ! isIndexEntryBeforeSliceStart ( info . lastName ) ) 
 + if ( ! isBeforeSliceStart ( info . lastName ) ) 
 return true ; 
 } 
 else 
 { 
 - if ( ! isIndexEntryAfterSliceFinish ( info . firstName ) ) 
 + if ( ! isAfterSliceFinish ( info . firstName ) ) 
 return true ; 
 } 
 } 
 @ @ - 480 , 10 + 443 , 8 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 / / We remenber when we are whithin a slice to avoid some comparison 
 boolean inSlice = false ; 
 
 - int columnCount = sstable . descriptor . version . hasRowSizeAndColumnCount ? file . readInt ( ) : Integer . MAX _ VALUE ; 
 AtomDeserializer deserializer = emptyColumnFamily . metadata ( ) . getOnDiskDeserializer ( file , sstable . descriptor . version ) ; 
 - int deserialized = 0 ; 
 - while ( deserializer . hasNext ( ) & & deserialized < columnCount ) 
 + while ( deserializer . hasNext ( ) ) 
 { 
 / / col is before slice 
 / / ( If in slice , don ' t bother checking that until we change slice ) 
 @ @ - 491 , 7 + 452 , 6 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 if ( ! inSlice & & ! start . isEmpty ( ) & & deserializer . compareNextTo ( start ) < 0 ) 
 { 
 deserializer . skipNext ( ) ; 
 - + + deserialized ; 
 continue ; 
 } 
 
 @ @ - 501 , 7 + 461 , 6 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 { 
 inSlice = true ; 
 addColumn ( deserializer . readNext ( ) ) ; 
 - + + deserialized ; 
 } 
 / / col is after slice . more slices ? 
 else 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java 
 index 374dedb . . 224b63f 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java 
 @ @ - 109 , 8 + 109 , 6 @ @ public class SSTableNamesIterator extends AbstractIterator < OnDiskAtom > implement 
 
 DecoratedKey keyInDisk = sstable . partitioner . decorateKey ( ByteBufferUtil . readWithShortLength ( file ) ) ; 
 assert keyInDisk . equals ( key ) : String . format ( " % s ! = % s in % s " , keyInDisk , key , file . getPath ( ) ) ; 
 - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) 
 - file . readLong ( ) ; 
 } 
 
 indexList = indexEntry . columnsIndex ( ) ; 
 @ @ - 137 , 8 + 135 , 7 @ @ public class SSTableNamesIterator extends AbstractIterator < OnDiskAtom > implement 
 List < OnDiskAtom > result = new ArrayList < OnDiskAtom > ( ) ; 
 if ( indexList . isEmpty ( ) ) 
 { 
 - int columnCount = sstable . descriptor . version . hasRowSizeAndColumnCount ? file . readInt ( ) : Integer . MAX _ VALUE ; 
 - readSimpleColumns ( file , columns , result , columnCount ) ; 
 + readSimpleColumns ( file , columns , result ) ; 
 } 
 else 
 { 
 @ @ - 149 , 9 + 146 , 9 @ @ public class SSTableNamesIterator extends AbstractIterator < OnDiskAtom > implement 
 iter = result . iterator ( ) ; 
 } 
 
 - private void readSimpleColumns ( FileDataInput file , SortedSet < CellName > columnNames , List < OnDiskAtom > result , int columnCount ) 
 + private void readSimpleColumns ( FileDataInput file , SortedSet < CellName > columnNames , List < OnDiskAtom > result ) 
 { 
 - Iterator < OnDiskAtom > atomIterator = cf . metadata ( ) . getOnDiskIterator ( file , columnCount , sstable . descriptor . version ) ; 
 + Iterator < OnDiskAtom > atomIterator = cf . metadata ( ) . getOnDiskIterator ( file , sstable . descriptor . version ) ; 
 int n = 0 ; 
 while ( atomIterator . hasNext ( ) ) 
 { 
 @ @ - 186 , 13 + 183 , 12 @ @ public class SSTableNamesIterator extends AbstractIterator < OnDiskAtom > implement 
 int lastIndexIdx = - 1 ; 
 for ( CellName name : columnNames ) 
 { 
 - int index = IndexedSliceReader . indexFor ( sstable , name , indexList , comparator , false , lastIndexIdx ) ; 
 + int index = IndexHelper . indexFor ( name , indexList , comparator , false , lastIndexIdx ) ; 
 if ( index < 0 | | index = = indexList . size ( ) ) 
 continue ; 
 IndexHelper . IndexInfo indexInfo = indexList . get ( index ) ; 
 / / Check the index block does contain the column names and that we haven ' t inserted this block yet . 
 - if ( IndexedSliceReader . comparatorForIndex ( sstable , comparator ) . compare ( IndexedSliceReader . forIndexComparison ( sstable , name ) , indexInfo . firstName ) < 0 
 - | | index = = lastIndexIdx ) 
 + if ( comparator . compare ( name , indexInfo . firstName ) < 0 | | index = = lastIndexIdx ) 
 continue ; 
 
 ranges . add ( indexInfo ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java 
 index 7fb48e3 . . 702bddc 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java 
 @ @ - 64 , 17 + 64 , 12 @ @ class SimpleSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskAt 
 this . needsClosing = false ; 
 } 
 
 - Descriptor . Version version = sstable . descriptor . version ; 
 - 
 / / Skip key and data size 
 ByteBufferUtil . skipShortLength ( file ) ; 
 - if ( version . hasRowSizeAndColumnCount ) 
 - file . readLong ( ) ; 
 
 emptyColumnFamily = ArrayBackedSortedColumns . factory . create ( sstable . metadata ) ; 
 emptyColumnFamily . delete ( DeletionTime . serializer . deserialize ( file ) ) ; 
 - int columnCount = version . hasRowSizeAndColumnCount ? file . readInt ( ) : Integer . MAX _ VALUE ; 
 - atomIterator = emptyColumnFamily . metadata ( ) . getOnDiskIterator ( file , columnCount , sstable . descriptor . version ) ; 
 + atomIterator = emptyColumnFamily . metadata ( ) . getOnDiskIterator ( file , sstable . descriptor . version ) ; 
 } 
 catch ( IOException e ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / Scrubber . java b / src / java / org / apache / cassandra / db / compaction / Scrubber . java 
 index 0a1e8c4 . . 01da2e1 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / Scrubber . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / Scrubber . java 
 @ @ - 130 , 11 + 130 , 6 @ @ public class Scrubber implements Closeable 
 try 
 { 
 key = sstable . partitioner . decorateKey ( ByteBufferUtil . readWithShortLength ( dataFile ) ) ; 
 - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) 
 - { 
 - dataSize = dataFile . readLong ( ) ; 
 - outputHandler . debug ( String . format ( " row % s is % s bytes " , ByteBufferUtil . bytesToHex ( key . key ) , dataSize ) ) ; 
 - } 
 } 
 catch ( Throwable th ) 
 { 
 @ @ - 162 , 22 + 157 , 12 @ @ public class Scrubber implements Closeable 
 long dataStartFromIndex = currentIndexKey = = null 
 ? - 1 
 : rowStart + 2 + currentIndexKey . remaining ( ) ; 
 - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) 
 - dataStartFromIndex + = 8 ; 
 long dataSizeFromIndex = nextRowPositionFromIndex - dataStartFromIndex ; 
 
 - if ( ! sstable . descriptor . version . hasRowSizeAndColumnCount ) 
 - { 
 - dataSize = dataSizeFromIndex ; 
 - / / avoid an NPE if key is null 
 - String keyName = key = = null ? " ( unreadable key ) " : ByteBufferUtil . bytesToHex ( key . key ) ; 
 - outputHandler . debug ( String . format ( " row % s is % s bytes " , keyName , dataSize ) ) ; 
 - } 
 - else 
 - { 
 - if ( currentIndexKey ! = null ) 
 - outputHandler . debug ( String . format ( " Index doublecheck : row % s is % s bytes " , ByteBufferUtil . bytesToHex ( currentIndexKey ) , dataSizeFromIndex ) ) ; 
 - } 
 + dataSize = dataSizeFromIndex ; 
 + / / avoid an NPE if key is null 
 + String keyName = key = = null ? " ( unreadable key ) " : ByteBufferUtil . bytesToHex ( key . key ) ; 
 + outputHandler . debug ( String . format ( " row % s is % s bytes " , keyName , dataSize ) ) ; 
 
 assert currentIndexKey ! = null | | indexFile . isEOF ( ) ; 
 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / Descriptor . java b / src / java / org / apache / cassandra / io / sstable / Descriptor . java 
 index 4803ae7 . . db6f13a 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / Descriptor . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / Descriptor . java 
 @ @ - 49 , 7 + 49 , 6 @ @ public class Descriptor 
 / / This needs to be at the begining for initialization sake 
 public static final String current _ version = " ka " ; 
 
 - / / ic ( 1 . 2 . 5 ) : omits per - row bloom filter of column names 
 / / ja ( 2 . 0 . 0 ) : super columns are serialized as composites ( note that there is no real format change , 
 / / this is mostly a marker to know if we should expect super columns or not . We do need 
 / / a major version bump however , because we should not allow streaming of super columns 
 @ @ - 69 , 12 + 68 , 6 @ @ public class Descriptor 
 private final String version ; 
 
 public final boolean isLatestVersion ; 
 - public final boolean hasSuperColumns ; 
 - public final boolean tracksMaxLocalDeletionTime ; 
 - public final boolean hasBloomFilterFPChance ; 
 - public final boolean offHeapSummaries ; 
 - public final boolean hasRowSizeAndColumnCount ; 
 - public final boolean tracksMaxMinColumnNames ; 
 public final boolean hasPostCompressionAdlerChecksums ; 
 public final boolean hasSamplingLevel ; 
 public final boolean newStatsFile ; 
 @ @ - 84 , 13 + 77 , 7 @ @ public class Descriptor 
 public Version ( String version ) 
 { 
 this . version = version ; 
 - tracksMaxLocalDeletionTime = version . compareTo ( " ja " ) > = 0 ; 
 isLatestVersion = version . compareTo ( current _ version ) = = 0 ; 
 - hasSuperColumns = version . compareTo ( " ja " ) < 0 ; 
 - hasBloomFilterFPChance = version . compareTo ( " ja " ) > = 0 ; 
 - offHeapSummaries = version . compareTo ( " ja " ) > = 0 ; 
 - hasRowSizeAndColumnCount = version . compareTo ( " ja " ) < 0 ; 
 - tracksMaxMinColumnNames = version . compareTo ( " ja " ) > = 0 ; 
 hasPostCompressionAdlerChecksums = version . compareTo ( " jb " ) > = 0 ; 
 hasSamplingLevel = version . compareTo ( " ka " ) > = 0 ; 
 newStatsFile = version . compareTo ( " ka " ) > = 0 ; 
 @ @ - 110 , 7 + 97 , 7 @ @ public class Descriptor 
 
 public boolean isCompatible ( ) 
 { 
 - return version . compareTo ( " ic " ) > = 0 & & version . charAt ( 0 ) < = CURRENT . version . charAt ( 0 ) ; 
 + return version . compareTo ( " ja " ) > = 0 & & version . charAt ( 0 ) < = CURRENT . version . charAt ( 0 ) ; 
 } 
 
 @ Override 
 @ @ - 249 , 7 + 236 , 7 @ @ public class Descriptor 
 } 
 
 if ( ! Version . validate ( nexttok ) ) 
 - throw new UnsupportedOperationException ( " SSTable " + name + " is too old to open . Upgrade to 1 . 2 . 5 first , and run upgradesstables " ) ; 
 + throw new UnsupportedOperationException ( " SSTable " + name + " is too old to open . Upgrade to 2 . 0 first , and run upgradesstables " ) ; 
 Version version = new Version ( nexttok ) ; 
 
 nexttok = st . nextToken ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java b / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java 
 index ce4b670 . . b784a7e 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java 
 @ @ - 89 , 8 + 89 , 7 @ @ public class SSTableIdentityIterator implements Comparable < SSTableIdentityIterat 
 try 
 { 
 columnFamily . delete ( DeletionTime . serializer . deserialize ( in ) ) ; 
 - int columnCount = dataVersion . hasRowSizeAndColumnCount ? in . readInt ( ) : Integer . MAX _ VALUE ; 
 - atomIterator = columnFamily . metadata ( ) . getOnDiskIterator ( in , columnCount , flag , expireBefore , dataVersion ) ; 
 + atomIterator = columnFamily . metadata ( ) . getOnDiskIterator ( in , flag , expireBefore , dataVersion ) ; 
 } 
 catch ( IOException e ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 index 94595b5 . . 82a0bc8 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 @ @ - 525 , 14 + 525 , 14 @ @ public class SSTableReader extends SSTable implements Closeable 
 / / bf is enabled , but filter component is missing . 
 load ( true , true ) ; 
 } 
 - else if ( descriptor . version . hasBloomFilterFPChance & & validation . bloomFilterFPChance ! = metadata . getBloomFilterFpChance ( ) ) 
 + else if ( validation . bloomFilterFPChance ! = metadata . getBloomFilterFpChance ( ) ) 
 { 
 / / bf fp chance in sstable metadata and it has changed since compaction . 
 load ( true , true ) ; 
 } 
 else 
 { 
 - / / bf is enabled , but fp chance isn ' t present in metadata ( pre - ja ) OR matches the currently configured value . 
 + / / bf is enabled and fp chance matches the currently configured value . 
 load ( false , true ) ; 
 loadBloomFilter ( ) ; 
 } 
 @ @ - 655 , 7 + 655 , 7 @ @ public class SSTableReader extends SSTable implements Closeable 
 public boolean loadSummary ( SegmentedFile . Builder ibuilder , SegmentedFile . Builder dbuilder ) 
 { 
 File summariesFile = new File ( descriptor . filenameFor ( Component . SUMMARY ) ) ; 
 - if ( ! descriptor . version . offHeapSummaries | | ! summariesFile . exists ( ) ) 
 + if ( ! summariesFile . exists ( ) ) 
 return false ; 
 
 DataInputStream iStream = null ; 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java b / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java 
 index 911ef8c . . 2af68ae 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java 
 @ @ - 261 , 8 + 261 , 6 @ @ public class SSTableScanner implements ICompactionScanner 
 { 
 dfile . seek ( currentEntry . position ) ; 
 ByteBufferUtil . readWithShortLength ( dfile ) ; / / key 
 - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) 
 - dfile . readLong ( ) ; 
 long dataSize = readEnd - dfile . getFilePointer ( ) ; 
 return new SSTableIdentityIterator ( sstable , dfile , currentKey , dataSize ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 index e93deb5 . . 1dc2c98 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 @ @ - 229 , 19 + 229 , 10 @ @ public class SSTableWriter extends SSTable 
 StreamingHistogram tombstones = new StreamingHistogram ( TOMBSTONE _ HISTOGRAM _ BIN _ SIZE ) ; 
 ColumnFamily cf = ArrayBackedSortedColumns . factory . create ( metadata ) ; 
 
 - / / skip row size for version < ja 
 - if ( version . hasRowSizeAndColumnCount ) 
 - FileUtils . skipBytesFully ( in , 8 ) ; 
 - 
 cf . delete ( DeletionTime . serializer . deserialize ( in ) ) ; 
 
 ColumnIndex . Builder columnIndexer = new ColumnIndex . Builder ( cf , key . key , dataFile . stream ) ; 
 
 - / / read column count for version < ja 
 - int columnCount = Integer . MAX _ VALUE ; 
 - if ( version . hasRowSizeAndColumnCount ) 
 - columnCount = in . readInt ( ) ; 
 - 
 if ( cf . deletionInfo ( ) . getTopLevelDeletion ( ) . localDeletionTime < Integer . MAX _ VALUE ) 
 tombstones . update ( cf . deletionInfo ( ) . getTopLevelDeletion ( ) . localDeletionTime ) ; 
 
 @ @ - 252 , 7 + 243 , 7 @ @ public class SSTableWriter extends SSTable 
 tombstones . update ( rangeTombstone . getLocalDeletionTime ( ) ) ; 
 } 
 
 - Iterator < OnDiskAtom > iter = metadata . getOnDiskIterator ( in , columnCount , ColumnSerializer . Flag . PRESERVE _ SIZE , Integer . MIN _ VALUE , version ) ; 
 + Iterator < OnDiskAtom > iter = metadata . getOnDiskIterator ( in , ColumnSerializer . Flag . PRESERVE _ SIZE , Integer . MIN _ VALUE , version ) ; 
 try 
 { 
 while ( iter . hasNext ( ) ) 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / metadata / LegacyMetadataSerializer . java b / src / java / org / apache / cassandra / io / sstable / metadata / LegacyMetadataSerializer . java 
 index 9e97e2e . . 59f7be5 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / metadata / LegacyMetadataSerializer . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / metadata / LegacyMetadataSerializer . java 
 @ @ - 38 , 8 + 38 , 6 @ @ import org . apache . cassandra . utils . StreamingHistogram ; 
 @ Deprecated 
 public class LegacyMetadataSerializer extends MetadataSerializer 
 { 
 - public static final double NO _ BLOOM _ FILTER _ FP _ CHANCE = - 1 . 0 ; 
 - 
 / * * 
 * Legacy serialization is only used for SSTable level reset . 
 * / 
 @ @ - 96 , 8 + 94 , 8 @ @ public class LegacyMetadataSerializer extends MetadataSerializer 
 ReplayPosition replayPosition = ReplayPosition . serializer . deserialize ( in ) ; 
 long minTimestamp = in . readLong ( ) ; 
 long maxTimestamp = in . readLong ( ) ; 
 - int maxLocalDeletionTime = descriptor . version . tracksMaxLocalDeletionTime ? in . readInt ( ) : Integer . MAX _ VALUE ; 
 - double bloomFilterFPChance = descriptor . version . hasBloomFilterFPChance ? in . readDouble ( ) : NO _ BLOOM _ FILTER _ FP _ CHANCE ; 
 + int maxLocalDeletionTime = in . readInt ( ) ; 
 + double bloomFilterFPChance = in . readDouble ( ) ; 
 double compressionRatio = in . readDouble ( ) ; 
 String partitioner = in . readUTF ( ) ; 
 int nbAncestors = in . readInt ( ) ; 
 @ @ - 109 , 28 + 107 , 15 @ @ public class LegacyMetadataSerializer extends MetadataSerializer 
 if ( in . available ( ) > 0 ) 
 sstableLevel = in . readInt ( ) ; 
 
 - List < ByteBuffer > minColumnNames ; 
 - List < ByteBuffer > maxColumnNames ; 
 - if ( descriptor . version . tracksMaxMinColumnNames ) 
 - { 
 - int colCount = in . readInt ( ) ; 
 - minColumnNames = new ArrayList < > ( colCount ) ; 
 - for ( int i = 0 ; i < colCount ; i + + ) 
 - { 
 - minColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; 
 - } 
 - colCount = in . readInt ( ) ; 
 - maxColumnNames = new ArrayList < > ( colCount ) ; 
 - for ( int i = 0 ; i < colCount ; i + + ) 
 - { 
 - maxColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; 
 - } 
 - } 
 - else 
 - { 
 - minColumnNames = Collections . emptyList ( ) ; 
 - maxColumnNames = Collections . emptyList ( ) ; 
 - } 
 + int colCount = in . readInt ( ) ; 
 + List < ByteBuffer > minColumnNames = new ArrayList < > ( colCount ) ; 
 + for ( int i = 0 ; i < colCount ; i + + ) 
 + minColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; 
 + 
 + colCount = in . readInt ( ) ; 
 + List < ByteBuffer > maxColumnNames = new ArrayList < > ( colCount ) ; 
 + for ( int i = 0 ; i < colCount ; i + + ) 
 + maxColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; 
 
 if ( types . contains ( MetadataType . VALIDATION ) ) 
 components . put ( MetadataType . VALIDATION , 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / metadata / StatsMetadata . java b / src / java / org / apache / cassandra / io / sstable / metadata / StatsMetadata . java 
 index 8568925 . . 1c3dfd5 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / metadata / StatsMetadata . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / metadata / StatsMetadata . java 
 @ @ - 21 , 7 + 21 , 6 @ @ import java . io . DataInput ; 
 import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 import java . util . ArrayList ; 
 - import java . util . Collections ; 
 import java . util . List ; 
 
 import org . apache . commons . lang3 . builder . EqualsBuilder ; 
 @ @ - 234 , 35 + 233 , 24 @ @ public class StatsMetadata extends MetadataComponent 
 ReplayPosition replayPosition = ReplayPosition . serializer . deserialize ( in ) ; 
 long minTimestamp = in . readLong ( ) ; 
 long maxTimestamp = in . readLong ( ) ; 
 - int maxLocalDeletionTime = version . tracksMaxLocalDeletionTime ? in . readInt ( ) : Integer . MAX _ VALUE ; 
 + int maxLocalDeletionTime = in . readInt ( ) ; 
 double compressionRatio = in . readDouble ( ) ; 
 StreamingHistogram tombstoneHistogram = StreamingHistogram . serializer . deserialize ( in ) ; 
 int sstableLevel = in . readInt ( ) ; 
 long repairedAt = 0 ; 
 if ( version . hasRepairedAt ) 
 repairedAt = in . readLong ( ) ; 
 - List < ByteBuffer > minColumnNames ; 
 - List < ByteBuffer > maxColumnNames ; 
 - if ( version . tracksMaxMinColumnNames ) 
 - { 
 - int colCount = in . readInt ( ) ; 
 - minColumnNames = new ArrayList < > ( colCount ) ; 
 - for ( int i = 0 ; i < colCount ; i + + ) 
 - { 
 - minColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; 
 - } 
 - colCount = in . readInt ( ) ; 
 - maxColumnNames = new ArrayList < > ( colCount ) ; 
 - for ( int i = 0 ; i < colCount ; i + + ) 
 - { 
 - maxColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; 
 - } 
 - } 
 - else 
 - { 
 - minColumnNames = Collections . emptyList ( ) ; 
 - maxColumnNames = Collections . emptyList ( ) ; 
 - } 
 + 
 + int colCount = in . readInt ( ) ; 
 + List < ByteBuffer > minColumnNames = new ArrayList < > ( colCount ) ; 
 + for ( int i = 0 ; i < colCount ; i + + ) 
 + minColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; 
 + 
 + colCount = in . readInt ( ) ; 
 + List < ByteBuffer > maxColumnNames = new ArrayList < > ( colCount ) ; 
 + for ( int i = 0 ; i < colCount ; i + + ) 
 + maxColumnNames . add ( ByteBufferUtil . readWithShortLength ( in ) ) ; 
 + 
 return new StatsMetadata ( rowSizes , 
 columnCounts , 
 replayPosition , 
 diff - - git a / src / java / org / apache / cassandra / tools / SSTableExport . java b / src / java / org / apache / cassandra / tools / SSTableExport . java 
 index cff6e71 . . bbc3494 100644 
 - - - a / src / java / org / apache / cassandra / tools / SSTableExport . java 
 + + + b / src / java / org / apache / cassandra / tools / SSTableExport . java 
 @ @ - 308 , 12 + 308 , 8 @ @ public class SSTableExport 
 
 dfile . seek ( entry . position ) ; 
 ByteBufferUtil . readWithShortLength ( dfile ) ; / / row key 
 - if ( sstable . descriptor . version . hasRowSizeAndColumnCount ) 
 - dfile . readLong ( ) ; / / row size 
 DeletionInfo deletionInfo = new DeletionInfo ( DeletionTime . serializer . deserialize ( dfile ) ) ; 
 - int columnCount = sstable . descriptor . version . hasRowSizeAndColumnCount ? dfile . readInt ( ) : Integer . MAX _ VALUE ; 
 - 
 - Iterator < OnDiskAtom > atomIterator = sstable . metadata . getOnDiskIterator ( dfile , columnCount , sstable . descriptor . version ) ; 
 + Iterator < OnDiskAtom > atomIterator = sstable . metadata . getOnDiskIterator ( dfile , sstable . descriptor . version ) ; 
 
 checkStream ( outs ) ; 
 
 diff - - git a / test / unit / org / apache / cassandra / io / sstable / LegacySSTableTest . java b / test / unit / org / apache / cassandra / io / sstable / LegacySSTableTest . java 
 index ad9ce5b . . c0c9d41 100644 
 - - - a / test / unit / org / apache / cassandra / io / sstable / LegacySSTableTest . java 
 + + + b / test / unit / org / apache / cassandra / io / sstable / LegacySSTableTest . java 
 @ @ - 97 , 7 + 97 , 7 @ @ public class LegacySSTableTest extends SchemaLoader 
 StorageService . instance . initServer ( ) ; 
 
 for ( File version : LEGACY _ SSTABLE _ ROOT . listFiles ( ) ) 
 - if ( Descriptor . Version . validate ( version . getName ( ) ) ) 
 + if ( Descriptor . Version . validate ( version . getName ( ) ) & & new Descriptor . Version ( version . getName ( ) ) . isCompatible ( ) ) 
 testStreaming ( version . getName ( ) ) ; 
 } 
 
 @ @ - 135 , 7 + 135 , 7 @ @ public class LegacySSTableTest extends SchemaLoader 
 public void testVersions ( ) throws Throwable 
 { 
 for ( File version : LEGACY _ SSTABLE _ ROOT . listFiles ( ) ) 
 - if ( Descriptor . Version . validate ( version . getName ( ) ) ) 
 + if ( Descriptor . Version . validate ( version . getName ( ) ) & & new Descriptor . Version ( version . getName ( ) ) . isCompatible ( ) ) 
 testVersion ( version . getName ( ) ) ; 
 } 


NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 7dbb62a . . 7fc93f4 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 5 + 1 , 4 @ @ 
 1 . 2 . 5 
 - * Fix promoted row - level tombstone writing ( CASSANDRA - 5486 ) 
 * Include fatal errors in trace events ( CASSANDRA - 5447 ) 
 * Ensure that PerRowSecondaryIndex is notified of row - level deletes 
 ( CASSANDRA - 5445 ) 
 diff - - git a / build . xml b / build . xml 
 index 2ddd43d . . 3491431 100644 
 - - - a / build . xml 
 + + + b / build . xml 
 @ @ - 519 , 7 + 519 , 7 @ @ 
 < / artifact : pom > 
 < / target > 
 
 - < target name = " maven - ant - tasks - retrieve - build " depends = " maven - declare - dependencies " unless = " without . maven " > 
 + < target name = " maven - ant - tasks - retrieve - build " depends = " maven - declare - dependencies " > 
 < artifact : dependencies pomRefId = " build - deps - pom " 
 filesetId = " build - dependency - jars " 
 sourcesFilesetId = " build - dependency - sources " 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnIndex . java b / src / java / org / apache / cassandra / db / ColumnIndex . java 
 index e2ac3e4 . . bcd0eef 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnIndex . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnIndex . java 
 @ @ - 33 , 7 + 33 , 7 @ @ public class ColumnIndex 
 public final List < IndexHelper . IndexInfo > columnsIndex ; 
 public final IFilter bloomFilter ; 
 
 - private static final ColumnIndex EMPTY = new ColumnIndex ( Collections . < IndexHelper . IndexInfo > emptyList ( ) , AlwaysPresentFilter . instance ) ; 
 + private static final ColumnIndex EMPTY = new ColumnIndex ( Collections . < IndexHelper . IndexInfo > emptyList ( ) , new AlwaysPresentFilter ( ) ) ; 
 
 private ColumnIndex ( int estimatedColumnCount ) 
 { 
 @ @ - 42 , 9 + 42 , 6 @ @ public class ColumnIndex 
 
 private ColumnIndex ( List < IndexHelper . IndexInfo > columnsIndex , IFilter bloomFilter ) 
 { 
 - assert columnsIndex ! = null ; 
 - assert bloomFilter ! = null ; 
 - 
 this . columnsIndex = columnsIndex ; 
 this . bloomFilter = bloomFilter ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / RowIndexEntry . java b / src / java / org / apache / cassandra / db / RowIndexEntry . java 
 index a60bf6d . . a831498 100644 
 - - - a / src / java / org / apache / cassandra / db / RowIndexEntry . java 
 + + + b / src / java / org / apache / cassandra / db / RowIndexEntry . java 
 @ @ - 28 , 7 + 28 , 6 @ @ import org . apache . cassandra . cache . IMeasurableMemory ; 
 import org . apache . cassandra . io . sstable . Descriptor ; 
 import org . apache . cassandra . io . sstable . IndexHelper ; 
 import org . apache . cassandra . io . util . FileUtils ; 
 - import org . apache . cassandra . utils . AlwaysPresentFilter ; 
 import org . apache . cassandra . utils . IFilter ; 
 import org . apache . cassandra . utils . FilterFactory ; 
 import org . apache . cassandra . utils . ObjectSizes ; 
 @ @ - 46 , 42 + 45 , 35 @ @ public class RowIndexEntry implements IMeasurableMemory 
 
 public int serializedSize ( ) 
 { 
 - return TypeSizes . NATIVE . sizeof ( position ) + promotedSize ( ) ; 
 + return TypeSizes . NATIVE . sizeof ( position ) ; 
 } 
 
 - public int promotedSize ( ) 
 - { 
 - return 0 ; 
 - } 
 - 
 - / / TODO only store DeletionTime 
 public static RowIndexEntry create ( long position , DeletionInfo deletionInfo , ColumnIndex index ) 
 { 
 - assert deletionInfo ! = null ; 
 - assert index ! = null ; 
 - 
 - if ( index . columnsIndex . size ( ) > 1 | | deletionInfo . getTopLevelDeletion ( ) ! = DeletionTime . LIVE ) 
 - return new IndexedEntry ( position , 
 - deletionInfo , 
 - index . columnsIndex . isEmpty ( ) ? Collections . < IndexHelper . IndexInfo > emptyList ( ) : index . columnsIndex , 
 - index . columnsIndex . isEmpty ( ) ? AlwaysPresentFilter . instance : index . bloomFilter ) ; 
 + if ( index ! = null & & index . columnsIndex ! = null & & index . columnsIndex . size ( ) > 1 ) 
 + return new IndexedEntry ( position , deletionInfo , index . columnsIndex , index . bloomFilter ) ; 
 else 
 return new RowIndexEntry ( position ) ; 
 } 
 
 + public boolean isIndexed ( ) 
 + { 
 + return ! columnsIndex ( ) . isEmpty ( ) ; 
 + } 
 + 
 public DeletionInfo deletionInfo ( ) 
 { 
 - return DeletionInfo . LIVE ; 
 + throw new UnsupportedOperationException ( ) ; 
 } 
 
 public List < IndexHelper . IndexInfo > columnsIndex ( ) 
 { 
 - return Collections . emptyList ( ) ; 
 + return Collections . < IndexHelper . IndexInfo > emptyList ( ) ; 
 } 
 
 public IFilter bloomFilter ( ) 
 { 
 - return AlwaysPresentFilter . instance ; 
 + throw new UnsupportedOperationException ( ) ; 
 } 
 
 public long memorySize ( ) 
 @ @ - 95 , 15 + 87 , 14 @ @ public class RowIndexEntry implements IMeasurableMemory 
 public void serialize ( RowIndexEntry rie , DataOutput dos ) throws IOException 
 { 
 dos . writeLong ( rie . position ) ; 
 - if ( ! rie . columnsIndex ( ) . isEmpty ( ) | | rie . deletionInfo ( ) . getTopLevelDeletion ( ) ! = DeletionTime . LIVE ) 
 + if ( rie . isIndexed ( ) ) 
 { 
 - dos . writeInt ( rie . promotedSize ( ) ) ; 
 + dos . writeInt ( ( ( IndexedEntry ) rie ) . serializedSize ( ) ) ; 
 DeletionInfo . serializer ( ) . serializeForSSTable ( rie . deletionInfo ( ) , dos ) ; 
 dos . writeInt ( rie . columnsIndex ( ) . size ( ) ) ; 
 for ( IndexHelper . IndexInfo info : rie . columnsIndex ( ) ) 
 info . serialize ( dos ) ; 
 - if ( ! rie . columnsIndex ( ) . isEmpty ( ) ) 
 - FilterFactory . serialize ( rie . bloomFilter ( ) , dos ) ; 
 + FilterFactory . serialize ( rie . bloomFilter ( ) , dos ) ; 
 } 
 else 
 { 
 @ @ - 111 , 24 + 102 , 38 @ @ public class RowIndexEntry implements IMeasurableMemory 
 } 
 } 
 
 - public RowIndexEntry deserialize ( DataInput dis , Descriptor . Version version ) throws IOException 
 + public RowIndexEntry deserializePositionOnly ( DataInput dis , Descriptor . Version version ) throws IOException 
 { 
 long position = dis . readLong ( ) ; 
 - if ( ! version . hasPromotedIndexes ) 
 - return new RowIndexEntry ( position ) ; 
 + if ( version . hasPromotedIndexes ) 
 + { 
 + int size = dis . readInt ( ) ; 
 + if ( size > 0 ) 
 + FileUtils . skipBytesFully ( dis , size ) ; 
 + } 
 + return new RowIndexEntry ( position ) ; 
 + } 
 
 - int size = dis . readInt ( ) ; 
 - if ( size > 0 ) 
 + public RowIndexEntry deserialize ( DataInput dis , Descriptor . Version version ) throws IOException 
 + { 
 + long position = dis . readLong ( ) ; 
 + if ( version . hasPromotedIndexes ) 
 { 
 - DeletionInfo delInfo = DeletionInfo . serializer ( ) . deserializeFromSSTable ( dis , version ) ; 
 - int entries = dis . readInt ( ) ; 
 - List < IndexHelper . IndexInfo > columnsIndex = new ArrayList < IndexHelper . IndexInfo > ( entries ) ; 
 - for ( int i = 0 ; i < entries ; i + + ) 
 - columnsIndex . add ( IndexHelper . IndexInfo . deserialize ( dis ) ) ; 
 - IFilter bf = entries = = 0 
 - ? AlwaysPresentFilter . instance 
 - : FilterFactory . deserialize ( dis , version . filterType , false ) ; 
 - return new IndexedEntry ( position , delInfo , columnsIndex , bf ) ; 
 + int size = dis . readInt ( ) ; 
 + if ( size > 0 ) 
 + { 
 + DeletionInfo delInfo = DeletionInfo . serializer ( ) . deserializeFromSSTable ( dis , version ) ; 
 + int entries = dis . readInt ( ) ; 
 + List < IndexHelper . IndexInfo > columnsIndex = new ArrayList < IndexHelper . IndexInfo > ( entries ) ; 
 + for ( int i = 0 ; i < entries ; i + + ) 
 + columnsIndex . add ( IndexHelper . IndexInfo . deserialize ( dis ) ) ; 
 + IFilter bf = FilterFactory . deserialize ( dis , version . filterType , false ) ; 
 + return new IndexedEntry ( position , delInfo , columnsIndex , bf ) ; 
 + } 
 + else 
 + { 
 + return new RowIndexEntry ( position ) ; 
 + } 
 } 
 else 
 { 
 @ @ - 166 , 7 + 171 , 7 @ @ public class RowIndexEntry implements IMeasurableMemory 
 { 
 super ( position ) ; 
 assert deletionInfo ! = null ; 
 - assert columnsIndex ! = null ; 
 + assert columnsIndex ! = null & & columnsIndex . size ( ) > 1 ; 
 this . deletionInfo = deletionInfo ; 
 this . columnsIndex = columnsIndex ; 
 this . bloomFilter = bloomFilter ; 
 @ @ - 191 , 7 + 196 , 7 @ @ public class RowIndexEntry implements IMeasurableMemory 
 } 
 
 @ Override 
 - public int promotedSize ( ) 
 + public int serializedSize ( ) 
 { 
 TypeSizes typeSizes = TypeSizes . NATIVE ; 
 long size = DeletionTime . serializer . serializedSize ( deletionInfo . getTopLevelDeletion ( ) , typeSizes ) ; 
 @ @ - 199 , 7 + 204 , 7 @ @ public class RowIndexEntry implements IMeasurableMemory 
 for ( IndexHelper . IndexInfo info : columnsIndex ) 
 size + = info . serializedSize ( typeSizes ) ; 
 
 - size + = bloomFilter instanceof AlwaysPresentFilter ? 0 : FilterFactory . serializedSize ( bloomFilter ) ; 
 + size + = FilterFactory . serializedSize ( bloomFilter ) ; 
 assert size < = Integer . MAX _ VALUE ; 
 return ( int ) size ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java 
 index 61ae00e . . 7289ab0 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java 
 @ @ - 65 , 7 + 65 , 7 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 * finish ( reverse start ) elements . i . e . forward : [ a , b ] , [ d , e ] , [ g , h ] reverse : [ h , g ] , [ e , d ] , [ b , a ] . This reader also 
 * assumes that validation has been performed in terms of intervals ( no overlapping intervals ) . 
 * / 
 - public IndexedSliceReader ( SSTableReader sstable , RowIndexEntry rowEntry , FileDataInput input , ColumnSlice [ ] slices , boolean reversed ) 
 + public IndexedSliceReader ( SSTableReader sstable , RowIndexEntry indexEntry , FileDataInput input , ColumnSlice [ ] slices , boolean reversed ) 
 { 
 this . sstable = sstable ; 
 this . originalInput = input ; 
 @ @ - 76 , 53 + 76 , 34 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 try 
 { 
 Descriptor . Version version = sstable . descriptor . version ; 
 - emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; 
 - 
 - if ( version . hasPromotedRowTombstones & & ! rowEntry . columnsIndex ( ) . isEmpty ( ) ) 
 - { 
 - / / skip the row header entirely 
 - indexes = rowEntry . columnsIndex ( ) ; 
 - emptyColumnFamily . delete ( rowEntry . deletionInfo ( ) ) ; 
 - fetcher = new IndexedBlockFetcher ( rowEntry . position ) ; 
 - return ; 
 - } 
 - 
 - / / skip up to bloom filter where things get a bit more interesting 
 - if ( input = = null ) 
 - { 
 - file = sstable . getFileDataInput ( rowEntry . position ) ; 
 - } 
 - else 
 - { 
 - file = input ; 
 - file . seek ( rowEntry . position ) ; 
 - } 
 - this . sstable . decodeKey ( ByteBufferUtil . readWithShortLength ( file ) ) ; 
 - SSTableReader . readRowSize ( file , this . sstable . descriptor ) ; 
 - 
 - / / read the row header up to and including the row - level tombstones 
 if ( version . hasPromotedIndexes ) 
 { 
 - indexes = rowEntry . columnsIndex ( ) ; 
 - emptyColumnFamily . delete ( rowEntry . deletionInfo ( ) ) ; 
 - } 
 - else 
 - { 
 - IndexHelper . skipSSTableBloomFilter ( input , version ) ; 
 - indexes = IndexHelper . deserializeIndex ( file ) ; 
 - } 
 - emptyColumnFamily . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , version ) ) ; 
 - 
 - if ( indexes . isEmpty ( ) ) 
 - { 
 - fetcher = new SimpleBlockFetcher ( ) ; 
 + this . indexes = indexEntry . columnsIndex ( ) ; 
 + if ( indexes . isEmpty ( ) ) 
 + { 
 + setToRowStart ( sstable , indexEntry , input ) ; 
 + this . emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; 
 + emptyColumnFamily . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , version ) ) ; 
 + fetcher = new SimpleBlockFetcher ( ) ; 
 + } 
 + else 
 + { 
 + this . emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; 
 + emptyColumnFamily . delete ( indexEntry . deletionInfo ( ) ) ; 
 + fetcher = new IndexedBlockFetcher ( indexEntry . position ) ; 
 + } 
 } 
 else 
 { 
 - / / index offsets changed to be based against the row key start in 1 . 2 
 - fetcher = version . hasPromotedIndexes 
 - ? new IndexedBlockFetcher ( rowEntry . position ) 
 - : new IndexedBlockFetcher ( file . getFilePointer ( ) + 4 ) ; / / + 4 to skip the int column count 
 + setToRowStart ( sstable , indexEntry , input ) ; 
 + IndexHelper . skipSSTableBloomFilter ( file , version ) ; 
 + this . indexes = IndexHelper . deserializeIndex ( file ) ; 
 + this . emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; 
 + emptyColumnFamily . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , version ) ) ; 
 + fetcher = indexes . isEmpty ( ) 
 + ? new SimpleBlockFetcher ( ) 
 + : new IndexedBlockFetcher ( file . getFilePointer ( ) + 4 ) ; / / We still have the column count to 
 + / / skip to get the basePosition 
 } 
 } 
 catch ( IOException e ) 
 @ @ - 132 , 6 + 113 , 24 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 } 
 } 
 
 + / * * 
 + * Sets the seek position to the start of the row for column scanning . 
 + * / 
 + private void setToRowStart ( SSTableReader reader , RowIndexEntry indexEntry , FileDataInput input ) throws IOException 
 + { 
 + if ( input = = null ) 
 + { 
 + this . file = sstable . getFileDataInput ( indexEntry . position ) ; 
 + } 
 + else 
 + { 
 + this . file = input ; 
 + input . seek ( indexEntry . position ) ; 
 + } 
 + sstable . decodeKey ( ByteBufferUtil . readWithShortLength ( file ) ) ; 
 + SSTableReader . readRowSize ( file , sstable . descriptor ) ; 
 + } 
 + 
 public ColumnFamily getColumnFamily ( ) 
 { 
 return emptyColumnFamily ; 
 @ @ - 198 , 6 + 197 , 8 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 return reversed ? slices [ currentSliceIdx ] . start : slices [ currentSliceIdx ] . finish ; 
 } 
 
 + protected abstract boolean setNextSlice ( ) ; 
 + 
 protected abstract boolean fetchMoreData ( ) ; 
 
 protected boolean isColumnBeforeSliceStart ( OnDiskAtom column ) 
 @ @ - 247 , 7 + 248 , 7 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 setNextSlice ( ) ; 
 } 
 
 - private boolean setNextSlice ( ) 
 + protected boolean setNextSlice ( ) 
 { 
 while ( + + currentSliceIdx < slices . length ) 
 { 
 @ @ - 349 , 7 + 350 , 7 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 / * seek to the correct offset to the data , and calculate the data size * / 
 long positionToSeek = basePosition + currentIndex . offset ; 
 
 - / / With 1 . 2 promoted indexes , our first seek in the data file will happen at this point 
 + / / With new promoted indexes , our first seek in the data file will happen at that point . 
 if ( file = = null ) 
 file = originalInput = = null ? sstable . getFileDataInput ( positionToSeek ) : originalInput ; 
 
 @ @ - 463 , 7 + 464 , 7 @ @ class IndexedSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskA 
 } 
 } 
 
 - private boolean setNextSlice ( ) 
 + protected boolean setNextSlice ( ) 
 { 
 if ( reversed ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java 
 index 326447f . . da4631d 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java 
 @ @ - 19 , 22 + 19 , 25 @ @ package org . apache . cassandra . db . columniterator ; 
 
 import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 - import java . util . ArrayList ; 
 - import java . util . Iterator ; 
 - import java . util . List ; 
 - import java . util . SortedSet ; 
 + import java . util . * ; 
 
 import org . apache . cassandra . config . CFMetaData ; 
 - import org . apache . cassandra . db . * ; 
 + import org . apache . cassandra . db . ColumnFamily ; 
 + import org . apache . cassandra . db . ColumnFamilySerializer ; 
 + import org . apache . cassandra . db . DecoratedKey ; 
 + import org . apache . cassandra . db . DeletionInfo ; 
 + import org . apache . cassandra . db . IColumn ; 
 + import org . apache . cassandra . db . RowIndexEntry ; 
 + import org . apache . cassandra . db . OnDiskAtom ; 
 import org . apache . cassandra . db . marshal . AbstractType ; 
 import org . apache . cassandra . io . sstable . CorruptSSTableException ; 
 - import org . apache . cassandra . io . sstable . Descriptor ; 
 import org . apache . cassandra . io . sstable . IndexHelper ; 
 import org . apache . cassandra . io . sstable . SSTableReader ; 
 import org . apache . cassandra . io . util . FileDataInput ; 
 import org . apache . cassandra . io . util . FileMark ; 
 import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 + import org . apache . cassandra . utils . IFilter ; 
 
 public class SSTableNamesIterator extends SimpleAbstractColumnIterator implements ISSTableColumnIterator 
 { 
 @ @ - 52 , 13 + 55 , 13 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement 
 this . columns = columns ; 
 this . key = key ; 
 
 - RowIndexEntry rowEntry = sstable . getPosition ( key , SSTableReader . Operator . EQ ) ; 
 - if ( rowEntry = = null ) 
 + RowIndexEntry indexEntry = sstable . getPosition ( key , SSTableReader . Operator . EQ ) ; 
 + if ( indexEntry = = null ) 
 return ; 
 
 try 
 { 
 - read ( sstable , null , rowEntry ) ; 
 + read ( sstable , null , indexEntry ) ; 
 } 
 catch ( IOException e ) 
 { 
 @ @ - 72 , 7 + 75 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement 
 } 
 } 
 
 - public SSTableNamesIterator ( SSTableReader sstable , FileDataInput file , DecoratedKey key , SortedSet < ByteBuffer > columns , RowIndexEntry rowEntry ) 
 + public SSTableNamesIterator ( SSTableReader sstable , FileDataInput file , DecoratedKey key , SortedSet < ByteBuffer > columns , RowIndexEntry indexEntry ) 
 { 
 assert columns ! = null ; 
 this . sstable = sstable ; 
 @ @ - 81 , 7 + 84 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement 
 
 try 
 { 
 - read ( sstable , file , rowEntry ) ; 
 + read ( sstable , file , indexEntry ) ; 
 } 
 catch ( IOException e ) 
 { 
 @ @ - 101 , 66 + 104 , 101 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement 
 return sstable ; 
 } 
 
 - private void read ( SSTableReader sstable , FileDataInput file , RowIndexEntry rowEntry ) 
 - throws IOException 
 + private void read ( SSTableReader sstable , FileDataInput file , RowIndexEntry indexEntry ) 
 + throws IOException 
 { 
 + IFilter bf ; 
 List < IndexHelper . IndexInfo > indexList ; 
 
 - Descriptor . Version version = sstable . descriptor . version ; 
 - cf = ColumnFamily . create ( sstable . metadata ) ; 
 - List < OnDiskAtom > result = new ArrayList < OnDiskAtom > ( columns . size ( ) ) ; 
 - 
 - if ( version . hasPromotedRowTombstones & & ! rowEntry . columnsIndex ( ) . isEmpty ( ) ) 
 + / / If the entry is not indexed or the index is not promoted , read from the row start 
 + if ( ! indexEntry . isIndexed ( ) ) 
 { 
 - / / skip the row header entirely 
 - cf . delete ( rowEntry . deletionInfo ( ) ) ; 
 + if ( file = = null ) 
 + file = createFileDataInput ( indexEntry . position ) ; 
 + else 
 + file . seek ( indexEntry . position ) ; 
 
 - readIndexedColumns ( sstable . metadata , file , columns , rowEntry . columnsIndex ( ) , rowEntry . position , result ) ; 
 - iter = result . iterator ( ) ; 
 - return ; 
 + DecoratedKey keyInDisk = SSTableReader . decodeKey ( sstable . partitioner , 
 + sstable . descriptor , 
 + ByteBufferUtil . readWithShortLength ( file ) ) ; 
 + assert keyInDisk . equals ( key ) : String . format ( " % s ! = % s in % s " , keyInDisk , key , file . getPath ( ) ) ; 
 + SSTableReader . readRowSize ( file , sstable . descriptor ) ; 
 } 
 
 - if ( file = = null ) 
 - file = createFileDataInput ( rowEntry . position ) ; 
 - else 
 - file . seek ( rowEntry . position ) ; 
 - 
 - DecoratedKey keyInDisk = SSTableReader . decodeKey ( sstable . partitioner , 
 - sstable . descriptor , 
 - ByteBufferUtil . readWithShortLength ( file ) ) ; 
 - assert keyInDisk . equals ( key ) : String . format ( " % s ! = % s in % s " , keyInDisk , key , file . getPath ( ) ) ; 
 - SSTableReader . readRowSize ( file , sstable . descriptor ) ; 
 - 
 if ( sstable . descriptor . version . hasPromotedIndexes ) 
 { 
 - indexList = rowEntry . columnsIndex ( ) ; 
 - cf . delete ( rowEntry . deletionInfo ( ) ) ; 
 + bf = indexEntry . isIndexed ( ) ? indexEntry . bloomFilter ( ) : null ; 
 + indexList = indexEntry . columnsIndex ( ) ; 
 } 
 else 
 { 
 + assert file ! = null ; 
 + bf = IndexHelper . defreezeBloomFilter ( file , sstable . descriptor . version . filterType ) ; 
 indexList = IndexHelper . deserializeIndex ( file ) ; 
 } 
 
 - cf . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , sstable . descriptor . version ) ) ; 
 + if ( ! indexEntry . isIndexed ( ) ) 
 + { 
 + / / we can stop early if bloom filter says none of the columns actually exist - - but , 
 + / / we can ' t stop before initializing the cf above , in case there ' s a relevant tombstone 
 + ColumnFamilySerializer serializer = ColumnFamily . serializer ; 
 + try 
 + { 
 + cf = ColumnFamily . create ( sstable . metadata ) ; 
 + cf . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , sstable . descriptor . version ) ) ; 
 + } 
 + catch ( Exception e ) 
 + { 
 + throw new IOException ( serializer + " failed to deserialize " + sstable . getColumnFamilyName ( ) + " with " + sstable . metadata + " from " + file , e ) ; 
 + } 
 + } 
 + else 
 + { 
 + cf = ColumnFamily . create ( sstable . metadata ) ; 
 + cf . delete ( indexEntry . deletionInfo ( ) ) ; 
 + } 
 + 
 + List < OnDiskAtom > result = new ArrayList < OnDiskAtom > ( ) ; 
 + List < ByteBuffer > filteredColumnNames = new ArrayList < ByteBuffer > ( columns . size ( ) ) ; 
 + for ( ByteBuffer name : columns ) 
 + { 
 + if ( bf = = null | | bf . isPresent ( name ) ) 
 + { 
 + filteredColumnNames . add ( name ) ; 
 + } 
 + } 
 + if ( filteredColumnNames . isEmpty ( ) ) 
 + return ; 
 
 if ( indexList . isEmpty ( ) ) 
 { 
 - readSimpleColumns ( file , columns , result ) ; 
 + readSimpleColumns ( file , columns , filteredColumnNames , result ) ; 
 } 
 else 
 { 
 - long basePosition = version . hasPromotedIndexes ? rowEntry . position : file . getFilePointer ( ) + 4 ; 
 - readIndexedColumns ( sstable . metadata , file , columns , indexList , basePosition , result ) ; 
 + long basePosition ; 
 + if ( sstable . descriptor . version . hasPromotedIndexes ) 
 + { 
 + basePosition = indexEntry . position ; 
 + } 
 + else 
 + { 
 + assert file ! = null ; 
 + file . readInt ( ) ; / / column count 
 + basePosition = file . getFilePointer ( ) ; 
 + } 
 + readIndexedColumns ( sstable . metadata , file , columns , filteredColumnNames , indexList , basePosition , result ) ; 
 } 
 
 / / create an iterator view of the columns we read 
 iter = result . iterator ( ) ; 
 } 
 
 - private void readSimpleColumns ( FileDataInput file , SortedSet < ByteBuffer > columnNames , List < OnDiskAtom > result ) throws IOException 
 + private void readSimpleColumns ( FileDataInput file , SortedSet < ByteBuffer > columnNames , List < ByteBuffer > filteredColumnNames , List < OnDiskAtom > result ) throws IOException 
 { 
 OnDiskAtom . Serializer atomSerializer = cf . getOnDiskSerializer ( ) ; 
 int columns = file . readInt ( ) ; 
 + int n = 0 ; 
 for ( int i = 0 ; i < columns ; i + + ) 
 { 
 OnDiskAtom column = atomSerializer . deserializeFromSSTable ( file , sstable . descriptor . version ) ; 
 @ @ - 169 , 7 + 207 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement 
 if ( columnNames . contains ( column . name ( ) ) ) 
 { 
 result . add ( column ) ; 
 - if ( result . size ( ) > = columnNames . size ( ) ) 
 + if ( n + + > filteredColumnNames . size ( ) ) 
 break ; 
 } 
 } 
 @ @ - 183 , 16 + 221 , 17 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement 
 private void readIndexedColumns ( CFMetaData metadata , 
 FileDataInput file , 
 SortedSet < ByteBuffer > columnNames , 
 + List < ByteBuffer > filteredColumnNames , 
 List < IndexHelper . IndexInfo > indexList , 
 long basePosition , 
 List < OnDiskAtom > result ) 
 - throws IOException 
 + throws IOException 
 { 
 / * get the various column ranges we have to read * / 
 AbstractType < ? > comparator = metadata . comparator ; 
 List < IndexHelper . IndexInfo > ranges = new ArrayList < IndexHelper . IndexInfo > ( ) ; 
 int lastIndexIdx = - 1 ; 
 - for ( ByteBuffer name : columnNames ) 
 + for ( ByteBuffer name : filteredColumnNames ) 
 { 
 int index = IndexHelper . indexFor ( name , indexList , comparator , false , lastIndexIdx ) ; 
 if ( index < 0 | | index = = indexList . size ( ) ) 
 @ @ - 212 , 7 + 251 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement 
 { 
 long positionToSeek = basePosition + indexInfo . offset ; 
 
 - / / With 1 . 2 promoted indexes , our first seek in the data file will happen at this point 
 + / / With new promoted indexes , our first seek in the data file will happen at that point . 
 if ( file = = null ) 
 file = createFileDataInput ( positionToSeek ) ; 
 
 @ @ - 223 , 6 + 262 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement 
 while ( file . bytesPastMark ( mark ) < indexInfo . width ) 
 { 
 OnDiskAtom column = atomSerializer . deserializeFromSSTable ( file , sstable . descriptor . version ) ; 
 + / / we check vs the original Set , not the filtered List , for efficiency 
 if ( ! ( column instanceof IColumn ) | | columnNames . contains ( column . name ( ) ) ) 
 result . add ( column ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java 
 index 0cf9af6 . . b30d360 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java 
 @ @ - 49 , 7 + 49 , 7 @ @ class SimpleSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskAt 
 private FileMark mark ; 
 private final OnDiskAtom . Serializer atomSerializer ; 
 
 - public SimpleSliceReader ( SSTableReader sstable , RowIndexEntry rowEntry , FileDataInput input , ByteBuffer finishColumn ) 
 + public SimpleSliceReader ( SSTableReader sstable , RowIndexEntry indexEntry , FileDataInput input , ByteBuffer finishColumn ) 
 { 
 this . sstable = sstable ; 
 this . finishColumn = finishColumn ; 
 @ @ - 58 , 13 + 58 , 13 @ @ class SimpleSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskAt 
 { 
 if ( input = = null ) 
 { 
 - this . file = sstable . getFileDataInput ( rowEntry . position ) ; 
 + this . file = sstable . getFileDataInput ( indexEntry . position ) ; 
 this . needsClosing = true ; 
 } 
 else 
 { 
 this . file = input ; 
 - input . seek ( rowEntry . position ) ; 
 + input . seek ( indexEntry . position ) ; 
 this . needsClosing = false ; 
 } 
 
 @ @ - 72 , 19 + 72 , 14 @ @ class SimpleSliceReader extends AbstractIterator < OnDiskAtom > implements OnDiskAt 
 ByteBufferUtil . skipShortLength ( file ) ; 
 SSTableReader . readRowSize ( file , sstable . descriptor ) ; 
 
 - emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; 
 - 
 Descriptor . Version version = sstable . descriptor . version ; 
 - if ( version . hasPromotedIndexes ) 
 - { 
 - emptyColumnFamily . delete ( rowEntry . deletionInfo ( ) ) ; 
 - } 
 - else 
 + if ( ! version . hasPromotedIndexes ) 
 { 
 IndexHelper . skipSSTableBloomFilter ( file , version ) ; 
 IndexHelper . skipIndex ( file ) ; 
 } 
 
 + emptyColumnFamily = ColumnFamily . create ( sstable . metadata ) ; 
 emptyColumnFamily . delete ( DeletionInfo . serializer ( ) . deserializeFromSSTable ( file , version ) ) ; 
 atomSerializer = emptyColumnFamily . getOnDiskSerializer ( ) ; 
 columns = file . readInt ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / Descriptor . java b / src / java / org / apache / cassandra / io / sstable / Descriptor . java 
 index 7b916cb . . f21a0d5 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / Descriptor . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / Descriptor . java 
 @ @ - 47 , 7 + 47 , 7 @ @ public class Descriptor 
 public static class Version 
 { 
 / / This needs to be at the begining for initialization sake 
 - public static final String current _ version = " ic " ; 
 + public static final String current _ version = " ib " ; 
 
 public static final Version LEGACY = new Version ( " a " ) ; / / " pre - history " 
 / / b ( 0 . 7 . 0 ) : added version to sstable filenames 
 @ @ - 62 , 11 + 62 , 10 @ @ public class Descriptor 
 / / hd ( 1 . 0 . 10 ) : includes row tombstones in maxtimestamp 
 / / he ( 1 . 1 . 3 ) : includes ancestors generation in metadata component 
 / / hf ( 1 . 1 . 6 ) : marker that replay position corresponds to 1 . 1 . 5 + millis - based id ( see CASSANDRA - 4782 ) 
 - / / ia ( 1 . 2 . 0 ) : column indexes are promoted to the index file . ( this means index offsets are now against the start of the row key , rather than the start of columns data , since the former allows us to skip the row header ) 
 + / / ia ( 1 . 2 . 0 ) : column indexes are promoted to the index file 
 / / records estimated histogram of deletion times in tombstones 
 / / bloom filter ( keys and columns ) upgraded to Murmur3 
 / / ib ( 1 . 2 . 1 ) : tracks min client timestamp in metadata component 
 - / / ic ( 1 . 2 . 6 ) : always promotes row - level tombstones into index file ; previously this was unreliable 
 
 public static final Version CURRENT = new Version ( current _ version ) ; 
 
 @ @ - 84 , 7 + 83 , 6 @ @ public class Descriptor 
 public final boolean hasPartitioner ; 
 public final boolean tracksTombstones ; 
 public final boolean hasPromotedIndexes ; 
 - public final boolean hasPromotedRowTombstones ; 
 public final FilterFactory . Type filterType ; 
 public final boolean hasAncestors ; 
 public final boolean hasBloomFilterSizeInHeader ; 
 @ @ - 104 , 7 + 102 , 6 @ @ public class Descriptor 
 metadataIncludesModernReplayPosition = version . compareTo ( " hf " ) > = 0 ; 
 tracksTombstones = version . compareTo ( " ia " ) > = 0 ; 
 hasPromotedIndexes = version . compareTo ( " ia " ) > = 0 ; 
 - hasPromotedRowTombstones = version . compareTo ( " ic " ) > = 0 ; 
 isLatestVersion = version . compareTo ( current _ version ) = = 0 ; 
 if ( version . compareTo ( " f " ) < 0 ) 
 filterType = FilterFactory . Type . SHA ; 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 index 61f505d . . 21a8673 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 @ @ - 323 , 7 + 323 , 7 @ @ public class SSTableReader extends SSTable 
 { 
 if ( ! components . contains ( Component . FILTER ) ) 
 { 
 - bf = AlwaysPresentFilter . instance ; 
 + bf = new AlwaysPresentFilter ( ) ; 
 return ; 
 } 
 
 diff - - git a / src / java / org / apache / cassandra / utils / AlwaysPresentFilter . java b / src / java / org / apache / cassandra / utils / AlwaysPresentFilter . java 
 index 39b3d5d . . 67ac111 100644 
 - - - a / src / java / org / apache / cassandra / utils / AlwaysPresentFilter . java 
 + + + b / src / java / org / apache / cassandra / utils / AlwaysPresentFilter . java 
 @ @ - 26 , 10 + 26 , 6 @ @ import java . nio . ByteBuffer ; 
 
 public class AlwaysPresentFilter implements IFilter 
 { 
 - public static final AlwaysPresentFilter instance = new AlwaysPresentFilter ( ) ; 
 - 
 - private AlwaysPresentFilter ( ) { } 
 - 
 public boolean isPresent ( ByteBuffer key ) 
 { 
 return true ; 
 diff - - git a / src / java / org / apache / cassandra / utils / FilterFactory . java b / src / java / org / apache / cassandra / utils / FilterFactory . java 
 index 1b9027d . . 88c8973 100644 
 - - - a / src / java / org / apache / cassandra / utils / FilterFactory . java 
 + + + b / src / java / org / apache / cassandra / utils / FilterFactory . java 
 @ @ - 131 , 7 + 131 , 7 @ @ public class FilterFactory 
 { 
 assert maxFalsePosProbability < = 1 . 0 : " Invalid probability " ; 
 if ( maxFalsePosProbability = = 1 . 0 ) 
 - return AlwaysPresentFilter . instance ; 
 + return new AlwaysPresentFilter ( ) ; 
 int bucketsPerElement = BloomCalculations . maxBucketsPerElement ( numElements ) ; 
 BloomCalculations . BloomSpecification spec = BloomCalculations . computeBloomSpec ( bucketsPerElement , maxFalsePosProbability ) ; 
 return createFilter ( spec . K , numElements , spec . bucketsPerElement , type , offheap ) ; 
 diff - - git a / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java b / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java 
 index c531461 . . 1bc846b 100644 
 - - - a / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java 
 + + + b / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java 
 @ @ - 164 , 6 + 164 , 10 @ @ public class RangeTombstoneTest extends SchemaLoader 
 return ByteBufferUtil . bytes ( i ) ; 
 } 
 
 + private static void insertData ( ColumnFamilyStore cfs , String key ) throws Exception 
 + { 
 + } 
 + 
 private static void add ( RowMutation rm , int value , long timestamp ) 
 { 
 rm . add ( new QueryPath ( CFNAME , null , b ( value ) ) , b ( value ) , timestamp ) ;
