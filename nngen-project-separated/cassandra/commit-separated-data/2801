BLEU SCORE: 0.018738883683389617

TEST MSG: clarify yaml comment about commitlog _ periodic _ queue _ size
GENERATED MSG: Fix bad merge

TEST DIFF (one line): diff - - git a / conf / cassandra . yaml b / conf / cassandra . yaml <nl> index 885d28d . . bdbb9ff 100644 <nl> - - - a / conf / cassandra . yaml <nl> + + + b / conf / cassandra . yaml <nl> @ @ - 198 , 9 + 198 , 9 @ @ saved _ caches _ directory : / var / lib / cassandra / saved _ caches <nl> # <nl> # the other option is " periodic " where writes may be acked immediately <nl> # and the CommitLog is simply synced every commitlog _ sync _ period _ in _ ms <nl> - # milliseconds . By default this allows 1024 * ( CPU cores ) pending <nl> - # entries on the commitlog queue . If you are writing very large blobs , <nl> - # you should reduce that ; 16 * cores works reasonably well for 1MB blobs . <nl> + # milliseconds . commitlog _ periodic _ queue _ size allows 1024 * ( CPU cores ) pending <nl> + # entries on the commitlog queue by default . If you are writing very large <nl> + # blobs , you should reduce that ; 16 * cores works reasonably well for 1MB blobs . <nl> # It should be at least as large as the concurrent _ writes setting . <nl> commitlog _ sync : periodic <nl> commitlog _ sync _ period _ in _ ms : 10000
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 3b257ba . . 9dafe3f 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 18 , 6 + 18 , 7 @ @ <nl> * store hints as serialized mutations instead of pointers to data rows <nl> * store hints in the coordinator node instead of in the closest <nl> replica ( CASSANDRA - 2914 ) . <nl> + * add row _ cache _ keys _ to _ save CF option ( CASSANDRA - 1966 ) <nl> <nl> <nl> 0 . 8 . 2 <nl> diff - - git a / interface / cassandra . thrift b / interface / cassandra . thrift <nl> index 14582fb . . 45ef50a 100644 <nl> - - - a / interface / cassandra . thrift <nl> + + + b / interface / cassandra . thrift <nl> @ @ - 46 , 7 + 46 , 7 @ @ namespace rb CassandraThrift <nl> # for every edit that doesn ' t result in a change to major / minor . <nl> # <nl> # See the Semantic Versioning Specification ( SemVer ) http : / / semver . org . <nl> - const string VERSION = " 19 . 10 . 0 " <nl> + const string VERSION = " 19 . 11 . 0 " <nl> <nl> <nl> # <nl> @ @ - 396 , 6 + 396 , 7 @ @ struct CfDef { <nl> 28 : optional binary key _ alias , <nl> 29 : optional string compaction _ strategy , <nl> 30 : optional map < string , string > compaction _ strategy _ options , <nl> + 31 : optional i32 row _ cache _ keys _ to _ save , <nl> } <nl> <nl> / * describes a keyspace . * / <nl> diff - - git a / interface / thrift / gen - java / org / apache / cassandra / thrift / Cassandra . java b / interface / thrift / gen - java / org / apache / cassandra / thrift / Cassandra . java <nl> index bd02789 . . 717370c 100644 <nl> - - - a / interface / thrift / gen - java / org / apache / cassandra / thrift / Cassandra . java <nl> + + + b / interface / thrift / gen - java / org / apache / cassandra / thrift / Cassandra . java <nl> @ @ - 9086 , 6 + 9086 , 8 @ @ public class Cassandra { <nl> <nl> private void readObject ( java . io . ObjectInputStream in ) throws java . io . IOException , ClassNotFoundException { <nl> try { <nl> + / / it doesn ' t seem like you should have to do this , but java serialization is wacky , and doesn ' t call the default constructor . <nl> + _ _ isset _ bit _ vector = new BitSet ( 1 ) ; <nl> read ( new org . apache . thrift . protocol . TCompactProtocol ( new org . apache . thrift . transport . TIOStreamTransport ( in ) ) ) ; <nl> } catch ( org . apache . thrift . TException te ) { <nl> throw new java . io . IOException ( te ) ; <nl> @ @ - 17041 , 8 + 17043 , 6 @ @ public class Cassandra { <nl> <nl> private void readObject ( java . io . ObjectInputStream in ) throws java . io . IOException , ClassNotFoundException { <nl> try { <nl> - / / it doesn ' t seem like you should have to do this , but java serialization is wacky , and doesn ' t call the default constructor . <nl> - _ _ isset _ bit _ vector = new BitSet ( 1 ) ; <nl> read ( new org . apache . thrift . protocol . TCompactProtocol ( new org . apache . thrift . transport . TIOStreamTransport ( in ) ) ) ; <nl> } catch ( org . apache . thrift . TException te ) { <nl> throw new java . io . IOException ( te ) ; <nl> @ @ - 25752 , 6 + 25752 , 8 @ @ public class Cassandra { <nl> <nl> private void readObject ( java . io . ObjectInputStream in ) throws java . io . IOException , ClassNotFoundException { <nl> try { <nl> + / / it doesn ' t seem like you should have to do this , but java serialization is wacky , and doesn ' t call the default constructor . <nl> + _ _ isset _ bit _ vector = new BitSet ( 1 ) ; <nl> read ( new org . apache . thrift . protocol . TCompactProtocol ( new org . apache . thrift . transport . TIOStreamTransport ( in ) ) ) ; <nl> } catch ( org . apache . thrift . TException te ) { <nl> throw new java . io . IOException ( te ) ; <nl> diff - - git a / interface / thrift / gen - java / org / apache / cassandra / thrift / CfDef . java b / interface / thrift / gen - java / org / apache / cassandra / thrift / CfDef . java <nl> index 6b7412e . . 9ab9aa2 100644 <nl> - - - a / interface / thrift / gen - java / org / apache / cassandra / thrift / CfDef . java <nl> + + + b / interface / thrift / gen - java / org / apache / cassandra / thrift / CfDef . java <nl> @ @ - 71 , 6 + 71 , 7 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> private static final org . apache . thrift . protocol . TField KEY _ ALIAS _ FIELD _ DESC = new org . apache . thrift . protocol . TField ( " key _ alias " , org . apache . thrift . protocol . TType . STRING , ( short ) 28 ) ; <nl> private static final org . apache . thrift . protocol . TField COMPACTION _ STRATEGY _ FIELD _ DESC = new org . apache . thrift . protocol . TField ( " compaction _ strategy " , org . apache . thrift . protocol . TType . STRING , ( short ) 29 ) ; <nl> private static final org . apache . thrift . protocol . TField COMPACTION _ STRATEGY _ OPTIONS _ FIELD _ DESC = new org . apache . thrift . protocol . TField ( " compaction _ strategy _ options " , org . apache . thrift . protocol . TType . MAP , ( short ) 30 ) ; <nl> + private static final org . apache . thrift . protocol . TField ROW _ CACHE _ KEYS _ TO _ SAVE _ FIELD _ DESC = new org . apache . thrift . protocol . TField ( " row _ cache _ keys _ to _ save " , org . apache . thrift . protocol . TType . I32 , ( short ) 31 ) ; <nl> <nl> public String keyspace ; <nl> public String name ; <nl> @ @ - 98 , 6 + 99 , 7 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> public ByteBuffer key _ alias ; <nl> public String compaction _ strategy ; <nl> public Map < String , String > compaction _ strategy _ options ; <nl> + public int row _ cache _ keys _ to _ save ; <nl> <nl> / * * The set of fields this struct contains , along with convenience methods for finding and manipulating them . * / <nl> public enum _ Fields implements org . apache . thrift . TFieldIdEnum { <nl> @ @ - 126 , 7 + 128 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> ROW _ CACHE _ PROVIDER ( ( short ) 27 , " row _ cache _ provider " ) , <nl> KEY _ ALIAS ( ( short ) 28 , " key _ alias " ) , <nl> COMPACTION _ STRATEGY ( ( short ) 29 , " compaction _ strategy " ) , <nl> - COMPACTION _ STRATEGY _ OPTIONS ( ( short ) 30 , " compaction _ strategy _ options " ) ; <nl> + COMPACTION _ STRATEGY _ OPTIONS ( ( short ) 30 , " compaction _ strategy _ options " ) , <nl> + ROW _ CACHE _ KEYS _ TO _ SAVE ( ( short ) 31 , " row _ cache _ keys _ to _ save " ) ; <nl> <nl> private static final Map < String , _ Fields > byName = new HashMap < String , _ Fields > ( ) ; <nl> <nl> @ @ - 193 , 6 + 196 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> return COMPACTION _ STRATEGY ; <nl> case 30 : / / COMPACTION _ STRATEGY _ OPTIONS <nl> return COMPACTION _ STRATEGY _ OPTIONS ; <nl> + case 31 : / / ROW _ CACHE _ KEYS _ TO _ SAVE <nl> + return ROW _ CACHE _ KEYS _ TO _ SAVE ; <nl> default : <nl> return null ; <nl> } <nl> @ @ - 246 , 7 + 251 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> private static final int _ _ MEMTABLE _ OPERATIONS _ IN _ MILLIONS _ ISSET _ ID = 10 ; <nl> private static final int _ _ REPLICATE _ ON _ WRITE _ ISSET _ ID = 11 ; <nl> private static final int _ _ MERGE _ SHARDS _ CHANCE _ ISSET _ ID = 12 ; <nl> - private BitSet _ _ isset _ bit _ vector = new BitSet ( 13 ) ; <nl> + private static final int _ _ ROW _ CACHE _ KEYS _ TO _ SAVE _ ISSET _ ID = 13 ; <nl> + private BitSet _ _ isset _ bit _ vector = new BitSet ( 14 ) ; <nl> <nl> public static final Map < _ Fields , org . apache . thrift . meta _ data . FieldMetaData > metaDataMap ; <nl> static { <nl> @ @ - 306 , 6 + 312 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> new org . apache . thrift . meta _ data . MapMetaData ( org . apache . thrift . protocol . TType . MAP , <nl> new org . apache . thrift . meta _ data . FieldValueMetaData ( org . apache . thrift . protocol . TType . STRING ) , <nl> new org . apache . thrift . meta _ data . FieldValueMetaData ( org . apache . thrift . protocol . TType . STRING ) ) ) ) ; <nl> + tmpMap . put ( _ Fields . ROW _ CACHE _ KEYS _ TO _ SAVE , new org . apache . thrift . meta _ data . FieldMetaData ( " row _ cache _ keys _ to _ save " , org . apache . thrift . TFieldRequirementType . OPTIONAL , <nl> + new org . apache . thrift . meta _ data . FieldValueMetaData ( org . apache . thrift . protocol . TType . I32 ) ) ) ; <nl> metaDataMap = Collections . unmodifiableMap ( tmpMap ) ; <nl> org . apache . thrift . meta _ data . FieldMetaData . addStructMetaDataMap ( CfDef . class , metaDataMap ) ; <nl> } <nl> @ @ - 409 , 6 + 417 , 7 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> } <nl> this . compaction _ strategy _ options = _ _ this _ _ compaction _ strategy _ options ; <nl> } <nl> + this . row _ cache _ keys _ to _ save = other . row _ cache _ keys _ to _ save ; <nl> } <nl> <nl> public CfDef deepCopy ( ) { <nl> @ @ - 459 , 6 + 468 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> this . key _ alias = null ; <nl> this . compaction _ strategy = null ; <nl> this . compaction _ strategy _ options = null ; <nl> + setRow _ cache _ keys _ to _ saveIsSet ( false ) ; <nl> + this . row _ cache _ keys _ to _ save = 0 ; <nl> } <nl> <nl> public String getKeyspace ( ) { <nl> @ @ - 1108 , 6 + 1119 , 29 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> } <nl> } <nl> <nl> + public int getRow _ cache _ keys _ to _ save ( ) { <nl> + return this . row _ cache _ keys _ to _ save ; <nl> + } <nl> + <nl> + public CfDef setRow _ cache _ keys _ to _ save ( int row _ cache _ keys _ to _ save ) { <nl> + this . row _ cache _ keys _ to _ save = row _ cache _ keys _ to _ save ; <nl> + setRow _ cache _ keys _ to _ saveIsSet ( true ) ; <nl> + return this ; <nl> + } <nl> + <nl> + public void unsetRow _ cache _ keys _ to _ save ( ) { <nl> + _ _ isset _ bit _ vector . clear ( _ _ ROW _ CACHE _ KEYS _ TO _ SAVE _ ISSET _ ID ) ; <nl> + } <nl> + <nl> + / * * Returns true if field row _ cache _ keys _ to _ save is set ( has been assigned a value ) and false otherwise * / <nl> + public boolean isSetRow _ cache _ keys _ to _ save ( ) { <nl> + return _ _ isset _ bit _ vector . get ( _ _ ROW _ CACHE _ KEYS _ TO _ SAVE _ ISSET _ ID ) ; <nl> + } <nl> + <nl> + public void setRow _ cache _ keys _ to _ saveIsSet ( boolean value ) { <nl> + _ _ isset _ bit _ vector . set ( _ _ ROW _ CACHE _ KEYS _ TO _ SAVE _ ISSET _ ID , value ) ; <nl> + } <nl> + <nl> public void setFieldValue ( _ Fields field , Object value ) { <nl> switch ( field ) { <nl> case KEYSPACE : <nl> @ @ - 1318 , 6 + 1352 , 14 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> } <nl> break ; <nl> <nl> + case ROW _ CACHE _ KEYS _ TO _ SAVE : <nl> + if ( value = = null ) { <nl> + unsetRow _ cache _ keys _ to _ save ( ) ; <nl> + } else { <nl> + setRow _ cache _ keys _ to _ save ( ( Integer ) value ) ; <nl> + } <nl> + break ; <nl> + <nl> } <nl> } <nl> <nl> @ @ - 1401 , 6 + 1443 , 9 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> case COMPACTION _ STRATEGY _ OPTIONS : <nl> return getCompaction _ strategy _ options ( ) ; <nl> <nl> + case ROW _ CACHE _ KEYS _ TO _ SAVE : <nl> + return new Integer ( getRow _ cache _ keys _ to _ save ( ) ) ; <nl> + <nl> } <nl> throw new IllegalStateException ( ) ; <nl> } <nl> @ @ - 1464 , 6 + 1509 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> return isSetCompaction _ strategy ( ) ; <nl> case COMPACTION _ STRATEGY _ OPTIONS : <nl> return isSetCompaction _ strategy _ options ( ) ; <nl> + case ROW _ CACHE _ KEYS _ TO _ SAVE : <nl> + return isSetRow _ cache _ keys _ to _ save ( ) ; <nl> } <nl> throw new IllegalStateException ( ) ; <nl> } <nl> @ @ - 1715 , 6 + 1762 , 15 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> return false ; <nl> } <nl> <nl> + boolean this _ present _ row _ cache _ keys _ to _ save = true & & this . isSetRow _ cache _ keys _ to _ save ( ) ; <nl> + boolean that _ present _ row _ cache _ keys _ to _ save = true & & that . isSetRow _ cache _ keys _ to _ save ( ) ; <nl> + if ( this _ present _ row _ cache _ keys _ to _ save | | that _ present _ row _ cache _ keys _ to _ save ) { <nl> + if ( ! ( this _ present _ row _ cache _ keys _ to _ save & & that _ present _ row _ cache _ keys _ to _ save ) ) <nl> + return false ; <nl> + if ( this . row _ cache _ keys _ to _ save ! = that . row _ cache _ keys _ to _ save ) <nl> + return false ; <nl> + } <nl> + <nl> return true ; <nl> } <nl> <nl> @ @ - 1852 , 6 + 1908 , 11 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> if ( present _ compaction _ strategy _ options ) <nl> builder . append ( compaction _ strategy _ options ) ; <nl> <nl> + boolean present _ row _ cache _ keys _ to _ save = true & & ( isSetRow _ cache _ keys _ to _ save ( ) ) ; <nl> + builder . append ( present _ row _ cache _ keys _ to _ save ) ; <nl> + if ( present _ row _ cache _ keys _ to _ save ) <nl> + builder . append ( row _ cache _ keys _ to _ save ) ; <nl> + <nl> return builder . toHashCode ( ) ; <nl> } <nl> <nl> @ @ - 2123 , 6 + 2184 , 16 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> return lastComparison ; <nl> } <nl> } <nl> + lastComparison = Boolean . valueOf ( isSetRow _ cache _ keys _ to _ save ( ) ) . compareTo ( typedOther . isSetRow _ cache _ keys _ to _ save ( ) ) ; <nl> + if ( lastComparison ! = 0 ) { <nl> + return lastComparison ; <nl> + } <nl> + if ( isSetRow _ cache _ keys _ to _ save ( ) ) { <nl> + lastComparison = org . apache . thrift . TBaseHelper . compareTo ( this . row _ cache _ keys _ to _ save , typedOther . row _ cache _ keys _ to _ save ) ; <nl> + if ( lastComparison ! = 0 ) { <nl> + return lastComparison ; <nl> + } <nl> + } <nl> return 0 ; <nl> } <nl> <nl> @ @ - 2358 , 6 + 2429 , 14 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , field . type ) ; <nl> } <nl> break ; <nl> + case 31 : / / ROW _ CACHE _ KEYS _ TO _ SAVE <nl> + if ( field . type = = org . apache . thrift . protocol . TType . I32 ) { <nl> + this . row _ cache _ keys _ to _ save = iprot . readI32 ( ) ; <nl> + setRow _ cache _ keys _ to _ saveIsSet ( true ) ; <nl> + } else { <nl> + org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , field . type ) ; <nl> + } <nl> + break ; <nl> default : <nl> org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , field . type ) ; <nl> } <nl> @ @ - 2540 , 6 + 2619 , 11 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> oprot . writeFieldEnd ( ) ; <nl> } <nl> } <nl> + if ( isSetRow _ cache _ keys _ to _ save ( ) ) { <nl> + oprot . writeFieldBegin ( ROW _ CACHE _ KEYS _ TO _ SAVE _ FIELD _ DESC ) ; <nl> + oprot . writeI32 ( this . row _ cache _ keys _ to _ save ) ; <nl> + oprot . writeFieldEnd ( ) ; <nl> + } <nl> oprot . writeFieldStop ( ) ; <nl> oprot . writeStructEnd ( ) ; <nl> } <nl> @ @ - 2752 , 6 + 2836 , 12 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav <nl> } <nl> first = false ; <nl> } <nl> + if ( isSetRow _ cache _ keys _ to _ save ( ) ) { <nl> + if ( ! first ) sb . append ( " , " ) ; <nl> + sb . append ( " row _ cache _ keys _ to _ save : " ) ; <nl> + sb . append ( this . row _ cache _ keys _ to _ save ) ; <nl> + first = false ; <nl> + } <nl> sb . append ( " ) " ) ; <nl> return sb . toString ( ) ; <nl> } <nl> diff - - git a / interface / thrift / gen - java / org / apache / cassandra / thrift / Constants . java b / interface / thrift / gen - java / org / apache / cassandra / thrift / Constants . java <nl> index e589e2e . . 6bac7b0 100644 <nl> - - - a / interface / thrift / gen - java / org / apache / cassandra / thrift / Constants . java <nl> + + + b / interface / thrift / gen - java / org / apache / cassandra / thrift / Constants . java <nl> @ @ - 44 , 6 + 44 , 6 @ @ import org . slf4j . LoggerFactory ; <nl> <nl> public class Constants { <nl> <nl> - public static final String VERSION = " 19 . 10 . 0 " ; <nl> + public static final String VERSION = " 19 . 11 . 0 " ; <nl> <nl> } <nl> diff - - git a / src / avro / internode . genavro b / src / avro / internode . genavro <nl> index ad103be . . c1bd9e5 100644 <nl> - - - a / src / avro / internode . genavro <nl> + + + b / src / avro / internode . genavro <nl> @ @ - 57 , 6 + 57 , 7 @ @ protocol InterNode { <nl> union { null , int } max _ compaction _ threshold = null ; <nl> union { int , null } row _ cache _ save _ period _ in _ seconds = 0 ; <nl> union { int , null } key _ cache _ save _ period _ in _ seconds = 3600 ; <nl> + union { int , null } row _ cache _ keys _ to _ save = null ; <nl> union { null , int } memtable _ throughput _ in _ mb = null ; <nl> union { null , double } memtable _ operations _ in _ millions = null ; <nl> union { null , double } merge _ shards _ chance = null ; <nl> diff - - git a / src / java / org / apache / cassandra / cache / AutoSavingCache . java b / src / java / org / apache / cassandra / cache / AutoSavingCache . java <nl> index 0e4ea0c . . e5df049 100644 <nl> - - - a / src / java / org / apache / cassandra / cache / AutoSavingCache . java <nl> + + + b / src / java / org / apache / cassandra / cache / AutoSavingCache . java <nl> @ @ - 77 , 12 + 77 , 12 @ @ public abstract class AutoSavingCache < K , V > extends InstrumentingCache < K , V > <nl> return DatabaseDescriptor . getSerializedCachePath ( tableName , cfName , cacheType ) ; <nl> } <nl> <nl> - public Writer getWriter ( ) <nl> + public Writer getWriter ( int keysToSave ) <nl> { <nl> - return new Writer ( tableName , cfName ) ; <nl> + return new Writer ( tableName , cfName , keysToSave ) ; <nl> } <nl> <nl> - public void scheduleSaving ( int savePeriodInSeconds ) <nl> + public void scheduleSaving ( int savePeriodInSeconds , final int keysToSave ) <nl> { <nl> if ( saveTask ! = null ) <nl> { <nl> @ @ - 95 , 7 + 95 , 7 @ @ public abstract class AutoSavingCache < K , V > extends InstrumentingCache < K , V > <nl> { <nl> public void runMayThrow ( ) <nl> { <nl> - submitWrite ( ) ; <nl> + submitWrite ( keysToSave ) ; <nl> } <nl> } ; <nl> saveTask = StorageService . tasks . scheduleWithFixedDelay ( runnable , <nl> @ @ - 105 , 9 + 105 , 9 @ @ public abstract class AutoSavingCache < K , V > extends InstrumentingCache < K , V > <nl> } <nl> } <nl> <nl> - public Future < ? > submitWrite ( ) <nl> + public Future < ? > submitWrite ( int keysToSave ) <nl> { <nl> - return CompactionManager . instance . submitCacheWrite ( getWriter ( ) ) ; <nl> + return CompactionManager . instance . submitCacheWrite ( getWriter ( keysToSave ) ) ; <nl> } <nl> <nl> public Set < DecoratedKey > readSaved ( ) <nl> @ @ - 195 , 9 + 195 , 12 @ @ public abstract class AutoSavingCache < K , V > extends InstrumentingCache < K , V > <nl> private final long estimatedTotalBytes ; <nl> private long bytesWritten ; <nl> <nl> - private Writer ( String ksname , String cfname ) <nl> + private Writer ( String ksname , String cfname , int keysToSave ) <nl> { <nl> - keys = getKeySet ( ) ; <nl> + if ( keysToSave > = getKeySet ( ) . size ( ) ) <nl> + keys = getKeySet ( ) ; <nl> + else <nl> + keys = hotKeySet ( keysToSave ) ; <nl> long bytes = 0 ; <nl> for ( K key : keys ) <nl> bytes + = translateKey ( key ) . remaining ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / cache / ConcurrentLinkedHashCache . java b / src / java / org / apache / cassandra / cache / ConcurrentLinkedHashCache . java <nl> index 34b136d . . ed44028 100644 <nl> - - - a / src / java / org / apache / cassandra / cache / ConcurrentLinkedHashCache . java <nl> + + + b / src / java / org / apache / cassandra / cache / ConcurrentLinkedHashCache . java <nl> @ @ - 96 , 6 + 96 , 11 @ @ public class ConcurrentLinkedHashCache < K , V > implements ICache < K , V > <nl> return map . keySet ( ) ; <nl> } <nl> <nl> + public Set < K > hotKeySet ( int n ) <nl> + { <nl> + return map . descendingKeySetWithLimit ( n ) ; <nl> + } <nl> + <nl> public boolean isPutCopying ( ) <nl> { <nl> return false ; <nl> diff - - git a / src / java / org / apache / cassandra / cache / ICache . java b / src / java / org / apache / cassandra / cache / ICache . java <nl> index 0eebdb4 . . deac174 100644 <nl> - - - a / src / java / org / apache / cassandra / cache / ICache . java <nl> + + + b / src / java / org / apache / cassandra / cache / ICache . java <nl> @ @ - 46 , 6 + 46 , 8 @ @ public interface ICache < K , V > <nl> <nl> public Set < K > keySet ( ) ; <nl> <nl> + public Set < K > hotKeySet ( int n ) ; <nl> + <nl> / * * <nl> * @ return true if the cache implementation inherently copies the cached values ; otherwise , <nl> * the caller should copy manually before caching shared values like Thrift ByteBuffers . <nl> diff - - git a / src / java / org / apache / cassandra / cache / InstrumentingCache . java b / src / java / org / apache / cassandra / cache / InstrumentingCache . java <nl> index 7c77f9f . . f622c55 100644 <nl> - - - a / src / java / org / apache / cassandra / cache / InstrumentingCache . java <nl> + + + b / src / java / org / apache / cassandra / cache / InstrumentingCache . java <nl> @ @ - 150 , 6 + 150 , 11 @ @ public class InstrumentingCache < K , V > implements InstrumentingCacheMBean <nl> return map . keySet ( ) ; <nl> } <nl> <nl> + public Set < K > hotKeySet ( int n ) <nl> + { <nl> + return map . hotKeySet ( n ) ; <nl> + } <nl> + <nl> public boolean isPutCopying ( ) <nl> { <nl> return map . isPutCopying ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / cache / SerializingCache . java b / src / java / org / apache / cassandra / cache / SerializingCache . java <nl> index bac6534 . . a505480 100644 <nl> - - - a / src / java / org / apache / cassandra / cache / SerializingCache . java <nl> + + + b / src / java / org / apache / cassandra / cache / SerializingCache . java <nl> @ @ - 163 , 6 + 163 , 11 @ @ public class SerializingCache < K , V > implements ICache < K , V > <nl> return map . keySet ( ) ; <nl> } <nl> <nl> + public Set < K > hotKeySet ( int n ) <nl> + { <nl> + return map . descendingKeySetWithLimit ( n ) ; <nl> + } <nl> + <nl> public boolean isPutCopying ( ) <nl> { <nl> return true ; <nl> diff - - git a / src / java / org / apache / cassandra / cli / CliClient . java b / src / java / org / apache / cassandra / cli / CliClient . java <nl> index 878bf74 . . 6e9ad23 100644 <nl> - - - a / src / java / org / apache / cassandra / cli / CliClient . java <nl> + + + b / src / java / org / apache / cassandra / cli / CliClient . java <nl> @ @ - 119 , 6 + 119 , 7 @ @ public class CliClient <nl> COMMENT , <nl> ROWS _ CACHED , <nl> ROW _ CACHE _ SAVE _ PERIOD , <nl> + ROW _ CACHE _ KEYS _ TO _ SAVE , <nl> KEYS _ CACHED , <nl> KEY _ CACHE _ SAVE _ PERIOD , <nl> READ _ REPAIR _ CHANCE , <nl> @ @ - 1231 , 6 + 1232 , 9 @ @ public class CliClient <nl> case KEY _ CACHE _ SAVE _ PERIOD : <nl> cfDef . setKey _ cache _ save _ period _ in _ seconds ( Integer . parseInt ( mValue ) ) ; <nl> break ; <nl> + case ROW _ CACHE _ KEYS _ TO _ SAVE : <nl> + cfDef . setRow _ cache _ keys _ to _ save ( Integer . parseInt ( mValue ) ) ; <nl> + break ; <nl> case DEFAULT _ VALIDATION _ CLASS : <nl> cfDef . setDefault _ validation _ class ( CliUtils . unescapeSQLString ( mValue ) ) ; <nl> break ; <nl> @ @ - 1716 , 7 + 1720 , 9 @ @ public class CliClient <nl> if ( cf _ def . default _ validation _ class ! = null ) <nl> sessionState . out . printf ( " Default column value validator : % s % n " , cf _ def . default _ validation _ class ) ; <nl> sessionState . out . printf ( " Columns sorted by : % s % s % n " , cf _ def . comparator _ type , cf _ def . column _ type . equals ( " Super " ) ? " / " + cf _ def . subcomparator _ type : " " ) ; <nl> - sessionState . out . printf ( " Row cache size / save period in seconds : % s / % s % n " , cf _ def . row _ cache _ size , cf _ def . row _ cache _ save _ period _ in _ seconds ) ; <nl> + sessionState . out . printf ( " Row cache size / save period in seconds / keys to save : % s / % s / % s % n " , <nl> + cf _ def . row _ cache _ size , cf _ def . row _ cache _ save _ period _ in _ seconds , <nl> + cf _ def . row _ cache _ keys _ to _ save = = Integer . MAX _ VALUE ? " all " : cf _ def . row _ cache _ keys _ to _ save ) ; <nl> sessionState . out . printf ( " Key cache size / save period in seconds : % s / % s % n " , cf _ def . key _ cache _ size , cf _ def . key _ cache _ save _ period _ in _ seconds ) ; <nl> sessionState . out . printf ( " Memtable thresholds : % s / % s ( millions of ops / MB ) % n " , <nl> cf _ def . memtable _ operations _ in _ millions , cf _ def . memtable _ throughput _ in _ mb ) ; <nl> diff - - git a / src / java / org / apache / cassandra / config / CFMetaData . java b / src / java / org / apache / cassandra / config / CFMetaData . java <nl> index 0284c5b . . 5283f65 100644 <nl> - - - a / src / java / org / apache / cassandra / config / CFMetaData . java <nl> + + + b / src / java / org / apache / cassandra / config / CFMetaData . java <nl> @ @ - 70 , 6 + 70 , 7 @ @ public final class CFMetaData <nl> public final static int DEFAULT _ SYSTEM _ MEMTABLE _ THROUGHPUT _ IN _ MB = 8 ; <nl> public final static int DEFAULT _ ROW _ CACHE _ SAVE _ PERIOD _ IN _ SECONDS = 0 ; <nl> public final static int DEFAULT _ KEY _ CACHE _ SAVE _ PERIOD _ IN _ SECONDS = 4 * 3600 ; <nl> + public final static int DEFAULT _ ROW _ CACHE _ KEYS _ TO _ SAVE = Integer . MAX _ VALUE ; <nl> public final static int DEFAULT _ GC _ GRACE _ SECONDS = 864000 ; <nl> public final static int DEFAULT _ MIN _ COMPACTION _ THRESHOLD = 4 ; <nl> public final static int DEFAULT _ MAX _ COMPACTION _ THRESHOLD = 32 ; <nl> @ @ - 164 , 6 + 165 , 7 @ @ public final class CFMetaData <nl> private int maxCompactionThreshold ; / / default 32 <nl> private int rowCacheSavePeriodInSeconds ; / / default 0 ( off ) <nl> private int keyCacheSavePeriodInSeconds ; / / default 3600 ( 1 hour ) <nl> + private int rowCacheKeysToSave ; / / default max int ( aka feature is off ) <nl> private int memtableThroughputInMb ; / / default based on heap size <nl> private double memtableOperationsInMillions ; / / default based on throughput <nl> private double mergeShardsChance ; / / default 0 . 1 , chance [ 0 . 0 , 1 . 0 ] of merging old shards during replication <nl> @ @ - 186 , 6 + 188 , 7 @ @ public final class CFMetaData <nl> public CFMetaData maxCompactionThreshold ( int prop ) { maxCompactionThreshold = prop ; return this ; } <nl> public CFMetaData rowCacheSavePeriod ( int prop ) { rowCacheSavePeriodInSeconds = prop ; return this ; } <nl> public CFMetaData keyCacheSavePeriod ( int prop ) { keyCacheSavePeriodInSeconds = prop ; return this ; } <nl> + public CFMetaData rowCacheKeysToSave ( int prop ) { rowCacheKeysToSave = prop ; return this ; } <nl> public CFMetaData memSize ( int prop ) { memtableThroughputInMb = prop ; return this ; } <nl> public CFMetaData memOps ( double prop ) { memtableOperationsInMillions = prop ; return this ; } <nl> public CFMetaData mergeShardsChance ( double prop ) { mergeShardsChance = prop ; return this ; } <nl> @ @ - 231 , 6 + 234 , 7 @ @ public final class CFMetaData <nl> / / Set a bunch of defaults <nl> rowCacheSize = DEFAULT _ ROW _ CACHE _ SIZE ; <nl> keyCacheSize = DEFAULT _ KEY _ CACHE _ SIZE ; <nl> + rowCacheKeysToSave = DEFAULT _ ROW _ CACHE _ KEYS _ TO _ SAVE ; <nl> readRepairChance = DEFAULT _ READ _ REPAIR _ CHANCE ; <nl> replicateOnWrite = DEFAULT _ REPLICATE _ ON _ WRITE ; <nl> gcGraceSeconds = DEFAULT _ GC _ GRACE _ SECONDS ; <nl> @ @ - 319 , 6 + 323 , 7 @ @ public final class CFMetaData <nl> . maxCompactionThreshold ( oldCFMD . maxCompactionThreshold ) <nl> . rowCacheSavePeriod ( oldCFMD . rowCacheSavePeriodInSeconds ) <nl> . keyCacheSavePeriod ( oldCFMD . keyCacheSavePeriodInSeconds ) <nl> + . rowCacheKeysToSave ( oldCFMD . rowCacheKeysToSave ) <nl> . memSize ( oldCFMD . memtableThroughputInMb ) <nl> . memOps ( oldCFMD . memtableOperationsInMillions ) <nl> . columnMetadata ( oldCFMD . column _ metadata ) <nl> @ @ - 368 , 6 + 373 , 7 @ @ public final class CFMetaData <nl> cf . max _ compaction _ threshold = maxCompactionThreshold ; <nl> cf . row _ cache _ save _ period _ in _ seconds = rowCacheSavePeriodInSeconds ; <nl> cf . key _ cache _ save _ period _ in _ seconds = keyCacheSavePeriodInSeconds ; <nl> + cf . row _ cache _ keys _ to _ save = rowCacheKeysToSave ; <nl> cf . memtable _ throughput _ in _ mb = memtableThroughputInMb ; <nl> cf . memtable _ operations _ in _ millions = memtableOperationsInMillions ; <nl> cf . merge _ shards _ chance = mergeShardsChance ; <nl> @ @ - 430 , 6 + 436 , 7 @ @ public final class CFMetaData <nl> if ( cf . max _ compaction _ threshold ! = null ) { newCFMD . maxCompactionThreshold ( cf . max _ compaction _ threshold ) ; } <nl> if ( cf . row _ cache _ save _ period _ in _ seconds ! = null ) { newCFMD . rowCacheSavePeriod ( cf . row _ cache _ save _ period _ in _ seconds ) ; } <nl> if ( cf . key _ cache _ save _ period _ in _ seconds ! = null ) { newCFMD . keyCacheSavePeriod ( cf . key _ cache _ save _ period _ in _ seconds ) ; } <nl> + if ( cf . row _ cache _ keys _ to _ save ! = null ) { newCFMD . rowCacheKeysToSave ( cf . row _ cache _ keys _ to _ save ) ; } <nl> if ( cf . memtable _ throughput _ in _ mb ! = null ) { newCFMD . memSize ( cf . memtable _ throughput _ in _ mb ) ; } <nl> if ( cf . memtable _ operations _ in _ millions ! = null ) { newCFMD . memOps ( cf . memtable _ operations _ in _ millions ) ; } <nl> if ( cf . merge _ shards _ chance ! = null ) { newCFMD . mergeShardsChance ( cf . merge _ shards _ chance ) ; } <nl> @ @ - 538 , 6 + 545 , 11 @ @ public final class CFMetaData <nl> return keyCacheSavePeriodInSeconds ; <nl> } <nl> <nl> + public int getRowCacheKeysToSave ( ) <nl> + { <nl> + return rowCacheKeysToSave ; <nl> + } <nl> + <nl> public int getMemtableThroughputInMb ( ) <nl> { <nl> return memtableThroughputInMb ; <nl> @ @ - 600 , 6 + 612 , 7 @ @ public final class CFMetaData <nl> . append ( column _ metadata , rhs . column _ metadata ) <nl> . append ( rowCacheSavePeriodInSeconds , rhs . rowCacheSavePeriodInSeconds ) <nl> . append ( keyCacheSavePeriodInSeconds , rhs . keyCacheSavePeriodInSeconds ) <nl> + . append ( rowCacheKeysToSave , rhs . rowCacheKeysToSave ) <nl> . append ( memtableThroughputInMb , rhs . memtableThroughputInMb ) <nl> . append ( memtableOperationsInMillions , rhs . memtableOperationsInMillions ) <nl> . append ( mergeShardsChance , rhs . mergeShardsChance ) <nl> @ @ - 631 , 6 + 644 , 7 @ @ public final class CFMetaData <nl> . append ( column _ metadata ) <nl> . append ( rowCacheSavePeriodInSeconds ) <nl> . append ( keyCacheSavePeriodInSeconds ) <nl> + . append ( rowCacheKeysToSave ) <nl> . append ( memtableThroughputInMb ) <nl> . append ( memtableOperationsInMillions ) <nl> . append ( mergeShardsChance ) <nl> @ @ - 669 , 6 + 683 , 8 @ @ public final class CFMetaData <nl> cf _ def . setRow _ cache _ save _ period _ in _ seconds ( CFMetaData . DEFAULT _ ROW _ CACHE _ SAVE _ PERIOD _ IN _ SECONDS ) ; <nl> if ( ! cf _ def . isSetKey _ cache _ save _ period _ in _ seconds ( ) ) <nl> cf _ def . setKey _ cache _ save _ period _ in _ seconds ( CFMetaData . DEFAULT _ KEY _ CACHE _ SAVE _ PERIOD _ IN _ SECONDS ) ; <nl> + if ( ! cf _ def . isSetRow _ cache _ keys _ to _ save ( ) ) <nl> + cf _ def . setRow _ cache _ keys _ to _ save ( CFMetaData . DEFAULT _ ROW _ CACHE _ KEYS _ TO _ SAVE ) ; <nl> if ( ! cf _ def . isSetMemtable _ throughput _ in _ mb ( ) ) <nl> cf _ def . setMemtable _ throughput _ in _ mb ( CFMetaData . DEFAULT _ MEMTABLE _ THROUGHPUT _ IN _ MB ) ; <nl> if ( ! cf _ def . isSetMemtable _ operations _ in _ millions ( ) ) <nl> @ @ - 704 , 6 + 720 , 7 @ @ public final class CFMetaData <nl> if ( cf _ def . isSetMax _ compaction _ threshold ( ) ) { newCFMD . maxCompactionThreshold ( cf _ def . max _ compaction _ threshold ) ; } <nl> if ( cf _ def . isSetRow _ cache _ save _ period _ in _ seconds ( ) ) { newCFMD . rowCacheSavePeriod ( cf _ def . row _ cache _ save _ period _ in _ seconds ) ; } <nl> if ( cf _ def . isSetKey _ cache _ save _ period _ in _ seconds ( ) ) { newCFMD . keyCacheSavePeriod ( cf _ def . key _ cache _ save _ period _ in _ seconds ) ; } <nl> + if ( cf _ def . isSetRow _ cache _ keys _ to _ save ( ) ) { newCFMD . rowCacheKeysToSave ( cf _ def . row _ cache _ keys _ to _ save ) ; } <nl> if ( cf _ def . isSetMemtable _ throughput _ in _ mb ( ) ) { newCFMD . memSize ( cf _ def . memtable _ throughput _ in _ mb ) ; } <nl> if ( cf _ def . isSetMemtable _ operations _ in _ millions ( ) ) { newCFMD . memOps ( cf _ def . memtable _ operations _ in _ millions ) ; } <nl> if ( cf _ def . isSetMerge _ shards _ chance ( ) ) { newCFMD . mergeShardsChance ( cf _ def . merge _ shards _ chance ) ; } <nl> @ @ - 776 , 6 + 793 , 7 @ @ public final class CFMetaData <nl> maxCompactionThreshold = cf _ def . max _ compaction _ threshold ; <nl> rowCacheSavePeriodInSeconds = cf _ def . row _ cache _ save _ period _ in _ seconds ; <nl> keyCacheSavePeriodInSeconds = cf _ def . key _ cache _ save _ period _ in _ seconds ; <nl> + rowCacheKeysToSave = cf _ def . row _ cache _ keys _ to _ save ; <nl> memtableThroughputInMb = cf _ def . memtable _ throughput _ in _ mb ; <nl> memtableOperationsInMillions = cf _ def . memtable _ operations _ in _ millions ; <nl> mergeShardsChance = cf _ def . merge _ shards _ chance ; <nl> @ @ - 895 , 6 + 913 , 7 @ @ public final class CFMetaData <nl> def . setMax _ compaction _ threshold ( cfm . maxCompactionThreshold ) ; <nl> def . setRow _ cache _ save _ period _ in _ seconds ( cfm . rowCacheSavePeriodInSeconds ) ; <nl> def . setKey _ cache _ save _ period _ in _ seconds ( cfm . keyCacheSavePeriodInSeconds ) ; <nl> + def . setRow _ cache _ keys _ to _ save ( cfm . rowCacheKeysToSave ) ; <nl> def . setMemtable _ throughput _ in _ mb ( cfm . memtableThroughputInMb ) ; <nl> def . setMemtable _ operations _ in _ millions ( cfm . memtableOperationsInMillions ) ; <nl> def . setMerge _ shards _ chance ( cfm . mergeShardsChance ) ; <nl> @ @ - 941 , 6 + 960 , 7 @ @ public final class CFMetaData <nl> def . max _ compaction _ threshold = cfm . maxCompactionThreshold ; <nl> def . row _ cache _ save _ period _ in _ seconds = cfm . rowCacheSavePeriodInSeconds ; <nl> def . key _ cache _ save _ period _ in _ seconds = cfm . keyCacheSavePeriodInSeconds ; <nl> + def . row _ cache _ keys _ to _ save = cfm . rowCacheKeysToSave ; <nl> def . memtable _ throughput _ in _ mb = cfm . memtableThroughputInMb ; <nl> def . memtable _ operations _ in _ millions = cfm . memtableOperationsInMillions ; <nl> def . merge _ shards _ chance = cfm . mergeShardsChance ; <nl> @ @ - 986 , 6 + 1006 , 7 @ @ public final class CFMetaData <nl> newDef . read _ repair _ chance = def . getRead _ repair _ chance ( ) ; <nl> newDef . replicate _ on _ write = def . isReplicate _ on _ write ( ) ; <nl> newDef . row _ cache _ save _ period _ in _ seconds = def . getRow _ cache _ save _ period _ in _ seconds ( ) ; <nl> + newDef . row _ cache _ keys _ to _ save = def . getRow _ cache _ keys _ to _ save ( ) ; <nl> newDef . row _ cache _ size = def . getRow _ cache _ size ( ) ; <nl> newDef . subcomparator _ type = def . getSubcomparator _ type ( ) ; <nl> newDef . merge _ shards _ chance = def . getMerge _ shards _ chance ( ) ; <nl> @ @ - 1120 , 6 + 1141 , 7 @ @ public final class CFMetaData <nl> . append ( " maxCompactionThreshold " , maxCompactionThreshold ) <nl> . append ( " rowCacheSavePeriodInSeconds " , rowCacheSavePeriodInSeconds ) <nl> . append ( " keyCacheSavePeriodInSeconds " , keyCacheSavePeriodInSeconds ) <nl> + . append ( " rowCacheKeysToSave " , rowCacheKeysToSave ) <nl> . append ( " memtableThroughputInMb " , memtableThroughputInMb ) <nl> . append ( " memtableOperationsInMillions " , memtableOperationsInMillions ) <nl> . append ( " mergeShardsChance " , mergeShardsChance ) <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index 6d932d8 . . 69e2c4b 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 142 , 6 + 142 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> private volatile DefaultDouble memops ; <nl> private volatile DefaultInteger rowCacheSaveInSeconds ; <nl> private volatile DefaultInteger keyCacheSaveInSeconds ; <nl> + private volatile DefaultInteger rowCacheKeysToSave ; <nl> <nl> / * * Lock to allow migrations to block all flushing , so we can be sure not to write orphaned data files * / <nl> public final Lock flushLock = new ReentrantLock ( ) ; <nl> @ @ - 195 , 11 + 196 , 13 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> rowCacheSaveInSeconds = new DefaultInteger ( metadata . getRowCacheSavePeriodInSeconds ( ) ) ; <nl> if ( ! keyCacheSaveInSeconds . isModified ( ) ) <nl> keyCacheSaveInSeconds = new DefaultInteger ( metadata . getKeyCacheSavePeriodInSeconds ( ) ) ; <nl> + if ( ! rowCacheKeysToSave . isModified ( ) ) <nl> + rowCacheKeysToSave = new DefaultInteger ( metadata . getRowCacheKeysToSave ( ) ) ; <nl> <nl> compactionStrategy = metadata . createCompactionStrategyInstance ( this ) ; <nl> <nl> updateCacheSizes ( ) ; <nl> - scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) ) ; <nl> + scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) , rowCacheKeysToSave . value ( ) ) ; <nl> <nl> / / figure out what needs to be added and dropped . <nl> / / future : if / when we have modifiable settings for secondary indexes , they ' ll need to be handled here . <nl> @ @ - 241 , 6 + 244 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> this . memops = new DefaultDouble ( metadata . getMemtableOperationsInMillions ( ) ) ; <nl> this . rowCacheSaveInSeconds = new DefaultInteger ( metadata . getRowCacheSavePeriodInSeconds ( ) ) ; <nl> this . keyCacheSaveInSeconds = new DefaultInteger ( metadata . getKeyCacheSavePeriodInSeconds ( ) ) ; <nl> + this . rowCacheKeysToSave = new DefaultInteger ( metadata . getRowCacheKeysToSave ( ) ) ; <nl> this . partitioner = partitioner ; <nl> fileIndexGenerator . set ( generation ) ; <nl> <nl> @ @ - 542 , 13 + 546 , 13 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> table . name , <nl> columnFamily ) ) ; <nl> <nl> - scheduleCacheSaving ( metadata . getRowCacheSavePeriodInSeconds ( ) , metadata . getKeyCacheSavePeriodInSeconds ( ) ) ; <nl> + scheduleCacheSaving ( metadata . getRowCacheSavePeriodInSeconds ( ) , metadata . getKeyCacheSavePeriodInSeconds ( ) , metadata . getRowCacheKeysToSave ( ) ) ; <nl> } <nl> <nl> - public void scheduleCacheSaving ( int rowCacheSavePeriodInSeconds , int keyCacheSavePeriodInSeconds ) <nl> + public void scheduleCacheSaving ( int rowCacheSavePeriodInSeconds , int keyCacheSavePeriodInSeconds , int rowCacheKeysToSave ) <nl> { <nl> - keyCache . scheduleSaving ( keyCacheSavePeriodInSeconds ) ; <nl> - rowCache . scheduleSaving ( rowCacheSavePeriodInSeconds ) ; <nl> + keyCache . scheduleSaving ( keyCacheSavePeriodInSeconds , Integer . MAX _ VALUE ) ; <nl> + rowCache . scheduleSaving ( rowCacheSavePeriodInSeconds , rowCacheKeysToSave ) ; <nl> } <nl> <nl> public AutoSavingCache < Pair < Descriptor , DecoratedKey > , Long > getKeyCache ( ) <nl> @ @ - 1985 , 6 + 1989 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> - get / set memtime <nl> - get / set rowCacheSavePeriodInSeconds <nl> - get / set keyCacheSavePeriodInSeconds <nl> + - get / set rowCacheKeysToSave <nl> * / <nl> <nl> public AbstractCompactionStrategy getCompactionStrategy ( ) <nl> @ @ - 2056 , 7 + 2061 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> throw new RuntimeException ( " RowCacheSavePeriodInSeconds must be non - negative . " ) ; <nl> } <nl> this . rowCacheSaveInSeconds . set ( rcspis ) ; <nl> - scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) ) ; <nl> + scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) , rowCacheKeysToSave . value ( ) ) ; <nl> } <nl> <nl> public int getKeyCacheSavePeriodInSeconds ( ) <nl> @ @ - 2070 , 7 + 2075 , 17 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> throw new RuntimeException ( " KeyCacheSavePeriodInSeconds must be non - negative . " ) ; <nl> } <nl> this . keyCacheSaveInSeconds . set ( kcspis ) ; <nl> - scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) ) ; <nl> + scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) , rowCacheKeysToSave . value ( ) ) ; <nl> + } <nl> + <nl> + public int getRowCacheKeysToSave ( ) <nl> + { <nl> + return rowCacheKeysToSave . value ( ) ; <nl> + } <nl> + <nl> + public void setRowCacheKeysToSave ( int keysToSave ) <nl> + { <nl> + this . rowCacheKeysToSave . set ( keysToSave ) ; <nl> } <nl> / / End JMX get / set . <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStoreMBean . java b / src / java / org / apache / cassandra / db / ColumnFamilyStoreMBean . java <nl> index 4b63c37 . . 616e101 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStoreMBean . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStoreMBean . java <nl> @ @ - 231 , 4 + 231 , 7 @ @ public interface ColumnFamilyStoreMBean <nl> <nl> public int getKeyCacheSavePeriodInSeconds ( ) ; <nl> public void setKeyCacheSavePeriodInSeconds ( int kcspis ) ; <nl> + <nl> + public int getRowCacheKeysToSave ( ) ; <nl> + public void setRowCacheKeysToSave ( int keysToSave ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / migration / Migration . java b / src / java / org / apache / cassandra / db / migration / Migration . java <nl> index 37d39a2 . . bdf2943 100644 <nl> - - - a / src / java / org / apache / cassandra / db / migration / Migration . java <nl> + + + b / src / java / org / apache / cassandra / db / migration / Migration . java <nl> @ @ - 159 , 6 + 159 , 7 @ @ public abstract class Migration <nl> assert ! StorageService . instance . isClientMode ( ) ; <nl> assert column ! = null ; <nl> MigrationManager . announce ( column ) ; <nl> + passiveAnnounce ( ) ; / / keeps gossip in sync w / what we just told everyone <nl> } <nl> <nl> public final void passiveAnnounce ( ) <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index c04aa7c . . a27c09c 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 2216 , 8 + 2216 , 8 @ @ public class StorageService implements IEndpointStateChangeSubscriber , StorageSe <nl> logger _ . debug ( " submitting cache saves " ) ; <nl> for ( ColumnFamilyStore cfs : ColumnFamilyStore . all ( ) ) <nl> { <nl> - futures . add ( cfs . keyCache . submitWrite ( ) ) ; <nl> - futures . add ( cfs . rowCache . submitWrite ( ) ) ; <nl> + futures . add ( cfs . keyCache . submitWrite ( - 1 ) ) ; <nl> + futures . add ( cfs . rowCache . submitWrite ( cfs . getRowCacheKeysToSave ( ) ) ) ; <nl> } <nl> FBUtilities . waitOnFutures ( futures ) ; <nl> logger _ . debug ( " cache saves completed " ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / KeyCacheTest . java b / test / unit / org / apache / cassandra / db / KeyCacheTest . java <nl> index 5279163 . . cd1fe2c 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / KeyCacheTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / KeyCacheTest . java <nl> @ @ - 84 , 7 + 84 , 7 @ @ public class KeyCacheTest extends CleanupHelper <nl> } <nl> <nl> / / force the cache to disk <nl> - store . keyCache . submitWrite ( ) . get ( ) ; <nl> + store . keyCache . submitWrite ( Integer . MAX _ VALUE ) . get ( ) ; <nl> <nl> / / empty the cache again to make sure values came from disk <nl> store . invalidateKeyCache ( ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / RowCacheTest . java b / test / unit / org / apache / cassandra / db / RowCacheTest . java <nl> index 3ab0d22 . . b494ca5 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / RowCacheTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / RowCacheTest . java <nl> @ @ - 114 , 6 + 114 , 19 @ @ public class RowCacheTest extends CleanupHelper <nl> @ Test <nl> public void testRowCacheLoad ( ) throws Exception <nl> { <nl> + rowCacheLoad ( 100 , 100 , Integer . MAX _ VALUE ) ; <nl> + } <nl> + <nl> + <nl> + @ Test <nl> + public void testRowCachePartialLoad ( ) throws Exception <nl> + { <nl> + rowCacheLoad ( 100 , 50 , 50 ) ; <nl> + } <nl> + <nl> + <nl> + public void rowCacheLoad ( int totalKeys , int expectedKeys , int keysToSave ) throws Exception <nl> + { <nl> CompactionManager . instance . disableAutoCompaction ( ) ; <nl> <nl> ColumnFamilyStore store = Table . open ( KEYSPACE ) . getColumnFamilyStore ( COLUMN _ FAMILY _ WITH _ CACHE ) ; <nl> @ @ - 123 , 12 + 136 , 12 @ @ public class RowCacheTest extends CleanupHelper <nl> assert store . getRowCacheSize ( ) = = 0 ; <nl> <nl> / / insert data and fill the cache <nl> - insertData ( KEYSPACE , COLUMN _ FAMILY _ WITH _ CACHE , 0 , 100 ) ; <nl> - readData ( KEYSPACE , COLUMN _ FAMILY _ WITH _ CACHE , 0 , 100 ) ; <nl> - assert store . getRowCacheSize ( ) = = 100 ; <nl> + insertData ( KEYSPACE , COLUMN _ FAMILY _ WITH _ CACHE , 0 , totalKeys ) ; <nl> + readData ( KEYSPACE , COLUMN _ FAMILY _ WITH _ CACHE , 0 , totalKeys ) ; <nl> + assert store . getRowCacheSize ( ) = = totalKeys ; <nl> <nl> / / force the cache to disk <nl> - store . rowCache . submitWrite ( ) . get ( ) ; <nl> + store . rowCache . submitWrite ( keysToSave ) . get ( ) ; <nl> <nl> / / empty the cache again to make sure values came from disk <nl> store . invalidateRowCache ( ) ; <nl> @ @ - 136 , 12 + 149 , 28 @ @ public class RowCacheTest extends CleanupHelper <nl> <nl> / / load the cache from disk <nl> store . initCaches ( ) ; <nl> - assert store . getRowCacheSize ( ) = = 100 ; <nl> + assert store . getRowCacheSize ( ) = = expectedKeys ; <nl> <nl> - for ( int i = 0 ; i < 100 ; i + + ) <nl> + / / If we are loading less than the entire cache back , we can ' t <nl> + / / be sure which rows we will get if all rows are equally hot . <nl> + int nulls = 0 ; <nl> + int nonNull = 0 ; <nl> + for ( int i = 0 ; i < expectedKeys ; i + + ) <nl> { <nl> - / / verify the correct data was found <nl> - assert store . getRawCachedRow ( Util . dk ( " key " + i ) ) . getColumn ( ByteBufferUtil . bytes ( " col " + i ) ) . value ( ) . equals ( ByteBufferUtil . bytes ( " val " + i ) ) ; <nl> + / / verify the correct data was found when we expect to get <nl> + / / back the entire cache . Otherwise only make assertions <nl> + / / about how many items are read back . <nl> + ColumnFamily row = store . getRawCachedRow ( Util . dk ( " key " + i ) ) ; <nl> + if ( expectedKeys = = totalKeys ) <nl> + { <nl> + assert row ! = null ; <nl> + assert row . getColumn ( ByteBufferUtil . bytes ( " col " + i ) ) . value ( ) . equals ( ByteBufferUtil . bytes ( " val " + i ) ) ; <nl> + } <nl> + if ( row = = null ) <nl> + nulls + + ; <nl> + else <nl> + nonNull + + ; <nl> } <nl> + assert nulls + nonNull = = expectedKeys ; <nl> } <nl> }

TEST DIFF:
diff - - git a / conf / cassandra . yaml b / conf / cassandra . yaml 
 index 885d28d . . bdbb9ff 100644 
 - - - a / conf / cassandra . yaml 
 + + + b / conf / cassandra . yaml 
 @ @ - 198 , 9 + 198 , 9 @ @ saved _ caches _ directory : / var / lib / cassandra / saved _ caches 
 # 
 # the other option is " periodic " where writes may be acked immediately 
 # and the CommitLog is simply synced every commitlog _ sync _ period _ in _ ms 
 - # milliseconds . By default this allows 1024 * ( CPU cores ) pending 
 - # entries on the commitlog queue . If you are writing very large blobs , 
 - # you should reduce that ; 16 * cores works reasonably well for 1MB blobs . 
 + # milliseconds . commitlog _ periodic _ queue _ size allows 1024 * ( CPU cores ) pending 
 + # entries on the commitlog queue by default . If you are writing very large 
 + # blobs , you should reduce that ; 16 * cores works reasonably well for 1MB blobs . 
 # It should be at least as large as the concurrent _ writes setting . 
 commitlog _ sync : periodic 
 commitlog _ sync _ period _ in _ ms : 10000

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 3b257ba . . 9dafe3f 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 18 , 6 + 18 , 7 @ @ 
 * store hints as serialized mutations instead of pointers to data rows 
 * store hints in the coordinator node instead of in the closest 
 replica ( CASSANDRA - 2914 ) . 
 + * add row _ cache _ keys _ to _ save CF option ( CASSANDRA - 1966 ) 
 
 
 0 . 8 . 2 
 diff - - git a / interface / cassandra . thrift b / interface / cassandra . thrift 
 index 14582fb . . 45ef50a 100644 
 - - - a / interface / cassandra . thrift 
 + + + b / interface / cassandra . thrift 
 @ @ - 46 , 7 + 46 , 7 @ @ namespace rb CassandraThrift 
 # for every edit that doesn ' t result in a change to major / minor . 
 # 
 # See the Semantic Versioning Specification ( SemVer ) http : / / semver . org . 
 - const string VERSION = " 19 . 10 . 0 " 
 + const string VERSION = " 19 . 11 . 0 " 
 
 
 # 
 @ @ - 396 , 6 + 396 , 7 @ @ struct CfDef { 
 28 : optional binary key _ alias , 
 29 : optional string compaction _ strategy , 
 30 : optional map < string , string > compaction _ strategy _ options , 
 + 31 : optional i32 row _ cache _ keys _ to _ save , 
 } 
 
 / * describes a keyspace . * / 
 diff - - git a / interface / thrift / gen - java / org / apache / cassandra / thrift / Cassandra . java b / interface / thrift / gen - java / org / apache / cassandra / thrift / Cassandra . java 
 index bd02789 . . 717370c 100644 
 - - - a / interface / thrift / gen - java / org / apache / cassandra / thrift / Cassandra . java 
 + + + b / interface / thrift / gen - java / org / apache / cassandra / thrift / Cassandra . java 
 @ @ - 9086 , 6 + 9086 , 8 @ @ public class Cassandra { 
 
 private void readObject ( java . io . ObjectInputStream in ) throws java . io . IOException , ClassNotFoundException { 
 try { 
 + / / it doesn ' t seem like you should have to do this , but java serialization is wacky , and doesn ' t call the default constructor . 
 + _ _ isset _ bit _ vector = new BitSet ( 1 ) ; 
 read ( new org . apache . thrift . protocol . TCompactProtocol ( new org . apache . thrift . transport . TIOStreamTransport ( in ) ) ) ; 
 } catch ( org . apache . thrift . TException te ) { 
 throw new java . io . IOException ( te ) ; 
 @ @ - 17041 , 8 + 17043 , 6 @ @ public class Cassandra { 
 
 private void readObject ( java . io . ObjectInputStream in ) throws java . io . IOException , ClassNotFoundException { 
 try { 
 - / / it doesn ' t seem like you should have to do this , but java serialization is wacky , and doesn ' t call the default constructor . 
 - _ _ isset _ bit _ vector = new BitSet ( 1 ) ; 
 read ( new org . apache . thrift . protocol . TCompactProtocol ( new org . apache . thrift . transport . TIOStreamTransport ( in ) ) ) ; 
 } catch ( org . apache . thrift . TException te ) { 
 throw new java . io . IOException ( te ) ; 
 @ @ - 25752 , 6 + 25752 , 8 @ @ public class Cassandra { 
 
 private void readObject ( java . io . ObjectInputStream in ) throws java . io . IOException , ClassNotFoundException { 
 try { 
 + / / it doesn ' t seem like you should have to do this , but java serialization is wacky , and doesn ' t call the default constructor . 
 + _ _ isset _ bit _ vector = new BitSet ( 1 ) ; 
 read ( new org . apache . thrift . protocol . TCompactProtocol ( new org . apache . thrift . transport . TIOStreamTransport ( in ) ) ) ; 
 } catch ( org . apache . thrift . TException te ) { 
 throw new java . io . IOException ( te ) ; 
 diff - - git a / interface / thrift / gen - java / org / apache / cassandra / thrift / CfDef . java b / interface / thrift / gen - java / org / apache / cassandra / thrift / CfDef . java 
 index 6b7412e . . 9ab9aa2 100644 
 - - - a / interface / thrift / gen - java / org / apache / cassandra / thrift / CfDef . java 
 + + + b / interface / thrift / gen - java / org / apache / cassandra / thrift / CfDef . java 
 @ @ - 71 , 6 + 71 , 7 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 private static final org . apache . thrift . protocol . TField KEY _ ALIAS _ FIELD _ DESC = new org . apache . thrift . protocol . TField ( " key _ alias " , org . apache . thrift . protocol . TType . STRING , ( short ) 28 ) ; 
 private static final org . apache . thrift . protocol . TField COMPACTION _ STRATEGY _ FIELD _ DESC = new org . apache . thrift . protocol . TField ( " compaction _ strategy " , org . apache . thrift . protocol . TType . STRING , ( short ) 29 ) ; 
 private static final org . apache . thrift . protocol . TField COMPACTION _ STRATEGY _ OPTIONS _ FIELD _ DESC = new org . apache . thrift . protocol . TField ( " compaction _ strategy _ options " , org . apache . thrift . protocol . TType . MAP , ( short ) 30 ) ; 
 + private static final org . apache . thrift . protocol . TField ROW _ CACHE _ KEYS _ TO _ SAVE _ FIELD _ DESC = new org . apache . thrift . protocol . TField ( " row _ cache _ keys _ to _ save " , org . apache . thrift . protocol . TType . I32 , ( short ) 31 ) ; 
 
 public String keyspace ; 
 public String name ; 
 @ @ - 98 , 6 + 99 , 7 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 public ByteBuffer key _ alias ; 
 public String compaction _ strategy ; 
 public Map < String , String > compaction _ strategy _ options ; 
 + public int row _ cache _ keys _ to _ save ; 
 
 / * * The set of fields this struct contains , along with convenience methods for finding and manipulating them . * / 
 public enum _ Fields implements org . apache . thrift . TFieldIdEnum { 
 @ @ - 126 , 7 + 128 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 ROW _ CACHE _ PROVIDER ( ( short ) 27 , " row _ cache _ provider " ) , 
 KEY _ ALIAS ( ( short ) 28 , " key _ alias " ) , 
 COMPACTION _ STRATEGY ( ( short ) 29 , " compaction _ strategy " ) , 
 - COMPACTION _ STRATEGY _ OPTIONS ( ( short ) 30 , " compaction _ strategy _ options " ) ; 
 + COMPACTION _ STRATEGY _ OPTIONS ( ( short ) 30 , " compaction _ strategy _ options " ) , 
 + ROW _ CACHE _ KEYS _ TO _ SAVE ( ( short ) 31 , " row _ cache _ keys _ to _ save " ) ; 
 
 private static final Map < String , _ Fields > byName = new HashMap < String , _ Fields > ( ) ; 
 
 @ @ - 193 , 6 + 196 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 return COMPACTION _ STRATEGY ; 
 case 30 : / / COMPACTION _ STRATEGY _ OPTIONS 
 return COMPACTION _ STRATEGY _ OPTIONS ; 
 + case 31 : / / ROW _ CACHE _ KEYS _ TO _ SAVE 
 + return ROW _ CACHE _ KEYS _ TO _ SAVE ; 
 default : 
 return null ; 
 } 
 @ @ - 246 , 7 + 251 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 private static final int _ _ MEMTABLE _ OPERATIONS _ IN _ MILLIONS _ ISSET _ ID = 10 ; 
 private static final int _ _ REPLICATE _ ON _ WRITE _ ISSET _ ID = 11 ; 
 private static final int _ _ MERGE _ SHARDS _ CHANCE _ ISSET _ ID = 12 ; 
 - private BitSet _ _ isset _ bit _ vector = new BitSet ( 13 ) ; 
 + private static final int _ _ ROW _ CACHE _ KEYS _ TO _ SAVE _ ISSET _ ID = 13 ; 
 + private BitSet _ _ isset _ bit _ vector = new BitSet ( 14 ) ; 
 
 public static final Map < _ Fields , org . apache . thrift . meta _ data . FieldMetaData > metaDataMap ; 
 static { 
 @ @ - 306 , 6 + 312 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 new org . apache . thrift . meta _ data . MapMetaData ( org . apache . thrift . protocol . TType . MAP , 
 new org . apache . thrift . meta _ data . FieldValueMetaData ( org . apache . thrift . protocol . TType . STRING ) , 
 new org . apache . thrift . meta _ data . FieldValueMetaData ( org . apache . thrift . protocol . TType . STRING ) ) ) ) ; 
 + tmpMap . put ( _ Fields . ROW _ CACHE _ KEYS _ TO _ SAVE , new org . apache . thrift . meta _ data . FieldMetaData ( " row _ cache _ keys _ to _ save " , org . apache . thrift . TFieldRequirementType . OPTIONAL , 
 + new org . apache . thrift . meta _ data . FieldValueMetaData ( org . apache . thrift . protocol . TType . I32 ) ) ) ; 
 metaDataMap = Collections . unmodifiableMap ( tmpMap ) ; 
 org . apache . thrift . meta _ data . FieldMetaData . addStructMetaDataMap ( CfDef . class , metaDataMap ) ; 
 } 
 @ @ - 409 , 6 + 417 , 7 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 } 
 this . compaction _ strategy _ options = _ _ this _ _ compaction _ strategy _ options ; 
 } 
 + this . row _ cache _ keys _ to _ save = other . row _ cache _ keys _ to _ save ; 
 } 
 
 public CfDef deepCopy ( ) { 
 @ @ - 459 , 6 + 468 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 this . key _ alias = null ; 
 this . compaction _ strategy = null ; 
 this . compaction _ strategy _ options = null ; 
 + setRow _ cache _ keys _ to _ saveIsSet ( false ) ; 
 + this . row _ cache _ keys _ to _ save = 0 ; 
 } 
 
 public String getKeyspace ( ) { 
 @ @ - 1108 , 6 + 1119 , 29 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 } 
 } 
 
 + public int getRow _ cache _ keys _ to _ save ( ) { 
 + return this . row _ cache _ keys _ to _ save ; 
 + } 
 + 
 + public CfDef setRow _ cache _ keys _ to _ save ( int row _ cache _ keys _ to _ save ) { 
 + this . row _ cache _ keys _ to _ save = row _ cache _ keys _ to _ save ; 
 + setRow _ cache _ keys _ to _ saveIsSet ( true ) ; 
 + return this ; 
 + } 
 + 
 + public void unsetRow _ cache _ keys _ to _ save ( ) { 
 + _ _ isset _ bit _ vector . clear ( _ _ ROW _ CACHE _ KEYS _ TO _ SAVE _ ISSET _ ID ) ; 
 + } 
 + 
 + / * * Returns true if field row _ cache _ keys _ to _ save is set ( has been assigned a value ) and false otherwise * / 
 + public boolean isSetRow _ cache _ keys _ to _ save ( ) { 
 + return _ _ isset _ bit _ vector . get ( _ _ ROW _ CACHE _ KEYS _ TO _ SAVE _ ISSET _ ID ) ; 
 + } 
 + 
 + public void setRow _ cache _ keys _ to _ saveIsSet ( boolean value ) { 
 + _ _ isset _ bit _ vector . set ( _ _ ROW _ CACHE _ KEYS _ TO _ SAVE _ ISSET _ ID , value ) ; 
 + } 
 + 
 public void setFieldValue ( _ Fields field , Object value ) { 
 switch ( field ) { 
 case KEYSPACE : 
 @ @ - 1318 , 6 + 1352 , 14 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 } 
 break ; 
 
 + case ROW _ CACHE _ KEYS _ TO _ SAVE : 
 + if ( value = = null ) { 
 + unsetRow _ cache _ keys _ to _ save ( ) ; 
 + } else { 
 + setRow _ cache _ keys _ to _ save ( ( Integer ) value ) ; 
 + } 
 + break ; 
 + 
 } 
 } 
 
 @ @ - 1401 , 6 + 1443 , 9 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 case COMPACTION _ STRATEGY _ OPTIONS : 
 return getCompaction _ strategy _ options ( ) ; 
 
 + case ROW _ CACHE _ KEYS _ TO _ SAVE : 
 + return new Integer ( getRow _ cache _ keys _ to _ save ( ) ) ; 
 + 
 } 
 throw new IllegalStateException ( ) ; 
 } 
 @ @ - 1464 , 6 + 1509 , 8 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 return isSetCompaction _ strategy ( ) ; 
 case COMPACTION _ STRATEGY _ OPTIONS : 
 return isSetCompaction _ strategy _ options ( ) ; 
 + case ROW _ CACHE _ KEYS _ TO _ SAVE : 
 + return isSetRow _ cache _ keys _ to _ save ( ) ; 
 } 
 throw new IllegalStateException ( ) ; 
 } 
 @ @ - 1715 , 6 + 1762 , 15 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 return false ; 
 } 
 
 + boolean this _ present _ row _ cache _ keys _ to _ save = true & & this . isSetRow _ cache _ keys _ to _ save ( ) ; 
 + boolean that _ present _ row _ cache _ keys _ to _ save = true & & that . isSetRow _ cache _ keys _ to _ save ( ) ; 
 + if ( this _ present _ row _ cache _ keys _ to _ save | | that _ present _ row _ cache _ keys _ to _ save ) { 
 + if ( ! ( this _ present _ row _ cache _ keys _ to _ save & & that _ present _ row _ cache _ keys _ to _ save ) ) 
 + return false ; 
 + if ( this . row _ cache _ keys _ to _ save ! = that . row _ cache _ keys _ to _ save ) 
 + return false ; 
 + } 
 + 
 return true ; 
 } 
 
 @ @ - 1852 , 6 + 1908 , 11 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 if ( present _ compaction _ strategy _ options ) 
 builder . append ( compaction _ strategy _ options ) ; 
 
 + boolean present _ row _ cache _ keys _ to _ save = true & & ( isSetRow _ cache _ keys _ to _ save ( ) ) ; 
 + builder . append ( present _ row _ cache _ keys _ to _ save ) ; 
 + if ( present _ row _ cache _ keys _ to _ save ) 
 + builder . append ( row _ cache _ keys _ to _ save ) ; 
 + 
 return builder . toHashCode ( ) ; 
 } 
 
 @ @ - 2123 , 6 + 2184 , 16 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 return lastComparison ; 
 } 
 } 
 + lastComparison = Boolean . valueOf ( isSetRow _ cache _ keys _ to _ save ( ) ) . compareTo ( typedOther . isSetRow _ cache _ keys _ to _ save ( ) ) ; 
 + if ( lastComparison ! = 0 ) { 
 + return lastComparison ; 
 + } 
 + if ( isSetRow _ cache _ keys _ to _ save ( ) ) { 
 + lastComparison = org . apache . thrift . TBaseHelper . compareTo ( this . row _ cache _ keys _ to _ save , typedOther . row _ cache _ keys _ to _ save ) ; 
 + if ( lastComparison ! = 0 ) { 
 + return lastComparison ; 
 + } 
 + } 
 return 0 ; 
 } 
 
 @ @ - 2358 , 6 + 2429 , 14 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , field . type ) ; 
 } 
 break ; 
 + case 31 : / / ROW _ CACHE _ KEYS _ TO _ SAVE 
 + if ( field . type = = org . apache . thrift . protocol . TType . I32 ) { 
 + this . row _ cache _ keys _ to _ save = iprot . readI32 ( ) ; 
 + setRow _ cache _ keys _ to _ saveIsSet ( true ) ; 
 + } else { 
 + org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , field . type ) ; 
 + } 
 + break ; 
 default : 
 org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , field . type ) ; 
 } 
 @ @ - 2540 , 6 + 2619 , 11 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 oprot . writeFieldEnd ( ) ; 
 } 
 } 
 + if ( isSetRow _ cache _ keys _ to _ save ( ) ) { 
 + oprot . writeFieldBegin ( ROW _ CACHE _ KEYS _ TO _ SAVE _ FIELD _ DESC ) ; 
 + oprot . writeI32 ( this . row _ cache _ keys _ to _ save ) ; 
 + oprot . writeFieldEnd ( ) ; 
 + } 
 oprot . writeFieldStop ( ) ; 
 oprot . writeStructEnd ( ) ; 
 } 
 @ @ - 2752 , 6 + 2836 , 12 @ @ public class CfDef implements org . apache . thrift . TBase < CfDef , CfDef . _ Fields > , jav 
 } 
 first = false ; 
 } 
 + if ( isSetRow _ cache _ keys _ to _ save ( ) ) { 
 + if ( ! first ) sb . append ( " , " ) ; 
 + sb . append ( " row _ cache _ keys _ to _ save : " ) ; 
 + sb . append ( this . row _ cache _ keys _ to _ save ) ; 
 + first = false ; 
 + } 
 sb . append ( " ) " ) ; 
 return sb . toString ( ) ; 
 } 
 diff - - git a / interface / thrift / gen - java / org / apache / cassandra / thrift / Constants . java b / interface / thrift / gen - java / org / apache / cassandra / thrift / Constants . java 
 index e589e2e . . 6bac7b0 100644 
 - - - a / interface / thrift / gen - java / org / apache / cassandra / thrift / Constants . java 
 + + + b / interface / thrift / gen - java / org / apache / cassandra / thrift / Constants . java 
 @ @ - 44 , 6 + 44 , 6 @ @ import org . slf4j . LoggerFactory ; 
 
 public class Constants { 
 
 - public static final String VERSION = " 19 . 10 . 0 " ; 
 + public static final String VERSION = " 19 . 11 . 0 " ; 
 
 } 
 diff - - git a / src / avro / internode . genavro b / src / avro / internode . genavro 
 index ad103be . . c1bd9e5 100644 
 - - - a / src / avro / internode . genavro 
 + + + b / src / avro / internode . genavro 
 @ @ - 57 , 6 + 57 , 7 @ @ protocol InterNode { 
 union { null , int } max _ compaction _ threshold = null ; 
 union { int , null } row _ cache _ save _ period _ in _ seconds = 0 ; 
 union { int , null } key _ cache _ save _ period _ in _ seconds = 3600 ; 
 + union { int , null } row _ cache _ keys _ to _ save = null ; 
 union { null , int } memtable _ throughput _ in _ mb = null ; 
 union { null , double } memtable _ operations _ in _ millions = null ; 
 union { null , double } merge _ shards _ chance = null ; 
 diff - - git a / src / java / org / apache / cassandra / cache / AutoSavingCache . java b / src / java / org / apache / cassandra / cache / AutoSavingCache . java 
 index 0e4ea0c . . e5df049 100644 
 - - - a / src / java / org / apache / cassandra / cache / AutoSavingCache . java 
 + + + b / src / java / org / apache / cassandra / cache / AutoSavingCache . java 
 @ @ - 77 , 12 + 77 , 12 @ @ public abstract class AutoSavingCache < K , V > extends InstrumentingCache < K , V > 
 return DatabaseDescriptor . getSerializedCachePath ( tableName , cfName , cacheType ) ; 
 } 
 
 - public Writer getWriter ( ) 
 + public Writer getWriter ( int keysToSave ) 
 { 
 - return new Writer ( tableName , cfName ) ; 
 + return new Writer ( tableName , cfName , keysToSave ) ; 
 } 
 
 - public void scheduleSaving ( int savePeriodInSeconds ) 
 + public void scheduleSaving ( int savePeriodInSeconds , final int keysToSave ) 
 { 
 if ( saveTask ! = null ) 
 { 
 @ @ - 95 , 7 + 95 , 7 @ @ public abstract class AutoSavingCache < K , V > extends InstrumentingCache < K , V > 
 { 
 public void runMayThrow ( ) 
 { 
 - submitWrite ( ) ; 
 + submitWrite ( keysToSave ) ; 
 } 
 } ; 
 saveTask = StorageService . tasks . scheduleWithFixedDelay ( runnable , 
 @ @ - 105 , 9 + 105 , 9 @ @ public abstract class AutoSavingCache < K , V > extends InstrumentingCache < K , V > 
 } 
 } 
 
 - public Future < ? > submitWrite ( ) 
 + public Future < ? > submitWrite ( int keysToSave ) 
 { 
 - return CompactionManager . instance . submitCacheWrite ( getWriter ( ) ) ; 
 + return CompactionManager . instance . submitCacheWrite ( getWriter ( keysToSave ) ) ; 
 } 
 
 public Set < DecoratedKey > readSaved ( ) 
 @ @ - 195 , 9 + 195 , 12 @ @ public abstract class AutoSavingCache < K , V > extends InstrumentingCache < K , V > 
 private final long estimatedTotalBytes ; 
 private long bytesWritten ; 
 
 - private Writer ( String ksname , String cfname ) 
 + private Writer ( String ksname , String cfname , int keysToSave ) 
 { 
 - keys = getKeySet ( ) ; 
 + if ( keysToSave > = getKeySet ( ) . size ( ) ) 
 + keys = getKeySet ( ) ; 
 + else 
 + keys = hotKeySet ( keysToSave ) ; 
 long bytes = 0 ; 
 for ( K key : keys ) 
 bytes + = translateKey ( key ) . remaining ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / cache / ConcurrentLinkedHashCache . java b / src / java / org / apache / cassandra / cache / ConcurrentLinkedHashCache . java 
 index 34b136d . . ed44028 100644 
 - - - a / src / java / org / apache / cassandra / cache / ConcurrentLinkedHashCache . java 
 + + + b / src / java / org / apache / cassandra / cache / ConcurrentLinkedHashCache . java 
 @ @ - 96 , 6 + 96 , 11 @ @ public class ConcurrentLinkedHashCache < K , V > implements ICache < K , V > 
 return map . keySet ( ) ; 
 } 
 
 + public Set < K > hotKeySet ( int n ) 
 + { 
 + return map . descendingKeySetWithLimit ( n ) ; 
 + } 
 + 
 public boolean isPutCopying ( ) 
 { 
 return false ; 
 diff - - git a / src / java / org / apache / cassandra / cache / ICache . java b / src / java / org / apache / cassandra / cache / ICache . java 
 index 0eebdb4 . . deac174 100644 
 - - - a / src / java / org / apache / cassandra / cache / ICache . java 
 + + + b / src / java / org / apache / cassandra / cache / ICache . java 
 @ @ - 46 , 6 + 46 , 8 @ @ public interface ICache < K , V > 
 
 public Set < K > keySet ( ) ; 
 
 + public Set < K > hotKeySet ( int n ) ; 
 + 
 / * * 
 * @ return true if the cache implementation inherently copies the cached values ; otherwise , 
 * the caller should copy manually before caching shared values like Thrift ByteBuffers . 
 diff - - git a / src / java / org / apache / cassandra / cache / InstrumentingCache . java b / src / java / org / apache / cassandra / cache / InstrumentingCache . java 
 index 7c77f9f . . f622c55 100644 
 - - - a / src / java / org / apache / cassandra / cache / InstrumentingCache . java 
 + + + b / src / java / org / apache / cassandra / cache / InstrumentingCache . java 
 @ @ - 150 , 6 + 150 , 11 @ @ public class InstrumentingCache < K , V > implements InstrumentingCacheMBean 
 return map . keySet ( ) ; 
 } 
 
 + public Set < K > hotKeySet ( int n ) 
 + { 
 + return map . hotKeySet ( n ) ; 
 + } 
 + 
 public boolean isPutCopying ( ) 
 { 
 return map . isPutCopying ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / cache / SerializingCache . java b / src / java / org / apache / cassandra / cache / SerializingCache . java 
 index bac6534 . . a505480 100644 
 - - - a / src / java / org / apache / cassandra / cache / SerializingCache . java 
 + + + b / src / java / org / apache / cassandra / cache / SerializingCache . java 
 @ @ - 163 , 6 + 163 , 11 @ @ public class SerializingCache < K , V > implements ICache < K , V > 
 return map . keySet ( ) ; 
 } 
 
 + public Set < K > hotKeySet ( int n ) 
 + { 
 + return map . descendingKeySetWithLimit ( n ) ; 
 + } 
 + 
 public boolean isPutCopying ( ) 
 { 
 return true ; 
 diff - - git a / src / java / org / apache / cassandra / cli / CliClient . java b / src / java / org / apache / cassandra / cli / CliClient . java 
 index 878bf74 . . 6e9ad23 100644 
 - - - a / src / java / org / apache / cassandra / cli / CliClient . java 
 + + + b / src / java / org / apache / cassandra / cli / CliClient . java 
 @ @ - 119 , 6 + 119 , 7 @ @ public class CliClient 
 COMMENT , 
 ROWS _ CACHED , 
 ROW _ CACHE _ SAVE _ PERIOD , 
 + ROW _ CACHE _ KEYS _ TO _ SAVE , 
 KEYS _ CACHED , 
 KEY _ CACHE _ SAVE _ PERIOD , 
 READ _ REPAIR _ CHANCE , 
 @ @ - 1231 , 6 + 1232 , 9 @ @ public class CliClient 
 case KEY _ CACHE _ SAVE _ PERIOD : 
 cfDef . setKey _ cache _ save _ period _ in _ seconds ( Integer . parseInt ( mValue ) ) ; 
 break ; 
 + case ROW _ CACHE _ KEYS _ TO _ SAVE : 
 + cfDef . setRow _ cache _ keys _ to _ save ( Integer . parseInt ( mValue ) ) ; 
 + break ; 
 case DEFAULT _ VALIDATION _ CLASS : 
 cfDef . setDefault _ validation _ class ( CliUtils . unescapeSQLString ( mValue ) ) ; 
 break ; 
 @ @ - 1716 , 7 + 1720 , 9 @ @ public class CliClient 
 if ( cf _ def . default _ validation _ class ! = null ) 
 sessionState . out . printf ( " Default column value validator : % s % n " , cf _ def . default _ validation _ class ) ; 
 sessionState . out . printf ( " Columns sorted by : % s % s % n " , cf _ def . comparator _ type , cf _ def . column _ type . equals ( " Super " ) ? " / " + cf _ def . subcomparator _ type : " " ) ; 
 - sessionState . out . printf ( " Row cache size / save period in seconds : % s / % s % n " , cf _ def . row _ cache _ size , cf _ def . row _ cache _ save _ period _ in _ seconds ) ; 
 + sessionState . out . printf ( " Row cache size / save period in seconds / keys to save : % s / % s / % s % n " , 
 + cf _ def . row _ cache _ size , cf _ def . row _ cache _ save _ period _ in _ seconds , 
 + cf _ def . row _ cache _ keys _ to _ save = = Integer . MAX _ VALUE ? " all " : cf _ def . row _ cache _ keys _ to _ save ) ; 
 sessionState . out . printf ( " Key cache size / save period in seconds : % s / % s % n " , cf _ def . key _ cache _ size , cf _ def . key _ cache _ save _ period _ in _ seconds ) ; 
 sessionState . out . printf ( " Memtable thresholds : % s / % s ( millions of ops / MB ) % n " , 
 cf _ def . memtable _ operations _ in _ millions , cf _ def . memtable _ throughput _ in _ mb ) ; 
 diff - - git a / src / java / org / apache / cassandra / config / CFMetaData . java b / src / java / org / apache / cassandra / config / CFMetaData . java 
 index 0284c5b . . 5283f65 100644 
 - - - a / src / java / org / apache / cassandra / config / CFMetaData . java 
 + + + b / src / java / org / apache / cassandra / config / CFMetaData . java 
 @ @ - 70 , 6 + 70 , 7 @ @ public final class CFMetaData 
 public final static int DEFAULT _ SYSTEM _ MEMTABLE _ THROUGHPUT _ IN _ MB = 8 ; 
 public final static int DEFAULT _ ROW _ CACHE _ SAVE _ PERIOD _ IN _ SECONDS = 0 ; 
 public final static int DEFAULT _ KEY _ CACHE _ SAVE _ PERIOD _ IN _ SECONDS = 4 * 3600 ; 
 + public final static int DEFAULT _ ROW _ CACHE _ KEYS _ TO _ SAVE = Integer . MAX _ VALUE ; 
 public final static int DEFAULT _ GC _ GRACE _ SECONDS = 864000 ; 
 public final static int DEFAULT _ MIN _ COMPACTION _ THRESHOLD = 4 ; 
 public final static int DEFAULT _ MAX _ COMPACTION _ THRESHOLD = 32 ; 
 @ @ - 164 , 6 + 165 , 7 @ @ public final class CFMetaData 
 private int maxCompactionThreshold ; / / default 32 
 private int rowCacheSavePeriodInSeconds ; / / default 0 ( off ) 
 private int keyCacheSavePeriodInSeconds ; / / default 3600 ( 1 hour ) 
 + private int rowCacheKeysToSave ; / / default max int ( aka feature is off ) 
 private int memtableThroughputInMb ; / / default based on heap size 
 private double memtableOperationsInMillions ; / / default based on throughput 
 private double mergeShardsChance ; / / default 0 . 1 , chance [ 0 . 0 , 1 . 0 ] of merging old shards during replication 
 @ @ - 186 , 6 + 188 , 7 @ @ public final class CFMetaData 
 public CFMetaData maxCompactionThreshold ( int prop ) { maxCompactionThreshold = prop ; return this ; } 
 public CFMetaData rowCacheSavePeriod ( int prop ) { rowCacheSavePeriodInSeconds = prop ; return this ; } 
 public CFMetaData keyCacheSavePeriod ( int prop ) { keyCacheSavePeriodInSeconds = prop ; return this ; } 
 + public CFMetaData rowCacheKeysToSave ( int prop ) { rowCacheKeysToSave = prop ; return this ; } 
 public CFMetaData memSize ( int prop ) { memtableThroughputInMb = prop ; return this ; } 
 public CFMetaData memOps ( double prop ) { memtableOperationsInMillions = prop ; return this ; } 
 public CFMetaData mergeShardsChance ( double prop ) { mergeShardsChance = prop ; return this ; } 
 @ @ - 231 , 6 + 234 , 7 @ @ public final class CFMetaData 
 / / Set a bunch of defaults 
 rowCacheSize = DEFAULT _ ROW _ CACHE _ SIZE ; 
 keyCacheSize = DEFAULT _ KEY _ CACHE _ SIZE ; 
 + rowCacheKeysToSave = DEFAULT _ ROW _ CACHE _ KEYS _ TO _ SAVE ; 
 readRepairChance = DEFAULT _ READ _ REPAIR _ CHANCE ; 
 replicateOnWrite = DEFAULT _ REPLICATE _ ON _ WRITE ; 
 gcGraceSeconds = DEFAULT _ GC _ GRACE _ SECONDS ; 
 @ @ - 319 , 6 + 323 , 7 @ @ public final class CFMetaData 
 . maxCompactionThreshold ( oldCFMD . maxCompactionThreshold ) 
 . rowCacheSavePeriod ( oldCFMD . rowCacheSavePeriodInSeconds ) 
 . keyCacheSavePeriod ( oldCFMD . keyCacheSavePeriodInSeconds ) 
 + . rowCacheKeysToSave ( oldCFMD . rowCacheKeysToSave ) 
 . memSize ( oldCFMD . memtableThroughputInMb ) 
 . memOps ( oldCFMD . memtableOperationsInMillions ) 
 . columnMetadata ( oldCFMD . column _ metadata ) 
 @ @ - 368 , 6 + 373 , 7 @ @ public final class CFMetaData 
 cf . max _ compaction _ threshold = maxCompactionThreshold ; 
 cf . row _ cache _ save _ period _ in _ seconds = rowCacheSavePeriodInSeconds ; 
 cf . key _ cache _ save _ period _ in _ seconds = keyCacheSavePeriodInSeconds ; 
 + cf . row _ cache _ keys _ to _ save = rowCacheKeysToSave ; 
 cf . memtable _ throughput _ in _ mb = memtableThroughputInMb ; 
 cf . memtable _ operations _ in _ millions = memtableOperationsInMillions ; 
 cf . merge _ shards _ chance = mergeShardsChance ; 
 @ @ - 430 , 6 + 436 , 7 @ @ public final class CFMetaData 
 if ( cf . max _ compaction _ threshold ! = null ) { newCFMD . maxCompactionThreshold ( cf . max _ compaction _ threshold ) ; } 
 if ( cf . row _ cache _ save _ period _ in _ seconds ! = null ) { newCFMD . rowCacheSavePeriod ( cf . row _ cache _ save _ period _ in _ seconds ) ; } 
 if ( cf . key _ cache _ save _ period _ in _ seconds ! = null ) { newCFMD . keyCacheSavePeriod ( cf . key _ cache _ save _ period _ in _ seconds ) ; } 
 + if ( cf . row _ cache _ keys _ to _ save ! = null ) { newCFMD . rowCacheKeysToSave ( cf . row _ cache _ keys _ to _ save ) ; } 
 if ( cf . memtable _ throughput _ in _ mb ! = null ) { newCFMD . memSize ( cf . memtable _ throughput _ in _ mb ) ; } 
 if ( cf . memtable _ operations _ in _ millions ! = null ) { newCFMD . memOps ( cf . memtable _ operations _ in _ millions ) ; } 
 if ( cf . merge _ shards _ chance ! = null ) { newCFMD . mergeShardsChance ( cf . merge _ shards _ chance ) ; } 
 @ @ - 538 , 6 + 545 , 11 @ @ public final class CFMetaData 
 return keyCacheSavePeriodInSeconds ; 
 } 
 
 + public int getRowCacheKeysToSave ( ) 
 + { 
 + return rowCacheKeysToSave ; 
 + } 
 + 
 public int getMemtableThroughputInMb ( ) 
 { 
 return memtableThroughputInMb ; 
 @ @ - 600 , 6 + 612 , 7 @ @ public final class CFMetaData 
 . append ( column _ metadata , rhs . column _ metadata ) 
 . append ( rowCacheSavePeriodInSeconds , rhs . rowCacheSavePeriodInSeconds ) 
 . append ( keyCacheSavePeriodInSeconds , rhs . keyCacheSavePeriodInSeconds ) 
 + . append ( rowCacheKeysToSave , rhs . rowCacheKeysToSave ) 
 . append ( memtableThroughputInMb , rhs . memtableThroughputInMb ) 
 . append ( memtableOperationsInMillions , rhs . memtableOperationsInMillions ) 
 . append ( mergeShardsChance , rhs . mergeShardsChance ) 
 @ @ - 631 , 6 + 644 , 7 @ @ public final class CFMetaData 
 . append ( column _ metadata ) 
 . append ( rowCacheSavePeriodInSeconds ) 
 . append ( keyCacheSavePeriodInSeconds ) 
 + . append ( rowCacheKeysToSave ) 
 . append ( memtableThroughputInMb ) 
 . append ( memtableOperationsInMillions ) 
 . append ( mergeShardsChance ) 
 @ @ - 669 , 6 + 683 , 8 @ @ public final class CFMetaData 
 cf _ def . setRow _ cache _ save _ period _ in _ seconds ( CFMetaData . DEFAULT _ ROW _ CACHE _ SAVE _ PERIOD _ IN _ SECONDS ) ; 
 if ( ! cf _ def . isSetKey _ cache _ save _ period _ in _ seconds ( ) ) 
 cf _ def . setKey _ cache _ save _ period _ in _ seconds ( CFMetaData . DEFAULT _ KEY _ CACHE _ SAVE _ PERIOD _ IN _ SECONDS ) ; 
 + if ( ! cf _ def . isSetRow _ cache _ keys _ to _ save ( ) ) 
 + cf _ def . setRow _ cache _ keys _ to _ save ( CFMetaData . DEFAULT _ ROW _ CACHE _ KEYS _ TO _ SAVE ) ; 
 if ( ! cf _ def . isSetMemtable _ throughput _ in _ mb ( ) ) 
 cf _ def . setMemtable _ throughput _ in _ mb ( CFMetaData . DEFAULT _ MEMTABLE _ THROUGHPUT _ IN _ MB ) ; 
 if ( ! cf _ def . isSetMemtable _ operations _ in _ millions ( ) ) 
 @ @ - 704 , 6 + 720 , 7 @ @ public final class CFMetaData 
 if ( cf _ def . isSetMax _ compaction _ threshold ( ) ) { newCFMD . maxCompactionThreshold ( cf _ def . max _ compaction _ threshold ) ; } 
 if ( cf _ def . isSetRow _ cache _ save _ period _ in _ seconds ( ) ) { newCFMD . rowCacheSavePeriod ( cf _ def . row _ cache _ save _ period _ in _ seconds ) ; } 
 if ( cf _ def . isSetKey _ cache _ save _ period _ in _ seconds ( ) ) { newCFMD . keyCacheSavePeriod ( cf _ def . key _ cache _ save _ period _ in _ seconds ) ; } 
 + if ( cf _ def . isSetRow _ cache _ keys _ to _ save ( ) ) { newCFMD . rowCacheKeysToSave ( cf _ def . row _ cache _ keys _ to _ save ) ; } 
 if ( cf _ def . isSetMemtable _ throughput _ in _ mb ( ) ) { newCFMD . memSize ( cf _ def . memtable _ throughput _ in _ mb ) ; } 
 if ( cf _ def . isSetMemtable _ operations _ in _ millions ( ) ) { newCFMD . memOps ( cf _ def . memtable _ operations _ in _ millions ) ; } 
 if ( cf _ def . isSetMerge _ shards _ chance ( ) ) { newCFMD . mergeShardsChance ( cf _ def . merge _ shards _ chance ) ; } 
 @ @ - 776 , 6 + 793 , 7 @ @ public final class CFMetaData 
 maxCompactionThreshold = cf _ def . max _ compaction _ threshold ; 
 rowCacheSavePeriodInSeconds = cf _ def . row _ cache _ save _ period _ in _ seconds ; 
 keyCacheSavePeriodInSeconds = cf _ def . key _ cache _ save _ period _ in _ seconds ; 
 + rowCacheKeysToSave = cf _ def . row _ cache _ keys _ to _ save ; 
 memtableThroughputInMb = cf _ def . memtable _ throughput _ in _ mb ; 
 memtableOperationsInMillions = cf _ def . memtable _ operations _ in _ millions ; 
 mergeShardsChance = cf _ def . merge _ shards _ chance ; 
 @ @ - 895 , 6 + 913 , 7 @ @ public final class CFMetaData 
 def . setMax _ compaction _ threshold ( cfm . maxCompactionThreshold ) ; 
 def . setRow _ cache _ save _ period _ in _ seconds ( cfm . rowCacheSavePeriodInSeconds ) ; 
 def . setKey _ cache _ save _ period _ in _ seconds ( cfm . keyCacheSavePeriodInSeconds ) ; 
 + def . setRow _ cache _ keys _ to _ save ( cfm . rowCacheKeysToSave ) ; 
 def . setMemtable _ throughput _ in _ mb ( cfm . memtableThroughputInMb ) ; 
 def . setMemtable _ operations _ in _ millions ( cfm . memtableOperationsInMillions ) ; 
 def . setMerge _ shards _ chance ( cfm . mergeShardsChance ) ; 
 @ @ - 941 , 6 + 960 , 7 @ @ public final class CFMetaData 
 def . max _ compaction _ threshold = cfm . maxCompactionThreshold ; 
 def . row _ cache _ save _ period _ in _ seconds = cfm . rowCacheSavePeriodInSeconds ; 
 def . key _ cache _ save _ period _ in _ seconds = cfm . keyCacheSavePeriodInSeconds ; 
 + def . row _ cache _ keys _ to _ save = cfm . rowCacheKeysToSave ; 
 def . memtable _ throughput _ in _ mb = cfm . memtableThroughputInMb ; 
 def . memtable _ operations _ in _ millions = cfm . memtableOperationsInMillions ; 
 def . merge _ shards _ chance = cfm . mergeShardsChance ; 
 @ @ - 986 , 6 + 1006 , 7 @ @ public final class CFMetaData 
 newDef . read _ repair _ chance = def . getRead _ repair _ chance ( ) ; 
 newDef . replicate _ on _ write = def . isReplicate _ on _ write ( ) ; 
 newDef . row _ cache _ save _ period _ in _ seconds = def . getRow _ cache _ save _ period _ in _ seconds ( ) ; 
 + newDef . row _ cache _ keys _ to _ save = def . getRow _ cache _ keys _ to _ save ( ) ; 
 newDef . row _ cache _ size = def . getRow _ cache _ size ( ) ; 
 newDef . subcomparator _ type = def . getSubcomparator _ type ( ) ; 
 newDef . merge _ shards _ chance = def . getMerge _ shards _ chance ( ) ; 
 @ @ - 1120 , 6 + 1141 , 7 @ @ public final class CFMetaData 
 . append ( " maxCompactionThreshold " , maxCompactionThreshold ) 
 . append ( " rowCacheSavePeriodInSeconds " , rowCacheSavePeriodInSeconds ) 
 . append ( " keyCacheSavePeriodInSeconds " , keyCacheSavePeriodInSeconds ) 
 + . append ( " rowCacheKeysToSave " , rowCacheKeysToSave ) 
 . append ( " memtableThroughputInMb " , memtableThroughputInMb ) 
 . append ( " memtableOperationsInMillions " , memtableOperationsInMillions ) 
 . append ( " mergeShardsChance " , mergeShardsChance ) 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index 6d932d8 . . 69e2c4b 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 142 , 6 + 142 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 private volatile DefaultDouble memops ; 
 private volatile DefaultInteger rowCacheSaveInSeconds ; 
 private volatile DefaultInteger keyCacheSaveInSeconds ; 
 + private volatile DefaultInteger rowCacheKeysToSave ; 
 
 / * * Lock to allow migrations to block all flushing , so we can be sure not to write orphaned data files * / 
 public final Lock flushLock = new ReentrantLock ( ) ; 
 @ @ - 195 , 11 + 196 , 13 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 rowCacheSaveInSeconds = new DefaultInteger ( metadata . getRowCacheSavePeriodInSeconds ( ) ) ; 
 if ( ! keyCacheSaveInSeconds . isModified ( ) ) 
 keyCacheSaveInSeconds = new DefaultInteger ( metadata . getKeyCacheSavePeriodInSeconds ( ) ) ; 
 + if ( ! rowCacheKeysToSave . isModified ( ) ) 
 + rowCacheKeysToSave = new DefaultInteger ( metadata . getRowCacheKeysToSave ( ) ) ; 
 
 compactionStrategy = metadata . createCompactionStrategyInstance ( this ) ; 
 
 updateCacheSizes ( ) ; 
 - scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) ) ; 
 + scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) , rowCacheKeysToSave . value ( ) ) ; 
 
 / / figure out what needs to be added and dropped . 
 / / future : if / when we have modifiable settings for secondary indexes , they ' ll need to be handled here . 
 @ @ - 241 , 6 + 244 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 this . memops = new DefaultDouble ( metadata . getMemtableOperationsInMillions ( ) ) ; 
 this . rowCacheSaveInSeconds = new DefaultInteger ( metadata . getRowCacheSavePeriodInSeconds ( ) ) ; 
 this . keyCacheSaveInSeconds = new DefaultInteger ( metadata . getKeyCacheSavePeriodInSeconds ( ) ) ; 
 + this . rowCacheKeysToSave = new DefaultInteger ( metadata . getRowCacheKeysToSave ( ) ) ; 
 this . partitioner = partitioner ; 
 fileIndexGenerator . set ( generation ) ; 
 
 @ @ - 542 , 13 + 546 , 13 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 table . name , 
 columnFamily ) ) ; 
 
 - scheduleCacheSaving ( metadata . getRowCacheSavePeriodInSeconds ( ) , metadata . getKeyCacheSavePeriodInSeconds ( ) ) ; 
 + scheduleCacheSaving ( metadata . getRowCacheSavePeriodInSeconds ( ) , metadata . getKeyCacheSavePeriodInSeconds ( ) , metadata . getRowCacheKeysToSave ( ) ) ; 
 } 
 
 - public void scheduleCacheSaving ( int rowCacheSavePeriodInSeconds , int keyCacheSavePeriodInSeconds ) 
 + public void scheduleCacheSaving ( int rowCacheSavePeriodInSeconds , int keyCacheSavePeriodInSeconds , int rowCacheKeysToSave ) 
 { 
 - keyCache . scheduleSaving ( keyCacheSavePeriodInSeconds ) ; 
 - rowCache . scheduleSaving ( rowCacheSavePeriodInSeconds ) ; 
 + keyCache . scheduleSaving ( keyCacheSavePeriodInSeconds , Integer . MAX _ VALUE ) ; 
 + rowCache . scheduleSaving ( rowCacheSavePeriodInSeconds , rowCacheKeysToSave ) ; 
 } 
 
 public AutoSavingCache < Pair < Descriptor , DecoratedKey > , Long > getKeyCache ( ) 
 @ @ - 1985 , 6 + 1989 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 - get / set memtime 
 - get / set rowCacheSavePeriodInSeconds 
 - get / set keyCacheSavePeriodInSeconds 
 + - get / set rowCacheKeysToSave 
 * / 
 
 public AbstractCompactionStrategy getCompactionStrategy ( ) 
 @ @ - 2056 , 7 + 2061 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 throw new RuntimeException ( " RowCacheSavePeriodInSeconds must be non - negative . " ) ; 
 } 
 this . rowCacheSaveInSeconds . set ( rcspis ) ; 
 - scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) ) ; 
 + scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) , rowCacheKeysToSave . value ( ) ) ; 
 } 
 
 public int getKeyCacheSavePeriodInSeconds ( ) 
 @ @ - 2070 , 7 + 2075 , 17 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 throw new RuntimeException ( " KeyCacheSavePeriodInSeconds must be non - negative . " ) ; 
 } 
 this . keyCacheSaveInSeconds . set ( kcspis ) ; 
 - scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) ) ; 
 + scheduleCacheSaving ( rowCacheSaveInSeconds . value ( ) , keyCacheSaveInSeconds . value ( ) , rowCacheKeysToSave . value ( ) ) ; 
 + } 
 + 
 + public int getRowCacheKeysToSave ( ) 
 + { 
 + return rowCacheKeysToSave . value ( ) ; 
 + } 
 + 
 + public void setRowCacheKeysToSave ( int keysToSave ) 
 + { 
 + this . rowCacheKeysToSave . set ( keysToSave ) ; 
 } 
 / / End JMX get / set . 
 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStoreMBean . java b / src / java / org / apache / cassandra / db / ColumnFamilyStoreMBean . java 
 index 4b63c37 . . 616e101 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStoreMBean . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStoreMBean . java 
 @ @ - 231 , 4 + 231 , 7 @ @ public interface ColumnFamilyStoreMBean 
 
 public int getKeyCacheSavePeriodInSeconds ( ) ; 
 public void setKeyCacheSavePeriodInSeconds ( int kcspis ) ; 
 + 
 + public int getRowCacheKeysToSave ( ) ; 
 + public void setRowCacheKeysToSave ( int keysToSave ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / migration / Migration . java b / src / java / org / apache / cassandra / db / migration / Migration . java 
 index 37d39a2 . . bdf2943 100644 
 - - - a / src / java / org / apache / cassandra / db / migration / Migration . java 
 + + + b / src / java / org / apache / cassandra / db / migration / Migration . java 
 @ @ - 159 , 6 + 159 , 7 @ @ public abstract class Migration 
 assert ! StorageService . instance . isClientMode ( ) ; 
 assert column ! = null ; 
 MigrationManager . announce ( column ) ; 
 + passiveAnnounce ( ) ; / / keeps gossip in sync w / what we just told everyone 
 } 
 
 public final void passiveAnnounce ( ) 
 diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index c04aa7c . . a27c09c 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 2216 , 8 + 2216 , 8 @ @ public class StorageService implements IEndpointStateChangeSubscriber , StorageSe 
 logger _ . debug ( " submitting cache saves " ) ; 
 for ( ColumnFamilyStore cfs : ColumnFamilyStore . all ( ) ) 
 { 
 - futures . add ( cfs . keyCache . submitWrite ( ) ) ; 
 - futures . add ( cfs . rowCache . submitWrite ( ) ) ; 
 + futures . add ( cfs . keyCache . submitWrite ( - 1 ) ) ; 
 + futures . add ( cfs . rowCache . submitWrite ( cfs . getRowCacheKeysToSave ( ) ) ) ; 
 } 
 FBUtilities . waitOnFutures ( futures ) ; 
 logger _ . debug ( " cache saves completed " ) ; 
 diff - - git a / test / unit / org / apache / cassandra / db / KeyCacheTest . java b / test / unit / org / apache / cassandra / db / KeyCacheTest . java 
 index 5279163 . . cd1fe2c 100644 
 - - - a / test / unit / org / apache / cassandra / db / KeyCacheTest . java 
 + + + b / test / unit / org / apache / cassandra / db / KeyCacheTest . java 
 @ @ - 84 , 7 + 84 , 7 @ @ public class KeyCacheTest extends CleanupHelper 
 } 
 
 / / force the cache to disk 
 - store . keyCache . submitWrite ( ) . get ( ) ; 
 + store . keyCache . submitWrite ( Integer . MAX _ VALUE ) . get ( ) ; 
 
 / / empty the cache again to make sure values came from disk 
 store . invalidateKeyCache ( ) ; 
 diff - - git a / test / unit / org / apache / cassandra / db / RowCacheTest . java b / test / unit / org / apache / cassandra / db / RowCacheTest . java 
 index 3ab0d22 . . b494ca5 100644 
 - - - a / test / unit / org / apache / cassandra / db / RowCacheTest . java 
 + + + b / test / unit / org / apache / cassandra / db / RowCacheTest . java 
 @ @ - 114 , 6 + 114 , 19 @ @ public class RowCacheTest extends CleanupHelper 
 @ Test 
 public void testRowCacheLoad ( ) throws Exception 
 { 
 + rowCacheLoad ( 100 , 100 , Integer . MAX _ VALUE ) ; 
 + } 
 + 
 + 
 + @ Test 
 + public void testRowCachePartialLoad ( ) throws Exception 
 + { 
 + rowCacheLoad ( 100 , 50 , 50 ) ; 
 + } 
 + 
 + 
 + public void rowCacheLoad ( int totalKeys , int expectedKeys , int keysToSave ) throws Exception 
 + { 
 CompactionManager . instance . disableAutoCompaction ( ) ; 
 
 ColumnFamilyStore store = Table . open ( KEYSPACE ) . getColumnFamilyStore ( COLUMN _ FAMILY _ WITH _ CACHE ) ; 
 @ @ - 123 , 12 + 136 , 12 @ @ public class RowCacheTest extends CleanupHelper 
 assert store . getRowCacheSize ( ) = = 0 ; 
 
 / / insert data and fill the cache 
 - insertData ( KEYSPACE , COLUMN _ FAMILY _ WITH _ CACHE , 0 , 100 ) ; 
 - readData ( KEYSPACE , COLUMN _ FAMILY _ WITH _ CACHE , 0 , 100 ) ; 
 - assert store . getRowCacheSize ( ) = = 100 ; 
 + insertData ( KEYSPACE , COLUMN _ FAMILY _ WITH _ CACHE , 0 , totalKeys ) ; 
 + readData ( KEYSPACE , COLUMN _ FAMILY _ WITH _ CACHE , 0 , totalKeys ) ; 
 + assert store . getRowCacheSize ( ) = = totalKeys ; 
 
 / / force the cache to disk 
 - store . rowCache . submitWrite ( ) . get ( ) ; 
 + store . rowCache . submitWrite ( keysToSave ) . get ( ) ; 
 
 / / empty the cache again to make sure values came from disk 
 store . invalidateRowCache ( ) ; 
 @ @ - 136 , 12 + 149 , 28 @ @ public class RowCacheTest extends CleanupHelper 
 
 / / load the cache from disk 
 store . initCaches ( ) ; 
 - assert store . getRowCacheSize ( ) = = 100 ; 
 + assert store . getRowCacheSize ( ) = = expectedKeys ; 
 
 - for ( int i = 0 ; i < 100 ; i + + ) 
 + / / If we are loading less than the entire cache back , we can ' t 
 + / / be sure which rows we will get if all rows are equally hot . 
 + int nulls = 0 ; 
 + int nonNull = 0 ; 
 + for ( int i = 0 ; i < expectedKeys ; i + + ) 
 { 
 - / / verify the correct data was found 
 - assert store . getRawCachedRow ( Util . dk ( " key " + i ) ) . getColumn ( ByteBufferUtil . bytes ( " col " + i ) ) . value ( ) . equals ( ByteBufferUtil . bytes ( " val " + i ) ) ; 
 + / / verify the correct data was found when we expect to get 
 + / / back the entire cache . Otherwise only make assertions 
 + / / about how many items are read back . 
 + ColumnFamily row = store . getRawCachedRow ( Util . dk ( " key " + i ) ) ; 
 + if ( expectedKeys = = totalKeys ) 
 + { 
 + assert row ! = null ; 
 + assert row . getColumn ( ByteBufferUtil . bytes ( " col " + i ) ) . value ( ) . equals ( ByteBufferUtil . bytes ( " val " + i ) ) ; 
 + } 
 + if ( row = = null ) 
 + nulls + + ; 
 + else 
 + nonNull + + ; 
 } 
 + assert nulls + nonNull = = expectedKeys ; 
 } 
 }
