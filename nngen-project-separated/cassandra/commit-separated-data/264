BLEU SCORE: 0.04266709328925954

TEST MSG: Improve TRUNCATE performance
GENERATED MSG: identify and blacklist corrupted SSTables from future compactions

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 4a45469 . . d6423b4 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 3 . 0 . 15 <nl> + * Improve TRUNCATE performance ( CASSANDRA - 13909 ) <nl> * Implement short read protection on partition boundaries ( CASSANDRA - 13595 ) <nl> * Fix ISE thrown by UPI . Serializer . hasNext ( ) for some SELECT queries ( CASSANDRA - 13911 ) <nl> * Filter header only commit logs before recovery ( CASSANDRA - 13918 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / Helpers . java b / src / java / org / apache / cassandra / db / lifecycle / Helpers . java <nl> index f9555f4 . . b9adc4b 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / Helpers . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / Helpers . java <nl> @ @ - 141 , 6 + 141 , 21 @ @ class Helpers <nl> return accumulate ; <nl> } <nl> <nl> + static Throwable prepareForBulkObsoletion ( Iterable < SSTableReader > readers , LogTransaction txnLogs , List < LogTransaction . Obsoletion > obsoletions , Throwable accumulate ) <nl> + { <nl> + try <nl> + { <nl> + for ( Map . Entry < SSTableReader , LogTransaction . SSTableTidier > entry : txnLogs . bulkObsoletion ( readers ) . entrySet ( ) ) <nl> + obsoletions . add ( new LogTransaction . Obsoletion ( entry . getKey ( ) , entry . getValue ( ) ) ) ; <nl> + } <nl> + catch ( Throwable t ) <nl> + { <nl> + accumulate = Throwables . merge ( accumulate , t ) ; <nl> + } <nl> + <nl> + return accumulate ; <nl> + } <nl> + <nl> static Throwable abortObsoletion ( List < LogTransaction . Obsoletion > obsoletions , Throwable accumulate ) <nl> { <nl> if ( obsoletions = = null | | obsoletions . isEmpty ( ) ) <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogFile . java b / src / java / org / apache / cassandra / db / lifecycle / LogFile . java <nl> index da5bb39 . . be26163 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / LogFile . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / LogFile . java <nl> @ @ - 37 , 6 + 37 , 7 @ @ import org . slf4j . LoggerFactory ; <nl> import org . apache . cassandra . db . compaction . OperationType ; <nl> import org . apache . cassandra . db . lifecycle . LogRecord . Type ; <nl> import org . apache . cassandra . io . sstable . SSTable ; <nl> + import org . apache . cassandra . io . sstable . format . SSTableReader ; <nl> import org . apache . cassandra . io . sstable . format . big . BigFormat ; <nl> import org . apache . cassandra . utils . Throwables ; <nl> <nl> @ @ - 284 , 6 + 285 , 25 @ @ final class LogFile implements AutoCloseable <nl> throw new IllegalStateException ( ) ; <nl> } <nl> <nl> + public void addAll ( Type type , Iterable < SSTableReader > toBulkAdd ) <nl> + { <nl> + for ( LogRecord record : makeRecords ( type , toBulkAdd ) ) <nl> + if ( ! addRecord ( record ) ) <nl> + throw new IllegalStateException ( ) ; <nl> + } <nl> + <nl> + private Collection < LogRecord > makeRecords ( Type type , Iterable < SSTableReader > tables ) <nl> + { <nl> + assert type = = Type . ADD | | type = = Type . REMOVE ; <nl> + <nl> + for ( SSTableReader sstable : tables ) <nl> + { <nl> + File folder = sstable . descriptor . directory ; <nl> + replicas . maybeCreateReplica ( folder , getFileName ( folder ) , records ) ; <nl> + } <nl> + return LogRecord . make ( type , tables ) ; <nl> + } <nl> + <nl> private LogRecord makeRecord ( Type type , SSTable table ) <nl> { <nl> assert type = = Type . ADD | | type = = Type . REMOVE ; <nl> @ @ - 414 , 4 + 434 , 9 @ @ final class LogFile implements AutoCloseable <nl> { <nl> return records ; <nl> } <nl> + <nl> + public boolean isEmpty ( ) <nl> + { <nl> + return records . isEmpty ( ) ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java b / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java <nl> index ac6d6d0 . . a322ea1 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java <nl> @ @ - 21 , 6 + 21 , 7 @ @ <nl> package org . apache . cassandra . db . lifecycle ; <nl> <nl> import java . io . File ; <nl> + import java . io . FilenameFilter ; <nl> import java . nio . file . Path ; <nl> import java . nio . file . Paths ; <nl> import java . util . * ; <nl> @ @ - 30 , 7 + 31 , 9 @ @ import java . util . stream . Collectors ; <nl> import java . util . zip . CRC32 ; <nl> <nl> import org . apache . cassandra . io . sstable . Component ; <nl> + import org . apache . cassandra . io . sstable . Descriptor ; <nl> import org . apache . cassandra . io . sstable . SSTable ; <nl> + import org . apache . cassandra . io . sstable . format . SSTableReader ; <nl> import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . utils . FBUtilities ; <nl> <nl> @ @ - 151 , 10 + 154 , 35 @ @ final class LogRecord <nl> / / there is no separator after the generation number , and this would cause files of sstables with <nl> / / a higher generation number that starts with the same number , to be incorrectly classified as files <nl> / / of this record sstable <nl> - String absoluteTablePath = FileUtils . getCanonicalPath ( table . descriptor . baseFilename ( ) + Component . separator ) ; <nl> + String absoluteTablePath = absolutePath ( table . descriptor . baseFilename ( ) ) ; <nl> return make ( type , getExistingFiles ( absoluteTablePath ) , table . getAllFilePaths ( ) . size ( ) , absoluteTablePath ) ; <nl> } <nl> <nl> + public static Collection < LogRecord > make ( Type type , Iterable < SSTableReader > tables ) <nl> + { <nl> + / / contains a mapping from sstable absolute path ( everything up until the ' Data ' / ' Index ' / etc part of the filename ) to the sstable <nl> + Map < String , SSTable > absolutePaths = new HashMap < > ( ) ; <nl> + for ( SSTableReader table : tables ) <nl> + absolutePaths . put ( absolutePath ( table . descriptor . baseFilename ( ) ) , table ) ; <nl> + <nl> + / / maps sstable base file name to the actual files on disk <nl> + Map < String , List < File > > existingFiles = getExistingFiles ( absolutePaths . keySet ( ) ) ; <nl> + List < LogRecord > records = new ArrayList < > ( existingFiles . size ( ) ) ; <nl> + for ( Map . Entry < String , List < File > > entry : existingFiles . entrySet ( ) ) <nl> + { <nl> + List < File > filesOnDisk = entry . getValue ( ) ; <nl> + String baseFileName = entry . getKey ( ) ; <nl> + SSTable sstable = absolutePaths . get ( baseFileName ) ; <nl> + records . add ( make ( type , filesOnDisk , sstable . getAllFilePaths ( ) . size ( ) , baseFileName ) ) ; <nl> + } <nl> + return records ; <nl> + } <nl> + <nl> + private static String absolutePath ( String baseFilename ) <nl> + { <nl> + return FileUtils . getCanonicalPath ( baseFilename + Component . separator ) ; <nl> + } <nl> + <nl> public LogRecord withExistingFiles ( ) <nl> { <nl> return make ( type , getExistingFiles ( ) , 0 , absolutePath . get ( ) ) ; <nl> @ @ - 275 , 6 + 303 , 41 @ @ final class LogRecord <nl> return files = = null ? Collections . emptyList ( ) : Arrays . asList ( files ) ; <nl> } <nl> <nl> + / * * <nl> + * absoluteFilePaths contains full file parts up to the component name <nl> + * <nl> + * this method finds all files on disk beginning with any of the paths in absoluteFilePaths <nl> + * @ return a map from absoluteFilePath to actual file on disk . <nl> + * / <nl> + public static Map < String , List < File > > getExistingFiles ( Set < String > absoluteFilePaths ) <nl> + { <nl> + Set < File > uniqueDirectories = absoluteFilePaths . stream ( ) . map ( path - > Paths . get ( path ) . getParent ( ) . toFile ( ) ) . collect ( Collectors . toSet ( ) ) ; <nl> + Map < String , List < File > > fileMap = new HashMap < > ( ) ; <nl> + FilenameFilter ff = ( dir , name ) - > { <nl> + Descriptor descriptor = null ; <nl> + try <nl> + { <nl> + descriptor = Descriptor . fromFilename ( dir , name ) . left ; <nl> + } <nl> + catch ( Throwable t ) <nl> + { / / ignored - if we can ' t parse the filename , just skip the file <nl> + } <nl> + <nl> + String absolutePath = descriptor ! = null ? absolutePath ( descriptor . baseFilename ( ) ) : null ; <nl> + if ( absolutePath ! = null & & absoluteFilePaths . contains ( absolutePath ) ) <nl> + fileMap . computeIfAbsent ( absolutePath , k - > new ArrayList < > ( ) ) . add ( new File ( dir , name ) ) ; <nl> + <nl> + return false ; <nl> + } ; <nl> + <nl> + / / populate the file map : <nl> + for ( File f : uniqueDirectories ) <nl> + f . listFiles ( ff ) ; <nl> + <nl> + return fileMap ; <nl> + } <nl> + <nl> + <nl> public boolean isFinal ( ) <nl> { <nl> return type . isFinal ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java b / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java <nl> index 350477c . . 6599142 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java <nl> @ @ - 163 , 6 + 163 , 22 @ @ class LogTransaction extends Transactional . AbstractTransactional implements Tran <nl> return new SSTableTidier ( reader , false , this ) ; <nl> } <nl> <nl> + Map < SSTableReader , SSTableTidier > bulkObsoletion ( Iterable < SSTableReader > sstables ) <nl> + { <nl> + if ( ! txnFile . isEmpty ( ) ) <nl> + throw new IllegalStateException ( " Bad state when doing bulk obsoletions " ) ; <nl> + <nl> + txnFile . addAll ( Type . REMOVE , sstables ) ; <nl> + Map < SSTableReader , SSTableTidier > tidiers = new HashMap < > ( ) ; <nl> + for ( SSTableReader sstable : sstables ) <nl> + { <nl> + if ( tracker ! = null ) <nl> + tracker . notifyDeleting ( sstable ) ; <nl> + tidiers . put ( sstable , new SSTableTidier ( sstable , false , this ) ) ; <nl> + } <nl> + return tidiers ; <nl> + } <nl> + <nl> OperationType type ( ) <nl> { <nl> return txnFile . type ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / lifecycle / Tracker . java b / src / java / org / apache / cassandra / db / lifecycle / Tracker . java <nl> index 9feaa3e . . d281278 100644 <nl> - - - a / src / java / org / apache / cassandra / db / lifecycle / Tracker . java <nl> + + + b / src / java / org / apache / cassandra / db / lifecycle / Tracker . java <nl> @ @ - 245 , 7 + 245 , 7 @ @ public class Tracker <nl> / / It is important that any method accepting / returning a Throwable never throws an exception , and does its best <nl> / / to complete the instructions given to it <nl> List < LogTransaction . Obsoletion > obsoletions = new ArrayList < > ( ) ; <nl> - accumulate = prepareForObsoletion ( removed , txnLogs , obsoletions , accumulate ) ; <nl> + accumulate = prepareForBulkObsoletion ( removed , txnLogs , obsoletions , accumulate ) ; <nl> try <nl> { <nl> txnLogs . finish ( ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / lifecycle / HelpersTest . java b / test / unit / org / apache / cassandra / db / lifecycle / HelpersTest . java <nl> index 3549523 . . 1b8e265 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / lifecycle / HelpersTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / lifecycle / HelpersTest . java <nl> @ @ - 18 , 14 + 18 , 21 @ @ <nl> * / <nl> package org . apache . cassandra . db . lifecycle ; <nl> <nl> + import java . io . File ; <nl> + import java . io . IOException ; <nl> + import java . nio . file . Files ; <nl> import java . util . ArrayList ; <nl> + import java . util . Collection ; <nl> + import java . util . HashSet ; <nl> import java . util . List ; <nl> import java . util . Map ; <nl> import java . util . Set ; <nl> + import java . util . stream . Collectors ; <nl> <nl> import com . google . common . collect . ImmutableMap ; <nl> import com . google . common . collect . ImmutableSet ; <nl> import com . google . common . collect . Lists ; <nl> + import com . google . common . collect . Sets ; <nl> <nl> import org . junit . BeforeClass ; <nl> import org . junit . Test ; <nl> @ @ - 158 , 12 + 165 , 23 @ @ public class HelpersTest <nl> @ Test <nl> public void testMarkObsolete ( ) <nl> { <nl> + testMarkObsoleteHelper ( false ) ; <nl> + } <nl> + @ Test <nl> + public void testBulkMarkObsolete ( ) <nl> + { <nl> + testMarkObsoleteHelper ( true ) ; <nl> + } <nl> + <nl> + public void testMarkObsoleteHelper ( boolean bulk ) <nl> + { <nl> ColumnFamilyStore cfs = MockSchema . newCFS ( ) ; <nl> LogTransaction txnLogs = new LogTransaction ( OperationType . UNKNOWN ) ; <nl> Iterable < SSTableReader > readers = Lists . newArrayList ( MockSchema . sstable ( 1 , cfs ) , MockSchema . sstable ( 2 , cfs ) ) ; <nl> + Iterable < SSTableReader > readersToKeep = Lists . newArrayList ( MockSchema . sstable ( 3 , cfs ) , MockSchema . sstable ( 4 , cfs ) ) ; <nl> <nl> List < LogTransaction . Obsoletion > obsoletions = new ArrayList < > ( ) ; <nl> - Assert . assertNull ( Helpers . prepareForObsoletion ( readers , txnLogs , obsoletions , null ) ) ; <nl> + Assert . assertNull ( bulk ? Helpers . prepareForBulkObsoletion ( readers , txnLogs , obsoletions , null ) : Helpers . prepareForObsoletion ( readers , txnLogs , obsoletions , null ) ) ; <nl> assertNotNull ( obsoletions ) ; <nl> assertEquals ( 2 , obsoletions . size ( ) ) ; <nl> <nl> @ @ - 172 , 9 + 190 , 47 @ @ public class HelpersTest <nl> for ( SSTableReader reader : readers ) <nl> Assert . assertTrue ( reader . isMarkedCompacted ( ) ) ; <nl> <nl> + for ( SSTableReader reader : readersToKeep ) <nl> + Assert . assertFalse ( reader . isMarkedCompacted ( ) ) ; <nl> + <nl> accumulate = Helpers . markObsolete ( obsoletions , null ) ; <nl> assertNotNull ( accumulate ) ; <nl> <nl> txnLogs . finish ( ) ; <nl> } <nl> + <nl> + @ Test <nl> + public void compareBulkAndNormalObsolete ( ) throws IOException <nl> + { <nl> + ColumnFamilyStore cfs = MockSchema . newCFS ( ) ; <nl> + LogTransaction txnLogs = new LogTransaction ( OperationType . UNKNOWN ) ; <nl> + LogTransaction txnLogs2 = new LogTransaction ( OperationType . UNKNOWN ) ; <nl> + <nl> + Collection < SSTableReader > readers = Lists . newArrayList ( MockSchema . sstable ( 1 , cfs ) , MockSchema . sstable ( 2 , cfs ) ) ; <nl> + / / add a few readers that should not be removed : <nl> + Lists . newArrayList ( MockSchema . sstable ( 3 , cfs ) , MockSchema . sstable ( 4 , cfs ) ) ; <nl> + <nl> + List < LogTransaction . Obsoletion > normalObsoletions = new ArrayList < > ( ) ; <nl> + List < LogTransaction . Obsoletion > bulkObsoletions = new ArrayList < > ( ) ; <nl> + <nl> + Assert . assertNull ( Helpers . prepareForBulkObsoletion ( readers , txnLogs , normalObsoletions , null ) ) ; <nl> + Assert . assertNull ( Helpers . prepareForObsoletion ( readers , txnLogs2 , bulkObsoletions , null ) ) ; <nl> + <nl> + assertEquals ( Sets . newHashSet ( readers ) , normalObsoletions . stream ( ) . map ( obs - > obs . reader ) . collect ( Collectors . toSet ( ) ) ) ; <nl> + assertEquals ( Sets . newHashSet ( readers ) , bulkObsoletions . stream ( ) . map ( obs - > obs . reader ) . collect ( Collectors . toSet ( ) ) ) ; <nl> + <nl> + Set < String > normalLogRecords = new HashSet < > ( ) ; <nl> + Set < String > bulkLogRecords = new HashSet < > ( ) ; <nl> + <nl> + for ( File f : txnLogs . logFiles ( ) ) <nl> + Files . lines ( f . toPath ( ) ) . forEach ( bulkLogRecords : : add ) ; <nl> + for ( File f : txnLogs2 . logFiles ( ) ) <nl> + Files . lines ( f . toPath ( ) ) . forEach ( normalLogRecords : : add ) ; <nl> + <nl> + Assert . assertEquals ( readers . size ( ) , normalLogRecords . size ( ) ) ; <nl> + Assert . assertEquals ( bulkLogRecords , normalLogRecords ) ; <nl> + <nl> + txnLogs . finish ( ) ; <nl> + txnLogs2 . finish ( ) ; <nl> + } <nl> }
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 6a2a56e . . 591ae9f 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 6 + 1 , 6 @ @ <nl> 1 . 1 . 1 - dev <nl> * optimize commitlog checksumming ( CASSANDRA - 3610 ) <nl> - <nl> + * identify and blacklist corrupted SSTables from future compactions ( CASSANDRA - 2261 ) <nl> <nl> 1 . 1 - dev <nl> * start hint replay as soon as FD notifies that the target is back up <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java <nl> index cd9f04d . . d4c7a47 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java <nl> @ @ - 72 , 6 + 72 , 7 @ @ class IndexedSliceReader extends AbstractIterator < IColumn > implements IColumnIte <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new IOError ( e ) ; <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java <nl> index 2d791c4 . . 7471778 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java <nl> @ @ - 70 , 6 + 70 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new IOError ( e ) ; <nl> } <nl> finally <nl> @ @ - 90 , 6 + 91 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement <nl> } <nl> catch ( IOException ioe ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new IOError ( ioe ) ; <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableSliceIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableSliceIterator . java <nl> index 8e374b3 . . 5e6aff0 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableSliceIterator . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableSliceIterator . java <nl> @ @ - 56 , 6 + 56 , 7 @ @ public class SSTableSliceIterator implements IColumnIterator <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new IOError ( e ) ; <nl> } <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java <nl> index 2a1e5cf . . e54e9bf 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java <nl> @ @ - 58 , 6 + 58 , 7 @ @ class SimpleSliceReader extends AbstractIterator < IColumn > implements IColumnIter <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new IOError ( e ) ; <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java <nl> index bb84d1d . . 5e0a911 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java <nl> @ @ - 17 , 9 + 17 , 7 @ @ <nl> * / <nl> package org . apache . cassandra . db . compaction ; <nl> <nl> - import java . util . Collection ; <nl> - import java . util . Map ; <nl> - import java . util . Set ; <nl> + import java . util . * ; <nl> import java . util . concurrent . TimeUnit ; <nl> <nl> import org . apache . cassandra . db . ColumnFamilyStore ; <nl> @ @ - 107 , 4 + 105 , 24 @ @ public abstract class AbstractCompactionStrategy <nl> * is going to be expensive <nl> * / <nl> public abstract boolean isKeyExistenceExpensive ( Set < ? extends SSTable > sstablesToIgnore ) ; <nl> + <nl> + / * * <nl> + * Filters SSTables that are to be blacklisted from the given collection <nl> + * <nl> + * @ param originalCandidates The collection to check for blacklisted SSTables <nl> + * <nl> + * @ return list of the SSTables with blacklisted ones filtered out <nl> + * / <nl> + public static List < SSTableReader > filterSuspectSSTables ( Collection < SSTableReader > originalCandidates ) <nl> + { <nl> + List < SSTableReader > filteredCandidates = new ArrayList < SSTableReader > ( ) ; <nl> + <nl> + for ( SSTableReader candidate : originalCandidates ) <nl> + { <nl> + if ( ! candidate . isMarkedSuspect ( ) ) <nl> + filteredCandidates . add ( candidate ) ; <nl> + } <nl> + <nl> + return filteredCandidates ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / LeveledManifest . java b / src / java / org / apache / cassandra / db / compaction / LeveledManifest . java <nl> index 069d289 . . 47b489d 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / LeveledManifest . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / LeveledManifest . java <nl> @ @ - 40 , 6 + 40 , 8 @ @ import org . codehaus . jackson . JsonGenerator ; <nl> import org . codehaus . jackson . JsonNode ; <nl> import org . codehaus . jackson . map . ObjectMapper ; <nl> <nl> + import static org . apache . cassandra . db . compaction . AbstractCompactionStrategy . filterSuspectSSTables ; <nl> + <nl> public class LeveledManifest <nl> { <nl> private static final Logger logger = LoggerFactory . getLogger ( LeveledManifest . class ) ; <nl> @ @ - 245 , 15 + 247 , 39 @ @ public class LeveledManifest <nl> if ( score > 1 . 001 | | i = = 0 ) <nl> { <nl> Collection < SSTableReader > candidates = getCandidatesFor ( i ) ; <nl> + <nl> if ( logger . isDebugEnabled ( ) ) <nl> logger . debug ( " Compaction candidates for L { } are { } " , i , toString ( candidates ) ) ; <nl> - return candidates ; <nl> + <nl> + / / check if have any SSTables marked as suspected , <nl> + / / saves us filter time when no SSTables are suspects <nl> + return hasSuspectSSTables ( candidates ) <nl> + ? filterSuspectSSTables ( candidates ) <nl> + : candidates ; <nl> } <nl> } <nl> <nl> return Collections . emptyList ( ) ; <nl> } <nl> <nl> + / * * <nl> + * Go through candidates collection and check if any of the SSTables are marked as suspected . <nl> + * <nl> + * @ param candidates The SSTable collection to examine . <nl> + * <nl> + * @ return true if collection has at least one SSTable marked as suspected , false otherwise . <nl> + * / <nl> + private boolean hasSuspectSSTables ( Collection < SSTableReader > candidates ) <nl> + { <nl> + for ( SSTableReader candidate : candidates ) <nl> + { <nl> + if ( candidate . isMarkedSuspect ( ) ) <nl> + return true ; <nl> + } <nl> + <nl> + return false ; <nl> + } <nl> + <nl> public int getLevelSize ( int i ) <nl> { <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java <nl> index 043e301 . . 97396e4 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java <nl> @ @ - 54 , 7 + 54 , 8 @ @ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy <nl> return null ; <nl> } <nl> <nl> - List < List < SSTableReader > > buckets = getBuckets ( createSSTableAndLengthPairs ( cfs . getUncompactingSSTables ( ) ) , minSSTableSize ) ; <nl> + Set < SSTableReader > candidates = cfs . getUncompactingSSTables ( ) ; <nl> + List < List < SSTableReader > > buckets = getBuckets ( createSSTableAndLengthPairs ( filterSuspectSSTables ( candidates ) ) , minSSTableSize ) ; <nl> updateEstimatedCompactionsByTasks ( buckets ) ; <nl> <nl> List < List < SSTableReader > > prunedBuckets = new ArrayList < List < SSTableReader > > ( ) ; <nl> @ @ - 101 , 7 + 102 , 7 @ @ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy <nl> <nl> public AbstractCompactionTask getMaximalTask ( final int gcBefore ) <nl> { <nl> - return cfs . getSSTables ( ) . isEmpty ( ) ? null : new CompactionTask ( cfs , cfs . getSSTables ( ) , gcBefore ) ; <nl> + return cfs . getSSTables ( ) . isEmpty ( ) ? null : new CompactionTask ( cfs , filterSuspectSSTables ( cfs . getSSTables ( ) ) , gcBefore ) ; <nl> } <nl> <nl> public AbstractCompactionTask getUserDefinedTask ( Collection < SSTableReader > sstables , final int gcBefore ) <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableBoundedScanner . java b / src / java / org / apache / cassandra / io / sstable / SSTableBoundedScanner . java <nl> index ccadb30 . . d69eb16 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableBoundedScanner . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableBoundedScanner . java <nl> @ @ - 48 , 6 + 48 , 7 @ @ public class SSTableBoundedScanner extends SSTableScanner <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new RuntimeException ( e ) ; <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java b / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java <nl> index ee88d94 . . bc16f91 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java <nl> @ @ - 147 , 6 + 147 , 7 @ @ public class SSTableIdentityIterator implements Comparable < SSTableIdentityIterat <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new IOError ( e ) ; <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> index c674c0c . . 0728e18 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> @ @ - 90 , 6 + 90 , 7 @ @ public class SSTableReader extends SSTable <nl> / / technically isCompacted is not necessary since it should never be unreferenced unless it is also compacted , <nl> / / but it seems like a good extra layer of protection against reference counting bugs to not delete data based on that alone <nl> private final AtomicBoolean isCompacted = new AtomicBoolean ( false ) ; <nl> + private final AtomicBoolean isSuspect = new AtomicBoolean ( false ) ; <nl> private final SSTableDeletingTask deletingTask ; <nl> <nl> private final SSTableMetadata sstableMetadata ; <nl> @ @ - 711 , 6 + 712 , 7 @ @ public class SSTableReader extends SSTable <nl> } <nl> catch ( IOException e ) <nl> { <nl> + markSuspect ( ) ; <nl> throw new IOError ( e ) ; <nl> } <nl> finally <nl> @ @ - 797 , 6 + 799 , 19 @ @ public class SSTableReader extends SSTable <nl> return true ; <nl> } <nl> <nl> + public void markSuspect ( ) <nl> + { <nl> + if ( logger . isDebugEnabled ( ) ) <nl> + logger . debug ( " Marking " + getFilename ( ) + " as a suspect for blacklisting . " ) ; <nl> + <nl> + isSuspect . getAndSet ( true ) ; <nl> + } <nl> + <nl> + public boolean isMarkedSuspect ( ) <nl> + { <nl> + return isSuspect . get ( ) ; <nl> + } <nl> + <nl> / * * <nl> * <nl> * @ param filter filter to use when reading the columns <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java b / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java <nl> index 87ff96c . . f7b52b5 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java <nl> @ @ - 55 , 6 + 55 , 7 @ @ public class SSTableScanner implements CloseableIterator < IColumnIterator > <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new IOError ( e ) ; <nl> } <nl> this . sstable = sstable ; <nl> @ @ - 72 , 6 + 73 , 7 @ @ public class SSTableScanner implements CloseableIterator < IColumnIterator > <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new IOError ( e ) ; <nl> } <nl> this . sstable = sstable ; <nl> @ @ - 98 , 6 + 100 , 7 @ @ public class SSTableScanner implements CloseableIterator < IColumnIterator > <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new RuntimeException ( " corrupt sstable " , e ) ; <nl> } <nl> } <nl> @ @ - 152 , 6 + 155 , 7 @ @ public class SSTableScanner implements CloseableIterator < IColumnIterator > <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new RuntimeException ( e ) ; <nl> } <nl> } <nl> @ @ - 183 , 6 + 187 , 7 @ @ public class SSTableScanner implements CloseableIterator < IColumnIterator > <nl> } <nl> catch ( IOException e ) <nl> { <nl> + sstable . markSuspect ( ) ; <nl> throw new RuntimeException ( SSTableScanner . this + " failed to provide next columns from " + this , e ) ; <nl> } <nl> } <nl> diff - - git a / test / unit / org / apache / cassandra / db / compaction / CompactionsTest . java b / test / unit / org / apache / cassandra / db / compaction / CompactionsTest . java <nl> index ff6636d . . 23a2657 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / compaction / CompactionsTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / compaction / CompactionsTest . java <nl> @ @ - 18 , 7 + 18 , 7 @ @ <nl> * / <nl> package org . apache . cassandra . db . compaction ; <nl> <nl> - import java . io . IOException ; <nl> + import java . io . * ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . ArrayList ; <nl> import java . util . HashSet ; <nl> @ @ - 30 , 6 + 30 , 7 @ @ import java . util . concurrent . Future ; <nl> <nl> import org . junit . Test ; <nl> import static junit . framework . Assert . assertEquals ; <nl> + import static junit . framework . Assert . assertNotNull ; <nl> <nl> import org . apache . cassandra . CleanupHelper ; <nl> import org . apache . cassandra . Util ; <nl> @ @ - 38 , 6 + 39 , 7 @ @ import org . apache . cassandra . db . * ; <nl> import org . apache . cassandra . db . filter . QueryFilter ; <nl> import org . apache . cassandra . db . filter . QueryPath ; <nl> import org . apache . cassandra . io . sstable . * ; <nl> + import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . apache . cassandra . utils . FBUtilities ; <nl> <nl> @ @ - 46 , 6 + 48 , 18 @ @ public class CompactionsTest extends CleanupHelper <nl> public static final String TABLE1 = " Keyspace1 " ; <nl> <nl> @ Test <nl> + public void testBlacklistingWithSizeTieredCompactionStrategy ( ) throws Exception <nl> + { <nl> + testBlacklisting ( SizeTieredCompactionStrategy . class . getCanonicalName ( ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testBlacklistingWithLeveledCompactionStrategy ( ) throws Exception <nl> + { <nl> + testBlacklisting ( LeveledCompactionStrategy . class . getCanonicalName ( ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> public void testStandardColumnCompactions ( ) throws IOException , ExecutionException , InterruptedException <nl> { <nl> / / this test does enough rows to force multiple block indexes to be used <nl> @ @ - 83 , 6 + 97 , 7 @ @ public class CompactionsTest extends CleanupHelper <nl> <nl> / / make sure max timestamp of compacted sstables is recorded properly after compaction . <nl> assertMaxTimestamp ( store , maxTimestampExpected ) ; <nl> + store . truncate ( ) ; <nl> } <nl> <nl> <nl> @ @ - 269 , 4 + 284 , 100 @ @ public class CompactionsTest extends CleanupHelper <nl> cf = store . getColumnFamily ( filter ) ; <nl> assert cf = = null | | cf . isEmpty ( ) : " should be empty : " + cf ; <nl> } <nl> + <nl> + public void testBlacklisting ( String compactionStrategy ) throws Exception <nl> + { <nl> + / / this test does enough rows to force multiple block indexes to be used <nl> + Table table = Table . open ( TABLE1 ) ; <nl> + final ColumnFamilyStore store = table . getColumnFamilyStore ( " Standard1 " ) ; <nl> + <nl> + final int ROWS _ PER _ SSTABLE = 10 ; <nl> + final int SSTABLES = DatabaseDescriptor . getIndexInterval ( ) * 2 / ROWS _ PER _ SSTABLE ; <nl> + <nl> + store . setCompactionStrategyClass ( compactionStrategy ) ; <nl> + <nl> + / / disable compaction while flushing <nl> + store . disableAutoCompaction ( ) ; <nl> + / / test index corruption <nl> + / / now create a few new SSTables <nl> + long maxTimestampExpected = Long . MIN _ VALUE ; <nl> + Set < DecoratedKey > inserted = new HashSet < DecoratedKey > ( ) ; <nl> + for ( int j = 0 ; j < SSTABLES ; j + + ) <nl> + { <nl> + for ( int i = 0 ; i < ROWS _ PER _ SSTABLE ; i + + ) <nl> + { <nl> + DecoratedKey key = Util . dk ( String . valueOf ( i % 2 ) ) ; <nl> + RowMutation rm = new RowMutation ( TABLE1 , key . key ) ; <nl> + long timestamp = j * ROWS _ PER _ SSTABLE + i ; <nl> + rm . add ( new QueryPath ( " Standard1 " , null , ByteBufferUtil . bytes ( String . valueOf ( i / 2 ) ) ) , <nl> + ByteBufferUtil . EMPTY _ BYTE _ BUFFER , <nl> + timestamp ) ; <nl> + maxTimestampExpected = Math . max ( timestamp , maxTimestampExpected ) ; <nl> + rm . apply ( ) ; <nl> + inserted . add ( key ) ; <nl> + } <nl> + store . forceBlockingFlush ( ) ; <nl> + assertMaxTimestamp ( store , maxTimestampExpected ) ; <nl> + assertEquals ( inserted . toString ( ) , inserted . size ( ) , Util . getRangeSlice ( store ) . size ( ) ) ; <nl> + } <nl> + <nl> + Collection < SSTableReader > sstables = store . getSSTables ( ) ; <nl> + int currentSSTable = 0 ; <nl> + int sstablesToCorrupt = 8 ; <nl> + <nl> + / / corrupt first ' sstablesToCorrupt ' SSTables <nl> + for ( SSTableReader sstable : sstables ) <nl> + { <nl> + if ( currentSSTable + 1 > sstablesToCorrupt ) <nl> + break ; <nl> + <nl> + RandomAccessFile raf = null ; <nl> + <nl> + try <nl> + { <nl> + raf = new RandomAccessFile ( sstable . getFilename ( ) , " rw " ) ; <nl> + assertNotNull ( raf ) ; <nl> + raf . write ( 0xFFFFFF ) ; <nl> + } <nl> + finally <nl> + { <nl> + FileUtils . closeQuietly ( raf ) ; <nl> + } <nl> + <nl> + currentSSTable + + ; <nl> + } <nl> + <nl> + int failures = 0 ; <nl> + <nl> + / / close error output steam to avoid printing ton of useless RuntimeException <nl> + System . err . close ( ) ; <nl> + <nl> + try <nl> + { <nl> + / / in case something will go wrong we don ' t want to loop forever using for ( ; ; ) <nl> + for ( int i = 0 ; i < sstables . size ( ) ; i + + ) <nl> + { <nl> + try <nl> + { <nl> + store . forceMajorCompaction ( ) ; <nl> + } <nl> + catch ( Exception e ) <nl> + { <nl> + failures + + ; <nl> + continue ; <nl> + } <nl> + <nl> + assertEquals ( sstablesToCorrupt + 1 , store . getSSTables ( ) . size ( ) ) ; <nl> + break ; <nl> + } <nl> + } <nl> + finally <nl> + { <nl> + System . setErr ( new PrintStream ( new ByteArrayOutputStream ( ) ) ) ; <nl> + } <nl> + <nl> + <nl> + store . truncate ( ) ; <nl> + assertEquals ( failures , sstablesToCorrupt ) ; <nl> + } <nl> }

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 4a45469 . . d6423b4 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 3 . 0 . 15 
 + * Improve TRUNCATE performance ( CASSANDRA - 13909 ) 
 * Implement short read protection on partition boundaries ( CASSANDRA - 13595 ) 
 * Fix ISE thrown by UPI . Serializer . hasNext ( ) for some SELECT queries ( CASSANDRA - 13911 ) 
 * Filter header only commit logs before recovery ( CASSANDRA - 13918 ) 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / Helpers . java b / src / java / org / apache / cassandra / db / lifecycle / Helpers . java 
 index f9555f4 . . b9adc4b 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / Helpers . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / Helpers . java 
 @ @ - 141 , 6 + 141 , 21 @ @ class Helpers 
 return accumulate ; 
 } 
 
 + static Throwable prepareForBulkObsoletion ( Iterable < SSTableReader > readers , LogTransaction txnLogs , List < LogTransaction . Obsoletion > obsoletions , Throwable accumulate ) 
 + { 
 + try 
 + { 
 + for ( Map . Entry < SSTableReader , LogTransaction . SSTableTidier > entry : txnLogs . bulkObsoletion ( readers ) . entrySet ( ) ) 
 + obsoletions . add ( new LogTransaction . Obsoletion ( entry . getKey ( ) , entry . getValue ( ) ) ) ; 
 + } 
 + catch ( Throwable t ) 
 + { 
 + accumulate = Throwables . merge ( accumulate , t ) ; 
 + } 
 + 
 + return accumulate ; 
 + } 
 + 
 static Throwable abortObsoletion ( List < LogTransaction . Obsoletion > obsoletions , Throwable accumulate ) 
 { 
 if ( obsoletions = = null | | obsoletions . isEmpty ( ) ) 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogFile . java b / src / java / org / apache / cassandra / db / lifecycle / LogFile . java 
 index da5bb39 . . be26163 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / LogFile . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / LogFile . java 
 @ @ - 37 , 6 + 37 , 7 @ @ import org . slf4j . LoggerFactory ; 
 import org . apache . cassandra . db . compaction . OperationType ; 
 import org . apache . cassandra . db . lifecycle . LogRecord . Type ; 
 import org . apache . cassandra . io . sstable . SSTable ; 
 + import org . apache . cassandra . io . sstable . format . SSTableReader ; 
 import org . apache . cassandra . io . sstable . format . big . BigFormat ; 
 import org . apache . cassandra . utils . Throwables ; 
 
 @ @ - 284 , 6 + 285 , 25 @ @ final class LogFile implements AutoCloseable 
 throw new IllegalStateException ( ) ; 
 } 
 
 + public void addAll ( Type type , Iterable < SSTableReader > toBulkAdd ) 
 + { 
 + for ( LogRecord record : makeRecords ( type , toBulkAdd ) ) 
 + if ( ! addRecord ( record ) ) 
 + throw new IllegalStateException ( ) ; 
 + } 
 + 
 + private Collection < LogRecord > makeRecords ( Type type , Iterable < SSTableReader > tables ) 
 + { 
 + assert type = = Type . ADD | | type = = Type . REMOVE ; 
 + 
 + for ( SSTableReader sstable : tables ) 
 + { 
 + File folder = sstable . descriptor . directory ; 
 + replicas . maybeCreateReplica ( folder , getFileName ( folder ) , records ) ; 
 + } 
 + return LogRecord . make ( type , tables ) ; 
 + } 
 + 
 private LogRecord makeRecord ( Type type , SSTable table ) 
 { 
 assert type = = Type . ADD | | type = = Type . REMOVE ; 
 @ @ - 414 , 4 + 434 , 9 @ @ final class LogFile implements AutoCloseable 
 { 
 return records ; 
 } 
 + 
 + public boolean isEmpty ( ) 
 + { 
 + return records . isEmpty ( ) ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java b / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java 
 index ac6d6d0 . . a322ea1 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / LogRecord . java 
 @ @ - 21 , 6 + 21 , 7 @ @ 
 package org . apache . cassandra . db . lifecycle ; 
 
 import java . io . File ; 
 + import java . io . FilenameFilter ; 
 import java . nio . file . Path ; 
 import java . nio . file . Paths ; 
 import java . util . * ; 
 @ @ - 30 , 7 + 31 , 9 @ @ import java . util . stream . Collectors ; 
 import java . util . zip . CRC32 ; 
 
 import org . apache . cassandra . io . sstable . Component ; 
 + import org . apache . cassandra . io . sstable . Descriptor ; 
 import org . apache . cassandra . io . sstable . SSTable ; 
 + import org . apache . cassandra . io . sstable . format . SSTableReader ; 
 import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . utils . FBUtilities ; 
 
 @ @ - 151 , 10 + 154 , 35 @ @ final class LogRecord 
 / / there is no separator after the generation number , and this would cause files of sstables with 
 / / a higher generation number that starts with the same number , to be incorrectly classified as files 
 / / of this record sstable 
 - String absoluteTablePath = FileUtils . getCanonicalPath ( table . descriptor . baseFilename ( ) + Component . separator ) ; 
 + String absoluteTablePath = absolutePath ( table . descriptor . baseFilename ( ) ) ; 
 return make ( type , getExistingFiles ( absoluteTablePath ) , table . getAllFilePaths ( ) . size ( ) , absoluteTablePath ) ; 
 } 
 
 + public static Collection < LogRecord > make ( Type type , Iterable < SSTableReader > tables ) 
 + { 
 + / / contains a mapping from sstable absolute path ( everything up until the ' Data ' / ' Index ' / etc part of the filename ) to the sstable 
 + Map < String , SSTable > absolutePaths = new HashMap < > ( ) ; 
 + for ( SSTableReader table : tables ) 
 + absolutePaths . put ( absolutePath ( table . descriptor . baseFilename ( ) ) , table ) ; 
 + 
 + / / maps sstable base file name to the actual files on disk 
 + Map < String , List < File > > existingFiles = getExistingFiles ( absolutePaths . keySet ( ) ) ; 
 + List < LogRecord > records = new ArrayList < > ( existingFiles . size ( ) ) ; 
 + for ( Map . Entry < String , List < File > > entry : existingFiles . entrySet ( ) ) 
 + { 
 + List < File > filesOnDisk = entry . getValue ( ) ; 
 + String baseFileName = entry . getKey ( ) ; 
 + SSTable sstable = absolutePaths . get ( baseFileName ) ; 
 + records . add ( make ( type , filesOnDisk , sstable . getAllFilePaths ( ) . size ( ) , baseFileName ) ) ; 
 + } 
 + return records ; 
 + } 
 + 
 + private static String absolutePath ( String baseFilename ) 
 + { 
 + return FileUtils . getCanonicalPath ( baseFilename + Component . separator ) ; 
 + } 
 + 
 public LogRecord withExistingFiles ( ) 
 { 
 return make ( type , getExistingFiles ( ) , 0 , absolutePath . get ( ) ) ; 
 @ @ - 275 , 6 + 303 , 41 @ @ final class LogRecord 
 return files = = null ? Collections . emptyList ( ) : Arrays . asList ( files ) ; 
 } 
 
 + / * * 
 + * absoluteFilePaths contains full file parts up to the component name 
 + * 
 + * this method finds all files on disk beginning with any of the paths in absoluteFilePaths 
 + * @ return a map from absoluteFilePath to actual file on disk . 
 + * / 
 + public static Map < String , List < File > > getExistingFiles ( Set < String > absoluteFilePaths ) 
 + { 
 + Set < File > uniqueDirectories = absoluteFilePaths . stream ( ) . map ( path - > Paths . get ( path ) . getParent ( ) . toFile ( ) ) . collect ( Collectors . toSet ( ) ) ; 
 + Map < String , List < File > > fileMap = new HashMap < > ( ) ; 
 + FilenameFilter ff = ( dir , name ) - > { 
 + Descriptor descriptor = null ; 
 + try 
 + { 
 + descriptor = Descriptor . fromFilename ( dir , name ) . left ; 
 + } 
 + catch ( Throwable t ) 
 + { / / ignored - if we can ' t parse the filename , just skip the file 
 + } 
 + 
 + String absolutePath = descriptor ! = null ? absolutePath ( descriptor . baseFilename ( ) ) : null ; 
 + if ( absolutePath ! = null & & absoluteFilePaths . contains ( absolutePath ) ) 
 + fileMap . computeIfAbsent ( absolutePath , k - > new ArrayList < > ( ) ) . add ( new File ( dir , name ) ) ; 
 + 
 + return false ; 
 + } ; 
 + 
 + / / populate the file map : 
 + for ( File f : uniqueDirectories ) 
 + f . listFiles ( ff ) ; 
 + 
 + return fileMap ; 
 + } 
 + 
 + 
 public boolean isFinal ( ) 
 { 
 return type . isFinal ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java b / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java 
 index 350477c . . 6599142 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / LogTransaction . java 
 @ @ - 163 , 6 + 163 , 22 @ @ class LogTransaction extends Transactional . AbstractTransactional implements Tran 
 return new SSTableTidier ( reader , false , this ) ; 
 } 
 
 + Map < SSTableReader , SSTableTidier > bulkObsoletion ( Iterable < SSTableReader > sstables ) 
 + { 
 + if ( ! txnFile . isEmpty ( ) ) 
 + throw new IllegalStateException ( " Bad state when doing bulk obsoletions " ) ; 
 + 
 + txnFile . addAll ( Type . REMOVE , sstables ) ; 
 + Map < SSTableReader , SSTableTidier > tidiers = new HashMap < > ( ) ; 
 + for ( SSTableReader sstable : sstables ) 
 + { 
 + if ( tracker ! = null ) 
 + tracker . notifyDeleting ( sstable ) ; 
 + tidiers . put ( sstable , new SSTableTidier ( sstable , false , this ) ) ; 
 + } 
 + return tidiers ; 
 + } 
 + 
 OperationType type ( ) 
 { 
 return txnFile . type ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / lifecycle / Tracker . java b / src / java / org / apache / cassandra / db / lifecycle / Tracker . java 
 index 9feaa3e . . d281278 100644 
 - - - a / src / java / org / apache / cassandra / db / lifecycle / Tracker . java 
 + + + b / src / java / org / apache / cassandra / db / lifecycle / Tracker . java 
 @ @ - 245 , 7 + 245 , 7 @ @ public class Tracker 
 / / It is important that any method accepting / returning a Throwable never throws an exception , and does its best 
 / / to complete the instructions given to it 
 List < LogTransaction . Obsoletion > obsoletions = new ArrayList < > ( ) ; 
 - accumulate = prepareForObsoletion ( removed , txnLogs , obsoletions , accumulate ) ; 
 + accumulate = prepareForBulkObsoletion ( removed , txnLogs , obsoletions , accumulate ) ; 
 try 
 { 
 txnLogs . finish ( ) ; 
 diff - - git a / test / unit / org / apache / cassandra / db / lifecycle / HelpersTest . java b / test / unit / org / apache / cassandra / db / lifecycle / HelpersTest . java 
 index 3549523 . . 1b8e265 100644 
 - - - a / test / unit / org / apache / cassandra / db / lifecycle / HelpersTest . java 
 + + + b / test / unit / org / apache / cassandra / db / lifecycle / HelpersTest . java 
 @ @ - 18 , 14 + 18 , 21 @ @ 
 * / 
 package org . apache . cassandra . db . lifecycle ; 
 
 + import java . io . File ; 
 + import java . io . IOException ; 
 + import java . nio . file . Files ; 
 import java . util . ArrayList ; 
 + import java . util . Collection ; 
 + import java . util . HashSet ; 
 import java . util . List ; 
 import java . util . Map ; 
 import java . util . Set ; 
 + import java . util . stream . Collectors ; 
 
 import com . google . common . collect . ImmutableMap ; 
 import com . google . common . collect . ImmutableSet ; 
 import com . google . common . collect . Lists ; 
 + import com . google . common . collect . Sets ; 
 
 import org . junit . BeforeClass ; 
 import org . junit . Test ; 
 @ @ - 158 , 12 + 165 , 23 @ @ public class HelpersTest 
 @ Test 
 public void testMarkObsolete ( ) 
 { 
 + testMarkObsoleteHelper ( false ) ; 
 + } 
 + @ Test 
 + public void testBulkMarkObsolete ( ) 
 + { 
 + testMarkObsoleteHelper ( true ) ; 
 + } 
 + 
 + public void testMarkObsoleteHelper ( boolean bulk ) 
 + { 
 ColumnFamilyStore cfs = MockSchema . newCFS ( ) ; 
 LogTransaction txnLogs = new LogTransaction ( OperationType . UNKNOWN ) ; 
 Iterable < SSTableReader > readers = Lists . newArrayList ( MockSchema . sstable ( 1 , cfs ) , MockSchema . sstable ( 2 , cfs ) ) ; 
 + Iterable < SSTableReader > readersToKeep = Lists . newArrayList ( MockSchema . sstable ( 3 , cfs ) , MockSchema . sstable ( 4 , cfs ) ) ; 
 
 List < LogTransaction . Obsoletion > obsoletions = new ArrayList < > ( ) ; 
 - Assert . assertNull ( Helpers . prepareForObsoletion ( readers , txnLogs , obsoletions , null ) ) ; 
 + Assert . assertNull ( bulk ? Helpers . prepareForBulkObsoletion ( readers , txnLogs , obsoletions , null ) : Helpers . prepareForObsoletion ( readers , txnLogs , obsoletions , null ) ) ; 
 assertNotNull ( obsoletions ) ; 
 assertEquals ( 2 , obsoletions . size ( ) ) ; 
 
 @ @ - 172 , 9 + 190 , 47 @ @ public class HelpersTest 
 for ( SSTableReader reader : readers ) 
 Assert . assertTrue ( reader . isMarkedCompacted ( ) ) ; 
 
 + for ( SSTableReader reader : readersToKeep ) 
 + Assert . assertFalse ( reader . isMarkedCompacted ( ) ) ; 
 + 
 accumulate = Helpers . markObsolete ( obsoletions , null ) ; 
 assertNotNull ( accumulate ) ; 
 
 txnLogs . finish ( ) ; 
 } 
 + 
 + @ Test 
 + public void compareBulkAndNormalObsolete ( ) throws IOException 
 + { 
 + ColumnFamilyStore cfs = MockSchema . newCFS ( ) ; 
 + LogTransaction txnLogs = new LogTransaction ( OperationType . UNKNOWN ) ; 
 + LogTransaction txnLogs2 = new LogTransaction ( OperationType . UNKNOWN ) ; 
 + 
 + Collection < SSTableReader > readers = Lists . newArrayList ( MockSchema . sstable ( 1 , cfs ) , MockSchema . sstable ( 2 , cfs ) ) ; 
 + / / add a few readers that should not be removed : 
 + Lists . newArrayList ( MockSchema . sstable ( 3 , cfs ) , MockSchema . sstable ( 4 , cfs ) ) ; 
 + 
 + List < LogTransaction . Obsoletion > normalObsoletions = new ArrayList < > ( ) ; 
 + List < LogTransaction . Obsoletion > bulkObsoletions = new ArrayList < > ( ) ; 
 + 
 + Assert . assertNull ( Helpers . prepareForBulkObsoletion ( readers , txnLogs , normalObsoletions , null ) ) ; 
 + Assert . assertNull ( Helpers . prepareForObsoletion ( readers , txnLogs2 , bulkObsoletions , null ) ) ; 
 + 
 + assertEquals ( Sets . newHashSet ( readers ) , normalObsoletions . stream ( ) . map ( obs - > obs . reader ) . collect ( Collectors . toSet ( ) ) ) ; 
 + assertEquals ( Sets . newHashSet ( readers ) , bulkObsoletions . stream ( ) . map ( obs - > obs . reader ) . collect ( Collectors . toSet ( ) ) ) ; 
 + 
 + Set < String > normalLogRecords = new HashSet < > ( ) ; 
 + Set < String > bulkLogRecords = new HashSet < > ( ) ; 
 + 
 + for ( File f : txnLogs . logFiles ( ) ) 
 + Files . lines ( f . toPath ( ) ) . forEach ( bulkLogRecords : : add ) ; 
 + for ( File f : txnLogs2 . logFiles ( ) ) 
 + Files . lines ( f . toPath ( ) ) . forEach ( normalLogRecords : : add ) ; 
 + 
 + Assert . assertEquals ( readers . size ( ) , normalLogRecords . size ( ) ) ; 
 + Assert . assertEquals ( bulkLogRecords , normalLogRecords ) ; 
 + 
 + txnLogs . finish ( ) ; 
 + txnLogs2 . finish ( ) ; 
 + } 
 }

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 6a2a56e . . 591ae9f 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 6 + 1 , 6 @ @ 
 1 . 1 . 1 - dev 
 * optimize commitlog checksumming ( CASSANDRA - 3610 ) 
 - 
 + * identify and blacklist corrupted SSTables from future compactions ( CASSANDRA - 2261 ) 
 
 1 . 1 - dev 
 * start hint replay as soon as FD notifies that the target is back up 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java 
 index cd9f04d . . d4c7a47 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / IndexedSliceReader . java 
 @ @ - 72 , 6 + 72 , 7 @ @ class IndexedSliceReader extends AbstractIterator < IColumn > implements IColumnIte 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new IOError ( e ) ; 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java 
 index 2d791c4 . . 7471778 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableNamesIterator . java 
 @ @ - 70 , 6 + 70 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new IOError ( e ) ; 
 } 
 finally 
 @ @ - 90 , 6 + 91 , 7 @ @ public class SSTableNamesIterator extends SimpleAbstractColumnIterator implement 
 } 
 catch ( IOException ioe ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new IOError ( ioe ) ; 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableSliceIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableSliceIterator . java 
 index 8e374b3 . . 5e6aff0 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableSliceIterator . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableSliceIterator . java 
 @ @ - 56 , 6 + 56 , 7 @ @ public class SSTableSliceIterator implements IColumnIterator 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new IOError ( e ) ; 
 } 
 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java 
 index 2a1e5cf . . e54e9bf 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / SimpleSliceReader . java 
 @ @ - 58 , 6 + 58 , 7 @ @ class SimpleSliceReader extends AbstractIterator < IColumn > implements IColumnIter 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new IOError ( e ) ; 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java 
 index bb84d1d . . 5e0a911 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java 
 @ @ - 17 , 9 + 17 , 7 @ @ 
 * / 
 package org . apache . cassandra . db . compaction ; 
 
 - import java . util . Collection ; 
 - import java . util . Map ; 
 - import java . util . Set ; 
 + import java . util . * ; 
 import java . util . concurrent . TimeUnit ; 
 
 import org . apache . cassandra . db . ColumnFamilyStore ; 
 @ @ - 107 , 4 + 105 , 24 @ @ public abstract class AbstractCompactionStrategy 
 * is going to be expensive 
 * / 
 public abstract boolean isKeyExistenceExpensive ( Set < ? extends SSTable > sstablesToIgnore ) ; 
 + 
 + / * * 
 + * Filters SSTables that are to be blacklisted from the given collection 
 + * 
 + * @ param originalCandidates The collection to check for blacklisted SSTables 
 + * 
 + * @ return list of the SSTables with blacklisted ones filtered out 
 + * / 
 + public static List < SSTableReader > filterSuspectSSTables ( Collection < SSTableReader > originalCandidates ) 
 + { 
 + List < SSTableReader > filteredCandidates = new ArrayList < SSTableReader > ( ) ; 
 + 
 + for ( SSTableReader candidate : originalCandidates ) 
 + { 
 + if ( ! candidate . isMarkedSuspect ( ) ) 
 + filteredCandidates . add ( candidate ) ; 
 + } 
 + 
 + return filteredCandidates ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / LeveledManifest . java b / src / java / org / apache / cassandra / db / compaction / LeveledManifest . java 
 index 069d289 . . 47b489d 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / LeveledManifest . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / LeveledManifest . java 
 @ @ - 40 , 6 + 40 , 8 @ @ import org . codehaus . jackson . JsonGenerator ; 
 import org . codehaus . jackson . JsonNode ; 
 import org . codehaus . jackson . map . ObjectMapper ; 
 
 + import static org . apache . cassandra . db . compaction . AbstractCompactionStrategy . filterSuspectSSTables ; 
 + 
 public class LeveledManifest 
 { 
 private static final Logger logger = LoggerFactory . getLogger ( LeveledManifest . class ) ; 
 @ @ - 245 , 15 + 247 , 39 @ @ public class LeveledManifest 
 if ( score > 1 . 001 | | i = = 0 ) 
 { 
 Collection < SSTableReader > candidates = getCandidatesFor ( i ) ; 
 + 
 if ( logger . isDebugEnabled ( ) ) 
 logger . debug ( " Compaction candidates for L { } are { } " , i , toString ( candidates ) ) ; 
 - return candidates ; 
 + 
 + / / check if have any SSTables marked as suspected , 
 + / / saves us filter time when no SSTables are suspects 
 + return hasSuspectSSTables ( candidates ) 
 + ? filterSuspectSSTables ( candidates ) 
 + : candidates ; 
 } 
 } 
 
 return Collections . emptyList ( ) ; 
 } 
 
 + / * * 
 + * Go through candidates collection and check if any of the SSTables are marked as suspected . 
 + * 
 + * @ param candidates The SSTable collection to examine . 
 + * 
 + * @ return true if collection has at least one SSTable marked as suspected , false otherwise . 
 + * / 
 + private boolean hasSuspectSSTables ( Collection < SSTableReader > candidates ) 
 + { 
 + for ( SSTableReader candidate : candidates ) 
 + { 
 + if ( candidate . isMarkedSuspect ( ) ) 
 + return true ; 
 + } 
 + 
 + return false ; 
 + } 
 + 
 public int getLevelSize ( int i ) 
 { 
 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java 
 index 043e301 . . 97396e4 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java 
 @ @ - 54 , 7 + 54 , 8 @ @ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy 
 return null ; 
 } 
 
 - List < List < SSTableReader > > buckets = getBuckets ( createSSTableAndLengthPairs ( cfs . getUncompactingSSTables ( ) ) , minSSTableSize ) ; 
 + Set < SSTableReader > candidates = cfs . getUncompactingSSTables ( ) ; 
 + List < List < SSTableReader > > buckets = getBuckets ( createSSTableAndLengthPairs ( filterSuspectSSTables ( candidates ) ) , minSSTableSize ) ; 
 updateEstimatedCompactionsByTasks ( buckets ) ; 
 
 List < List < SSTableReader > > prunedBuckets = new ArrayList < List < SSTableReader > > ( ) ; 
 @ @ - 101 , 7 + 102 , 7 @ @ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy 
 
 public AbstractCompactionTask getMaximalTask ( final int gcBefore ) 
 { 
 - return cfs . getSSTables ( ) . isEmpty ( ) ? null : new CompactionTask ( cfs , cfs . getSSTables ( ) , gcBefore ) ; 
 + return cfs . getSSTables ( ) . isEmpty ( ) ? null : new CompactionTask ( cfs , filterSuspectSSTables ( cfs . getSSTables ( ) ) , gcBefore ) ; 
 } 
 
 public AbstractCompactionTask getUserDefinedTask ( Collection < SSTableReader > sstables , final int gcBefore ) 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableBoundedScanner . java b / src / java / org / apache / cassandra / io / sstable / SSTableBoundedScanner . java 
 index ccadb30 . . d69eb16 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableBoundedScanner . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableBoundedScanner . java 
 @ @ - 48 , 6 + 48 , 7 @ @ public class SSTableBoundedScanner extends SSTableScanner 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new RuntimeException ( e ) ; 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java b / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java 
 index ee88d94 . . bc16f91 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableIdentityIterator . java 
 @ @ - 147 , 6 + 147 , 7 @ @ public class SSTableIdentityIterator implements Comparable < SSTableIdentityIterat 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new IOError ( e ) ; 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 index c674c0c . . 0728e18 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 @ @ - 90 , 6 + 90 , 7 @ @ public class SSTableReader extends SSTable 
 / / technically isCompacted is not necessary since it should never be unreferenced unless it is also compacted , 
 / / but it seems like a good extra layer of protection against reference counting bugs to not delete data based on that alone 
 private final AtomicBoolean isCompacted = new AtomicBoolean ( false ) ; 
 + private final AtomicBoolean isSuspect = new AtomicBoolean ( false ) ; 
 private final SSTableDeletingTask deletingTask ; 
 
 private final SSTableMetadata sstableMetadata ; 
 @ @ - 711 , 6 + 712 , 7 @ @ public class SSTableReader extends SSTable 
 } 
 catch ( IOException e ) 
 { 
 + markSuspect ( ) ; 
 throw new IOError ( e ) ; 
 } 
 finally 
 @ @ - 797 , 6 + 799 , 19 @ @ public class SSTableReader extends SSTable 
 return true ; 
 } 
 
 + public void markSuspect ( ) 
 + { 
 + if ( logger . isDebugEnabled ( ) ) 
 + logger . debug ( " Marking " + getFilename ( ) + " as a suspect for blacklisting . " ) ; 
 + 
 + isSuspect . getAndSet ( true ) ; 
 + } 
 + 
 + public boolean isMarkedSuspect ( ) 
 + { 
 + return isSuspect . get ( ) ; 
 + } 
 + 
 / * * 
 * 
 * @ param filter filter to use when reading the columns 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java b / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java 
 index 87ff96c . . f7b52b5 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableScanner . java 
 @ @ - 55 , 6 + 55 , 7 @ @ public class SSTableScanner implements CloseableIterator < IColumnIterator > 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new IOError ( e ) ; 
 } 
 this . sstable = sstable ; 
 @ @ - 72 , 6 + 73 , 7 @ @ public class SSTableScanner implements CloseableIterator < IColumnIterator > 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new IOError ( e ) ; 
 } 
 this . sstable = sstable ; 
 @ @ - 98 , 6 + 100 , 7 @ @ public class SSTableScanner implements CloseableIterator < IColumnIterator > 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new RuntimeException ( " corrupt sstable " , e ) ; 
 } 
 } 
 @ @ - 152 , 6 + 155 , 7 @ @ public class SSTableScanner implements CloseableIterator < IColumnIterator > 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new RuntimeException ( e ) ; 
 } 
 } 
 @ @ - 183 , 6 + 187 , 7 @ @ public class SSTableScanner implements CloseableIterator < IColumnIterator > 
 } 
 catch ( IOException e ) 
 { 
 + sstable . markSuspect ( ) ; 
 throw new RuntimeException ( SSTableScanner . this + " failed to provide next columns from " + this , e ) ; 
 } 
 } 
 diff - - git a / test / unit / org / apache / cassandra / db / compaction / CompactionsTest . java b / test / unit / org / apache / cassandra / db / compaction / CompactionsTest . java 
 index ff6636d . . 23a2657 100644 
 - - - a / test / unit / org / apache / cassandra / db / compaction / CompactionsTest . java 
 + + + b / test / unit / org / apache / cassandra / db / compaction / CompactionsTest . java 
 @ @ - 18 , 7 + 18 , 7 @ @ 
 * / 
 package org . apache . cassandra . db . compaction ; 
 
 - import java . io . IOException ; 
 + import java . io . * ; 
 import java . nio . ByteBuffer ; 
 import java . util . ArrayList ; 
 import java . util . HashSet ; 
 @ @ - 30 , 6 + 30 , 7 @ @ import java . util . concurrent . Future ; 
 
 import org . junit . Test ; 
 import static junit . framework . Assert . assertEquals ; 
 + import static junit . framework . Assert . assertNotNull ; 
 
 import org . apache . cassandra . CleanupHelper ; 
 import org . apache . cassandra . Util ; 
 @ @ - 38 , 6 + 39 , 7 @ @ import org . apache . cassandra . db . * ; 
 import org . apache . cassandra . db . filter . QueryFilter ; 
 import org . apache . cassandra . db . filter . QueryPath ; 
 import org . apache . cassandra . io . sstable . * ; 
 + import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . apache . cassandra . utils . FBUtilities ; 
 
 @ @ - 46 , 6 + 48 , 18 @ @ public class CompactionsTest extends CleanupHelper 
 public static final String TABLE1 = " Keyspace1 " ; 
 
 @ Test 
 + public void testBlacklistingWithSizeTieredCompactionStrategy ( ) throws Exception 
 + { 
 + testBlacklisting ( SizeTieredCompactionStrategy . class . getCanonicalName ( ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testBlacklistingWithLeveledCompactionStrategy ( ) throws Exception 
 + { 
 + testBlacklisting ( LeveledCompactionStrategy . class . getCanonicalName ( ) ) ; 
 + } 
 + 
 + @ Test 
 public void testStandardColumnCompactions ( ) throws IOException , ExecutionException , InterruptedException 
 { 
 / / this test does enough rows to force multiple block indexes to be used 
 @ @ - 83 , 6 + 97 , 7 @ @ public class CompactionsTest extends CleanupHelper 
 
 / / make sure max timestamp of compacted sstables is recorded properly after compaction . 
 assertMaxTimestamp ( store , maxTimestampExpected ) ; 
 + store . truncate ( ) ; 
 } 
 
 
 @ @ - 269 , 4 + 284 , 100 @ @ public class CompactionsTest extends CleanupHelper 
 cf = store . getColumnFamily ( filter ) ; 
 assert cf = = null | | cf . isEmpty ( ) : " should be empty : " + cf ; 
 } 
 + 
 + public void testBlacklisting ( String compactionStrategy ) throws Exception 
 + { 
 + / / this test does enough rows to force multiple block indexes to be used 
 + Table table = Table . open ( TABLE1 ) ; 
 + final ColumnFamilyStore store = table . getColumnFamilyStore ( " Standard1 " ) ; 
 + 
 + final int ROWS _ PER _ SSTABLE = 10 ; 
 + final int SSTABLES = DatabaseDescriptor . getIndexInterval ( ) * 2 / ROWS _ PER _ SSTABLE ; 
 + 
 + store . setCompactionStrategyClass ( compactionStrategy ) ; 
 + 
 + / / disable compaction while flushing 
 + store . disableAutoCompaction ( ) ; 
 + / / test index corruption 
 + / / now create a few new SSTables 
 + long maxTimestampExpected = Long . MIN _ VALUE ; 
 + Set < DecoratedKey > inserted = new HashSet < DecoratedKey > ( ) ; 
 + for ( int j = 0 ; j < SSTABLES ; j + + ) 
 + { 
 + for ( int i = 0 ; i < ROWS _ PER _ SSTABLE ; i + + ) 
 + { 
 + DecoratedKey key = Util . dk ( String . valueOf ( i % 2 ) ) ; 
 + RowMutation rm = new RowMutation ( TABLE1 , key . key ) ; 
 + long timestamp = j * ROWS _ PER _ SSTABLE + i ; 
 + rm . add ( new QueryPath ( " Standard1 " , null , ByteBufferUtil . bytes ( String . valueOf ( i / 2 ) ) ) , 
 + ByteBufferUtil . EMPTY _ BYTE _ BUFFER , 
 + timestamp ) ; 
 + maxTimestampExpected = Math . max ( timestamp , maxTimestampExpected ) ; 
 + rm . apply ( ) ; 
 + inserted . add ( key ) ; 
 + } 
 + store . forceBlockingFlush ( ) ; 
 + assertMaxTimestamp ( store , maxTimestampExpected ) ; 
 + assertEquals ( inserted . toString ( ) , inserted . size ( ) , Util . getRangeSlice ( store ) . size ( ) ) ; 
 + } 
 + 
 + Collection < SSTableReader > sstables = store . getSSTables ( ) ; 
 + int currentSSTable = 0 ; 
 + int sstablesToCorrupt = 8 ; 
 + 
 + / / corrupt first ' sstablesToCorrupt ' SSTables 
 + for ( SSTableReader sstable : sstables ) 
 + { 
 + if ( currentSSTable + 1 > sstablesToCorrupt ) 
 + break ; 
 + 
 + RandomAccessFile raf = null ; 
 + 
 + try 
 + { 
 + raf = new RandomAccessFile ( sstable . getFilename ( ) , " rw " ) ; 
 + assertNotNull ( raf ) ; 
 + raf . write ( 0xFFFFFF ) ; 
 + } 
 + finally 
 + { 
 + FileUtils . closeQuietly ( raf ) ; 
 + } 
 + 
 + currentSSTable + + ; 
 + } 
 + 
 + int failures = 0 ; 
 + 
 + / / close error output steam to avoid printing ton of useless RuntimeException 
 + System . err . close ( ) ; 
 + 
 + try 
 + { 
 + / / in case something will go wrong we don ' t want to loop forever using for ( ; ; ) 
 + for ( int i = 0 ; i < sstables . size ( ) ; i + + ) 
 + { 
 + try 
 + { 
 + store . forceMajorCompaction ( ) ; 
 + } 
 + catch ( Exception e ) 
 + { 
 + failures + + ; 
 + continue ; 
 + } 
 + 
 + assertEquals ( sstablesToCorrupt + 1 , store . getSSTables ( ) . size ( ) ) ; 
 + break ; 
 + } 
 + } 
 + finally 
 + { 
 + System . setErr ( new PrintStream ( new ByteArrayOutputStream ( ) ) ) ; 
 + } 
 + 
 + 
 + store . truncate ( ) ; 
 + assertEquals ( failures , sstablesToCorrupt ) ; 
 + } 
 }
