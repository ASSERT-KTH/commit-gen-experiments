BLEU SCORE: 0.05341087579952926

TEST MSG: Fix overflow on histogram computation
GENERATED MSG: Cleanup and document EstimatedHistogram

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 5348f2f . . 89db48e 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 1 . 3 <nl> + * Fix overflow on histogram computation ( CASSANDRA - 8028 ) <nl> * Have paxos reuse the timestamp generation of normal queries ( CASSANDRA - 7801 ) <nl> <nl> 2 . 1 . 2 <nl> diff - - git a / src / java / org / apache / cassandra / metrics / ColumnFamilyMetrics . java b / src / java / org / apache / cassandra / metrics / ColumnFamilyMetrics . java <nl> index d9d3ed9 . . 2bdaf27 100644 <nl> - - - a / src / java / org / apache / cassandra / metrics / ColumnFamilyMetrics . java <nl> + + + b / src / java / org / apache / cassandra / metrics / ColumnFamilyMetrics . java <nl> @ @ - 18 , 6 + 18 , 7 @ @ <nl> package org . apache . cassandra . metrics ; <nl> <nl> import java . util . HashSet ; <nl> + import java . util . Iterator ; <nl> import java . util . Set ; <nl> import java . util . concurrent . ConcurrentMap ; <nl> import java . util . concurrent . TimeUnit ; <nl> @ @ - 146 , 6 + 147 , 46 @ @ public class ColumnFamilyMetrics <nl> * Stores all metric names created that can be used when unregistering <nl> * / <nl> public final static Set < String > all = Sets . newHashSet ( ) ; <nl> + <nl> + private interface GetHistogram <nl> + { <nl> + public EstimatedHistogram getHistogram ( SSTableReader reader ) ; <nl> + } <nl> + <nl> + private static long [ ] combineHistograms ( Iterable < SSTableReader > sstables , GetHistogram getHistogram ) <nl> + { <nl> + Iterator < SSTableReader > iterator = sstables . iterator ( ) ; <nl> + if ( ! iterator . hasNext ( ) ) <nl> + { <nl> + return new long [ 0 ] ; <nl> + } <nl> + long [ ] firstBucket = getHistogram . getHistogram ( iterator . next ( ) ) . getBuckets ( false ) ; <nl> + long [ ] values = new long [ firstBucket . length ] ; <nl> + System . arraycopy ( firstBucket , 0 , values , 0 , values . length ) ; <nl> + <nl> + while ( iterator . hasNext ( ) ) <nl> + { <nl> + long [ ] nextBucket = getHistogram . getHistogram ( iterator . next ( ) ) . getBuckets ( false ) ; <nl> + if ( nextBucket . length > values . length ) <nl> + { <nl> + long [ ] newValues = new long [ nextBucket . length ] ; <nl> + System . arraycopy ( firstBucket , 0 , newValues , 0 , firstBucket . length ) ; <nl> + for ( int i = 0 ; i < newValues . length ; i + + ) <nl> + { <nl> + newValues [ i ] + = nextBucket [ i ] ; <nl> + } <nl> + values = newValues ; <nl> + } <nl> + else <nl> + { <nl> + for ( int i = 0 ; i < values . length ; i + + ) <nl> + { <nl> + values [ i ] + = nextBucket [ i ] ; <nl> + } <nl> + } <nl> + } <nl> + return values ; <nl> + } <nl> <nl> / * * <nl> * Creates metrics for given { @ link ColumnFamilyStore } . <nl> @ @ - 219 , 28 + 260 , 26 @ @ public class ColumnFamilyMetrics <nl> { <nl> public long [ ] value ( ) <nl> { <nl> - long [ ] histogram = new long [ 90 ] ; <nl> - for ( SSTableReader sstable : cfs . getSSTables ( ) ) <nl> + return combineHistograms ( cfs . getSSTables ( ) , new GetHistogram ( ) <nl> { <nl> - long [ ] rowSize = sstable . getEstimatedRowSize ( ) . getBuckets ( false ) ; <nl> - for ( int i = 0 ; i < histogram . length ; i + + ) <nl> - histogram [ i ] + = rowSize [ i ] ; <nl> - } <nl> - return histogram ; <nl> + public EstimatedHistogram getHistogram ( SSTableReader reader ) <nl> + { <nl> + return reader . getEstimatedRowSize ( ) ; <nl> + } <nl> + } ) ; <nl> } <nl> } ) ; <nl> estimatedColumnCountHistogram = Metrics . newGauge ( factory . createMetricName ( " EstimatedColumnCountHistogram " ) , new Gauge < long [ ] > ( ) <nl> { <nl> public long [ ] value ( ) <nl> { <nl> - long [ ] histogram = new long [ 90 ] ; <nl> - for ( SSTableReader sstable : cfs . getSSTables ( ) ) <nl> + return combineHistograms ( cfs . getSSTables ( ) , new GetHistogram ( ) <nl> { <nl> - long [ ] columnSize = sstable . getEstimatedColumnCount ( ) . getBuckets ( false ) ; <nl> - for ( int i = 0 ; i < histogram . length ; i + + ) <nl> - histogram [ i ] + = columnSize [ i ] ; <nl> - } <nl> - return histogram ; <nl> + public EstimatedHistogram getHistogram ( SSTableReader reader ) <nl> + { <nl> + return reader . getEstimatedColumnCount ( ) ; <nl> + } <nl> + } ) ; <nl> } <nl> } ) ; <nl> sstablesPerReadHistogram = createColumnFamilyHistogram ( " SSTablesPerReadHistogram " , cfs . keyspace . metric . sstablesPerReadHistogram ) ; <nl> diff - - git a / src / java / org / apache / cassandra / tools / NodeTool . java b / src / java / org / apache / cassandra / tools / NodeTool . java <nl> index 39bc4fd . . c09751b 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / NodeTool . java <nl> + + + b / src / java / org / apache / cassandra / tools / NodeTool . java <nl> @ @ - 895 , 18 + 895 , 38 @ @ public class NodeTool <nl> long [ ] estimatedRowSize = ( long [ ] ) probe . getColumnFamilyMetric ( keyspace , cfname , " EstimatedRowSizeHistogram " ) ; <nl> long [ ] estimatedColumnCount = ( long [ ] ) probe . getColumnFamilyMetric ( keyspace , cfname , " EstimatedColumnCountHistogram " ) ; <nl> <nl> - long [ ] bucketOffsets = new EstimatedHistogram ( ) . getBucketOffsets ( ) ; <nl> - EstimatedHistogram rowSizeHist = new EstimatedHistogram ( bucketOffsets , estimatedRowSize ) ; <nl> - EstimatedHistogram columnCountHist = new EstimatedHistogram ( bucketOffsets , estimatedColumnCount ) ; <nl> + long [ ] rowSizeBucketOffsets = new EstimatedHistogram ( estimatedRowSize . length ) . getBucketOffsets ( ) ; <nl> + long [ ] columnCountBucketOffsets = new EstimatedHistogram ( estimatedColumnCount . length ) . getBucketOffsets ( ) ; <nl> + EstimatedHistogram rowSizeHist = new EstimatedHistogram ( rowSizeBucketOffsets , estimatedRowSize ) ; <nl> + EstimatedHistogram columnCountHist = new EstimatedHistogram ( columnCountBucketOffsets , estimatedColumnCount ) ; <nl> <nl> / / build arrays to store percentile values <nl> double [ ] estimatedRowSizePercentiles = new double [ 7 ] ; <nl> double [ ] estimatedColumnCountPercentiles = new double [ 7 ] ; <nl> double [ ] offsetPercentiles = new double [ ] { 0 . 5 , 0 . 75 , 0 . 95 , 0 . 98 , 0 . 99 } ; <nl> - for ( int i = 0 ; i < offsetPercentiles . length ; i + + ) <nl> + <nl> + if ( rowSizeHist . isOverflowed ( ) ) <nl> + { <nl> + System . err . println ( String . format ( " Row sizes are larger than % s , unable to calculate percentiles " , rowSizeBucketOffsets [ rowSizeBucketOffsets . length - 1 ] ) ) ; <nl> + for ( int i = 0 ; i < offsetPercentiles . length ; i + + ) <nl> + estimatedRowSizePercentiles [ i ] = Double . NaN ; <nl> + } <nl> + else <nl> + { <nl> + for ( int i = 0 ; i < offsetPercentiles . length ; i + + ) <nl> + estimatedRowSizePercentiles [ i ] = rowSizeHist . percentile ( offsetPercentiles [ i ] ) ; <nl> + } <nl> + <nl> + if ( columnCountHist . isOverflowed ( ) ) <nl> + { <nl> + System . err . println ( String . format ( " Column counts are larger than % s , unable to calculate percentiles " , columnCountBucketOffsets [ columnCountBucketOffsets . length - 1 ] ) ) ; <nl> + for ( int i = 0 ; i < estimatedColumnCountPercentiles . length ; i + + ) <nl> + estimatedColumnCountPercentiles [ i ] = Double . NaN ; <nl> + } <nl> + else <nl> { <nl> - estimatedRowSizePercentiles [ i ] = rowSizeHist . percentile ( offsetPercentiles [ i ] ) ; <nl> - estimatedColumnCountPercentiles [ i ] = columnCountHist . percentile ( offsetPercentiles [ i ] ) ; <nl> + for ( int i = 0 ; i < offsetPercentiles . length ; i + + ) <nl> + estimatedColumnCountPercentiles [ i ] = columnCountHist . percentile ( offsetPercentiles [ i ] ) ; <nl> } <nl> <nl> / / min value
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index e268270 . . 42f86f7 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 18 , 7 + 18 , 7 @ @ <nl> * add nodetool scrub ( CASSANDRA - 2217 ) <nl> * fix sstable2json large - row pagination ( CASSANDRA - 2188 ) <nl> * fix EOFing on requests for the last bytes in a file ( CASSANDRA - 2213 ) <nl> - * fix BRAF performance when seeking to EOF ( CASSANDRA - 2218 ) <nl> + * fix BufferedRandomAccessFile bugs ( CASSANDRA - 2218 , - 2241 ) <nl> * check for memtable flush _ after _ mins exceeded every 10s ( CASSANDRA - 2183 ) <nl> * fix cache saving on Windows ( CASSANDRA - 2207 ) <nl> * add validateSchemaAgreement call + synchronization to schema <nl> diff - - git a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java <nl> index 82d8320 . . 3d5ad19 100644 <nl> - - - a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java <nl> + + + b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java <nl> @ @ - 172 , 7 + 172 , 7 @ @ public class CommitLog <nl> <nl> for ( File file : clogs ) <nl> { <nl> - int bufferSize = ( int ) Math . min ( file . length ( ) , 32 * 1024 * 1024 ) ; <nl> + int bufferSize = ( int ) Math . min ( Math . max ( file . length ( ) , 1 ) , 32 * 1024 * 1024 ) ; <nl> BufferedRandomAccessFile reader = new BufferedRandomAccessFile ( new File ( file . getAbsolutePath ( ) ) , " r " , bufferSize , true ) ; <nl> <nl> try <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / Descriptor . java b / src / java / org / apache / cassandra / io / sstable / Descriptor . java <nl> index effeb82 . . 08d3b00 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / Descriptor . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / Descriptor . java <nl> @ @ - 76 , 8 + 76 , 8 @ @ public class Descriptor <nl> hasStringsInBloomFilter = version . compareTo ( " c " ) < 0 ; <nl> hasIntRowSize = version . compareTo ( " d " ) < 0 ; <nl> hasEncodedKeys = version . compareTo ( " e " ) < 0 ; <nl> - isLatestVersion = version . compareTo ( CURRENT _ VERSION ) = = 0 ; <nl> usesOldBloomFilter = version . compareTo ( " f " ) < 0 ; <nl> + isLatestVersion = version . compareTo ( CURRENT _ VERSION ) = = 0 ; <nl> } <nl> <nl> public String filenameFor ( Component component ) <nl> diff - - git a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java <nl> index 8059c2a . . 073ad72 100644 <nl> - - - a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java <nl> + + + b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java <nl> @ @ - 47 , 16 + 47 , 16 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> public static final int DEFAULT _ BUFFER _ SIZE = 65535 ; <nl> <nl> / / isDirty - true if this . buffer contains any un - synced bytes <nl> - / / hitEOF - true if buffer capacity is less then it ' s maximal size <nl> - private boolean isDirty , syncNeeded , hitEOF = false ; <nl> + private boolean isDirty , syncNeeded ; <nl> <nl> / / buffer which will cache file blocks <nl> - private ByteBuffer buffer ; <nl> + private byte [ ] buffer ; <nl> <nl> / / ` current ` as current position in file <nl> / / ` bufferOffset ` is the offset of the beginning of the buffer <nl> - / / ` bufferEnd ` is ` bufferOffset ` + count of bytes read from file , i . e . the lowest position we can ' t read from the buffer <nl> - private long bufferOffset , bufferEnd , current = 0 ; <nl> + / / ` validBufferBytes ` is the number of bytes in the buffer that are actually valid ; this will be LESS than buffer capacity if buffer is not full ! <nl> + private long bufferOffset , current = 0 ; <nl> + private int validBufferBytes = 0 ; <nl> <nl> / / constant , used for caching purpose , - 1 if file is open in " rw " mode <nl> / / otherwise this will hold cached file length <nl> @ @ - 118 , 11 + 118 , 11 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> / / allocating required size of the buffer <nl> if ( bufferSize < = 0 ) <nl> throw new IllegalArgumentException ( " bufferSize must be positive " ) ; <nl> - buffer = ByteBuffer . allocate ( bufferSize ) ; <nl> + buffer = new byte [ bufferSize ] ; <nl> + reBuffer ( ) ; <nl> <nl> / / if in read - only mode , caching file size <nl> fileLength = ( mode . equals ( " r " ) ) ? this . channel . size ( ) : - 1 ; <nl> - bufferEnd = reBuffer ( ) ; / / bufferBottom equals to the bytes read <nl> fd = CLibrary . getfd ( this . getFD ( ) ) ; <nl> } <nl> <nl> @ @ - 155 , 9 + 155 , 7 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> if ( channel . position ( ) ! = bufferOffset ) <nl> channel . position ( bufferOffset ) ; <nl> <nl> - int lengthToWrite = ( int ) ( bufferEnd - bufferOffset ) ; <nl> - <nl> - super . write ( buffer . array ( ) , 0 , lengthToWrite ) ; <nl> + super . write ( buffer , 0 , validBufferBytes ) ; <nl> <nl> if ( skipCache ) <nl> { <nl> @ @ - 167 , 7 + 165 , 7 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> / / so we continue to clear pages we don ' t need from the first <nl> / / offset we see <nl> / / periodically we update this starting offset <nl> - bytesSinceCacheFlush + = lengthToWrite ; <nl> + bytesSinceCacheFlush + = validBufferBytes ; <nl> <nl> if ( bufferOffset < minBufferOffset ) <nl> minBufferOffset = bufferOffset ; <nl> @ @ - 185 , 66 + 183 , 53 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> } <nl> } <nl> <nl> - private long reBuffer ( ) throws IOException <nl> + private void reBuffer ( ) throws IOException <nl> { <nl> flush ( ) ; / / synchronizing buffer and file on disk <nl> - buffer . clear ( ) ; <nl> - bufferOffset = current ; <nl> <nl> + bufferOffset = current ; <nl> if ( bufferOffset > = channel . size ( ) ) <nl> { <nl> - buffer . rewind ( ) ; <nl> - bufferEnd = bufferOffset ; <nl> - hitEOF = true ; <nl> - <nl> - return 0 ; <nl> + validBufferBytes = 0 ; <nl> + return ; <nl> } <nl> <nl> if ( bufferOffset < minBufferOffset ) <nl> minBufferOffset = bufferOffset ; <nl> <nl> channel . position ( bufferOffset ) ; / / setting channel position <nl> - long bytesRead = channel . read ( buffer ) ; / / reading from that position <nl> - <nl> - hitEOF = ( bytesRead < buffer . capacity ( ) ) ; / / buffer is not fully loaded with <nl> - / / data <nl> - bufferEnd = bufferOffset + bytesRead ; <nl> - <nl> - buffer . rewind ( ) ; <nl> - <nl> - bytesSinceCacheFlush + = bytesRead ; <nl> + int read = 0 ; <nl> + while ( read < buffer . length ) <nl> + { <nl> + int n = super . read ( buffer , read , buffer . length - read ) ; <nl> + if ( n < 0 ) <nl> + break ; <nl> + read + = n ; <nl> + } <nl> + validBufferBytes = read ; <nl> <nl> + bytesSinceCacheFlush + = read ; <nl> if ( skipCache & & bytesSinceCacheFlush > = MAX _ BYTES _ IN _ PAGE _ CACHE ) <nl> { <nl> CLibrary . trySkipCache ( this . fd , ( int ) minBufferOffset , 0 ) ; <nl> bytesSinceCacheFlush = 0 ; <nl> minBufferOffset = Long . MAX _ VALUE ; <nl> } <nl> - <nl> - return bytesRead ; <nl> } <nl> <nl> @ Override <nl> - / / - 1 will be returned if EOF is reached , RandomAccessFile is responsible <nl> - / / for <nl> - / / throwing EOFException <nl> + / / - 1 will be returned if there is nothing to read ; higher - level methods like readInt <nl> + / / or readFully ( from RandomAccessFile ) will throw EOFException but this should not <nl> public int read ( ) throws IOException <nl> { <nl> if ( isEOF ( ) ) <nl> return - 1 ; / / required by RandomAccessFile <nl> <nl> - if ( current < bufferOffset | | current > = bufferEnd ) <nl> - { <nl> + if ( current > = bufferOffset + buffer . length ) <nl> reBuffer ( ) ; <nl> + assert current > = bufferOffset & & current < bufferOffset + validBufferBytes ; <nl> <nl> - if ( current = = bufferEnd & & hitEOF ) <nl> - return - 1 ; / / required by RandomAccessFile <nl> - } <nl> - <nl> - byte result = buffer . get ( ) ; <nl> - current + + ; <nl> - <nl> - return ( ( int ) result ) & 0xFF ; <nl> + return ( ( int ) buffer [ ( int ) ( current + + - bufferOffset ) ] ) & 0xFF ; <nl> } <nl> <nl> @ Override <nl> @ @ - 254 , 40 + 239 , 25 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> } <nl> <nl> @ Override <nl> - / / - 1 will be returned if EOF is reached ; higher - level methods like readInt <nl> + / / - 1 will be returned if there is nothing to read ; higher - level methods like readInt <nl> / / or readFully ( from RandomAccessFile ) will throw EOFException but this should not <nl> public int read ( byte [ ] buff , int offset , int length ) throws IOException <nl> { <nl> - int bytesCount = 0 ; <nl> - <nl> - while ( length > 0 ) <nl> - { <nl> - int bytesRead = readAtMost ( buff , offset , length ) ; <nl> - if ( bytesRead = = - 1 ) <nl> - return - 1 ; / / EOF <nl> - <nl> - offset + = bytesRead ; <nl> - length - = bytesRead ; <nl> - bytesCount + = bytesRead ; <nl> - } <nl> - <nl> - return bytesCount ; <nl> - } <nl> + if ( length = = 0 ) <nl> + return 0 ; <nl> <nl> - private int readAtMost ( byte [ ] buff , int offset , int length ) throws IOException <nl> - { <nl> - if ( length > bufferEnd & & hitEOF ) <nl> + if ( isEOF ( ) ) <nl> return - 1 ; <nl> <nl> - final int left = buffer . capacity ( ) - buffer . position ( ) ; <nl> - if ( current < bufferOffset | | left < length ) <nl> + if ( current > = bufferOffset + buffer . length ) <nl> reBuffer ( ) ; <nl> + assert current > = bufferOffset & & current < bufferOffset + validBufferBytes ; <nl> <nl> - length = Math . min ( length , buffer . capacity ( ) - buffer . position ( ) ) ; <nl> - buffer . get ( buff , offset , length ) ; <nl> - current + = length ; <nl> + int toCopy = Math . min ( length , validBufferBytes - ( int ) ( current - bufferOffset ) ) ; <nl> + System . arraycopy ( buffer , ( int ) ( current - bufferOffset ) , buff , offset , toCopy ) ; <nl> + current + = toCopy ; <nl> <nl> - return length ; <nl> + return toCopy ; <nl> } <nl> <nl> public ByteBuffer readBytes ( int length ) throws IOException <nl> @ @ - 300 , 12 + 270 , 12 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> return ByteBuffer . wrap ( buff ) ; <nl> } <nl> <nl> + private final byte [ ] singleByteBuffer = new byte [ 1 ] ; / / so we can use the write ( byte [ ] ) path w / o tons of new byte [ ] allocations <nl> @ Override <nl> public void write ( int val ) throws IOException <nl> { <nl> - byte [ ] b = new byte [ 1 ] ; <nl> - b [ 0 ] = ( byte ) val ; <nl> - this . write ( b , 0 , b . length ) ; <nl> + singleByteBuffer [ 0 ] = ( byte ) val ; <nl> + this . write ( singleByteBuffer , 0 , 1 ) ; <nl> } <nl> <nl> @ Override <nl> @ @ - 334 , 21 + 304 , 18 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> * / <nl> private int writeAtMost ( byte [ ] buff , int offset , int length ) throws IOException <nl> { <nl> - final int left = buffer . capacity ( ) - buffer . position ( ) ; <nl> - if ( current < bufferOffset | | left < length ) <nl> + if ( current > = bufferOffset + buffer . length ) <nl> reBuffer ( ) ; <nl> + assert current < bufferOffset + buffer . length ; <nl> <nl> - / / logic is the following : we need to add bytes to the end of the buffer <nl> - / / starting from current buffer position and return this length <nl> - length = Math . min ( length , buffer . capacity ( ) - buffer . position ( ) ) ; <nl> - <nl> - buffer . put ( buff , offset , length ) ; <nl> - current + = length ; <nl> + int positionWithinBuffer = ( int ) ( current - bufferOffset ) ; <nl> + int toCopy = Math . min ( length , buffer . length - positionWithinBuffer ) ; <nl> + System . arraycopy ( buff , offset , buffer , positionWithinBuffer , toCopy ) ; <nl> + current + = toCopy ; <nl> + validBufferBytes = Math . max ( validBufferBytes , positionWithinBuffer + toCopy ) ; <nl> + assert current < = bufferOffset + buffer . length ; <nl> <nl> - if ( current > bufferEnd ) <nl> - bufferEnd = current ; <nl> - <nl> - return length ; <nl> + return toCopy ; <nl> } <nl> <nl> @ Override <nl> @ @ - 356 , 13 + 323 , 8 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> { <nl> current = newPosition ; <nl> <nl> - if ( newPosition > = bufferEnd | | newPosition < bufferOffset ) <nl> - { <nl> + if ( newPosition > = bufferOffset + validBufferBytes | | newPosition < bufferOffset ) <nl> reBuffer ( ) ; / / this will set bufferEnd for us <nl> - } <nl> - <nl> - final int delta = ( int ) ( newPosition - bufferOffset ) ; <nl> - buffer . position ( delta ) ; <nl> } <nl> <nl> @ Override <nl> @ @ - 382 , 12 + 344 , 12 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> <nl> public long length ( ) throws IOException <nl> { <nl> - return ( fileLength = = - 1 ) ? Math . max ( current , channel . size ( ) ) : fileLength ; <nl> + return ( fileLength = = - 1 ) ? Math . max ( Math . max ( current , channel . size ( ) ) , bufferOffset + validBufferBytes ) : fileLength ; <nl> } <nl> <nl> public long getFilePointer ( ) <nl> { <nl> - return bufferOffset + buffer . position ( ) ; <nl> + return current ; <nl> } <nl> <nl> public String getPath ( ) <nl> @ @ - 395 , 6 + 357 , 9 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> return filePath ; <nl> } <nl> <nl> + / * * <nl> + * @ return true if there is no more data to read <nl> + * / <nl> public boolean isEOF ( ) throws IOException <nl> { <nl> return getFilePointer ( ) = = length ( ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / io / sstable / DescriptorTest . java b / test / unit / org / apache / cassandra / io / sstable / DescriptorTest . java <nl> new file mode 100644 <nl> index 0000000 . . 62fc998 <nl> - - - / dev / null <nl> + + + b / test / unit / org / apache / cassandra / io / sstable / DescriptorTest . java <nl> @ @ - 0 , 0 + 1 , 16 @ @ <nl> + package org . apache . cassandra . io . sstable ; <nl> + <nl> + import java . io . File ; <nl> + <nl> + import org . junit . Test ; <nl> + <nl> + public class DescriptorTest <nl> + { <nl> + @ Test <nl> + public void testLegacy ( ) <nl> + { <nl> + Descriptor descriptor = Descriptor . fromFilename ( new File ( " Keyspace1 " ) , " userActionUtilsKey - 9 - Data . db " ) . left ; <nl> + assert descriptor . version . equals ( Descriptor . LEGACY _ VERSION ) ; <nl> + assert descriptor . usesOldBloomFilter ; <nl> + } <nl> + } <nl> diff - - git a / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java b / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java <nl> index 606ba09 . . 2116a7e 100644 <nl> - - - a / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java <nl> + + + b / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java <nl> @ @ - 26 , 6 + 26 , 7 @ @ import java . io . File ; <nl> import java . io . FileOutputStream ; <nl> import java . io . IOException ; <nl> import java . util . Arrays ; <nl> + import java . util . concurrent . Callable ; <nl> <nl> import org . junit . Test ; <nl> <nl> @ @ - 98 , 37 + 99 , 69 @ @ public class BufferedRandomAccessFileTest <nl> rw . write ( 42 ) ; <nl> } <nl> <nl> - protected void expectException ( int size , int offset , int len , BufferedRandomAccessFile braf ) <nl> + @ Test <nl> + public void testNotEOF ( ) throws IOException <nl> + { <nl> + assertEquals ( 1 , new BufferedRandomAccessFile ( writeTemporaryFile ( new byte [ 1 ] ) , " rw " ) . read ( new byte [ 2 ] ) ) ; <nl> + } <nl> + <nl> + <nl> + protected void expectEOF ( Callable < ? > callable ) <nl> { <nl> boolean threw = false ; <nl> try <nl> { <nl> - braf . readFully ( new byte [ size ] , offset , len ) ; <nl> + callable . call ( ) ; <nl> } <nl> - catch ( Throwable t ) <nl> + catch ( Exception e ) <nl> { <nl> - assert t . getClass ( ) . equals ( EOFException . class ) : t . getClass ( ) . getName ( ) + " is not " + EOFException . class . getName ( ) ; <nl> + assert e . getClass ( ) . equals ( EOFException . class ) : e . getClass ( ) . getName ( ) + " is not " + EOFException . class . getName ( ) ; <nl> threw = true ; <nl> } <nl> assert threw : EOFException . class . getName ( ) + " not received " ; <nl> } <nl> <nl> @ Test <nl> - public void testEOF ( ) throws Exception <nl> + public void testEOF ( ) throws IOException <nl> { <nl> for ( String mode : Arrays . asList ( " r " , " rw " ) ) / / read , read + write <nl> { <nl> - for ( int buf : Arrays . asList ( 8 , 16 , 32 , 0 ) ) / / smaller , equal , bigger , zero <nl> + for ( int bufferSize : Arrays . asList ( 1 , 2 , 3 , 5 , 8 , 64 ) ) / / smaller , equal , bigger buffer sizes <nl> { <nl> - for ( int off : Arrays . asList ( 0 , 8 ) ) <nl> + final byte [ ] target = new byte [ 32 ] ; <nl> + <nl> + / / single too - large read <nl> + for ( final int offset : Arrays . asList ( 0 , 8 ) ) <nl> { <nl> - expectException ( 32 , off , 17 , new BufferedRandomAccessFile ( writeTemporaryFile ( new byte [ 16 ] ) , mode , buf ) ) ; <nl> + final BufferedRandomAccessFile file = new BufferedRandomAccessFile ( writeTemporaryFile ( new byte [ 16 ] ) , mode , bufferSize ) ; <nl> + expectEOF ( new Callable < Object > ( ) <nl> + { <nl> + public Object call ( ) throws IOException <nl> + { <nl> + file . readFully ( target , offset , 17 ) ; <nl> + return null ; <nl> + } <nl> + } ) ; <nl> + } <nl> + <nl> + / / first read is ok but eventually EOFs <nl> + for ( final int n : Arrays . asList ( 1 , 2 , 4 , 8 ) ) <nl> + { <nl> + final BufferedRandomAccessFile file = new BufferedRandomAccessFile ( writeTemporaryFile ( new byte [ 16 ] ) , mode , bufferSize ) ; <nl> + expectEOF ( new Callable < Object > ( ) <nl> + { <nl> + public Object call ( ) throws IOException <nl> + { <nl> + while ( true ) <nl> + file . readFully ( target , 0 , n ) ; <nl> + } <nl> + } ) ; <nl> } <nl> } <nl> } <nl> } <nl> <nl> - protected File writeTemporaryFile ( byte [ ] data ) throws Exception <nl> + protected File writeTemporaryFile ( byte [ ] data ) throws IOException <nl> { <nl> File f = File . createTempFile ( " BRAFTestFile " , null ) ; <nl> f . deleteOnExit ( ) ; <nl> @ @ - 172 , 12 + 205 , 12 @ @ public class BufferedRandomAccessFileTest <nl> <nl> BufferedRandomAccessFile rw = new BufferedRandomAccessFile ( tmpFile . getPath ( ) , " rw " ) ; <nl> rw . write ( new byte [ ] { 1 } ) ; <nl> - <nl> rw . seek ( 0 ) ; <nl> + <nl> / / test read of buffered - but - not - yet - written data <nl> byte [ ] buffer = new byte [ 1 ] ; <nl> - assert rw . read ( buffer ) = = 1 ; <nl> - assert buffer [ 0 ] = = 1 ; <nl> + assertEquals ( 1 , rw . read ( buffer ) ) ; <nl> + assertEquals ( 1 , buffer [ 0 ] ) ; <nl> rw . close ( ) ; <nl> <nl> / / test read of not - yet - buffered data

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 5348f2f . . 89db48e 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 1 . 3 
 + * Fix overflow on histogram computation ( CASSANDRA - 8028 ) 
 * Have paxos reuse the timestamp generation of normal queries ( CASSANDRA - 7801 ) 
 
 2 . 1 . 2 
 diff - - git a / src / java / org / apache / cassandra / metrics / ColumnFamilyMetrics . java b / src / java / org / apache / cassandra / metrics / ColumnFamilyMetrics . java 
 index d9d3ed9 . . 2bdaf27 100644 
 - - - a / src / java / org / apache / cassandra / metrics / ColumnFamilyMetrics . java 
 + + + b / src / java / org / apache / cassandra / metrics / ColumnFamilyMetrics . java 
 @ @ - 18 , 6 + 18 , 7 @ @ 
 package org . apache . cassandra . metrics ; 
 
 import java . util . HashSet ; 
 + import java . util . Iterator ; 
 import java . util . Set ; 
 import java . util . concurrent . ConcurrentMap ; 
 import java . util . concurrent . TimeUnit ; 
 @ @ - 146 , 6 + 147 , 46 @ @ public class ColumnFamilyMetrics 
 * Stores all metric names created that can be used when unregistering 
 * / 
 public final static Set < String > all = Sets . newHashSet ( ) ; 
 + 
 + private interface GetHistogram 
 + { 
 + public EstimatedHistogram getHistogram ( SSTableReader reader ) ; 
 + } 
 + 
 + private static long [ ] combineHistograms ( Iterable < SSTableReader > sstables , GetHistogram getHistogram ) 
 + { 
 + Iterator < SSTableReader > iterator = sstables . iterator ( ) ; 
 + if ( ! iterator . hasNext ( ) ) 
 + { 
 + return new long [ 0 ] ; 
 + } 
 + long [ ] firstBucket = getHistogram . getHistogram ( iterator . next ( ) ) . getBuckets ( false ) ; 
 + long [ ] values = new long [ firstBucket . length ] ; 
 + System . arraycopy ( firstBucket , 0 , values , 0 , values . length ) ; 
 + 
 + while ( iterator . hasNext ( ) ) 
 + { 
 + long [ ] nextBucket = getHistogram . getHistogram ( iterator . next ( ) ) . getBuckets ( false ) ; 
 + if ( nextBucket . length > values . length ) 
 + { 
 + long [ ] newValues = new long [ nextBucket . length ] ; 
 + System . arraycopy ( firstBucket , 0 , newValues , 0 , firstBucket . length ) ; 
 + for ( int i = 0 ; i < newValues . length ; i + + ) 
 + { 
 + newValues [ i ] + = nextBucket [ i ] ; 
 + } 
 + values = newValues ; 
 + } 
 + else 
 + { 
 + for ( int i = 0 ; i < values . length ; i + + ) 
 + { 
 + values [ i ] + = nextBucket [ i ] ; 
 + } 
 + } 
 + } 
 + return values ; 
 + } 
 
 / * * 
 * Creates metrics for given { @ link ColumnFamilyStore } . 
 @ @ - 219 , 28 + 260 , 26 @ @ public class ColumnFamilyMetrics 
 { 
 public long [ ] value ( ) 
 { 
 - long [ ] histogram = new long [ 90 ] ; 
 - for ( SSTableReader sstable : cfs . getSSTables ( ) ) 
 + return combineHistograms ( cfs . getSSTables ( ) , new GetHistogram ( ) 
 { 
 - long [ ] rowSize = sstable . getEstimatedRowSize ( ) . getBuckets ( false ) ; 
 - for ( int i = 0 ; i < histogram . length ; i + + ) 
 - histogram [ i ] + = rowSize [ i ] ; 
 - } 
 - return histogram ; 
 + public EstimatedHistogram getHistogram ( SSTableReader reader ) 
 + { 
 + return reader . getEstimatedRowSize ( ) ; 
 + } 
 + } ) ; 
 } 
 } ) ; 
 estimatedColumnCountHistogram = Metrics . newGauge ( factory . createMetricName ( " EstimatedColumnCountHistogram " ) , new Gauge < long [ ] > ( ) 
 { 
 public long [ ] value ( ) 
 { 
 - long [ ] histogram = new long [ 90 ] ; 
 - for ( SSTableReader sstable : cfs . getSSTables ( ) ) 
 + return combineHistograms ( cfs . getSSTables ( ) , new GetHistogram ( ) 
 { 
 - long [ ] columnSize = sstable . getEstimatedColumnCount ( ) . getBuckets ( false ) ; 
 - for ( int i = 0 ; i < histogram . length ; i + + ) 
 - histogram [ i ] + = columnSize [ i ] ; 
 - } 
 - return histogram ; 
 + public EstimatedHistogram getHistogram ( SSTableReader reader ) 
 + { 
 + return reader . getEstimatedColumnCount ( ) ; 
 + } 
 + } ) ; 
 } 
 } ) ; 
 sstablesPerReadHistogram = createColumnFamilyHistogram ( " SSTablesPerReadHistogram " , cfs . keyspace . metric . sstablesPerReadHistogram ) ; 
 diff - - git a / src / java / org / apache / cassandra / tools / NodeTool . java b / src / java / org / apache / cassandra / tools / NodeTool . java 
 index 39bc4fd . . c09751b 100644 
 - - - a / src / java / org / apache / cassandra / tools / NodeTool . java 
 + + + b / src / java / org / apache / cassandra / tools / NodeTool . java 
 @ @ - 895 , 18 + 895 , 38 @ @ public class NodeTool 
 long [ ] estimatedRowSize = ( long [ ] ) probe . getColumnFamilyMetric ( keyspace , cfname , " EstimatedRowSizeHistogram " ) ; 
 long [ ] estimatedColumnCount = ( long [ ] ) probe . getColumnFamilyMetric ( keyspace , cfname , " EstimatedColumnCountHistogram " ) ; 
 
 - long [ ] bucketOffsets = new EstimatedHistogram ( ) . getBucketOffsets ( ) ; 
 - EstimatedHistogram rowSizeHist = new EstimatedHistogram ( bucketOffsets , estimatedRowSize ) ; 
 - EstimatedHistogram columnCountHist = new EstimatedHistogram ( bucketOffsets , estimatedColumnCount ) ; 
 + long [ ] rowSizeBucketOffsets = new EstimatedHistogram ( estimatedRowSize . length ) . getBucketOffsets ( ) ; 
 + long [ ] columnCountBucketOffsets = new EstimatedHistogram ( estimatedColumnCount . length ) . getBucketOffsets ( ) ; 
 + EstimatedHistogram rowSizeHist = new EstimatedHistogram ( rowSizeBucketOffsets , estimatedRowSize ) ; 
 + EstimatedHistogram columnCountHist = new EstimatedHistogram ( columnCountBucketOffsets , estimatedColumnCount ) ; 
 
 / / build arrays to store percentile values 
 double [ ] estimatedRowSizePercentiles = new double [ 7 ] ; 
 double [ ] estimatedColumnCountPercentiles = new double [ 7 ] ; 
 double [ ] offsetPercentiles = new double [ ] { 0 . 5 , 0 . 75 , 0 . 95 , 0 . 98 , 0 . 99 } ; 
 - for ( int i = 0 ; i < offsetPercentiles . length ; i + + ) 
 + 
 + if ( rowSizeHist . isOverflowed ( ) ) 
 + { 
 + System . err . println ( String . format ( " Row sizes are larger than % s , unable to calculate percentiles " , rowSizeBucketOffsets [ rowSizeBucketOffsets . length - 1 ] ) ) ; 
 + for ( int i = 0 ; i < offsetPercentiles . length ; i + + ) 
 + estimatedRowSizePercentiles [ i ] = Double . NaN ; 
 + } 
 + else 
 + { 
 + for ( int i = 0 ; i < offsetPercentiles . length ; i + + ) 
 + estimatedRowSizePercentiles [ i ] = rowSizeHist . percentile ( offsetPercentiles [ i ] ) ; 
 + } 
 + 
 + if ( columnCountHist . isOverflowed ( ) ) 
 + { 
 + System . err . println ( String . format ( " Column counts are larger than % s , unable to calculate percentiles " , columnCountBucketOffsets [ columnCountBucketOffsets . length - 1 ] ) ) ; 
 + for ( int i = 0 ; i < estimatedColumnCountPercentiles . length ; i + + ) 
 + estimatedColumnCountPercentiles [ i ] = Double . NaN ; 
 + } 
 + else 
 { 
 - estimatedRowSizePercentiles [ i ] = rowSizeHist . percentile ( offsetPercentiles [ i ] ) ; 
 - estimatedColumnCountPercentiles [ i ] = columnCountHist . percentile ( offsetPercentiles [ i ] ) ; 
 + for ( int i = 0 ; i < offsetPercentiles . length ; i + + ) 
 + estimatedColumnCountPercentiles [ i ] = columnCountHist . percentile ( offsetPercentiles [ i ] ) ; 
 } 
 
 / / min value

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index e268270 . . 42f86f7 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 18 , 7 + 18 , 7 @ @ 
 * add nodetool scrub ( CASSANDRA - 2217 ) 
 * fix sstable2json large - row pagination ( CASSANDRA - 2188 ) 
 * fix EOFing on requests for the last bytes in a file ( CASSANDRA - 2213 ) 
 - * fix BRAF performance when seeking to EOF ( CASSANDRA - 2218 ) 
 + * fix BufferedRandomAccessFile bugs ( CASSANDRA - 2218 , - 2241 ) 
 * check for memtable flush _ after _ mins exceeded every 10s ( CASSANDRA - 2183 ) 
 * fix cache saving on Windows ( CASSANDRA - 2207 ) 
 * add validateSchemaAgreement call + synchronization to schema 
 diff - - git a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java 
 index 82d8320 . . 3d5ad19 100644 
 - - - a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java 
 + + + b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java 
 @ @ - 172 , 7 + 172 , 7 @ @ public class CommitLog 
 
 for ( File file : clogs ) 
 { 
 - int bufferSize = ( int ) Math . min ( file . length ( ) , 32 * 1024 * 1024 ) ; 
 + int bufferSize = ( int ) Math . min ( Math . max ( file . length ( ) , 1 ) , 32 * 1024 * 1024 ) ; 
 BufferedRandomAccessFile reader = new BufferedRandomAccessFile ( new File ( file . getAbsolutePath ( ) ) , " r " , bufferSize , true ) ; 
 
 try 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / Descriptor . java b / src / java / org / apache / cassandra / io / sstable / Descriptor . java 
 index effeb82 . . 08d3b00 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / Descriptor . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / Descriptor . java 
 @ @ - 76 , 8 + 76 , 8 @ @ public class Descriptor 
 hasStringsInBloomFilter = version . compareTo ( " c " ) < 0 ; 
 hasIntRowSize = version . compareTo ( " d " ) < 0 ; 
 hasEncodedKeys = version . compareTo ( " e " ) < 0 ; 
 - isLatestVersion = version . compareTo ( CURRENT _ VERSION ) = = 0 ; 
 usesOldBloomFilter = version . compareTo ( " f " ) < 0 ; 
 + isLatestVersion = version . compareTo ( CURRENT _ VERSION ) = = 0 ; 
 } 
 
 public String filenameFor ( Component component ) 
 diff - - git a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java 
 index 8059c2a . . 073ad72 100644 
 - - - a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java 
 + + + b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java 
 @ @ - 47 , 16 + 47 , 16 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 public static final int DEFAULT _ BUFFER _ SIZE = 65535 ; 
 
 / / isDirty - true if this . buffer contains any un - synced bytes 
 - / / hitEOF - true if buffer capacity is less then it ' s maximal size 
 - private boolean isDirty , syncNeeded , hitEOF = false ; 
 + private boolean isDirty , syncNeeded ; 
 
 / / buffer which will cache file blocks 
 - private ByteBuffer buffer ; 
 + private byte [ ] buffer ; 
 
 / / ` current ` as current position in file 
 / / ` bufferOffset ` is the offset of the beginning of the buffer 
 - / / ` bufferEnd ` is ` bufferOffset ` + count of bytes read from file , i . e . the lowest position we can ' t read from the buffer 
 - private long bufferOffset , bufferEnd , current = 0 ; 
 + / / ` validBufferBytes ` is the number of bytes in the buffer that are actually valid ; this will be LESS than buffer capacity if buffer is not full ! 
 + private long bufferOffset , current = 0 ; 
 + private int validBufferBytes = 0 ; 
 
 / / constant , used for caching purpose , - 1 if file is open in " rw " mode 
 / / otherwise this will hold cached file length 
 @ @ - 118 , 11 + 118 , 11 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 / / allocating required size of the buffer 
 if ( bufferSize < = 0 ) 
 throw new IllegalArgumentException ( " bufferSize must be positive " ) ; 
 - buffer = ByteBuffer . allocate ( bufferSize ) ; 
 + buffer = new byte [ bufferSize ] ; 
 + reBuffer ( ) ; 
 
 / / if in read - only mode , caching file size 
 fileLength = ( mode . equals ( " r " ) ) ? this . channel . size ( ) : - 1 ; 
 - bufferEnd = reBuffer ( ) ; / / bufferBottom equals to the bytes read 
 fd = CLibrary . getfd ( this . getFD ( ) ) ; 
 } 
 
 @ @ - 155 , 9 + 155 , 7 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 if ( channel . position ( ) ! = bufferOffset ) 
 channel . position ( bufferOffset ) ; 
 
 - int lengthToWrite = ( int ) ( bufferEnd - bufferOffset ) ; 
 - 
 - super . write ( buffer . array ( ) , 0 , lengthToWrite ) ; 
 + super . write ( buffer , 0 , validBufferBytes ) ; 
 
 if ( skipCache ) 
 { 
 @ @ - 167 , 7 + 165 , 7 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 / / so we continue to clear pages we don ' t need from the first 
 / / offset we see 
 / / periodically we update this starting offset 
 - bytesSinceCacheFlush + = lengthToWrite ; 
 + bytesSinceCacheFlush + = validBufferBytes ; 
 
 if ( bufferOffset < minBufferOffset ) 
 minBufferOffset = bufferOffset ; 
 @ @ - 185 , 66 + 183 , 53 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 } 
 } 
 
 - private long reBuffer ( ) throws IOException 
 + private void reBuffer ( ) throws IOException 
 { 
 flush ( ) ; / / synchronizing buffer and file on disk 
 - buffer . clear ( ) ; 
 - bufferOffset = current ; 
 
 + bufferOffset = current ; 
 if ( bufferOffset > = channel . size ( ) ) 
 { 
 - buffer . rewind ( ) ; 
 - bufferEnd = bufferOffset ; 
 - hitEOF = true ; 
 - 
 - return 0 ; 
 + validBufferBytes = 0 ; 
 + return ; 
 } 
 
 if ( bufferOffset < minBufferOffset ) 
 minBufferOffset = bufferOffset ; 
 
 channel . position ( bufferOffset ) ; / / setting channel position 
 - long bytesRead = channel . read ( buffer ) ; / / reading from that position 
 - 
 - hitEOF = ( bytesRead < buffer . capacity ( ) ) ; / / buffer is not fully loaded with 
 - / / data 
 - bufferEnd = bufferOffset + bytesRead ; 
 - 
 - buffer . rewind ( ) ; 
 - 
 - bytesSinceCacheFlush + = bytesRead ; 
 + int read = 0 ; 
 + while ( read < buffer . length ) 
 + { 
 + int n = super . read ( buffer , read , buffer . length - read ) ; 
 + if ( n < 0 ) 
 + break ; 
 + read + = n ; 
 + } 
 + validBufferBytes = read ; 
 
 + bytesSinceCacheFlush + = read ; 
 if ( skipCache & & bytesSinceCacheFlush > = MAX _ BYTES _ IN _ PAGE _ CACHE ) 
 { 
 CLibrary . trySkipCache ( this . fd , ( int ) minBufferOffset , 0 ) ; 
 bytesSinceCacheFlush = 0 ; 
 minBufferOffset = Long . MAX _ VALUE ; 
 } 
 - 
 - return bytesRead ; 
 } 
 
 @ Override 
 - / / - 1 will be returned if EOF is reached , RandomAccessFile is responsible 
 - / / for 
 - / / throwing EOFException 
 + / / - 1 will be returned if there is nothing to read ; higher - level methods like readInt 
 + / / or readFully ( from RandomAccessFile ) will throw EOFException but this should not 
 public int read ( ) throws IOException 
 { 
 if ( isEOF ( ) ) 
 return - 1 ; / / required by RandomAccessFile 
 
 - if ( current < bufferOffset | | current > = bufferEnd ) 
 - { 
 + if ( current > = bufferOffset + buffer . length ) 
 reBuffer ( ) ; 
 + assert current > = bufferOffset & & current < bufferOffset + validBufferBytes ; 
 
 - if ( current = = bufferEnd & & hitEOF ) 
 - return - 1 ; / / required by RandomAccessFile 
 - } 
 - 
 - byte result = buffer . get ( ) ; 
 - current + + ; 
 - 
 - return ( ( int ) result ) & 0xFF ; 
 + return ( ( int ) buffer [ ( int ) ( current + + - bufferOffset ) ] ) & 0xFF ; 
 } 
 
 @ Override 
 @ @ - 254 , 40 + 239 , 25 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 } 
 
 @ Override 
 - / / - 1 will be returned if EOF is reached ; higher - level methods like readInt 
 + / / - 1 will be returned if there is nothing to read ; higher - level methods like readInt 
 / / or readFully ( from RandomAccessFile ) will throw EOFException but this should not 
 public int read ( byte [ ] buff , int offset , int length ) throws IOException 
 { 
 - int bytesCount = 0 ; 
 - 
 - while ( length > 0 ) 
 - { 
 - int bytesRead = readAtMost ( buff , offset , length ) ; 
 - if ( bytesRead = = - 1 ) 
 - return - 1 ; / / EOF 
 - 
 - offset + = bytesRead ; 
 - length - = bytesRead ; 
 - bytesCount + = bytesRead ; 
 - } 
 - 
 - return bytesCount ; 
 - } 
 + if ( length = = 0 ) 
 + return 0 ; 
 
 - private int readAtMost ( byte [ ] buff , int offset , int length ) throws IOException 
 - { 
 - if ( length > bufferEnd & & hitEOF ) 
 + if ( isEOF ( ) ) 
 return - 1 ; 
 
 - final int left = buffer . capacity ( ) - buffer . position ( ) ; 
 - if ( current < bufferOffset | | left < length ) 
 + if ( current > = bufferOffset + buffer . length ) 
 reBuffer ( ) ; 
 + assert current > = bufferOffset & & current < bufferOffset + validBufferBytes ; 
 
 - length = Math . min ( length , buffer . capacity ( ) - buffer . position ( ) ) ; 
 - buffer . get ( buff , offset , length ) ; 
 - current + = length ; 
 + int toCopy = Math . min ( length , validBufferBytes - ( int ) ( current - bufferOffset ) ) ; 
 + System . arraycopy ( buffer , ( int ) ( current - bufferOffset ) , buff , offset , toCopy ) ; 
 + current + = toCopy ; 
 
 - return length ; 
 + return toCopy ; 
 } 
 
 public ByteBuffer readBytes ( int length ) throws IOException 
 @ @ - 300 , 12 + 270 , 12 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 return ByteBuffer . wrap ( buff ) ; 
 } 
 
 + private final byte [ ] singleByteBuffer = new byte [ 1 ] ; / / so we can use the write ( byte [ ] ) path w / o tons of new byte [ ] allocations 
 @ Override 
 public void write ( int val ) throws IOException 
 { 
 - byte [ ] b = new byte [ 1 ] ; 
 - b [ 0 ] = ( byte ) val ; 
 - this . write ( b , 0 , b . length ) ; 
 + singleByteBuffer [ 0 ] = ( byte ) val ; 
 + this . write ( singleByteBuffer , 0 , 1 ) ; 
 } 
 
 @ Override 
 @ @ - 334 , 21 + 304 , 18 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 * / 
 private int writeAtMost ( byte [ ] buff , int offset , int length ) throws IOException 
 { 
 - final int left = buffer . capacity ( ) - buffer . position ( ) ; 
 - if ( current < bufferOffset | | left < length ) 
 + if ( current > = bufferOffset + buffer . length ) 
 reBuffer ( ) ; 
 + assert current < bufferOffset + buffer . length ; 
 
 - / / logic is the following : we need to add bytes to the end of the buffer 
 - / / starting from current buffer position and return this length 
 - length = Math . min ( length , buffer . capacity ( ) - buffer . position ( ) ) ; 
 - 
 - buffer . put ( buff , offset , length ) ; 
 - current + = length ; 
 + int positionWithinBuffer = ( int ) ( current - bufferOffset ) ; 
 + int toCopy = Math . min ( length , buffer . length - positionWithinBuffer ) ; 
 + System . arraycopy ( buff , offset , buffer , positionWithinBuffer , toCopy ) ; 
 + current + = toCopy ; 
 + validBufferBytes = Math . max ( validBufferBytes , positionWithinBuffer + toCopy ) ; 
 + assert current < = bufferOffset + buffer . length ; 
 
 - if ( current > bufferEnd ) 
 - bufferEnd = current ; 
 - 
 - return length ; 
 + return toCopy ; 
 } 
 
 @ Override 
 @ @ - 356 , 13 + 323 , 8 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 { 
 current = newPosition ; 
 
 - if ( newPosition > = bufferEnd | | newPosition < bufferOffset ) 
 - { 
 + if ( newPosition > = bufferOffset + validBufferBytes | | newPosition < bufferOffset ) 
 reBuffer ( ) ; / / this will set bufferEnd for us 
 - } 
 - 
 - final int delta = ( int ) ( newPosition - bufferOffset ) ; 
 - buffer . position ( delta ) ; 
 } 
 
 @ Override 
 @ @ - 382 , 12 + 344 , 12 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 
 public long length ( ) throws IOException 
 { 
 - return ( fileLength = = - 1 ) ? Math . max ( current , channel . size ( ) ) : fileLength ; 
 + return ( fileLength = = - 1 ) ? Math . max ( Math . max ( current , channel . size ( ) ) , bufferOffset + validBufferBytes ) : fileLength ; 
 } 
 
 public long getFilePointer ( ) 
 { 
 - return bufferOffset + buffer . position ( ) ; 
 + return current ; 
 } 
 
 public String getPath ( ) 
 @ @ - 395 , 6 + 357 , 9 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 return filePath ; 
 } 
 
 + / * * 
 + * @ return true if there is no more data to read 
 + * / 
 public boolean isEOF ( ) throws IOException 
 { 
 return getFilePointer ( ) = = length ( ) ; 
 diff - - git a / test / unit / org / apache / cassandra / io / sstable / DescriptorTest . java b / test / unit / org / apache / cassandra / io / sstable / DescriptorTest . java 
 new file mode 100644 
 index 0000000 . . 62fc998 
 - - - / dev / null 
 + + + b / test / unit / org / apache / cassandra / io / sstable / DescriptorTest . java 
 @ @ - 0 , 0 + 1 , 16 @ @ 
 + package org . apache . cassandra . io . sstable ; 
 + 
 + import java . io . File ; 
 + 
 + import org . junit . Test ; 
 + 
 + public class DescriptorTest 
 + { 
 + @ Test 
 + public void testLegacy ( ) 
 + { 
 + Descriptor descriptor = Descriptor . fromFilename ( new File ( " Keyspace1 " ) , " userActionUtilsKey - 9 - Data . db " ) . left ; 
 + assert descriptor . version . equals ( Descriptor . LEGACY _ VERSION ) ; 
 + assert descriptor . usesOldBloomFilter ; 
 + } 
 + } 
 diff - - git a / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java b / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java 
 index 606ba09 . . 2116a7e 100644 
 - - - a / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java 
 + + + b / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java 
 @ @ - 26 , 6 + 26 , 7 @ @ import java . io . File ; 
 import java . io . FileOutputStream ; 
 import java . io . IOException ; 
 import java . util . Arrays ; 
 + import java . util . concurrent . Callable ; 
 
 import org . junit . Test ; 
 
 @ @ - 98 , 37 + 99 , 69 @ @ public class BufferedRandomAccessFileTest 
 rw . write ( 42 ) ; 
 } 
 
 - protected void expectException ( int size , int offset , int len , BufferedRandomAccessFile braf ) 
 + @ Test 
 + public void testNotEOF ( ) throws IOException 
 + { 
 + assertEquals ( 1 , new BufferedRandomAccessFile ( writeTemporaryFile ( new byte [ 1 ] ) , " rw " ) . read ( new byte [ 2 ] ) ) ; 
 + } 
 + 
 + 
 + protected void expectEOF ( Callable < ? > callable ) 
 { 
 boolean threw = false ; 
 try 
 { 
 - braf . readFully ( new byte [ size ] , offset , len ) ; 
 + callable . call ( ) ; 
 } 
 - catch ( Throwable t ) 
 + catch ( Exception e ) 
 { 
 - assert t . getClass ( ) . equals ( EOFException . class ) : t . getClass ( ) . getName ( ) + " is not " + EOFException . class . getName ( ) ; 
 + assert e . getClass ( ) . equals ( EOFException . class ) : e . getClass ( ) . getName ( ) + " is not " + EOFException . class . getName ( ) ; 
 threw = true ; 
 } 
 assert threw : EOFException . class . getName ( ) + " not received " ; 
 } 
 
 @ Test 
 - public void testEOF ( ) throws Exception 
 + public void testEOF ( ) throws IOException 
 { 
 for ( String mode : Arrays . asList ( " r " , " rw " ) ) / / read , read + write 
 { 
 - for ( int buf : Arrays . asList ( 8 , 16 , 32 , 0 ) ) / / smaller , equal , bigger , zero 
 + for ( int bufferSize : Arrays . asList ( 1 , 2 , 3 , 5 , 8 , 64 ) ) / / smaller , equal , bigger buffer sizes 
 { 
 - for ( int off : Arrays . asList ( 0 , 8 ) ) 
 + final byte [ ] target = new byte [ 32 ] ; 
 + 
 + / / single too - large read 
 + for ( final int offset : Arrays . asList ( 0 , 8 ) ) 
 { 
 - expectException ( 32 , off , 17 , new BufferedRandomAccessFile ( writeTemporaryFile ( new byte [ 16 ] ) , mode , buf ) ) ; 
 + final BufferedRandomAccessFile file = new BufferedRandomAccessFile ( writeTemporaryFile ( new byte [ 16 ] ) , mode , bufferSize ) ; 
 + expectEOF ( new Callable < Object > ( ) 
 + { 
 + public Object call ( ) throws IOException 
 + { 
 + file . readFully ( target , offset , 17 ) ; 
 + return null ; 
 + } 
 + } ) ; 
 + } 
 + 
 + / / first read is ok but eventually EOFs 
 + for ( final int n : Arrays . asList ( 1 , 2 , 4 , 8 ) ) 
 + { 
 + final BufferedRandomAccessFile file = new BufferedRandomAccessFile ( writeTemporaryFile ( new byte [ 16 ] ) , mode , bufferSize ) ; 
 + expectEOF ( new Callable < Object > ( ) 
 + { 
 + public Object call ( ) throws IOException 
 + { 
 + while ( true ) 
 + file . readFully ( target , 0 , n ) ; 
 + } 
 + } ) ; 
 } 
 } 
 } 
 } 
 
 - protected File writeTemporaryFile ( byte [ ] data ) throws Exception 
 + protected File writeTemporaryFile ( byte [ ] data ) throws IOException 
 { 
 File f = File . createTempFile ( " BRAFTestFile " , null ) ; 
 f . deleteOnExit ( ) ; 
 @ @ - 172 , 12 + 205 , 12 @ @ public class BufferedRandomAccessFileTest 
 
 BufferedRandomAccessFile rw = new BufferedRandomAccessFile ( tmpFile . getPath ( ) , " rw " ) ; 
 rw . write ( new byte [ ] { 1 } ) ; 
 - 
 rw . seek ( 0 ) ; 
 + 
 / / test read of buffered - but - not - yet - written data 
 byte [ ] buffer = new byte [ 1 ] ; 
 - assert rw . read ( buffer ) = = 1 ; 
 - assert buffer [ 0 ] = = 1 ; 
 + assertEquals ( 1 , rw . read ( buffer ) ) ; 
 + assertEquals ( 1 , buffer [ 0 ] ) ; 
 rw . close ( ) ; 
 
 / / test read of not - yet - buffered data
