BLEU SCORE: 0.020980574531482755

TEST MSG: Fix the merging of cells with different user type versions
GENERATED MSG: Allow comparator parameters and add generic ReverseType

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index a35cc1b . . ba35152 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 3 . 0 . 15 <nl> + * Fix the merging of cells with different user type versions ( CASSANDRA - 13776 ) <nl> * Copy session properties on cqlsh . py do _ login ( CASSANDRA - 13640 ) <nl> * Potential AssertionError during ReadRepair of range tombstone and partition deletions ( CASSANDRA - 13719 ) <nl> * Don ' t let stress write warmup data if n = 0 ( CASSANDRA - 13773 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / SerializationHeader . java b / src / java / org / apache / cassandra / db / SerializationHeader . java <nl> index 19dad95 . . 494c2a3 100644 <nl> - - - a / src / java / org / apache / cassandra / db / SerializationHeader . java <nl> + + + b / src / java / org / apache / cassandra / db / SerializationHeader . java <nl> @ @ - 108 , 7 + 108 , 8 @ @ public class SerializationHeader <nl> / / but rather on their stats stored in StatsMetadata that are fully accurate . <nl> EncodingStats . Collector stats = new EncodingStats . Collector ( ) ; <nl> PartitionColumns . Builder columns = PartitionColumns . builder ( ) ; <nl> - for ( SSTableReader sstable : sstables ) <nl> + / / We need to order the SSTables by descending generation to be sure that we use latest column definitions . <nl> + for ( SSTableReader sstable : orderByDescendingGeneration ( sstables ) ) <nl> { <nl> stats . updateTimestamp ( sstable . getMinTimestamp ( ) ) ; <nl> stats . updateLocalDeletionTime ( sstable . getMinLocalDeletionTime ( ) ) ; <nl> @ @ - 121 , 6 + 122 , 16 @ @ public class SerializationHeader <nl> return new SerializationHeader ( true , metadata , columns . build ( ) , stats . get ( ) ) ; <nl> } <nl> <nl> + private static Collection < SSTableReader > orderByDescendingGeneration ( Collection < SSTableReader > sstables ) <nl> + { <nl> + if ( sstables . size ( ) < 2 ) <nl> + return sstables ; <nl> + <nl> + List < SSTableReader > readers = new ArrayList < > ( sstables ) ; <nl> + readers . sort ( SSTableReader . generationReverseComparator ) ; <nl> + return readers ; <nl> + } <nl> + <nl> public SerializationHeader ( boolean isForSSTable , <nl> CFMetaData metadata , <nl> PartitionColumns columns , <nl> diff - - git a / src / java / org / apache / cassandra / db / marshal / AbstractType . java b / src / java / org / apache / cassandra / db / marshal / AbstractType . java <nl> index 77e0971 . . 20062bd 100644 <nl> - - - a / src / java / org / apache / cassandra / db / marshal / AbstractType . java <nl> + + + b / src / java / org / apache / cassandra / db / marshal / AbstractType . java <nl> @ @ - 325 , 6 + 325 , 16 @ @ public abstract class AbstractType < T > implements Comparator < ByteBuffer > <nl> return false ; <nl> } <nl> <nl> + public boolean isTuple ( ) <nl> + { <nl> + return false ; <nl> + } <nl> + <nl> + public boolean isUDT ( ) <nl> + { <nl> + return false ; <nl> + } <nl> + <nl> public AbstractType < ? > freeze ( ) <nl> { <nl> return this ; <nl> diff - - git a / src / java / org / apache / cassandra / db / marshal / TupleType . java b / src / java / org / apache / cassandra / db / marshal / TupleType . java <nl> index 2d6363e . . 5c74332 100644 <nl> - - - a / src / java / org / apache / cassandra / db / marshal / TupleType . java <nl> + + + b / src / java / org / apache / cassandra / db / marshal / TupleType . java <nl> @ @ - 347 , 4 + 347 , 9 @ @ public class TupleType extends AbstractType < ByteBuffer > <nl> { <nl> return getClass ( ) . getName ( ) + TypeParser . stringifyTypeParameters ( types , true ) ; <nl> } <nl> + <nl> + public boolean isTuple ( ) <nl> + { <nl> + return true ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / marshal / UserType . java b / src / java / org / apache / cassandra / db / marshal / UserType . java <nl> index b91dbf8 . . 03545ca 100644 <nl> - - - a / src / java / org / apache / cassandra / db / marshal / UserType . java <nl> + + + b / src / java / org / apache / cassandra / db / marshal / UserType . java <nl> @ @ - 232 , 4 + 232 , 14 @ @ public class UserType extends TupleType <nl> { <nl> return serializer ; <nl> } <nl> + <nl> + public boolean isTuple ( ) <nl> + { <nl> + return false ; <nl> + } <nl> + <nl> + public boolean isUDT ( ) <nl> + { <nl> + return true ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / rows / AbstractTypeVersionComparator . java b / src / java / org / apache / cassandra / db / rows / AbstractTypeVersionComparator . java <nl> new file mode 100644 <nl> index 0000000 . . e47f681 <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / db / rows / AbstractTypeVersionComparator . java <nl> @ @ - 0 , 0 + 1 , 121 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an " AS IS " BASIS , <nl> + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + * See the License for the specific language governing permissions and <nl> + * limitations under the License . <nl> + * / <nl> + package org . apache . cassandra . db . rows ; <nl> + <nl> + import java . util . Comparator ; <nl> + import java . util . List ; <nl> + <nl> + import org . apache . cassandra . db . marshal . * ; <nl> + <nl> + / * * <nl> + * A { @ code Comparator } use to determine which version of a type should be used . <nl> + * < p > In the case of UDTs it is possible to have 2 versions or more of the same type , if some fields has been added to <nl> + * the type . To avoid problems the latest type need to be used . < / p > <nl> + * / <nl> + final class AbstractTypeVersionComparator implements Comparator < AbstractType < ? > > <nl> + { <nl> + public static final Comparator < AbstractType < ? > > INSTANCE = new AbstractTypeVersionComparator ( ) ; <nl> + <nl> + private AbstractTypeVersionComparator ( ) <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public int compare ( AbstractType < ? > type , AbstractType < ? > otherType ) <nl> + { <nl> + if ( ! type . getClass ( ) . equals ( otherType . getClass ( ) ) ) <nl> + throw new IllegalArgumentException ( String . format ( " Trying to compare 2 different types : % s and % s " , <nl> + type , <nl> + otherType ) ) ; <nl> + <nl> + if ( type . equals ( otherType ) ) <nl> + return 0 ; <nl> + <nl> + / / The only case where 2 types can differ is if they contains some UDTs and one of them has more <nl> + / / fields ( due to an ALTER type ADD ) than in the other type . In this case we need to pick the type with <nl> + / / the bigger amount of fields . <nl> + if ( type . isUDT ( ) ) <nl> + return compareUserType ( ( UserType ) type , ( UserType ) otherType ) ; <nl> + <nl> + if ( type . isTuple ( ) ) <nl> + return compareTuple ( ( TupleType ) type , ( TupleType ) otherType ) ; <nl> + <nl> + if ( type . isCollection ( ) ) <nl> + return compareCollectionTypes ( type , otherType ) ; <nl> + <nl> + if ( type instanceof CompositeType ) <nl> + return compareCompositeTypes ( ( CompositeType ) type , ( CompositeType ) otherType ) ; <nl> + <nl> + / / In theory we should never reach that point but to be on the safe side we allow it . <nl> + return 0 ; <nl> + } <nl> + <nl> + private int compareCompositeTypes ( CompositeType type , CompositeType otherType ) <nl> + { <nl> + List < AbstractType < ? > > types = type . getComponents ( ) ; <nl> + List < AbstractType < ? > > otherTypes = otherType . getComponents ( ) ; <nl> + <nl> + if ( types . size ( ) ! = otherTypes . size ( ) ) <nl> + return Integer . compare ( types . size ( ) , otherTypes . size ( ) ) ; <nl> + <nl> + for ( int i = 0 , m = type . componentsCount ( ) ; i < m ; i + + ) <nl> + { <nl> + int test = compare ( types . get ( i ) , otherTypes . get ( i ) ) ; <nl> + if ( test ! = 0 ) ; <nl> + return test ; <nl> + } <nl> + return 0 ; <nl> + } <nl> + <nl> + private int compareCollectionTypes ( AbstractType < ? > type , AbstractType < ? > otherType ) <nl> + { <nl> + if ( type instanceof MapType ) <nl> + return compareMapType ( ( MapType < ? , ? > ) type , ( MapType < ? , ? > ) otherType ) ; <nl> + <nl> + if ( type instanceof SetType ) <nl> + return compare ( ( ( SetType < ? > ) type ) . getElementsType ( ) , ( ( SetType < ? > ) otherType ) . getElementsType ( ) ) ; <nl> + <nl> + return compare ( ( ( ListType < ? > ) type ) . getElementsType ( ) , ( ( ListType < ? > ) otherType ) . getElementsType ( ) ) ; <nl> + } <nl> + <nl> + private int compareMapType ( MapType < ? , ? > type , MapType < ? , ? > otherType ) <nl> + { <nl> + int test = compare ( type . getKeysType ( ) , otherType . getKeysType ( ) ) ; <nl> + return test ! = 0 ? test : compare ( type . getValuesType ( ) , otherType . getValuesType ( ) ) ; <nl> + } <nl> + <nl> + private int compareUserType ( UserType type , UserType otherType ) <nl> + { <nl> + return compareTuple ( type , otherType ) ; <nl> + } <nl> + <nl> + private int compareTuple ( TupleType type , TupleType otherType ) <nl> + { <nl> + if ( type . size ( ) ! = otherType . size ( ) ) <nl> + return Integer . compare ( type . size ( ) , otherType . size ( ) ) ; <nl> + <nl> + int test = 0 ; <nl> + int i = 0 ; <nl> + while ( test = = 0 & & i < type . size ( ) ) <nl> + { <nl> + test = compare ( type . type ( i ) , otherType . type ( i ) ) ; <nl> + i + + ; <nl> + } <nl> + return test ; <nl> + } <nl> + } <nl> diff - - git a / src / java / org / apache / cassandra / db / rows / Row . java b / src / java / org / apache / cassandra / db / rows / Row . java <nl> index a61f365 . . 9ab1f09 100644 <nl> - - - a / src / java / org / apache / cassandra / db / rows / Row . java <nl> + + + b / src / java / org / apache / cassandra / db / rows / Row . java <nl> @ @ - 601 , 10 + 601 , 25 @ @ public interface Row extends Unfiltered , Collection < ColumnData > <nl> <nl> public void reduce ( int idx , ColumnData data ) <nl> { <nl> - column = data . column ( ) ; <nl> + if ( useColumnDefinition ( data . column ( ) ) ) <nl> + column = data . column ( ) ; <nl> + <nl> versions . add ( data ) ; <nl> } <nl> <nl> + / * * <nl> + * Determines it the { @ code ColumnDefinition } is the one that should be used . <nl> + * @ param dataColumn the { @ code ColumnDefinition } to use . <nl> + * @ return { @ code true } if the { @ code ColumnDefinition } is the one that should be used , { @ code false } otherwise . <nl> + * / <nl> + private boolean useColumnDefinition ( ColumnDefinition dataColumn ) <nl> + { <nl> + if ( column = = null ) <nl> + return true ; <nl> + <nl> + return AbstractTypeVersionComparator . INSTANCE . compare ( column . type , dataColumn . type ) < 0 ; <nl> + } <nl> + <nl> protected ColumnData getReduced ( ) <nl> { <nl> if ( column . isSimple ( ) ) <nl> @ @ - 654 , 6 + 669 , 7 @ @ public interface Row extends Unfiltered , Collection < ColumnData > <nl> <nl> protected void onKeyChange ( ) <nl> { <nl> + column = null ; <nl> versions . clear ( ) ; <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / rows / Rows . java b / src / java / org / apache / cassandra / db / rows / Rows . java <nl> index e325091 . . 09213a4 100644 <nl> - - - a / src / java / org / apache / cassandra / db / rows / Rows . java <nl> + + + b / src / java / org / apache / cassandra / db / rows / Rows . java <nl> @ @ - 279 , 7 + 279 , 8 @ @ public abstract class Rows <nl> int comparison = nexta = = null ? 1 : nextb = = null ? - 1 : nexta . column . compareTo ( nextb . column ) ; <nl> ColumnData cura = comparison < = 0 ? nexta : null ; <nl> ColumnData curb = comparison > = 0 ? nextb : null ; <nl> - ColumnDefinition column = ( cura ! = null ? cura : curb ) . column ; <nl> + ColumnDefinition column = getColumnDefinition ( cura , curb ) ; <nl> + <nl> if ( column . isSimple ( ) ) <nl> { <nl> timeDelta = Math . min ( timeDelta , Cells . reconcile ( ( Cell ) cura , ( Cell ) curb , deletion , builder , nowInSec ) ) ; <nl> @ @ - 309 , 4 + 310 , 22 @ @ public abstract class Rows <nl> } <nl> return timeDelta ; <nl> } <nl> + <nl> + / * * <nl> + * Returns the { @ code ColumnDefinition } to use for merging the columns . <nl> + * If the 2 column definitions are different the latest one will be returned . <nl> + * / <nl> + private static ColumnDefinition getColumnDefinition ( ColumnData cura , ColumnData curb ) <nl> + { <nl> + if ( cura = = null ) <nl> + return curb . column ; <nl> + <nl> + if ( curb = = null ) <nl> + return cura . column ; <nl> + <nl> + if ( AbstractTypeVersionComparator . INSTANCE . compare ( cura . column . type , curb . column . type ) > = 0 ) <nl> + return cura . column ; <nl> + <nl> + return curb . column ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / format / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / format / SSTableReader . java <nl> index f38738d . . cd41b5b 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / format / SSTableReader . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / format / SSTableReader . java <nl> @ @ - 45 , 7 + 45 , 6 @ @ import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . config . Schema ; <nl> import org . apache . cassandra . db . * ; <nl> - import org . apache . cassandra . db . commitlog . ReplayPosition ; <nl> import org . apache . cassandra . db . filter . ColumnFilter ; <nl> import org . apache . cassandra . db . rows . SliceableUnfilteredRowIterator ; <nl> import org . apache . cassandra . dht . AbstractBounds ; <nl> @ @ - 141 , 26 + 140 , 14 @ @ public abstract class SSTableReader extends SSTable implements SelfRefCounted < SS <nl> } <nl> private static final RateLimiter meterSyncThrottle = RateLimiter . create ( 100 . 0 ) ; <nl> <nl> - public static final Comparator < SSTableReader > maxTimestampComparator = new Comparator < SSTableReader > ( ) <nl> - { <nl> - public int compare ( SSTableReader o1 , SSTableReader o2 ) <nl> - { <nl> - long ts1 = o1 . getMaxTimestamp ( ) ; <nl> - long ts2 = o2 . getMaxTimestamp ( ) ; <nl> - return ( ts1 > ts2 ? - 1 : ( ts1 = = ts2 ? 0 : 1 ) ) ; <nl> - } <nl> - } ; <nl> + public static final Comparator < SSTableReader > maxTimestampComparator = ( o1 , o2 ) - > Long . compare ( o1 . getMaxTimestamp ( ) , o2 . getMaxTimestamp ( ) ) ; <nl> <nl> / / it ' s just an object , which we use regular Object equality on ; we introduce a special class just for easy recognition <nl> public static final class UniqueIdentifier { } <nl> <nl> - public static final Comparator < SSTableReader > sstableComparator = new Comparator < SSTableReader > ( ) <nl> - { <nl> - public int compare ( SSTableReader o1 , SSTableReader o2 ) <nl> - { <nl> - return o1 . first . compareTo ( o2 . first ) ; <nl> - } <nl> - } ; <nl> + public static final Comparator < SSTableReader > sstableComparator = ( o1 , o2 ) - > o1 . first . compareTo ( o2 . first ) ; <nl> + <nl> + public static final Comparator < SSTableReader > generationReverseComparator = ( o1 , o2 ) - > - Integer . compare ( o1 . descriptor . generation , o2 . descriptor . generation ) ; <nl> <nl> public static final Ordering < SSTableReader > sstableOrdering = Ordering . from ( sstableComparator ) ; <nl> <nl> @ @ - 1717 , 7 + 1704 , 7 @ @ public abstract class SSTableReader extends SSTable implements SelfRefCounted < SS <nl> / * * <nl> * Direct I / O SSTableScanner over an iterator of bounds . <nl> * <nl> - * @ param bounds the keys to cover <nl> + * @ param rangeIterator the keys to cover <nl> * @ return A Scanner for seeking over the rows of the SSTable . <nl> * / <nl> public abstract ISSTableScanner getScanner ( Iterator < AbstractBounds < PartitionPosition > > rangeIterator ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / cql3 / CQLTester . java b / test / unit / org / apache / cassandra / cql3 / CQLTester . java <nl> index ba23c67 . . 40aec88 100644 <nl> - - - a / test / unit / org / apache / cassandra / cql3 / CQLTester . java <nl> + + + b / test / unit / org / apache / cassandra / cql3 / CQLTester . java <nl> @ @ - 396 , 7 + 396 , 8 @ @ public abstract class CQLTester <nl> public void disableCompaction ( String keyspace ) <nl> { <nl> ColumnFamilyStore store = getCurrentColumnFamilyStore ( keyspace ) ; <nl> - store . disableAutoCompaction ( ) ; <nl> + if ( store ! = null ) <nl> + store . disableAutoCompaction ( ) ; <nl> } <nl> <nl> public void flush ( boolean forceFlush ) <nl> @ @ - 437 , 6 + 438 , 23 @ @ public abstract class CQLTester <nl> } <nl> } <nl> <nl> + public void disableCompaction ( ) <nl> + { <nl> + disableCompaction ( KEYSPACE ) ; <nl> + } <nl> + <nl> + public void enableCompaction ( String keyspace ) <nl> + { <nl> + ColumnFamilyStore store = getCurrentColumnFamilyStore ( keyspace ) ; <nl> + if ( store ! = null ) <nl> + store . enableAutoCompaction ( ) ; <nl> + } <nl> + <nl> + public void enableCompaction ( ) <nl> + { <nl> + enableCompaction ( KEYSPACE ) ; <nl> + } <nl> + <nl> public void cleanupCache ( ) <nl> { <nl> ColumnFamilyStore store = getCurrentColumnFamilyStore ( ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / cql3 / validation / entities / UserTypesTest . java b / test / unit / org / apache / cassandra / cql3 / validation / entities / UserTypesTest . java <nl> index c279e00 . . dfc2e5e 100644 <nl> - - - a / test / unit / org / apache / cassandra / cql3 / validation / entities / UserTypesTest . java <nl> + + + b / test / unit / org / apache / cassandra / cql3 / validation / entities / UserTypesTest . java <nl> @ @ - 562 , 6 + 562 , 157 @ @ public class UserTypesTest extends CQLTester <nl> assertInvalidMessage ( " Cannot drop user type " + typeWithKs ( t ) , " DROP TYPE " + typeWithKs ( t ) + ' ; ' ) ; <nl> } <nl> <nl> + @ Test <nl> + public void testReadAfterAlteringUserTypeNestedWithinSet ( ) throws Throwable <nl> + { <nl> + String columnType = typeWithKs ( createType ( " CREATE TYPE % s ( a int ) " ) ) ; <nl> + <nl> + try <nl> + { <nl> + createTable ( " CREATE TABLE % s ( x int PRIMARY KEY , y set < frozen < " + columnType + " > > ) " ) ; <nl> + disableCompaction ( ) ; <nl> + <nl> + execute ( " INSERT INTO % s ( x , y ) VALUES ( 1 , ? ) " , set ( userType ( 1 ) , userType ( 2 ) ) ) ; <nl> + assertRows ( execute ( " SELECT * FROM % s " ) , row ( 1 , set ( userType ( 1 ) , userType ( 2 ) ) ) ) ; <nl> + flush ( ) ; <nl> + <nl> + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , <nl> + row ( 1 , set ( userType ( 1 ) , userType ( 2 ) ) ) ) ; <nl> + <nl> + execute ( " ALTER TYPE " + columnType + " ADD b int " ) ; <nl> + execute ( " UPDATE % s SET y = y + ? WHERE x = 1 " , <nl> + set ( userType ( 1 , 1 ) , userType ( 1 , 2 ) , userType ( 2 , 1 ) ) ) ; <nl> + <nl> + flush ( ) ; <nl> + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , <nl> + row ( 1 , set ( userType ( 1 ) , <nl> + userType ( 1 , 1 ) , <nl> + userType ( 1 , 2 ) , <nl> + userType ( 2 ) , <nl> + userType ( 2 , 1 ) ) ) ) ; <nl> + <nl> + compact ( ) ; <nl> + <nl> + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , <nl> + row ( 1 , set ( userType ( 1 ) , <nl> + userType ( 1 , 1 ) , <nl> + userType ( 1 , 2 ) , <nl> + userType ( 2 ) , <nl> + userType ( 2 , 1 ) ) ) ) ; <nl> + } <nl> + finally <nl> + { <nl> + enableCompaction ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void testReadAfterAlteringUserTypeNestedWithinMap ( ) throws Throwable <nl> + { <nl> + String columnType = typeWithKs ( createType ( " CREATE TYPE % s ( a int ) " ) ) ; <nl> + <nl> + try <nl> + { <nl> + createTable ( " CREATE TABLE % s ( x int PRIMARY KEY , y map < frozen < " + columnType + " > , int > ) " ) ; <nl> + disableCompaction ( ) ; <nl> + <nl> + execute ( " INSERT INTO % s ( x , y ) VALUES ( 1 , ? ) " , map ( userType ( 1 ) , 1 , userType ( 2 ) , 2 ) ) ; <nl> + assertRows ( execute ( " SELECT * FROM % s " ) , row ( 1 , map ( userType ( 1 ) , 1 , userType ( 2 ) , 2 ) ) ) ; <nl> + flush ( ) ; <nl> + <nl> + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , <nl> + row ( 1 , map ( userType ( 1 ) , 1 , userType ( 2 ) , 2 ) ) ) ; <nl> + <nl> + execute ( " ALTER TYPE " + columnType + " ADD b int " ) ; <nl> + execute ( " UPDATE % s SET y = y + ? WHERE x = 1 " , <nl> + map ( userType ( 1 , 1 ) , 1 , userType ( 1 , 2 ) , 1 , userType ( 2 , 1 ) , 2 ) ) ; <nl> + <nl> + flush ( ) ; <nl> + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , <nl> + row ( 1 , map ( userType ( 1 ) , 1 , <nl> + userType ( 1 , 1 ) , 1 , <nl> + userType ( 1 , 2 ) , 1 , <nl> + userType ( 2 ) , 2 , <nl> + userType ( 2 , 1 ) , 2 ) ) ) ; <nl> + <nl> + compact ( ) ; <nl> + <nl> + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , <nl> + row ( 1 , map ( userType ( 1 ) , 1 , <nl> + userType ( 1 , 1 ) , 1 , <nl> + userType ( 1 , 2 ) , 1 , <nl> + userType ( 2 ) , 2 , <nl> + userType ( 2 , 1 ) , 2 ) ) ) ; <nl> + } <nl> + finally <nl> + { <nl> + enableCompaction ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void testReadAfterAlteringUserTypeNestedWithinList ( ) throws Throwable <nl> + { <nl> + String columnType = typeWithKs ( createType ( " CREATE TYPE % s ( a int ) " ) ) ; <nl> + <nl> + try <nl> + { <nl> + createTable ( " CREATE TABLE % s ( x int PRIMARY KEY , y list < frozen < " + columnType + " > > ) " ) ; <nl> + disableCompaction ( ) ; <nl> + <nl> + execute ( " INSERT INTO % s ( x , y ) VALUES ( 1 , ? ) " , list ( userType ( 1 ) , userType ( 2 ) ) ) ; <nl> + assertRows ( execute ( " SELECT * FROM % s " ) , row ( 1 , list ( userType ( 1 ) , userType ( 2 ) ) ) ) ; <nl> + flush ( ) ; <nl> + <nl> + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , <nl> + row ( 1 , list ( userType ( 1 ) , userType ( 2 ) ) ) ) ; <nl> + <nl> + execute ( " ALTER TYPE " + columnType + " ADD b int " ) ; <nl> + execute ( " UPDATE % s SET y = y + ? WHERE x = 1 " , <nl> + list ( userType ( 1 , 1 ) , userType ( 1 , 2 ) , userType ( 2 , 1 ) ) ) ; <nl> + <nl> + flush ( ) ; <nl> + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , <nl> + row ( 1 , list ( userType ( 1 ) , <nl> + userType ( 2 ) , <nl> + userType ( 1 , 1 ) , <nl> + userType ( 1 , 2 ) , <nl> + userType ( 2 , 1 ) ) ) ) ; <nl> + <nl> + compact ( ) ; <nl> + <nl> + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , <nl> + row ( 1 , list ( userType ( 1 ) , <nl> + userType ( 2 ) , <nl> + userType ( 1 , 1 ) , <nl> + userType ( 1 , 2 ) , <nl> + userType ( 2 , 1 ) ) ) ) ; <nl> + } <nl> + finally <nl> + { <nl> + enableCompaction ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void testAlteringUserTypeNestedWithinSetWithView ( ) throws Throwable <nl> + { <nl> + String columnType = typeWithKs ( createType ( " CREATE TYPE % s ( a int ) " ) ) ; <nl> + <nl> + createTable ( " CREATE TABLE % s ( pk int , c int , v int , s set < frozen < " + columnType + " > > , PRIMARY KEY ( pk , c ) ) " ) ; <nl> + execute ( " CREATE MATERIALIZED VIEW " + keyspace ( ) + " . view1 AS SELECT c , pk , v FROM % s WHERE pk IS NOT NULL AND c IS NOT NULL AND v IS NOT NULL PRIMARY KEY ( c , pk ) " ) ; <nl> + <nl> + execute ( " INSERT INTO % s ( pk , c , v , s ) VALUES ( ? , ? , ? , ? ) " , 1 , 1 , 1 , set ( userType ( 1 ) , userType ( 2 ) ) ) ; <nl> + flush ( ) ; <nl> + <nl> + execute ( " ALTER TYPE " + columnType + " ADD b int " ) ; <nl> + execute ( " UPDATE % s SET s = s + ? , v = ? WHERE pk = ? AND c = ? " , <nl> + set ( userType ( 1 , 1 ) , userType ( 1 , 2 ) , userType ( 2 , 1 ) ) , 2 , 1 , 1 ) ; <nl> + <nl> + assertRows ( execute ( " SELECT * FROM % s WHERE pk = ? AND c = ? " , 1 , 1 ) , <nl> + row ( 1 , 1 , set ( userType ( 1 ) , userType ( 1 , 1 ) , userType ( 1 , 2 ) , userType ( 2 ) , userType ( 2 , 1 ) ) , 2 ) ) ; <nl> + } <nl> + <nl> private String typeWithKs ( String type1 ) <nl> { <nl> return keyspace ( ) + ' . ' + type1 ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / rows / AbstractTypeVersionComparatorTest . java b / test / unit / org / apache / cassandra / db / rows / AbstractTypeVersionComparatorTest . java <nl> new file mode 100644 <nl> index 0000000 . . ad0c05c <nl> - - - / dev / null <nl> + + + b / test / unit / org / apache / cassandra / db / rows / AbstractTypeVersionComparatorTest . java <nl> @ @ - 0 , 0 + 1 , 184 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an " AS IS " BASIS , <nl> + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + * See the License for the specific language governing permissions and <nl> + * limitations under the License . <nl> + * / <nl> + package org . apache . cassandra . db . rows ; <nl> + <nl> + import java . nio . ByteBuffer ; <nl> + import java . util . Set ; <nl> + <nl> + import org . junit . After ; <nl> + import org . junit . Before ; <nl> + import org . junit . Test ; <nl> + <nl> + import org . apache . cassandra . db . marshal . * ; <nl> + <nl> + import static java . util . Arrays . asList ; <nl> + import static org . apache . cassandra . utils . ByteBufferUtil . bytes ; <nl> + import static org . junit . Assert . assertEquals ; <nl> + import static org . junit . Assert . fail ; <nl> + <nl> + public class AbstractTypeVersionComparatorTest <nl> + { <nl> + private UserType udtWith2Fields ; <nl> + private UserType udtWith3Fields ; <nl> + <nl> + @ Before <nl> + public void setUp ( ) <nl> + { <nl> + udtWith2Fields = new UserType ( " ks " , <nl> + bytes ( " myType " ) , <nl> + asList ( bytes ( " a " ) , bytes ( " b " ) ) , <nl> + asList ( Int32Type . instance , Int32Type . instance ) ) ; <nl> + udtWith3Fields = new UserType ( " ks " , <nl> + bytes ( " myType " ) , <nl> + asList ( bytes ( " a " ) , bytes ( " b " ) , bytes ( " c " ) ) , <nl> + asList ( Int32Type . instance , Int32Type . instance , Int32Type . instance ) ) ; <nl> + } <nl> + <nl> + @ After <nl> + public void tearDown ( ) <nl> + { <nl> + udtWith2Fields = null ; <nl> + udtWith3Fields = null ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testWithTuples ( ) <nl> + { <nl> + checkComparisonResults ( new TupleType ( asList ( Int32Type . instance , Int32Type . instance ) ) , <nl> + new TupleType ( asList ( Int32Type . instance , Int32Type . instance , Int32Type . instance ) ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testWithUDTs ( ) <nl> + { <nl> + checkComparisonResults ( udtWith2Fields , udtWith3Fields ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testWithUDTsNestedWithinSet ( ) <nl> + { <nl> + for ( boolean isMultiCell : new boolean [ ] { false , true } ) <nl> + { <nl> + SetType < ByteBuffer > set1 = SetType . getInstance ( udtWith2Fields , isMultiCell ) ; <nl> + SetType < ByteBuffer > set2 = SetType . getInstance ( udtWith3Fields , isMultiCell ) ; <nl> + checkComparisonResults ( set1 , set2 ) ; <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void testWithUDTsNestedWithinList ( ) <nl> + { <nl> + for ( boolean isMultiCell : new boolean [ ] { false , true } ) <nl> + { <nl> + ListType < ByteBuffer > list1 = ListType . getInstance ( udtWith2Fields , isMultiCell ) ; <nl> + ListType < ByteBuffer > list2 = ListType . getInstance ( udtWith3Fields , isMultiCell ) ; <nl> + checkComparisonResults ( list1 , list2 ) ; <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void testWithUDTsNestedWithinMap ( ) <nl> + { <nl> + for ( boolean isMultiCell : new boolean [ ] { false , true } ) <nl> + { <nl> + MapType < ByteBuffer , Integer > map1 = MapType . getInstance ( udtWith2Fields , Int32Type . instance , isMultiCell ) ; <nl> + MapType < ByteBuffer , Integer > map2 = MapType . getInstance ( udtWith3Fields , Int32Type . instance , isMultiCell ) ; <nl> + checkComparisonResults ( map1 , map2 ) ; <nl> + } <nl> + <nl> + for ( boolean isMultiCell : new boolean [ ] { false , true } ) <nl> + { <nl> + MapType < Integer , ByteBuffer > map1 = MapType . getInstance ( Int32Type . instance , udtWith2Fields , isMultiCell ) ; <nl> + MapType < Integer , ByteBuffer > map2 = MapType . getInstance ( Int32Type . instance , udtWith3Fields , isMultiCell ) ; <nl> + checkComparisonResults ( map1 , map2 ) ; <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void testWithUDTsNestedWithinTuple ( ) <nl> + { <nl> + TupleType tuple1 = new TupleType ( asList ( udtWith2Fields , Int32Type . instance ) ) ; <nl> + TupleType tuple2 = new TupleType ( asList ( udtWith3Fields , Int32Type . instance ) ) ; <nl> + checkComparisonResults ( tuple1 , tuple2 ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testWithUDTsNestedWithinComposite ( ) <nl> + { <nl> + CompositeType composite1 = CompositeType . getInstance ( asList ( udtWith2Fields , Int32Type . instance ) ) ; <nl> + CompositeType composite2 = CompositeType . getInstance ( asList ( udtWith3Fields , Int32Type . instance ) ) ; <nl> + checkComparisonResults ( composite1 , composite2 ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testWithDeeplyNestedUDT ( ) <nl> + { <nl> + for ( boolean isMultiCell : new boolean [ ] { false , true } ) <nl> + { <nl> + ListType < Set < ByteBuffer > > list1 = ListType . getInstance ( SetType . getInstance ( new TupleType ( asList ( udtWith2Fields , Int32Type . instance ) ) , isMultiCell ) , isMultiCell ) ; <nl> + ListType < Set < ByteBuffer > > list2 = ListType . getInstance ( SetType . getInstance ( new TupleType ( asList ( udtWith3Fields , Int32Type . instance ) ) , isMultiCell ) , isMultiCell ) ; <nl> + checkComparisonResults ( list1 , list2 ) ; <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void testInvalidComparison ( ) <nl> + { <nl> + assertInvalidComparison ( " Trying to compare 2 different types : org . apache . cassandra . db . marshal . UserType ( ks , 6d7954797065 , 61 : org . apache . cassandra . db . marshal . Int32Type , 62 : org . apache . cassandra . db . marshal . Int32Type ) and org . apache . cassandra . db . marshal . Int32Type " , <nl> + udtWith2Fields , <nl> + Int32Type . instance ) ; <nl> + assertInvalidComparison ( " Trying to compare 2 different types : org . apache . cassandra . db . marshal . UTF8Type and org . apache . cassandra . db . marshal . InetAddressType " , <nl> + SetType . getInstance ( UTF8Type . instance , true ) , <nl> + SetType . getInstance ( InetAddressType . instance , true ) ) ; <nl> + assertInvalidComparison ( " Trying to compare 2 different types : org . apache . cassandra . db . marshal . UTF8Type and org . apache . cassandra . db . marshal . InetAddressType " , <nl> + ListType . getInstance ( UTF8Type . instance , true ) , <nl> + ListType . getInstance ( InetAddressType . instance , true ) ) ; <nl> + assertInvalidComparison ( " Trying to compare 2 different types : org . apache . cassandra . db . marshal . UTF8Type and org . apache . cassandra . db . marshal . InetAddressType " , <nl> + MapType . getInstance ( UTF8Type . instance , IntegerType . instance , true ) , <nl> + MapType . getInstance ( InetAddressType . instance , IntegerType . instance , true ) ) ; <nl> + assertInvalidComparison ( " Trying to compare 2 different types : org . apache . cassandra . db . marshal . UTF8Type and org . apache . cassandra . db . marshal . InetAddressType " , <nl> + MapType . getInstance ( IntegerType . instance , UTF8Type . instance , true ) , <nl> + MapType . getInstance ( IntegerType . instance , InetAddressType . instance , true ) ) ; <nl> + } <nl> + <nl> + private void assertInvalidComparison ( String expectedMessage , AbstractType < ? > oldVersion , AbstractType < ? > newVersion ) <nl> + { <nl> + try <nl> + { <nl> + checkComparisonResults ( oldVersion , newVersion ) ; <nl> + fail ( " comparison doesn ' t throw expected IllegalArgumentException : " + expectedMessage ) ; <nl> + } <nl> + catch ( IllegalArgumentException e ) <nl> + { <nl> + assertEquals ( e . getMessage ( ) , expectedMessage ) ; <nl> + } <nl> + } <nl> + <nl> + private void checkComparisonResults ( AbstractType < ? > oldVersion , AbstractType < ? > newVersion ) <nl> + { <nl> + assertEquals ( 0 , compare ( oldVersion , oldVersion ) ) ; <nl> + assertEquals ( 0 , compare ( newVersion , newVersion ) ) ; <nl> + assertEquals ( - 1 , compare ( oldVersion , newVersion ) ) ; <nl> + assertEquals ( 1 , compare ( newVersion , oldVersion ) ) ; <nl> + } <nl> + <nl> + private int compare ( AbstractType < ? > left , AbstractType < ? > right ) <nl> + { <nl> + return AbstractTypeVersionComparator . INSTANCE . compare ( left , right ) ; <nl> + } <nl> + }
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 8dc4e5b . . 3c92516 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 11 , 11 + 11 , 14 @ @ <nl> * JDBC CQL driver exposes getColumn for access to timestamp <nl> * JDBC ResultSetMetadata properties added to AbstractType <nl> * r / m clustertool ( CASSANDRA - 2607 ) <nl> + * add support for presenting row key as a column in CQL result sets <nl> + ( CASSANDRA - 2622 ) <nl> <nl> <nl> 0 . 8 . 0 - beta2 <nl> * fix NPE compacting index CFs ( CASSANDRA - 2528 ) <nl> - * Remove checking all column families on startup for compaction candidates ( CASSANDRA - 2444 ) <nl> + * Remove checking all column families on startup for compaction candidates <nl> + ( CASSANDRA - 2444 ) <nl> * validate CQL create keyspace options ( CASSANDRA - 2525 ) <nl> * fix nodetool setcompactionthroughput ( CASSANDRA - 2550 ) <nl> * move 	 gossip heartbeat back to its own thread ( CASSANDRA - 2554 ) <nl> diff - - git a / drivers / java / src / org / apache / cassandra / cql / jdbc / ColumnDecoder . java b / drivers / java / src / org / apache / cassandra / cql / jdbc / ColumnDecoder . java <nl> index a6367b5 . . 606bb1b 100644 <nl> - - - a / drivers / java / src / org / apache / cassandra / cql / jdbc / ColumnDecoder . java <nl> + + + b / drivers / java / src / org / apache / cassandra / cql / jdbc / ColumnDecoder . java <nl> @ @ - 25 , 6 + 25 , 7 @ @ import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . ColumnDefinition ; <nl> import org . apache . cassandra . config . ConfigurationException ; <nl> import org . apache . cassandra . db . marshal . AbstractType ; <nl> + import org . apache . cassandra . db . marshal . AsciiType ; <nl> import org . apache . cassandra . thrift . * ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . apache . cassandra . utils . FBUtilities ; <nl> @ @ - 33 , 6 + 34 , 7 @ @ import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> import java . nio . ByteBuffer ; <nl> + import java . nio . charset . CharacterCodingException ; <nl> import java . util . HashMap ; <nl> import java . util . List ; <nl> import java . util . Map ; <nl> @ @ - 80 , 12 + 82 , 30 @ @ class ColumnDecoder <nl> { <nl> <nl> CFMetaData md = metadata . get ( String . format ( " % s . % s " , keyspace , columnFamily ) ) ; <nl> + try <nl> + { <nl> + if ( ByteBufferUtil . string ( name ) . equalsIgnoreCase ( ByteBufferUtil . string ( md . getKeyName ( ) ) ) ) <nl> + return AsciiType . instance ; <nl> + } <nl> + catch ( CharacterCodingException e ) <nl> + { <nl> + / / not be the key name <nl> + } <nl> return md . comparator ; <nl> } <nl> <nl> AbstractType getValueType ( String keyspace , String columnFamily , ByteBuffer name ) <nl> { <nl> CFMetaData md = metadata . get ( String . format ( " % s . % s " , keyspace , columnFamily ) ) ; <nl> + try <nl> + { <nl> + if ( ByteBufferUtil . string ( name ) . equalsIgnoreCase ( ByteBufferUtil . string ( md . getKeyName ( ) ) ) ) <nl> + return md . getKeyValidator ( ) ; <nl> + } <nl> + catch ( CharacterCodingException e ) <nl> + { <nl> + / / not be the key name <nl> + } <nl> ColumnDefinition cd = md . getColumnDefinition ( name ) ; <nl> return cd = = null ? md . getDefaultValidator ( ) : cd . getValidator ( ) ; <nl> } <nl> diff - - git a / drivers / java / test / org / apache / cassandra / cql / JdbcDriverTest . java b / drivers / java / test / org / apache / cassandra / cql / JdbcDriverTest . java <nl> index f5301ab . . f3f748f 100644 <nl> - - - a / drivers / java / test / org / apache / cassandra / cql / JdbcDriverTest . java <nl> + + + b / drivers / java / test / org / apache / cassandra / cql / JdbcDriverTest . java <nl> @ @ - 33 , 6 + 33 , 7 @ @ import org . junit . BeforeClass ; <nl> import org . junit . Test ; <nl> <nl> import org . apache . cassandra . db . marshal . * ; <nl> + import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . apache . cassandra . utils . FBUtilities ; <nl> <nl> import static junit . framework . Assert . assertEquals ; <nl> @ @ - 120 , 6 + 121 , 12 @ @ public class JdbcDriverTest extends EmbeddedServiceBase <nl> expectedMetaData ( md , 2 , BigInteger . class . getName ( ) , " JdbcInteger " , " Keyspace1 " , " 2 " , Types . BIGINT , IntegerType . class . getSimpleName ( ) , true , false ) ; <nl> expectedMetaData ( md , 3 , String . class . getName ( ) , " JdbcInteger " , " Keyspace1 " , " 42 " , Types . VARCHAR , UTF8Type . class . getSimpleName ( ) , false , true ) ; <nl> <nl> + rs = stmt . executeQuery ( " select key , 1 , 2 , 42 from JdbcInteger where key = ' " + key + " ' " ) ; <nl> + assert rs . next ( ) ; <nl> + assert Arrays . equals ( rs . getBytes ( " key " ) , FBUtilities . hexToBytes ( key ) ) ; <nl> + assert rs . getObject ( " 1 " ) . equals ( new BigInteger ( " 36893488147419103232 " ) ) ; <nl> + assert rs . getString ( " 42 " ) . equals ( " fortytwofortytwo " ) : rs . getString ( " 42 " ) ; <nl> + <nl> stmt . executeUpdate ( " update JdbcUtf8 set a = ' aa ' , b = ' bb ' , fortytwo = ' 4242 ' where key = ' " + key + " ' " ) ; <nl> rs = stmt . executeQuery ( " select a , b , fortytwo from JdbcUtf8 where key = ' " + key + " ' " ) ; <nl> assert rs . next ( ) ; <nl> diff - - git a / drivers / py / cql / _ _ init _ _ . py b / drivers / py / cql / _ _ init _ _ . py <nl> index b5b58bc . . de00876 100644 <nl> - - - a / drivers / py / cql / _ _ init _ _ . py <nl> + + + b / drivers / py / cql / _ _ init _ _ . py <nl> @ @ - 45 , 8 + 45 , 6 @ @ apilevel = 1 . 0 <nl> threadsafety = 1 # Threads may share the module , but not connections / cursors . <nl> paramstyle = ' named ' <nl> <nl> - ROW _ KEY = " Row Key " <nl> - <nl> # TODO : Pull connections out of a pool instead . <nl> def connect ( host , port = 9160 , keyspace = ' system ' , user = None , password = None ) : <nl> return connection . Connection ( host , port , keyspace , user , password ) <nl> diff - - git a / drivers / py / cql / cursor . py b / drivers / py / cql / cursor . py <nl> index 9771c67 . . 8858d8d 100644 <nl> - - - a / drivers / py / cql / cursor . py <nl> + + + b / drivers / py / cql / cursor . py <nl> @ @ - 92 , 16 + 92 , 14 @ @ class Cursor : <nl> return results <nl> <nl> def column _ families ( cf _ defs ) : <nl> - cfresults = { } <nl> - if cf _ defs : <nl> - for cf in cf _ defs : <nl> - cfresults [ cf . name ] = { " comparator " : cf . comparator _ type } <nl> - cfresults [ cf . name ] [ " default _ validation _ class " ] = \ <nl> - cf . default _ validation _ class <nl> - cfresults [ cf . name ] [ " key _ validation _ class " ] = \ <nl> - cf . key _ validation _ class <nl> - cfresults [ cf . name ] [ " columns " ] = columns ( cf . column _ metadata ) <nl> - return cfresults <nl> + d = { } <nl> + for cf in cf _ defs : <nl> + d [ cf . name ] = { ' comparator ' : cf . comparator _ type , <nl> + ' default _ validation _ class ' : cf . default _ validation _ class , <nl> + ' key _ validation _ class ' : cf . key _ validation _ class , <nl> + ' columns ' : columns ( cf . column _ metadata ) , <nl> + ' key _ alias ' : cf . key _ alias } <nl> + return d <nl> <nl> schema = { } <nl> client = self . parent _ connection . client <nl> diff - - git a / drivers / py / cql / decoders . py b / drivers / py / cql / decoders . py <nl> index 9d7cad1 . . f91e2b2 100644 <nl> - - - a / drivers / py / cql / decoders . py <nl> + + + b / drivers / py / cql / decoders . py <nl> @ @ - 32 , 45 + 32 , 44 @ @ class SchemaDecoder ( object ) : <nl> <nl> def _ _ comparator _ for ( self , keyspace , column _ family ) : <nl> cfam = self . _ _ get _ column _ family _ def ( keyspace , column _ family ) <nl> - if cfam and " comparator " in cfam : <nl> + if " comparator " in cfam : <nl> return cfam [ " comparator " ] <nl> return None <nl> <nl> def _ _ validator _ for ( self , keyspace , column _ family , name ) : <nl> cfam = self . _ _ get _ column _ family _ def ( keyspace , column _ family ) <nl> - if cfam : <nl> - if name in cfam [ " columns " ] : <nl> - return cfam [ " columns " ] [ name ] <nl> - return cfam [ " default _ validation _ class " ] <nl> - return None <nl> + if name in cfam [ " columns " ] : <nl> + return cfam [ " columns " ] [ name ] <nl> + return cfam [ " default _ validation _ class " ] <nl> <nl> def _ _ keytype _ for ( self , keyspace , column _ family ) : <nl> cfam = self . _ _ get _ column _ family _ def ( keyspace , column _ family ) <nl> - if cfam and " key _ validation _ class " in cfam : <nl> + if " key _ validation _ class " in cfam : <nl> return cfam [ " key _ validation _ class " ] <nl> return None <nl> <nl> def decode _ description ( self , keyspace , column _ family , row ) : <nl> - key _ type = self . _ _ keytype _ for ( keyspace , column _ family ) <nl> - description = [ ( cql . ROW _ KEY , key _ type , None , None , None , None , None , False ) ] <nl> + description = [ ] <nl> comparator = self . _ _ comparator _ for ( keyspace , column _ family ) <nl> unmarshal = unmarshallers . get ( comparator , unmarshal _ noop ) <nl> for column in row . columns : <nl> - description . append ( ( unmarshal ( column . name ) , comparator , None , None , None , None , True ) ) <nl> - <nl> + if column . name = = self . _ _ get _ column _ family _ def ( keyspace , column _ family ) [ ' key _ alias ' ] : <nl> + description . append ( ( column . name , ' text ' , None , None , None , None , True ) ) <nl> + else : <nl> + description . append ( ( unmarshal ( column . name ) , comparator , None , None , None , None , True ) ) <nl> return description <nl> <nl> def decode _ row ( self , keyspace , column _ family , row ) : <nl> - key _ type = self . _ _ keytype _ for ( keyspace , column _ family ) <nl> - key = unmarshallers . get ( key _ type , unmarshal _ noop ) ( row . key ) <nl> comparator = self . _ _ comparator _ for ( keyspace , column _ family ) <nl> unmarshal = unmarshallers . get ( comparator , unmarshal _ noop ) <nl> - values = [ key ] <nl> + values = [ ] <nl> for column in row . columns : <nl> - validator = self . _ _ validator _ for ( keyspace , column _ family , column . name ) <nl> if column . value is None : <nl> values . append ( None ) <nl> + continue <nl> + if column . name = = self . _ _ get _ column _ family _ def ( keyspace , column _ family ) [ ' key _ alias ' ] : <nl> + validator = self . _ _ keytype _ for ( keyspace , column _ family ) <nl> else : <nl> - values . append ( unmarshallers . get ( validator , unmarshal _ noop ) ( column . value ) ) <nl> - <nl> + validator = self . _ _ validator _ for ( keyspace , column _ family , column . name ) <nl> + values . append ( unmarshallers . get ( validator , unmarshal _ noop ) ( column . value ) ) <nl> return values <nl> diff - - git a / src / java / org / apache / cassandra / config / CFMetaData . java b / src / java / org / apache / cassandra / config / CFMetaData . java <nl> index 992c55d . . ebebe4d 100644 <nl> - - - a / src / java / org / apache / cassandra / config / CFMetaData . java <nl> + + + b / src / java / org / apache / cassandra / config / CFMetaData . java <nl> @ @ - 78 , 6 + 78 , 7 @ @ public final class CFMetaData <nl> public static final CFMetaData SchemaCf = newSystemMetadata ( Migration . SCHEMA _ CF , 3 , " current state of the schema " , UTF8Type . instance , null , DEFAULT _ SYSTEM _ MEMTABLE _ THROUGHPUT _ IN _ MB ) ; <nl> public static final CFMetaData IndexCf = newSystemMetadata ( SystemTable . INDEX _ CF , 5 , " indexes that have been completed " , UTF8Type . instance , null , DEFAULT _ SYSTEM _ MEMTABLE _ THROUGHPUT _ IN _ MB ) ; <nl> public static final CFMetaData NodeIdCf = newSystemMetadata ( SystemTable . NODE _ ID _ CF , 6 , " nodeId and their metadata " , TimeUUIDType . instance , null , DEFAULT _ SYSTEM _ MEMTABLE _ THROUGHPUT _ IN _ MB ) ; <nl> + private static final ByteBuffer DEFAULT _ KEY _ NAME = ByteBufferUtil . bytes ( " KEY " ) ; <nl> <nl> / * * <nl> * @ return A calculated memtable throughput size for this machine . <nl> @ @ - 504 , 9 + 505 , 9 @ @ public final class CFMetaData <nl> return rowCacheProvider ; <nl> } <nl> <nl> - public ByteBuffer getKeyAlias ( ) <nl> + public ByteBuffer getKeyName ( ) <nl> { <nl> - return keyAlias ; <nl> + return keyAlias = = null ? DEFAULT _ KEY _ NAME : keyAlias ; <nl> } <nl> <nl> public Map < ByteBuffer , ColumnDefinition > getColumn _ metadata ( ) <nl> @ @ - 640 , 7 + 641 , 6 @ @ public final class CFMetaData <nl> <nl> validateMinMaxCompactionThresholds ( cf _ def ) ; <nl> validateMemtableSettings ( cf _ def ) ; <nl> - validateAliasCompares ( cf _ def ) ; <nl> <nl> CFMetaData newCFMD = new CFMetaData ( cf _ def . keyspace , <nl> cf _ def . name , <nl> @ @ - 785 , 7 + 785 , 7 @ @ public final class CFMetaData <nl> def . setMemtable _ throughput _ in _ mb ( cfm . memtableThroughputInMb ) ; <nl> def . setMemtable _ operations _ in _ millions ( cfm . memtableOperationsInMillions ) ; <nl> def . setMerge _ shards _ chance ( cfm . mergeShardsChance ) ; <nl> - def . setKey _ alias ( cfm . keyAlias ) ; <nl> + def . setKey _ alias ( cfm . getKeyName ( ) ) ; <nl> List < org . apache . cassandra . thrift . ColumnDef > column _ meta = new ArrayList < org . apache . cassandra . thrift . ColumnDef > ( cfm . column _ metadata . size ( ) ) ; <nl> for ( ColumnDefinition cd : cfm . column _ metadata . values ( ) ) <nl> { <nl> @ @ - 970 , 13 + 970 , 6 @ @ public final class CFMetaData <nl> DatabaseDescriptor . validateMemtableOperations ( cf _ def . memtable _ operations _ in _ millions ) ; <nl> } <nl> <nl> - public static void validateAliasCompares ( org . apache . cassandra . thrift . CfDef cf _ def ) throws ConfigurationException <nl> - { <nl> - AbstractType comparator = DatabaseDescriptor . getComparator ( cf _ def . comparator _ type ) ; <nl> - if ( cf _ def . key _ alias ! = null ) <nl> - comparator . validate ( cf _ def . key _ alias ) ; <nl> - } <nl> - <nl> public static void validateAliasCompares ( org . apache . cassandra . db . migration . avro . CfDef cf _ def ) throws ConfigurationException <nl> { <nl> AbstractType comparator = DatabaseDescriptor . getComparator ( cf _ def . comparator _ type ) ; <nl> diff - - git a / src / java / org / apache / cassandra / cql / Cql . g b / src / java / org / apache / cassandra / cql / Cql . g <nl> index 6d4c707 . . 3b0d812 100644 <nl> - - - a / src / java / org / apache / cassandra / cql / Cql . g <nl> + + + b / src / java / org / apache / cassandra / cql / Cql . g <nl> @ @ - 167 , 8 + 167 , 8 @ @ selectExpression returns [ SelectExpression expr ] <nl> ( K _ REVERSED { reversed = true ; } ) ? <nl> ( first = term { $ expr = new SelectExpression ( first , count , reversed ) ; } <nl> ( ' , ' next = term { $ expr . and ( next ) ; } ) * <nl> - | start = term RANGEOP finish = term { $ expr = new SelectExpression ( start , finish , count , reversed ) ; } <nl> - | ' \ * ' { $ expr = new SelectExpression ( new Term ( ) , new Term ( ) , count , reversed ) ; } <nl> + | start = term RANGEOP finish = term { $ expr = new SelectExpression ( start , finish , count , reversed , false ) ; } <nl> + | ' \ * ' { $ expr = new SelectExpression ( new Term ( ) , new Term ( ) , count , reversed , true ) ; } <nl> ) <nl> ; <nl> <nl> @ @ - 346 , 7 + 346 , 7 @ @ comparatorType <nl> ; <nl> <nl> term returns [ Term item ] <nl> - : ( t = STRING _ LITERAL | t = INTEGER | t = UUID | t = IDENT ) { $ item = new Term ( $ t . text , $ t . type ) ; } <nl> + : ( t = K _ KEY | t = STRING _ LITERAL | t = INTEGER | t = UUID | t = IDENT ) { $ item = new Term ( $ t . text , $ t . type ) ; } <nl> ; <nl> <nl> termList returns [ List < Term > items ] <nl> diff - - git a / src / java / org / apache / cassandra / cql / QueryProcessor . java b / src / java / org / apache / cassandra / cql / QueryProcessor . java <nl> index 08556b3 . . 8bd0724 100644 <nl> - - - a / src / java / org / apache / cassandra / cql / QueryProcessor . java <nl> + + + b / src / java / org / apache / cassandra / cql / QueryProcessor . java <nl> @ @ - 23 , 6 + 23 , 7 @ @ package org . apache . cassandra . cql ; <nl> <nl> import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> + import java . nio . charset . CharacterCodingException ; <nl> import java . util . * ; <nl> import java . util . concurrent . Callable ; <nl> import java . util . concurrent . ExecutionException ; <nl> @ @ - 67 , 7 + 68 , 6 @ @ public class QueryProcessor <nl> { <nl> List < org . apache . cassandra . db . Row > rows ; <nl> QueryPath queryPath = new QueryPath ( select . getColumnFamily ( ) ) ; <nl> - AbstractType < ? > comparator = select . getComparator ( keyspace ) ; <nl> List < ReadCommand > commands = new ArrayList < ReadCommand > ( ) ; <nl> <nl> assert select . getKeys ( ) . size ( ) = = 1 ; <nl> @ @ - 79 , 16 + 79 , 14 @ @ public class QueryProcessor <nl> / / . . . of a list of column names <nl> if ( ! select . isColumnRange ( ) ) <nl> { <nl> - Collection < ByteBuffer > columnNames = new ArrayList < ByteBuffer > ( ) ; <nl> - for ( Term column : select . getColumnNames ( ) ) <nl> - columnNames . add ( column . getByteBuffer ( comparator ) ) ; <nl> - <nl> + Collection < ByteBuffer > columnNames = getColumnNames ( select , metadata ) ; <nl> validateColumnNames ( columnNames ) ; <nl> commands . add ( new SliceByNamesReadCommand ( keyspace , key , queryPath , columnNames ) ) ; <nl> } <nl> / / . . . a range ( slice ) of column names <nl> else <nl> { <nl> + AbstractType < ? > comparator = select . getComparator ( keyspace ) ; <nl> ByteBuffer start = select . getColumnStart ( ) . getByteBuffer ( comparator ) ; <nl> ByteBuffer finish = select . getColumnFinish ( ) . getByteBuffer ( comparator ) ; <nl> <nl> @ @ - 117 , 7 + 115 , 20 @ @ public class QueryProcessor <nl> <nl> return rows ; <nl> } <nl> - <nl> + <nl> + private static List < ByteBuffer > getColumnNames ( SelectStatement select , CFMetaData metadata ) throws InvalidRequestException <nl> + { <nl> + String keyString = getKeyString ( metadata ) ; <nl> + List < ByteBuffer > columnNames = new ArrayList < ByteBuffer > ( ) ; <nl> + for ( Term column : select . getColumnNames ( ) ) <nl> + { <nl> + / / skip the key for the slice op ; we ' ll add it to the resultset in extractThriftColumns <nl> + if ( ! column . getText ( ) . equalsIgnoreCase ( keyString ) ) <nl> + columnNames . add ( column . getByteBuffer ( metadata . comparator ) ) ; <nl> + } <nl> + return columnNames ; <nl> + } <nl> + <nl> private static List < org . apache . cassandra . db . Row > multiRangeSlice ( String keyspace , SelectStatement select ) <nl> throws TimedOutException , UnavailableException , InvalidRequestException <nl> { <nl> @ @ - 146 , 9 + 157 , 8 @ @ public class QueryProcessor <nl> AbstractBounds bounds = new Bounds ( startToken , finishToken ) ; <nl> <nl> CFMetaData metadata = validateColumnFamily ( keyspace , select . getColumnFamily ( ) , false ) ; <nl> - AbstractType < ? > comparator = metadata . getComparatorFor ( null ) ; <nl> / / XXX : Our use of Thrift structs internally makes me Sad . : ( <nl> - SlicePredicate thriftSlicePredicate = slicePredicateFromSelect ( select , comparator ) ; <nl> + SlicePredicate thriftSlicePredicate = slicePredicateFromSelect ( select , metadata ) ; <nl> validateSlicePredicate ( metadata , thriftSlicePredicate ) ; <nl> <nl> int limit = select . isKeyRange ( ) & & select . getKeyStart ( ) ! = null <nl> @ @ - 200 , 16 + 210 , 15 @ @ public class QueryProcessor <nl> throws TimedOutException , UnavailableException , InvalidRequestException <nl> { <nl> CFMetaData metadata = validateColumnFamily ( keyspace , select . getColumnFamily ( ) , false ) ; <nl> - AbstractType < ? > comparator = metadata . getComparatorFor ( null ) ; <nl> / / XXX : Our use of Thrift structs internally ( still ) makes me Sad . : ~ ( <nl> - SlicePredicate thriftSlicePredicate = slicePredicateFromSelect ( select , comparator ) ; <nl> + SlicePredicate thriftSlicePredicate = slicePredicateFromSelect ( select , metadata ) ; <nl> validateSlicePredicate ( metadata , thriftSlicePredicate ) ; <nl> <nl> List < IndexExpression > expressions = new ArrayList < IndexExpression > ( ) ; <nl> for ( Relation columnRelation : select . getColumnRelations ( ) ) <nl> { <nl> / / Left and right side of relational expression encoded according to comparator / validator . <nl> - ByteBuffer entity = columnRelation . getEntity ( ) . getByteBuffer ( comparator ) ; <nl> + ByteBuffer entity = columnRelation . getEntity ( ) . getByteBuffer ( metadata . comparator ) ; <nl> ByteBuffer value = columnRelation . getValue ( ) . getByteBuffer ( select . getValueValidator ( keyspace , entity ) ) ; <nl> <nl> expressions . add ( new IndexExpression ( entity , <nl> @ @ - 291 , 7 + 300 , 7 @ @ public class QueryProcessor <nl> } <nl> } <nl> <nl> - private static SlicePredicate slicePredicateFromSelect ( SelectStatement select , AbstractType < ? > comparator ) <nl> + private static SlicePredicate slicePredicateFromSelect ( SelectStatement select , CFMetaData metadata ) <nl> throws InvalidRequestException <nl> { <nl> SlicePredicate thriftSlicePredicate = new SlicePredicate ( ) ; <nl> @ @ - 299 , 18 + 308 , 15 @ @ public class QueryProcessor <nl> if ( select . isColumnRange ( ) | | select . getColumnNames ( ) . size ( ) = = 0 ) <nl> { <nl> SliceRange sliceRange = new SliceRange ( ) ; <nl> - sliceRange . start = select . getColumnStart ( ) . getByteBuffer ( comparator ) ; <nl> - sliceRange . finish = select . getColumnFinish ( ) . getByteBuffer ( comparator ) ; <nl> + sliceRange . start = select . getColumnStart ( ) . getByteBuffer ( metadata . comparator ) ; <nl> + sliceRange . finish = select . getColumnFinish ( ) . getByteBuffer ( metadata . comparator ) ; <nl> sliceRange . reversed = select . isColumnsReversed ( ) ; <nl> sliceRange . count = select . getColumnsLimit ( ) ; <nl> thriftSlicePredicate . slice _ range = sliceRange ; <nl> } <nl> else <nl> { <nl> - List < ByteBuffer > columnNames = new ArrayList < ByteBuffer > ( ) ; <nl> - for ( Term column : select . getColumnNames ( ) ) <nl> - columnNames . add ( column . getByteBuffer ( comparator ) ) ; <nl> - thriftSlicePredicate . column _ names = columnNames ; <nl> + thriftSlicePredicate . column _ names = getColumnNames ( select , metadata ) ; <nl> } <nl> <nl> return thriftSlicePredicate ; <nl> @ @ - 489 , 19 + 495 , 17 @ @ public class QueryProcessor <nl> / / Some statements won ' t have ( or don ' t need ) a keyspace ( think USE , or CREATE ) . <nl> if ( StatementType . requiresKeyspace . contains ( statement . type ) ) <nl> keyspace = clientState . getKeyspace ( ) ; <nl> - <nl> + <nl> CqlResult result = new CqlResult ( ) ; <nl> <nl> logger . debug ( " CQL statement type : { } " , statement . type . toString ( ) ) ; <nl> CFMetaData metadata ; <nl> - AbstractType < ? > comparator ; <nl> switch ( statement . type ) <nl> { <nl> case SELECT : <nl> SelectStatement select = ( SelectStatement ) statement . statement ; <nl> clientState . hasColumnFamilyAccess ( select . getColumnFamily ( ) , Permission . READ ) ; <nl> metadata = validateColumnFamily ( keyspace , select . getColumnFamily ( ) , false ) ; <nl> - comparator = metadata . getComparatorFor ( null ) ; <nl> validateSelect ( keyspace , select ) ; <nl> <nl> List < org . apache . cassandra . db . Row > rows = null ; <nl> @ @ - 538 , 7 + 542 , 7 @ @ public class QueryProcessor <nl> <nl> List < CqlRow > cqlRows = new ArrayList < CqlRow > ( ) ; <nl> result . type = CqlResultType . ROWS ; <nl> - <nl> + <nl> / / Create the result set <nl> for ( org . apache . cassandra . db . Row row : rows ) <nl> { <nl> @ @ - 546 , 7 + 550 , 7 @ @ public class QueryProcessor <nl> if ( row . cf = = null ) <nl> continue ; <nl> <nl> - List < Column > thriftColumns = extractThriftColumns ( select , comparator , row ) ; <nl> + List < Column > thriftColumns = extractThriftColumns ( select , metadata , row ) ; <nl> / / Create a new row , add the columns to it , and then add it to the list of rows <nl> CqlRow cqlRow = new CqlRow ( ) ; <nl> cqlRow . key = row . key . key ; <nl> @ @ - 609 , 7 + 613 , 7 @ @ public class QueryProcessor <nl> DeleteStatement delete = ( DeleteStatement ) statement . statement ; <nl> clientState . hasColumnFamilyAccess ( delete . getColumnFamily ( ) , Permission . WRITE ) ; <nl> metadata = validateColumnFamily ( keyspace , delete . getColumnFamily ( ) , false ) ; <nl> - comparator = metadata . getComparatorFor ( null ) ; <nl> + AbstractType comparator = metadata . getComparatorFor ( null ) ; <nl> AbstractType < ? > keyType = DatabaseDescriptor . getCFMetaData ( keyspace , <nl> delete . getColumnFamily ( ) ) . getKeyValidator ( ) ; <nl> <nl> @ @ - 809 , 11 + 813 , 17 @ @ public class QueryProcessor <nl> return null ; / / We should never get here . <nl> } <nl> <nl> - private static List < Column > extractThriftColumns ( SelectStatement select , AbstractType < ? > comparator , Row row ) <nl> + private static List < Column > extractThriftColumns ( SelectStatement select , CFMetaData metadata , Row row ) <nl> { <nl> List < Column > thriftColumns = new ArrayList < Column > ( ) ; <nl> if ( select . isColumnRange ( ) ) <nl> { <nl> + if ( select . isWildcard ( ) ) <nl> + { <nl> + / / prepend key <nl> + thriftColumns . add ( new Column ( metadata . getKeyName ( ) ) . setValue ( row . key . key ) . setTimestamp ( - 1 ) ) ; <nl> + } <nl> + <nl> / / preserve comparator order <nl> for ( IColumn c : row . cf . getSortedColumns ( ) ) <nl> { <nl> @ @ - 824 , 13 + 834 , 23 @ @ public class QueryProcessor <nl> } <nl> else <nl> { <nl> + String keyString = getKeyString ( metadata ) ; <nl> + <nl> / / order columns in the order they were asked for <nl> for ( Term term : select . getColumnNames ( ) ) <nl> { <nl> + if ( term . getText ( ) . equalsIgnoreCase ( keyString ) ) <nl> + { <nl> + / / preserve case of key as it was requested <nl> + ByteBuffer requestedKey = ByteBufferUtil . bytes ( term . getText ( ) ) ; <nl> + thriftColumns . add ( new Column ( requestedKey ) . setValue ( row . key . key ) . setTimestamp ( - 1 ) ) ; <nl> + continue ; <nl> + } <nl> + <nl> ByteBuffer name ; <nl> try <nl> { <nl> - name = term . getByteBuffer ( comparator ) ; <nl> + name = term . getByteBuffer ( metadata . comparator ) ; <nl> } <nl> catch ( InvalidRequestException e ) <nl> { <nl> @ @ - 846 , 6 + 866 , 20 @ @ public class QueryProcessor <nl> return thriftColumns ; <nl> } <nl> <nl> + private static String getKeyString ( CFMetaData metadata ) <nl> + { <nl> + String keyString ; <nl> + try <nl> + { <nl> + keyString = ByteBufferUtil . string ( metadata . getKeyName ( ) ) ; <nl> + } <nl> + catch ( CharacterCodingException e ) <nl> + { <nl> + throw new AssertionError ( e ) ; <nl> + } <nl> + return keyString ; <nl> + } <nl> + <nl> private static CQLStatement getStatement ( String queryStr ) throws InvalidRequestException , RecognitionException <nl> { <nl> / / Lexer and parser <nl> diff - - git a / src / java / org / apache / cassandra / cql / SelectExpression . java b / src / java / org / apache / cassandra / cql / SelectExpression . java <nl> index 562d27d . . f2d8623 100644 <nl> - - - a / src / java / org / apache / cassandra / cql / SelectExpression . java <nl> + + + b / src / java / org / apache / cassandra / cql / SelectExpression . java <nl> @ @ - 37 , 6 + 37 , 7 @ @ public class SelectExpression <nl> <nl> private int numColumns = MAX _ COLUMNS _ DEFAULT ; <nl> private boolean reverseColumns = false ; <nl> + private final boolean wildcard ; <nl> private Term start , finish ; <nl> private List < Term > columns ; <nl> <nl> @ @ - 48 , 12 + 49 , 13 @ @ public class SelectExpression <nl> * @ param count the number of columns to limit the results to <nl> * @ param reverse true to reverse column order <nl> * / <nl> - public SelectExpression ( Term start , Term finish , int count , boolean reverse ) <nl> + public SelectExpression ( Term start , Term finish , int count , boolean reverse , boolean wildcard ) <nl> { <nl> this . start = start ; <nl> this . finish = finish ; <nl> numColumns = count ; <nl> reverseColumns = reverse ; <nl> + this . wildcard = wildcard ; <nl> } <nl> <nl> / * * <nl> @ @ - 65 , 6 + 67 , 7 @ @ public class SelectExpression <nl> * / <nl> public SelectExpression ( Term first , int count , boolean reverse ) <nl> { <nl> + wildcard = false ; <nl> columns = new ArrayList < Term > ( ) ; <nl> columns . add ( first ) ; <nl> numColumns = count ; <nl> @ @ - 125 , 4 + 128 , 9 @ @ public class SelectExpression <nl> { <nl> return columns ; <nl> } <nl> + <nl> + public boolean isWildcard ( ) <nl> + { <nl> + return wildcard ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / cql / SelectStatement . java b / src / java / org / apache / cassandra / cql / SelectStatement . java <nl> index b595806 . . dacba98 100644 <nl> - - - a / src / java / org / apache / cassandra / cql / SelectStatement . java <nl> + + + b / src / java / org / apache / cassandra / cql / SelectStatement . java <nl> @ @ - 81 , 6 + 81 , 11 @ @ public class SelectStatement <nl> { <nl> return expression . isColumnRange ( ) ; <nl> } <nl> + <nl> + public boolean isWildcard ( ) <nl> + { <nl> + return expression . isWildcard ( ) ; <nl> + } <nl> <nl> public List < Term > getColumnNames ( ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / thrift / ThriftValidation . java b / src / java / org / apache / cassandra / thrift / ThriftValidation . java <nl> index f200eca . . 35e042b 100644 <nl> - - - a / src / java / org / apache / cassandra / thrift / ThriftValidation . java <nl> + + + b / src / java / org / apache / cassandra / thrift / ThriftValidation . java <nl> @ @ - 26 , 6 + 26 , 7 @ @ import java . util . * ; <nl> import org . apache . cassandra . config . * ; <nl> import org . apache . cassandra . db . * ; <nl> import org . apache . cassandra . db . marshal . AbstractType ; <nl> + import org . apache . cassandra . db . marshal . AsciiType ; <nl> import org . apache . cassandra . db . marshal . MarshalException ; <nl> import org . apache . cassandra . dht . IPartitioner ; <nl> import org . apache . cassandra . dht . RandomPartitioner ; <nl> @ @ - 515 , 6 + 516 , 22 @ @ public class ThriftValidation <nl> { <nl> try <nl> { <nl> + if ( cf _ def . key _ alias ! = null ) <nl> + { <nl> + if ( ! cf _ def . key _ alias . hasRemaining ( ) ) <nl> + throw new InvalidRequestException ( " key _ alias may not be empty " ) ; <nl> + try <nl> + { <nl> + / / it ' s hard to use a key in a select statement if we can ' t type it . <nl> + / / for now let ' s keep it simple and require ascii . <nl> + AsciiType . instance . validate ( cf _ def . key _ alias ) ; <nl> + } <nl> + catch ( MarshalException e ) <nl> + { <nl> + throw new InvalidRequestException ( " Key aliases must be ascii " ) ; <nl> + } <nl> + } <nl> + <nl> ColumnFamilyType cfType = ColumnFamilyType . create ( cf _ def . column _ type ) ; <nl> if ( cfType = = null ) <nl> throw new InvalidRequestException ( " invalid column type " + cf _ def . column _ type ) ; <nl> diff - - git a / test / system / test _ cql . py b / test / system / test _ cql . py <nl> index a088ed2 . . f1d9ceb 100644 <nl> - - - a / test / system / test _ cql . py <nl> + + + b / test / system / test _ cql . py <nl> @ @ - 127 , 11 + 127 , 11 @ @ class TestCql ( ThriftTester ) : <nl> def test _ select _ simple ( self ) : <nl> " single - row named column queries " <nl> cursor = init ( ) <nl> - cursor . execute ( " SELECT ' ca1 ' FROM StandardString1 WHERE KEY = ' ka ' " ) <nl> + cursor . execute ( " SELECT KEY , ca1 FROM StandardString1 WHERE KEY = ' ka ' " ) <nl> r = cursor . fetchone ( ) <nl> d = cursor . description <nl> <nl> - assert d [ 0 ] [ 0 ] = = cql . ROW _ KEY <nl> + assert d [ 0 ] [ 0 ] = = ' KEY ' <nl> assert r [ 0 ] = = ' ka ' <nl> <nl> assert d [ 1 ] [ 0 ] = = ' ca1 ' <nl> @ @ - 144 , 10 + 144 , 10 @ @ class TestCql ( ThriftTester ) : <nl> " " " ) <nl> <nl> d = cursor . description <nl> - assert [ ' Row Key ' , ' ca1 ' , ' col ' , ' cd1 ' ] = = [ col _ dscptn [ 0 ] for col _ dscptn in d ] , d <nl> + assert [ ' ca1 ' , ' col ' , ' cd1 ' ] = = [ col _ dscptn [ 0 ] for col _ dscptn in d ] , d <nl> row = cursor . fetchone ( ) <nl> # check that the column that didn ' t exist in the row comes back as null <nl> - assert [ ' kd ' , None , ' val ' , ' vd1 ' ] = = row , row <nl> + assert [ None , ' val ' , ' vd1 ' ] = = row , row <nl> <nl> def test _ select _ row _ range ( self ) : <nl> " retrieve a range of rows with columns " <nl> @ @ - 219 , 51 + 219 , 39 @ @ class TestCql ( ThriftTester ) : <nl> " column slice tests " <nl> cursor = init ( ) <nl> <nl> - # all columns <nl> + # * includes row key , explicit slice does not <nl> cursor . execute ( " SELECT * FROM StandardString1 WHERE KEY = ' ka ' ; " ) <nl> - r = cursor . fetchone ( ) <nl> - assert len ( r ) = = 3 <nl> + row = cursor . fetchone ( ) <nl> + assert [ ' ka ' , ' va1 ' , ' val ' ] = = row , row <nl> + <nl> cursor . execute ( " SELECT ' ' . . ' ' FROM StandardString1 WHERE KEY = ' ka ' ; " ) <nl> - r = cursor . fetchone ( ) <nl> - assert len ( r ) = = 3 <nl> + row = cursor . fetchone ( ) <nl> + assert [ ' va1 ' , ' val ' ] = = row , row <nl> <nl> # column subsets <nl> cursor . execute ( " SELECT 1 . . 3 FROM StandardLongA WHERE KEY = ' aa ' ; " ) <nl> assert cursor . rowcount = = 1 <nl> - r = cursor . fetchone ( ) <nl> - assert r [ 0 ] = = " aa " <nl> - assert r [ 1 ] = = " 1 " <nl> - assert r [ 2 ] = = " 2 " <nl> - assert r [ 3 ] = = " 3 " <nl> + row = cursor . fetchone ( ) <nl> + assert [ ' 1 ' , ' 2 ' , ' 3 ' ] = = row , row <nl> <nl> - cursor . execute ( " SELECT 10 . . 30 FROM StandardIntegerA WHERE KEY = ' k1 ' " ) <nl> - assert cursor . rowcount = = 1 <nl> - r = cursor . fetchone ( ) <nl> - assert r [ 0 ] = = " k1 " <nl> - assert r [ 1 ] = = " a " <nl> - assert r [ 2 ] = = " b " <nl> - assert r [ 3 ] = = " c " <nl> - <nl> - # range of columns ( slice ) by row with FIRST <nl> cursor . execute ( " " " <nl> - SELECT FIRST 1 1 . . 3 FROM StandardLongA WHERE KEY = ' aa ' ; <nl> + SELECT key , 20 , 40 FROM StandardIntegerA <nl> + WHERE KEY > ' k1 ' AND KEY < ' k7 ' LIMIT 5 <nl> " " " ) <nl> + row = cursor . fetchone ( ) <nl> + assert [ ' k2 ' , ' f ' , ' h ' ] = = row , row <nl> + <nl> + # range of columns ( slice ) by row with FIRST <nl> + cursor . execute ( " SELECT FIRST 1 1 . . 3 FROM StandardLongA WHERE KEY = ' aa ' " ) <nl> assert cursor . rowcount = = 1 <nl> - r = cursor . fetchone ( ) <nl> - assert len ( r ) = = 2 <nl> - assert r [ 0 ] = = " aa " <nl> - assert r [ 1 ] = = " 1 " <nl> + row = cursor . fetchone ( ) <nl> + assert [ ' 1 ' ] = = row , row <nl> <nl> # range of columns ( slice ) by row reversed <nl> - cursor . execute ( " " " <nl> - SELECT FIRST 2 REVERSED 3 . . 1 FROM StandardLongA WHERE KEY = ' aa ' ; <nl> - " " " ) <nl> + cursor . execute ( " SELECT FIRST 2 REVERSED 3 . . 1 FROM StandardLongA WHERE KEY = ' aa ' " ) <nl> assert cursor . rowcount = = 1 , " % d ! = 1 " % cursor . rowcount <nl> - r = cursor . fetchone ( ) <nl> - assert len ( r ) = = 3 <nl> - assert r [ 0 ] = = ' aa ' <nl> - assert r [ 1 ] = = " 3 " <nl> - assert r [ 2 ] = = " 2 " <nl> + row = cursor . fetchone ( ) <nl> + assert [ ' 3 ' , ' 2 ' ] = = row , row <nl> <nl> def test _ select _ range _ with _ single _ column _ results ( self ) : <nl> " range should not fail when keys were not set " <nl> @ @ - 277 , 7 + 265 , 7 @ @ class TestCql ( ThriftTester ) : <nl> " " " ) <nl> <nl> cursor . execute ( " " " <nl> - SELECT name FROM StandardString2 <nl> + SELECT KEY , name FROM StandardString2 <nl> " " " ) <nl> <nl> assert cursor . rowcount = = 3 , " expected 3 results , got % d " % cursor . rowcount <nl> @ @ - 305 , 7 + 293 , 7 @ @ class TestCql ( ThriftTester ) : <nl> " indexed scan where column equals value " <nl> cursor = init ( ) <nl> cursor . execute ( " " " <nl> - SELECT ' birthdate ' FROM IndexedA WHERE ' birthdate ' = 100 <nl> + SELECT KEY , birthdate FROM IndexedA WHERE birthdate = 100 <nl> " " " ) <nl> assert cursor . rowcount = = 2 <nl> <nl> @ @ - 321 , 19 + 309 , 19 @ @ class TestCql ( ThriftTester ) : <nl> " indexed scan where a column is greater than a value " <nl> cursor = init ( ) <nl> cursor . execute ( " " " <nl> - SELECT ' birthdate ' FROM IndexedA WHERE ' birthdate ' = 100 <nl> - AND ' unindexed ' > 200 <nl> + SELECT KEY , ' birthdate ' FROM IndexedA <nl> + WHERE ' birthdate ' = 100 AND ' unindexed ' > 200 <nl> " " " ) <nl> assert cursor . rowcount = = 1 <nl> - r = cursor . fetchone ( ) <nl> - assert r [ 0 ] = = " asmith " <nl> + row = cursor . fetchone ( ) <nl> + assert row [ 0 ] = = " asmith " , row <nl> <nl> def test _ index _ scan _ with _ start _ key ( self ) : <nl> " indexed scan with a starting key " <nl> cursor = init ( ) <nl> cursor . execute ( " " " <nl> - SELECT ' birthdate ' FROM IndexedA WHERE ' birthdate ' = 100 <nl> - AND KEY > = ' asmithZ ' <nl> + SELECT KEY , ' birthdate ' FROM IndexedA <nl> + WHERE ' birthdate ' = 100 AND KEY > = ' asmithZ ' <nl> " " " ) <nl> assert cursor . rowcount = = 1 <nl> r = cursor . fetchone ( ) <nl> @ @ - 342 , 7 + 330 , 7 @ @ class TestCql ( ThriftTester ) : <nl> def test _ no _ where _ clause ( self ) : <nl> " empty where clause ( range query w / o start key ) " <nl> cursor = init ( ) <nl> - cursor . execute ( " SELECT ' col ' FROM StandardString1 LIMIT 3 " ) <nl> + cursor . execute ( " SELECT KEY , ' col ' FROM StandardString1 LIMIT 3 " ) <nl> assert cursor . rowcount = = 3 <nl> rows = cursor . fetchmany ( 3 ) <nl> assert rows [ 0 ] [ 0 ] = = " ka " <nl> @ @ - 376 , 7 + 364 , 8 @ @ class TestCql ( ThriftTester ) : <nl> cursor . execute ( " " " <nl> SELECT ' cd1 ' , ' col ' FROM StandardString1 WHERE KEY = ' kd ' <nl> " " " ) <nl> - assert [ ' Row Key ' , ' cd1 ' , ' col ' ] = = [ col _ d [ 0 ] for col _ d in cursor . description ] <nl> + desc = [ col _ d [ 0 ] for col _ d in cursor . description ] <nl> + assert [ ' cd1 ' , ' col ' ] = = desc , desc <nl> <nl> cursor . execute ( " " " <nl> DELETE ' cd1 ' , ' col ' FROM StandardString1 WHERE KEY = ' kd ' <nl> @ @ - 384 , 31 + 373 , 31 @ @ class TestCql ( ThriftTester ) : <nl> cursor . execute ( " " " <nl> SELECT ' cd1 ' , ' col ' FROM StandardString1 WHERE KEY = ' kd ' <nl> " " " ) <nl> - r = cursor . fetchone ( ) <nl> - assert [ ' kd ' , None , None ] = = r , r <nl> + row = cursor . fetchone ( ) <nl> + assert [ None , None ] = = row , row <nl> <nl> def test _ delete _ columns _ multi _ rows ( self ) : <nl> " delete columns from multiple rows " <nl> cursor = init ( ) <nl> <nl> + # verify rows exist initially <nl> cursor . execute ( " SELECT ' col ' FROM StandardString1 WHERE KEY = ' kc ' " ) <nl> - r = cursor . fetchone ( ) <nl> - assert [ ' kc ' , ' val ' ] = = r , r <nl> - <nl> + row = cursor . fetchone ( ) <nl> + assert [ ' val ' ] = = row , row <nl> cursor . execute ( " SELECT ' col ' FROM StandardString1 WHERE KEY = ' kd ' " ) <nl> - r = cursor . fetchone ( ) <nl> - assert [ ' kd ' , ' val ' ] = = r , r <nl> + row = cursor . fetchone ( ) <nl> + assert [ ' val ' ] = = row , row <nl> <nl> + # delete and verify data is gone <nl> cursor . execute ( " " " <nl> DELETE ' col ' FROM StandardString1 WHERE KEY IN ( ' kc ' , ' kd ' ) <nl> " " " ) <nl> cursor . execute ( " SELECT ' col ' FROM StandardString1 WHERE KEY = ' kc ' " ) <nl> - r = cursor . fetchone ( ) <nl> - assert [ ' kc ' , None ] = = r , r <nl> - <nl> + row = cursor . fetchone ( ) <nl> + assert [ None ] = = row , row <nl> cursor . execute ( " SELECT ' col ' FROM StandardString1 WHERE KEY = ' kd ' " ) <nl> r = cursor . fetchone ( ) <nl> - assert [ ' kd ' , None ] = = r , r <nl> + assert [ None ] = = r , r <nl> <nl> def test _ delete _ rows ( self ) : <nl> " delete entire rows " <nl> @ @ - 416 , 13 + 405 , 13 @ @ class TestCql ( ThriftTester ) : <nl> cursor . execute ( " " " <nl> SELECT ' cd1 ' , ' col ' FROM StandardString1 WHERE KEY = ' kd ' <nl> " " " ) <nl> - assert [ ' Row Key ' , ' cd1 ' , ' col ' ] = = [ col _ d [ 0 ] for col _ d in cursor . description ] <nl> + assert [ ' cd1 ' , ' col ' ] = = [ col _ d [ 0 ] for col _ d in cursor . description ] <nl> cursor . execute ( " DELETE FROM StandardString1 WHERE KEY = ' kd ' " ) <nl> cursor . execute ( " " " <nl> SELECT ' cd1 ' , ' col ' FROM StandardString1 WHERE KEY = ' kd ' <nl> " " " ) <nl> - r = cursor . fetchone ( ) <nl> - assert [ ' kd ' , None , None ] = = r , r <nl> + row = cursor . fetchone ( ) <nl> + assert [ None , None ] = = row , row <nl> <nl> def test _ create _ keyspace ( self ) : <nl> " create a new keyspace " <nl> @ @ - 578 , 7 + 567 , 7 @ @ class TestCql ( ThriftTester ) : <nl> SELECT ' % s ' FROM StandardTimeUUID WHERE KEY = ' uuidtest ' <nl> " " " % str ( timeuuid ) ) <nl> d = cursor . description <nl> - assert d [ 1 ] [ 0 ] = = timeuuid , " % s , % s " % ( str ( d [ 1 ] [ 0 ] ) , str ( timeuuid ) ) <nl> + assert d [ 0 ] [ 0 ] = = timeuuid , " % s , % s " % ( str ( d [ 1 ] [ 0 ] ) , str ( timeuuid ) ) <nl> <nl> # Tests a node - side conversion from bigint to UUID . <nl> ms = uuid1bytes _ to _ millis ( uuid . uuid1 ( ) . bytes ) <nl> @ @ - 590 , 7 + 579 , 7 @ @ class TestCql ( ThriftTester ) : <nl> SELECT ' id ' FROM StandardTimeUUIDValues WHERE KEY = ' uuidtest ' <nl> " " " ) <nl> r = cursor . fetchone ( ) <nl> - assert uuid1bytes _ to _ millis ( r [ 1 ] . bytes ) = = ms <nl> + assert uuid1bytes _ to _ millis ( r [ 0 ] . bytes ) = = ms <nl> <nl> # Tests a node - side conversion from ISO8601 to UUID . <nl> cursor . execute ( " " " <nl> @ @ - 603 , 7 + 592 , 7 @ @ class TestCql ( ThriftTester ) : <nl> " " " ) <nl> # 2011 - 01 - 31 17 : 00 : 00 - 0000 = = 1296493200000ms <nl> r = cursor . fetchone ( ) <nl> - ms = uuid1bytes _ to _ millis ( r [ 1 ] . bytes ) <nl> + ms = uuid1bytes _ to _ millis ( r [ 0 ] . bytes ) <nl> assert ms = = 1296493200000 , \ <nl> " % d ! = 1296493200000 ( 2011 - 01 - 31 17 : 00 : 00 - 0000 ) " % ms <nl> <nl> @ @ - 617 , 7 + 606 , 7 @ @ class TestCql ( ThriftTester ) : <nl> SELECT ' id3 ' FROM StandardTimeUUIDValues WHERE KEY = ' uuidtest ' <nl> " " " ) <nl> r = cursor . fetchone ( ) <nl> - ms = uuid1bytes _ to _ millis ( r [ 1 ] . bytes ) <nl> + ms = uuid1bytes _ to _ millis ( r [ 0 ] . bytes ) <nl> assert ( ( time . time ( ) * 1e3 ) - ms ) < 100 , \ <nl> " new timeuuid not within 100ms of now ( UPDATE vs . SELECT ) " <nl> <nl> @ @ - 631 , 7 + 620 , 7 @ @ class TestCql ( ThriftTester ) : <nl> SELECT : start . . : finish FROM StandardTimeUUID WHERE KEY = slicetest <nl> " " " , dict ( start = uuid _ range [ 0 ] , finish = uuid _ range [ len ( uuid _ range ) - 1 ] ) ) <nl> d = cursor . description <nl> - for ( i , col _ d ) in enumerate ( d [ 1 : ] ) : <nl> + for ( i , col _ d ) in enumerate ( d ) : <nl> assert uuid _ range [ i ] = = col _ d [ 0 ] <nl> <nl> <nl> @ @ - 645 , 7 + 634 , 7 @ @ class TestCql ( ThriftTester ) : <nl> cursor . execute ( " SELECT : name FROM StandardUUID WHERE KEY = ' uuidtest ' " , <nl> dict ( name = uid ) ) <nl> d = cursor . description <nl> - assert d [ 1 ] [ 0 ] = = uid , " expected % s , got % s ( % s ) " % \ <nl> + assert d [ 0 ] [ 0 ] = = uid , " expected % s , got % s ( % s ) " % \ <nl> ( uid . bytes . encode ( ' hex ' ) , str ( d [ 1 ] [ 0 ] ) . encode ( ' hex ' ) , d [ 1 ] [ 1 ] ) <nl> <nl> # TODO : slices of uuids from cf w / LexicalUUIDType comparator <nl> @ @ - 661 , 18 + 650 , 19 @ @ class TestCql ( ThriftTester ) : <nl> <nl> cursor . execute ( " SELECT * FROM StandardUtf82 WHERE KEY = k1 " ) <nl> d = cursor . description <nl> + assert d [ 0 ] [ 0 ] = = ' KEY ' , d [ 0 ] [ 0 ] <nl> assert d [ 1 ] [ 0 ] = = u "  " , d [ 1 ] [ 0 ] <nl> assert d [ 2 ] [ 0 ] = = u "  " , d [ 2 ] [ 0 ] <nl> assert d [ 3 ] [ 0 ] = = u "  " , d [ 3 ] [ 0 ] <nl> assert d [ 4 ] [ 0 ] = = u "  " , d [ 4 ] [ 0 ] <nl> <nl> cursor . execute ( " SELECT : start . . ' ' FROM StandardUtf82 WHERE KEY = k1 " , dict ( start = "  " ) ) <nl> - r = cursor . fetchone ( ) <nl> - assert len ( r ) = = 4 <nl> + row = cursor . fetchone ( ) <nl> + assert len ( row ) = = 3 , row <nl> d = cursor . description <nl> - assert d [ 1 ] [ 0 ] = = u "  " <nl> - assert d [ 2 ] [ 0 ] = = u "  " <nl> - assert d [ 3 ] [ 0 ] = = u "  " <nl> + assert d [ 0 ] [ 0 ] = = u "  " <nl> + assert d [ 1 ] [ 0 ] = = u "  " <nl> + assert d [ 2 ] [ 0 ] = = u "  " <nl> <nl> def test _ read _ write _ negative _ numerics ( self ) : <nl> " reading and writing negative numeric values " <nl> @ @ - 685 , 11 + 675 , 11 @ @ class TestCql ( ThriftTester ) : <nl> cursor . execute ( " SELECT : start . . : finish FROM : cf WHERE KEY = negatives ; " , <nl> dict ( start = - 10 , finish = - 1 , cf = cf ) ) <nl> r = cursor . fetchone ( ) <nl> - assert len ( r ) = = 11 , \ <nl> + assert len ( r ) = = 10 , \ <nl> " returned % d columns , expected % d " % ( len ( r ) - 1 , 10 ) <nl> d = cursor . description <nl> - assert d [ 1 ] [ 0 ] = = - 10 <nl> - assert d [ 10 ] [ 0 ] = = - 1 <nl> + assert d [ 0 ] [ 0 ] = = - 10 <nl> + assert d [ 9 ] [ 0 ] = = - 1 <nl> <nl> def test _ escaped _ quotes ( self ) : <nl> " reading and writing strings w / escaped quotes " <nl> @ @ - 704 , 17 + 694 , 17 @ @ class TestCql ( ThriftTester ) : <nl> " " " , dict ( key = " test _ escaped _ quotes " ) ) <nl> assert cursor . rowcount = = 1 <nl> r = cursor . fetchone ( ) <nl> - assert len ( r ) = = 2 , " wrong number of results " <nl> + assert len ( r ) = = 1 , " wrong number of results " <nl> d = cursor . description <nl> - assert d [ 1 ] [ 0 ] = = " x \ ' and \ ' y " <nl> - <nl> + assert d [ 0 ] [ 0 ] = = " x ' and ' y " <nl> + <nl> def test _ typed _ keys ( self ) : <nl> " using typed keys " <nl> cursor = init ( ) <nl> cursor . execute ( " SELECT * FROM StandardString1 WHERE KEY = : key " , dict ( key = " ka " ) ) <nl> - r = cursor . fetchone ( ) <nl> - assert isinstance ( r [ 0 ] , unicode ) , \ <nl> - " wrong key - type returned , expected unicode , got % s " % type ( r [ 0 ] ) <nl> + row = cursor . fetchone ( ) <nl> + assert isinstance ( row [ 0 ] , unicode ) , \ <nl> + " wrong key - type returned , expected unicode , got % s " % type ( row [ 0 ] ) <nl> <nl> # FIXME : The above is woefully inadequate , but the test config uses <nl> # CollatingOrderPreservingPartitioner which only supports UTF8 . <nl> @ @ - 760 , 8 + 750 , 6 @ @ class TestCql ( ThriftTester ) : <nl> <nl> assert cursor . rowcount = = 1 , " expected 1 result , got % d " % cursor . rowcount <nl> colnames = [ col _ d [ 0 ] for col _ d in cursor . description ] <nl> - assert colnames [ 1 ] = = " some _ name " , \ <nl> - " unrecognized name ' % s ' " % colnames [ 1 ] <nl> - r = cursor . fetchone ( ) <nl> - assert r [ 1 ] = = " some _ value " , \ <nl> - " unrecognized value ' % s ' " % r [ 1 ] <nl> + assert [ ' some _ name ' ] = = colnames , colnames <nl> + row = cursor . fetchone ( ) <nl> + assert [ ' some _ value ' ] = = row , row

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index a35cc1b . . ba35152 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 3 . 0 . 15 
 + * Fix the merging of cells with different user type versions ( CASSANDRA - 13776 ) 
 * Copy session properties on cqlsh . py do _ login ( CASSANDRA - 13640 ) 
 * Potential AssertionError during ReadRepair of range tombstone and partition deletions ( CASSANDRA - 13719 ) 
 * Don ' t let stress write warmup data if n = 0 ( CASSANDRA - 13773 ) 
 diff - - git a / src / java / org / apache / cassandra / db / SerializationHeader . java b / src / java / org / apache / cassandra / db / SerializationHeader . java 
 index 19dad95 . . 494c2a3 100644 
 - - - a / src / java / org / apache / cassandra / db / SerializationHeader . java 
 + + + b / src / java / org / apache / cassandra / db / SerializationHeader . java 
 @ @ - 108 , 7 + 108 , 8 @ @ public class SerializationHeader 
 / / but rather on their stats stored in StatsMetadata that are fully accurate . 
 EncodingStats . Collector stats = new EncodingStats . Collector ( ) ; 
 PartitionColumns . Builder columns = PartitionColumns . builder ( ) ; 
 - for ( SSTableReader sstable : sstables ) 
 + / / We need to order the SSTables by descending generation to be sure that we use latest column definitions . 
 + for ( SSTableReader sstable : orderByDescendingGeneration ( sstables ) ) 
 { 
 stats . updateTimestamp ( sstable . getMinTimestamp ( ) ) ; 
 stats . updateLocalDeletionTime ( sstable . getMinLocalDeletionTime ( ) ) ; 
 @ @ - 121 , 6 + 122 , 16 @ @ public class SerializationHeader 
 return new SerializationHeader ( true , metadata , columns . build ( ) , stats . get ( ) ) ; 
 } 
 
 + private static Collection < SSTableReader > orderByDescendingGeneration ( Collection < SSTableReader > sstables ) 
 + { 
 + if ( sstables . size ( ) < 2 ) 
 + return sstables ; 
 + 
 + List < SSTableReader > readers = new ArrayList < > ( sstables ) ; 
 + readers . sort ( SSTableReader . generationReverseComparator ) ; 
 + return readers ; 
 + } 
 + 
 public SerializationHeader ( boolean isForSSTable , 
 CFMetaData metadata , 
 PartitionColumns columns , 
 diff - - git a / src / java / org / apache / cassandra / db / marshal / AbstractType . java b / src / java / org / apache / cassandra / db / marshal / AbstractType . java 
 index 77e0971 . . 20062bd 100644 
 - - - a / src / java / org / apache / cassandra / db / marshal / AbstractType . java 
 + + + b / src / java / org / apache / cassandra / db / marshal / AbstractType . java 
 @ @ - 325 , 6 + 325 , 16 @ @ public abstract class AbstractType < T > implements Comparator < ByteBuffer > 
 return false ; 
 } 
 
 + public boolean isTuple ( ) 
 + { 
 + return false ; 
 + } 
 + 
 + public boolean isUDT ( ) 
 + { 
 + return false ; 
 + } 
 + 
 public AbstractType < ? > freeze ( ) 
 { 
 return this ; 
 diff - - git a / src / java / org / apache / cassandra / db / marshal / TupleType . java b / src / java / org / apache / cassandra / db / marshal / TupleType . java 
 index 2d6363e . . 5c74332 100644 
 - - - a / src / java / org / apache / cassandra / db / marshal / TupleType . java 
 + + + b / src / java / org / apache / cassandra / db / marshal / TupleType . java 
 @ @ - 347 , 4 + 347 , 9 @ @ public class TupleType extends AbstractType < ByteBuffer > 
 { 
 return getClass ( ) . getName ( ) + TypeParser . stringifyTypeParameters ( types , true ) ; 
 } 
 + 
 + public boolean isTuple ( ) 
 + { 
 + return true ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / marshal / UserType . java b / src / java / org / apache / cassandra / db / marshal / UserType . java 
 index b91dbf8 . . 03545ca 100644 
 - - - a / src / java / org / apache / cassandra / db / marshal / UserType . java 
 + + + b / src / java / org / apache / cassandra / db / marshal / UserType . java 
 @ @ - 232 , 4 + 232 , 14 @ @ public class UserType extends TupleType 
 { 
 return serializer ; 
 } 
 + 
 + public boolean isTuple ( ) 
 + { 
 + return false ; 
 + } 
 + 
 + public boolean isUDT ( ) 
 + { 
 + return true ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / rows / AbstractTypeVersionComparator . java b / src / java / org / apache / cassandra / db / rows / AbstractTypeVersionComparator . java 
 new file mode 100644 
 index 0000000 . . e47f681 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / db / rows / AbstractTypeVersionComparator . java 
 @ @ - 0 , 0 + 1 , 121 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , software 
 + * distributed under the License is distributed on an " AS IS " BASIS , 
 + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + * See the License for the specific language governing permissions and 
 + * limitations under the License . 
 + * / 
 + package org . apache . cassandra . db . rows ; 
 + 
 + import java . util . Comparator ; 
 + import java . util . List ; 
 + 
 + import org . apache . cassandra . db . marshal . * ; 
 + 
 + / * * 
 + * A { @ code Comparator } use to determine which version of a type should be used . 
 + * < p > In the case of UDTs it is possible to have 2 versions or more of the same type , if some fields has been added to 
 + * the type . To avoid problems the latest type need to be used . < / p > 
 + * / 
 + final class AbstractTypeVersionComparator implements Comparator < AbstractType < ? > > 
 + { 
 + public static final Comparator < AbstractType < ? > > INSTANCE = new AbstractTypeVersionComparator ( ) ; 
 + 
 + private AbstractTypeVersionComparator ( ) 
 + { 
 + } 
 + 
 + @ Override 
 + public int compare ( AbstractType < ? > type , AbstractType < ? > otherType ) 
 + { 
 + if ( ! type . getClass ( ) . equals ( otherType . getClass ( ) ) ) 
 + throw new IllegalArgumentException ( String . format ( " Trying to compare 2 different types : % s and % s " , 
 + type , 
 + otherType ) ) ; 
 + 
 + if ( type . equals ( otherType ) ) 
 + return 0 ; 
 + 
 + / / The only case where 2 types can differ is if they contains some UDTs and one of them has more 
 + / / fields ( due to an ALTER type ADD ) than in the other type . In this case we need to pick the type with 
 + / / the bigger amount of fields . 
 + if ( type . isUDT ( ) ) 
 + return compareUserType ( ( UserType ) type , ( UserType ) otherType ) ; 
 + 
 + if ( type . isTuple ( ) ) 
 + return compareTuple ( ( TupleType ) type , ( TupleType ) otherType ) ; 
 + 
 + if ( type . isCollection ( ) ) 
 + return compareCollectionTypes ( type , otherType ) ; 
 + 
 + if ( type instanceof CompositeType ) 
 + return compareCompositeTypes ( ( CompositeType ) type , ( CompositeType ) otherType ) ; 
 + 
 + / / In theory we should never reach that point but to be on the safe side we allow it . 
 + return 0 ; 
 + } 
 + 
 + private int compareCompositeTypes ( CompositeType type , CompositeType otherType ) 
 + { 
 + List < AbstractType < ? > > types = type . getComponents ( ) ; 
 + List < AbstractType < ? > > otherTypes = otherType . getComponents ( ) ; 
 + 
 + if ( types . size ( ) ! = otherTypes . size ( ) ) 
 + return Integer . compare ( types . size ( ) , otherTypes . size ( ) ) ; 
 + 
 + for ( int i = 0 , m = type . componentsCount ( ) ; i < m ; i + + ) 
 + { 
 + int test = compare ( types . get ( i ) , otherTypes . get ( i ) ) ; 
 + if ( test ! = 0 ) ; 
 + return test ; 
 + } 
 + return 0 ; 
 + } 
 + 
 + private int compareCollectionTypes ( AbstractType < ? > type , AbstractType < ? > otherType ) 
 + { 
 + if ( type instanceof MapType ) 
 + return compareMapType ( ( MapType < ? , ? > ) type , ( MapType < ? , ? > ) otherType ) ; 
 + 
 + if ( type instanceof SetType ) 
 + return compare ( ( ( SetType < ? > ) type ) . getElementsType ( ) , ( ( SetType < ? > ) otherType ) . getElementsType ( ) ) ; 
 + 
 + return compare ( ( ( ListType < ? > ) type ) . getElementsType ( ) , ( ( ListType < ? > ) otherType ) . getElementsType ( ) ) ; 
 + } 
 + 
 + private int compareMapType ( MapType < ? , ? > type , MapType < ? , ? > otherType ) 
 + { 
 + int test = compare ( type . getKeysType ( ) , otherType . getKeysType ( ) ) ; 
 + return test ! = 0 ? test : compare ( type . getValuesType ( ) , otherType . getValuesType ( ) ) ; 
 + } 
 + 
 + private int compareUserType ( UserType type , UserType otherType ) 
 + { 
 + return compareTuple ( type , otherType ) ; 
 + } 
 + 
 + private int compareTuple ( TupleType type , TupleType otherType ) 
 + { 
 + if ( type . size ( ) ! = otherType . size ( ) ) 
 + return Integer . compare ( type . size ( ) , otherType . size ( ) ) ; 
 + 
 + int test = 0 ; 
 + int i = 0 ; 
 + while ( test = = 0 & & i < type . size ( ) ) 
 + { 
 + test = compare ( type . type ( i ) , otherType . type ( i ) ) ; 
 + i + + ; 
 + } 
 + return test ; 
 + } 
 + } 
 diff - - git a / src / java / org / apache / cassandra / db / rows / Row . java b / src / java / org / apache / cassandra / db / rows / Row . java 
 index a61f365 . . 9ab1f09 100644 
 - - - a / src / java / org / apache / cassandra / db / rows / Row . java 
 + + + b / src / java / org / apache / cassandra / db / rows / Row . java 
 @ @ - 601 , 10 + 601 , 25 @ @ public interface Row extends Unfiltered , Collection < ColumnData > 
 
 public void reduce ( int idx , ColumnData data ) 
 { 
 - column = data . column ( ) ; 
 + if ( useColumnDefinition ( data . column ( ) ) ) 
 + column = data . column ( ) ; 
 + 
 versions . add ( data ) ; 
 } 
 
 + / * * 
 + * Determines it the { @ code ColumnDefinition } is the one that should be used . 
 + * @ param dataColumn the { @ code ColumnDefinition } to use . 
 + * @ return { @ code true } if the { @ code ColumnDefinition } is the one that should be used , { @ code false } otherwise . 
 + * / 
 + private boolean useColumnDefinition ( ColumnDefinition dataColumn ) 
 + { 
 + if ( column = = null ) 
 + return true ; 
 + 
 + return AbstractTypeVersionComparator . INSTANCE . compare ( column . type , dataColumn . type ) < 0 ; 
 + } 
 + 
 protected ColumnData getReduced ( ) 
 { 
 if ( column . isSimple ( ) ) 
 @ @ - 654 , 6 + 669 , 7 @ @ public interface Row extends Unfiltered , Collection < ColumnData > 
 
 protected void onKeyChange ( ) 
 { 
 + column = null ; 
 versions . clear ( ) ; 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / rows / Rows . java b / src / java / org / apache / cassandra / db / rows / Rows . java 
 index e325091 . . 09213a4 100644 
 - - - a / src / java / org / apache / cassandra / db / rows / Rows . java 
 + + + b / src / java / org / apache / cassandra / db / rows / Rows . java 
 @ @ - 279 , 7 + 279 , 8 @ @ public abstract class Rows 
 int comparison = nexta = = null ? 1 : nextb = = null ? - 1 : nexta . column . compareTo ( nextb . column ) ; 
 ColumnData cura = comparison < = 0 ? nexta : null ; 
 ColumnData curb = comparison > = 0 ? nextb : null ; 
 - ColumnDefinition column = ( cura ! = null ? cura : curb ) . column ; 
 + ColumnDefinition column = getColumnDefinition ( cura , curb ) ; 
 + 
 if ( column . isSimple ( ) ) 
 { 
 timeDelta = Math . min ( timeDelta , Cells . reconcile ( ( Cell ) cura , ( Cell ) curb , deletion , builder , nowInSec ) ) ; 
 @ @ - 309 , 4 + 310 , 22 @ @ public abstract class Rows 
 } 
 return timeDelta ; 
 } 
 + 
 + / * * 
 + * Returns the { @ code ColumnDefinition } to use for merging the columns . 
 + * If the 2 column definitions are different the latest one will be returned . 
 + * / 
 + private static ColumnDefinition getColumnDefinition ( ColumnData cura , ColumnData curb ) 
 + { 
 + if ( cura = = null ) 
 + return curb . column ; 
 + 
 + if ( curb = = null ) 
 + return cura . column ; 
 + 
 + if ( AbstractTypeVersionComparator . INSTANCE . compare ( cura . column . type , curb . column . type ) > = 0 ) 
 + return cura . column ; 
 + 
 + return curb . column ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / format / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / format / SSTableReader . java 
 index f38738d . . cd41b5b 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / format / SSTableReader . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / format / SSTableReader . java 
 @ @ - 45 , 7 + 45 , 6 @ @ import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . config . Schema ; 
 import org . apache . cassandra . db . * ; 
 - import org . apache . cassandra . db . commitlog . ReplayPosition ; 
 import org . apache . cassandra . db . filter . ColumnFilter ; 
 import org . apache . cassandra . db . rows . SliceableUnfilteredRowIterator ; 
 import org . apache . cassandra . dht . AbstractBounds ; 
 @ @ - 141 , 26 + 140 , 14 @ @ public abstract class SSTableReader extends SSTable implements SelfRefCounted < SS 
 } 
 private static final RateLimiter meterSyncThrottle = RateLimiter . create ( 100 . 0 ) ; 
 
 - public static final Comparator < SSTableReader > maxTimestampComparator = new Comparator < SSTableReader > ( ) 
 - { 
 - public int compare ( SSTableReader o1 , SSTableReader o2 ) 
 - { 
 - long ts1 = o1 . getMaxTimestamp ( ) ; 
 - long ts2 = o2 . getMaxTimestamp ( ) ; 
 - return ( ts1 > ts2 ? - 1 : ( ts1 = = ts2 ? 0 : 1 ) ) ; 
 - } 
 - } ; 
 + public static final Comparator < SSTableReader > maxTimestampComparator = ( o1 , o2 ) - > Long . compare ( o1 . getMaxTimestamp ( ) , o2 . getMaxTimestamp ( ) ) ; 
 
 / / it ' s just an object , which we use regular Object equality on ; we introduce a special class just for easy recognition 
 public static final class UniqueIdentifier { } 
 
 - public static final Comparator < SSTableReader > sstableComparator = new Comparator < SSTableReader > ( ) 
 - { 
 - public int compare ( SSTableReader o1 , SSTableReader o2 ) 
 - { 
 - return o1 . first . compareTo ( o2 . first ) ; 
 - } 
 - } ; 
 + public static final Comparator < SSTableReader > sstableComparator = ( o1 , o2 ) - > o1 . first . compareTo ( o2 . first ) ; 
 + 
 + public static final Comparator < SSTableReader > generationReverseComparator = ( o1 , o2 ) - > - Integer . compare ( o1 . descriptor . generation , o2 . descriptor . generation ) ; 
 
 public static final Ordering < SSTableReader > sstableOrdering = Ordering . from ( sstableComparator ) ; 
 
 @ @ - 1717 , 7 + 1704 , 7 @ @ public abstract class SSTableReader extends SSTable implements SelfRefCounted < SS 
 / * * 
 * Direct I / O SSTableScanner over an iterator of bounds . 
 * 
 - * @ param bounds the keys to cover 
 + * @ param rangeIterator the keys to cover 
 * @ return A Scanner for seeking over the rows of the SSTable . 
 * / 
 public abstract ISSTableScanner getScanner ( Iterator < AbstractBounds < PartitionPosition > > rangeIterator ) ; 
 diff - - git a / test / unit / org / apache / cassandra / cql3 / CQLTester . java b / test / unit / org / apache / cassandra / cql3 / CQLTester . java 
 index ba23c67 . . 40aec88 100644 
 - - - a / test / unit / org / apache / cassandra / cql3 / CQLTester . java 
 + + + b / test / unit / org / apache / cassandra / cql3 / CQLTester . java 
 @ @ - 396 , 7 + 396 , 8 @ @ public abstract class CQLTester 
 public void disableCompaction ( String keyspace ) 
 { 
 ColumnFamilyStore store = getCurrentColumnFamilyStore ( keyspace ) ; 
 - store . disableAutoCompaction ( ) ; 
 + if ( store ! = null ) 
 + store . disableAutoCompaction ( ) ; 
 } 
 
 public void flush ( boolean forceFlush ) 
 @ @ - 437 , 6 + 438 , 23 @ @ public abstract class CQLTester 
 } 
 } 
 
 + public void disableCompaction ( ) 
 + { 
 + disableCompaction ( KEYSPACE ) ; 
 + } 
 + 
 + public void enableCompaction ( String keyspace ) 
 + { 
 + ColumnFamilyStore store = getCurrentColumnFamilyStore ( keyspace ) ; 
 + if ( store ! = null ) 
 + store . enableAutoCompaction ( ) ; 
 + } 
 + 
 + public void enableCompaction ( ) 
 + { 
 + enableCompaction ( KEYSPACE ) ; 
 + } 
 + 
 public void cleanupCache ( ) 
 { 
 ColumnFamilyStore store = getCurrentColumnFamilyStore ( ) ; 
 diff - - git a / test / unit / org / apache / cassandra / cql3 / validation / entities / UserTypesTest . java b / test / unit / org / apache / cassandra / cql3 / validation / entities / UserTypesTest . java 
 index c279e00 . . dfc2e5e 100644 
 - - - a / test / unit / org / apache / cassandra / cql3 / validation / entities / UserTypesTest . java 
 + + + b / test / unit / org / apache / cassandra / cql3 / validation / entities / UserTypesTest . java 
 @ @ - 562 , 6 + 562 , 157 @ @ public class UserTypesTest extends CQLTester 
 assertInvalidMessage ( " Cannot drop user type " + typeWithKs ( t ) , " DROP TYPE " + typeWithKs ( t ) + ' ; ' ) ; 
 } 
 
 + @ Test 
 + public void testReadAfterAlteringUserTypeNestedWithinSet ( ) throws Throwable 
 + { 
 + String columnType = typeWithKs ( createType ( " CREATE TYPE % s ( a int ) " ) ) ; 
 + 
 + try 
 + { 
 + createTable ( " CREATE TABLE % s ( x int PRIMARY KEY , y set < frozen < " + columnType + " > > ) " ) ; 
 + disableCompaction ( ) ; 
 + 
 + execute ( " INSERT INTO % s ( x , y ) VALUES ( 1 , ? ) " , set ( userType ( 1 ) , userType ( 2 ) ) ) ; 
 + assertRows ( execute ( " SELECT * FROM % s " ) , row ( 1 , set ( userType ( 1 ) , userType ( 2 ) ) ) ) ; 
 + flush ( ) ; 
 + 
 + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , 
 + row ( 1 , set ( userType ( 1 ) , userType ( 2 ) ) ) ) ; 
 + 
 + execute ( " ALTER TYPE " + columnType + " ADD b int " ) ; 
 + execute ( " UPDATE % s SET y = y + ? WHERE x = 1 " , 
 + set ( userType ( 1 , 1 ) , userType ( 1 , 2 ) , userType ( 2 , 1 ) ) ) ; 
 + 
 + flush ( ) ; 
 + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , 
 + row ( 1 , set ( userType ( 1 ) , 
 + userType ( 1 , 1 ) , 
 + userType ( 1 , 2 ) , 
 + userType ( 2 ) , 
 + userType ( 2 , 1 ) ) ) ) ; 
 + 
 + compact ( ) ; 
 + 
 + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , 
 + row ( 1 , set ( userType ( 1 ) , 
 + userType ( 1 , 1 ) , 
 + userType ( 1 , 2 ) , 
 + userType ( 2 ) , 
 + userType ( 2 , 1 ) ) ) ) ; 
 + } 
 + finally 
 + { 
 + enableCompaction ( ) ; 
 + } 
 + } 
 + 
 + @ Test 
 + public void testReadAfterAlteringUserTypeNestedWithinMap ( ) throws Throwable 
 + { 
 + String columnType = typeWithKs ( createType ( " CREATE TYPE % s ( a int ) " ) ) ; 
 + 
 + try 
 + { 
 + createTable ( " CREATE TABLE % s ( x int PRIMARY KEY , y map < frozen < " + columnType + " > , int > ) " ) ; 
 + disableCompaction ( ) ; 
 + 
 + execute ( " INSERT INTO % s ( x , y ) VALUES ( 1 , ? ) " , map ( userType ( 1 ) , 1 , userType ( 2 ) , 2 ) ) ; 
 + assertRows ( execute ( " SELECT * FROM % s " ) , row ( 1 , map ( userType ( 1 ) , 1 , userType ( 2 ) , 2 ) ) ) ; 
 + flush ( ) ; 
 + 
 + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , 
 + row ( 1 , map ( userType ( 1 ) , 1 , userType ( 2 ) , 2 ) ) ) ; 
 + 
 + execute ( " ALTER TYPE " + columnType + " ADD b int " ) ; 
 + execute ( " UPDATE % s SET y = y + ? WHERE x = 1 " , 
 + map ( userType ( 1 , 1 ) , 1 , userType ( 1 , 2 ) , 1 , userType ( 2 , 1 ) , 2 ) ) ; 
 + 
 + flush ( ) ; 
 + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , 
 + row ( 1 , map ( userType ( 1 ) , 1 , 
 + userType ( 1 , 1 ) , 1 , 
 + userType ( 1 , 2 ) , 1 , 
 + userType ( 2 ) , 2 , 
 + userType ( 2 , 1 ) , 2 ) ) ) ; 
 + 
 + compact ( ) ; 
 + 
 + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , 
 + row ( 1 , map ( userType ( 1 ) , 1 , 
 + userType ( 1 , 1 ) , 1 , 
 + userType ( 1 , 2 ) , 1 , 
 + userType ( 2 ) , 2 , 
 + userType ( 2 , 1 ) , 2 ) ) ) ; 
 + } 
 + finally 
 + { 
 + enableCompaction ( ) ; 
 + } 
 + } 
 + 
 + @ Test 
 + public void testReadAfterAlteringUserTypeNestedWithinList ( ) throws Throwable 
 + { 
 + String columnType = typeWithKs ( createType ( " CREATE TYPE % s ( a int ) " ) ) ; 
 + 
 + try 
 + { 
 + createTable ( " CREATE TABLE % s ( x int PRIMARY KEY , y list < frozen < " + columnType + " > > ) " ) ; 
 + disableCompaction ( ) ; 
 + 
 + execute ( " INSERT INTO % s ( x , y ) VALUES ( 1 , ? ) " , list ( userType ( 1 ) , userType ( 2 ) ) ) ; 
 + assertRows ( execute ( " SELECT * FROM % s " ) , row ( 1 , list ( userType ( 1 ) , userType ( 2 ) ) ) ) ; 
 + flush ( ) ; 
 + 
 + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , 
 + row ( 1 , list ( userType ( 1 ) , userType ( 2 ) ) ) ) ; 
 + 
 + execute ( " ALTER TYPE " + columnType + " ADD b int " ) ; 
 + execute ( " UPDATE % s SET y = y + ? WHERE x = 1 " , 
 + list ( userType ( 1 , 1 ) , userType ( 1 , 2 ) , userType ( 2 , 1 ) ) ) ; 
 + 
 + flush ( ) ; 
 + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , 
 + row ( 1 , list ( userType ( 1 ) , 
 + userType ( 2 ) , 
 + userType ( 1 , 1 ) , 
 + userType ( 1 , 2 ) , 
 + userType ( 2 , 1 ) ) ) ) ; 
 + 
 + compact ( ) ; 
 + 
 + assertRows ( execute ( " SELECT * FROM % s WHERE x = 1 " ) , 
 + row ( 1 , list ( userType ( 1 ) , 
 + userType ( 2 ) , 
 + userType ( 1 , 1 ) , 
 + userType ( 1 , 2 ) , 
 + userType ( 2 , 1 ) ) ) ) ; 
 + } 
 + finally 
 + { 
 + enableCompaction ( ) ; 
 + } 
 + } 
 + 
 + @ Test 
 + public void testAlteringUserTypeNestedWithinSetWithView ( ) throws Throwable 
 + { 
 + String columnType = typeWithKs ( createType ( " CREATE TYPE % s ( a int ) " ) ) ; 
 + 
 + createTable ( " CREATE TABLE % s ( pk int , c int , v int , s set < frozen < " + columnType + " > > , PRIMARY KEY ( pk , c ) ) " ) ; 
 + execute ( " CREATE MATERIALIZED VIEW " + keyspace ( ) + " . view1 AS SELECT c , pk , v FROM % s WHERE pk IS NOT NULL AND c IS NOT NULL AND v IS NOT NULL PRIMARY KEY ( c , pk ) " ) ; 
 + 
 + execute ( " INSERT INTO % s ( pk , c , v , s ) VALUES ( ? , ? , ? , ? ) " , 1 , 1 , 1 , set ( userType ( 1 ) , userType ( 2 ) ) ) ; 
 + flush ( ) ; 
 + 
 + execute ( " ALTER TYPE " + columnType + " ADD b int " ) ; 
 + execute ( " UPDATE % s SET s = s + ? , v = ? WHERE pk = ? AND c = ? " , 
 + set ( userType ( 1 , 1 ) , userType ( 1 , 2 ) , userType ( 2 , 1 ) ) , 2 , 1 , 1 ) ; 
 + 
 + assertRows ( execute ( " SELECT * FROM % s WHERE pk = ? AND c = ? " , 1 , 1 ) , 
 + row ( 1 , 1 , set ( userType ( 1 ) , userType ( 1 , 1 ) , userType ( 1 , 2 ) , userType ( 2 ) , userType ( 2 , 1 ) ) , 2 ) ) ; 
 + } 
 + 
 private String typeWithKs ( String type1 ) 
 { 
 return keyspace ( ) + ' . ' + type1 ; 
 diff - - git a / test / unit / org / apache / cassandra / db / rows / AbstractTypeVersionComparatorTest . java b / test / unit / org / apache / cassandra / db / rows / AbstractTypeVersionComparatorTest . java 
 new file mode 100644 
 index 0000000 . . ad0c05c 
 - - - / dev / null 
 + + + b / test / unit / org / apache / cassandra / db / rows / AbstractTypeVersionComparatorTest . java 
 @ @ - 0 , 0 + 1 , 184 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , software 
 + * distributed under the License is distributed on an " AS IS " BASIS , 
 + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + * See the License for the specific language governing permissions and 
 + * limitations under the License . 
 + * / 
 + package org . apache . cassandra . db . rows ; 
 + 
 + import java . nio . ByteBuffer ; 
 + import java . util . Set ; 
 + 
 + import org . junit . After ; 
 + import org . junit . Before ; 
 + import org . junit . Test ; 
 + 
 + import org . apache . cassandra . db . marshal . * ; 
 + 
 + import static java . util . Arrays . asList ; 
 + import static org . apache . cassandra . utils . ByteBufferUtil . bytes ; 
 + import static org . junit . Assert . assertEquals ; 
 + import static org . junit . Assert . fail ; 
 + 
 + public class AbstractTypeVersionComparatorTest 
 + { 
 + private UserType udtWith2Fields ; 
 + private UserType udtWith3Fields ; 
 + 
 + @ Before 
 + public void setUp ( ) 
 + { 
 + udtWith2Fields = new UserType ( " ks " , 
 + bytes ( " myType " ) , 
 + asList ( bytes ( " a " ) , bytes ( " b " ) ) , 
 + asList ( Int32Type . instance , Int32Type . instance ) ) ; 
 + udtWith3Fields = new UserType ( " ks " , 
 + bytes ( " myType " ) , 
 + asList ( bytes ( " a " ) , bytes ( " b " ) , bytes ( " c " ) ) , 
 + asList ( Int32Type . instance , Int32Type . instance , Int32Type . instance ) ) ; 
 + } 
 + 
 + @ After 
 + public void tearDown ( ) 
 + { 
 + udtWith2Fields = null ; 
 + udtWith3Fields = null ; 
 + } 
 + 
 + @ Test 
 + public void testWithTuples ( ) 
 + { 
 + checkComparisonResults ( new TupleType ( asList ( Int32Type . instance , Int32Type . instance ) ) , 
 + new TupleType ( asList ( Int32Type . instance , Int32Type . instance , Int32Type . instance ) ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testWithUDTs ( ) 
 + { 
 + checkComparisonResults ( udtWith2Fields , udtWith3Fields ) ; 
 + } 
 + 
 + @ Test 
 + public void testWithUDTsNestedWithinSet ( ) 
 + { 
 + for ( boolean isMultiCell : new boolean [ ] { false , true } ) 
 + { 
 + SetType < ByteBuffer > set1 = SetType . getInstance ( udtWith2Fields , isMultiCell ) ; 
 + SetType < ByteBuffer > set2 = SetType . getInstance ( udtWith3Fields , isMultiCell ) ; 
 + checkComparisonResults ( set1 , set2 ) ; 
 + } 
 + } 
 + 
 + @ Test 
 + public void testWithUDTsNestedWithinList ( ) 
 + { 
 + for ( boolean isMultiCell : new boolean [ ] { false , true } ) 
 + { 
 + ListType < ByteBuffer > list1 = ListType . getInstance ( udtWith2Fields , isMultiCell ) ; 
 + ListType < ByteBuffer > list2 = ListType . getInstance ( udtWith3Fields , isMultiCell ) ; 
 + checkComparisonResults ( list1 , list2 ) ; 
 + } 
 + } 
 + 
 + @ Test 
 + public void testWithUDTsNestedWithinMap ( ) 
 + { 
 + for ( boolean isMultiCell : new boolean [ ] { false , true } ) 
 + { 
 + MapType < ByteBuffer , Integer > map1 = MapType . getInstance ( udtWith2Fields , Int32Type . instance , isMultiCell ) ; 
 + MapType < ByteBuffer , Integer > map2 = MapType . getInstance ( udtWith3Fields , Int32Type . instance , isMultiCell ) ; 
 + checkComparisonResults ( map1 , map2 ) ; 
 + } 
 + 
 + for ( boolean isMultiCell : new boolean [ ] { false , true } ) 
 + { 
 + MapType < Integer , ByteBuffer > map1 = MapType . getInstance ( Int32Type . instance , udtWith2Fields , isMultiCell ) ; 
 + MapType < Integer , ByteBuffer > map2 = MapType . getInstance ( Int32Type . instance , udtWith3Fields , isMultiCell ) ; 
 + checkComparisonResults ( map1 , map2 ) ; 
 + } 
 + } 
 + 
 + @ Test 
 + public void testWithUDTsNestedWithinTuple ( ) 
 + { 
 + TupleType tuple1 = new TupleType ( asList ( udtWith2Fields , Int32Type . instance ) ) ; 
 + TupleType tuple2 = new TupleType ( asList ( udtWith3Fields , Int32Type . instance ) ) ; 
 + checkComparisonResults ( tuple1 , tuple2 ) ; 
 + } 
 + 
 + @ Test 
 + public void testWithUDTsNestedWithinComposite ( ) 
 + { 
 + CompositeType composite1 = CompositeType . getInstance ( asList ( udtWith2Fields , Int32Type . instance ) ) ; 
 + CompositeType composite2 = CompositeType . getInstance ( asList ( udtWith3Fields , Int32Type . instance ) ) ; 
 + checkComparisonResults ( composite1 , composite2 ) ; 
 + } 
 + 
 + @ Test 
 + public void testWithDeeplyNestedUDT ( ) 
 + { 
 + for ( boolean isMultiCell : new boolean [ ] { false , true } ) 
 + { 
 + ListType < Set < ByteBuffer > > list1 = ListType . getInstance ( SetType . getInstance ( new TupleType ( asList ( udtWith2Fields , Int32Type . instance ) ) , isMultiCell ) , isMultiCell ) ; 
 + ListType < Set < ByteBuffer > > list2 = ListType . getInstance ( SetType . getInstance ( new TupleType ( asList ( udtWith3Fields , Int32Type . instance ) ) , isMultiCell ) , isMultiCell ) ; 
 + checkComparisonResults ( list1 , list2 ) ; 
 + } 
 + } 
 + 
 + @ Test 
 + public void testInvalidComparison ( ) 
 + { 
 + assertInvalidComparison ( " Trying to compare 2 different types : org . apache . cassandra . db . marshal . UserType ( ks , 6d7954797065 , 61 : org . apache . cassandra . db . marshal . Int32Type , 62 : org . apache . cassandra . db . marshal . Int32Type ) and org . apache . cassandra . db . marshal . Int32Type " , 
 + udtWith2Fields , 
 + Int32Type . instance ) ; 
 + assertInvalidComparison ( " Trying to compare 2 different types : org . apache . cassandra . db . marshal . UTF8Type and org . apache . cassandra . db . marshal . InetAddressType " , 
 + SetType . getInstance ( UTF8Type . instance , true ) , 
 + SetType . getInstance ( InetAddressType . instance , true ) ) ; 
 + assertInvalidComparison ( " Trying to compare 2 different types : org . apache . cassandra . db . marshal . UTF8Type and org . apache . cassandra . db . marshal . InetAddressType " , 
 + ListType . getInstance ( UTF8Type . instance , true ) , 
 + ListType . getInstance ( InetAddressType . instance , true ) ) ; 
 + assertInvalidComparison ( " Trying to compare 2 different types : org . apache . cassandra . db . marshal . UTF8Type and org . apache . cassandra . db . marshal . InetAddressType " , 
 + MapType . getInstance ( UTF8Type . instance , IntegerType . instance , true ) , 
 + MapType . getInstance ( InetAddressType . instance , IntegerType . instance , true ) ) ; 
 + assertInvalidComparison ( " Trying to compare 2 different types : org . apache . cassandra . db . marshal . UTF8Type and org . apache . cassandra . db . marshal . InetAddressType " , 
 + MapType . getInstance ( IntegerType . instance , UTF8Type . instance , true ) , 
 + MapType . getInstance ( IntegerType . instance , InetAddressType . instance , true ) ) ; 
 + } 
 + 
 + private void assertInvalidComparison ( String expectedMessage , AbstractType < ? > oldVersion , AbstractType < ? > newVersion ) 
 + { 
 + try 
 + { 
 + checkComparisonResults ( oldVersion , newVersion ) ; 
 + fail ( " comparison doesn ' t throw expected IllegalArgumentException : " + expectedMessage ) ; 
 + } 
 + catch ( IllegalArgumentException e ) 
 + { 
 + assertEquals ( e . getMessage ( ) , expectedMessage ) ; 
 + } 
 + } 
 + 
 + private void checkComparisonResults ( AbstractType < ? > oldVersion , AbstractType < ? > newVersion ) 
 + { 
 + assertEquals ( 0 , compare ( oldVersion , oldVersion ) ) ; 
 + assertEquals ( 0 , compare ( newVersion , newVersion ) ) ; 
 + assertEquals ( - 1 , compare ( oldVersion , newVersion ) ) ; 
 + assertEquals ( 1 , compare ( newVersion , oldVersion ) ) ; 
 + } 
 + 
 + private int compare ( AbstractType < ? > left , AbstractType < ? > right ) 
 + { 
 + return AbstractTypeVersionComparator . INSTANCE . compare ( left , right ) ; 
 + } 
 + }

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 8dc4e5b . . 3c92516 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 11 , 11 + 11 , 14 @ @ 
 * JDBC CQL driver exposes getColumn for access to timestamp 
 * JDBC ResultSetMetadata properties added to AbstractType 
 * r / m clustertool ( CASSANDRA - 2607 ) 
 + * add support for presenting row key as a column in CQL result sets 
 + ( CASSANDRA - 2622 ) 
 
 
 0 . 8 . 0 - beta2 
 * fix NPE compacting index CFs ( CASSANDRA - 2528 ) 
 - * Remove checking all column families on startup for compaction candidates ( CASSANDRA - 2444 ) 
 + * Remove checking all column families on startup for compaction candidates 
 + ( CASSANDRA - 2444 ) 
 * validate CQL create keyspace options ( CASSANDRA - 2525 ) 
 * fix nodetool setcompactionthroughput ( CASSANDRA - 2550 ) 
 * move 	 gossip heartbeat back to its own thread ( CASSANDRA - 2554 ) 
 diff - - git a / drivers / java / src / org / apache / cassandra / cql / jdbc / ColumnDecoder . java b / drivers / java / src / org / apache / cassandra / cql / jdbc / ColumnDecoder . java 
 index a6367b5 . . 606bb1b 100644 
 - - - a / drivers / java / src / org / apache / cassandra / cql / jdbc / ColumnDecoder . java 
 + + + b / drivers / java / src / org / apache / cassandra / cql / jdbc / ColumnDecoder . java 
 @ @ - 25 , 6 + 25 , 7 @ @ import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . ColumnDefinition ; 
 import org . apache . cassandra . config . ConfigurationException ; 
 import org . apache . cassandra . db . marshal . AbstractType ; 
 + import org . apache . cassandra . db . marshal . AsciiType ; 
 import org . apache . cassandra . thrift . * ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . apache . cassandra . utils . FBUtilities ; 
 @ @ - 33 , 6 + 34 , 7 @ @ import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 import java . nio . ByteBuffer ; 
 + import java . nio . charset . CharacterCodingException ; 
 import java . util . HashMap ; 
 import java . util . List ; 
 import java . util . Map ; 
 @ @ - 80 , 12 + 82 , 30 @ @ class ColumnDecoder 
 { 
 
 CFMetaData md = metadata . get ( String . format ( " % s . % s " , keyspace , columnFamily ) ) ; 
 + try 
 + { 
 + if ( ByteBufferUtil . string ( name ) . equalsIgnoreCase ( ByteBufferUtil . string ( md . getKeyName ( ) ) ) ) 
 + return AsciiType . instance ; 
 + } 
 + catch ( CharacterCodingException e ) 
 + { 
 + / / not be the key name 
 + } 
 return md . comparator ; 
 } 
 
 AbstractType getValueType ( String keyspace , String columnFamily , ByteBuffer name ) 
 { 
 CFMetaData md = metadata . get ( String . format ( " % s . % s " , keyspace , columnFamily ) ) ; 
 + try 
 + { 
 + if ( ByteBufferUtil . string ( name ) . equalsIgnoreCase ( ByteBufferUtil . string ( md . getKeyName ( ) ) ) ) 
 + return md . getKeyValidator ( ) ; 
 + } 
 + catch ( CharacterCodingException e ) 
 + { 
 + / / not be the key name 
 + } 
 ColumnDefinition cd = md . getColumnDefinition ( name ) ; 
 return cd = = null ? md . getDefaultValidator ( ) : cd . getValidator ( ) ; 
 } 
 diff - - git a / drivers / java / test / org / apache / cassandra / cql / JdbcDriverTest . java b / drivers / java / test / org / apache / cassandra / cql / JdbcDriverTest . java 
 index f5301ab . . f3f748f 100644 
 - - - a / drivers / java / test / org / apache / cassandra / cql / JdbcDriverTest . java 
 + + + b / drivers / java / test / org / apache / cassandra / cql / JdbcDriverTest . java 
 @ @ - 33 , 6 + 33 , 7 @ @ import org . junit . BeforeClass ; 
 import org . junit . Test ; 
 
 import org . apache . cassandra . db . marshal . * ; 
 + import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . apache . cassandra . utils . FBUtilities ; 
 
 import static junit . framework . Assert . assertEquals ; 
 @ @ - 120 , 6 + 121 , 12 @ @ public class JdbcDriverTest extends EmbeddedServiceBase 
 expectedMetaData ( md , 2 , BigInteger . class . getName ( ) , " JdbcInteger " , " Keyspace1 " , " 2 " , Types . BIGINT , IntegerType . class . getSimpleName ( ) , true , false ) ; 
 expectedMetaData ( md , 3 , String . class . getName ( ) , " JdbcInteger " , " Keyspace1 " , " 42 " , Types . VARCHAR , UTF8Type . class . getSimpleName ( ) , false , true ) ; 
 
 + rs = stmt . executeQuery ( " select key , 1 , 2 , 42 from JdbcInteger where key = ' " + key + " ' " ) ; 
 + assert rs . next ( ) ; 
 + assert Arrays . equals ( rs . getBytes ( " key " ) , FBUtilities . hexToBytes ( key ) ) ; 
 + assert rs . getObject ( " 1 " ) . equals ( new BigInteger ( " 36893488147419103232 " ) ) ; 
 + assert rs . getString ( " 42 " ) . equals ( " fortytwofortytwo " ) : rs . getString ( " 42 " ) ; 
 + 
 stmt . executeUpdate ( " update JdbcUtf8 set a = ' aa ' , b = ' bb ' , fortytwo = ' 4242 ' where key = ' " + key + " ' " ) ; 
 rs = stmt . executeQuery ( " select a , b , fortytwo from JdbcUtf8 where key = ' " + key + " ' " ) ; 
 assert rs . next ( ) ; 
 diff - - git a / drivers / py / cql / _ _ init _ _ . py b / drivers / py / cql / _ _ init _ _ . py 
 index b5b58bc . . de00876 100644 
 - - - a / drivers / py / cql / _ _ init _ _ . py 
 + + + b / drivers / py / cql / _ _ init _ _ . py 
 @ @ - 45 , 8 + 45 , 6 @ @ apilevel = 1 . 0 
 threadsafety = 1 # Threads may share the module , but not connections / cursors . 
 paramstyle = ' named ' 
 
 - ROW _ KEY = " Row Key " 
 - 
 # TODO : Pull connections out of a pool instead . 
 def connect ( host , port = 9160 , keyspace = ' system ' , user = None , password = None ) : 
 return connection . Connection ( host , port , keyspace , user , password ) 
 diff - - git a / drivers / py / cql / cursor . py b / drivers / py / cql / cursor . py 
 index 9771c67 . . 8858d8d 100644 
 - - - a / drivers / py / cql / cursor . py 
 + + + b / drivers / py / cql / cursor . py 
 @ @ - 92 , 16 + 92 , 14 @ @ class Cursor : 
 return results 
 
 def column _ families ( cf _ defs ) : 
 - cfresults = { } 
 - if cf _ defs : 
 - for cf in cf _ defs : 
 - cfresults [ cf . name ] = { " comparator " : cf . comparator _ type } 
 - cfresults [ cf . name ] [ " default _ validation _ class " ] = \ 
 - cf . default _ validation _ class 
 - cfresults [ cf . name ] [ " key _ validation _ class " ] = \ 
 - cf . key _ validation _ class 
 - cfresults [ cf . name ] [ " columns " ] = columns ( cf . column _ metadata ) 
 - return cfresults 
 + d = { } 
 + for cf in cf _ defs : 
 + d [ cf . name ] = { ' comparator ' : cf . comparator _ type , 
 + ' default _ validation _ class ' : cf . default _ validation _ class , 
 + ' key _ validation _ class ' : cf . key _ validation _ class , 
 + ' columns ' : columns ( cf . column _ metadata ) , 
 + ' key _ alias ' : cf . key _ alias } 
 + return d 
 
 schema = { } 
 client = self . parent _ connection . client 
 diff - - git a / drivers / py / cql / decoders . py b / drivers / py / cql / decoders . py 
 index 9d7cad1 . . f91e2b2 100644 
 - - - a / drivers / py / cql / decoders . py 
 + + + b / drivers / py / cql / decoders . py 
 @ @ - 32 , 45 + 32 , 44 @ @ class SchemaDecoder ( object ) : 
 
 def _ _ comparator _ for ( self , keyspace , column _ family ) : 
 cfam = self . _ _ get _ column _ family _ def ( keyspace , column _ family ) 
 - if cfam and " comparator " in cfam : 
 + if " comparator " in cfam : 
 return cfam [ " comparator " ] 
 return None 
 
 def _ _ validator _ for ( self , keyspace , column _ family , name ) : 
 cfam = self . _ _ get _ column _ family _ def ( keyspace , column _ family ) 
 - if cfam : 
 - if name in cfam [ " columns " ] : 
 - return cfam [ " columns " ] [ name ] 
 - return cfam [ " default _ validation _ class " ] 
 - return None 
 + if name in cfam [ " columns " ] : 
 + return cfam [ " columns " ] [ name ] 
 + return cfam [ " default _ validation _ class " ] 
 
 def _ _ keytype _ for ( self , keyspace , column _ family ) : 
 cfam = self . _ _ get _ column _ family _ def ( keyspace , column _ family ) 
 - if cfam and " key _ validation _ class " in cfam : 
 + if " key _ validation _ class " in cfam : 
 return cfam [ " key _ validation _ class " ] 
 return None 
 
 def decode _ description ( self , keyspace , column _ family , row ) : 
 - key _ type = self . _ _ keytype _ for ( keyspace , column _ family ) 
 - description = [ ( cql . ROW _ KEY , key _ type , None , None , None , None , None , False ) ] 
 + description = [ ] 
 comparator = self . _ _ comparator _ for ( keyspace , column _ family ) 
 unmarshal = unmarshallers . get ( comparator , unmarshal _ noop ) 
 for column in row . columns : 
 - description . append ( ( unmarshal ( column . name ) , comparator , None , None , None , None , True ) ) 
 - 
 + if column . name = = self . _ _ get _ column _ family _ def ( keyspace , column _ family ) [ ' key _ alias ' ] : 
 + description . append ( ( column . name , ' text ' , None , None , None , None , True ) ) 
 + else : 
 + description . append ( ( unmarshal ( column . name ) , comparator , None , None , None , None , True ) ) 
 return description 
 
 def decode _ row ( self , keyspace , column _ family , row ) : 
 - key _ type = self . _ _ keytype _ for ( keyspace , column _ family ) 
 - key = unmarshallers . get ( key _ type , unmarshal _ noop ) ( row . key ) 
 comparator = self . _ _ comparator _ for ( keyspace , column _ family ) 
 unmarshal = unmarshallers . get ( comparator , unmarshal _ noop ) 
 - values = [ key ] 
 + values = [ ] 
 for column in row . columns : 
 - validator = self . _ _ validator _ for ( keyspace , column _ family , column . name ) 
 if column . value is None : 
 values . append ( None ) 
 + continue 
 + if column . name = = self . _ _ get _ column _ family _ def ( keyspace , column _ family ) [ ' key _ alias ' ] : 
 + validator = self . _ _ keytype _ for ( keyspace , column _ family ) 
 else : 
 - values . append ( unmarshallers . get ( validator , unmarshal _ noop ) ( column . value ) ) 
 - 
 + validator = self . _ _ validator _ for ( keyspace , column _ family , column . name ) 
 + values . append ( unmarshallers . get ( validator , unmarshal _ noop ) ( column . value ) ) 
 return values 
 diff - - git a / src / java / org / apache / cassandra / config / CFMetaData . java b / src / java / org / apache / cassandra / config / CFMetaData . java 
 index 992c55d . . ebebe4d 100644 
 - - - a / src / java / org / apache / cassandra / config / CFMetaData . java 
 + + + b / src / java / org / apache / cassandra / config / CFMetaData . java 
 @ @ - 78 , 6 + 78 , 7 @ @ public final class CFMetaData 
 public static final CFMetaData SchemaCf = newSystemMetadata ( Migration . SCHEMA _ CF , 3 , " current state of the schema " , UTF8Type . instance , null , DEFAULT _ SYSTEM _ MEMTABLE _ THROUGHPUT _ IN _ MB ) ; 
 public static final CFMetaData IndexCf = newSystemMetadata ( SystemTable . INDEX _ CF , 5 , " indexes that have been completed " , UTF8Type . instance , null , DEFAULT _ SYSTEM _ MEMTABLE _ THROUGHPUT _ IN _ MB ) ; 
 public static final CFMetaData NodeIdCf = newSystemMetadata ( SystemTable . NODE _ ID _ CF , 6 , " nodeId and their metadata " , TimeUUIDType . instance , null , DEFAULT _ SYSTEM _ MEMTABLE _ THROUGHPUT _ IN _ MB ) ; 
 + private static final ByteBuffer DEFAULT _ KEY _ NAME = ByteBufferUtil . bytes ( " KEY " ) ; 
 
 / * * 
 * @ return A calculated memtable throughput size for this machine . 
 @ @ - 504 , 9 + 505 , 9 @ @ public final class CFMetaData 
 return rowCacheProvider ; 
 } 
 
 - public ByteBuffer getKeyAlias ( ) 
 + public ByteBuffer getKeyName ( ) 
 { 
 - return keyAlias ; 
 + return keyAlias = = null ? DEFAULT _ KEY _ NAME : keyAlias ; 
 } 
 
 public Map < ByteBuffer , ColumnDefinition > getColumn _ metadata ( ) 
 @ @ - 640 , 7 + 641 , 6 @ @ public final class CFMetaData 
 
 validateMinMaxCompactionThresholds ( cf _ def ) ; 
 validateMemtableSettings ( cf _ def ) ; 
 - validateAliasCompares ( cf _ def ) ; 
 
 CFMetaData newCFMD = new CFMetaData ( cf _ def . keyspace , 
 cf _ def . name , 
 @ @ - 785 , 7 + 785 , 7 @ @ public final class CFMetaData 
 def . setMemtable _ throughput _ in _ mb ( cfm . memtableThroughputInMb ) ; 
 def . setMemtable _ operations _ in _ millions ( cfm . memtableOperationsInMillions ) ; 
 def . setMerge _ shards _ chance ( cfm . mergeShardsChance ) ; 
 - def . setKey _ alias ( cfm . keyAlias ) ; 
 + def . setKey _ alias ( cfm . getKeyName ( ) ) ; 
 List < org . apache . cassandra . thrift . ColumnDef > column _ meta = new ArrayList < org . apache . cassandra . thrift . ColumnDef > ( cfm . column _ metadata . size ( ) ) ; 
 for ( ColumnDefinition cd : cfm . column _ metadata . values ( ) ) 
 { 
 @ @ - 970 , 13 + 970 , 6 @ @ public final class CFMetaData 
 DatabaseDescriptor . validateMemtableOperations ( cf _ def . memtable _ operations _ in _ millions ) ; 
 } 
 
 - public static void validateAliasCompares ( org . apache . cassandra . thrift . CfDef cf _ def ) throws ConfigurationException 
 - { 
 - AbstractType comparator = DatabaseDescriptor . getComparator ( cf _ def . comparator _ type ) ; 
 - if ( cf _ def . key _ alias ! = null ) 
 - comparator . validate ( cf _ def . key _ alias ) ; 
 - } 
 - 
 public static void validateAliasCompares ( org . apache . cassandra . db . migration . avro . CfDef cf _ def ) throws ConfigurationException 
 { 
 AbstractType comparator = DatabaseDescriptor . getComparator ( cf _ def . comparator _ type ) ; 
 diff - - git a / src / java / org / apache / cassandra / cql / Cql . g b / src / java / org / apache / cassandra / cql / Cql . g 
 index 6d4c707 . . 3b0d812 100644 
 - - - a / src / java / org / apache / cassandra / cql / Cql . g 
 + + + b / src / java / org / apache / cassandra / cql / Cql . g 
 @ @ - 167 , 8 + 167 , 8 @ @ selectExpression returns [ SelectExpression expr ] 
 ( K _ REVERSED { reversed = true ; } ) ? 
 ( first = term { $ expr = new SelectExpression ( first , count , reversed ) ; } 
 ( ' , ' next = term { $ expr . and ( next ) ; } ) * 
 - | start = term RANGEOP finish = term { $ expr = new SelectExpression ( start , finish , count , reversed ) ; } 
 - | ' \ * ' { $ expr = new SelectExpression ( new Term ( ) , new Term ( ) , count , reversed ) ; } 
 + | start = term RANGEOP finish = term { $ expr = new SelectExpression ( start , finish , count , reversed , false ) ; } 
 + | ' \ * ' { $ expr = new SelectExpression ( new Term ( ) , new Term ( ) , count , reversed , true ) ; } 
 ) 
 ; 
 
 @ @ - 346 , 7 + 346 , 7 @ @ comparatorType 
 ; 
 
 term returns [ Term item ] 
 - : ( t = STRING _ LITERAL | t = INTEGER | t = UUID | t = IDENT ) { $ item = new Term ( $ t . text , $ t . type ) ; } 
 + : ( t = K _ KEY | t = STRING _ LITERAL | t = INTEGER | t = UUID | t = IDENT ) { $ item = new Term ( $ t . text , $ t . type ) ; } 
 ; 
 
 termList returns [ List < Term > items ] 
 diff - - git a / src / java / org / apache / cassandra / cql / QueryProcessor . java b / src / java / org / apache / cassandra / cql / QueryProcessor . java 
 index 08556b3 . . 8bd0724 100644 
 - - - a / src / java / org / apache / cassandra / cql / QueryProcessor . java 
 + + + b / src / java / org / apache / cassandra / cql / QueryProcessor . java 
 @ @ - 23 , 6 + 23 , 7 @ @ package org . apache . cassandra . cql ; 
 
 import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 + import java . nio . charset . CharacterCodingException ; 
 import java . util . * ; 
 import java . util . concurrent . Callable ; 
 import java . util . concurrent . ExecutionException ; 
 @ @ - 67 , 7 + 68 , 6 @ @ public class QueryProcessor 
 { 
 List < org . apache . cassandra . db . Row > rows ; 
 QueryPath queryPath = new QueryPath ( select . getColumnFamily ( ) ) ; 
 - AbstractType < ? > comparator = select . getComparator ( keyspace ) ; 
 List < ReadCommand > commands = new ArrayList < ReadCommand > ( ) ; 
 
 assert select . getKeys ( ) . size ( ) = = 1 ; 
 @ @ - 79 , 16 + 79 , 14 @ @ public class QueryProcessor 
 / / . . . of a list of column names 
 if ( ! select . isColumnRange ( ) ) 
 { 
 - Collection < ByteBuffer > columnNames = new ArrayList < ByteBuffer > ( ) ; 
 - for ( Term column : select . getColumnNames ( ) ) 
 - columnNames . add ( column . getByteBuffer ( comparator ) ) ; 
 - 
 + Collection < ByteBuffer > columnNames = getColumnNames ( select , metadata ) ; 
 validateColumnNames ( columnNames ) ; 
 commands . add ( new SliceByNamesReadCommand ( keyspace , key , queryPath , columnNames ) ) ; 
 } 
 / / . . . a range ( slice ) of column names 
 else 
 { 
 + AbstractType < ? > comparator = select . getComparator ( keyspace ) ; 
 ByteBuffer start = select . getColumnStart ( ) . getByteBuffer ( comparator ) ; 
 ByteBuffer finish = select . getColumnFinish ( ) . getByteBuffer ( comparator ) ; 
 
 @ @ - 117 , 7 + 115 , 20 @ @ public class QueryProcessor 
 
 return rows ; 
 } 
 - 
 + 
 + private static List < ByteBuffer > getColumnNames ( SelectStatement select , CFMetaData metadata ) throws InvalidRequestException 
 + { 
 + String keyString = getKeyString ( metadata ) ; 
 + List < ByteBuffer > columnNames = new ArrayList < ByteBuffer > ( ) ; 
 + for ( Term column : select . getColumnNames ( ) ) 
 + { 
 + / / skip the key for the slice op ; we ' ll add it to the resultset in extractThriftColumns 
 + if ( ! column . getText ( ) . equalsIgnoreCase ( keyString ) ) 
 + columnNames . add ( column . getByteBuffer ( metadata . comparator ) ) ; 
 + } 
 + return columnNames ; 
 + } 
 + 
 private static List < org . apache . cassandra . db . Row > multiRangeSlice ( String keyspace , SelectStatement select ) 
 throws TimedOutException , UnavailableException , InvalidRequestException 
 { 
 @ @ - 146 , 9 + 157 , 8 @ @ public class QueryProcessor 
 AbstractBounds bounds = new Bounds ( startToken , finishToken ) ; 
 
 CFMetaData metadata = validateColumnFamily ( keyspace , select . getColumnFamily ( ) , false ) ; 
 - AbstractType < ? > comparator = metadata . getComparatorFor ( null ) ; 
 / / XXX : Our use of Thrift structs internally makes me Sad . : ( 
 - SlicePredicate thriftSlicePredicate = slicePredicateFromSelect ( select , comparator ) ; 
 + SlicePredicate thriftSlicePredicate = slicePredicateFromSelect ( select , metadata ) ; 
 validateSlicePredicate ( metadata , thriftSlicePredicate ) ; 
 
 int limit = select . isKeyRange ( ) & & select . getKeyStart ( ) ! = null 
 @ @ - 200 , 16 + 210 , 15 @ @ public class QueryProcessor 
 throws TimedOutException , UnavailableException , InvalidRequestException 
 { 
 CFMetaData metadata = validateColumnFamily ( keyspace , select . getColumnFamily ( ) , false ) ; 
 - AbstractType < ? > comparator = metadata . getComparatorFor ( null ) ; 
 / / XXX : Our use of Thrift structs internally ( still ) makes me Sad . : ~ ( 
 - SlicePredicate thriftSlicePredicate = slicePredicateFromSelect ( select , comparator ) ; 
 + SlicePredicate thriftSlicePredicate = slicePredicateFromSelect ( select , metadata ) ; 
 validateSlicePredicate ( metadata , thriftSlicePredicate ) ; 
 
 List < IndexExpression > expressions = new ArrayList < IndexExpression > ( ) ; 
 for ( Relation columnRelation : select . getColumnRelations ( ) ) 
 { 
 / / Left and right side of relational expression encoded according to comparator / validator . 
 - ByteBuffer entity = columnRelation . getEntity ( ) . getByteBuffer ( comparator ) ; 
 + ByteBuffer entity = columnRelation . getEntity ( ) . getByteBuffer ( metadata . comparator ) ; 
 ByteBuffer value = columnRelation . getValue ( ) . getByteBuffer ( select . getValueValidator ( keyspace , entity ) ) ; 
 
 expressions . add ( new IndexExpression ( entity , 
 @ @ - 291 , 7 + 300 , 7 @ @ public class QueryProcessor 
 } 
 } 
 
 - private static SlicePredicate slicePredicateFromSelect ( SelectStatement select , AbstractType < ? > comparator ) 
 + private static SlicePredicate slicePredicateFromSelect ( SelectStatement select , CFMetaData metadata ) 
 throws InvalidRequestException 
 { 
 SlicePredicate thriftSlicePredicate = new SlicePredicate ( ) ; 
 @ @ - 299 , 18 + 308 , 15 @ @ public class QueryProcessor 
 if ( select . isColumnRange ( ) | | select . getColumnNames ( ) . size ( ) = = 0 ) 
 { 
 SliceRange sliceRange = new SliceRange ( ) ; 
 - sliceRange . start = select . getColumnStart ( ) . getByteBuffer ( comparator ) ; 
 - sliceRange . finish = select . getColumnFinish ( ) . getByteBuffer ( comparator ) ; 
 + sliceRange . start = select . getColumnStart ( ) . getByteBuffer ( metadata . comparator ) ; 
 + sliceRange . finish = select . getColumnFinish ( ) . getByteBuffer ( metadata . comparator ) ; 
 sliceRange . reversed = select . isColumnsReversed ( ) ; 
 sliceRange . count = select . getColumnsLimit ( ) ; 
 thriftSlicePredicate . slice _ range = sliceRange ; 
 } 
 else 
 { 
 - List < ByteBuffer > columnNames = new ArrayList < ByteBuffer > ( ) ; 
 - for ( Term column : select . getColumnNames ( ) ) 
 - columnNames . add ( column . getByteBuffer ( comparator ) ) ; 
 - thriftSlicePredicate . column _ names = columnNames ; 
 + thriftSlicePredicate . column _ names = getColumnNames ( select , metadata ) ; 
 } 
 
 return thriftSlicePredicate ; 
 @ @ - 489 , 19 + 495 , 17 @ @ public class QueryProcessor 
 / / Some statements won ' t have ( or don ' t need ) a keyspace ( think USE , or CREATE ) . 
 if ( StatementType . requiresKeyspace . contains ( statement . type ) ) 
 keyspace = clientState . getKeyspace ( ) ; 
 - 
 + 
 CqlResult result = new CqlResult ( ) ; 
 
 logger . debug ( " CQL statement type : { } " , statement . type . toString ( ) ) ; 
 CFMetaData metadata ; 
 - AbstractType < ? > comparator ; 
 switch ( statement . type ) 
 { 
 case SELECT : 
 SelectStatement select = ( SelectStatement ) statement . statement ; 
 clientState . hasColumnFamilyAccess ( select . getColumnFamily ( ) , Permission . READ ) ; 
 metadata = validateColumnFamily ( keyspace , select . getColumnFamily ( ) , false ) ; 
 - comparator = metadata . getComparatorFor ( null ) ; 
 validateSelect ( keyspace , select ) ; 
 
 List < org . apache . cassandra . db . Row > rows = null ; 
 @ @ - 538 , 7 + 542 , 7 @ @ public class QueryProcessor 
 
 List < CqlRow > cqlRows = new ArrayList < CqlRow > ( ) ; 
 result . type = CqlResultType . ROWS ; 
 - 
 + 
 / / Create the result set 
 for ( org . apache . cassandra . db . Row row : rows ) 
 { 
 @ @ - 546 , 7 + 550 , 7 @ @ public class QueryProcessor 
 if ( row . cf = = null ) 
 continue ; 
 
 - List < Column > thriftColumns = extractThriftColumns ( select , comparator , row ) ; 
 + List < Column > thriftColumns = extractThriftColumns ( select , metadata , row ) ; 
 / / Create a new row , add the columns to it , and then add it to the list of rows 
 CqlRow cqlRow = new CqlRow ( ) ; 
 cqlRow . key = row . key . key ; 
 @ @ - 609 , 7 + 613 , 7 @ @ public class QueryProcessor 
 DeleteStatement delete = ( DeleteStatement ) statement . statement ; 
 clientState . hasColumnFamilyAccess ( delete . getColumnFamily ( ) , Permission . WRITE ) ; 
 metadata = validateColumnFamily ( keyspace , delete . getColumnFamily ( ) , false ) ; 
 - comparator = metadata . getComparatorFor ( null ) ; 
 + AbstractType comparator = metadata . getComparatorFor ( null ) ; 
 AbstractType < ? > keyType = DatabaseDescriptor . getCFMetaData ( keyspace , 
 delete . getColumnFamily ( ) ) . getKeyValidator ( ) ; 
 
 @ @ - 809 , 11 + 813 , 17 @ @ public class QueryProcessor 
 return null ; / / We should never get here . 
 } 
 
 - private static List < Column > extractThriftColumns ( SelectStatement select , AbstractType < ? > comparator , Row row ) 
 + private static List < Column > extractThriftColumns ( SelectStatement select , CFMetaData metadata , Row row ) 
 { 
 List < Column > thriftColumns = new ArrayList < Column > ( ) ; 
 if ( select . isColumnRange ( ) ) 
 { 
 + if ( select . isWildcard ( ) ) 
 + { 
 + / / prepend key 
 + thriftColumns . add ( new Column ( metadata . getKeyName ( ) ) . setValue ( row . key . key ) . setTimestamp ( - 1 ) ) ; 
 + } 
 + 
 / / preserve comparator order 
 for ( IColumn c : row . cf . getSortedColumns ( ) ) 
 { 
 @ @ - 824 , 13 + 834 , 23 @ @ public class QueryProcessor 
 } 
 else 
 { 
 + String keyString = getKeyString ( metadata ) ; 
 + 
 / / order columns in the order they were asked for 
 for ( Term term : select . getColumnNames ( ) ) 
 { 
 + if ( term . getText ( ) . equalsIgnoreCase ( keyString ) ) 
 + { 
 + / / preserve case of key as it was requested 
 + ByteBuffer requestedKey = ByteBufferUtil . bytes ( term . getText ( ) ) ; 
 + thriftColumns . add ( new Column ( requestedKey ) . setValue ( row . key . key ) . setTimestamp ( - 1 ) ) ; 
 + continue ; 
 + } 
 + 
 ByteBuffer name ; 
 try 
 { 
 - name = term . getByteBuffer ( comparator ) ; 
 + name = term . getByteBuffer ( metadata . comparator ) ; 
 } 
 catch ( InvalidRequestException e ) 
 { 
 @ @ - 846 , 6 + 866 , 20 @ @ public class QueryProcessor 
 return thriftColumns ; 
 } 
 
 + private static String getKeyString ( CFMetaData metadata ) 
 + { 
 + String keyString ; 
 + try 
 + { 
 + keyString = ByteBufferUtil . string ( metadata . getKeyName ( ) ) ; 
 + } 
 + catch ( CharacterCodingException e ) 
 + { 
 + throw new AssertionError ( e ) ; 
 + } 
 + return keyString ; 
 + } 
 + 
 private static CQLStatement getStatement ( String queryStr ) throws InvalidRequestException , RecognitionException 
 { 
 / / Lexer and parser 
 diff - - git a / src / java / org / apache / cassandra / cql / SelectExpression . java b / src / java / org / apache / cassandra / cql / SelectExpression . java 
 index 562d27d . . f2d8623 100644 
 - - - a / src / java / org / apache / cassandra / cql / SelectExpression . java 
 + + + b / src / java / org / apache / cassandra / cql / SelectExpression . java 
 @ @ - 37 , 6 + 37 , 7 @ @ public class SelectExpression 
 
 private int numColumns = MAX _ COLUMNS _ DEFAULT ; 
 private boolean reverseColumns = false ; 
 + private final boolean wildcard ; 
 private Term start , finish ; 
 private List < Term > columns ; 
 
 @ @ - 48 , 12 + 49 , 13 @ @ public class SelectExpression 
 * @ param count the number of columns to limit the results to 
 * @ param reverse true to reverse column order 
 * / 
 - public SelectExpression ( Term start , Term finish , int count , boolean reverse ) 
 + public SelectExpression ( Term start , Term finish , int count , boolean reverse , boolean wildcard ) 
 { 
 this . start = start ; 
 this . finish = finish ; 
 numColumns = count ; 
 reverseColumns = reverse ; 
 + this . wildcard = wildcard ; 
 } 
 
 / * * 
 @ @ - 65 , 6 + 67 , 7 @ @ public class SelectExpression 
 * / 
 public SelectExpression ( Term first , int count , boolean reverse ) 
 { 
 + wildcard = false ; 
 columns = new ArrayList < Term > ( ) ; 
 columns . add ( first ) ; 
 numColumns = count ; 
 @ @ - 125 , 4 + 128 , 9 @ @ public class SelectExpression 
 { 
 return columns ; 
 } 
 + 
 + public boolean isWildcard ( ) 
 + { 
 + return wildcard ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / cql / SelectStatement . java b / src / java / org / apache / cassandra / cql / SelectStatement . java 
 index b595806 . . dacba98 100644 
 - - - a / src / java / org / apache / cassandra / cql / SelectStatement . java 
 + + + b / src / java / org / apache / cassandra / cql / SelectStatement . java 
 @ @ - 81 , 6 + 81 , 11 @ @ public class SelectStatement 
 { 
 return expression . isColumnRange ( ) ; 
 } 
 + 
 + public boolean isWildcard ( ) 
 + { 
 + return expression . isWildcard ( ) ; 
 + } 
 
 public List < Term > getColumnNames ( ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / thrift / ThriftValidation . java b / src / java / org / apache / cassandra / thrift / ThriftValidation . java 
 index f200eca . . 35e042b 100644 
 - - - a / src / java / org / apache / cassandra / thrift / ThriftValidation . java 
 + + + b / src / java / org / apache / cassandra / thrift / ThriftValidation . java 
 @ @ - 26 , 6 + 26 , 7 @ @ import java . util . * ; 
 import org . apache . cassandra . config . * ; 
 import org . apache . cassandra . db . * ; 
 import org . apache . cassandra . db . marshal . AbstractType ; 
 + import org . apache . cassandra . db . marshal . AsciiType ; 
 import org . apache . cassandra . db . marshal . MarshalException ; 
 import org . apache . cassandra . dht . IPartitioner ; 
 import org . apache . cassandra . dht . RandomPartitioner ; 
 @ @ - 515 , 6 + 516 , 22 @ @ public class ThriftValidation 
 { 
 try 
 { 
 + if ( cf _ def . key _ alias ! = null ) 
 + { 
 + if ( ! cf _ def . key _ alias . hasRemaining ( ) ) 
 + throw new InvalidRequestException ( " key _ alias may not be empty " ) ; 
 + try 
 + { 
 + / / it ' s hard to use a key in a select statement if we can ' t type it . 
 + / / for now let ' s keep it simple and require ascii . 
 + AsciiType . instance . validate ( cf _ def . key _ alias ) ; 
 + } 
 + catch ( MarshalException e ) 
 + { 
 + throw new InvalidRequestException ( " Key aliases must be ascii " ) ; 
 + } 
 + } 
 + 
 ColumnFamilyType cfType = ColumnFamilyType . create ( cf _ def . column _ type ) ; 
 if ( cfType = = null ) 
 throw new InvalidRequestException ( " invalid column type " + cf _ def . column _ type ) ; 
 diff - - git a / test / system / test _ cql . py b / test / system / test _ cql . py 
 index a088ed2 . . f1d9ceb 100644 
 - - - a / test / system / test _ cql . py 
 + + + b / test / system / test _ cql . py 
 @ @ - 127 , 11 + 127 , 11 @ @ class TestCql ( ThriftTester ) : 
 def test _ select _ simple ( self ) : 
 " single - row named column queries " 
 cursor = init ( ) 
 - cursor . execute ( " SELECT ' ca1 ' FROM StandardString1 WHERE KEY = ' ka ' " ) 
 + cursor . execute ( " SELECT KEY , ca1 FROM StandardString1 WHERE KEY = ' ka ' " ) 
 r = cursor . fetchone ( ) 
 d = cursor . description 
 
 - assert d [ 0 ] [ 0 ] = = cql . ROW _ KEY 
 + assert d [ 0 ] [ 0 ] = = ' KEY ' 
 assert r [ 0 ] = = ' ka ' 
 
 assert d [ 1 ] [ 0 ] = = ' ca1 ' 
 @ @ - 144 , 10 + 144 , 10 @ @ class TestCql ( ThriftTester ) : 
 " " " ) 
 
 d = cursor . description 
 - assert [ ' Row Key ' , ' ca1 ' , ' col ' , ' cd1 ' ] = = [ col _ dscptn [ 0 ] for col _ dscptn in d ] , d 
 + assert [ ' ca1 ' , ' col ' , ' cd1 ' ] = = [ col _ dscptn [ 0 ] for col _ dscptn in d ] , d 
 row = cursor . fetchone ( ) 
 # check that the column that didn ' t exist in the row comes back as null 
 - assert [ ' kd ' , None , ' val ' , ' vd1 ' ] = = row , row 
 + assert [ None , ' val ' , ' vd1 ' ] = = row , row 
 
 def test _ select _ row _ range ( self ) : 
 " retrieve a range of rows with columns " 
 @ @ - 219 , 51 + 219 , 39 @ @ class TestCql ( ThriftTester ) : 
 " column slice tests " 
 cursor = init ( ) 
 
 - # all columns 
 + # * includes row key , explicit slice does not 
 cursor . execute ( " SELECT * FROM StandardString1 WHERE KEY = ' ka ' ; " ) 
 - r = cursor . fetchone ( ) 
 - assert len ( r ) = = 3 
 + row = cursor . fetchone ( ) 
 + assert [ ' ka ' , ' va1 ' , ' val ' ] = = row , row 
 + 
 cursor . execute ( " SELECT ' ' . . ' ' FROM StandardString1 WHERE KEY = ' ka ' ; " ) 
 - r = cursor . fetchone ( ) 
 - assert len ( r ) = = 3 
 + row = cursor . fetchone ( ) 
 + assert [ ' va1 ' , ' val ' ] = = row , row 
 
 # column subsets 
 cursor . execute ( " SELECT 1 . . 3 FROM StandardLongA WHERE KEY = ' aa ' ; " ) 
 assert cursor . rowcount = = 1 
 - r = cursor . fetchone ( ) 
 - assert r [ 0 ] = = " aa " 
 - assert r [ 1 ] = = " 1 " 
 - assert r [ 2 ] = = " 2 " 
 - assert r [ 3 ] = = " 3 " 
 + row = cursor . fetchone ( ) 
 + assert [ ' 1 ' , ' 2 ' , ' 3 ' ] = = row , row 
 
 - cursor . execute ( " SELECT 10 . . 30 FROM StandardIntegerA WHERE KEY = ' k1 ' " ) 
 - assert cursor . rowcount = = 1 
 - r = cursor . fetchone ( ) 
 - assert r [ 0 ] = = " k1 " 
 - assert r [ 1 ] = = " a " 
 - assert r [ 2 ] = = " b " 
 - assert r [ 3 ] = = " c " 
 - 
 - # range of columns ( slice ) by row with FIRST 
 cursor . execute ( " " " 
 - SELECT FIRST 1 1 . . 3 FROM StandardLongA WHERE KEY = ' aa ' ; 
 + SELECT key , 20 , 40 FROM StandardIntegerA 
 + WHERE KEY > ' k1 ' AND KEY < ' k7 ' LIMIT 5 
 " " " ) 
 + row = cursor . fetchone ( ) 
 + assert [ ' k2 ' , ' f ' , ' h ' ] = = row , row 
 + 
 + # range of columns ( slice ) by row with FIRST 
 + cursor . execute ( " SELECT FIRST 1 1 . . 3 FROM StandardLongA WHERE KEY = ' aa ' " ) 
 assert cursor . rowcount = = 1 
 - r = cursor . fetchone ( ) 
 - assert len ( r ) = = 2 
 - assert r [ 0 ] = = " aa " 
 - assert r [ 1 ] = = " 1 " 
 + row = cursor . fetchone ( ) 
 + assert [ ' 1 ' ] = = row , row 
 
 # range of columns ( slice ) by row reversed 
 - cursor . execute ( " " " 
 - SELECT FIRST 2 REVERSED 3 . . 1 FROM StandardLongA WHERE KEY = ' aa ' ; 
 - " " " ) 
 + cursor . execute ( " SELECT FIRST 2 REVERSED 3 . . 1 FROM StandardLongA WHERE KEY = ' aa ' " ) 
 assert cursor . rowcount = = 1 , " % d ! = 1 " % cursor . rowcount 
 - r = cursor . fetchone ( ) 
 - assert len ( r ) = = 3 
 - assert r [ 0 ] = = ' aa ' 
 - assert r [ 1 ] = = " 3 " 
 - assert r [ 2 ] = = " 2 " 
 + row = cursor . fetchone ( ) 
 + assert [ ' 3 ' , ' 2 ' ] = = row , row 
 
 def test _ select _ range _ with _ single _ column _ results ( self ) : 
 " range should not fail when keys were not set " 
 @ @ - 277 , 7 + 265 , 7 @ @ class TestCql ( ThriftTester ) : 
 " " " ) 
 
 cursor . execute ( " " " 
 - SELECT name FROM StandardString2 
 + SELECT KEY , name FROM StandardString2 
 " " " ) 
 
 assert cursor . rowcount = = 3 , " expected 3 results , got % d " % cursor . rowcount 
 @ @ - 305 , 7 + 293 , 7 @ @ class TestCql ( ThriftTester ) : 
 " indexed scan where column equals value " 
 cursor = init ( ) 
 cursor . execute ( " " " 
 - SELECT ' birthdate ' FROM IndexedA WHERE ' birthdate ' = 100 
 + SELECT KEY , birthdate FROM IndexedA WHERE birthdate = 100 
 " " " ) 
 assert cursor . rowcount = = 2 
 
 @ @ - 321 , 19 + 309 , 19 @ @ class TestCql ( ThriftTester ) : 
 " indexed scan where a column is greater than a value " 
 cursor = init ( ) 
 cursor . execute ( " " " 
 - SELECT ' birthdate ' FROM IndexedA WHERE ' birthdate ' = 100 
 - AND ' unindexed ' > 200 
 + SELECT KEY , ' birthdate ' FROM IndexedA 
 + WHERE ' birthdate ' = 100 AND ' unindexed ' > 200 
 " " " ) 
 assert cursor . rowcount = = 1 
 - r = cursor . fetchone ( ) 
 - assert r [ 0 ] = = " asmith " 
 + row = cursor . fetchone ( ) 
 + assert row [ 0 ] = = " asmith " , row 
 
 def test _ index _ scan _ with _ start _ key ( self ) : 
 " indexed scan with a starting key " 
 cursor = init ( ) 
 cursor . execute ( " " " 
 - SELECT ' birthdate ' FROM IndexedA WHERE ' birthdate ' = 100 
 - AND KEY > = ' asmithZ ' 
 + SELECT KEY , ' birthdate ' FROM IndexedA 
 + WHERE ' birthdate ' = 100 AND KEY > = ' asmithZ ' 
 " " " ) 
 assert cursor . rowcount = = 1 
 r = cursor . fetchone ( ) 
 @ @ - 342 , 7 + 330 , 7 @ @ class TestCql ( ThriftTester ) : 
 def test _ no _ where _ clause ( self ) : 
 " empty where clause ( range query w / o start key ) " 
 cursor = init ( ) 
 - cursor . execute ( " SELECT ' col ' FROM StandardString1 LIMIT 3 " ) 
 + cursor . execute ( " SELECT KEY , ' col ' FROM StandardString1 LIMIT 3 " ) 
 assert cursor . rowcount = = 3 
 rows = cursor . fetchmany ( 3 ) 
 assert rows [ 0 ] [ 0 ] = = " ka " 
 @ @ - 376 , 7 + 364 , 8 @ @ class TestCql ( ThriftTester ) : 
 cursor . execute ( " " " 
 SELECT ' cd1 ' , ' col ' FROM StandardString1 WHERE KEY = ' kd ' 
 " " " ) 
 - assert [ ' Row Key ' , ' cd1 ' , ' col ' ] = = [ col _ d [ 0 ] for col _ d in cursor . description ] 
 + desc = [ col _ d [ 0 ] for col _ d in cursor . description ] 
 + assert [ ' cd1 ' , ' col ' ] = = desc , desc 
 
 cursor . execute ( " " " 
 DELETE ' cd1 ' , ' col ' FROM StandardString1 WHERE KEY = ' kd ' 
 @ @ - 384 , 31 + 373 , 31 @ @ class TestCql ( ThriftTester ) : 
 cursor . execute ( " " " 
 SELECT ' cd1 ' , ' col ' FROM StandardString1 WHERE KEY = ' kd ' 
 " " " ) 
 - r = cursor . fetchone ( ) 
 - assert [ ' kd ' , None , None ] = = r , r 
 + row = cursor . fetchone ( ) 
 + assert [ None , None ] = = row , row 
 
 def test _ delete _ columns _ multi _ rows ( self ) : 
 " delete columns from multiple rows " 
 cursor = init ( ) 
 
 + # verify rows exist initially 
 cursor . execute ( " SELECT ' col ' FROM StandardString1 WHERE KEY = ' kc ' " ) 
 - r = cursor . fetchone ( ) 
 - assert [ ' kc ' , ' val ' ] = = r , r 
 - 
 + row = cursor . fetchone ( ) 
 + assert [ ' val ' ] = = row , row 
 cursor . execute ( " SELECT ' col ' FROM StandardString1 WHERE KEY = ' kd ' " ) 
 - r = cursor . fetchone ( ) 
 - assert [ ' kd ' , ' val ' ] = = r , r 
 + row = cursor . fetchone ( ) 
 + assert [ ' val ' ] = = row , row 
 
 + # delete and verify data is gone 
 cursor . execute ( " " " 
 DELETE ' col ' FROM StandardString1 WHERE KEY IN ( ' kc ' , ' kd ' ) 
 " " " ) 
 cursor . execute ( " SELECT ' col ' FROM StandardString1 WHERE KEY = ' kc ' " ) 
 - r = cursor . fetchone ( ) 
 - assert [ ' kc ' , None ] = = r , r 
 - 
 + row = cursor . fetchone ( ) 
 + assert [ None ] = = row , row 
 cursor . execute ( " SELECT ' col ' FROM StandardString1 WHERE KEY = ' kd ' " ) 
 r = cursor . fetchone ( ) 
 - assert [ ' kd ' , None ] = = r , r 
 + assert [ None ] = = r , r 
 
 def test _ delete _ rows ( self ) : 
 " delete entire rows " 
 @ @ - 416 , 13 + 405 , 13 @ @ class TestCql ( ThriftTester ) : 
 cursor . execute ( " " " 
 SELECT ' cd1 ' , ' col ' FROM StandardString1 WHERE KEY = ' kd ' 
 " " " ) 
 - assert [ ' Row Key ' , ' cd1 ' , ' col ' ] = = [ col _ d [ 0 ] for col _ d in cursor . description ] 
 + assert [ ' cd1 ' , ' col ' ] = = [ col _ d [ 0 ] for col _ d in cursor . description ] 
 cursor . execute ( " DELETE FROM StandardString1 WHERE KEY = ' kd ' " ) 
 cursor . execute ( " " " 
 SELECT ' cd1 ' , ' col ' FROM StandardString1 WHERE KEY = ' kd ' 
 " " " ) 
 - r = cursor . fetchone ( ) 
 - assert [ ' kd ' , None , None ] = = r , r 
 + row = cursor . fetchone ( ) 
 + assert [ None , None ] = = row , row 
 
 def test _ create _ keyspace ( self ) : 
 " create a new keyspace " 
 @ @ - 578 , 7 + 567 , 7 @ @ class TestCql ( ThriftTester ) : 
 SELECT ' % s ' FROM StandardTimeUUID WHERE KEY = ' uuidtest ' 
 " " " % str ( timeuuid ) ) 
 d = cursor . description 
 - assert d [ 1 ] [ 0 ] = = timeuuid , " % s , % s " % ( str ( d [ 1 ] [ 0 ] ) , str ( timeuuid ) ) 
 + assert d [ 0 ] [ 0 ] = = timeuuid , " % s , % s " % ( str ( d [ 1 ] [ 0 ] ) , str ( timeuuid ) ) 
 
 # Tests a node - side conversion from bigint to UUID . 
 ms = uuid1bytes _ to _ millis ( uuid . uuid1 ( ) . bytes ) 
 @ @ - 590 , 7 + 579 , 7 @ @ class TestCql ( ThriftTester ) : 
 SELECT ' id ' FROM StandardTimeUUIDValues WHERE KEY = ' uuidtest ' 
 " " " ) 
 r = cursor . fetchone ( ) 
 - assert uuid1bytes _ to _ millis ( r [ 1 ] . bytes ) = = ms 
 + assert uuid1bytes _ to _ millis ( r [ 0 ] . bytes ) = = ms 
 
 # Tests a node - side conversion from ISO8601 to UUID . 
 cursor . execute ( " " " 
 @ @ - 603 , 7 + 592 , 7 @ @ class TestCql ( ThriftTester ) : 
 " " " ) 
 # 2011 - 01 - 31 17 : 00 : 00 - 0000 = = 1296493200000ms 
 r = cursor . fetchone ( ) 
 - ms = uuid1bytes _ to _ millis ( r [ 1 ] . bytes ) 
 + ms = uuid1bytes _ to _ millis ( r [ 0 ] . bytes ) 
 assert ms = = 1296493200000 , \ 
 " % d ! = 1296493200000 ( 2011 - 01 - 31 17 : 00 : 00 - 0000 ) " % ms 
 
 @ @ - 617 , 7 + 606 , 7 @ @ class TestCql ( ThriftTester ) : 
 SELECT ' id3 ' FROM StandardTimeUUIDValues WHERE KEY = ' uuidtest ' 
 " " " ) 
 r = cursor . fetchone ( ) 
 - ms = uuid1bytes _ to _ millis ( r [ 1 ] . bytes ) 
 + ms = uuid1bytes _ to _ millis ( r [ 0 ] . bytes ) 
 assert ( ( time . time ( ) * 1e3 ) - ms ) < 100 , \ 
 " new timeuuid not within 100ms of now ( UPDATE vs . SELECT ) " 
 
 @ @ - 631 , 7 + 620 , 7 @ @ class TestCql ( ThriftTester ) : 
 SELECT : start . . : finish FROM StandardTimeUUID WHERE KEY = slicetest 
 " " " , dict ( start = uuid _ range [ 0 ] , finish = uuid _ range [ len ( uuid _ range ) - 1 ] ) ) 
 d = cursor . description 
 - for ( i , col _ d ) in enumerate ( d [ 1 : ] ) : 
 + for ( i , col _ d ) in enumerate ( d ) : 
 assert uuid _ range [ i ] = = col _ d [ 0 ] 
 
 
 @ @ - 645 , 7 + 634 , 7 @ @ class TestCql ( ThriftTester ) : 
 cursor . execute ( " SELECT : name FROM StandardUUID WHERE KEY = ' uuidtest ' " , 
 dict ( name = uid ) ) 
 d = cursor . description 
 - assert d [ 1 ] [ 0 ] = = uid , " expected % s , got % s ( % s ) " % \ 
 + assert d [ 0 ] [ 0 ] = = uid , " expected % s , got % s ( % s ) " % \ 
 ( uid . bytes . encode ( ' hex ' ) , str ( d [ 1 ] [ 0 ] ) . encode ( ' hex ' ) , d [ 1 ] [ 1 ] ) 
 
 # TODO : slices of uuids from cf w / LexicalUUIDType comparator 
 @ @ - 661 , 18 + 650 , 19 @ @ class TestCql ( ThriftTester ) : 
 
 cursor . execute ( " SELECT * FROM StandardUtf82 WHERE KEY = k1 " ) 
 d = cursor . description 
 + assert d [ 0 ] [ 0 ] = = ' KEY ' , d [ 0 ] [ 0 ] 
 assert d [ 1 ] [ 0 ] = = u "  " , d [ 1 ] [ 0 ] 
 assert d [ 2 ] [ 0 ] = = u "  " , d [ 2 ] [ 0 ] 
 assert d [ 3 ] [ 0 ] = = u "  " , d [ 3 ] [ 0 ] 
 assert d [ 4 ] [ 0 ] = = u "  " , d [ 4 ] [ 0 ] 
 
 cursor . execute ( " SELECT : start . . ' ' FROM StandardUtf82 WHERE KEY = k1 " , dict ( start = "  " ) ) 
 - r = cursor . fetchone ( ) 
 - assert len ( r ) = = 4 
 + row = cursor . fetchone ( ) 
 + assert len ( row ) = = 3 , row 
 d = cursor . description 
 - assert d [ 1 ] [ 0 ] = = u "  " 
 - assert d [ 2 ] [ 0 ] = = u "  " 
 - assert d [ 3 ] [ 0 ] = = u "  " 
 + assert d [ 0 ] [ 0 ] = = u "  " 
 + assert d [ 1 ] [ 0 ] = = u "  " 
 + assert d [ 2 ] [ 0 ] = = u "  " 
 
 def test _ read _ write _ negative _ numerics ( self ) : 
 " reading and writing negative numeric values " 
 @ @ - 685 , 11 + 675 , 11 @ @ class TestCql ( ThriftTester ) : 
 cursor . execute ( " SELECT : start . . : finish FROM : cf WHERE KEY = negatives ; " , 
 dict ( start = - 10 , finish = - 1 , cf = cf ) ) 
 r = cursor . fetchone ( ) 
 - assert len ( r ) = = 11 , \ 
 + assert len ( r ) = = 10 , \ 
 " returned % d columns , expected % d " % ( len ( r ) - 1 , 10 ) 
 d = cursor . description 
 - assert d [ 1 ] [ 0 ] = = - 10 
 - assert d [ 10 ] [ 0 ] = = - 1 
 + assert d [ 0 ] [ 0 ] = = - 10 
 + assert d [ 9 ] [ 0 ] = = - 1 
 
 def test _ escaped _ quotes ( self ) : 
 " reading and writing strings w / escaped quotes " 
 @ @ - 704 , 17 + 694 , 17 @ @ class TestCql ( ThriftTester ) : 
 " " " , dict ( key = " test _ escaped _ quotes " ) ) 
 assert cursor . rowcount = = 1 
 r = cursor . fetchone ( ) 
 - assert len ( r ) = = 2 , " wrong number of results " 
 + assert len ( r ) = = 1 , " wrong number of results " 
 d = cursor . description 
 - assert d [ 1 ] [ 0 ] = = " x \ ' and \ ' y " 
 - 
 + assert d [ 0 ] [ 0 ] = = " x ' and ' y " 
 + 
 def test _ typed _ keys ( self ) : 
 " using typed keys " 
 cursor = init ( ) 
 cursor . execute ( " SELECT * FROM StandardString1 WHERE KEY = : key " , dict ( key = " ka " ) ) 
 - r = cursor . fetchone ( ) 
 - assert isinstance ( r [ 0 ] , unicode ) , \ 
 - " wrong key - type returned , expected unicode , got % s " % type ( r [ 0 ] ) 
 + row = cursor . fetchone ( ) 
 + assert isinstance ( row [ 0 ] , unicode ) , \ 
 + " wrong key - type returned , expected unicode , got % s " % type ( row [ 0 ] ) 
 
 # FIXME : The above is woefully inadequate , but the test config uses 
 # CollatingOrderPreservingPartitioner which only supports UTF8 . 
 @ @ - 760 , 8 + 750 , 6 @ @ class TestCql ( ThriftTester ) : 
 
 assert cursor . rowcount = = 1 , " expected 1 result , got % d " % cursor . rowcount 
 colnames = [ col _ d [ 0 ] for col _ d in cursor . description ] 
 - assert colnames [ 1 ] = = " some _ name " , \ 
 - " unrecognized name ' % s ' " % colnames [ 1 ] 
 - r = cursor . fetchone ( ) 
 - assert r [ 1 ] = = " some _ value " , \ 
 - " unrecognized value ' % s ' " % r [ 1 ] 
 + assert [ ' some _ name ' ] = = colnames , colnames 
 + row = cursor . fetchone ( ) 
 + assert [ ' some _ value ' ] = = row , row
