BLEU SCORE: 0.018738883683389617

TEST MSG: getValidColumnFamilies adds 2I if requested and no ks / cf specified
GENERATED MSG: Update news for 4880

TEST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index 8470078 . . 345d6c9 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 2259 , 13 + 2259 , 27 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> public Iterable < ColumnFamilyStore > getValidColumnFamilies ( boolean allowIndexes , boolean autoAddIndexes , String keyspaceName , String . . . cfNames ) throws IOException <nl> { <nl> Keyspace keyspace = getValidKeyspace ( keyspaceName ) ; <nl> + Set < ColumnFamilyStore > valid = new HashSet < > ( ) ; <nl> <nl> if ( cfNames . length = = 0 ) <nl> + { <nl> / / all stores are interesting <nl> - return keyspace . getColumnFamilyStores ( ) ; <nl> + for ( ColumnFamilyStore cfStore : keyspace . getColumnFamilyStores ( ) ) <nl> + { <nl> + valid . add ( cfStore ) ; <nl> + if ( autoAddIndexes ) <nl> + { <nl> + for ( SecondaryIndex si : cfStore . indexManager . getIndexes ( ) ) <nl> + { <nl> + logger . info ( " adding secondary index { } to operation " , si . getIndexName ( ) ) ; <nl> + valid . add ( si . getIndexCfs ( ) ) ; <nl> + } <nl> <nl> + } <nl> + } <nl> + return valid ; <nl> + } <nl> / / filter out interesting stores <nl> - Set < ColumnFamilyStore > valid = new HashSet < ColumnFamilyStore > ( ) ; <nl> for ( String cfName : cfNames ) <nl> { <nl> / / if the CF name is an index , just flush the CF that owns the index
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 2ec66c9 . . 95aad22 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 20 , 6 + 20 , 7 @ @ <nl> * cqlsh : Add default limit to SELECT statements ( CASSANDRA - 4972 ) <nl> * cqlsh : fix DESCRIBE for 1 . 1 cfs in CQL3 ( CASSANDRA - 5101 ) <nl> * Correctly gossip with nodes > = 1 . 1 . 7 ( CASSANDRA - 5102 ) <nl> + * Ensure CL guarantees on digest mismatch ( CASSANDRA - 5113 ) <nl> Merged from 1 . 1 : <nl> * Pig : correctly decode row keys in widerow mode ( CASSANDRA - 5098 ) <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / ReadCommand . java b / src / java / org / apache / cassandra / db / ReadCommand . java <nl> index f3494e5 . . 6c364cb 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ReadCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / ReadCommand . java <nl> @ @ - 32 , 7 + 32 , 7 @ @ import org . apache . cassandra . io . IVersionedSerializer ; <nl> import org . apache . cassandra . net . MessageOut ; <nl> import org . apache . cassandra . net . MessagingService ; <nl> import org . apache . cassandra . service . IReadCommand ; <nl> - import org . apache . cassandra . service . RepairCallback ; <nl> + import org . apache . cassandra . service . RowDataResolver ; <nl> import org . apache . cassandra . utils . IFilter ; <nl> <nl> <nl> @ @ - 94 , 7 + 94 , 7 @ @ public abstract class ReadCommand implements IReadCommand <nl> } <nl> <nl> / / maybeGenerateRetryCommand is used to generate a retry for short reads <nl> - public ReadCommand maybeGenerateRetryCommand ( RepairCallback handler , Row row ) <nl> + public ReadCommand maybeGenerateRetryCommand ( RowDataResolver resolver , Row row ) <nl> { <nl> return null ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java <nl> index d52826b . . 8a08a42 100644 <nl> - - - a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java <nl> @ @ - 30 , 7 + 30 , 7 @ @ import org . apache . cassandra . db . filter . QueryFilter ; <nl> import org . apache . cassandra . db . filter . QueryPath ; <nl> import org . apache . cassandra . db . filter . SliceQueryFilter ; <nl> import org . apache . cassandra . io . IVersionedSerializer ; <nl> - import org . apache . cassandra . service . RepairCallback ; <nl> + import org . apache . cassandra . service . RowDataResolver ; <nl> import org . apache . cassandra . service . StorageService ; <nl> import org . apache . cassandra . thrift . ColumnParent ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> @ @ - 71 , 9 + 71 , 9 @ @ public class SliceFromReadCommand extends ReadCommand <nl> } <nl> <nl> @ Override <nl> - public ReadCommand maybeGenerateRetryCommand ( RepairCallback handler , Row row ) <nl> + public ReadCommand maybeGenerateRetryCommand ( RowDataResolver resolver , Row row ) <nl> { <nl> - int maxLiveColumns = handler . getMaxLiveCount ( ) ; <nl> + int maxLiveColumns = resolver . getMaxLiveCount ( ) ; <nl> <nl> int count = filter . count ; <nl> assert maxLiveColumns < = count ; <nl> diff - - git a / src / java / org / apache / cassandra / service / AsyncRepairCallback . java b / src / java / org / apache / cassandra / service / AsyncRepairCallback . java <nl> index 675f61c . . 63b7df3 100644 <nl> - - - a / src / java / org / apache / cassandra / service / AsyncRepairCallback . java <nl> + + + b / src / java / org / apache / cassandra / service / AsyncRepairCallback . java <nl> @ @ - 28 , 11 + 28 , 11 @ @ import org . apache . cassandra . utils . WrappedRunnable ; <nl> <nl> public class AsyncRepairCallback implements IAsyncCallback <nl> { <nl> - private final RowRepairResolver repairResolver ; <nl> + private final RowDataResolver repairResolver ; <nl> private final int blockfor ; <nl> protected final AtomicInteger received = new AtomicInteger ( 0 ) ; <nl> <nl> - public AsyncRepairCallback ( RowRepairResolver repairResolver , int blockfor ) <nl> + public AsyncRepairCallback ( RowDataResolver repairResolver , int blockfor ) <nl> { <nl> this . repairResolver = repairResolver ; <nl> this . blockfor = blockfor ; <nl> diff - - git a / src / java / org / apache / cassandra / service / DatacenterReadCallback . java b / src / java / org / apache / cassandra / service / DatacenterReadCallback . java <nl> index d125553 . . e1ae652 100644 <nl> - - - a / src / java / org / apache / cassandra / service / DatacenterReadCallback . java <nl> + + + b / src / java / org / apache / cassandra / service / DatacenterReadCallback . java <nl> @ @ - 46 , 11 + 46 , 22 @ @ public class DatacenterReadCallback < TMessage , TResolved > extends ReadCallback < TM <nl> } <nl> } ; <nl> <nl> - public DatacenterReadCallback ( IResponseResolver resolver , ConsistencyLevel consistencyLevel , IReadCommand command , List < InetAddress > endpoints ) <nl> + public DatacenterReadCallback ( IResponseResolver < TMessage , TResolved > resolver , ConsistencyLevel consistencyLevel , IReadCommand command , List < InetAddress > endpoints ) <nl> { <nl> super ( resolver , consistencyLevel , command , endpoints ) ; <nl> } <nl> <nl> + protected DatacenterReadCallback ( IResponseResolver < TMessage , TResolved > resolver , ConsistencyLevel consistencyLevel , int blockfor , IReadCommand command , List < InetAddress > endpoints ) <nl> + { <nl> + super ( resolver , consistencyLevel , blockfor , command , endpoints ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public ReadCallback < TMessage , TResolved > withNewResolver ( IResponseResolver < TMessage , TResolved > newResolver ) <nl> + { <nl> + return new DatacenterReadCallback ( newResolver , consistencyLevel , blockfor , command , endpoints ) ; <nl> + } <nl> + <nl> @ Override <nl> protected void sortForConsistencyLevel ( List < InetAddress > endpoints ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / service / RangeSliceResponseResolver . java b / src / java / org / apache / cassandra / service / RangeSliceResponseResolver . java <nl> index 0d24fbf . . 1dfd01e 100644 <nl> - - - a / src / java / org / apache / cassandra / service / RangeSliceResponseResolver . java <nl> + + + b / src / java / org / apache / cassandra / service / RangeSliceResponseResolver . java <nl> @ @ - 138 , 7 + 138 , 7 @ @ public class RangeSliceResponseResolver implements IResponseResolver < RangeSliceR <nl> protected Row getReduced ( ) <nl> { <nl> ColumnFamily resolved = versions . size ( ) > 1 <nl> - ? RowRepairResolver . resolveSuperset ( versions ) <nl> + ? RowDataResolver . resolveSuperset ( versions ) <nl> : versions . get ( 0 ) ; <nl> if ( versions . size ( ) < sources . size ( ) ) <nl> { <nl> @ @ - 154 , 7 + 154 , 7 @ @ public class RangeSliceResponseResolver implements IResponseResolver < RangeSliceR <nl> } <nl> / / resolved can be null even if versions doesn ' t have all nulls because of the call to removeDeleted in resolveSuperSet <nl> if ( resolved ! = null ) <nl> - repairResults . addAll ( RowRepairResolver . scheduleRepairs ( resolved , table , key , versions , versionSources ) ) ; <nl> + repairResults . addAll ( RowDataResolver . scheduleRepairs ( resolved , table , key , versions , versionSources ) ) ; <nl> versions . clear ( ) ; <nl> versionSources . clear ( ) ; <nl> return new Row ( key , resolved ) ; <nl> diff - - git a / src / java / org / apache / cassandra / service / ReadCallback . java b / src / java / org / apache / cassandra / service / ReadCallback . java <nl> index 8df2e10 . . e12859a 100644 <nl> - - - a / src / java / org / apache / cassandra / service / ReadCallback . java <nl> + + + b / src / java / org / apache / cassandra / service / ReadCallback . java <nl> @ @ - 60 , 7 + 60 , 7 @ @ public class ReadCallback < TMessage , TResolved > implements IAsyncCallback < TMessag <nl> private final long startTime ; <nl> protected final int blockfor ; <nl> final List < InetAddress > endpoints ; <nl> - private final IReadCommand command ; <nl> + protected final IReadCommand command ; <nl> protected final ConsistencyLevel consistencyLevel ; <nl> protected final AtomicInteger received = new AtomicInteger ( 0 ) ; <nl> <nl> @ @ - 75 , 11 + 75 , 26 @ @ public class ReadCallback < TMessage , TResolved > implements IAsyncCallback < TMessag <nl> this . startTime = System . currentTimeMillis ( ) ; <nl> this . consistencyLevel = consistencyLevel ; <nl> sortForConsistencyLevel ( endpoints ) ; <nl> - this . endpoints = resolver instanceof RowRepairResolver ? endpoints : filterEndpoints ( endpoints ) ; <nl> + this . endpoints = filterEndpoints ( endpoints ) ; <nl> if ( logger . isTraceEnabled ( ) ) <nl> logger . trace ( String . format ( " Blockfor is % s ; setting up requests to % s " , blockfor , StringUtils . join ( this . endpoints , " , " ) ) ) ; <nl> } <nl> <nl> + protected ReadCallback ( IResponseResolver < TMessage , TResolved > resolver , ConsistencyLevel consistencyLevel , int blockfor , IReadCommand command , List < InetAddress > endpoints ) <nl> + { <nl> + this . command = command ; <nl> + this . blockfor = blockfor ; <nl> + this . consistencyLevel = consistencyLevel ; <nl> + this . resolver = resolver ; <nl> + this . startTime = System . currentTimeMillis ( ) ; <nl> + this . endpoints = endpoints ; <nl> + } <nl> + <nl> + public ReadCallback < TMessage , TResolved > withNewResolver ( IResponseResolver < TMessage , TResolved > newResolver ) <nl> + { <nl> + return new ReadCallback ( newResolver , consistencyLevel , blockfor , command , endpoints ) ; <nl> + } <nl> + <nl> / * * <nl> * Endpoints is already restricted to live replicas , sorted by snitch preference . This is a hook for <nl> * DatacenterReadCallback to move local - DC replicas to the front of the list . We need this both <nl> @ @ - 209 , 17 + 224 , 22 @ @ public class ReadCallback < TMessage , TResolved > implements IAsyncCallback < TMessag <nl> { <nl> protected void runMayThrow ( ) throws IOException <nl> { <nl> + / / If the resolver is a RowDigestResolver , we need to do a full data read if there is a mismatch . <nl> + / / Otherwise , resolve will send the repairs directly if needs be ( and in that case we should never <nl> + / / get a digest mismatch ) <nl> try <nl> { <nl> resolver . resolve ( ) ; <nl> } <nl> catch ( DigestMismatchException e ) <nl> { <nl> + assert resolver instanceof RowDigestResolver ; <nl> + <nl> if ( logger . isDebugEnabled ( ) ) <nl> logger . debug ( " Digest mismatch : " , e ) ; <nl> <nl> ReadCommand readCommand = ( ReadCommand ) command ; <nl> - final RowRepairResolver repairResolver = new RowRepairResolver ( readCommand . table , readCommand . key , readCommand . filter ( ) ) ; <nl> + final RowDataResolver repairResolver = new RowDataResolver ( readCommand . table , readCommand . key , readCommand . filter ( ) ) ; <nl> IAsyncCallback repairHandler = new AsyncRepairCallback ( repairResolver , endpoints . size ( ) ) ; <nl> <nl> MessageOut < ReadCommand > message = ( ( ReadCommand ) command ) . createMessage ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / service / RepairCallback . java b / src / java / org / apache / cassandra / service / RepairCallback . java <nl> deleted file mode 100644 <nl> index 9388328 . . 0000000 <nl> - - - a / src / java / org / apache / cassandra / service / RepairCallback . java <nl> + + + / dev / null <nl> @ @ - 1 , 86 + 0 , 0 @ @ <nl> - / * <nl> - * Licensed to the Apache Software Foundation ( ASF ) under one <nl> - * or more contributor license agreements . See the NOTICE file <nl> - * distributed with this work for additional information <nl> - * regarding copyright ownership . The ASF licenses this file <nl> - * to you under the Apache License , Version 2 . 0 ( the <nl> - * " License " ) ; you may not use this file except in compliance <nl> - * with the License . You may obtain a copy of the License at <nl> - * <nl> - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> - * <nl> - * Unless required by applicable law or agreed to in writing , software <nl> - * distributed under the License is distributed on an " AS IS " BASIS , <nl> - * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> - * See the License for the specific language governing permissions and <nl> - * limitations under the License . <nl> - * / <nl> - package org . apache . cassandra . service ; <nl> - <nl> - import java . io . IOException ; <nl> - import java . net . InetAddress ; <nl> - import java . util . List ; <nl> - import java . util . concurrent . TimeUnit ; <nl> - import java . util . concurrent . atomic . AtomicInteger ; <nl> - <nl> - import org . apache . cassandra . config . DatabaseDescriptor ; <nl> - import org . apache . cassandra . db . Row ; <nl> - import org . apache . cassandra . net . IAsyncCallback ; <nl> - import org . apache . cassandra . net . MessageIn ; <nl> - import org . apache . cassandra . utils . SimpleCondition ; <nl> - <nl> - public class RepairCallback implements IAsyncCallback <nl> - { <nl> - public final RowRepairResolver resolver ; <nl> - private final List < InetAddress > endpoints ; <nl> - private final SimpleCondition condition = new SimpleCondition ( ) ; <nl> - private final long startTime ; <nl> - protected final AtomicInteger received = new AtomicInteger ( 0 ) ; <nl> - <nl> - / * * <nl> - * The main difference between this and ReadCallback is , ReadCallback has a ConsistencyLevel <nl> - * it needs to achieve . Repair on the other hand is happy to repair whoever replies within the timeout . <nl> - * <nl> - * ( The other main difference of course is , this is only created once we know we have a digest <nl> - * mismatch , and we ' re going to do full - data reads from everyone - - that is , this is the final <nl> - * stage in the read process . ) <nl> - * / <nl> - public RepairCallback ( RowRepairResolver resolver , List < InetAddress > endpoints ) <nl> - { <nl> - this . resolver = resolver ; <nl> - this . endpoints = endpoints ; <nl> - this . startTime = System . currentTimeMillis ( ) ; <nl> - } <nl> - <nl> - public Row get ( ) throws DigestMismatchException , IOException <nl> - { <nl> - long timeout = DatabaseDescriptor . getWriteRpcTimeout ( ) - ( System . currentTimeMillis ( ) - startTime ) ; <nl> - try <nl> - { <nl> - condition . await ( timeout , TimeUnit . MILLISECONDS ) ; <nl> - } <nl> - catch ( InterruptedException ex ) <nl> - { <nl> - throw new AssertionError ( ex ) ; <nl> - } <nl> - <nl> - return received . get ( ) > 1 ? resolver . resolve ( ) : null ; <nl> - } <nl> - <nl> - public void response ( MessageIn message ) <nl> - { <nl> - resolver . preprocess ( message ) ; <nl> - if ( received . incrementAndGet ( ) = = endpoints . size ( ) ) <nl> - condition . signal ( ) ; <nl> - } <nl> - <nl> - public boolean isLatencyForSnitch ( ) <nl> - { <nl> - return true ; <nl> - } <nl> - <nl> - public int getMaxLiveCount ( ) <nl> - { <nl> - return resolver . getMaxLiveCount ( ) ; <nl> - } <nl> - } <nl> diff - - git a / src / java / org / apache / cassandra / service / RowDataResolver . java b / src / java / org / apache / cassandra / service / RowDataResolver . java <nl> new file mode 100644 <nl> index 0000000 . . 5545293 <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / service / RowDataResolver . java <nl> @ @ - 0 , 0 + 1 , 182 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an " AS IS " BASIS , <nl> + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + * See the License for the specific language governing permissions and <nl> + * limitations under the License . <nl> + * / <nl> + package org . apache . cassandra . service ; <nl> + <nl> + import java . io . IOException ; <nl> + import java . net . InetAddress ; <nl> + import java . nio . ByteBuffer ; <nl> + import java . util . ArrayList ; <nl> + import java . util . Collections ; <nl> + import java . util . List ; <nl> + <nl> + import com . google . common . collect . Iterables ; <nl> + <nl> + import org . apache . cassandra . db . * ; <nl> + import org . apache . cassandra . db . columniterator . IdentityQueryFilter ; <nl> + import org . apache . cassandra . db . filter . IDiskAtomFilter ; <nl> + import org . apache . cassandra . db . filter . QueryFilter ; <nl> + import org . apache . cassandra . db . filter . QueryPath ; <nl> + import org . apache . cassandra . db . filter . SliceQueryFilter ; <nl> + import org . apache . cassandra . net . IAsyncResult ; <nl> + import org . apache . cassandra . net . MessageIn ; <nl> + import org . apache . cassandra . net . MessageOut ; <nl> + import org . apache . cassandra . net . MessagingService ; <nl> + import org . apache . cassandra . utils . CloseableIterator ; <nl> + import org . apache . cassandra . utils . FBUtilities ; <nl> + import org . apache . cassandra . utils . IFilter ; <nl> + <nl> + public class RowDataResolver extends AbstractRowResolver <nl> + { <nl> + private int maxLiveCount = 0 ; <nl> + public List < IAsyncResult > repairResults = Collections . emptyList ( ) ; <nl> + private final IDiskAtomFilter filter ; <nl> + <nl> + public RowDataResolver ( String table , ByteBuffer key , IDiskAtomFilter qFilter ) <nl> + { <nl> + super ( key , table ) ; <nl> + this . filter = qFilter ; <nl> + } <nl> + <nl> + / * <nl> + * This method handles the following scenario : <nl> + * <nl> + * there was a mismatch on the initial read , so we redid the digest requests <nl> + * as full data reads . In this case we need to compute the most recent version <nl> + * of each column , and send diffs to out - of - date replicas . <nl> + * / <nl> + public Row resolve ( ) throws DigestMismatchException , IOException <nl> + { <nl> + if ( logger . isDebugEnabled ( ) ) <nl> + logger . debug ( " resolving " + replies . size ( ) + " responses " ) ; <nl> + long startTime = System . currentTimeMillis ( ) ; <nl> + <nl> + ColumnFamily resolved ; <nl> + if ( replies . size ( ) > 1 ) <nl> + { <nl> + List < ColumnFamily > versions = new ArrayList < ColumnFamily > ( replies . size ( ) ) ; <nl> + List < InetAddress > endpoints = new ArrayList < InetAddress > ( replies . size ( ) ) ; <nl> + <nl> + for ( MessageIn < ReadResponse > message : replies ) <nl> + { <nl> + ReadResponse response = message . payload ; <nl> + ColumnFamily cf = response . row ( ) . cf ; <nl> + assert ! response . isDigestQuery ( ) : " Received digest response to repair read from " + message . from ; <nl> + versions . add ( cf ) ; <nl> + endpoints . add ( message . from ) ; <nl> + <nl> + / / compute maxLiveCount to prevent short reads - - see https : / / issues . apache . org / jira / browse / CASSANDRA - 2643 <nl> + int liveCount = cf = = null ? 0 : filter . getLiveCount ( cf ) ; <nl> + if ( liveCount > maxLiveCount ) <nl> + maxLiveCount = liveCount ; <nl> + } <nl> + <nl> + resolved = resolveSuperset ( versions ) ; <nl> + if ( logger . isDebugEnabled ( ) ) <nl> + logger . debug ( " versions merged " ) ; <nl> + <nl> + / / send updates to any replica that was missing part of the full row <nl> + / / ( resolved can be null even if versions doesn ' t have all nulls because of the call to removeDeleted in resolveSuperSet ) <nl> + if ( resolved ! = null ) <nl> + repairResults = scheduleRepairs ( resolved , table , key , versions , endpoints ) ; <nl> + } <nl> + else <nl> + { <nl> + resolved = replies . iterator ( ) . next ( ) . payload . row ( ) . cf ; <nl> + } <nl> + <nl> + if ( logger . isDebugEnabled ( ) ) <nl> + logger . debug ( " resolve : " + ( System . currentTimeMillis ( ) - startTime ) + " ms . " ) ; <nl> + <nl> + return new Row ( key , resolved ) ; <nl> + } <nl> + <nl> + / * * <nl> + * For each row version , compare with resolved ( the superset of all row versions ) ; <nl> + * if it is missing anything , send a mutation to the endpoint it come from . <nl> + * / <nl> + public static List < IAsyncResult > scheduleRepairs ( ColumnFamily resolved , String table , DecoratedKey key , List < ColumnFamily > versions , List < InetAddress > endpoints ) <nl> + { <nl> + List < IAsyncResult > results = new ArrayList < IAsyncResult > ( versions . size ( ) ) ; <nl> + <nl> + for ( int i = 0 ; i < versions . size ( ) ; i + + ) <nl> + { <nl> + ColumnFamily diffCf = ColumnFamily . diff ( versions . get ( i ) , resolved ) ; <nl> + if ( diffCf = = null ) / / no repair needs to happen <nl> + continue ; <nl> + <nl> + / / create and send the row mutation message based on the diff <nl> + RowMutation rowMutation = new RowMutation ( table , key . key ) ; <nl> + rowMutation . add ( diffCf ) ; <nl> + MessageOut repairMessage ; <nl> + / / use a separate verb here because we don ' t want these to be get the white glove hint - <nl> + / / on - timeout behavior that a " real " mutation gets <nl> + repairMessage = rowMutation . createMessage ( MessagingService . Verb . READ _ REPAIR ) ; <nl> + results . add ( MessagingService . instance ( ) . sendRR ( repairMessage , endpoints . get ( i ) ) ) ; <nl> + } <nl> + <nl> + return results ; <nl> + } <nl> + <nl> + static ColumnFamily resolveSuperset ( Iterable < ColumnFamily > versions ) <nl> + { <nl> + assert Iterables . size ( versions ) > 0 ; <nl> + <nl> + ColumnFamily resolved = null ; <nl> + for ( ColumnFamily cf : versions ) <nl> + { <nl> + if ( cf = = null ) <nl> + continue ; <nl> + <nl> + if ( resolved = = null ) <nl> + resolved = cf . cloneMeShallow ( ) ; <nl> + else <nl> + resolved . delete ( cf ) ; <nl> + } <nl> + if ( resolved = = null ) <nl> + return null ; <nl> + <nl> + / / mimic the collectCollatedColumn + removeDeleted path that getColumnFamily takes . <nl> + / / this will handle removing columns and subcolumns that are supressed by a row or <nl> + / / supercolumn tombstone . <nl> + QueryFilter filter = new QueryFilter ( null , new QueryPath ( resolved . metadata ( ) . cfName ) , new IdentityQueryFilter ( ) ) ; <nl> + List < CloseableIterator < IColumn > > iters = new ArrayList < CloseableIterator < IColumn > > ( ) ; <nl> + for ( ColumnFamily version : versions ) <nl> + { <nl> + if ( version = = null ) <nl> + continue ; <nl> + iters . add ( FBUtilities . closeableIterator ( version . iterator ( ) ) ) ; <nl> + } <nl> + filter . collateColumns ( resolved , iters , Integer . MIN _ VALUE ) ; <nl> + return ColumnFamilyStore . removeDeleted ( resolved , Integer . MIN _ VALUE ) ; <nl> + } <nl> + <nl> + public Row getData ( ) throws IOException <nl> + { <nl> + return replies . iterator ( ) . next ( ) . payload . row ( ) ; <nl> + } <nl> + <nl> + public boolean isDataPresent ( ) <nl> + { <nl> + return ! replies . isEmpty ( ) ; <nl> + } <nl> + <nl> + public int getMaxLiveCount ( ) <nl> + { <nl> + return maxLiveCount ; <nl> + } <nl> + } <nl> diff - - git a / src / java / org / apache / cassandra / service / RowDigestResolver . java b / src / java / org / apache / cassandra / service / RowDigestResolver . java <nl> index e0e262b . . eeccbeb 100644 <nl> - - - a / src / java / org / apache / cassandra / service / RowDigestResolver . java <nl> + + + b / src / java / org / apache / cassandra / service / RowDigestResolver . java <nl> @ @ - 95 , 7 + 95 , 7 @ @ public class RowDigestResolver extends AbstractRowResolver <nl> / / with the data response . If there is a mismatch then throw an exception so that read repair can happen . <nl> / / <nl> / / It ' s important to note that we do not consider the possibility of multiple data responses - - <nl> - / / that can only happen when we ' re doing the repair post - mismatch , and will be handled by RowRepairResolver . <nl> + / / that can only happen when we ' re doing the repair post - mismatch , and will be handled by RowDataResolver . <nl> if ( digest ! = null ) <nl> { <nl> ByteBuffer digest2 = ColumnFamily . digest ( data ) ; <nl> diff - - git a / src / java / org / apache / cassandra / service / RowRepairResolver . java b / src / java / org / apache / cassandra / service / RowRepairResolver . java <nl> deleted file mode 100644 <nl> index 21cf5ab . . 0000000 <nl> - - - a / src / java / org / apache / cassandra / service / RowRepairResolver . java <nl> + + + / dev / null <nl> @ @ - 1 , 182 + 0 , 0 @ @ <nl> - / * <nl> - * Licensed to the Apache Software Foundation ( ASF ) under one <nl> - * or more contributor license agreements . See the NOTICE file <nl> - * distributed with this work for additional information <nl> - * regarding copyright ownership . The ASF licenses this file <nl> - * to you under the Apache License , Version 2 . 0 ( the <nl> - * " License " ) ; you may not use this file except in compliance <nl> - * with the License . You may obtain a copy of the License at <nl> - * <nl> - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> - * <nl> - * Unless required by applicable law or agreed to in writing , software <nl> - * distributed under the License is distributed on an " AS IS " BASIS , <nl> - * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> - * See the License for the specific language governing permissions and <nl> - * limitations under the License . <nl> - * / <nl> - package org . apache . cassandra . service ; <nl> - <nl> - import java . io . IOException ; <nl> - import java . net . InetAddress ; <nl> - import java . nio . ByteBuffer ; <nl> - import java . util . ArrayList ; <nl> - import java . util . Collections ; <nl> - import java . util . List ; <nl> - <nl> - import com . google . common . collect . Iterables ; <nl> - <nl> - import org . apache . cassandra . db . * ; <nl> - import org . apache . cassandra . db . columniterator . IdentityQueryFilter ; <nl> - import org . apache . cassandra . db . filter . IDiskAtomFilter ; <nl> - import org . apache . cassandra . db . filter . QueryFilter ; <nl> - import org . apache . cassandra . db . filter . QueryPath ; <nl> - import org . apache . cassandra . db . filter . SliceQueryFilter ; <nl> - import org . apache . cassandra . net . IAsyncResult ; <nl> - import org . apache . cassandra . net . MessageIn ; <nl> - import org . apache . cassandra . net . MessageOut ; <nl> - import org . apache . cassandra . net . MessagingService ; <nl> - import org . apache . cassandra . utils . CloseableIterator ; <nl> - import org . apache . cassandra . utils . FBUtilities ; <nl> - import org . apache . cassandra . utils . IFilter ; <nl> - <nl> - public class RowRepairResolver extends AbstractRowResolver <nl> - { <nl> - private int maxLiveCount = 0 ; <nl> - public List < IAsyncResult > repairResults = Collections . emptyList ( ) ; <nl> - private final IDiskAtomFilter filter ; <nl> - <nl> - public RowRepairResolver ( String table , ByteBuffer key , IDiskAtomFilter qFilter ) <nl> - { <nl> - super ( key , table ) ; <nl> - this . filter = qFilter ; <nl> - } <nl> - <nl> - / * <nl> - * This method handles the following scenario : <nl> - * <nl> - * there was a mismatch on the initial read , so we redid the digest requests <nl> - * as full data reads . In this case we need to compute the most recent version <nl> - * of each column , and send diffs to out - of - date replicas . <nl> - * / <nl> - public Row resolve ( ) throws DigestMismatchException , IOException <nl> - { <nl> - if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " resolving " + replies . size ( ) + " responses " ) ; <nl> - long startTime = System . currentTimeMillis ( ) ; <nl> - <nl> - ColumnFamily resolved ; <nl> - if ( replies . size ( ) > 1 ) <nl> - { <nl> - List < ColumnFamily > versions = new ArrayList < ColumnFamily > ( replies . size ( ) ) ; <nl> - List < InetAddress > endpoints = new ArrayList < InetAddress > ( replies . size ( ) ) ; <nl> - <nl> - for ( MessageIn < ReadResponse > message : replies ) <nl> - { <nl> - ReadResponse response = message . payload ; <nl> - ColumnFamily cf = response . row ( ) . cf ; <nl> - assert ! response . isDigestQuery ( ) : " Received digest response to repair read from " + message . from ; <nl> - versions . add ( cf ) ; <nl> - endpoints . add ( message . from ) ; <nl> - <nl> - / / compute maxLiveCount to prevent short reads - - see https : / / issues . apache . org / jira / browse / CASSANDRA - 2643 <nl> - int liveCount = cf = = null ? 0 : filter . getLiveCount ( cf ) ; <nl> - if ( liveCount > maxLiveCount ) <nl> - maxLiveCount = liveCount ; <nl> - } <nl> - <nl> - resolved = resolveSuperset ( versions ) ; <nl> - if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " versions merged " ) ; <nl> - <nl> - / / send updates to any replica that was missing part of the full row <nl> - / / ( resolved can be null even if versions doesn ' t have all nulls because of the call to removeDeleted in resolveSuperSet ) <nl> - if ( resolved ! = null ) <nl> - repairResults = scheduleRepairs ( resolved , table , key , versions , endpoints ) ; <nl> - } <nl> - else <nl> - { <nl> - resolved = replies . iterator ( ) . next ( ) . payload . row ( ) . cf ; <nl> - } <nl> - <nl> - if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " resolve : " + ( System . currentTimeMillis ( ) - startTime ) + " ms . " ) ; <nl> - <nl> - return new Row ( key , resolved ) ; <nl> - } <nl> - <nl> - / * * <nl> - * For each row version , compare with resolved ( the superset of all row versions ) ; <nl> - * if it is missing anything , send a mutation to the endpoint it come from . <nl> - * / <nl> - public static List < IAsyncResult > scheduleRepairs ( ColumnFamily resolved , String table , DecoratedKey key , List < ColumnFamily > versions , List < InetAddress > endpoints ) <nl> - { <nl> - List < IAsyncResult > results = new ArrayList < IAsyncResult > ( versions . size ( ) ) ; <nl> - <nl> - for ( int i = 0 ; i < versions . size ( ) ; i + + ) <nl> - { <nl> - ColumnFamily diffCf = ColumnFamily . diff ( versions . get ( i ) , resolved ) ; <nl> - if ( diffCf = = null ) / / no repair needs to happen <nl> - continue ; <nl> - <nl> - / / create and send the row mutation message based on the diff <nl> - RowMutation rowMutation = new RowMutation ( table , key . key ) ; <nl> - rowMutation . add ( diffCf ) ; <nl> - MessageOut repairMessage ; <nl> - / / use a separate verb here because we don ' t want these to be get the white glove hint - <nl> - / / on - timeout behavior that a " real " mutation gets <nl> - repairMessage = rowMutation . createMessage ( MessagingService . Verb . READ _ REPAIR ) ; <nl> - results . add ( MessagingService . instance ( ) . sendRR ( repairMessage , endpoints . get ( i ) ) ) ; <nl> - } <nl> - <nl> - return results ; <nl> - } <nl> - <nl> - static ColumnFamily resolveSuperset ( Iterable < ColumnFamily > versions ) <nl> - { <nl> - assert Iterables . size ( versions ) > 0 ; <nl> - <nl> - ColumnFamily resolved = null ; <nl> - for ( ColumnFamily cf : versions ) <nl> - { <nl> - if ( cf = = null ) <nl> - continue ; <nl> - <nl> - if ( resolved = = null ) <nl> - resolved = cf . cloneMeShallow ( ) ; <nl> - else <nl> - resolved . delete ( cf ) ; <nl> - } <nl> - if ( resolved = = null ) <nl> - return null ; <nl> - <nl> - / / mimic the collectCollatedColumn + removeDeleted path that getColumnFamily takes . <nl> - / / this will handle removing columns and subcolumns that are supressed by a row or <nl> - / / supercolumn tombstone . <nl> - QueryFilter filter = new QueryFilter ( null , new QueryPath ( resolved . metadata ( ) . cfName ) , new IdentityQueryFilter ( ) ) ; <nl> - List < CloseableIterator < IColumn > > iters = new ArrayList < CloseableIterator < IColumn > > ( ) ; <nl> - for ( ColumnFamily version : versions ) <nl> - { <nl> - if ( version = = null ) <nl> - continue ; <nl> - iters . add ( FBUtilities . closeableIterator ( version . iterator ( ) ) ) ; <nl> - } <nl> - filter . collateColumns ( resolved , iters , Integer . MIN _ VALUE ) ; <nl> - return ColumnFamilyStore . removeDeleted ( resolved , Integer . MIN _ VALUE ) ; <nl> - } <nl> - <nl> - public Row getData ( ) throws IOException <nl> - { <nl> - throw new UnsupportedOperationException ( ) ; <nl> - } <nl> - <nl> - public boolean isDataPresent ( ) <nl> - { <nl> - throw new UnsupportedOperationException ( ) ; <nl> - } <nl> - <nl> - public int getMaxLiveCount ( ) <nl> - { <nl> - return maxLiveCount ; <nl> - } <nl> - } <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageProxy . java b / src / java / org / apache / cassandra / service / StorageProxy . java <nl> index fe427af . . 0fb7ec4 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageProxy . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageProxy . java <nl> @ @ - 923 , 7 + 923 , 7 @ @ public class StorageProxy implements StorageProxyMBean <nl> <nl> / / read results and make a second pass for any digest mismatches <nl> List < ReadCommand > repairCommands = null ; <nl> - List < RepairCallback > repairResponseHandlers = null ; <nl> + List < ReadCallback < ReadResponse , Row > > repairResponseHandlers = null ; <nl> for ( int i = 0 ; i < commands . size ( ) ; i + + ) <nl> { <nl> ReadCallback < ReadResponse , Row > handler = readCallbacks [ i ] ; <nl> @ @ - 946 , 13 + 946 , 14 @ @ public class StorageProxy implements StorageProxyMBean <nl> catch ( DigestMismatchException ex ) <nl> { <nl> logger . debug ( " Digest mismatch : { } " , ex . toString ( ) ) ; <nl> - RowRepairResolver resolver = new RowRepairResolver ( command . table , command . key , command . filter ( ) ) ; <nl> - RepairCallback repairHandler = new RepairCallback ( resolver , handler . endpoints ) ; <nl> + / / Do a full data read to resolve the correct response ( and repair node that need be ) <nl> + RowDataResolver resolver = new RowDataResolver ( command . table , command . key , command . filter ( ) ) ; <nl> + ReadCallback < ReadResponse , Row > repairHandler = handler . withNewResolver ( resolver ) ; <nl> <nl> if ( repairCommands = = null ) <nl> { <nl> repairCommands = new ArrayList < ReadCommand > ( ) ; <nl> - repairResponseHandlers = new ArrayList < RepairCallback > ( ) ; <nl> + repairResponseHandlers = new ArrayList < ReadCallback < ReadResponse , Row > > ( ) ; <nl> } <nl> repairCommands . add ( command ) ; <nl> repairResponseHandlers . add ( repairHandler ) ; <nl> @ @ - 974 , 7 + 975 , 7 @ @ public class StorageProxy implements StorageProxyMBean <nl> for ( int i = 0 ; i < repairCommands . size ( ) ; i + + ) <nl> { <nl> ReadCommand command = repairCommands . get ( i ) ; <nl> - RepairCallback handler = repairResponseHandlers . get ( i ) ; <nl> + ReadCallback < ReadResponse , Row > handler = repairResponseHandlers . get ( i ) ; <nl> <nl> Row row ; <nl> try <nl> @ @ - 986 , 11 + 987 , 12 @ @ public class StorageProxy implements StorageProxyMBean <nl> throw new AssertionError ( e ) ; / / full data requested from each node here , no digests should be sent <nl> } <nl> <nl> + RowDataResolver resolver = ( RowDataResolver ) handler . resolver ; <nl> try <nl> { <nl> / / wait for the repair writes to be acknowledged , to minimize impact on any replica that ' s <nl> / / behind on writes in case the out - of - sync row is read multiple times in quick succession <nl> - FBUtilities . waitOnFutures ( handler . resolver . repairResults , DatabaseDescriptor . getWriteRpcTimeout ( ) ) ; <nl> + FBUtilities . waitOnFutures ( resolver . repairResults , DatabaseDescriptor . getWriteRpcTimeout ( ) ) ; <nl> } <nl> catch ( TimeoutException e ) <nl> { <nl> @ @ - 999 , 7 + 1001 , 7 @ @ public class StorageProxy implements StorageProxyMBean <nl> } <nl> <nl> / / retry any potential short reads <nl> - ReadCommand retryCommand = command . maybeGenerateRetryCommand ( handler , row ) ; <nl> + ReadCommand retryCommand = command . maybeGenerateRetryCommand ( resolver , row ) ; <nl> if ( retryCommand ! = null ) <nl> { <nl> logger . debug ( " Issuing retry for read command " ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / service / RowResolverTest . java b / test / unit / org / apache / cassandra / service / RowResolverTest . java <nl> index 3c530f1 . . 2cc7860 100644 <nl> - - - a / test / unit / org / apache / cassandra / service / RowResolverTest . java <nl> + + + b / test / unit / org / apache / cassandra / service / RowResolverTest . java <nl> @ @ - 46 , 7 + 46 , 7 @ @ public class RowResolverTest extends SchemaLoader <nl> ColumnFamily cf2 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; <nl> cf2 . addColumn ( column ( " c1 " , " v2 " , 1 ) ) ; <nl> <nl> - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; <nl> + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; <nl> assertColumns ( resolved , " c1 " ) ; <nl> assertColumns ( ColumnFamily . diff ( cf1 , resolved ) , " c1 " ) ; <nl> assertNull ( ColumnFamily . diff ( cf2 , resolved ) ) ; <nl> @ @ - 61 , 7 + 61 , 7 @ @ public class RowResolverTest extends SchemaLoader <nl> ColumnFamily cf2 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; <nl> cf2 . addColumn ( column ( " c2 " , " v2 " , 1 ) ) ; <nl> <nl> - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; <nl> + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; <nl> assertColumns ( resolved , " c1 " , " c2 " ) ; <nl> assertColumns ( ColumnFamily . diff ( cf1 , resolved ) , " c2 " ) ; <nl> assertColumns ( ColumnFamily . diff ( cf2 , resolved ) , " c1 " ) ; <nl> @ @ - 73 , 7 + 73 , 7 @ @ public class RowResolverTest extends SchemaLoader <nl> ColumnFamily cf2 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; <nl> cf2 . addColumn ( column ( " c2 " , " v2 " , 1 ) ) ; <nl> <nl> - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( null , cf2 ) ) ; <nl> + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( null , cf2 ) ) ; <nl> assertColumns ( resolved , " c2 " ) ; <nl> assertColumns ( ColumnFamily . diff ( null , resolved ) , " c2 " ) ; <nl> assertNull ( ColumnFamily . diff ( cf2 , resolved ) ) ; <nl> @ @ - 85 , 7 + 85 , 7 @ @ public class RowResolverTest extends SchemaLoader <nl> ColumnFamily cf1 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; <nl> cf1 . addColumn ( column ( " c1 " , " v1 " , 0 ) ) ; <nl> <nl> - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( cf1 , null ) ) ; <nl> + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( cf1 , null ) ) ; <nl> assertColumns ( resolved , " c1 " ) ; <nl> assertNull ( ColumnFamily . diff ( cf1 , resolved ) ) ; <nl> assertColumns ( ColumnFamily . diff ( null , resolved ) , " c1 " ) ; <nl> @ @ - 94 , 7 + 94 , 7 @ @ public class RowResolverTest extends SchemaLoader <nl> @ Test <nl> public void testResolveSupersetNullBoth ( ) <nl> { <nl> - assertNull ( RowRepairResolver . resolveSuperset ( Arrays . < ColumnFamily > asList ( null , null ) ) ) ; <nl> + assertNull ( RowDataResolver . resolveSuperset ( Arrays . < ColumnFamily > asList ( null , null ) ) ) ; <nl> } <nl> <nl> @ Test <nl> @ @ - 107 , 7 + 107 , 7 @ @ public class RowResolverTest extends SchemaLoader <nl> ColumnFamily cf2 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; <nl> cf2 . delete ( new DeletionInfo ( 1L , ( int ) ( System . currentTimeMillis ( ) / 1000 ) ) ) ; <nl> <nl> - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; <nl> + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; <nl> / / no columns in the cf <nl> assertColumns ( resolved ) ; <nl> assertTrue ( resolved . isMarkedForDelete ( ) ) ; <nl> @ @ - 119 , 7 + 119 , 7 @ @ public class RowResolverTest extends SchemaLoader <nl> ColumnFamily scf2 = ColumnFamily . create ( " Keyspace1 " , " Super1 " ) ; <nl> scf2 . delete ( new DeletionInfo ( 1L , ( int ) ( System . currentTimeMillis ( ) / 1000 ) ) ) ; <nl> <nl> - ColumnFamily superResolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 ) ) ; <nl> + ColumnFamily superResolved = RowDataResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 ) ) ; <nl> / / no columns in the cf <nl> assertColumns ( superResolved ) ; <nl> assertTrue ( superResolved . isMarkedForDelete ( ) ) ; <nl> @ @ - 138 , 7 + 138 , 7 @ @ public class RowResolverTest extends SchemaLoader <nl> ColumnFamily scf2 = ColumnFamily . create ( " Keyspace1 " , " Super1 " ) ; <nl> scf2 . delete ( new DeletionInfo ( 2L , ( int ) ( System . currentTimeMillis ( ) / 1000 ) ) ) ; <nl> <nl> - ColumnFamily superResolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 ) ) ; <nl> + ColumnFamily superResolved = RowDataResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 ) ) ; <nl> / / no columns in the cf <nl> assertColumns ( superResolved ) ; <nl> assertTrue ( superResolved . isMarkedForDelete ( ) ) ; <nl> @ @ - 165 , 7 + 165 , 7 @ @ public class RowResolverTest extends SchemaLoader <nl> ColumnFamily cf4 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; <nl> cf4 . delete ( new DeletionInfo ( 2L , ( int ) ( System . currentTimeMillis ( ) / 1000 ) ) ) ; <nl> <nl> - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 , cf3 , cf4 ) ) ; <nl> + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 , cf3 , cf4 ) ) ; <nl> / / will have deleted marker and one column <nl> assertColumns ( resolved , " two " ) ; <nl> assertColumn ( resolved , " two " , " B " , 3 ) ; <nl> @ @ - 188 , 7 + 188 , 7 @ @ public class RowResolverTest extends SchemaLoader <nl> ColumnFamily scf4 = ColumnFamily . create ( " Keyspace1 " , " Super1 " ) ; <nl> scf4 . delete ( new DeletionInfo ( 2L , ( int ) ( System . currentTimeMillis ( ) / 1000 ) ) ) ; <nl> <nl> - ColumnFamily superResolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 , scf3 , scf4 ) ) ; <nl> + ColumnFamily superResolved = RowDataResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 , scf3 , scf4 ) ) ; <nl> / / will have deleted marker and two super cols <nl> assertColumns ( superResolved , " super1 " , " super2 " ) ; <nl>

TEST DIFF:
diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index 8470078 . . 345d6c9 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 2259 , 13 + 2259 , 27 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 public Iterable < ColumnFamilyStore > getValidColumnFamilies ( boolean allowIndexes , boolean autoAddIndexes , String keyspaceName , String . . . cfNames ) throws IOException 
 { 
 Keyspace keyspace = getValidKeyspace ( keyspaceName ) ; 
 + Set < ColumnFamilyStore > valid = new HashSet < > ( ) ; 
 
 if ( cfNames . length = = 0 ) 
 + { 
 / / all stores are interesting 
 - return keyspace . getColumnFamilyStores ( ) ; 
 + for ( ColumnFamilyStore cfStore : keyspace . getColumnFamilyStores ( ) ) 
 + { 
 + valid . add ( cfStore ) ; 
 + if ( autoAddIndexes ) 
 + { 
 + for ( SecondaryIndex si : cfStore . indexManager . getIndexes ( ) ) 
 + { 
 + logger . info ( " adding secondary index { } to operation " , si . getIndexName ( ) ) ; 
 + valid . add ( si . getIndexCfs ( ) ) ; 
 + } 
 
 + } 
 + } 
 + return valid ; 
 + } 
 / / filter out interesting stores 
 - Set < ColumnFamilyStore > valid = new HashSet < ColumnFamilyStore > ( ) ; 
 for ( String cfName : cfNames ) 
 { 
 / / if the CF name is an index , just flush the CF that owns the index

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 2ec66c9 . . 95aad22 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 20 , 6 + 20 , 7 @ @ 
 * cqlsh : Add default limit to SELECT statements ( CASSANDRA - 4972 ) 
 * cqlsh : fix DESCRIBE for 1 . 1 cfs in CQL3 ( CASSANDRA - 5101 ) 
 * Correctly gossip with nodes > = 1 . 1 . 7 ( CASSANDRA - 5102 ) 
 + * Ensure CL guarantees on digest mismatch ( CASSANDRA - 5113 ) 
 Merged from 1 . 1 : 
 * Pig : correctly decode row keys in widerow mode ( CASSANDRA - 5098 ) 
 
 diff - - git a / src / java / org / apache / cassandra / db / ReadCommand . java b / src / java / org / apache / cassandra / db / ReadCommand . java 
 index f3494e5 . . 6c364cb 100644 
 - - - a / src / java / org / apache / cassandra / db / ReadCommand . java 
 + + + b / src / java / org / apache / cassandra / db / ReadCommand . java 
 @ @ - 32 , 7 + 32 , 7 @ @ import org . apache . cassandra . io . IVersionedSerializer ; 
 import org . apache . cassandra . net . MessageOut ; 
 import org . apache . cassandra . net . MessagingService ; 
 import org . apache . cassandra . service . IReadCommand ; 
 - import org . apache . cassandra . service . RepairCallback ; 
 + import org . apache . cassandra . service . RowDataResolver ; 
 import org . apache . cassandra . utils . IFilter ; 
 
 
 @ @ - 94 , 7 + 94 , 7 @ @ public abstract class ReadCommand implements IReadCommand 
 } 
 
 / / maybeGenerateRetryCommand is used to generate a retry for short reads 
 - public ReadCommand maybeGenerateRetryCommand ( RepairCallback handler , Row row ) 
 + public ReadCommand maybeGenerateRetryCommand ( RowDataResolver resolver , Row row ) 
 { 
 return null ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java 
 index d52826b . . 8a08a42 100644 
 - - - a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java 
 + + + b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java 
 @ @ - 30 , 7 + 30 , 7 @ @ import org . apache . cassandra . db . filter . QueryFilter ; 
 import org . apache . cassandra . db . filter . QueryPath ; 
 import org . apache . cassandra . db . filter . SliceQueryFilter ; 
 import org . apache . cassandra . io . IVersionedSerializer ; 
 - import org . apache . cassandra . service . RepairCallback ; 
 + import org . apache . cassandra . service . RowDataResolver ; 
 import org . apache . cassandra . service . StorageService ; 
 import org . apache . cassandra . thrift . ColumnParent ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 @ @ - 71 , 9 + 71 , 9 @ @ public class SliceFromReadCommand extends ReadCommand 
 } 
 
 @ Override 
 - public ReadCommand maybeGenerateRetryCommand ( RepairCallback handler , Row row ) 
 + public ReadCommand maybeGenerateRetryCommand ( RowDataResolver resolver , Row row ) 
 { 
 - int maxLiveColumns = handler . getMaxLiveCount ( ) ; 
 + int maxLiveColumns = resolver . getMaxLiveCount ( ) ; 
 
 int count = filter . count ; 
 assert maxLiveColumns < = count ; 
 diff - - git a / src / java / org / apache / cassandra / service / AsyncRepairCallback . java b / src / java / org / apache / cassandra / service / AsyncRepairCallback . java 
 index 675f61c . . 63b7df3 100644 
 - - - a / src / java / org / apache / cassandra / service / AsyncRepairCallback . java 
 + + + b / src / java / org / apache / cassandra / service / AsyncRepairCallback . java 
 @ @ - 28 , 11 + 28 , 11 @ @ import org . apache . cassandra . utils . WrappedRunnable ; 
 
 public class AsyncRepairCallback implements IAsyncCallback 
 { 
 - private final RowRepairResolver repairResolver ; 
 + private final RowDataResolver repairResolver ; 
 private final int blockfor ; 
 protected final AtomicInteger received = new AtomicInteger ( 0 ) ; 
 
 - public AsyncRepairCallback ( RowRepairResolver repairResolver , int blockfor ) 
 + public AsyncRepairCallback ( RowDataResolver repairResolver , int blockfor ) 
 { 
 this . repairResolver = repairResolver ; 
 this . blockfor = blockfor ; 
 diff - - git a / src / java / org / apache / cassandra / service / DatacenterReadCallback . java b / src / java / org / apache / cassandra / service / DatacenterReadCallback . java 
 index d125553 . . e1ae652 100644 
 - - - a / src / java / org / apache / cassandra / service / DatacenterReadCallback . java 
 + + + b / src / java / org / apache / cassandra / service / DatacenterReadCallback . java 
 @ @ - 46 , 11 + 46 , 22 @ @ public class DatacenterReadCallback < TMessage , TResolved > extends ReadCallback < TM 
 } 
 } ; 
 
 - public DatacenterReadCallback ( IResponseResolver resolver , ConsistencyLevel consistencyLevel , IReadCommand command , List < InetAddress > endpoints ) 
 + public DatacenterReadCallback ( IResponseResolver < TMessage , TResolved > resolver , ConsistencyLevel consistencyLevel , IReadCommand command , List < InetAddress > endpoints ) 
 { 
 super ( resolver , consistencyLevel , command , endpoints ) ; 
 } 
 
 + protected DatacenterReadCallback ( IResponseResolver < TMessage , TResolved > resolver , ConsistencyLevel consistencyLevel , int blockfor , IReadCommand command , List < InetAddress > endpoints ) 
 + { 
 + super ( resolver , consistencyLevel , blockfor , command , endpoints ) ; 
 + } 
 + 
 + @ Override 
 + public ReadCallback < TMessage , TResolved > withNewResolver ( IResponseResolver < TMessage , TResolved > newResolver ) 
 + { 
 + return new DatacenterReadCallback ( newResolver , consistencyLevel , blockfor , command , endpoints ) ; 
 + } 
 + 
 @ Override 
 protected void sortForConsistencyLevel ( List < InetAddress > endpoints ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / service / RangeSliceResponseResolver . java b / src / java / org / apache / cassandra / service / RangeSliceResponseResolver . java 
 index 0d24fbf . . 1dfd01e 100644 
 - - - a / src / java / org / apache / cassandra / service / RangeSliceResponseResolver . java 
 + + + b / src / java / org / apache / cassandra / service / RangeSliceResponseResolver . java 
 @ @ - 138 , 7 + 138 , 7 @ @ public class RangeSliceResponseResolver implements IResponseResolver < RangeSliceR 
 protected Row getReduced ( ) 
 { 
 ColumnFamily resolved = versions . size ( ) > 1 
 - ? RowRepairResolver . resolveSuperset ( versions ) 
 + ? RowDataResolver . resolveSuperset ( versions ) 
 : versions . get ( 0 ) ; 
 if ( versions . size ( ) < sources . size ( ) ) 
 { 
 @ @ - 154 , 7 + 154 , 7 @ @ public class RangeSliceResponseResolver implements IResponseResolver < RangeSliceR 
 } 
 / / resolved can be null even if versions doesn ' t have all nulls because of the call to removeDeleted in resolveSuperSet 
 if ( resolved ! = null ) 
 - repairResults . addAll ( RowRepairResolver . scheduleRepairs ( resolved , table , key , versions , versionSources ) ) ; 
 + repairResults . addAll ( RowDataResolver . scheduleRepairs ( resolved , table , key , versions , versionSources ) ) ; 
 versions . clear ( ) ; 
 versionSources . clear ( ) ; 
 return new Row ( key , resolved ) ; 
 diff - - git a / src / java / org / apache / cassandra / service / ReadCallback . java b / src / java / org / apache / cassandra / service / ReadCallback . java 
 index 8df2e10 . . e12859a 100644 
 - - - a / src / java / org / apache / cassandra / service / ReadCallback . java 
 + + + b / src / java / org / apache / cassandra / service / ReadCallback . java 
 @ @ - 60 , 7 + 60 , 7 @ @ public class ReadCallback < TMessage , TResolved > implements IAsyncCallback < TMessag 
 private final long startTime ; 
 protected final int blockfor ; 
 final List < InetAddress > endpoints ; 
 - private final IReadCommand command ; 
 + protected final IReadCommand command ; 
 protected final ConsistencyLevel consistencyLevel ; 
 protected final AtomicInteger received = new AtomicInteger ( 0 ) ; 
 
 @ @ - 75 , 11 + 75 , 26 @ @ public class ReadCallback < TMessage , TResolved > implements IAsyncCallback < TMessag 
 this . startTime = System . currentTimeMillis ( ) ; 
 this . consistencyLevel = consistencyLevel ; 
 sortForConsistencyLevel ( endpoints ) ; 
 - this . endpoints = resolver instanceof RowRepairResolver ? endpoints : filterEndpoints ( endpoints ) ; 
 + this . endpoints = filterEndpoints ( endpoints ) ; 
 if ( logger . isTraceEnabled ( ) ) 
 logger . trace ( String . format ( " Blockfor is % s ; setting up requests to % s " , blockfor , StringUtils . join ( this . endpoints , " , " ) ) ) ; 
 } 
 
 + protected ReadCallback ( IResponseResolver < TMessage , TResolved > resolver , ConsistencyLevel consistencyLevel , int blockfor , IReadCommand command , List < InetAddress > endpoints ) 
 + { 
 + this . command = command ; 
 + this . blockfor = blockfor ; 
 + this . consistencyLevel = consistencyLevel ; 
 + this . resolver = resolver ; 
 + this . startTime = System . currentTimeMillis ( ) ; 
 + this . endpoints = endpoints ; 
 + } 
 + 
 + public ReadCallback < TMessage , TResolved > withNewResolver ( IResponseResolver < TMessage , TResolved > newResolver ) 
 + { 
 + return new ReadCallback ( newResolver , consistencyLevel , blockfor , command , endpoints ) ; 
 + } 
 + 
 / * * 
 * Endpoints is already restricted to live replicas , sorted by snitch preference . This is a hook for 
 * DatacenterReadCallback to move local - DC replicas to the front of the list . We need this both 
 @ @ - 209 , 17 + 224 , 22 @ @ public class ReadCallback < TMessage , TResolved > implements IAsyncCallback < TMessag 
 { 
 protected void runMayThrow ( ) throws IOException 
 { 
 + / / If the resolver is a RowDigestResolver , we need to do a full data read if there is a mismatch . 
 + / / Otherwise , resolve will send the repairs directly if needs be ( and in that case we should never 
 + / / get a digest mismatch ) 
 try 
 { 
 resolver . resolve ( ) ; 
 } 
 catch ( DigestMismatchException e ) 
 { 
 + assert resolver instanceof RowDigestResolver ; 
 + 
 if ( logger . isDebugEnabled ( ) ) 
 logger . debug ( " Digest mismatch : " , e ) ; 
 
 ReadCommand readCommand = ( ReadCommand ) command ; 
 - final RowRepairResolver repairResolver = new RowRepairResolver ( readCommand . table , readCommand . key , readCommand . filter ( ) ) ; 
 + final RowDataResolver repairResolver = new RowDataResolver ( readCommand . table , readCommand . key , readCommand . filter ( ) ) ; 
 IAsyncCallback repairHandler = new AsyncRepairCallback ( repairResolver , endpoints . size ( ) ) ; 
 
 MessageOut < ReadCommand > message = ( ( ReadCommand ) command ) . createMessage ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / service / RepairCallback . java b / src / java / org / apache / cassandra / service / RepairCallback . java 
 deleted file mode 100644 
 index 9388328 . . 0000000 
 - - - a / src / java / org / apache / cassandra / service / RepairCallback . java 
 + + + / dev / null 
 @ @ - 1 , 86 + 0 , 0 @ @ 
 - / * 
 - * Licensed to the Apache Software Foundation ( ASF ) under one 
 - * or more contributor license agreements . See the NOTICE file 
 - * distributed with this work for additional information 
 - * regarding copyright ownership . The ASF licenses this file 
 - * to you under the Apache License , Version 2 . 0 ( the 
 - * " License " ) ; you may not use this file except in compliance 
 - * with the License . You may obtain a copy of the License at 
 - * 
 - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 - * 
 - * Unless required by applicable law or agreed to in writing , software 
 - * distributed under the License is distributed on an " AS IS " BASIS , 
 - * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 - * See the License for the specific language governing permissions and 
 - * limitations under the License . 
 - * / 
 - package org . apache . cassandra . service ; 
 - 
 - import java . io . IOException ; 
 - import java . net . InetAddress ; 
 - import java . util . List ; 
 - import java . util . concurrent . TimeUnit ; 
 - import java . util . concurrent . atomic . AtomicInteger ; 
 - 
 - import org . apache . cassandra . config . DatabaseDescriptor ; 
 - import org . apache . cassandra . db . Row ; 
 - import org . apache . cassandra . net . IAsyncCallback ; 
 - import org . apache . cassandra . net . MessageIn ; 
 - import org . apache . cassandra . utils . SimpleCondition ; 
 - 
 - public class RepairCallback implements IAsyncCallback 
 - { 
 - public final RowRepairResolver resolver ; 
 - private final List < InetAddress > endpoints ; 
 - private final SimpleCondition condition = new SimpleCondition ( ) ; 
 - private final long startTime ; 
 - protected final AtomicInteger received = new AtomicInteger ( 0 ) ; 
 - 
 - / * * 
 - * The main difference between this and ReadCallback is , ReadCallback has a ConsistencyLevel 
 - * it needs to achieve . Repair on the other hand is happy to repair whoever replies within the timeout . 
 - * 
 - * ( The other main difference of course is , this is only created once we know we have a digest 
 - * mismatch , and we ' re going to do full - data reads from everyone - - that is , this is the final 
 - * stage in the read process . ) 
 - * / 
 - public RepairCallback ( RowRepairResolver resolver , List < InetAddress > endpoints ) 
 - { 
 - this . resolver = resolver ; 
 - this . endpoints = endpoints ; 
 - this . startTime = System . currentTimeMillis ( ) ; 
 - } 
 - 
 - public Row get ( ) throws DigestMismatchException , IOException 
 - { 
 - long timeout = DatabaseDescriptor . getWriteRpcTimeout ( ) - ( System . currentTimeMillis ( ) - startTime ) ; 
 - try 
 - { 
 - condition . await ( timeout , TimeUnit . MILLISECONDS ) ; 
 - } 
 - catch ( InterruptedException ex ) 
 - { 
 - throw new AssertionError ( ex ) ; 
 - } 
 - 
 - return received . get ( ) > 1 ? resolver . resolve ( ) : null ; 
 - } 
 - 
 - public void response ( MessageIn message ) 
 - { 
 - resolver . preprocess ( message ) ; 
 - if ( received . incrementAndGet ( ) = = endpoints . size ( ) ) 
 - condition . signal ( ) ; 
 - } 
 - 
 - public boolean isLatencyForSnitch ( ) 
 - { 
 - return true ; 
 - } 
 - 
 - public int getMaxLiveCount ( ) 
 - { 
 - return resolver . getMaxLiveCount ( ) ; 
 - } 
 - } 
 diff - - git a / src / java / org / apache / cassandra / service / RowDataResolver . java b / src / java / org / apache / cassandra / service / RowDataResolver . java 
 new file mode 100644 
 index 0000000 . . 5545293 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / service / RowDataResolver . java 
 @ @ - 0 , 0 + 1 , 182 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , software 
 + * distributed under the License is distributed on an " AS IS " BASIS , 
 + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + * See the License for the specific language governing permissions and 
 + * limitations under the License . 
 + * / 
 + package org . apache . cassandra . service ; 
 + 
 + import java . io . IOException ; 
 + import java . net . InetAddress ; 
 + import java . nio . ByteBuffer ; 
 + import java . util . ArrayList ; 
 + import java . util . Collections ; 
 + import java . util . List ; 
 + 
 + import com . google . common . collect . Iterables ; 
 + 
 + import org . apache . cassandra . db . * ; 
 + import org . apache . cassandra . db . columniterator . IdentityQueryFilter ; 
 + import org . apache . cassandra . db . filter . IDiskAtomFilter ; 
 + import org . apache . cassandra . db . filter . QueryFilter ; 
 + import org . apache . cassandra . db . filter . QueryPath ; 
 + import org . apache . cassandra . db . filter . SliceQueryFilter ; 
 + import org . apache . cassandra . net . IAsyncResult ; 
 + import org . apache . cassandra . net . MessageIn ; 
 + import org . apache . cassandra . net . MessageOut ; 
 + import org . apache . cassandra . net . MessagingService ; 
 + import org . apache . cassandra . utils . CloseableIterator ; 
 + import org . apache . cassandra . utils . FBUtilities ; 
 + import org . apache . cassandra . utils . IFilter ; 
 + 
 + public class RowDataResolver extends AbstractRowResolver 
 + { 
 + private int maxLiveCount = 0 ; 
 + public List < IAsyncResult > repairResults = Collections . emptyList ( ) ; 
 + private final IDiskAtomFilter filter ; 
 + 
 + public RowDataResolver ( String table , ByteBuffer key , IDiskAtomFilter qFilter ) 
 + { 
 + super ( key , table ) ; 
 + this . filter = qFilter ; 
 + } 
 + 
 + / * 
 + * This method handles the following scenario : 
 + * 
 + * there was a mismatch on the initial read , so we redid the digest requests 
 + * as full data reads . In this case we need to compute the most recent version 
 + * of each column , and send diffs to out - of - date replicas . 
 + * / 
 + public Row resolve ( ) throws DigestMismatchException , IOException 
 + { 
 + if ( logger . isDebugEnabled ( ) ) 
 + logger . debug ( " resolving " + replies . size ( ) + " responses " ) ; 
 + long startTime = System . currentTimeMillis ( ) ; 
 + 
 + ColumnFamily resolved ; 
 + if ( replies . size ( ) > 1 ) 
 + { 
 + List < ColumnFamily > versions = new ArrayList < ColumnFamily > ( replies . size ( ) ) ; 
 + List < InetAddress > endpoints = new ArrayList < InetAddress > ( replies . size ( ) ) ; 
 + 
 + for ( MessageIn < ReadResponse > message : replies ) 
 + { 
 + ReadResponse response = message . payload ; 
 + ColumnFamily cf = response . row ( ) . cf ; 
 + assert ! response . isDigestQuery ( ) : " Received digest response to repair read from " + message . from ; 
 + versions . add ( cf ) ; 
 + endpoints . add ( message . from ) ; 
 + 
 + / / compute maxLiveCount to prevent short reads - - see https : / / issues . apache . org / jira / browse / CASSANDRA - 2643 
 + int liveCount = cf = = null ? 0 : filter . getLiveCount ( cf ) ; 
 + if ( liveCount > maxLiveCount ) 
 + maxLiveCount = liveCount ; 
 + } 
 + 
 + resolved = resolveSuperset ( versions ) ; 
 + if ( logger . isDebugEnabled ( ) ) 
 + logger . debug ( " versions merged " ) ; 
 + 
 + / / send updates to any replica that was missing part of the full row 
 + / / ( resolved can be null even if versions doesn ' t have all nulls because of the call to removeDeleted in resolveSuperSet ) 
 + if ( resolved ! = null ) 
 + repairResults = scheduleRepairs ( resolved , table , key , versions , endpoints ) ; 
 + } 
 + else 
 + { 
 + resolved = replies . iterator ( ) . next ( ) . payload . row ( ) . cf ; 
 + } 
 + 
 + if ( logger . isDebugEnabled ( ) ) 
 + logger . debug ( " resolve : " + ( System . currentTimeMillis ( ) - startTime ) + " ms . " ) ; 
 + 
 + return new Row ( key , resolved ) ; 
 + } 
 + 
 + / * * 
 + * For each row version , compare with resolved ( the superset of all row versions ) ; 
 + * if it is missing anything , send a mutation to the endpoint it come from . 
 + * / 
 + public static List < IAsyncResult > scheduleRepairs ( ColumnFamily resolved , String table , DecoratedKey key , List < ColumnFamily > versions , List < InetAddress > endpoints ) 
 + { 
 + List < IAsyncResult > results = new ArrayList < IAsyncResult > ( versions . size ( ) ) ; 
 + 
 + for ( int i = 0 ; i < versions . size ( ) ; i + + ) 
 + { 
 + ColumnFamily diffCf = ColumnFamily . diff ( versions . get ( i ) , resolved ) ; 
 + if ( diffCf = = null ) / / no repair needs to happen 
 + continue ; 
 + 
 + / / create and send the row mutation message based on the diff 
 + RowMutation rowMutation = new RowMutation ( table , key . key ) ; 
 + rowMutation . add ( diffCf ) ; 
 + MessageOut repairMessage ; 
 + / / use a separate verb here because we don ' t want these to be get the white glove hint - 
 + / / on - timeout behavior that a " real " mutation gets 
 + repairMessage = rowMutation . createMessage ( MessagingService . Verb . READ _ REPAIR ) ; 
 + results . add ( MessagingService . instance ( ) . sendRR ( repairMessage , endpoints . get ( i ) ) ) ; 
 + } 
 + 
 + return results ; 
 + } 
 + 
 + static ColumnFamily resolveSuperset ( Iterable < ColumnFamily > versions ) 
 + { 
 + assert Iterables . size ( versions ) > 0 ; 
 + 
 + ColumnFamily resolved = null ; 
 + for ( ColumnFamily cf : versions ) 
 + { 
 + if ( cf = = null ) 
 + continue ; 
 + 
 + if ( resolved = = null ) 
 + resolved = cf . cloneMeShallow ( ) ; 
 + else 
 + resolved . delete ( cf ) ; 
 + } 
 + if ( resolved = = null ) 
 + return null ; 
 + 
 + / / mimic the collectCollatedColumn + removeDeleted path that getColumnFamily takes . 
 + / / this will handle removing columns and subcolumns that are supressed by a row or 
 + / / supercolumn tombstone . 
 + QueryFilter filter = new QueryFilter ( null , new QueryPath ( resolved . metadata ( ) . cfName ) , new IdentityQueryFilter ( ) ) ; 
 + List < CloseableIterator < IColumn > > iters = new ArrayList < CloseableIterator < IColumn > > ( ) ; 
 + for ( ColumnFamily version : versions ) 
 + { 
 + if ( version = = null ) 
 + continue ; 
 + iters . add ( FBUtilities . closeableIterator ( version . iterator ( ) ) ) ; 
 + } 
 + filter . collateColumns ( resolved , iters , Integer . MIN _ VALUE ) ; 
 + return ColumnFamilyStore . removeDeleted ( resolved , Integer . MIN _ VALUE ) ; 
 + } 
 + 
 + public Row getData ( ) throws IOException 
 + { 
 + return replies . iterator ( ) . next ( ) . payload . row ( ) ; 
 + } 
 + 
 + public boolean isDataPresent ( ) 
 + { 
 + return ! replies . isEmpty ( ) ; 
 + } 
 + 
 + public int getMaxLiveCount ( ) 
 + { 
 + return maxLiveCount ; 
 + } 
 + } 
 diff - - git a / src / java / org / apache / cassandra / service / RowDigestResolver . java b / src / java / org / apache / cassandra / service / RowDigestResolver . java 
 index e0e262b . . eeccbeb 100644 
 - - - a / src / java / org / apache / cassandra / service / RowDigestResolver . java 
 + + + b / src / java / org / apache / cassandra / service / RowDigestResolver . java 
 @ @ - 95 , 7 + 95 , 7 @ @ public class RowDigestResolver extends AbstractRowResolver 
 / / with the data response . If there is a mismatch then throw an exception so that read repair can happen . 
 / / 
 / / It ' s important to note that we do not consider the possibility of multiple data responses - - 
 - / / that can only happen when we ' re doing the repair post - mismatch , and will be handled by RowRepairResolver . 
 + / / that can only happen when we ' re doing the repair post - mismatch , and will be handled by RowDataResolver . 
 if ( digest ! = null ) 
 { 
 ByteBuffer digest2 = ColumnFamily . digest ( data ) ; 
 diff - - git a / src / java / org / apache / cassandra / service / RowRepairResolver . java b / src / java / org / apache / cassandra / service / RowRepairResolver . java 
 deleted file mode 100644 
 index 21cf5ab . . 0000000 
 - - - a / src / java / org / apache / cassandra / service / RowRepairResolver . java 
 + + + / dev / null 
 @ @ - 1 , 182 + 0 , 0 @ @ 
 - / * 
 - * Licensed to the Apache Software Foundation ( ASF ) under one 
 - * or more contributor license agreements . See the NOTICE file 
 - * distributed with this work for additional information 
 - * regarding copyright ownership . The ASF licenses this file 
 - * to you under the Apache License , Version 2 . 0 ( the 
 - * " License " ) ; you may not use this file except in compliance 
 - * with the License . You may obtain a copy of the License at 
 - * 
 - * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 - * 
 - * Unless required by applicable law or agreed to in writing , software 
 - * distributed under the License is distributed on an " AS IS " BASIS , 
 - * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 - * See the License for the specific language governing permissions and 
 - * limitations under the License . 
 - * / 
 - package org . apache . cassandra . service ; 
 - 
 - import java . io . IOException ; 
 - import java . net . InetAddress ; 
 - import java . nio . ByteBuffer ; 
 - import java . util . ArrayList ; 
 - import java . util . Collections ; 
 - import java . util . List ; 
 - 
 - import com . google . common . collect . Iterables ; 
 - 
 - import org . apache . cassandra . db . * ; 
 - import org . apache . cassandra . db . columniterator . IdentityQueryFilter ; 
 - import org . apache . cassandra . db . filter . IDiskAtomFilter ; 
 - import org . apache . cassandra . db . filter . QueryFilter ; 
 - import org . apache . cassandra . db . filter . QueryPath ; 
 - import org . apache . cassandra . db . filter . SliceQueryFilter ; 
 - import org . apache . cassandra . net . IAsyncResult ; 
 - import org . apache . cassandra . net . MessageIn ; 
 - import org . apache . cassandra . net . MessageOut ; 
 - import org . apache . cassandra . net . MessagingService ; 
 - import org . apache . cassandra . utils . CloseableIterator ; 
 - import org . apache . cassandra . utils . FBUtilities ; 
 - import org . apache . cassandra . utils . IFilter ; 
 - 
 - public class RowRepairResolver extends AbstractRowResolver 
 - { 
 - private int maxLiveCount = 0 ; 
 - public List < IAsyncResult > repairResults = Collections . emptyList ( ) ; 
 - private final IDiskAtomFilter filter ; 
 - 
 - public RowRepairResolver ( String table , ByteBuffer key , IDiskAtomFilter qFilter ) 
 - { 
 - super ( key , table ) ; 
 - this . filter = qFilter ; 
 - } 
 - 
 - / * 
 - * This method handles the following scenario : 
 - * 
 - * there was a mismatch on the initial read , so we redid the digest requests 
 - * as full data reads . In this case we need to compute the most recent version 
 - * of each column , and send diffs to out - of - date replicas . 
 - * / 
 - public Row resolve ( ) throws DigestMismatchException , IOException 
 - { 
 - if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " resolving " + replies . size ( ) + " responses " ) ; 
 - long startTime = System . currentTimeMillis ( ) ; 
 - 
 - ColumnFamily resolved ; 
 - if ( replies . size ( ) > 1 ) 
 - { 
 - List < ColumnFamily > versions = new ArrayList < ColumnFamily > ( replies . size ( ) ) ; 
 - List < InetAddress > endpoints = new ArrayList < InetAddress > ( replies . size ( ) ) ; 
 - 
 - for ( MessageIn < ReadResponse > message : replies ) 
 - { 
 - ReadResponse response = message . payload ; 
 - ColumnFamily cf = response . row ( ) . cf ; 
 - assert ! response . isDigestQuery ( ) : " Received digest response to repair read from " + message . from ; 
 - versions . add ( cf ) ; 
 - endpoints . add ( message . from ) ; 
 - 
 - / / compute maxLiveCount to prevent short reads - - see https : / / issues . apache . org / jira / browse / CASSANDRA - 2643 
 - int liveCount = cf = = null ? 0 : filter . getLiveCount ( cf ) ; 
 - if ( liveCount > maxLiveCount ) 
 - maxLiveCount = liveCount ; 
 - } 
 - 
 - resolved = resolveSuperset ( versions ) ; 
 - if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " versions merged " ) ; 
 - 
 - / / send updates to any replica that was missing part of the full row 
 - / / ( resolved can be null even if versions doesn ' t have all nulls because of the call to removeDeleted in resolveSuperSet ) 
 - if ( resolved ! = null ) 
 - repairResults = scheduleRepairs ( resolved , table , key , versions , endpoints ) ; 
 - } 
 - else 
 - { 
 - resolved = replies . iterator ( ) . next ( ) . payload . row ( ) . cf ; 
 - } 
 - 
 - if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " resolve : " + ( System . currentTimeMillis ( ) - startTime ) + " ms . " ) ; 
 - 
 - return new Row ( key , resolved ) ; 
 - } 
 - 
 - / * * 
 - * For each row version , compare with resolved ( the superset of all row versions ) ; 
 - * if it is missing anything , send a mutation to the endpoint it come from . 
 - * / 
 - public static List < IAsyncResult > scheduleRepairs ( ColumnFamily resolved , String table , DecoratedKey key , List < ColumnFamily > versions , List < InetAddress > endpoints ) 
 - { 
 - List < IAsyncResult > results = new ArrayList < IAsyncResult > ( versions . size ( ) ) ; 
 - 
 - for ( int i = 0 ; i < versions . size ( ) ; i + + ) 
 - { 
 - ColumnFamily diffCf = ColumnFamily . diff ( versions . get ( i ) , resolved ) ; 
 - if ( diffCf = = null ) / / no repair needs to happen 
 - continue ; 
 - 
 - / / create and send the row mutation message based on the diff 
 - RowMutation rowMutation = new RowMutation ( table , key . key ) ; 
 - rowMutation . add ( diffCf ) ; 
 - MessageOut repairMessage ; 
 - / / use a separate verb here because we don ' t want these to be get the white glove hint - 
 - / / on - timeout behavior that a " real " mutation gets 
 - repairMessage = rowMutation . createMessage ( MessagingService . Verb . READ _ REPAIR ) ; 
 - results . add ( MessagingService . instance ( ) . sendRR ( repairMessage , endpoints . get ( i ) ) ) ; 
 - } 
 - 
 - return results ; 
 - } 
 - 
 - static ColumnFamily resolveSuperset ( Iterable < ColumnFamily > versions ) 
 - { 
 - assert Iterables . size ( versions ) > 0 ; 
 - 
 - ColumnFamily resolved = null ; 
 - for ( ColumnFamily cf : versions ) 
 - { 
 - if ( cf = = null ) 
 - continue ; 
 - 
 - if ( resolved = = null ) 
 - resolved = cf . cloneMeShallow ( ) ; 
 - else 
 - resolved . delete ( cf ) ; 
 - } 
 - if ( resolved = = null ) 
 - return null ; 
 - 
 - / / mimic the collectCollatedColumn + removeDeleted path that getColumnFamily takes . 
 - / / this will handle removing columns and subcolumns that are supressed by a row or 
 - / / supercolumn tombstone . 
 - QueryFilter filter = new QueryFilter ( null , new QueryPath ( resolved . metadata ( ) . cfName ) , new IdentityQueryFilter ( ) ) ; 
 - List < CloseableIterator < IColumn > > iters = new ArrayList < CloseableIterator < IColumn > > ( ) ; 
 - for ( ColumnFamily version : versions ) 
 - { 
 - if ( version = = null ) 
 - continue ; 
 - iters . add ( FBUtilities . closeableIterator ( version . iterator ( ) ) ) ; 
 - } 
 - filter . collateColumns ( resolved , iters , Integer . MIN _ VALUE ) ; 
 - return ColumnFamilyStore . removeDeleted ( resolved , Integer . MIN _ VALUE ) ; 
 - } 
 - 
 - public Row getData ( ) throws IOException 
 - { 
 - throw new UnsupportedOperationException ( ) ; 
 - } 
 - 
 - public boolean isDataPresent ( ) 
 - { 
 - throw new UnsupportedOperationException ( ) ; 
 - } 
 - 
 - public int getMaxLiveCount ( ) 
 - { 
 - return maxLiveCount ; 
 - } 
 - } 
 diff - - git a / src / java / org / apache / cassandra / service / StorageProxy . java b / src / java / org / apache / cassandra / service / StorageProxy . java 
 index fe427af . . 0fb7ec4 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageProxy . java 
 + + + b / src / java / org / apache / cassandra / service / StorageProxy . java 
 @ @ - 923 , 7 + 923 , 7 @ @ public class StorageProxy implements StorageProxyMBean 
 
 / / read results and make a second pass for any digest mismatches 
 List < ReadCommand > repairCommands = null ; 
 - List < RepairCallback > repairResponseHandlers = null ; 
 + List < ReadCallback < ReadResponse , Row > > repairResponseHandlers = null ; 
 for ( int i = 0 ; i < commands . size ( ) ; i + + ) 
 { 
 ReadCallback < ReadResponse , Row > handler = readCallbacks [ i ] ; 
 @ @ - 946 , 13 + 946 , 14 @ @ public class StorageProxy implements StorageProxyMBean 
 catch ( DigestMismatchException ex ) 
 { 
 logger . debug ( " Digest mismatch : { } " , ex . toString ( ) ) ; 
 - RowRepairResolver resolver = new RowRepairResolver ( command . table , command . key , command . filter ( ) ) ; 
 - RepairCallback repairHandler = new RepairCallback ( resolver , handler . endpoints ) ; 
 + / / Do a full data read to resolve the correct response ( and repair node that need be ) 
 + RowDataResolver resolver = new RowDataResolver ( command . table , command . key , command . filter ( ) ) ; 
 + ReadCallback < ReadResponse , Row > repairHandler = handler . withNewResolver ( resolver ) ; 
 
 if ( repairCommands = = null ) 
 { 
 repairCommands = new ArrayList < ReadCommand > ( ) ; 
 - repairResponseHandlers = new ArrayList < RepairCallback > ( ) ; 
 + repairResponseHandlers = new ArrayList < ReadCallback < ReadResponse , Row > > ( ) ; 
 } 
 repairCommands . add ( command ) ; 
 repairResponseHandlers . add ( repairHandler ) ; 
 @ @ - 974 , 7 + 975 , 7 @ @ public class StorageProxy implements StorageProxyMBean 
 for ( int i = 0 ; i < repairCommands . size ( ) ; i + + ) 
 { 
 ReadCommand command = repairCommands . get ( i ) ; 
 - RepairCallback handler = repairResponseHandlers . get ( i ) ; 
 + ReadCallback < ReadResponse , Row > handler = repairResponseHandlers . get ( i ) ; 
 
 Row row ; 
 try 
 @ @ - 986 , 11 + 987 , 12 @ @ public class StorageProxy implements StorageProxyMBean 
 throw new AssertionError ( e ) ; / / full data requested from each node here , no digests should be sent 
 } 
 
 + RowDataResolver resolver = ( RowDataResolver ) handler . resolver ; 
 try 
 { 
 / / wait for the repair writes to be acknowledged , to minimize impact on any replica that ' s 
 / / behind on writes in case the out - of - sync row is read multiple times in quick succession 
 - FBUtilities . waitOnFutures ( handler . resolver . repairResults , DatabaseDescriptor . getWriteRpcTimeout ( ) ) ; 
 + FBUtilities . waitOnFutures ( resolver . repairResults , DatabaseDescriptor . getWriteRpcTimeout ( ) ) ; 
 } 
 catch ( TimeoutException e ) 
 { 
 @ @ - 999 , 7 + 1001 , 7 @ @ public class StorageProxy implements StorageProxyMBean 
 } 
 
 / / retry any potential short reads 
 - ReadCommand retryCommand = command . maybeGenerateRetryCommand ( handler , row ) ; 
 + ReadCommand retryCommand = command . maybeGenerateRetryCommand ( resolver , row ) ; 
 if ( retryCommand ! = null ) 
 { 
 logger . debug ( " Issuing retry for read command " ) ; 
 diff - - git a / test / unit / org / apache / cassandra / service / RowResolverTest . java b / test / unit / org / apache / cassandra / service / RowResolverTest . java 
 index 3c530f1 . . 2cc7860 100644 
 - - - a / test / unit / org / apache / cassandra / service / RowResolverTest . java 
 + + + b / test / unit / org / apache / cassandra / service / RowResolverTest . java 
 @ @ - 46 , 7 + 46 , 7 @ @ public class RowResolverTest extends SchemaLoader 
 ColumnFamily cf2 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; 
 cf2 . addColumn ( column ( " c1 " , " v2 " , 1 ) ) ; 
 
 - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; 
 + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; 
 assertColumns ( resolved , " c1 " ) ; 
 assertColumns ( ColumnFamily . diff ( cf1 , resolved ) , " c1 " ) ; 
 assertNull ( ColumnFamily . diff ( cf2 , resolved ) ) ; 
 @ @ - 61 , 7 + 61 , 7 @ @ public class RowResolverTest extends SchemaLoader 
 ColumnFamily cf2 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; 
 cf2 . addColumn ( column ( " c2 " , " v2 " , 1 ) ) ; 
 
 - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; 
 + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; 
 assertColumns ( resolved , " c1 " , " c2 " ) ; 
 assertColumns ( ColumnFamily . diff ( cf1 , resolved ) , " c2 " ) ; 
 assertColumns ( ColumnFamily . diff ( cf2 , resolved ) , " c1 " ) ; 
 @ @ - 73 , 7 + 73 , 7 @ @ public class RowResolverTest extends SchemaLoader 
 ColumnFamily cf2 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; 
 cf2 . addColumn ( column ( " c2 " , " v2 " , 1 ) ) ; 
 
 - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( null , cf2 ) ) ; 
 + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( null , cf2 ) ) ; 
 assertColumns ( resolved , " c2 " ) ; 
 assertColumns ( ColumnFamily . diff ( null , resolved ) , " c2 " ) ; 
 assertNull ( ColumnFamily . diff ( cf2 , resolved ) ) ; 
 @ @ - 85 , 7 + 85 , 7 @ @ public class RowResolverTest extends SchemaLoader 
 ColumnFamily cf1 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; 
 cf1 . addColumn ( column ( " c1 " , " v1 " , 0 ) ) ; 
 
 - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( cf1 , null ) ) ; 
 + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( cf1 , null ) ) ; 
 assertColumns ( resolved , " c1 " ) ; 
 assertNull ( ColumnFamily . diff ( cf1 , resolved ) ) ; 
 assertColumns ( ColumnFamily . diff ( null , resolved ) , " c1 " ) ; 
 @ @ - 94 , 7 + 94 , 7 @ @ public class RowResolverTest extends SchemaLoader 
 @ Test 
 public void testResolveSupersetNullBoth ( ) 
 { 
 - assertNull ( RowRepairResolver . resolveSuperset ( Arrays . < ColumnFamily > asList ( null , null ) ) ) ; 
 + assertNull ( RowDataResolver . resolveSuperset ( Arrays . < ColumnFamily > asList ( null , null ) ) ) ; 
 } 
 
 @ Test 
 @ @ - 107 , 7 + 107 , 7 @ @ public class RowResolverTest extends SchemaLoader 
 ColumnFamily cf2 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; 
 cf2 . delete ( new DeletionInfo ( 1L , ( int ) ( System . currentTimeMillis ( ) / 1000 ) ) ) ; 
 
 - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; 
 + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 ) ) ; 
 / / no columns in the cf 
 assertColumns ( resolved ) ; 
 assertTrue ( resolved . isMarkedForDelete ( ) ) ; 
 @ @ - 119 , 7 + 119 , 7 @ @ public class RowResolverTest extends SchemaLoader 
 ColumnFamily scf2 = ColumnFamily . create ( " Keyspace1 " , " Super1 " ) ; 
 scf2 . delete ( new DeletionInfo ( 1L , ( int ) ( System . currentTimeMillis ( ) / 1000 ) ) ) ; 
 
 - ColumnFamily superResolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 ) ) ; 
 + ColumnFamily superResolved = RowDataResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 ) ) ; 
 / / no columns in the cf 
 assertColumns ( superResolved ) ; 
 assertTrue ( superResolved . isMarkedForDelete ( ) ) ; 
 @ @ - 138 , 7 + 138 , 7 @ @ public class RowResolverTest extends SchemaLoader 
 ColumnFamily scf2 = ColumnFamily . create ( " Keyspace1 " , " Super1 " ) ; 
 scf2 . delete ( new DeletionInfo ( 2L , ( int ) ( System . currentTimeMillis ( ) / 1000 ) ) ) ; 
 
 - ColumnFamily superResolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 ) ) ; 
 + ColumnFamily superResolved = RowDataResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 ) ) ; 
 / / no columns in the cf 
 assertColumns ( superResolved ) ; 
 assertTrue ( superResolved . isMarkedForDelete ( ) ) ; 
 @ @ - 165 , 7 + 165 , 7 @ @ public class RowResolverTest extends SchemaLoader 
 ColumnFamily cf4 = ColumnFamily . create ( " Keyspace1 " , " Standard1 " ) ; 
 cf4 . delete ( new DeletionInfo ( 2L , ( int ) ( System . currentTimeMillis ( ) / 1000 ) ) ) ; 
 
 - ColumnFamily resolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 , cf3 , cf4 ) ) ; 
 + ColumnFamily resolved = RowDataResolver . resolveSuperset ( Arrays . asList ( cf1 , cf2 , cf3 , cf4 ) ) ; 
 / / will have deleted marker and one column 
 assertColumns ( resolved , " two " ) ; 
 assertColumn ( resolved , " two " , " B " , 3 ) ; 
 @ @ - 188 , 7 + 188 , 7 @ @ public class RowResolverTest extends SchemaLoader 
 ColumnFamily scf4 = ColumnFamily . create ( " Keyspace1 " , " Super1 " ) ; 
 scf4 . delete ( new DeletionInfo ( 2L , ( int ) ( System . currentTimeMillis ( ) / 1000 ) ) ) ; 
 
 - ColumnFamily superResolved = RowRepairResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 , scf3 , scf4 ) ) ; 
 + ColumnFamily superResolved = RowDataResolver . resolveSuperset ( Arrays . asList ( scf1 , scf2 , scf3 , scf4 ) ) ; 
 / / will have deleted marker and two super cols 
 assertColumns ( superResolved , " super1 " , " super2 " ) ; 

