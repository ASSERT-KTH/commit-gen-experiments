BLEU SCORE: 0.016932492841722675

TEST MSG: Allow Cassandra config to be updated to restart Daemon without unloading classes
GENERATED MSG: merge from 0 . 6

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index d6e8f57 . . 9f89e3f 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 3 . 0 <nl> + * Allow cassandra config to be updated to restart daemon without unloading classes ( CASSANDRA - 9046 ) <nl> * Don ' t initialize compaction writer before checking if iter is empty ( CASSANDRA - 9117 ) <nl> * Remove line number generation from default logback . xml <nl> * Don ' t execute any functions at prepare - time ( CASSANDRA - 9037 ) <nl> diff - - git a / build . xml b / build . xml <nl> index 047f9a8 . . c2c60f3 100644 <nl> - - - a / build . xml <nl> + + + b / build . xml <nl> @ @ - 326 , 7 + 326 , 7 @ @ <nl> < dependency groupId = " commons - codec " artifactId = " commons - codec " version = " 1 . 2 " / > <nl> < dependency groupId = " org . apache . commons " artifactId = " commons - lang3 " version = " 3 . 1 " / > <nl> < dependency groupId = " org . apache . commons " artifactId = " commons - math3 " version = " 3 . 2 " / > <nl> - < dependency groupId = " com . googlecode . concurrentlinkedhashmap " artifactId = " concurrentlinkedhashmap - lru " version = " 1 . 3 " / > <nl> + < dependency groupId = " com . googlecode . concurrentlinkedhashmap " artifactId = " concurrentlinkedhashmap - lru " version = " 1 . 4 " / > <nl> < dependency groupId = " org . antlr " artifactId = " antlr " version = " 3 . 5 . 2 " > <nl> < exclusion groupId = " org . antlr " artifactId = " stringtemplate " / > <nl> < / dependency > <nl> diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> index 781dcfa . . fd1faeb 100644 <nl> - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> @ @ - 254 , 7 + 254 , 7 @ @ public class DatabaseDescriptor <nl> } <nl> } <nl> <nl> - private static void applyConfig ( Config config ) throws ConfigurationException <nl> + public static void applyConfig ( Config config ) throws ConfigurationException <nl> { <nl> conf = config ; <nl>
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 8d9e2ea . . c97b17f 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 7 + 1 , 10 @ @ <nl> dev <nl> * sstable versioning ( CASSANDRA - 389 ) <nl> <nl> - 0 . 6 . 0 - dev <nl> + 0 . 6 . 0 - RC1 <nl> + * fix compaction bucketing bug ( CASSANDRA - 814 ) <nl> + <nl> + 0 . 6 . 0 - beta1 / beta2 <nl> * add batch _ mutate thrift command , deprecating batch _ insert ( CASSANDRA - 336 ) <nl> * remove get _ key _ range Thrift API , deprecated in 0 . 5 ( CASSANDRA - 710 ) <nl> * add optional login ( ) Thrift call for authentication ( CASSANDRA - 547 ) <nl> @ @ - 42 , 7 + 45 , 9 @ @ dev <nl> * allow larger numbers of keys ( > 140M ) in a sstable bloom filter <nl> ( CASSANDRA - 790 ) <nl> * include jvm argument improvements from CASSANDRA - 504 in debian package <nl> - * change streaming chunk size to 32MB ( was 64MB ) ( CASSANDRA - 795 ) <nl> + * change streaming chunk size to 32MB to accomodate Windows XP limitations <nl> + ( was 64MB ) ( CASSANDRA - 795 ) <nl> + * fix get _ range _ slice returning results in the wrong order ( CASSANDRA - 781 ) <nl> <nl> <nl> 0 . 5 . 0 final <nl> diff - - git a / build . xml b / build . xml <nl> index ea79876 . . 54ef12d 100644 <nl> - - - a / build . xml <nl> + + + b / build . xml <nl> @ @ - 314 , 6 + 314 , 7 @ @ <nl> < include name = " * * " / > <nl> < exclude name = " build / * * " / > <nl> < exclude name = " src / gen - java / * * " / > <nl> + < exclude name = " interface / avro / * * " / > <nl> < / tarfileset > <nl> < / tar > <nl> < / target > <nl> diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> index fbd5ebb . . 1b5b6b1 100644 <nl> - - - a / src / java / org / apache / cassandra / db / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> @ @ - 89 , 7 + 89 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> return 0 ; <nl> } <nl> logger . debug ( " Checking to see if compaction of " + cfs . columnFamily _ + " would be useful " ) ; <nl> - Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> + Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> updateEstimateFor ( cfs , buckets ) ; <nl> <nl> for ( List < SSTableReader > sstables : buckets ) <nl> @ @ - 441 , 7 + 441 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> / * <nl> * Group files of similar size into buckets . <nl> * / <nl> - static Set < List < SSTableReader > > getCompactionBuckets ( Iterable < SSTableReader > files , long min ) <nl> + static Set < List < SSTableReader > > getBuckets ( Iterable < SSTableReader > files , long min ) <nl> { <nl> Map < List < SSTableReader > , Long > buckets = new HashMap < List < SSTableReader > , Long > ( ) ; <nl> for ( SSTableReader sstable : files ) <nl> @ @ - 461 , 7 + 461 , 8 @ @ public class CompactionManager implements CompactionManagerMBean <nl> { <nl> / / remove and re - add because adding changes the hash <nl> buckets . remove ( bucket ) ; <nl> - averageSize = ( averageSize + size ) / 2 ; <nl> + long totalSize = bucket . size ( ) * averageSize ; <nl> + averageSize = ( totalSize + size ) / ( bucket . size ( ) + 1 ) ; <nl> bucket . add ( sstable ) ; <nl> buckets . put ( bucket , averageSize ) ; <nl> bFound = true ; <nl> @ @ - 538 , 7 + 539 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> public void run ( ) <nl> { <nl> logger . debug ( " Estimating compactions for " + cfs . columnFamily _ ) ; <nl> - final Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> + final Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> updateEstimateFor ( cfs , buckets ) ; <nl> } <nl> } ;

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index d6e8f57 . . 9f89e3f 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 3 . 0 
 + * Allow cassandra config to be updated to restart daemon without unloading classes ( CASSANDRA - 9046 ) 
 * Don ' t initialize compaction writer before checking if iter is empty ( CASSANDRA - 9117 ) 
 * Remove line number generation from default logback . xml 
 * Don ' t execute any functions at prepare - time ( CASSANDRA - 9037 ) 
 diff - - git a / build . xml b / build . xml 
 index 047f9a8 . . c2c60f3 100644 
 - - - a / build . xml 
 + + + b / build . xml 
 @ @ - 326 , 7 + 326 , 7 @ @ 
 < dependency groupId = " commons - codec " artifactId = " commons - codec " version = " 1 . 2 " / > 
 < dependency groupId = " org . apache . commons " artifactId = " commons - lang3 " version = " 3 . 1 " / > 
 < dependency groupId = " org . apache . commons " artifactId = " commons - math3 " version = " 3 . 2 " / > 
 - < dependency groupId = " com . googlecode . concurrentlinkedhashmap " artifactId = " concurrentlinkedhashmap - lru " version = " 1 . 3 " / > 
 + < dependency groupId = " com . googlecode . concurrentlinkedhashmap " artifactId = " concurrentlinkedhashmap - lru " version = " 1 . 4 " / > 
 < dependency groupId = " org . antlr " artifactId = " antlr " version = " 3 . 5 . 2 " > 
 < exclusion groupId = " org . antlr " artifactId = " stringtemplate " / > 
 < / dependency > 
 diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 index 781dcfa . . fd1faeb 100644 
 - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 @ @ - 254 , 7 + 254 , 7 @ @ public class DatabaseDescriptor 
 } 
 } 
 
 - private static void applyConfig ( Config config ) throws ConfigurationException 
 + public static void applyConfig ( Config config ) throws ConfigurationException 
 { 
 conf = config ; 


NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 8d9e2ea . . c97b17f 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 7 + 1 , 10 @ @ 
 dev 
 * sstable versioning ( CASSANDRA - 389 ) 
 
 - 0 . 6 . 0 - dev 
 + 0 . 6 . 0 - RC1 
 + * fix compaction bucketing bug ( CASSANDRA - 814 ) 
 + 
 + 0 . 6 . 0 - beta1 / beta2 
 * add batch _ mutate thrift command , deprecating batch _ insert ( CASSANDRA - 336 ) 
 * remove get _ key _ range Thrift API , deprecated in 0 . 5 ( CASSANDRA - 710 ) 
 * add optional login ( ) Thrift call for authentication ( CASSANDRA - 547 ) 
 @ @ - 42 , 7 + 45 , 9 @ @ dev 
 * allow larger numbers of keys ( > 140M ) in a sstable bloom filter 
 ( CASSANDRA - 790 ) 
 * include jvm argument improvements from CASSANDRA - 504 in debian package 
 - * change streaming chunk size to 32MB ( was 64MB ) ( CASSANDRA - 795 ) 
 + * change streaming chunk size to 32MB to accomodate Windows XP limitations 
 + ( was 64MB ) ( CASSANDRA - 795 ) 
 + * fix get _ range _ slice returning results in the wrong order ( CASSANDRA - 781 ) 
 
 
 0 . 5 . 0 final 
 diff - - git a / build . xml b / build . xml 
 index ea79876 . . 54ef12d 100644 
 - - - a / build . xml 
 + + + b / build . xml 
 @ @ - 314 , 6 + 314 , 7 @ @ 
 < include name = " * * " / > 
 < exclude name = " build / * * " / > 
 < exclude name = " src / gen - java / * * " / > 
 + < exclude name = " interface / avro / * * " / > 
 < / tarfileset > 
 < / tar > 
 < / target > 
 diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java 
 index fbd5ebb . . 1b5b6b1 100644 
 - - - a / src / java / org / apache / cassandra / db / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / CompactionManager . java 
 @ @ - 89 , 7 + 89 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 return 0 ; 
 } 
 logger . debug ( " Checking to see if compaction of " + cfs . columnFamily _ + " would be useful " ) ; 
 - Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 + Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 updateEstimateFor ( cfs , buckets ) ; 
 
 for ( List < SSTableReader > sstables : buckets ) 
 @ @ - 441 , 7 + 441 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 / * 
 * Group files of similar size into buckets . 
 * / 
 - static Set < List < SSTableReader > > getCompactionBuckets ( Iterable < SSTableReader > files , long min ) 
 + static Set < List < SSTableReader > > getBuckets ( Iterable < SSTableReader > files , long min ) 
 { 
 Map < List < SSTableReader > , Long > buckets = new HashMap < List < SSTableReader > , Long > ( ) ; 
 for ( SSTableReader sstable : files ) 
 @ @ - 461 , 7 + 461 , 8 @ @ public class CompactionManager implements CompactionManagerMBean 
 { 
 / / remove and re - add because adding changes the hash 
 buckets . remove ( bucket ) ; 
 - averageSize = ( averageSize + size ) / 2 ; 
 + long totalSize = bucket . size ( ) * averageSize ; 
 + averageSize = ( totalSize + size ) / ( bucket . size ( ) + 1 ) ; 
 bucket . add ( sstable ) ; 
 buckets . put ( bucket , averageSize ) ; 
 bFound = true ; 
 @ @ - 538 , 7 + 539 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 public void run ( ) 
 { 
 logger . debug ( " Estimating compactions for " + cfs . columnFamily _ ) ; 
 - final Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 + final Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 updateEstimateFor ( cfs , buckets ) ; 
 } 
 } ;
