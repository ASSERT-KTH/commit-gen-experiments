BLEU SCORE: 0.05693025330278466

TEST MSG: Update syntax for changing caching options .
GENERATED MSG: enable skipping bad rows on LazilyCompacted path .

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index d8eb3a1 . . 61e17e3 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 11 , 6 + 11 , 7 @ @ <nl> * Improve handling of range tombstone for wide partitions ( CASSANDRA - 6446 ) <nl> * Fix ClassCastException for compact table with composites ( CASSANDRA - 6738 ) <nl> * Fix potentially repairing with wrong nodes ( CASSANDRA - 6808 ) <nl> + * Change caching option syntax ( CASSANDRA - 6745 ) <nl> Merged from 2 . 0 : <nl> * Fix saving triggers to schema ( CASSANDRA - 6789 ) <nl> * Fix trigger mutations when base mutation list is immutable ( CASSANDRA - 6790 ) <nl> diff - - git a / pylib / cqlshlib / cql3handling . py b / pylib / cqlshlib / cql3handling . py <nl> index 158e60d . . 3522d1c 100644 <nl> - - - a / pylib / cqlshlib / cql3handling . py <nl> + + + b / pylib / cqlshlib / cql3handling . py <nl> @ @ - 62 , 8 + 62 , 6 @ @ class Cql3ParsingRuleSet ( CqlParsingRuleSet ) : <nl> <nl> columnfamily _ layout _ options = ( <nl> ( ' bloom _ filter _ fp _ chance ' , None ) , <nl> - ( ' caching ' , None ) , <nl> - ( ' rows _ per _ partition _ to _ cache ' , None ) , <nl> ( ' comment ' , None ) , <nl> ( ' dclocal _ read _ repair _ chance ' , ' local _ read _ repair _ chance ' ) , <nl> ( ' gc _ grace _ seconds ' , None ) , <nl> @ @ - 83 , 6 + 81 , 8 @ @ class Cql3ParsingRuleSet ( CqlParsingRuleSet ) : <nl> ( ' class ' , ' min _ threshold ' , ' max _ threshold ' ) ) , <nl> ( ' compression ' , ' compression _ parameters ' , <nl> ( ' sstable _ compression ' , ' chunk _ length _ kb ' , ' crc _ check _ chance ' ) ) , <nl> + ( ' caching ' , None , <nl> + ( ' rows _ per _ partition ' , ' keys ' ) ) , <nl> ) <nl> <nl> obsolete _ cf _ options = ( ) <nl> @ @ - 463 , 6 + 463 , 8 @ @ def cf _ prop _ val _ mapkey _ completer ( ctxt , cass ) : <nl> pairsseen = dict ( zip ( keysseen , valsseen ) ) <nl> if optname = = ' compression ' : <nl> return map ( escape _ value , set ( subopts ) . difference ( keysseen ) ) <nl> + if optname = = ' caching ' : <nl> + return map ( escape _ value , set ( subopts ) . difference ( keysseen ) ) <nl> if optname = = ' compaction ' : <nl> opts = set ( subopts ) <nl> try : <nl> @ @ - 488 , 6 + 490 , 11 @ @ def cf _ prop _ val _ mapval _ completer ( ctxt , cass ) : <nl> if key = = ' sstable _ compression ' : <nl> return map ( escape _ value , CqlRuleSet . available _ compression _ classes ) <nl> return [ Hint ( ' < option _ value > ' ) ] <nl> + elif opt = = ' caching ' : <nl> + if key = = ' rows _ per _ partition ' : <nl> + return [ Hint ( ' ALL ' ) , Hint ( ' NONE ' ) , Hint ( ' # rows _ per _ partition ' ) ] <nl> + elif key = = ' keys ' : <nl> + return [ Hint ( ' ALL ' ) , Hint ( ' NONE ' ) ] <nl> return ( ) <nl> <nl> def cf _ prop _ val _ mapender _ completer ( ctxt , cass ) : <nl> @ @ - 1187 , 7 + 1194 , 7 @ @ class CqlTableDef : <nl> for attr , val in layout . items ( ) : <nl> setattr ( cf , attr . encode ( ' ascii ' ) , val ) <nl> cf . comparator = lookup _ casstype ( cf . comparator ) <nl> - for attr in ( ' compaction _ strategy _ options ' , ' compression _ parameters ' ) : <nl> + for attr in ( ' compaction _ strategy _ options ' , ' compression _ parameters ' , ' caching ' ) : <nl> setattr ( cf , attr , json . loads ( getattr ( cf , attr ) ) ) <nl> <nl> # deal with columns , filter out empty column names ( see CASSANDRA - 6139 ) <nl> diff - - git a / src / java / org / apache / cassandra / cache / CachingOptions . java b / src / java / org / apache / cassandra / cache / CachingOptions . java <nl> new file mode 100644 <nl> index 0000000 . . 6eeaa37 <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / cache / CachingOptions . java <nl> @ @ - 0 , 0 + 1 , 288 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an " AS IS " BASIS , <nl> + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + * See the License for the specific language governing permissions and <nl> + * limitations under the License . <nl> + * / <nl> + package org . apache . cassandra . cache ; <nl> + <nl> + <nl> + import java . util . Arrays ; <nl> + import java . util . HashSet ; <nl> + import java . util . Map ; <nl> + import java . util . Set ; <nl> + import org . apache . commons . lang3 . StringUtils ; <nl> + <nl> + import org . apache . cassandra . exceptions . ConfigurationException ; <nl> + import static org . apache . cassandra . utils . FBUtilities . fromJsonMap ; <nl> + <nl> + / * <nl> + CQL : { ' keys ' : ' ALL | NONE ' , ' rows _ per _ partition ' : ' 200 | NONE | ALL ' } <nl> + * / <nl> + public class CachingOptions <nl> + { <nl> + public static final CachingOptions KEYS _ ONLY = new CachingOptions ( new KeyCache ( KeyCache . Type . ALL ) , new RowCache ( RowCache . Type . NONE ) ) ; <nl> + public static final CachingOptions ALL = new CachingOptions ( new KeyCache ( KeyCache . Type . ALL ) , new RowCache ( RowCache . Type . ALL ) ) ; <nl> + public static final CachingOptions ROWS _ ONLY = new CachingOptions ( new KeyCache ( KeyCache . Type . NONE ) , new RowCache ( RowCache . Type . ALL ) ) ; <nl> + public static final CachingOptions NONE = new CachingOptions ( new KeyCache ( KeyCache . Type . NONE ) , new RowCache ( RowCache . Type . NONE ) ) ; <nl> + <nl> + public final KeyCache keyCache ; <nl> + public final RowCache rowCache ; <nl> + private static final Set < String > legacyOptions = new HashSet < > ( Arrays . asList ( " ALL " , " NONE " , " KEYS _ ONLY " , " ROWS _ ONLY " ) ) ; <nl> + <nl> + public CachingOptions ( KeyCache kc , RowCache rc ) <nl> + { <nl> + this . keyCache = kc ; <nl> + this . rowCache = rc ; <nl> + } <nl> + <nl> + public static CachingOptions fromString ( String cache ) throws ConfigurationException <nl> + { <nl> + if ( legacyOptions . contains ( cache . toUpperCase ( ) ) ) <nl> + return fromLegacyOption ( cache . toUpperCase ( ) ) ; <nl> + return fromMap ( fromJsonMap ( cache ) ) ; <nl> + } <nl> + <nl> + public static CachingOptions fromMap ( Map < String , String > cacheConfig ) throws ConfigurationException <nl> + { <nl> + validateCacheConfig ( cacheConfig ) ; <nl> + if ( ! cacheConfig . containsKey ( " keys " ) & & ! cacheConfig . containsKey ( " rows _ per _ partition " ) ) <nl> + return CachingOptions . NONE ; <nl> + if ( ! cacheConfig . containsKey ( " keys " ) ) <nl> + return new CachingOptions ( new KeyCache ( KeyCache . Type . NONE ) , RowCache . fromString ( cacheConfig . get ( " rows _ per _ partition " ) ) ) ; <nl> + if ( ! cacheConfig . containsKey ( " rows _ per _ partition " ) ) <nl> + return CachingOptions . KEYS _ ONLY ; <nl> + <nl> + return new CachingOptions ( KeyCache . fromString ( cacheConfig . get ( " keys " ) ) , RowCache . fromString ( cacheConfig . get ( " rows _ per _ partition " ) ) ) ; <nl> + } <nl> + <nl> + private static void validateCacheConfig ( Map < String , String > cacheConfig ) throws ConfigurationException <nl> + { <nl> + for ( Map . Entry < String , String > entry : cacheConfig . entrySet ( ) ) <nl> + { <nl> + String value = entry . getValue ( ) . toUpperCase ( ) ; <nl> + if ( entry . getKey ( ) . equals ( " keys " ) ) <nl> + { <nl> + if ( ! ( value . equals ( " ALL " ) | | value . equals ( " NONE " ) ) ) <nl> + { <nl> + throw new ConfigurationException ( " ' keys ' can only have values ' ALL ' or ' NONE ' " ) ; <nl> + } <nl> + } <nl> + else if ( entry . getKey ( ) . equals ( " rows _ per _ partition " ) ) <nl> + { <nl> + if ( ! ( value . equals ( " ALL " ) | | value . equals ( " NONE " ) | | StringUtils . isNumeric ( value ) ) ) <nl> + { <nl> + throw new ConfigurationException ( " ' rows _ per _ partition ' can only have values ' ALL ' , ' NONE ' or be numeric . " ) ; <nl> + } <nl> + } <nl> + else <nl> + throw new ConfigurationException ( " Only supported CachingOptions parameters are ' keys ' and ' rows _ per _ partition ' " ) ; <nl> + } <nl> + } <nl> + <nl> + @ Override <nl> + public String toString ( ) <nl> + { <nl> + return String . format ( " { \ " keys \ " : \ " % s \ " , \ " rows _ per _ partition \ " : \ " % s \ " } " , keyCache . toString ( ) , rowCache . toString ( ) ) ; <nl> + } <nl> + <nl> + private static CachingOptions fromLegacyOption ( String cache ) <nl> + { <nl> + if ( cache . equals ( " ALL " ) ) <nl> + return ALL ; <nl> + if ( cache . equals ( " KEYS _ ONLY " ) ) <nl> + return KEYS _ ONLY ; <nl> + if ( cache . equals ( " ROWS _ ONLY " ) ) <nl> + return ROWS _ ONLY ; <nl> + return NONE ; <nl> + } <nl> + <nl> + @ Override <nl> + public boolean equals ( Object o ) <nl> + { <nl> + if ( this = = o ) return true ; <nl> + if ( o = = null | | getClass ( ) ! = o . getClass ( ) ) return false ; <nl> + <nl> + CachingOptions o2 = ( CachingOptions ) o ; <nl> + <nl> + if ( ! keyCache . equals ( o2 . keyCache ) ) return false ; <nl> + if ( ! rowCache . equals ( o2 . rowCache ) ) return false ; <nl> + <nl> + return true ; <nl> + } <nl> + <nl> + @ Override <nl> + public int hashCode ( ) <nl> + { <nl> + int result = keyCache . hashCode ( ) ; <nl> + result = 31 * result + rowCache . hashCode ( ) ; <nl> + return result ; <nl> + } <nl> + <nl> + public static boolean isLegacy ( String CachingOptions ) <nl> + { <nl> + return legacyOptions . contains ( CachingOptions . toUpperCase ( ) ) ; <nl> + } <nl> + <nl> + public static CachingOptions fromThrift ( String caching , String cellsPerRow ) throws ConfigurationException <nl> + { <nl> + <nl> + RowCache rc = new RowCache ( RowCache . Type . NONE ) ; <nl> + KeyCache kc = new KeyCache ( KeyCache . Type . ALL ) ; <nl> + / / if we get a caching string from thrift it is legacy , " ALL " , " KEYS _ ONLY " etc , fromString handles those <nl> + if ( caching ! = null ) <nl> + { <nl> + CachingOptions givenOptions = CachingOptions . fromString ( caching ) ; <nl> + rc = givenOptions . rowCache ; <nl> + kc = givenOptions . keyCache ; <nl> + } <nl> + / / if we get cells _ per _ row from thrift , it is either " ALL " or " < number of cells to cache > " . <nl> + if ( cellsPerRow ! = null & & rc . isEnabled ( ) ) <nl> + rc = RowCache . fromString ( cellsPerRow ) ; <nl> + return new CachingOptions ( kc , rc ) ; <nl> + } <nl> + <nl> + public String toThriftCaching ( ) <nl> + { <nl> + if ( rowCache . isEnabled ( ) & & keyCache . isEnabled ( ) ) <nl> + return " ALL " ; <nl> + if ( rowCache . isEnabled ( ) ) <nl> + return " ROWS _ ONLY " ; <nl> + if ( keyCache . isEnabled ( ) ) <nl> + return " KEYS _ ONLY " ; <nl> + return " NONE " ; <nl> + } <nl> + <nl> + public String toThriftCellsPerRow ( ) <nl> + { <nl> + if ( rowCache . cacheFullPartitions ( ) ) <nl> + return " ALL " ; <nl> + return String . valueOf ( rowCache . rowsToCache ) ; <nl> + } <nl> + <nl> + <nl> + public static class KeyCache <nl> + { <nl> + public final Type type ; <nl> + public KeyCache ( Type type ) <nl> + { <nl> + this . type = type ; <nl> + } <nl> + <nl> + public enum Type <nl> + { <nl> + ALL , NONE <nl> + } <nl> + public static KeyCache fromString ( String keyCache ) <nl> + { <nl> + return new KeyCache ( Type . valueOf ( keyCache . toUpperCase ( ) ) ) ; <nl> + } <nl> + <nl> + public boolean isEnabled ( ) <nl> + { <nl> + return type . equals ( Type . ALL ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public boolean equals ( Object o ) <nl> + { <nl> + if ( this = = o ) return true ; <nl> + if ( o = = null | | getClass ( ) ! = o . getClass ( ) ) return false ; <nl> + <nl> + KeyCache keyCache = ( KeyCache ) o ; <nl> + <nl> + if ( type ! = keyCache . type ) return false ; <nl> + <nl> + return true ; <nl> + } <nl> + <nl> + @ Override <nl> + public int hashCode ( ) <nl> + { <nl> + return type . hashCode ( ) ; <nl> + } <nl> + @ Override <nl> + public String toString ( ) <nl> + { <nl> + return type . toString ( ) ; <nl> + } <nl> + } <nl> + <nl> + public static class RowCache <nl> + { <nl> + public final Type type ; <nl> + public final int rowsToCache ; <nl> + <nl> + public RowCache ( Type type ) <nl> + { <nl> + this ( type , type . equals ( Type . ALL ) ? Integer . MAX _ VALUE : 0 ) ; <nl> + } <nl> + public RowCache ( Type type , int rowsToCache ) <nl> + { <nl> + this . type = type ; <nl> + this . rowsToCache = rowsToCache ; <nl> + } <nl> + <nl> + public enum Type <nl> + { <nl> + ALL , NONE , HEAD <nl> + } <nl> + <nl> + public static RowCache fromString ( String rowCache ) <nl> + { <nl> + if ( rowCache = = null | | rowCache . equalsIgnoreCase ( " none " ) ) <nl> + return new RowCache ( Type . NONE , 0 ) ; <nl> + else if ( rowCache . equalsIgnoreCase ( " all " ) ) <nl> + return new RowCache ( Type . ALL , Integer . MAX _ VALUE ) ; <nl> + return new RowCache ( Type . HEAD , Integer . parseInt ( rowCache ) ) ; <nl> + } <nl> + public boolean isEnabled ( ) <nl> + { <nl> + return type . equals ( Type . ALL ) | | type . equals ( Type . HEAD ) ; <nl> + } <nl> + public boolean cacheFullPartitions ( ) <nl> + { <nl> + return type . equals ( Type . ALL ) ; <nl> + } <nl> + @ Override <nl> + public String toString ( ) <nl> + { <nl> + if ( type . equals ( Type . ALL ) ) return " ALL " ; <nl> + if ( type . equals ( Type . NONE ) ) return " NONE " ; <nl> + return String . valueOf ( rowsToCache ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public boolean equals ( Object o ) <nl> + { <nl> + if ( this = = o ) return true ; <nl> + if ( o = = null | | getClass ( ) ! = o . getClass ( ) ) return false ; <nl> + <nl> + RowCache rowCache = ( RowCache ) o ; <nl> + <nl> + if ( rowsToCache ! = rowCache . rowsToCache ) return false ; <nl> + if ( type ! = rowCache . type ) return false ; <nl> + <nl> + return true ; <nl> + } <nl> + <nl> + @ Override <nl> + public int hashCode ( ) <nl> + { <nl> + int result = type . hashCode ( ) ; <nl> + result = 31 * result + rowsToCache ; <nl> + return result ; <nl> + } <nl> + } <nl> + } <nl> diff - - git a / src / java / org / apache / cassandra / cli / CliClient . java b / src / java / org / apache / cassandra / cli / CliClient . java <nl> index b30bee1 . . ab6a221 100644 <nl> - - - a / src / java / org / apache / cassandra / cli / CliClient . java <nl> + + + b / src / java / org / apache / cassandra / cli / CliClient . java <nl> @ @ - 1350 , 7 + 1350 , 7 @ @ public class CliClient <nl> cfDef . setCaching ( CliUtils . unescapeSQLString ( mValue ) ) ; <nl> break ; <nl> case CELLS _ PER _ ROW _ TO _ CACHE : <nl> - cfDef . setCells _ per _ row _ to _ cache ( mValue ) ; <nl> + cfDef . setCells _ per _ row _ to _ cache ( CliUtils . unescapeSQLString ( mValue ) ) ; <nl> break ; <nl> case DEFAULT _ TIME _ TO _ LIVE : <nl> cfDef . setDefault _ time _ to _ live ( Integer . parseInt ( mValue ) ) ; <nl> @ @ - 1853 , 7 + 1853 , 6 @ @ public class CliClient <nl> <nl> writeAttrRaw ( output , false , " compaction _ strategy _ options " , cOptions . toString ( ) ) ; <nl> } <nl> - <nl> if ( ! StringUtils . isEmpty ( cfDef . comment ) ) <nl> writeAttr ( output , false , " comment " , cfDef . comment ) ; <nl> <nl> diff - - git a / src / java / org / apache / cassandra / config / CFMetaData . java b / src / java / org / apache / cassandra / config / CFMetaData . java <nl> index ac5dea7 . . f38dd5e 100644 <nl> - - - a / src / java / org / apache / cassandra / config / CFMetaData . java <nl> + + + b / src / java / org / apache / cassandra / config / CFMetaData . java <nl> @ @ - 30 , 9 + 30 , 11 @ @ import com . google . common . collect . AbstractIterator ; <nl> import com . google . common . collect . Iterables ; <nl> import com . google . common . collect . MapDifference ; <nl> import com . google . common . collect . Maps ; <nl> + <nl> + import org . apache . cassandra . cache . CachingOptions ; <nl> import org . apache . cassandra . db . composites . * ; <nl> + <nl> import org . apache . commons . lang3 . ArrayUtils ; <nl> - import org . apache . commons . lang3 . StringUtils ; <nl> import org . apache . commons . lang3 . builder . HashCodeBuilder ; <nl> import org . apache . commons . lang3 . builder . ToStringBuilder ; <nl> import org . slf4j . Logger ; <nl> @ @ - 80 , 13 + 82 , 12 @ @ public final class CFMetaData <nl> public final static int DEFAULT _ MIN _ COMPACTION _ THRESHOLD = 4 ; <nl> public final static int DEFAULT _ MAX _ COMPACTION _ THRESHOLD = 32 ; <nl> public final static Class < ? extends AbstractCompactionStrategy > DEFAULT _ COMPACTION _ STRATEGY _ CLASS = SizeTieredCompactionStrategy . class ; <nl> - public final static Caching DEFAULT _ CACHING _ STRATEGY = Caching . KEYS _ ONLY ; <nl> + public final static CachingOptions DEFAULT _ CACHING _ STRATEGY = CachingOptions . KEYS _ ONLY ; <nl> public final static int DEFAULT _ DEFAULT _ TIME _ TO _ LIVE = 0 ; <nl> public final static SpeculativeRetry DEFAULT _ SPECULATIVE _ RETRY = new SpeculativeRetry ( SpeculativeRetry . RetryType . PERCENTILE , 0 . 99 ) ; <nl> public final static int DEFAULT _ MIN _ INDEX _ INTERVAL = 128 ; <nl> public final static int DEFAULT _ MAX _ INDEX _ INTERVAL = 2048 ; <nl> public final static boolean DEFAULT _ POPULATE _ IO _ CACHE _ ON _ FLUSH = false ; <nl> - public final static RowsPerPartitionToCache DEFAULT _ ROWS _ PER _ PARTITION _ TO _ CACHE = new RowsPerPartitionToCache ( 100 , RowsPerPartitionToCache . Type . HEAD ) ; <nl> <nl> / / Note that this is the default only for user created tables <nl> public final static String DEFAULT _ COMPRESSOR = LZ4Compressor . class . getCanonicalName ( ) ; <nl> @ @ - 300 , 65 + 301 , 6 @ @ public final class CFMetaData <nl> + " PRIMARY KEY ( id ) " <nl> + " ) WITH COMMENT = ' show all compaction history ' AND DEFAULT _ TIME _ TO _ LIVE = 604800 " ) ; <nl> <nl> - public enum Caching <nl> - { <nl> - ALL , KEYS _ ONLY , ROWS _ ONLY , NONE ; <nl> - <nl> - public static Caching fromString ( String cache ) throws ConfigurationException <nl> - { <nl> - try <nl> - { <nl> - return valueOf ( cache . toUpperCase ( ) ) ; <nl> - } <nl> - catch ( IllegalArgumentException e ) <nl> - { <nl> - throw new ConfigurationException ( String . format ( " % s not found , available types : % s . " , cache , StringUtils . join ( values ( ) , " , " ) ) ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> - public static class RowsPerPartitionToCache <nl> - { <nl> - public enum Type <nl> - { <nl> - ALL , HEAD <nl> - } <nl> - public final int rowsToCache ; <nl> - public final Type type ; <nl> - <nl> - private RowsPerPartitionToCache ( int rowsToCache , Type type ) <nl> - { <nl> - this . rowsToCache = rowsToCache ; <nl> - this . type = type ; <nl> - } <nl> - <nl> - public static RowsPerPartitionToCache fromString ( String rpptc ) <nl> - { <nl> - if ( rpptc . equalsIgnoreCase ( " all " ) ) <nl> - return new RowsPerPartitionToCache ( Integer . MAX _ VALUE , Type . ALL ) ; <nl> - return new RowsPerPartitionToCache ( Integer . parseInt ( rpptc ) , Type . HEAD ) ; <nl> - } <nl> - <nl> - public boolean cacheFullPartitions ( ) <nl> - { <nl> - return type = = Type . ALL ; <nl> - } <nl> - <nl> - public String toString ( ) <nl> - { <nl> - if ( rowsToCache = = Integer . MAX _ VALUE ) <nl> - return " ALL " ; <nl> - return String . valueOf ( rowsToCache ) ; <nl> - } <nl> - <nl> - public boolean equals ( Object rhs ) <nl> - { <nl> - if ( ! ( rhs instanceof RowsPerPartitionToCache ) ) <nl> - return false ; <nl> - RowsPerPartitionToCache rppc = ( RowsPerPartitionToCache ) rhs ; <nl> - return rowsToCache = = rppc . rowsToCache & & type = = rppc . type ; <nl> - } <nl> - } <nl> <nl> public static class SpeculativeRetry <nl> { <nl> @ @ - 453 , 7 + 395 , 7 @ @ public final class CFMetaData <nl> private volatile int minCompactionThreshold = DEFAULT _ MIN _ COMPACTION _ THRESHOLD ; <nl> private volatile int maxCompactionThreshold = DEFAULT _ MAX _ COMPACTION _ THRESHOLD ; <nl> private volatile Double bloomFilterFpChance = null ; <nl> - private volatile Caching caching = DEFAULT _ CACHING _ STRATEGY ; <nl> + private volatile CachingOptions caching = DEFAULT _ CACHING _ STRATEGY ; <nl> private volatile int minIndexInterval = DEFAULT _ MIN _ INDEX _ INTERVAL ; <nl> private volatile int maxIndexInterval = DEFAULT _ MAX _ INDEX _ INTERVAL ; <nl> private int memtableFlushPeriod = 0 ; <nl> @ @ - 463 , 7 + 405 , 6 @ @ public final class CFMetaData <nl> private volatile Map < ColumnIdentifier , Long > droppedColumns = new HashMap < > ( ) ; <nl> private volatile Map < String , TriggerDefinition > triggers = new HashMap < > ( ) ; <nl> private volatile boolean isPurged = false ; <nl> - private volatile RowsPerPartitionToCache rowsPerPartitionToCache = DEFAULT _ ROWS _ PER _ PARTITION _ TO _ CACHE ; <nl> / * <nl> * All CQL3 columns definition are stored in the columnMetadata map . <nl> * On top of that , we keep separated collection of each kind of definition , to <nl> @ @ - 500 , 7 + 441 , 7 @ @ public final class CFMetaData <nl> public CFMetaData compactionStrategyOptions ( Map < String , String > prop ) { compactionStrategyOptions = prop ; return this ; } <nl> public CFMetaData compressionParameters ( CompressionParameters prop ) { compressionParameters = prop ; return this ; } <nl> public CFMetaData bloomFilterFpChance ( Double prop ) { bloomFilterFpChance = prop ; return this ; } <nl> - public CFMetaData caching ( Caching prop ) { caching = prop ; return this ; } <nl> + public CFMetaData caching ( CachingOptions prop ) { caching = prop ; return this ; } <nl> public CFMetaData minIndexInterval ( int prop ) { minIndexInterval = prop ; return this ; } <nl> public CFMetaData maxIndexInterval ( int prop ) { maxIndexInterval = prop ; return this ; } <nl> public CFMetaData memtableFlushPeriod ( int prop ) { memtableFlushPeriod = prop ; return this ; } <nl> @ @ - 509 , 7 + 450 , 6 @ @ public final class CFMetaData <nl> public CFMetaData populateIoCacheOnFlush ( boolean prop ) { populateIoCacheOnFlush = prop ; return this ; } <nl> public CFMetaData droppedColumns ( Map < ColumnIdentifier , Long > cols ) { droppedColumns = cols ; return this ; } <nl> public CFMetaData triggers ( Map < String , TriggerDefinition > prop ) { triggers = prop ; return this ; } <nl> - public CFMetaData rowsPerPartitionToCache ( RowsPerPartitionToCache prop ) { rowsPerPartitionToCache = prop ; return this ; } <nl> <nl> / * * <nl> * Create new ColumnFamily metadata with generated random ID . <nl> @ @ - 626 , 9 + 566 , 9 @ @ public final class CFMetaData <nl> { <nl> / / Depends on parent ' s cache setting , turn on its index CF ' s cache . <nl> / / Row caching is never enabled ; see CASSANDRA - 5732 <nl> - Caching indexCaching = parent . getCaching ( ) = = Caching . ALL | | parent . getCaching ( ) = = Caching . KEYS _ ONLY <nl> - ? Caching . KEYS _ ONLY <nl> - : Caching . NONE ; <nl> + CachingOptions indexCaching = parent . getCaching ( ) . keyCache . isEnabled ( ) <nl> + ? CachingOptions . KEYS _ ONLY <nl> + : CachingOptions . NONE ; <nl> <nl> return new CFMetaData ( parent . ksName , parent . indexColumnFamilyName ( info ) , ColumnFamilyType . Standard , indexComparator , parent . cfId ) <nl> . keyValidator ( info . type ) <nl> @ @ - 697 , 7 + 637 , 6 @ @ public final class CFMetaData <nl> . populateIoCacheOnFlush ( oldCFMD . populateIoCacheOnFlush ) <nl> . droppedColumns ( new HashMap < > ( oldCFMD . droppedColumns ) ) <nl> . triggers ( new HashMap < > ( oldCFMD . triggers ) ) <nl> - . rowsPerPartitionToCache ( oldCFMD . rowsPerPartitionToCache ) <nl> . rebuild ( ) ; <nl> } <nl> <nl> @ @ - 884 , 7 + 823 , 7 @ @ public final class CFMetaData <nl> : bloomFilterFpChance ; <nl> } <nl> <nl> - public Caching getCaching ( ) <nl> + public CachingOptions getCaching ( ) <nl> { <nl> return caching ; <nl> } <nl> @ @ - 899 , 11 + 838 , 6 @ @ public final class CFMetaData <nl> return maxIndexInterval ; <nl> } <nl> <nl> - public RowsPerPartitionToCache getRowsPerPartitionToCache ( ) <nl> - { <nl> - return rowsPerPartitionToCache ; <nl> - } <nl> - <nl> public SpeculativeRetry getSpeculativeRetry ( ) <nl> { <nl> return speculativeRetry ; <nl> @ @ - 961 , 8 + 895 , 7 @ @ public final class CFMetaData <nl> & & Objects . equal ( speculativeRetry , other . speculativeRetry ) <nl> & & Objects . equal ( populateIoCacheOnFlush , other . populateIoCacheOnFlush ) <nl> & & Objects . equal ( droppedColumns , other . droppedColumns ) <nl> - & & Objects . equal ( triggers , other . triggers ) <nl> - & & Objects . equal ( rowsPerPartitionToCache , other . rowsPerPartitionToCache ) ; <nl> + & & Objects . equal ( triggers , other . triggers ) ; <nl> } <nl> <nl> @ Override <nl> @ @ - 996 , 7 + 929 , 6 @ @ public final class CFMetaData <nl> . append ( populateIoCacheOnFlush ) <nl> . append ( droppedColumns ) <nl> . append ( triggers ) <nl> - . append ( rowsPerPartitionToCache ) <nl> . toHashCode ( ) ; <nl> } <nl> <nl> @ @ - 1067 , 9 + 999 , 6 @ @ public final class CFMetaData <nl> / / ensure the max is at least as large as the min <nl> cf _ def . setMax _ index _ interval ( Math . max ( cf _ def . min _ index _ interval , CFMetaData . DEFAULT _ MAX _ INDEX _ INTERVAL ) ) ; <nl> } <nl> - <nl> - if ( ! cf _ def . isSetCells _ per _ row _ to _ cache ( ) ) <nl> - cf _ def . setCells _ per _ row _ to _ cache ( CFMetaData . DEFAULT _ ROWS _ PER _ PARTITION _ TO _ CACHE . toString ( ) ) ; <nl> } <nl> <nl> public static CFMetaData fromThrift ( org . apache . cassandra . thrift . CfDef cf _ def ) throws InvalidRequestException , ConfigurationException <nl> @ @ - 1112 , 8 + 1041 , 8 @ @ public final class CFMetaData <nl> newCFMD . bloomFilterFpChance ( cf _ def . bloom _ filter _ fp _ chance ) ; <nl> if ( cf _ def . isSetMemtable _ flush _ period _ in _ ms ( ) ) <nl> newCFMD . memtableFlushPeriod ( cf _ def . memtable _ flush _ period _ in _ ms ) ; <nl> - if ( cf _ def . isSetCaching ( ) ) <nl> - newCFMD . caching ( Caching . fromString ( cf _ def . caching ) ) ; <nl> + if ( cf _ def . isSetCaching ( ) | | cf _ def . isSetCells _ per _ row _ to _ cache ( ) ) <nl> + newCFMD . caching ( CachingOptions . fromThrift ( cf _ def . caching , cf _ def . cells _ per _ row _ to _ cache ) ) ; <nl> if ( cf _ def . isSetRead _ repair _ chance ( ) ) <nl> newCFMD . readRepairChance ( cf _ def . read _ repair _ chance ) ; <nl> if ( cf _ def . isSetDefault _ time _ to _ live ( ) ) <nl> @ @ - 1130 , 8 + 1059 , 6 @ @ public final class CFMetaData <nl> newCFMD . populateIoCacheOnFlush ( cf _ def . populate _ io _ cache _ on _ flush ) ; <nl> if ( cf _ def . isSetTriggers ( ) ) <nl> newCFMD . triggers ( TriggerDefinition . fromThrift ( cf _ def . triggers ) ) ; <nl> - if ( cf _ def . isSetCells _ per _ row _ to _ cache ( ) ) <nl> - newCFMD . rowsPerPartitionToCache ( RowsPerPartitionToCache . fromString ( cf _ def . cells _ per _ row _ to _ cache ) ) ; <nl> <nl> CompressionParameters cp = CompressionParameters . create ( cf _ def . compression _ options ) ; <nl> <nl> @ @ - 1229 , 7 + 1156 , 6 @ @ public final class CFMetaData <nl> minIndexInterval = cfm . minIndexInterval ; <nl> maxIndexInterval = cfm . maxIndexInterval ; <nl> memtableFlushPeriod = cfm . memtableFlushPeriod ; <nl> - rowsPerPartitionToCache = cfm . rowsPerPartitionToCache ; <nl> defaultTimeToLive = cfm . defaultTimeToLive ; <nl> speculativeRetry = cfm . speculativeRetry ; <nl> populateIoCacheOnFlush = cfm . populateIoCacheOnFlush ; <nl> @ @ - 1378 , 8 + 1304 , 8 @ @ public final class CFMetaData <nl> def . setMin _ index _ interval ( minIndexInterval ) ; <nl> def . setMax _ index _ interval ( maxIndexInterval ) ; <nl> def . setMemtable _ flush _ period _ in _ ms ( memtableFlushPeriod ) ; <nl> - def . setCaching ( caching . toString ( ) ) ; <nl> - def . setCells _ per _ row _ to _ cache ( rowsPerPartitionToCache . toString ( ) ) ; <nl> + def . setCaching ( caching . toThriftCaching ( ) ) ; <nl> + def . setCells _ per _ row _ to _ cache ( caching . toThriftCellsPerRow ( ) ) ; <nl> def . setDefault _ time _ to _ live ( defaultTimeToLive ) ; <nl> def . setSpeculative _ retry ( speculativeRetry . toString ( ) ) ; <nl> def . setTriggers ( TriggerDefinition . toThrift ( triggers ) ) ; <nl> @ @ - 1748 , 7 + 1674 , 6 @ @ public final class CFMetaData <nl> <nl> adder . add ( " memtable _ flush _ period _ in _ ms " , memtableFlushPeriod ) ; <nl> adder . add ( " caching " , caching . toString ( ) ) ; <nl> - adder . add ( " rows _ per _ partition _ to _ cache " , rowsPerPartitionToCache . toString ( ) ) ; <nl> adder . add ( " default _ time _ to _ live " , defaultTimeToLive ) ; <nl> adder . add ( " compaction _ strategy _ class " , compactionStrategyClass . getName ( ) ) ; <nl> adder . add ( " compression _ parameters " , json ( compressionParameters . asThriftOptions ( ) ) ) ; <nl> @ @ - 1815 , 9 + 1740 , 7 @ @ public final class CFMetaData <nl> cfm . bloomFilterFpChance ( result . getDouble ( " bloom _ filter _ fp _ chance " ) ) ; <nl> if ( result . has ( " memtable _ flush _ period _ in _ ms " ) ) <nl> cfm . memtableFlushPeriod ( result . getInt ( " memtable _ flush _ period _ in _ ms " ) ) ; <nl> - cfm . caching ( Caching . valueOf ( result . getString ( " caching " ) ) ) ; <nl> - if ( result . has ( " rows _ per _ partition _ to _ cache " ) ) <nl> - cfm . rowsPerPartitionToCache ( RowsPerPartitionToCache . fromString ( result . getString ( " rows _ per _ partition _ to _ cache " ) ) ) ; <nl> + cfm . caching ( CachingOptions . fromString ( result . getString ( " caching " ) ) ) ; <nl> if ( result . has ( " default _ time _ to _ live " ) ) <nl> cfm . defaultTimeToLive ( result . getInt ( " default _ time _ to _ live " ) ) ; <nl> if ( result . has ( " speculative _ retry " ) ) <nl> @ @ - 2312 , 7 + 2235 , 6 @ @ public final class CFMetaData <nl> . append ( " populateIoCacheOnFlush " , populateIoCacheOnFlush ) <nl> . append ( " droppedColumns " , droppedColumns ) <nl> . append ( " triggers " , triggers ) <nl> - . append ( " rowsPerPartitionToCache " , rowsPerPartitionToCache ) <nl> . toString ( ) ; <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / cql / AlterTableStatement . java b / src / java / org / apache / cassandra / cql / AlterTableStatement . java <nl> index 2fda212 . . 034f660 100644 <nl> - - - a / src / java / org / apache / cassandra / cql / AlterTableStatement . java <nl> + + + b / src / java / org / apache / cassandra / cql / AlterTableStatement . java <nl> @ @ - 17 , 6 + 17 , 7 @ @ <nl> * / <nl> package org . apache . cassandra . cql ; <nl> <nl> + import org . apache . cassandra . cache . CachingOptions ; <nl> import org . apache . cassandra . config . * ; <nl> import org . apache . cassandra . db . marshal . TypeParser ; <nl> import org . apache . cassandra . exceptions . * ; <nl> @ @ - 179 , 8 + 180 , 7 @ @ public class AlterTableStatement <nl> throw new ConfigurationException ( " Disabling compaction by setting compaction thresholds to 0 has been deprecated , set the compaction option ' enabled ' to false instead . " ) ; <nl> cfm . minCompactionThreshold ( minCompactionThreshold ) ; <nl> cfm . maxCompactionThreshold ( maxCompactionThreshold ) ; <nl> - cfm . caching ( CFMetaData . Caching . fromString ( cfProps . getPropertyString ( CFPropDefs . KW _ CACHING , cfm . getCaching ( ) . toString ( ) ) ) ) ; <nl> - cfm . rowsPerPartitionToCache ( CFMetaData . RowsPerPartitionToCache . fromString ( cfProps . getPropertyString ( CFPropDefs . KW _ ROWS _ PER _ PARTITION _ TO _ CACHE , cfm . getRowsPerPartitionToCache ( ) . toString ( ) ) ) ) ; <nl> + cfm . caching ( CachingOptions . fromString ( cfProps . getPropertyString ( CFPropDefs . KW _ CACHING , cfm . getCaching ( ) . toString ( ) ) ) ) ; <nl> cfm . defaultTimeToLive ( cfProps . getPropertyInt ( CFPropDefs . KW _ DEFAULT _ TIME _ TO _ LIVE , cfm . getDefaultTimeToLive ( ) ) ) ; <nl> cfm . speculativeRetry ( CFMetaData . SpeculativeRetry . fromString ( cfProps . getPropertyString ( CFPropDefs . KW _ SPECULATIVE _ RETRY , cfm . getSpeculativeRetry ( ) . toString ( ) ) ) ) ; <nl> cfm . populateIoCacheOnFlush ( cfProps . getPropertyBoolean ( CFPropDefs . KW _ POPULATE _ IO _ CACHE _ ON _ FLUSH , cfm . populateIoCacheOnFlush ( ) ) ) ; <nl> diff - - git a / src / java / org / apache / cassandra / cql / CreateColumnFamilyStatement . java b / src / java / org / apache / cassandra / cql / CreateColumnFamilyStatement . java <nl> index e568dd7 . . b483451 100644 <nl> - - - a / src / java / org / apache / cassandra / cql / CreateColumnFamilyStatement . java <nl> + + + b / src / java / org / apache / cassandra / cql / CreateColumnFamilyStatement . java <nl> @ @ - 24 , 6 + 24 , 7 @ @ import java . util . List ; <nl> import java . util . Map ; <nl> import java . util . Set ; <nl> <nl> + import org . apache . cassandra . cache . CachingOptions ; <nl> import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . ColumnDefinition ; <nl> import org . apache . cassandra . db . composites . SimpleDenseCellNameType ; <nl> @ @ - 196 , 8 + 197 , 7 @ @ public class CreateColumnFamilyStatement <nl> . compactionStrategyClass ( cfProps . compactionStrategyClass ) <nl> . compactionStrategyOptions ( cfProps . compactionStrategyOptions ) <nl> . compressionParameters ( CompressionParameters . create ( cfProps . compressionParameters ) ) <nl> - . caching ( CFMetaData . Caching . fromString ( getPropertyString ( CFPropDefs . KW _ CACHING , CFMetaData . DEFAULT _ CACHING _ STRATEGY . toString ( ) ) ) ) <nl> - . rowsPerPartitionToCache ( CFMetaData . RowsPerPartitionToCache . fromString ( cfProps . getPropertyString ( CFPropDefs . KW _ ROWS _ PER _ PARTITION _ TO _ CACHE , CFMetaData . DEFAULT _ ROWS _ PER _ PARTITION _ TO _ CACHE . toString ( ) ) ) ) <nl> + . caching ( CachingOptions . fromString ( getPropertyString ( CFPropDefs . KW _ CACHING , CFMetaData . DEFAULT _ CACHING _ STRATEGY . toString ( ) ) ) ) <nl> . speculativeRetry ( CFMetaData . SpeculativeRetry . fromString ( getPropertyString ( CFPropDefs . KW _ SPECULATIVE _ RETRY , CFMetaData . DEFAULT _ SPECULATIVE _ RETRY . toString ( ) ) ) ) <nl> . bloomFilterFpChance ( getPropertyDouble ( CFPropDefs . KW _ BF _ FP _ CHANCE , null ) ) <nl> . memtableFlushPeriod ( getPropertyInt ( CFPropDefs . KW _ MEMTABLE _ FLUSH _ PERIOD , 0 ) ) <nl> diff - - git a / src / java / org / apache / cassandra / cql3 / statements / CFPropDefs . java b / src / java / org / apache / cassandra / cql3 / statements / CFPropDefs . java <nl> index f473e22 . . 95fb750 100644 <nl> - - - a / src / java / org / apache / cassandra / cql3 / statements / CFPropDefs . java <nl> + + + b / src / java / org / apache / cassandra / cql3 / statements / CFPropDefs . java <nl> @ @ - 19 , 6 + 19 , 7 @ @ package org . apache . cassandra . cql3 . statements ; <nl> <nl> import java . util . * ; <nl> <nl> + import org . apache . cassandra . cache . CachingOptions ; <nl> import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . CFMetaData . SpeculativeRetry ; <nl> import org . apache . cassandra . db . compaction . AbstractCompactionStrategy ; <nl> @ @ - 149 , 6 + 150 , 21 @ @ public class CFPropDefs extends PropertyDefinitions <nl> return new HashMap < > ( ) ; <nl> return compressionOptions ; <nl> } <nl> + public CachingOptions getCachingOptions ( ) throws SyntaxException , ConfigurationException <nl> + { <nl> + CachingOptions options = null ; <nl> + Object val = properties . get ( KW _ CACHING ) ; <nl> + if ( val = = null ) <nl> + return null ; <nl> + else if ( val instanceof Map ) <nl> + options = CachingOptions . fromMap ( getMap ( KW _ CACHING ) ) ; <nl> + else if ( val instanceof String ) / / legacy syntax <nl> + { <nl> + options = CachingOptions . fromString ( getSimple ( KW _ CACHING ) ) ; <nl> + logger . warn ( " Setting caching options with deprecated syntax . " ) ; <nl> + } <nl> + return options ; <nl> + } <nl> <nl> public void applyToCFMetadata ( CFMetaData cfm ) throws ConfigurationException , SyntaxException <nl> { <nl> @ @ - 164 , 12 + 180 , 6 @ @ public class CFPropDefs extends PropertyDefinitions <nl> throw new ConfigurationException ( " Disabling compaction by setting compaction thresholds to 0 has been deprecated , set the compaction option ' enabled ' to false instead . " ) ; <nl> cfm . minCompactionThreshold ( minCompactionThreshold ) ; <nl> cfm . maxCompactionThreshold ( maxCompactionThreshold ) ; <nl> - cfm . caching ( CFMetaData . Caching . fromString ( getString ( KW _ CACHING , cfm . getCaching ( ) . toString ( ) ) ) ) ; <nl> - CFMetaData . RowsPerPartitionToCache newRppc = CFMetaData . RowsPerPartitionToCache . fromString ( getString ( KW _ ROWS _ PER _ PARTITION _ TO _ CACHE , cfm . getRowsPerPartitionToCache ( ) . toString ( ) ) ) ; <nl> - / / we need to invalidate row cache if the amount of rows cached changes , otherwise we might serve out bad data . <nl> - if ( ! cfm . getRowsPerPartitionToCache ( ) . equals ( newRppc ) ) <nl> - CacheService . instance . invalidateRowCacheForCf ( cfm . cfId ) ; <nl> - cfm . rowsPerPartitionToCache ( newRppc ) ; <nl> cfm . defaultTimeToLive ( getInt ( KW _ DEFAULT _ TIME _ TO _ LIVE , cfm . getDefaultTimeToLive ( ) ) ) ; <nl> cfm . speculativeRetry ( CFMetaData . SpeculativeRetry . fromString ( getString ( KW _ SPECULATIVE _ RETRY , cfm . getSpeculativeRetry ( ) . toString ( ) ) ) ) ; <nl> cfm . memtableFlushPeriod ( getInt ( KW _ MEMTABLE _ FLUSH _ PERIOD , cfm . getMemtableFlushPeriod ( ) ) ) ; <nl> @ @ - 187 , 6 + 197 , 9 @ @ public class CFPropDefs extends PropertyDefinitions <nl> <nl> if ( ! getCompressionOptions ( ) . isEmpty ( ) ) <nl> cfm . compressionParameters ( CompressionParameters . create ( getCompressionOptions ( ) ) ) ; <nl> + CachingOptions cachingOptions = getCachingOptions ( ) ; <nl> + if ( cachingOptions ! = null ) <nl> + cfm . caching ( cachingOptions ) ; <nl> } <nl> <nl> @ Override <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index 8d064dd . . 34aa5f5 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 77 , 8 + 77 , 6 @ @ import org . apache . cassandra . tracing . Tracing ; <nl> import org . apache . cassandra . utils . * ; <nl> import org . apache . cassandra . utils . concurrent . OpOrder ; <nl> <nl> - import static org . apache . cassandra . config . CFMetaData . Caching ; <nl> - <nl> public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> { <nl> private static final Logger logger = LoggerFactory . getLogger ( ColumnFamilyStore . class ) ; <nl> @ @ - 276 , 7 + 274 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> fileIndexGenerator . set ( generation ) ; <nl> sampleLatencyNanos = DatabaseDescriptor . getReadRpcTimeout ( ) / 2 ; <nl> <nl> - Caching caching = metadata . getCaching ( ) ; <nl> + CachingOptions caching = metadata . getCaching ( ) ; <nl> <nl> logger . info ( " Initializing { } . { } " , keyspace . getName ( ) , name ) ; <nl> <nl> @ @ - 290 , 7 + 288 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> data . addInitialSSTables ( sstables ) ; <nl> } <nl> <nl> - if ( caching = = Caching . ALL | | caching = = Caching . KEYS _ ONLY ) <nl> + if ( caching . keyCache . isEnabled ( ) ) <nl> CacheService . instance . keyCache . loadSaved ( this ) ; <nl> <nl> / / compaction strategy should be created after the CFS has been prepared <nl> @ @ - 1498 , 7 + 1496 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> try <nl> { <nl> / / If we are explicitely asked to fill the cache with full partitions , we go ahead and query the whole thing <nl> - if ( metadata . getRowsPerPartitionToCache ( ) . cacheFullPartitions ( ) ) <nl> + if ( metadata . getCaching ( ) . rowCache . cacheFullPartitions ( ) ) <nl> { <nl> data = getTopLevelColumns ( QueryFilter . getIdentityFilter ( filter . key , name , filter . timestamp ) , Integer . MIN _ VALUE ) ; <nl> toCache = data ; <nl> @ @ - 1521 , 7 + 1519 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> if ( filter . filter . isHeadFilter ( ) & & filter . filter . countCQL3Rows ( metadata . comparator ) ) <nl> { <nl> SliceQueryFilter sliceFilter = ( SliceQueryFilter ) filter . filter ; <nl> - int rowsToCache = metadata . getRowsPerPartitionToCache ( ) . rowsToCache ; <nl> + int rowsToCache = metadata . getCaching ( ) . rowCache . rowsToCache ; <nl> <nl> SliceQueryFilter cacheSlice = readFilterForCache ( ) ; <nl> QueryFilter cacheFilter = new QueryFilter ( filter . key , name , cacheSlice , filter . timestamp ) ; <nl> @ @ - 1578 , 7 + 1576 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> public SliceQueryFilter readFilterForCache ( ) <nl> { <nl> / / We create a new filter everytime before for now SliceQueryFilter is unfortunatly mutable . <nl> - return new SliceQueryFilter ( ColumnSlice . ALL _ COLUMNS _ ARRAY , false , metadata . getRowsPerPartitionToCache ( ) . rowsToCache , metadata . clusteringColumns ( ) . size ( ) ) ; <nl> + return new SliceQueryFilter ( ColumnSlice . ALL _ COLUMNS _ ARRAY , false , metadata . getCaching ( ) . rowCache . rowsToCache , metadata . clusteringColumns ( ) . size ( ) ) ; <nl> } <nl> <nl> public boolean isFilterFullyCoveredBy ( IDiskAtomFilter filter , ColumnFamily cachedCf , long now ) <nl> @ @ - 1592 , 7 + 1590 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> / / columns : if we use a timestamp newer than the one that was used when populating the cache , we might <nl> / / end up deciding the whole partition is cached when it ' s really not ( just some rows expired since the <nl> / / cf was cached ) . This is the reason for Integer . MIN _ VALUE below . <nl> - boolean wholePartitionCached = cachedCf . liveCQL3RowCount ( Integer . MIN _ VALUE ) < metadata . getRowsPerPartitionToCache ( ) . rowsToCache ; <nl> + boolean wholePartitionCached = cachedCf . liveCQL3RowCount ( Integer . MIN _ VALUE ) < metadata . getCaching ( ) . rowCache . rowsToCache ; <nl> <nl> / / Contrarily to the " wholePartitionCached " check above , we do want isFullyCoveredBy to take the <nl> / / timestamp of the query into account when dealing with expired columns . Otherwise , we could think <nl> @ @ - 2674 , 9 + 2672 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> <nl> private boolean isRowCacheEnabled ( ) <nl> { <nl> - return ! ( metadata . getCaching ( ) = = Caching . NONE <nl> - | | metadata . getCaching ( ) = = Caching . KEYS _ ONLY <nl> - | | CacheService . instance . rowCache . getCapacity ( ) = = 0 ) ; <nl> + return metadata . getCaching ( ) . rowCache . isEnabled ( ) & & CacheService . instance . rowCache . getCapacity ( ) > 0 ; <nl> } <nl> <nl> / * * <nl> diff - - git a / src / java / org / apache / cassandra / db / SystemKeyspace . java b / src / java / org / apache / cassandra / db / SystemKeyspace . java <nl> index 292d3da . . 0273341 100644 <nl> - - - a / src / java / org / apache / cassandra / db / SystemKeyspace . java <nl> + + + b / src / java / org / apache / cassandra / db / SystemKeyspace . java <nl> @ @ - 33 , 6 + 33 , 7 @ @ import org . apache . commons . lang3 . StringUtils ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> + import org . apache . cassandra . cache . CachingOptions ; <nl> import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . config . KSMetaData ; <nl> @ @ - 112 , 7 + 113 , 7 @ @ public class SystemKeyspace <nl> setupVersion ( ) ; <nl> <nl> migrateIndexInterval ( ) ; <nl> - <nl> + migrateCachingOption ( ) ; <nl> / / add entries to system schema columnfamilies for the hardcoded system definitions <nl> for ( String ksname : Schema . systemKeyspaceNames ) <nl> { <nl> @ @ - 175 , 6 + 176 , 36 @ @ public class SystemKeyspace <nl> } <nl> } <nl> <nl> + private static void migrateCachingOption ( ) <nl> + { <nl> + for ( UntypedResultSet . Row row : processInternal ( String . format ( " SELECT * FROM system . % s " , SCHEMA _ COLUMNFAMILIES _ CF ) ) ) <nl> + { <nl> + if ( ! row . has ( " caching " ) ) <nl> + continue ; <nl> + <nl> + if ( ! CachingOptions . isLegacy ( row . getString ( " caching " ) ) ) <nl> + continue ; <nl> + try <nl> + { <nl> + CachingOptions caching = CachingOptions . fromString ( row . getString ( " caching " ) ) ; <nl> + CFMetaData table = CFMetaData . fromSchema ( row ) ; <nl> + logger . info ( " Migrating caching option { } to { } for { } . { } " , row . getString ( " caching " ) , caching . toString ( ) , table . ksName , table . cfName ) ; <nl> + String query = String . format ( " SELECT writetime ( type ) " <nl> + + " FROM system . % s " <nl> + + " WHERE keyspace _ name = ' % s ' AND columnfamily _ name = ' % s ' " , <nl> + SCHEMA _ COLUMNFAMILIES _ CF , <nl> + table . ksName , <nl> + table . cfName ) ; <nl> + long timestamp = processInternal ( query ) . one ( ) . getLong ( " writetime ( type ) " ) ; <nl> + table . toSchema ( timestamp ) . apply ( ) ; <nl> + } <nl> + catch ( ConfigurationException e ) <nl> + { <nl> + / / shouldn ' t happen <nl> + } <nl> + } <nl> + } <nl> + <nl> / * * <nl> * Write compaction log , except columfamilies under system keyspace . <nl> * <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> index c02e397 . . 17e9b8f 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java <nl> @ @ - 36 , 6 + 36 , 7 @ @ import com . google . common . util . concurrent . RateLimiter ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> + import org . apache . cassandra . cache . CachingOptions ; <nl> import org . apache . cassandra . cache . InstrumentingCache ; <nl> import org . apache . cassandra . cache . KeyCacheKey ; <nl> import org . apache . cassandra . concurrent . DebuggableThreadPoolExecutor ; <nl> @ @ - 1068 , 10 + 1069 , 9 @ @ public class SSTableReader extends SSTable implements Closeable <nl> <nl> public void cacheKey ( DecoratedKey key , RowIndexEntry info ) <nl> { <nl> - CFMetaData . Caching caching = metadata . getCaching ( ) ; <nl> + CachingOptions caching = metadata . getCaching ( ) ; <nl> <nl> - if ( caching = = CFMetaData . Caching . NONE <nl> - | | caching = = CFMetaData . Caching . ROWS _ ONLY <nl> + if ( ! caching . keyCache . isEnabled ( ) <nl> | | keyCache = = null <nl> | | keyCache . getCapacity ( ) = = 0 ) <nl> { <nl> diff - - git a / test / unit / org / apache / cassandra / SchemaLoader . java b / test / unit / org / apache / cassandra / SchemaLoader . java <nl> index f67386a . . 5fb5697 100644 <nl> - - - a / test / unit / org / apache / cassandra / SchemaLoader . java <nl> + + + b / test / unit / org / apache / cassandra / SchemaLoader . java <nl> @ @ - 21 , 6 + 21 , 7 @ @ import java . io . File ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> <nl> + import org . apache . cassandra . cache . CachingOptions ; <nl> import org . apache . cassandra . db . index . PerRowSecondaryIndexTest ; <nl> import org . apache . cassandra . db . index . SecondaryIndex ; <nl> import org . junit . AfterClass ; <nl> @ @ - 164 , 7 + 165 , 9 @ @ public class SchemaLoader <nl> standardCFMD ( ks1 , " legacyleveled " ) <nl> . compactionStrategyClass ( LeveledCompactionStrategy . class ) <nl> . compactionStrategyOptions ( leveledOptions ) , <nl> - standardCFMD ( ks1 , " StandardLowIndexInterval " ) . minIndexInterval ( 8 ) . maxIndexInterval ( 256 ) . caching ( CFMetaData . Caching . NONE ) ) ) ; <nl> + standardCFMD ( ks1 , " StandardLowIndexInterval " ) . minIndexInterval ( 8 ) <nl> + . maxIndexInterval ( 256 ) <nl> + . caching ( CachingOptions . NONE ) ) ) ; <nl> <nl> <nl> / / Keyspace 2 <nl> @ @ - 228 , 9 + 231 , 12 @ @ public class SchemaLoader <nl> schema . add ( KSMetaData . testMetadata ( ks _ rcs , <nl> simple , <nl> opts _ rf1 , <nl> - standardCFMD ( ks _ rcs , " CFWithoutCache " ) . caching ( CFMetaData . Caching . NONE ) , <nl> - standardCFMD ( ks _ rcs , " CachedCF " ) . caching ( CFMetaData . Caching . ALL ) . rowsPerPartitionToCache ( CFMetaData . RowsPerPartitionToCache . fromString ( " ALL " ) ) , <nl> - standardCFMD ( ks _ rcs , " CachedIntCF " ) . defaultValidator ( IntegerType . instance ) . caching ( CFMetaData . Caching . ALL ) ) ) ; <nl> + standardCFMD ( ks _ rcs , " CFWithoutCache " ) . caching ( CachingOptions . NONE ) , <nl> + standardCFMD ( ks _ rcs , " CachedCF " ) . caching ( CachingOptions . ALL ) , <nl> + standardCFMD ( ks _ rcs , " CachedIntCF " ) . <nl> + defaultValidator ( IntegerType . instance ) . <nl> + caching ( new CachingOptions ( new CachingOptions . KeyCache ( CachingOptions . KeyCache . Type . ALL ) , <nl> + new CachingOptions . RowCache ( CachingOptions . RowCache . Type . HEAD , 100 ) ) ) ) ) ; <nl> <nl> / / CounterCacheSpace <nl> schema . add ( KSMetaData . testMetadata ( ks _ ccs ,
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index b993c48 . . 36050c5 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 15 , 6 + 15 , 7 @ @ dev <nl> * include jna dependency in RPM package ( CASSANDRA - 1690 ) <nl> * add - - skip - keys option to stress . py ( CASSANDRA - 1696 ) <nl> * improve cli handling of non - string column names ( CASSANDRA - 1701 ) <nl> + * enable skipping bad rows on LazilyCompacted path ( CASSANDRA - 1702 ) <nl> <nl> <nl> 0 . 7 . 0 - beta3 <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnSerializer . java b / src / java / org / apache / cassandra / db / ColumnSerializer . java <nl> index 34ac0ac . . 569289d 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnSerializer . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnSerializer . java <nl> @ @ - 64 , 6 + 64 , 9 @ @ public class ColumnSerializer implements ICompactSerializer2 < IColumn > <nl> public Column deserialize ( DataInput dis ) throws IOException <nl> { <nl> ByteBuffer name = FBUtilities . readShortByteArray ( dis ) ; <nl> + if ( name . remaining ( ) < = 0 ) <nl> + throw new CorruptColumnException ( " invalid column name length " + name . remaining ( ) ) ; <nl> + <nl> int b = dis . readUnsignedByte ( ) ; <nl> if ( ( b & EXPIRATION _ MASK ) ! = 0 ) <nl> { <nl> @ @ - 97 , 4 + 100 , 12 @ @ public class ColumnSerializer implements ICompactSerializer2 < IColumn > <nl> } <nl> } <nl> } <nl> + <nl> + private static class CorruptColumnException extends IOException <nl> + { <nl> + public CorruptColumnException ( String s ) <nl> + { <nl> + super ( s ) ; <nl> + } <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> index 057f4a2 . . 077914e 100644 <nl> - - - a / src / java / org / apache / cassandra / db / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> @ @ - 272 , 16 + 272 , 21 @ @ public class CompactionManager implements CompactionManagerMBean <nl> writer = new SSTableWriter ( newFilename , expectedBloomFilterSize , cfs . metadata , cfs . partitioner ) ; <nl> while ( nni . hasNext ( ) ) <nl> { <nl> - AbstractCompactedRow row = nni . next ( ) ; <nl> + writer . mark ( ) ; <nl> try <nl> { <nl> + AbstractCompactedRow row = nni . next ( ) ; <nl> writer . append ( row ) ; <nl> } <nl> - catch ( IOException ex ) <nl> + catch ( Exception e ) <nl> + { <nl> + logger . error ( " non - fatal error during compaction " , e ) ; <nl> + writer . reset ( ) ; <nl> + } <nl> + catch ( IOError e ) <nl> { <nl> - writer . abort ( ) ; <nl> - / / rethrow the exception so that caller knows compaction failed . <nl> - throw ex ; <nl> + logger . error ( " non - fatal error during compaction " , e ) ; <nl> + writer . reset ( ) ; <nl> } <nl> totalkeysWritten + + ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> index 4b3b5f0 . . 523a2c4 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> @ @ - 38 , 6 + 38 , 7 @ @ import org . apache . cassandra . dht . IPartitioner ; <nl> import org . apache . cassandra . io . AbstractCompactedRow ; <nl> import org . apache . cassandra . io . ICompactionInfo ; <nl> import org . apache . cassandra . io . util . BufferedRandomAccessFile ; <nl> + import org . apache . cassandra . io . util . FileMark ; <nl> import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . io . util . SegmentedFile ; <nl> import org . apache . cassandra . service . StorageService ; <nl> @ @ - 55 , 6 + 56 , 7 @ @ public class SSTableWriter extends SSTable <nl> private SegmentedFile . Builder dbuilder ; <nl> private final BufferedRandomAccessFile dataFile ; <nl> private DecoratedKey lastWrittenKey ; <nl> + private FileMark dataMark ; <nl> <nl> public SSTableWriter ( String filename , long keyCount ) throws IOException <nl> { <nl> @ @ - 99 , 6 + 101 , 25 @ @ public class SSTableWriter extends SSTable <nl> } <nl> } <nl> <nl> + public void mark ( ) <nl> + { <nl> + dataMark = dataFile . mark ( ) ; <nl> + iwriter . mark ( ) ; <nl> + } <nl> + <nl> + public void reset ( ) <nl> + { <nl> + try <nl> + { <nl> + dataFile . reset ( dataMark ) ; <nl> + iwriter . reset ( ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new IOError ( e ) ; <nl> + } <nl> + } <nl> + <nl> private long beforeAppend ( DecoratedKey decoratedKey ) throws IOException <nl> { <nl> if ( decoratedKey = = null ) <nl> @ @ - 121 , 8 + 142 , 8 @ @ public class SSTableWriter extends SSTable <nl> <nl> if ( logger . isTraceEnabled ( ) ) <nl> logger . trace ( " wrote " + decoratedKey + " at " + dataPosition ) ; <nl> - dbuilder . addPotentialBoundary ( dataPosition ) ; <nl> iwriter . afterAppend ( decoratedKey , dataPosition ) ; <nl> + dbuilder . addPotentialBoundary ( dataPosition ) ; <nl> } <nl> <nl> public void append ( AbstractCompactedRow row ) throws IOException <nl> @ @ - 176 , 7 + 197 , 9 @ @ public class SSTableWriter extends SSTable <nl> iwriter . close ( ) ; <nl> <nl> / / main data <nl> + long position = dataFile . getFilePointer ( ) ; <nl> dataFile . close ( ) ; / / calls force <nl> + FileUtils . truncate ( dataFile . getPath ( ) , position ) ; <nl> <nl> / / write sstable statistics <nl> writeStatistics ( descriptor , estimatedRowSize , estimatedColumnCount ) ; <nl> @ @ - 358 , 7 + 381 , 8 @ @ public class SSTableWriter extends SSTable <nl> public final SegmentedFile . Builder builder ; <nl> public final IndexSummary summary ; <nl> public final BloomFilter bf ; <nl> - <nl> + private FileMark mark ; <nl> + <nl> IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException <nl> { <nl> this . desc = desc ; <nl> @ @ - 396 , 11 + 420 , 25 @ @ public class SSTableWriter extends SSTable <nl> stream . close ( ) ; <nl> <nl> / / index <nl> - indexFile . getChannel ( ) . force ( true ) ; <nl> - indexFile . close ( ) ; <nl> + long position = indexFile . getFilePointer ( ) ; <nl> + indexFile . close ( ) ; / / calls force <nl> + FileUtils . truncate ( indexFile . getPath ( ) , position ) ; <nl> <nl> / / finalize in - memory index state <nl> summary . complete ( ) ; <nl> } <nl> + <nl> + public void mark ( ) <nl> + { <nl> + mark = indexFile . mark ( ) ; <nl> + } <nl> + <nl> + public void reset ( ) throws IOException <nl> + { <nl> + / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . <nl> + / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so <nl> + / / we assume that if that worked then we won ' t be trying to reset . <nl> + indexFile . reset ( mark ) ; <nl> + } <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / io / util / FileUtils . java b / src / java / org / apache / cassandra / io / util / FileUtils . java <nl> index e2ca78c . . 11c6b4b 100644 <nl> - - - a / src / java / org / apache / cassandra / io / util / FileUtils . java <nl> + + + b / src / java / org / apache / cassandra / io / util / FileUtils . java <nl> @ @ - 19 , 7 + 19 , 9 @ @ <nl> package org . apache . cassandra . io . util ; <nl> <nl> import java . io . File ; <nl> + import java . io . FileNotFoundException ; <nl> import java . io . IOException ; <nl> + import java . io . RandomAccessFile ; <nl> import java . text . DecimalFormat ; <nl> import java . util . Comparator ; <nl> import java . util . List ; <nl> @ @ - 27 , 9 + 29 , 6 @ @ import java . util . List ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> - import com . sun . jna . LastErrorException ; <nl> - import org . apache . cassandra . utils . CLibrary ; <nl> - <nl> <nl> public class FileUtils <nl> { <nl> @ @ - 65 , 6 + 64 , 20 @ @ public class FileUtils <nl> throw new IOException ( String . format ( " Failed to rename % s to % s " , from . getPath ( ) , to . getPath ( ) ) ) ; <nl> } <nl> <nl> + public static void truncate ( String path , long size ) throws IOException <nl> + { <nl> + RandomAccessFile file ; <nl> + try <nl> + { <nl> + file = new RandomAccessFile ( path , " rw " ) ; <nl> + } <nl> + catch ( FileNotFoundException e ) <nl> + { <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> + file . getChannel ( ) . truncate ( size ) ; <nl> + } <nl> + <nl> public static class FileComparator implements Comparator < File > <nl> { <nl> public int compare ( File f , File f2 )

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index d8eb3a1 . . 61e17e3 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 11 , 6 + 11 , 7 @ @ 
 * Improve handling of range tombstone for wide partitions ( CASSANDRA - 6446 ) 
 * Fix ClassCastException for compact table with composites ( CASSANDRA - 6738 ) 
 * Fix potentially repairing with wrong nodes ( CASSANDRA - 6808 ) 
 + * Change caching option syntax ( CASSANDRA - 6745 ) 
 Merged from 2 . 0 : 
 * Fix saving triggers to schema ( CASSANDRA - 6789 ) 
 * Fix trigger mutations when base mutation list is immutable ( CASSANDRA - 6790 ) 
 diff - - git a / pylib / cqlshlib / cql3handling . py b / pylib / cqlshlib / cql3handling . py 
 index 158e60d . . 3522d1c 100644 
 - - - a / pylib / cqlshlib / cql3handling . py 
 + + + b / pylib / cqlshlib / cql3handling . py 
 @ @ - 62 , 8 + 62 , 6 @ @ class Cql3ParsingRuleSet ( CqlParsingRuleSet ) : 
 
 columnfamily _ layout _ options = ( 
 ( ' bloom _ filter _ fp _ chance ' , None ) , 
 - ( ' caching ' , None ) , 
 - ( ' rows _ per _ partition _ to _ cache ' , None ) , 
 ( ' comment ' , None ) , 
 ( ' dclocal _ read _ repair _ chance ' , ' local _ read _ repair _ chance ' ) , 
 ( ' gc _ grace _ seconds ' , None ) , 
 @ @ - 83 , 6 + 81 , 8 @ @ class Cql3ParsingRuleSet ( CqlParsingRuleSet ) : 
 ( ' class ' , ' min _ threshold ' , ' max _ threshold ' ) ) , 
 ( ' compression ' , ' compression _ parameters ' , 
 ( ' sstable _ compression ' , ' chunk _ length _ kb ' , ' crc _ check _ chance ' ) ) , 
 + ( ' caching ' , None , 
 + ( ' rows _ per _ partition ' , ' keys ' ) ) , 
 ) 
 
 obsolete _ cf _ options = ( ) 
 @ @ - 463 , 6 + 463 , 8 @ @ def cf _ prop _ val _ mapkey _ completer ( ctxt , cass ) : 
 pairsseen = dict ( zip ( keysseen , valsseen ) ) 
 if optname = = ' compression ' : 
 return map ( escape _ value , set ( subopts ) . difference ( keysseen ) ) 
 + if optname = = ' caching ' : 
 + return map ( escape _ value , set ( subopts ) . difference ( keysseen ) ) 
 if optname = = ' compaction ' : 
 opts = set ( subopts ) 
 try : 
 @ @ - 488 , 6 + 490 , 11 @ @ def cf _ prop _ val _ mapval _ completer ( ctxt , cass ) : 
 if key = = ' sstable _ compression ' : 
 return map ( escape _ value , CqlRuleSet . available _ compression _ classes ) 
 return [ Hint ( ' < option _ value > ' ) ] 
 + elif opt = = ' caching ' : 
 + if key = = ' rows _ per _ partition ' : 
 + return [ Hint ( ' ALL ' ) , Hint ( ' NONE ' ) , Hint ( ' # rows _ per _ partition ' ) ] 
 + elif key = = ' keys ' : 
 + return [ Hint ( ' ALL ' ) , Hint ( ' NONE ' ) ] 
 return ( ) 
 
 def cf _ prop _ val _ mapender _ completer ( ctxt , cass ) : 
 @ @ - 1187 , 7 + 1194 , 7 @ @ class CqlTableDef : 
 for attr , val in layout . items ( ) : 
 setattr ( cf , attr . encode ( ' ascii ' ) , val ) 
 cf . comparator = lookup _ casstype ( cf . comparator ) 
 - for attr in ( ' compaction _ strategy _ options ' , ' compression _ parameters ' ) : 
 + for attr in ( ' compaction _ strategy _ options ' , ' compression _ parameters ' , ' caching ' ) : 
 setattr ( cf , attr , json . loads ( getattr ( cf , attr ) ) ) 
 
 # deal with columns , filter out empty column names ( see CASSANDRA - 6139 ) 
 diff - - git a / src / java / org / apache / cassandra / cache / CachingOptions . java b / src / java / org / apache / cassandra / cache / CachingOptions . java 
 new file mode 100644 
 index 0000000 . . 6eeaa37 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / cache / CachingOptions . java 
 @ @ - 0 , 0 + 1 , 288 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , software 
 + * distributed under the License is distributed on an " AS IS " BASIS , 
 + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + * See the License for the specific language governing permissions and 
 + * limitations under the License . 
 + * / 
 + package org . apache . cassandra . cache ; 
 + 
 + 
 + import java . util . Arrays ; 
 + import java . util . HashSet ; 
 + import java . util . Map ; 
 + import java . util . Set ; 
 + import org . apache . commons . lang3 . StringUtils ; 
 + 
 + import org . apache . cassandra . exceptions . ConfigurationException ; 
 + import static org . apache . cassandra . utils . FBUtilities . fromJsonMap ; 
 + 
 + / * 
 + CQL : { ' keys ' : ' ALL | NONE ' , ' rows _ per _ partition ' : ' 200 | NONE | ALL ' } 
 + * / 
 + public class CachingOptions 
 + { 
 + public static final CachingOptions KEYS _ ONLY = new CachingOptions ( new KeyCache ( KeyCache . Type . ALL ) , new RowCache ( RowCache . Type . NONE ) ) ; 
 + public static final CachingOptions ALL = new CachingOptions ( new KeyCache ( KeyCache . Type . ALL ) , new RowCache ( RowCache . Type . ALL ) ) ; 
 + public static final CachingOptions ROWS _ ONLY = new CachingOptions ( new KeyCache ( KeyCache . Type . NONE ) , new RowCache ( RowCache . Type . ALL ) ) ; 
 + public static final CachingOptions NONE = new CachingOptions ( new KeyCache ( KeyCache . Type . NONE ) , new RowCache ( RowCache . Type . NONE ) ) ; 
 + 
 + public final KeyCache keyCache ; 
 + public final RowCache rowCache ; 
 + private static final Set < String > legacyOptions = new HashSet < > ( Arrays . asList ( " ALL " , " NONE " , " KEYS _ ONLY " , " ROWS _ ONLY " ) ) ; 
 + 
 + public CachingOptions ( KeyCache kc , RowCache rc ) 
 + { 
 + this . keyCache = kc ; 
 + this . rowCache = rc ; 
 + } 
 + 
 + public static CachingOptions fromString ( String cache ) throws ConfigurationException 
 + { 
 + if ( legacyOptions . contains ( cache . toUpperCase ( ) ) ) 
 + return fromLegacyOption ( cache . toUpperCase ( ) ) ; 
 + return fromMap ( fromJsonMap ( cache ) ) ; 
 + } 
 + 
 + public static CachingOptions fromMap ( Map < String , String > cacheConfig ) throws ConfigurationException 
 + { 
 + validateCacheConfig ( cacheConfig ) ; 
 + if ( ! cacheConfig . containsKey ( " keys " ) & & ! cacheConfig . containsKey ( " rows _ per _ partition " ) ) 
 + return CachingOptions . NONE ; 
 + if ( ! cacheConfig . containsKey ( " keys " ) ) 
 + return new CachingOptions ( new KeyCache ( KeyCache . Type . NONE ) , RowCache . fromString ( cacheConfig . get ( " rows _ per _ partition " ) ) ) ; 
 + if ( ! cacheConfig . containsKey ( " rows _ per _ partition " ) ) 
 + return CachingOptions . KEYS _ ONLY ; 
 + 
 + return new CachingOptions ( KeyCache . fromString ( cacheConfig . get ( " keys " ) ) , RowCache . fromString ( cacheConfig . get ( " rows _ per _ partition " ) ) ) ; 
 + } 
 + 
 + private static void validateCacheConfig ( Map < String , String > cacheConfig ) throws ConfigurationException 
 + { 
 + for ( Map . Entry < String , String > entry : cacheConfig . entrySet ( ) ) 
 + { 
 + String value = entry . getValue ( ) . toUpperCase ( ) ; 
 + if ( entry . getKey ( ) . equals ( " keys " ) ) 
 + { 
 + if ( ! ( value . equals ( " ALL " ) | | value . equals ( " NONE " ) ) ) 
 + { 
 + throw new ConfigurationException ( " ' keys ' can only have values ' ALL ' or ' NONE ' " ) ; 
 + } 
 + } 
 + else if ( entry . getKey ( ) . equals ( " rows _ per _ partition " ) ) 
 + { 
 + if ( ! ( value . equals ( " ALL " ) | | value . equals ( " NONE " ) | | StringUtils . isNumeric ( value ) ) ) 
 + { 
 + throw new ConfigurationException ( " ' rows _ per _ partition ' can only have values ' ALL ' , ' NONE ' or be numeric . " ) ; 
 + } 
 + } 
 + else 
 + throw new ConfigurationException ( " Only supported CachingOptions parameters are ' keys ' and ' rows _ per _ partition ' " ) ; 
 + } 
 + } 
 + 
 + @ Override 
 + public String toString ( ) 
 + { 
 + return String . format ( " { \ " keys \ " : \ " % s \ " , \ " rows _ per _ partition \ " : \ " % s \ " } " , keyCache . toString ( ) , rowCache . toString ( ) ) ; 
 + } 
 + 
 + private static CachingOptions fromLegacyOption ( String cache ) 
 + { 
 + if ( cache . equals ( " ALL " ) ) 
 + return ALL ; 
 + if ( cache . equals ( " KEYS _ ONLY " ) ) 
 + return KEYS _ ONLY ; 
 + if ( cache . equals ( " ROWS _ ONLY " ) ) 
 + return ROWS _ ONLY ; 
 + return NONE ; 
 + } 
 + 
 + @ Override 
 + public boolean equals ( Object o ) 
 + { 
 + if ( this = = o ) return true ; 
 + if ( o = = null | | getClass ( ) ! = o . getClass ( ) ) return false ; 
 + 
 + CachingOptions o2 = ( CachingOptions ) o ; 
 + 
 + if ( ! keyCache . equals ( o2 . keyCache ) ) return false ; 
 + if ( ! rowCache . equals ( o2 . rowCache ) ) return false ; 
 + 
 + return true ; 
 + } 
 + 
 + @ Override 
 + public int hashCode ( ) 
 + { 
 + int result = keyCache . hashCode ( ) ; 
 + result = 31 * result + rowCache . hashCode ( ) ; 
 + return result ; 
 + } 
 + 
 + public static boolean isLegacy ( String CachingOptions ) 
 + { 
 + return legacyOptions . contains ( CachingOptions . toUpperCase ( ) ) ; 
 + } 
 + 
 + public static CachingOptions fromThrift ( String caching , String cellsPerRow ) throws ConfigurationException 
 + { 
 + 
 + RowCache rc = new RowCache ( RowCache . Type . NONE ) ; 
 + KeyCache kc = new KeyCache ( KeyCache . Type . ALL ) ; 
 + / / if we get a caching string from thrift it is legacy , " ALL " , " KEYS _ ONLY " etc , fromString handles those 
 + if ( caching ! = null ) 
 + { 
 + CachingOptions givenOptions = CachingOptions . fromString ( caching ) ; 
 + rc = givenOptions . rowCache ; 
 + kc = givenOptions . keyCache ; 
 + } 
 + / / if we get cells _ per _ row from thrift , it is either " ALL " or " < number of cells to cache > " . 
 + if ( cellsPerRow ! = null & & rc . isEnabled ( ) ) 
 + rc = RowCache . fromString ( cellsPerRow ) ; 
 + return new CachingOptions ( kc , rc ) ; 
 + } 
 + 
 + public String toThriftCaching ( ) 
 + { 
 + if ( rowCache . isEnabled ( ) & & keyCache . isEnabled ( ) ) 
 + return " ALL " ; 
 + if ( rowCache . isEnabled ( ) ) 
 + return " ROWS _ ONLY " ; 
 + if ( keyCache . isEnabled ( ) ) 
 + return " KEYS _ ONLY " ; 
 + return " NONE " ; 
 + } 
 + 
 + public String toThriftCellsPerRow ( ) 
 + { 
 + if ( rowCache . cacheFullPartitions ( ) ) 
 + return " ALL " ; 
 + return String . valueOf ( rowCache . rowsToCache ) ; 
 + } 
 + 
 + 
 + public static class KeyCache 
 + { 
 + public final Type type ; 
 + public KeyCache ( Type type ) 
 + { 
 + this . type = type ; 
 + } 
 + 
 + public enum Type 
 + { 
 + ALL , NONE 
 + } 
 + public static KeyCache fromString ( String keyCache ) 
 + { 
 + return new KeyCache ( Type . valueOf ( keyCache . toUpperCase ( ) ) ) ; 
 + } 
 + 
 + public boolean isEnabled ( ) 
 + { 
 + return type . equals ( Type . ALL ) ; 
 + } 
 + 
 + @ Override 
 + public boolean equals ( Object o ) 
 + { 
 + if ( this = = o ) return true ; 
 + if ( o = = null | | getClass ( ) ! = o . getClass ( ) ) return false ; 
 + 
 + KeyCache keyCache = ( KeyCache ) o ; 
 + 
 + if ( type ! = keyCache . type ) return false ; 
 + 
 + return true ; 
 + } 
 + 
 + @ Override 
 + public int hashCode ( ) 
 + { 
 + return type . hashCode ( ) ; 
 + } 
 + @ Override 
 + public String toString ( ) 
 + { 
 + return type . toString ( ) ; 
 + } 
 + } 
 + 
 + public static class RowCache 
 + { 
 + public final Type type ; 
 + public final int rowsToCache ; 
 + 
 + public RowCache ( Type type ) 
 + { 
 + this ( type , type . equals ( Type . ALL ) ? Integer . MAX _ VALUE : 0 ) ; 
 + } 
 + public RowCache ( Type type , int rowsToCache ) 
 + { 
 + this . type = type ; 
 + this . rowsToCache = rowsToCache ; 
 + } 
 + 
 + public enum Type 
 + { 
 + ALL , NONE , HEAD 
 + } 
 + 
 + public static RowCache fromString ( String rowCache ) 
 + { 
 + if ( rowCache = = null | | rowCache . equalsIgnoreCase ( " none " ) ) 
 + return new RowCache ( Type . NONE , 0 ) ; 
 + else if ( rowCache . equalsIgnoreCase ( " all " ) ) 
 + return new RowCache ( Type . ALL , Integer . MAX _ VALUE ) ; 
 + return new RowCache ( Type . HEAD , Integer . parseInt ( rowCache ) ) ; 
 + } 
 + public boolean isEnabled ( ) 
 + { 
 + return type . equals ( Type . ALL ) | | type . equals ( Type . HEAD ) ; 
 + } 
 + public boolean cacheFullPartitions ( ) 
 + { 
 + return type . equals ( Type . ALL ) ; 
 + } 
 + @ Override 
 + public String toString ( ) 
 + { 
 + if ( type . equals ( Type . ALL ) ) return " ALL " ; 
 + if ( type . equals ( Type . NONE ) ) return " NONE " ; 
 + return String . valueOf ( rowsToCache ) ; 
 + } 
 + 
 + @ Override 
 + public boolean equals ( Object o ) 
 + { 
 + if ( this = = o ) return true ; 
 + if ( o = = null | | getClass ( ) ! = o . getClass ( ) ) return false ; 
 + 
 + RowCache rowCache = ( RowCache ) o ; 
 + 
 + if ( rowsToCache ! = rowCache . rowsToCache ) return false ; 
 + if ( type ! = rowCache . type ) return false ; 
 + 
 + return true ; 
 + } 
 + 
 + @ Override 
 + public int hashCode ( ) 
 + { 
 + int result = type . hashCode ( ) ; 
 + result = 31 * result + rowsToCache ; 
 + return result ; 
 + } 
 + } 
 + } 
 diff - - git a / src / java / org / apache / cassandra / cli / CliClient . java b / src / java / org / apache / cassandra / cli / CliClient . java 
 index b30bee1 . . ab6a221 100644 
 - - - a / src / java / org / apache / cassandra / cli / CliClient . java 
 + + + b / src / java / org / apache / cassandra / cli / CliClient . java 
 @ @ - 1350 , 7 + 1350 , 7 @ @ public class CliClient 
 cfDef . setCaching ( CliUtils . unescapeSQLString ( mValue ) ) ; 
 break ; 
 case CELLS _ PER _ ROW _ TO _ CACHE : 
 - cfDef . setCells _ per _ row _ to _ cache ( mValue ) ; 
 + cfDef . setCells _ per _ row _ to _ cache ( CliUtils . unescapeSQLString ( mValue ) ) ; 
 break ; 
 case DEFAULT _ TIME _ TO _ LIVE : 
 cfDef . setDefault _ time _ to _ live ( Integer . parseInt ( mValue ) ) ; 
 @ @ - 1853 , 7 + 1853 , 6 @ @ public class CliClient 
 
 writeAttrRaw ( output , false , " compaction _ strategy _ options " , cOptions . toString ( ) ) ; 
 } 
 - 
 if ( ! StringUtils . isEmpty ( cfDef . comment ) ) 
 writeAttr ( output , false , " comment " , cfDef . comment ) ; 
 
 diff - - git a / src / java / org / apache / cassandra / config / CFMetaData . java b / src / java / org / apache / cassandra / config / CFMetaData . java 
 index ac5dea7 . . f38dd5e 100644 
 - - - a / src / java / org / apache / cassandra / config / CFMetaData . java 
 + + + b / src / java / org / apache / cassandra / config / CFMetaData . java 
 @ @ - 30 , 9 + 30 , 11 @ @ import com . google . common . collect . AbstractIterator ; 
 import com . google . common . collect . Iterables ; 
 import com . google . common . collect . MapDifference ; 
 import com . google . common . collect . Maps ; 
 + 
 + import org . apache . cassandra . cache . CachingOptions ; 
 import org . apache . cassandra . db . composites . * ; 
 + 
 import org . apache . commons . lang3 . ArrayUtils ; 
 - import org . apache . commons . lang3 . StringUtils ; 
 import org . apache . commons . lang3 . builder . HashCodeBuilder ; 
 import org . apache . commons . lang3 . builder . ToStringBuilder ; 
 import org . slf4j . Logger ; 
 @ @ - 80 , 13 + 82 , 12 @ @ public final class CFMetaData 
 public final static int DEFAULT _ MIN _ COMPACTION _ THRESHOLD = 4 ; 
 public final static int DEFAULT _ MAX _ COMPACTION _ THRESHOLD = 32 ; 
 public final static Class < ? extends AbstractCompactionStrategy > DEFAULT _ COMPACTION _ STRATEGY _ CLASS = SizeTieredCompactionStrategy . class ; 
 - public final static Caching DEFAULT _ CACHING _ STRATEGY = Caching . KEYS _ ONLY ; 
 + public final static CachingOptions DEFAULT _ CACHING _ STRATEGY = CachingOptions . KEYS _ ONLY ; 
 public final static int DEFAULT _ DEFAULT _ TIME _ TO _ LIVE = 0 ; 
 public final static SpeculativeRetry DEFAULT _ SPECULATIVE _ RETRY = new SpeculativeRetry ( SpeculativeRetry . RetryType . PERCENTILE , 0 . 99 ) ; 
 public final static int DEFAULT _ MIN _ INDEX _ INTERVAL = 128 ; 
 public final static int DEFAULT _ MAX _ INDEX _ INTERVAL = 2048 ; 
 public final static boolean DEFAULT _ POPULATE _ IO _ CACHE _ ON _ FLUSH = false ; 
 - public final static RowsPerPartitionToCache DEFAULT _ ROWS _ PER _ PARTITION _ TO _ CACHE = new RowsPerPartitionToCache ( 100 , RowsPerPartitionToCache . Type . HEAD ) ; 
 
 / / Note that this is the default only for user created tables 
 public final static String DEFAULT _ COMPRESSOR = LZ4Compressor . class . getCanonicalName ( ) ; 
 @ @ - 300 , 65 + 301 , 6 @ @ public final class CFMetaData 
 + " PRIMARY KEY ( id ) " 
 + " ) WITH COMMENT = ' show all compaction history ' AND DEFAULT _ TIME _ TO _ LIVE = 604800 " ) ; 
 
 - public enum Caching 
 - { 
 - ALL , KEYS _ ONLY , ROWS _ ONLY , NONE ; 
 - 
 - public static Caching fromString ( String cache ) throws ConfigurationException 
 - { 
 - try 
 - { 
 - return valueOf ( cache . toUpperCase ( ) ) ; 
 - } 
 - catch ( IllegalArgumentException e ) 
 - { 
 - throw new ConfigurationException ( String . format ( " % s not found , available types : % s . " , cache , StringUtils . join ( values ( ) , " , " ) ) ) ; 
 - } 
 - } 
 - } 
 - 
 - public static class RowsPerPartitionToCache 
 - { 
 - public enum Type 
 - { 
 - ALL , HEAD 
 - } 
 - public final int rowsToCache ; 
 - public final Type type ; 
 - 
 - private RowsPerPartitionToCache ( int rowsToCache , Type type ) 
 - { 
 - this . rowsToCache = rowsToCache ; 
 - this . type = type ; 
 - } 
 - 
 - public static RowsPerPartitionToCache fromString ( String rpptc ) 
 - { 
 - if ( rpptc . equalsIgnoreCase ( " all " ) ) 
 - return new RowsPerPartitionToCache ( Integer . MAX _ VALUE , Type . ALL ) ; 
 - return new RowsPerPartitionToCache ( Integer . parseInt ( rpptc ) , Type . HEAD ) ; 
 - } 
 - 
 - public boolean cacheFullPartitions ( ) 
 - { 
 - return type = = Type . ALL ; 
 - } 
 - 
 - public String toString ( ) 
 - { 
 - if ( rowsToCache = = Integer . MAX _ VALUE ) 
 - return " ALL " ; 
 - return String . valueOf ( rowsToCache ) ; 
 - } 
 - 
 - public boolean equals ( Object rhs ) 
 - { 
 - if ( ! ( rhs instanceof RowsPerPartitionToCache ) ) 
 - return false ; 
 - RowsPerPartitionToCache rppc = ( RowsPerPartitionToCache ) rhs ; 
 - return rowsToCache = = rppc . rowsToCache & & type = = rppc . type ; 
 - } 
 - } 
 
 public static class SpeculativeRetry 
 { 
 @ @ - 453 , 7 + 395 , 7 @ @ public final class CFMetaData 
 private volatile int minCompactionThreshold = DEFAULT _ MIN _ COMPACTION _ THRESHOLD ; 
 private volatile int maxCompactionThreshold = DEFAULT _ MAX _ COMPACTION _ THRESHOLD ; 
 private volatile Double bloomFilterFpChance = null ; 
 - private volatile Caching caching = DEFAULT _ CACHING _ STRATEGY ; 
 + private volatile CachingOptions caching = DEFAULT _ CACHING _ STRATEGY ; 
 private volatile int minIndexInterval = DEFAULT _ MIN _ INDEX _ INTERVAL ; 
 private volatile int maxIndexInterval = DEFAULT _ MAX _ INDEX _ INTERVAL ; 
 private int memtableFlushPeriod = 0 ; 
 @ @ - 463 , 7 + 405 , 6 @ @ public final class CFMetaData 
 private volatile Map < ColumnIdentifier , Long > droppedColumns = new HashMap < > ( ) ; 
 private volatile Map < String , TriggerDefinition > triggers = new HashMap < > ( ) ; 
 private volatile boolean isPurged = false ; 
 - private volatile RowsPerPartitionToCache rowsPerPartitionToCache = DEFAULT _ ROWS _ PER _ PARTITION _ TO _ CACHE ; 
 / * 
 * All CQL3 columns definition are stored in the columnMetadata map . 
 * On top of that , we keep separated collection of each kind of definition , to 
 @ @ - 500 , 7 + 441 , 7 @ @ public final class CFMetaData 
 public CFMetaData compactionStrategyOptions ( Map < String , String > prop ) { compactionStrategyOptions = prop ; return this ; } 
 public CFMetaData compressionParameters ( CompressionParameters prop ) { compressionParameters = prop ; return this ; } 
 public CFMetaData bloomFilterFpChance ( Double prop ) { bloomFilterFpChance = prop ; return this ; } 
 - public CFMetaData caching ( Caching prop ) { caching = prop ; return this ; } 
 + public CFMetaData caching ( CachingOptions prop ) { caching = prop ; return this ; } 
 public CFMetaData minIndexInterval ( int prop ) { minIndexInterval = prop ; return this ; } 
 public CFMetaData maxIndexInterval ( int prop ) { maxIndexInterval = prop ; return this ; } 
 public CFMetaData memtableFlushPeriod ( int prop ) { memtableFlushPeriod = prop ; return this ; } 
 @ @ - 509 , 7 + 450 , 6 @ @ public final class CFMetaData 
 public CFMetaData populateIoCacheOnFlush ( boolean prop ) { populateIoCacheOnFlush = prop ; return this ; } 
 public CFMetaData droppedColumns ( Map < ColumnIdentifier , Long > cols ) { droppedColumns = cols ; return this ; } 
 public CFMetaData triggers ( Map < String , TriggerDefinition > prop ) { triggers = prop ; return this ; } 
 - public CFMetaData rowsPerPartitionToCache ( RowsPerPartitionToCache prop ) { rowsPerPartitionToCache = prop ; return this ; } 
 
 / * * 
 * Create new ColumnFamily metadata with generated random ID . 
 @ @ - 626 , 9 + 566 , 9 @ @ public final class CFMetaData 
 { 
 / / Depends on parent ' s cache setting , turn on its index CF ' s cache . 
 / / Row caching is never enabled ; see CASSANDRA - 5732 
 - Caching indexCaching = parent . getCaching ( ) = = Caching . ALL | | parent . getCaching ( ) = = Caching . KEYS _ ONLY 
 - ? Caching . KEYS _ ONLY 
 - : Caching . NONE ; 
 + CachingOptions indexCaching = parent . getCaching ( ) . keyCache . isEnabled ( ) 
 + ? CachingOptions . KEYS _ ONLY 
 + : CachingOptions . NONE ; 
 
 return new CFMetaData ( parent . ksName , parent . indexColumnFamilyName ( info ) , ColumnFamilyType . Standard , indexComparator , parent . cfId ) 
 . keyValidator ( info . type ) 
 @ @ - 697 , 7 + 637 , 6 @ @ public final class CFMetaData 
 . populateIoCacheOnFlush ( oldCFMD . populateIoCacheOnFlush ) 
 . droppedColumns ( new HashMap < > ( oldCFMD . droppedColumns ) ) 
 . triggers ( new HashMap < > ( oldCFMD . triggers ) ) 
 - . rowsPerPartitionToCache ( oldCFMD . rowsPerPartitionToCache ) 
 . rebuild ( ) ; 
 } 
 
 @ @ - 884 , 7 + 823 , 7 @ @ public final class CFMetaData 
 : bloomFilterFpChance ; 
 } 
 
 - public Caching getCaching ( ) 
 + public CachingOptions getCaching ( ) 
 { 
 return caching ; 
 } 
 @ @ - 899 , 11 + 838 , 6 @ @ public final class CFMetaData 
 return maxIndexInterval ; 
 } 
 
 - public RowsPerPartitionToCache getRowsPerPartitionToCache ( ) 
 - { 
 - return rowsPerPartitionToCache ; 
 - } 
 - 
 public SpeculativeRetry getSpeculativeRetry ( ) 
 { 
 return speculativeRetry ; 
 @ @ - 961 , 8 + 895 , 7 @ @ public final class CFMetaData 
 & & Objects . equal ( speculativeRetry , other . speculativeRetry ) 
 & & Objects . equal ( populateIoCacheOnFlush , other . populateIoCacheOnFlush ) 
 & & Objects . equal ( droppedColumns , other . droppedColumns ) 
 - & & Objects . equal ( triggers , other . triggers ) 
 - & & Objects . equal ( rowsPerPartitionToCache , other . rowsPerPartitionToCache ) ; 
 + & & Objects . equal ( triggers , other . triggers ) ; 
 } 
 
 @ Override 
 @ @ - 996 , 7 + 929 , 6 @ @ public final class CFMetaData 
 . append ( populateIoCacheOnFlush ) 
 . append ( droppedColumns ) 
 . append ( triggers ) 
 - . append ( rowsPerPartitionToCache ) 
 . toHashCode ( ) ; 
 } 
 
 @ @ - 1067 , 9 + 999 , 6 @ @ public final class CFMetaData 
 / / ensure the max is at least as large as the min 
 cf _ def . setMax _ index _ interval ( Math . max ( cf _ def . min _ index _ interval , CFMetaData . DEFAULT _ MAX _ INDEX _ INTERVAL ) ) ; 
 } 
 - 
 - if ( ! cf _ def . isSetCells _ per _ row _ to _ cache ( ) ) 
 - cf _ def . setCells _ per _ row _ to _ cache ( CFMetaData . DEFAULT _ ROWS _ PER _ PARTITION _ TO _ CACHE . toString ( ) ) ; 
 } 
 
 public static CFMetaData fromThrift ( org . apache . cassandra . thrift . CfDef cf _ def ) throws InvalidRequestException , ConfigurationException 
 @ @ - 1112 , 8 + 1041 , 8 @ @ public final class CFMetaData 
 newCFMD . bloomFilterFpChance ( cf _ def . bloom _ filter _ fp _ chance ) ; 
 if ( cf _ def . isSetMemtable _ flush _ period _ in _ ms ( ) ) 
 newCFMD . memtableFlushPeriod ( cf _ def . memtable _ flush _ period _ in _ ms ) ; 
 - if ( cf _ def . isSetCaching ( ) ) 
 - newCFMD . caching ( Caching . fromString ( cf _ def . caching ) ) ; 
 + if ( cf _ def . isSetCaching ( ) | | cf _ def . isSetCells _ per _ row _ to _ cache ( ) ) 
 + newCFMD . caching ( CachingOptions . fromThrift ( cf _ def . caching , cf _ def . cells _ per _ row _ to _ cache ) ) ; 
 if ( cf _ def . isSetRead _ repair _ chance ( ) ) 
 newCFMD . readRepairChance ( cf _ def . read _ repair _ chance ) ; 
 if ( cf _ def . isSetDefault _ time _ to _ live ( ) ) 
 @ @ - 1130 , 8 + 1059 , 6 @ @ public final class CFMetaData 
 newCFMD . populateIoCacheOnFlush ( cf _ def . populate _ io _ cache _ on _ flush ) ; 
 if ( cf _ def . isSetTriggers ( ) ) 
 newCFMD . triggers ( TriggerDefinition . fromThrift ( cf _ def . triggers ) ) ; 
 - if ( cf _ def . isSetCells _ per _ row _ to _ cache ( ) ) 
 - newCFMD . rowsPerPartitionToCache ( RowsPerPartitionToCache . fromString ( cf _ def . cells _ per _ row _ to _ cache ) ) ; 
 
 CompressionParameters cp = CompressionParameters . create ( cf _ def . compression _ options ) ; 
 
 @ @ - 1229 , 7 + 1156 , 6 @ @ public final class CFMetaData 
 minIndexInterval = cfm . minIndexInterval ; 
 maxIndexInterval = cfm . maxIndexInterval ; 
 memtableFlushPeriod = cfm . memtableFlushPeriod ; 
 - rowsPerPartitionToCache = cfm . rowsPerPartitionToCache ; 
 defaultTimeToLive = cfm . defaultTimeToLive ; 
 speculativeRetry = cfm . speculativeRetry ; 
 populateIoCacheOnFlush = cfm . populateIoCacheOnFlush ; 
 @ @ - 1378 , 8 + 1304 , 8 @ @ public final class CFMetaData 
 def . setMin _ index _ interval ( minIndexInterval ) ; 
 def . setMax _ index _ interval ( maxIndexInterval ) ; 
 def . setMemtable _ flush _ period _ in _ ms ( memtableFlushPeriod ) ; 
 - def . setCaching ( caching . toString ( ) ) ; 
 - def . setCells _ per _ row _ to _ cache ( rowsPerPartitionToCache . toString ( ) ) ; 
 + def . setCaching ( caching . toThriftCaching ( ) ) ; 
 + def . setCells _ per _ row _ to _ cache ( caching . toThriftCellsPerRow ( ) ) ; 
 def . setDefault _ time _ to _ live ( defaultTimeToLive ) ; 
 def . setSpeculative _ retry ( speculativeRetry . toString ( ) ) ; 
 def . setTriggers ( TriggerDefinition . toThrift ( triggers ) ) ; 
 @ @ - 1748 , 7 + 1674 , 6 @ @ public final class CFMetaData 
 
 adder . add ( " memtable _ flush _ period _ in _ ms " , memtableFlushPeriod ) ; 
 adder . add ( " caching " , caching . toString ( ) ) ; 
 - adder . add ( " rows _ per _ partition _ to _ cache " , rowsPerPartitionToCache . toString ( ) ) ; 
 adder . add ( " default _ time _ to _ live " , defaultTimeToLive ) ; 
 adder . add ( " compaction _ strategy _ class " , compactionStrategyClass . getName ( ) ) ; 
 adder . add ( " compression _ parameters " , json ( compressionParameters . asThriftOptions ( ) ) ) ; 
 @ @ - 1815 , 9 + 1740 , 7 @ @ public final class CFMetaData 
 cfm . bloomFilterFpChance ( result . getDouble ( " bloom _ filter _ fp _ chance " ) ) ; 
 if ( result . has ( " memtable _ flush _ period _ in _ ms " ) ) 
 cfm . memtableFlushPeriod ( result . getInt ( " memtable _ flush _ period _ in _ ms " ) ) ; 
 - cfm . caching ( Caching . valueOf ( result . getString ( " caching " ) ) ) ; 
 - if ( result . has ( " rows _ per _ partition _ to _ cache " ) ) 
 - cfm . rowsPerPartitionToCache ( RowsPerPartitionToCache . fromString ( result . getString ( " rows _ per _ partition _ to _ cache " ) ) ) ; 
 + cfm . caching ( CachingOptions . fromString ( result . getString ( " caching " ) ) ) ; 
 if ( result . has ( " default _ time _ to _ live " ) ) 
 cfm . defaultTimeToLive ( result . getInt ( " default _ time _ to _ live " ) ) ; 
 if ( result . has ( " speculative _ retry " ) ) 
 @ @ - 2312 , 7 + 2235 , 6 @ @ public final class CFMetaData 
 . append ( " populateIoCacheOnFlush " , populateIoCacheOnFlush ) 
 . append ( " droppedColumns " , droppedColumns ) 
 . append ( " triggers " , triggers ) 
 - . append ( " rowsPerPartitionToCache " , rowsPerPartitionToCache ) 
 . toString ( ) ; 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / cql / AlterTableStatement . java b / src / java / org / apache / cassandra / cql / AlterTableStatement . java 
 index 2fda212 . . 034f660 100644 
 - - - a / src / java / org / apache / cassandra / cql / AlterTableStatement . java 
 + + + b / src / java / org / apache / cassandra / cql / AlterTableStatement . java 
 @ @ - 17 , 6 + 17 , 7 @ @ 
 * / 
 package org . apache . cassandra . cql ; 
 
 + import org . apache . cassandra . cache . CachingOptions ; 
 import org . apache . cassandra . config . * ; 
 import org . apache . cassandra . db . marshal . TypeParser ; 
 import org . apache . cassandra . exceptions . * ; 
 @ @ - 179 , 8 + 180 , 7 @ @ public class AlterTableStatement 
 throw new ConfigurationException ( " Disabling compaction by setting compaction thresholds to 0 has been deprecated , set the compaction option ' enabled ' to false instead . " ) ; 
 cfm . minCompactionThreshold ( minCompactionThreshold ) ; 
 cfm . maxCompactionThreshold ( maxCompactionThreshold ) ; 
 - cfm . caching ( CFMetaData . Caching . fromString ( cfProps . getPropertyString ( CFPropDefs . KW _ CACHING , cfm . getCaching ( ) . toString ( ) ) ) ) ; 
 - cfm . rowsPerPartitionToCache ( CFMetaData . RowsPerPartitionToCache . fromString ( cfProps . getPropertyString ( CFPropDefs . KW _ ROWS _ PER _ PARTITION _ TO _ CACHE , cfm . getRowsPerPartitionToCache ( ) . toString ( ) ) ) ) ; 
 + cfm . caching ( CachingOptions . fromString ( cfProps . getPropertyString ( CFPropDefs . KW _ CACHING , cfm . getCaching ( ) . toString ( ) ) ) ) ; 
 cfm . defaultTimeToLive ( cfProps . getPropertyInt ( CFPropDefs . KW _ DEFAULT _ TIME _ TO _ LIVE , cfm . getDefaultTimeToLive ( ) ) ) ; 
 cfm . speculativeRetry ( CFMetaData . SpeculativeRetry . fromString ( cfProps . getPropertyString ( CFPropDefs . KW _ SPECULATIVE _ RETRY , cfm . getSpeculativeRetry ( ) . toString ( ) ) ) ) ; 
 cfm . populateIoCacheOnFlush ( cfProps . getPropertyBoolean ( CFPropDefs . KW _ POPULATE _ IO _ CACHE _ ON _ FLUSH , cfm . populateIoCacheOnFlush ( ) ) ) ; 
 diff - - git a / src / java / org / apache / cassandra / cql / CreateColumnFamilyStatement . java b / src / java / org / apache / cassandra / cql / CreateColumnFamilyStatement . java 
 index e568dd7 . . b483451 100644 
 - - - a / src / java / org / apache / cassandra / cql / CreateColumnFamilyStatement . java 
 + + + b / src / java / org / apache / cassandra / cql / CreateColumnFamilyStatement . java 
 @ @ - 24 , 6 + 24 , 7 @ @ import java . util . List ; 
 import java . util . Map ; 
 import java . util . Set ; 
 
 + import org . apache . cassandra . cache . CachingOptions ; 
 import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . ColumnDefinition ; 
 import org . apache . cassandra . db . composites . SimpleDenseCellNameType ; 
 @ @ - 196 , 8 + 197 , 7 @ @ public class CreateColumnFamilyStatement 
 . compactionStrategyClass ( cfProps . compactionStrategyClass ) 
 . compactionStrategyOptions ( cfProps . compactionStrategyOptions ) 
 . compressionParameters ( CompressionParameters . create ( cfProps . compressionParameters ) ) 
 - . caching ( CFMetaData . Caching . fromString ( getPropertyString ( CFPropDefs . KW _ CACHING , CFMetaData . DEFAULT _ CACHING _ STRATEGY . toString ( ) ) ) ) 
 - . rowsPerPartitionToCache ( CFMetaData . RowsPerPartitionToCache . fromString ( cfProps . getPropertyString ( CFPropDefs . KW _ ROWS _ PER _ PARTITION _ TO _ CACHE , CFMetaData . DEFAULT _ ROWS _ PER _ PARTITION _ TO _ CACHE . toString ( ) ) ) ) 
 + . caching ( CachingOptions . fromString ( getPropertyString ( CFPropDefs . KW _ CACHING , CFMetaData . DEFAULT _ CACHING _ STRATEGY . toString ( ) ) ) ) 
 . speculativeRetry ( CFMetaData . SpeculativeRetry . fromString ( getPropertyString ( CFPropDefs . KW _ SPECULATIVE _ RETRY , CFMetaData . DEFAULT _ SPECULATIVE _ RETRY . toString ( ) ) ) ) 
 . bloomFilterFpChance ( getPropertyDouble ( CFPropDefs . KW _ BF _ FP _ CHANCE , null ) ) 
 . memtableFlushPeriod ( getPropertyInt ( CFPropDefs . KW _ MEMTABLE _ FLUSH _ PERIOD , 0 ) ) 
 diff - - git a / src / java / org / apache / cassandra / cql3 / statements / CFPropDefs . java b / src / java / org / apache / cassandra / cql3 / statements / CFPropDefs . java 
 index f473e22 . . 95fb750 100644 
 - - - a / src / java / org / apache / cassandra / cql3 / statements / CFPropDefs . java 
 + + + b / src / java / org / apache / cassandra / cql3 / statements / CFPropDefs . java 
 @ @ - 19 , 6 + 19 , 7 @ @ package org . apache . cassandra . cql3 . statements ; 
 
 import java . util . * ; 
 
 + import org . apache . cassandra . cache . CachingOptions ; 
 import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . CFMetaData . SpeculativeRetry ; 
 import org . apache . cassandra . db . compaction . AbstractCompactionStrategy ; 
 @ @ - 149 , 6 + 150 , 21 @ @ public class CFPropDefs extends PropertyDefinitions 
 return new HashMap < > ( ) ; 
 return compressionOptions ; 
 } 
 + public CachingOptions getCachingOptions ( ) throws SyntaxException , ConfigurationException 
 + { 
 + CachingOptions options = null ; 
 + Object val = properties . get ( KW _ CACHING ) ; 
 + if ( val = = null ) 
 + return null ; 
 + else if ( val instanceof Map ) 
 + options = CachingOptions . fromMap ( getMap ( KW _ CACHING ) ) ; 
 + else if ( val instanceof String ) / / legacy syntax 
 + { 
 + options = CachingOptions . fromString ( getSimple ( KW _ CACHING ) ) ; 
 + logger . warn ( " Setting caching options with deprecated syntax . " ) ; 
 + } 
 + return options ; 
 + } 
 
 public void applyToCFMetadata ( CFMetaData cfm ) throws ConfigurationException , SyntaxException 
 { 
 @ @ - 164 , 12 + 180 , 6 @ @ public class CFPropDefs extends PropertyDefinitions 
 throw new ConfigurationException ( " Disabling compaction by setting compaction thresholds to 0 has been deprecated , set the compaction option ' enabled ' to false instead . " ) ; 
 cfm . minCompactionThreshold ( minCompactionThreshold ) ; 
 cfm . maxCompactionThreshold ( maxCompactionThreshold ) ; 
 - cfm . caching ( CFMetaData . Caching . fromString ( getString ( KW _ CACHING , cfm . getCaching ( ) . toString ( ) ) ) ) ; 
 - CFMetaData . RowsPerPartitionToCache newRppc = CFMetaData . RowsPerPartitionToCache . fromString ( getString ( KW _ ROWS _ PER _ PARTITION _ TO _ CACHE , cfm . getRowsPerPartitionToCache ( ) . toString ( ) ) ) ; 
 - / / we need to invalidate row cache if the amount of rows cached changes , otherwise we might serve out bad data . 
 - if ( ! cfm . getRowsPerPartitionToCache ( ) . equals ( newRppc ) ) 
 - CacheService . instance . invalidateRowCacheForCf ( cfm . cfId ) ; 
 - cfm . rowsPerPartitionToCache ( newRppc ) ; 
 cfm . defaultTimeToLive ( getInt ( KW _ DEFAULT _ TIME _ TO _ LIVE , cfm . getDefaultTimeToLive ( ) ) ) ; 
 cfm . speculativeRetry ( CFMetaData . SpeculativeRetry . fromString ( getString ( KW _ SPECULATIVE _ RETRY , cfm . getSpeculativeRetry ( ) . toString ( ) ) ) ) ; 
 cfm . memtableFlushPeriod ( getInt ( KW _ MEMTABLE _ FLUSH _ PERIOD , cfm . getMemtableFlushPeriod ( ) ) ) ; 
 @ @ - 187 , 6 + 197 , 9 @ @ public class CFPropDefs extends PropertyDefinitions 
 
 if ( ! getCompressionOptions ( ) . isEmpty ( ) ) 
 cfm . compressionParameters ( CompressionParameters . create ( getCompressionOptions ( ) ) ) ; 
 + CachingOptions cachingOptions = getCachingOptions ( ) ; 
 + if ( cachingOptions ! = null ) 
 + cfm . caching ( cachingOptions ) ; 
 } 
 
 @ Override 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index 8d064dd . . 34aa5f5 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 77 , 8 + 77 , 6 @ @ import org . apache . cassandra . tracing . Tracing ; 
 import org . apache . cassandra . utils . * ; 
 import org . apache . cassandra . utils . concurrent . OpOrder ; 
 
 - import static org . apache . cassandra . config . CFMetaData . Caching ; 
 - 
 public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 { 
 private static final Logger logger = LoggerFactory . getLogger ( ColumnFamilyStore . class ) ; 
 @ @ - 276 , 7 + 274 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 fileIndexGenerator . set ( generation ) ; 
 sampleLatencyNanos = DatabaseDescriptor . getReadRpcTimeout ( ) / 2 ; 
 
 - Caching caching = metadata . getCaching ( ) ; 
 + CachingOptions caching = metadata . getCaching ( ) ; 
 
 logger . info ( " Initializing { } . { } " , keyspace . getName ( ) , name ) ; 
 
 @ @ - 290 , 7 + 288 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 data . addInitialSSTables ( sstables ) ; 
 } 
 
 - if ( caching = = Caching . ALL | | caching = = Caching . KEYS _ ONLY ) 
 + if ( caching . keyCache . isEnabled ( ) ) 
 CacheService . instance . keyCache . loadSaved ( this ) ; 
 
 / / compaction strategy should be created after the CFS has been prepared 
 @ @ - 1498 , 7 + 1496 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 try 
 { 
 / / If we are explicitely asked to fill the cache with full partitions , we go ahead and query the whole thing 
 - if ( metadata . getRowsPerPartitionToCache ( ) . cacheFullPartitions ( ) ) 
 + if ( metadata . getCaching ( ) . rowCache . cacheFullPartitions ( ) ) 
 { 
 data = getTopLevelColumns ( QueryFilter . getIdentityFilter ( filter . key , name , filter . timestamp ) , Integer . MIN _ VALUE ) ; 
 toCache = data ; 
 @ @ - 1521 , 7 + 1519 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 if ( filter . filter . isHeadFilter ( ) & & filter . filter . countCQL3Rows ( metadata . comparator ) ) 
 { 
 SliceQueryFilter sliceFilter = ( SliceQueryFilter ) filter . filter ; 
 - int rowsToCache = metadata . getRowsPerPartitionToCache ( ) . rowsToCache ; 
 + int rowsToCache = metadata . getCaching ( ) . rowCache . rowsToCache ; 
 
 SliceQueryFilter cacheSlice = readFilterForCache ( ) ; 
 QueryFilter cacheFilter = new QueryFilter ( filter . key , name , cacheSlice , filter . timestamp ) ; 
 @ @ - 1578 , 7 + 1576 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 public SliceQueryFilter readFilterForCache ( ) 
 { 
 / / We create a new filter everytime before for now SliceQueryFilter is unfortunatly mutable . 
 - return new SliceQueryFilter ( ColumnSlice . ALL _ COLUMNS _ ARRAY , false , metadata . getRowsPerPartitionToCache ( ) . rowsToCache , metadata . clusteringColumns ( ) . size ( ) ) ; 
 + return new SliceQueryFilter ( ColumnSlice . ALL _ COLUMNS _ ARRAY , false , metadata . getCaching ( ) . rowCache . rowsToCache , metadata . clusteringColumns ( ) . size ( ) ) ; 
 } 
 
 public boolean isFilterFullyCoveredBy ( IDiskAtomFilter filter , ColumnFamily cachedCf , long now ) 
 @ @ - 1592 , 7 + 1590 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 / / columns : if we use a timestamp newer than the one that was used when populating the cache , we might 
 / / end up deciding the whole partition is cached when it ' s really not ( just some rows expired since the 
 / / cf was cached ) . This is the reason for Integer . MIN _ VALUE below . 
 - boolean wholePartitionCached = cachedCf . liveCQL3RowCount ( Integer . MIN _ VALUE ) < metadata . getRowsPerPartitionToCache ( ) . rowsToCache ; 
 + boolean wholePartitionCached = cachedCf . liveCQL3RowCount ( Integer . MIN _ VALUE ) < metadata . getCaching ( ) . rowCache . rowsToCache ; 
 
 / / Contrarily to the " wholePartitionCached " check above , we do want isFullyCoveredBy to take the 
 / / timestamp of the query into account when dealing with expired columns . Otherwise , we could think 
 @ @ - 2674 , 9 + 2672 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 
 private boolean isRowCacheEnabled ( ) 
 { 
 - return ! ( metadata . getCaching ( ) = = Caching . NONE 
 - | | metadata . getCaching ( ) = = Caching . KEYS _ ONLY 
 - | | CacheService . instance . rowCache . getCapacity ( ) = = 0 ) ; 
 + return metadata . getCaching ( ) . rowCache . isEnabled ( ) & & CacheService . instance . rowCache . getCapacity ( ) > 0 ; 
 } 
 
 / * * 
 diff - - git a / src / java / org / apache / cassandra / db / SystemKeyspace . java b / src / java / org / apache / cassandra / db / SystemKeyspace . java 
 index 292d3da . . 0273341 100644 
 - - - a / src / java / org / apache / cassandra / db / SystemKeyspace . java 
 + + + b / src / java / org / apache / cassandra / db / SystemKeyspace . java 
 @ @ - 33 , 6 + 33 , 7 @ @ import org . apache . commons . lang3 . StringUtils ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 + import org . apache . cassandra . cache . CachingOptions ; 
 import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . config . KSMetaData ; 
 @ @ - 112 , 7 + 113 , 7 @ @ public class SystemKeyspace 
 setupVersion ( ) ; 
 
 migrateIndexInterval ( ) ; 
 - 
 + migrateCachingOption ( ) ; 
 / / add entries to system schema columnfamilies for the hardcoded system definitions 
 for ( String ksname : Schema . systemKeyspaceNames ) 
 { 
 @ @ - 175 , 6 + 176 , 36 @ @ public class SystemKeyspace 
 } 
 } 
 
 + private static void migrateCachingOption ( ) 
 + { 
 + for ( UntypedResultSet . Row row : processInternal ( String . format ( " SELECT * FROM system . % s " , SCHEMA _ COLUMNFAMILIES _ CF ) ) ) 
 + { 
 + if ( ! row . has ( " caching " ) ) 
 + continue ; 
 + 
 + if ( ! CachingOptions . isLegacy ( row . getString ( " caching " ) ) ) 
 + continue ; 
 + try 
 + { 
 + CachingOptions caching = CachingOptions . fromString ( row . getString ( " caching " ) ) ; 
 + CFMetaData table = CFMetaData . fromSchema ( row ) ; 
 + logger . info ( " Migrating caching option { } to { } for { } . { } " , row . getString ( " caching " ) , caching . toString ( ) , table . ksName , table . cfName ) ; 
 + String query = String . format ( " SELECT writetime ( type ) " 
 + + " FROM system . % s " 
 + + " WHERE keyspace _ name = ' % s ' AND columnfamily _ name = ' % s ' " , 
 + SCHEMA _ COLUMNFAMILIES _ CF , 
 + table . ksName , 
 + table . cfName ) ; 
 + long timestamp = processInternal ( query ) . one ( ) . getLong ( " writetime ( type ) " ) ; 
 + table . toSchema ( timestamp ) . apply ( ) ; 
 + } 
 + catch ( ConfigurationException e ) 
 + { 
 + / / shouldn ' t happen 
 + } 
 + } 
 + } 
 + 
 / * * 
 * Write compaction log , except columfamilies under system keyspace . 
 * 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 index c02e397 . . 17e9b8f 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableReader . java 
 @ @ - 36 , 6 + 36 , 7 @ @ import com . google . common . util . concurrent . RateLimiter ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 + import org . apache . cassandra . cache . CachingOptions ; 
 import org . apache . cassandra . cache . InstrumentingCache ; 
 import org . apache . cassandra . cache . KeyCacheKey ; 
 import org . apache . cassandra . concurrent . DebuggableThreadPoolExecutor ; 
 @ @ - 1068 , 10 + 1069 , 9 @ @ public class SSTableReader extends SSTable implements Closeable 
 
 public void cacheKey ( DecoratedKey key , RowIndexEntry info ) 
 { 
 - CFMetaData . Caching caching = metadata . getCaching ( ) ; 
 + CachingOptions caching = metadata . getCaching ( ) ; 
 
 - if ( caching = = CFMetaData . Caching . NONE 
 - | | caching = = CFMetaData . Caching . ROWS _ ONLY 
 + if ( ! caching . keyCache . isEnabled ( ) 
 | | keyCache = = null 
 | | keyCache . getCapacity ( ) = = 0 ) 
 { 
 diff - - git a / test / unit / org / apache / cassandra / SchemaLoader . java b / test / unit / org / apache / cassandra / SchemaLoader . java 
 index f67386a . . 5fb5697 100644 
 - - - a / test / unit / org / apache / cassandra / SchemaLoader . java 
 + + + b / test / unit / org / apache / cassandra / SchemaLoader . java 
 @ @ - 21 , 6 + 21 , 7 @ @ import java . io . File ; 
 import java . nio . ByteBuffer ; 
 import java . util . * ; 
 
 + import org . apache . cassandra . cache . CachingOptions ; 
 import org . apache . cassandra . db . index . PerRowSecondaryIndexTest ; 
 import org . apache . cassandra . db . index . SecondaryIndex ; 
 import org . junit . AfterClass ; 
 @ @ - 164 , 7 + 165 , 9 @ @ public class SchemaLoader 
 standardCFMD ( ks1 , " legacyleveled " ) 
 . compactionStrategyClass ( LeveledCompactionStrategy . class ) 
 . compactionStrategyOptions ( leveledOptions ) , 
 - standardCFMD ( ks1 , " StandardLowIndexInterval " ) . minIndexInterval ( 8 ) . maxIndexInterval ( 256 ) . caching ( CFMetaData . Caching . NONE ) ) ) ; 
 + standardCFMD ( ks1 , " StandardLowIndexInterval " ) . minIndexInterval ( 8 ) 
 + . maxIndexInterval ( 256 ) 
 + . caching ( CachingOptions . NONE ) ) ) ; 
 
 
 / / Keyspace 2 
 @ @ - 228 , 9 + 231 , 12 @ @ public class SchemaLoader 
 schema . add ( KSMetaData . testMetadata ( ks _ rcs , 
 simple , 
 opts _ rf1 , 
 - standardCFMD ( ks _ rcs , " CFWithoutCache " ) . caching ( CFMetaData . Caching . NONE ) , 
 - standardCFMD ( ks _ rcs , " CachedCF " ) . caching ( CFMetaData . Caching . ALL ) . rowsPerPartitionToCache ( CFMetaData . RowsPerPartitionToCache . fromString ( " ALL " ) ) , 
 - standardCFMD ( ks _ rcs , " CachedIntCF " ) . defaultValidator ( IntegerType . instance ) . caching ( CFMetaData . Caching . ALL ) ) ) ; 
 + standardCFMD ( ks _ rcs , " CFWithoutCache " ) . caching ( CachingOptions . NONE ) , 
 + standardCFMD ( ks _ rcs , " CachedCF " ) . caching ( CachingOptions . ALL ) , 
 + standardCFMD ( ks _ rcs , " CachedIntCF " ) . 
 + defaultValidator ( IntegerType . instance ) . 
 + caching ( new CachingOptions ( new CachingOptions . KeyCache ( CachingOptions . KeyCache . Type . ALL ) , 
 + new CachingOptions . RowCache ( CachingOptions . RowCache . Type . HEAD , 100 ) ) ) ) ) ; 
 
 / / CounterCacheSpace 
 schema . add ( KSMetaData . testMetadata ( ks _ ccs ,

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index b993c48 . . 36050c5 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 15 , 6 + 15 , 7 @ @ dev 
 * include jna dependency in RPM package ( CASSANDRA - 1690 ) 
 * add - - skip - keys option to stress . py ( CASSANDRA - 1696 ) 
 * improve cli handling of non - string column names ( CASSANDRA - 1701 ) 
 + * enable skipping bad rows on LazilyCompacted path ( CASSANDRA - 1702 ) 
 
 
 0 . 7 . 0 - beta3 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnSerializer . java b / src / java / org / apache / cassandra / db / ColumnSerializer . java 
 index 34ac0ac . . 569289d 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnSerializer . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnSerializer . java 
 @ @ - 64 , 6 + 64 , 9 @ @ public class ColumnSerializer implements ICompactSerializer2 < IColumn > 
 public Column deserialize ( DataInput dis ) throws IOException 
 { 
 ByteBuffer name = FBUtilities . readShortByteArray ( dis ) ; 
 + if ( name . remaining ( ) < = 0 ) 
 + throw new CorruptColumnException ( " invalid column name length " + name . remaining ( ) ) ; 
 + 
 int b = dis . readUnsignedByte ( ) ; 
 if ( ( b & EXPIRATION _ MASK ) ! = 0 ) 
 { 
 @ @ - 97 , 4 + 100 , 12 @ @ public class ColumnSerializer implements ICompactSerializer2 < IColumn > 
 } 
 } 
 } 
 + 
 + private static class CorruptColumnException extends IOException 
 + { 
 + public CorruptColumnException ( String s ) 
 + { 
 + super ( s ) ; 
 + } 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java 
 index 057f4a2 . . 077914e 100644 
 - - - a / src / java / org / apache / cassandra / db / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / CompactionManager . java 
 @ @ - 272 , 16 + 272 , 21 @ @ public class CompactionManager implements CompactionManagerMBean 
 writer = new SSTableWriter ( newFilename , expectedBloomFilterSize , cfs . metadata , cfs . partitioner ) ; 
 while ( nni . hasNext ( ) ) 
 { 
 - AbstractCompactedRow row = nni . next ( ) ; 
 + writer . mark ( ) ; 
 try 
 { 
 + AbstractCompactedRow row = nni . next ( ) ; 
 writer . append ( row ) ; 
 } 
 - catch ( IOException ex ) 
 + catch ( Exception e ) 
 + { 
 + logger . error ( " non - fatal error during compaction " , e ) ; 
 + writer . reset ( ) ; 
 + } 
 + catch ( IOError e ) 
 { 
 - writer . abort ( ) ; 
 - / / rethrow the exception so that caller knows compaction failed . 
 - throw ex ; 
 + logger . error ( " non - fatal error during compaction " , e ) ; 
 + writer . reset ( ) ; 
 } 
 totalkeysWritten + + ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 index 4b3b5f0 . . 523a2c4 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 @ @ - 38 , 6 + 38 , 7 @ @ import org . apache . cassandra . dht . IPartitioner ; 
 import org . apache . cassandra . io . AbstractCompactedRow ; 
 import org . apache . cassandra . io . ICompactionInfo ; 
 import org . apache . cassandra . io . util . BufferedRandomAccessFile ; 
 + import org . apache . cassandra . io . util . FileMark ; 
 import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . io . util . SegmentedFile ; 
 import org . apache . cassandra . service . StorageService ; 
 @ @ - 55 , 6 + 56 , 7 @ @ public class SSTableWriter extends SSTable 
 private SegmentedFile . Builder dbuilder ; 
 private final BufferedRandomAccessFile dataFile ; 
 private DecoratedKey lastWrittenKey ; 
 + private FileMark dataMark ; 
 
 public SSTableWriter ( String filename , long keyCount ) throws IOException 
 { 
 @ @ - 99 , 6 + 101 , 25 @ @ public class SSTableWriter extends SSTable 
 } 
 } 
 
 + public void mark ( ) 
 + { 
 + dataMark = dataFile . mark ( ) ; 
 + iwriter . mark ( ) ; 
 + } 
 + 
 + public void reset ( ) 
 + { 
 + try 
 + { 
 + dataFile . reset ( dataMark ) ; 
 + iwriter . reset ( ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new IOError ( e ) ; 
 + } 
 + } 
 + 
 private long beforeAppend ( DecoratedKey decoratedKey ) throws IOException 
 { 
 if ( decoratedKey = = null ) 
 @ @ - 121 , 8 + 142 , 8 @ @ public class SSTableWriter extends SSTable 
 
 if ( logger . isTraceEnabled ( ) ) 
 logger . trace ( " wrote " + decoratedKey + " at " + dataPosition ) ; 
 - dbuilder . addPotentialBoundary ( dataPosition ) ; 
 iwriter . afterAppend ( decoratedKey , dataPosition ) ; 
 + dbuilder . addPotentialBoundary ( dataPosition ) ; 
 } 
 
 public void append ( AbstractCompactedRow row ) throws IOException 
 @ @ - 176 , 7 + 197 , 9 @ @ public class SSTableWriter extends SSTable 
 iwriter . close ( ) ; 
 
 / / main data 
 + long position = dataFile . getFilePointer ( ) ; 
 dataFile . close ( ) ; / / calls force 
 + FileUtils . truncate ( dataFile . getPath ( ) , position ) ; 
 
 / / write sstable statistics 
 writeStatistics ( descriptor , estimatedRowSize , estimatedColumnCount ) ; 
 @ @ - 358 , 7 + 381 , 8 @ @ public class SSTableWriter extends SSTable 
 public final SegmentedFile . Builder builder ; 
 public final IndexSummary summary ; 
 public final BloomFilter bf ; 
 - 
 + private FileMark mark ; 
 + 
 IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException 
 { 
 this . desc = desc ; 
 @ @ - 396 , 11 + 420 , 25 @ @ public class SSTableWriter extends SSTable 
 stream . close ( ) ; 
 
 / / index 
 - indexFile . getChannel ( ) . force ( true ) ; 
 - indexFile . close ( ) ; 
 + long position = indexFile . getFilePointer ( ) ; 
 + indexFile . close ( ) ; / / calls force 
 + FileUtils . truncate ( indexFile . getPath ( ) , position ) ; 
 
 / / finalize in - memory index state 
 summary . complete ( ) ; 
 } 
 + 
 + public void mark ( ) 
 + { 
 + mark = indexFile . mark ( ) ; 
 + } 
 + 
 + public void reset ( ) throws IOException 
 + { 
 + / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . 
 + / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so 
 + / / we assume that if that worked then we won ' t be trying to reset . 
 + indexFile . reset ( mark ) ; 
 + } 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / io / util / FileUtils . java b / src / java / org / apache / cassandra / io / util / FileUtils . java 
 index e2ca78c . . 11c6b4b 100644 
 - - - a / src / java / org / apache / cassandra / io / util / FileUtils . java 
 + + + b / src / java / org / apache / cassandra / io / util / FileUtils . java 
 @ @ - 19 , 7 + 19 , 9 @ @ 
 package org . apache . cassandra . io . util ; 
 
 import java . io . File ; 
 + import java . io . FileNotFoundException ; 
 import java . io . IOException ; 
 + import java . io . RandomAccessFile ; 
 import java . text . DecimalFormat ; 
 import java . util . Comparator ; 
 import java . util . List ; 
 @ @ - 27 , 9 + 29 , 6 @ @ import java . util . List ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 - import com . sun . jna . LastErrorException ; 
 - import org . apache . cassandra . utils . CLibrary ; 
 - 
 
 public class FileUtils 
 { 
 @ @ - 65 , 6 + 64 , 20 @ @ public class FileUtils 
 throw new IOException ( String . format ( " Failed to rename % s to % s " , from . getPath ( ) , to . getPath ( ) ) ) ; 
 } 
 
 + public static void truncate ( String path , long size ) throws IOException 
 + { 
 + RandomAccessFile file ; 
 + try 
 + { 
 + file = new RandomAccessFile ( path , " rw " ) ; 
 + } 
 + catch ( FileNotFoundException e ) 
 + { 
 + throw new RuntimeException ( e ) ; 
 + } 
 + file . getChannel ( ) . truncate ( size ) ; 
 + } 
 + 
 public static class FileComparator implements Comparator < File > 
 { 
 public int compare ( File f , File f2 )
