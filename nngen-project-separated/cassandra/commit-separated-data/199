BLEU SCORE: 0.040583489434387374

TEST MSG: Remove GossipDigestSynVerbHandler # doSort ( )
GENERATED MSG: merge from 0 . 6

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index a10b6eb . . 62775ce 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 4 . 0 <nl> + * Remove GossipDigestSynVerbHandler # doSort ( ) ( CASSANDRA - 14174 ) <nl> * Add nodetool clientlist ( CASSANDRA - 13665 ) <nl> * Revert ProtocolVersion changes from CASSANDRA - 7544 ( CASSANDRA - 14211 ) <nl> * Non - disruptive seed node list reload ( CASSANDRA - 14190 ) <nl> diff - - git a / src / java / org / apache / cassandra / gms / GossipDigestSynVerbHandler . java b / src / java / org / apache / cassandra / gms / GossipDigestSynVerbHandler . java <nl> index 9619f4e . . b06c24d 100644 <nl> - - - a / src / java / org / apache / cassandra / gms / GossipDigestSynVerbHandler . java <nl> + + + b / src / java / org / apache / cassandra / gms / GossipDigestSynVerbHandler . java <nl> @ @ - 19 , 8 + 19 , 6 @ @ package org . apache . cassandra . gms ; <nl> <nl> import java . util . * ; <nl> <nl> - import com . google . common . collect . Maps ; <nl> - <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 99 , 8 + 97 , 6 @ @ public class GossipDigestSynVerbHandler implements IVerbHandler < GossipDigestSyn > <nl> logger . trace ( " Gossip syn digests are : { } " , sb ) ; <nl> } <nl> <nl> - doSort ( gDigestList ) ; <nl> - <nl> List < GossipDigest > deltaGossipDigestList = new ArrayList < GossipDigest > ( ) ; <nl> Map < InetAddressAndPort , EndpointState > deltaEpStateMap = new HashMap < InetAddressAndPort , EndpointState > ( ) ; <nl> Gossiper . instance . examineGossiper ( gDigestList , deltaGossipDigestList , deltaEpStateMap ) ; <nl> @ @ - 112 , 47 + 108 , 4 @ @ public class GossipDigestSynVerbHandler implements IVerbHandler < GossipDigestSyn > <nl> logger . trace ( " Sending a GossipDigestAckMessage to { } " , from ) ; <nl> MessagingService . instance ( ) . sendOneWay ( gDigestAckMessage , from ) ; <nl> } <nl> - <nl> - / * <nl> - * First construct a map whose key is the endpoint in the GossipDigest and the value is the <nl> - * GossipDigest itself . Then build a list of version differences i . e difference between the <nl> - * version in the GossipDigest and the version in the local state for a given InetAddressAndPort . <nl> - * Sort this list . Now loop through the sorted list and retrieve the GossipDigest corresponding <nl> - * to the endpoint from the map that was initially constructed . <nl> - * / <nl> - private void doSort ( List < GossipDigest > gDigestList ) <nl> - { <nl> - / * Construct a map of endpoint to GossipDigest . * / <nl> - Map < InetAddressAndPort , GossipDigest > epToDigestMap = Maps . newHashMapWithExpectedSize ( gDigestList . size ( ) ) ; <nl> - for ( GossipDigest gDigest : gDigestList ) <nl> - { <nl> - epToDigestMap . put ( gDigest . getEndpoint ( ) , gDigest ) ; <nl> - } <nl> - <nl> - / * <nl> - * These digests have their maxVersion set to the difference of the version <nl> - * of the local EndpointState and the version found in the GossipDigest . <nl> - * / <nl> - List < GossipDigest > diffDigests = new ArrayList < GossipDigest > ( gDigestList . size ( ) ) ; <nl> - for ( GossipDigest gDigest : gDigestList ) <nl> - { <nl> - InetAddressAndPort ep = gDigest . getEndpoint ( ) ; <nl> - EndpointState epState = Gossiper . instance . getEndpointStateForEndpoint ( ep ) ; <nl> - int version = ( epState ! = null ) ? Gossiper . instance . getMaxEndpointStateVersion ( epState ) : 0 ; <nl> - int diffVersion = Math . abs ( version - gDigest . getMaxVersion ( ) ) ; <nl> - diffDigests . add ( new GossipDigest ( ep , gDigest . getGeneration ( ) , diffVersion ) ) ; <nl> - } <nl> - <nl> - gDigestList . clear ( ) ; <nl> - Collections . sort ( diffDigests ) ; <nl> - int size = diffDigests . size ( ) ; <nl> - / * <nl> - * Report the digests in descending order . This takes care of the endpoints <nl> - * that are far behind w . r . t this local endpoint <nl> - * / <nl> - for ( int i = size - 1 ; i > = 0 ; - - i ) <nl> - { <nl> - gDigestList . add ( epToDigestMap . get ( diffDigests . get ( i ) . getEndpoint ( ) ) ) ; <nl> - } <nl> - } <nl> }
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 8d9e2ea . . c97b17f 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 7 + 1 , 10 @ @ <nl> dev <nl> * sstable versioning ( CASSANDRA - 389 ) <nl> <nl> - 0 . 6 . 0 - dev <nl> + 0 . 6 . 0 - RC1 <nl> + * fix compaction bucketing bug ( CASSANDRA - 814 ) <nl> + <nl> + 0 . 6 . 0 - beta1 / beta2 <nl> * add batch _ mutate thrift command , deprecating batch _ insert ( CASSANDRA - 336 ) <nl> * remove get _ key _ range Thrift API , deprecated in 0 . 5 ( CASSANDRA - 710 ) <nl> * add optional login ( ) Thrift call for authentication ( CASSANDRA - 547 ) <nl> @ @ - 42 , 7 + 45 , 9 @ @ dev <nl> * allow larger numbers of keys ( > 140M ) in a sstable bloom filter <nl> ( CASSANDRA - 790 ) <nl> * include jvm argument improvements from CASSANDRA - 504 in debian package <nl> - * change streaming chunk size to 32MB ( was 64MB ) ( CASSANDRA - 795 ) <nl> + * change streaming chunk size to 32MB to accomodate Windows XP limitations <nl> + ( was 64MB ) ( CASSANDRA - 795 ) <nl> + * fix get _ range _ slice returning results in the wrong order ( CASSANDRA - 781 ) <nl> <nl> <nl> 0 . 5 . 0 final <nl> diff - - git a / build . xml b / build . xml <nl> index ea79876 . . 54ef12d 100644 <nl> - - - a / build . xml <nl> + + + b / build . xml <nl> @ @ - 314 , 6 + 314 , 7 @ @ <nl> < include name = " * * " / > <nl> < exclude name = " build / * * " / > <nl> < exclude name = " src / gen - java / * * " / > <nl> + < exclude name = " interface / avro / * * " / > <nl> < / tarfileset > <nl> < / tar > <nl> < / target > <nl> diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> index fbd5ebb . . 1b5b6b1 100644 <nl> - - - a / src / java / org / apache / cassandra / db / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> @ @ - 89 , 7 + 89 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> return 0 ; <nl> } <nl> logger . debug ( " Checking to see if compaction of " + cfs . columnFamily _ + " would be useful " ) ; <nl> - Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> + Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> updateEstimateFor ( cfs , buckets ) ; <nl> <nl> for ( List < SSTableReader > sstables : buckets ) <nl> @ @ - 441 , 7 + 441 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> / * <nl> * Group files of similar size into buckets . <nl> * / <nl> - static Set < List < SSTableReader > > getCompactionBuckets ( Iterable < SSTableReader > files , long min ) <nl> + static Set < List < SSTableReader > > getBuckets ( Iterable < SSTableReader > files , long min ) <nl> { <nl> Map < List < SSTableReader > , Long > buckets = new HashMap < List < SSTableReader > , Long > ( ) ; <nl> for ( SSTableReader sstable : files ) <nl> @ @ - 461 , 7 + 461 , 8 @ @ public class CompactionManager implements CompactionManagerMBean <nl> { <nl> / / remove and re - add because adding changes the hash <nl> buckets . remove ( bucket ) ; <nl> - averageSize = ( averageSize + size ) / 2 ; <nl> + long totalSize = bucket . size ( ) * averageSize ; <nl> + averageSize = ( totalSize + size ) / ( bucket . size ( ) + 1 ) ; <nl> bucket . add ( sstable ) ; <nl> buckets . put ( bucket , averageSize ) ; <nl> bFound = true ; <nl> @ @ - 538 , 7 + 539 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> public void run ( ) <nl> { <nl> logger . debug ( " Estimating compactions for " + cfs . columnFamily _ ) ; <nl> - final Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> + final Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> updateEstimateFor ( cfs , buckets ) ; <nl> } <nl> } ;

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index a10b6eb . . 62775ce 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 4 . 0 
 + * Remove GossipDigestSynVerbHandler # doSort ( ) ( CASSANDRA - 14174 ) 
 * Add nodetool clientlist ( CASSANDRA - 13665 ) 
 * Revert ProtocolVersion changes from CASSANDRA - 7544 ( CASSANDRA - 14211 ) 
 * Non - disruptive seed node list reload ( CASSANDRA - 14190 ) 
 diff - - git a / src / java / org / apache / cassandra / gms / GossipDigestSynVerbHandler . java b / src / java / org / apache / cassandra / gms / GossipDigestSynVerbHandler . java 
 index 9619f4e . . b06c24d 100644 
 - - - a / src / java / org / apache / cassandra / gms / GossipDigestSynVerbHandler . java 
 + + + b / src / java / org / apache / cassandra / gms / GossipDigestSynVerbHandler . java 
 @ @ - 19 , 8 + 19 , 6 @ @ package org . apache . cassandra . gms ; 
 
 import java . util . * ; 
 
 - import com . google . common . collect . Maps ; 
 - 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 99 , 8 + 97 , 6 @ @ public class GossipDigestSynVerbHandler implements IVerbHandler < GossipDigestSyn > 
 logger . trace ( " Gossip syn digests are : { } " , sb ) ; 
 } 
 
 - doSort ( gDigestList ) ; 
 - 
 List < GossipDigest > deltaGossipDigestList = new ArrayList < GossipDigest > ( ) ; 
 Map < InetAddressAndPort , EndpointState > deltaEpStateMap = new HashMap < InetAddressAndPort , EndpointState > ( ) ; 
 Gossiper . instance . examineGossiper ( gDigestList , deltaGossipDigestList , deltaEpStateMap ) ; 
 @ @ - 112 , 47 + 108 , 4 @ @ public class GossipDigestSynVerbHandler implements IVerbHandler < GossipDigestSyn > 
 logger . trace ( " Sending a GossipDigestAckMessage to { } " , from ) ; 
 MessagingService . instance ( ) . sendOneWay ( gDigestAckMessage , from ) ; 
 } 
 - 
 - / * 
 - * First construct a map whose key is the endpoint in the GossipDigest and the value is the 
 - * GossipDigest itself . Then build a list of version differences i . e difference between the 
 - * version in the GossipDigest and the version in the local state for a given InetAddressAndPort . 
 - * Sort this list . Now loop through the sorted list and retrieve the GossipDigest corresponding 
 - * to the endpoint from the map that was initially constructed . 
 - * / 
 - private void doSort ( List < GossipDigest > gDigestList ) 
 - { 
 - / * Construct a map of endpoint to GossipDigest . * / 
 - Map < InetAddressAndPort , GossipDigest > epToDigestMap = Maps . newHashMapWithExpectedSize ( gDigestList . size ( ) ) ; 
 - for ( GossipDigest gDigest : gDigestList ) 
 - { 
 - epToDigestMap . put ( gDigest . getEndpoint ( ) , gDigest ) ; 
 - } 
 - 
 - / * 
 - * These digests have their maxVersion set to the difference of the version 
 - * of the local EndpointState and the version found in the GossipDigest . 
 - * / 
 - List < GossipDigest > diffDigests = new ArrayList < GossipDigest > ( gDigestList . size ( ) ) ; 
 - for ( GossipDigest gDigest : gDigestList ) 
 - { 
 - InetAddressAndPort ep = gDigest . getEndpoint ( ) ; 
 - EndpointState epState = Gossiper . instance . getEndpointStateForEndpoint ( ep ) ; 
 - int version = ( epState ! = null ) ? Gossiper . instance . getMaxEndpointStateVersion ( epState ) : 0 ; 
 - int diffVersion = Math . abs ( version - gDigest . getMaxVersion ( ) ) ; 
 - diffDigests . add ( new GossipDigest ( ep , gDigest . getGeneration ( ) , diffVersion ) ) ; 
 - } 
 - 
 - gDigestList . clear ( ) ; 
 - Collections . sort ( diffDigests ) ; 
 - int size = diffDigests . size ( ) ; 
 - / * 
 - * Report the digests in descending order . This takes care of the endpoints 
 - * that are far behind w . r . t this local endpoint 
 - * / 
 - for ( int i = size - 1 ; i > = 0 ; - - i ) 
 - { 
 - gDigestList . add ( epToDigestMap . get ( diffDigests . get ( i ) . getEndpoint ( ) ) ) ; 
 - } 
 - } 
 }

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 8d9e2ea . . c97b17f 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 7 + 1 , 10 @ @ 
 dev 
 * sstable versioning ( CASSANDRA - 389 ) 
 
 - 0 . 6 . 0 - dev 
 + 0 . 6 . 0 - RC1 
 + * fix compaction bucketing bug ( CASSANDRA - 814 ) 
 + 
 + 0 . 6 . 0 - beta1 / beta2 
 * add batch _ mutate thrift command , deprecating batch _ insert ( CASSANDRA - 336 ) 
 * remove get _ key _ range Thrift API , deprecated in 0 . 5 ( CASSANDRA - 710 ) 
 * add optional login ( ) Thrift call for authentication ( CASSANDRA - 547 ) 
 @ @ - 42 , 7 + 45 , 9 @ @ dev 
 * allow larger numbers of keys ( > 140M ) in a sstable bloom filter 
 ( CASSANDRA - 790 ) 
 * include jvm argument improvements from CASSANDRA - 504 in debian package 
 - * change streaming chunk size to 32MB ( was 64MB ) ( CASSANDRA - 795 ) 
 + * change streaming chunk size to 32MB to accomodate Windows XP limitations 
 + ( was 64MB ) ( CASSANDRA - 795 ) 
 + * fix get _ range _ slice returning results in the wrong order ( CASSANDRA - 781 ) 
 
 
 0 . 5 . 0 final 
 diff - - git a / build . xml b / build . xml 
 index ea79876 . . 54ef12d 100644 
 - - - a / build . xml 
 + + + b / build . xml 
 @ @ - 314 , 6 + 314 , 7 @ @ 
 < include name = " * * " / > 
 < exclude name = " build / * * " / > 
 < exclude name = " src / gen - java / * * " / > 
 + < exclude name = " interface / avro / * * " / > 
 < / tarfileset > 
 < / tar > 
 < / target > 
 diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java 
 index fbd5ebb . . 1b5b6b1 100644 
 - - - a / src / java / org / apache / cassandra / db / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / CompactionManager . java 
 @ @ - 89 , 7 + 89 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 return 0 ; 
 } 
 logger . debug ( " Checking to see if compaction of " + cfs . columnFamily _ + " would be useful " ) ; 
 - Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 + Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 updateEstimateFor ( cfs , buckets ) ; 
 
 for ( List < SSTableReader > sstables : buckets ) 
 @ @ - 441 , 7 + 441 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 / * 
 * Group files of similar size into buckets . 
 * / 
 - static Set < List < SSTableReader > > getCompactionBuckets ( Iterable < SSTableReader > files , long min ) 
 + static Set < List < SSTableReader > > getBuckets ( Iterable < SSTableReader > files , long min ) 
 { 
 Map < List < SSTableReader > , Long > buckets = new HashMap < List < SSTableReader > , Long > ( ) ; 
 for ( SSTableReader sstable : files ) 
 @ @ - 461 , 7 + 461 , 8 @ @ public class CompactionManager implements CompactionManagerMBean 
 { 
 / / remove and re - add because adding changes the hash 
 buckets . remove ( bucket ) ; 
 - averageSize = ( averageSize + size ) / 2 ; 
 + long totalSize = bucket . size ( ) * averageSize ; 
 + averageSize = ( totalSize + size ) / ( bucket . size ( ) + 1 ) ; 
 bucket . add ( sstable ) ; 
 buckets . put ( bucket , averageSize ) ; 
 bFound = true ; 
 @ @ - 538 , 7 + 539 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 public void run ( ) 
 { 
 logger . debug ( " Estimating compactions for " + cfs . columnFamily _ ) ; 
 - final Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 + final Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 updateEstimateFor ( cfs , buckets ) ; 
 } 
 } ;
