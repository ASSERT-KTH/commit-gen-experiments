BLEU SCORE: 0.040583489434387374

TEST MSG: nodetool no longer shows node joining
GENERATED MSG: Fix CQL doc imprecision

TEST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / tools / NodeTool . java b / src / java / org / apache / cassandra / tools / NodeTool . java <nl> index d24e013 . . 5120739 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / NodeTool . java <nl> + + + b / src / java / org / apache / cassandra / tools / NodeTool . java <nl> @ @ - 506 , 41 + 506 , 49 @ @ public class NodeTool <nl> else <nl> System . out . println ( ) ; <nl> <nl> - for ( Map . Entry < InetAddress , Float > entry : filteredOwnerships . entrySet ( ) ) <nl> + for ( Map . Entry < String , String > entry : endpointsToTokens . entries ( ) ) <nl> { <nl> - String endpoint = entry . getKey ( ) . getHostAddress ( ) ; <nl> - for ( String token : endpointsToTokens . get ( endpoint ) ) <nl> + String endpoint = entry . getKey ( ) ; <nl> + String rack ; <nl> + try <nl> { <nl> - String rack ; <nl> - try <nl> - { <nl> - rack = probe . getEndpointSnitchInfoProxy ( ) . getRack ( endpoint ) ; <nl> - } catch ( UnknownHostException e ) <nl> - { <nl> - rack = " Unknown " ; <nl> - } <nl> + rack = probe . getEndpointSnitchInfoProxy ( ) . getRack ( endpoint ) ; <nl> + } <nl> + catch ( UnknownHostException e ) <nl> + { <nl> + rack = " Unknown " ; <nl> + } <nl> <nl> - String status = liveNodes . contains ( endpoint ) <nl> - ? " Up " <nl> - : deadNodes . contains ( endpoint ) <nl> - ? " Down " <nl> - : " ? " ; <nl> - <nl> - String state = " Normal " ; <nl> - <nl> - if ( joiningNodes . contains ( endpoint ) ) <nl> - state = " Joining " ; <nl> - else if ( leavingNodes . contains ( endpoint ) ) <nl> - state = " Leaving " ; <nl> - else if ( movingNodes . contains ( endpoint ) ) <nl> - state = " Moving " ; <nl> - <nl> - String load = loadMap . containsKey ( endpoint ) <nl> - ? loadMap . get ( endpoint ) <nl> - : " ? " ; <nl> - String owns = new DecimalFormat ( " # # 0 . 00 % " ) . format ( entry . getValue ( ) ) ; <nl> - System . out . printf ( format , endpoint , rack , status , state , load , owns , token ) ; <nl> + String status = liveNodes . contains ( endpoint ) <nl> + ? " Up " <nl> + : deadNodes . contains ( endpoint ) <nl> + ? " Down " <nl> + : " ? " ; <nl> + <nl> + String state = " Normal " ; <nl> + <nl> + if ( joiningNodes . contains ( endpoint ) ) <nl> + state = " Joining " ; <nl> + else if ( leavingNodes . contains ( endpoint ) ) <nl> + state = " Leaving " ; <nl> + else if ( movingNodes . contains ( endpoint ) ) <nl> + state = " Moving " ; <nl> + <nl> + String load = loadMap . containsKey ( endpoint ) <nl> + ? loadMap . get ( endpoint ) <nl> + : " ? " ; <nl> + String owns ; <nl> + try <nl> + { <nl> + InetAddress ep = InetAddress . getByName ( endpoint ) ; <nl> + Float percent = filteredOwnerships . get ( ep ) ; <nl> + owns = ( percent ! = null ) ? new DecimalFormat ( " # # 0 . 00 % " ) . format ( percent ) : " ? " ; <nl> + } <nl> + catch ( UnknownHostException e ) <nl> + { <nl> + throw new RuntimeException ( e ) ; <nl> } <nl> + System . out . printf ( format , endpoint , rack , status , state , load , owns , entry . getValue ( ) ) ; <nl> } <nl> System . out . println ( ) ; <nl> }
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 47ff752 . . fb9915e 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 1 . 2 . 10 <nl> + * Avoid second - guessing out - of - space state ( CASSANDRA - 5605 ) <nl> * Tuning knobs for dealing with large blobs and many CFs ( CASSANDRA - 5982 ) <nl> * ( Hadoop ) Fix CQLRW for thrift tables ( CASSANDRA - 6002 ) <nl> * Fix possible divide - by - zero in HHOM ( CASSANDRA - 5990 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / Directories . java b / src / java / org / apache / cassandra / db / Directories . java <nl> index 0890d29 . . 351c0c0 100644 <nl> - - - a / src / java / org / apache / cassandra / db / Directories . java <nl> + + + b / src / java / org / apache / cassandra / db / Directories . java <nl> @ @ - 19 , 6 + 19 , 7 @ @ package org . apache . cassandra . db ; <nl> <nl> import java . io . File ; <nl> import java . io . FileFilter ; <nl> + import java . io . IOError ; <nl> import java . io . IOException ; <nl> import java . util . * ; <nl> import java . util . concurrent . atomic . AtomicInteger ; <nl> @ @ - 132 , 9 + 133 , 9 @ @ public class Directories <nl> return null ; <nl> } <nl> <nl> - public File getDirectoryForNewSSTables ( long estimatedSize ) <nl> + public File getDirectoryForNewSSTables ( ) <nl> { <nl> - File path = getLocationWithMaximumAvailableSpace ( estimatedSize ) ; <nl> + File path = getWriteableLocationAsFile ( ) ; <nl> <nl> / / Requesting GC has a chance to free space only if we ' re using mmap and a non SUN jvm <nl> if ( path = = null <nl> @ @ - 154 , 68 + 155 , 37 @ @ public class Directories <nl> { <nl> throw new AssertionError ( e ) ; <nl> } <nl> - path = getLocationWithMaximumAvailableSpace ( estimatedSize ) ; <nl> + path = getWriteableLocationAsFile ( ) ; <nl> } <nl> <nl> return path ; <nl> } <nl> <nl> - / * <nl> - * Loop through all the disks to see which disk has the max free space <nl> - * return the disk with max free space for compactions . If the size of the expected <nl> - * compacted file is greater than the max disk space available return null , we cannot <nl> - * do compaction in this case . <nl> - * / <nl> - public File getLocationWithMaximumAvailableSpace ( long estimatedSize ) <nl> + public File getWriteableLocationAsFile ( ) <nl> { <nl> - long maxFreeDisk = 0 ; <nl> - File maxLocation = null ; <nl> - <nl> - for ( File dir : sstableDirectories ) <nl> - { <nl> - if ( BlacklistedDirectories . isUnwritable ( dir ) ) <nl> - continue ; <nl> - <nl> - long usableSpace = dir . getUsableSpace ( ) ; <nl> - if ( maxFreeDisk < usableSpace ) <nl> - { <nl> - maxFreeDisk = usableSpace ; <nl> - maxLocation = dir ; <nl> - } <nl> - } <nl> - / / Load factor of 0 . 9 we do not want to use the entire disk that is too risky . <nl> - maxFreeDisk = ( long ) ( 0 . 9 * maxFreeDisk ) ; <nl> - logger . debug ( String . format ( " expected data files size is % d ; largest free partition ( % s ) has % d bytes free " , <nl> - estimatedSize , maxLocation , maxFreeDisk ) ) ; <nl> - <nl> - return estimatedSize < maxFreeDisk ? maxLocation : null ; <nl> + return getLocationForDisk ( getWriteableLocation ( ) ) ; <nl> } <nl> <nl> / * * <nl> - * Finds location which is capable of holding given { @ code estimatedSize } . <nl> - * Picks a non - blacklisted directory with most free space and least current tasks . <nl> - * If no directory can hold given { @ code estimatedSize } , then returns null . <nl> + * @ return a non - blacklisted directory with the most free space and least current tasks . <nl> * <nl> - * @ param estimatedSize estimated size you need to find location to fit <nl> - * @ return directory capable of given estimated size , or null if none found <nl> + * @ throws IOError if all directories are blacklisted . <nl> * / <nl> - public DataDirectory getLocationCapableOfSize ( long estimatedSize ) <nl> + public DataDirectory getWriteableLocation ( ) <nl> { <nl> List < DataDirectory > candidates = new ArrayList < DataDirectory > ( ) ; <nl> <nl> / / pick directories with enough space and so that resulting sstable dirs aren ' t blacklisted for writes . <nl> for ( DataDirectory dataDir : dataFileLocations ) <nl> { <nl> - File sstableDir = getLocationForDisk ( dataDir ) ; <nl> - <nl> - if ( BlacklistedDirectories . isUnwritable ( sstableDir ) ) <nl> + if ( BlacklistedDirectories . isUnwritable ( getLocationForDisk ( dataDir ) ) ) <nl> continue ; <nl> - <nl> - / / need a separate check for sstableDir itself - could be a mounted separate disk or SSD just for this CF . <nl> - if ( dataDir . getEstimatedAvailableSpace ( ) > estimatedSize & & sstableDir . getUsableSpace ( ) * 0 . 9 > estimatedSize ) <nl> - candidates . add ( dataDir ) ; <nl> + candidates . add ( dataDir ) ; <nl> } <nl> <nl> + if ( candidates . isEmpty ( ) ) <nl> + throw new IOError ( new IOException ( " All configured data directories have been blacklisted as unwritable for erroring out " ) ) ; <nl> + <nl> / / sort directories by free space , in _ descending _ order . <nl> Collections . sort ( candidates ) ; <nl> <nl> @ @ - 228 , 7 + 198 , 7 @ @ public class Directories <nl> } <nl> } ) ; <nl> <nl> - return candidates . isEmpty ( ) ? null : candidates . get ( 0 ) ; <nl> + return candidates . get ( 0 ) ; <nl> } <nl> <nl> <nl> @ @ - 265 , 7 + 235 , 7 @ @ public class Directories <nl> public long getEstimatedAvailableSpace ( ) <nl> { <nl> / / Load factor of 0 . 9 we do not want to use the entire disk that is too risky . <nl> - return ( long ) ( 0 . 9 * location . getUsableSpace ( ) ) - estimatedWorkingSize . get ( ) ; <nl> + return location . getUsableSpace ( ) - estimatedWorkingSize . get ( ) ; <nl> } <nl> <nl> public int compareTo ( DataDirectory o ) <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> index 4c9c707 . . 93f3108 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> @ @ - 584 , 7 + 584 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> logger . info ( " Cleaning up " + sstable ) ; <nl> / / Calculate the expected compacted filesize <nl> long expectedRangeFileSize = cfs . getExpectedCompactedFileSize ( Arrays . asList ( sstable ) , OperationType . CLEANUP ) ; <nl> - File compactionFileLocation = cfs . directories . getDirectoryForNewSSTables ( expectedRangeFileSize ) ; <nl> + File compactionFileLocation = cfs . directories . getDirectoryForNewSSTables ( ) ; <nl> if ( compactionFileLocation = = null ) <nl> throw new IOException ( " disk full " ) ; <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / Scrubber . java b / src / java / org / apache / cassandra / db / compaction / Scrubber . java <nl> index cb529cb . . 7b2178b 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / Scrubber . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / Scrubber . java <nl> @ @ - 76 , 7 + 76 , 7 @ @ public class Scrubber implements Closeable <nl> this . outputHandler = outputHandler ; <nl> <nl> / / Calculate the expected compacted filesize <nl> - this . destination = cfs . directories . getDirectoryForNewSSTables ( sstable . onDiskLength ( ) ) ; <nl> + this . destination = cfs . directories . getDirectoryForNewSSTables ( ) ; <nl> if ( destination = = null ) <nl> throw new IOException ( " disk full " ) ; <nl> <nl> diff - - git a / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java b / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java <nl> index 1be4803 . . 198a88d 100644 <nl> - - - a / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java <nl> + + + b / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java <nl> @ @ - 34 , 7 + 34 , 7 @ @ public abstract class DiskAwareRunnable extends WrappedRunnable <nl> while ( true ) <nl> { <nl> writeSize = getExpectedWriteSize ( ) ; <nl> - directory = getDirectories ( ) . getLocationCapableOfSize ( writeSize ) ; <nl> + directory = getDirectories ( ) . getWriteableLocation ( ) ; <nl> if ( directory ! = null | | ! reduceScopeForLimitedSpace ( ) ) <nl> break ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamIn . java b / src / java / org / apache / cassandra / streaming / StreamIn . java <nl> index 740b430 . . 85ea7fa 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamIn . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamIn . java <nl> @ @ - 80 , 7 + 80 , 7 @ @ public class StreamIn <nl> / / new local sstable <nl> Table table = Table . open ( remotedesc . ksname ) ; <nl> ColumnFamilyStore cfStore = table . getColumnFamilyStore ( remotedesc . cfname ) ; <nl> - Directories . DataDirectory localDir = cfStore . directories . getLocationCapableOfSize ( remote . size ) ; <nl> + Directories . DataDirectory localDir = cfStore . directories . getWriteableLocation ( ) ; <nl> if ( localDir = = null ) <nl> throw new RuntimeException ( " Insufficient disk space to store " + remote . size + " bytes " ) ; <nl> Descriptor localdesc = Descriptor . fromFilename ( cfStore . getTempSSTablePath ( cfStore . directories . getLocationForDisk ( localDir ) ) ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java b / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java <nl> index a394644 . . abe3f05 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java <nl> @ @ - 837 , 7 + 837 , 7 @ @ public class ColumnFamilyStoreTest extends SchemaLoader <nl> <nl> for ( int version = 1 ; version < = 2 ; + + version ) <nl> { <nl> - Descriptor existing = new Descriptor ( cfs . directories . getDirectoryForNewSSTables ( 1 ) , " Keyspace2 " , " Standard1 " , version , false ) ; <nl> + Descriptor existing = new Descriptor ( cfs . directories . getDirectoryForNewSSTables ( ) , " Keyspace2 " , " Standard1 " , version , false ) ; <nl> Descriptor desc = new Descriptor ( Directories . getBackupsDirectory ( existing ) , " Keyspace2 " , " Standard1 " , version , false ) ; <nl> for ( Component c : new Component [ ] { Component . DATA , Component . PRIMARY _ INDEX , Component . FILTER , Component . STATS } ) <nl> assertTrue ( " can not find backedup file : " + desc . filenameFor ( c ) , new File ( desc . filenameFor ( c ) ) . exists ( ) ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / DirectoriesTest . java b / test / unit / org / apache / cassandra / db / DirectoriesTest . java <nl> index 21e183c . . dce6f87 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / DirectoriesTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / DirectoriesTest . java <nl> @ @ - 107 , 7 + 107 , 7 @ @ public class DirectoriesTest <nl> for ( String cf : CFS ) <nl> { <nl> Directories directories = Directories . create ( KS , cf ) ; <nl> - Assert . assertEquals ( cfDir ( cf ) , directories . getDirectoryForNewSSTables ( 0 ) ) ; <nl> + Assert . assertEquals ( cfDir ( cf ) , directories . getDirectoryForNewSSTables ( ) ) ; <nl> <nl> Descriptor desc = new Descriptor ( cfDir ( cf ) , KS , cf , 1 , false ) ; <nl> File snapshotDir = new File ( cfDir ( cf ) , File . separator + Directories . SNAPSHOT _ SUBDIR + File . separator + " 42 " ) ; <nl> @ @ - 180 , 7 + 180 , 7 @ @ public class DirectoriesTest <nl> { <nl> / * files not matching the pattern should just be ignored , with a log warning * / <nl> Directories directories = Directories . create ( KS , " bad " ) ; <nl> - File dir = directories . getDirectoryForNewSSTables ( 1 ) ; <nl> + File dir = directories . getDirectoryForNewSSTables ( ) ; <nl> File f = File . createTempFile ( " bad " , " file " , dir . getParentFile ( ) ) ; <nl> Directories . migrateSSTables ( ) ; <nl> Assert . assertTrue ( f . isFile ( ) ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / ScrubTest . java b / test / unit / org / apache / cassandra / db / ScrubTest . java <nl> index 26f0e78 . . c26939a 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / ScrubTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / ScrubTest . java <nl> @ @ - 55 , 7 + 55 , 7 @ @ public class ScrubTest extends SchemaLoader <nl> File rootDir = new File ( root ) ; <nl> assert rootDir . isDirectory ( ) ; <nl> <nl> - File destDir = Directories . create ( TABLE , cf ) . getDirectoryForNewSSTables ( 1 ) ; <nl> + File destDir = Directories . create ( TABLE , cf ) . getDirectoryForNewSSTables ( ) ; <nl> <nl> String corruptSSTableName = null ; <nl> <nl> diff - - git a / test / unit / org / apache / cassandra / io / sstable / SSTableReaderTest . java b / test / unit / org / apache / cassandra / io / sstable / SSTableReaderTest . java <nl> index d0670a0 . . 02b6855 100644 <nl> - - - a / test / unit / org / apache / cassandra / io / sstable / SSTableReaderTest . java <nl> + + + b / test / unit / org / apache / cassandra / io / sstable / SSTableReaderTest . java <nl> @ @ - 28 , 7 + 28 , 6 @ @ import java . util . ArrayList ; <nl> import java . util . Arrays ; <nl> import java . util . List ; <nl> import java . util . concurrent . ExecutionException ; <nl> - import java . util . * ; <nl> <nl> import org . junit . Test ; <nl> import org . junit . runner . RunWith ; <nl> @ @ - 230 , 7 + 229 , 7 @ @ public class SSTableReaderTest extends SchemaLoader <nl> File rootDir = new File ( root + File . separator + " hb " + File . separator + " Keyspace1 " ) ; <nl> assert rootDir . isDirectory ( ) ; <nl> <nl> - File destDir = Directories . create ( " Keyspace1 " , " Indexed1 " ) . getDirectoryForNewSSTables ( 0 ) ; <nl> + File destDir = Directories . create ( " Keyspace1 " , " Indexed1 " ) . getDirectoryForNewSSTables ( ) ; <nl> assert destDir ! = null ; <nl> <nl> FileUtils . createDirectory ( destDir ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java b / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java <nl> index 6efdc9b . . ce569b9 100644 <nl> - - - a / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java <nl> + + + b / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java <nl> @ @ - 43 , 7 + 43 , 7 @ @ public class SSTableSimpleWriterTest extends SchemaLoader <nl> String cfname = " StandardInteger1 " ; <nl> <nl> Table t = Table . open ( tablename ) ; / / make sure we create the directory <nl> - File dir = Directories . create ( tablename , cfname ) . getDirectoryForNewSSTables ( 0 ) ; <nl> + File dir = Directories . create ( tablename , cfname ) . getDirectoryForNewSSTables ( ) ; <nl> assert dir . exists ( ) ; <nl> <nl> IPartitioner partitioner = StorageService . getPartitioner ( ) ;

TEST DIFF:
diff - - git a / src / java / org / apache / cassandra / tools / NodeTool . java b / src / java / org / apache / cassandra / tools / NodeTool . java 
 index d24e013 . . 5120739 100644 
 - - - a / src / java / org / apache / cassandra / tools / NodeTool . java 
 + + + b / src / java / org / apache / cassandra / tools / NodeTool . java 
 @ @ - 506 , 41 + 506 , 49 @ @ public class NodeTool 
 else 
 System . out . println ( ) ; 
 
 - for ( Map . Entry < InetAddress , Float > entry : filteredOwnerships . entrySet ( ) ) 
 + for ( Map . Entry < String , String > entry : endpointsToTokens . entries ( ) ) 
 { 
 - String endpoint = entry . getKey ( ) . getHostAddress ( ) ; 
 - for ( String token : endpointsToTokens . get ( endpoint ) ) 
 + String endpoint = entry . getKey ( ) ; 
 + String rack ; 
 + try 
 { 
 - String rack ; 
 - try 
 - { 
 - rack = probe . getEndpointSnitchInfoProxy ( ) . getRack ( endpoint ) ; 
 - } catch ( UnknownHostException e ) 
 - { 
 - rack = " Unknown " ; 
 - } 
 + rack = probe . getEndpointSnitchInfoProxy ( ) . getRack ( endpoint ) ; 
 + } 
 + catch ( UnknownHostException e ) 
 + { 
 + rack = " Unknown " ; 
 + } 
 
 - String status = liveNodes . contains ( endpoint ) 
 - ? " Up " 
 - : deadNodes . contains ( endpoint ) 
 - ? " Down " 
 - : " ? " ; 
 - 
 - String state = " Normal " ; 
 - 
 - if ( joiningNodes . contains ( endpoint ) ) 
 - state = " Joining " ; 
 - else if ( leavingNodes . contains ( endpoint ) ) 
 - state = " Leaving " ; 
 - else if ( movingNodes . contains ( endpoint ) ) 
 - state = " Moving " ; 
 - 
 - String load = loadMap . containsKey ( endpoint ) 
 - ? loadMap . get ( endpoint ) 
 - : " ? " ; 
 - String owns = new DecimalFormat ( " # # 0 . 00 % " ) . format ( entry . getValue ( ) ) ; 
 - System . out . printf ( format , endpoint , rack , status , state , load , owns , token ) ; 
 + String status = liveNodes . contains ( endpoint ) 
 + ? " Up " 
 + : deadNodes . contains ( endpoint ) 
 + ? " Down " 
 + : " ? " ; 
 + 
 + String state = " Normal " ; 
 + 
 + if ( joiningNodes . contains ( endpoint ) ) 
 + state = " Joining " ; 
 + else if ( leavingNodes . contains ( endpoint ) ) 
 + state = " Leaving " ; 
 + else if ( movingNodes . contains ( endpoint ) ) 
 + state = " Moving " ; 
 + 
 + String load = loadMap . containsKey ( endpoint ) 
 + ? loadMap . get ( endpoint ) 
 + : " ? " ; 
 + String owns ; 
 + try 
 + { 
 + InetAddress ep = InetAddress . getByName ( endpoint ) ; 
 + Float percent = filteredOwnerships . get ( ep ) ; 
 + owns = ( percent ! = null ) ? new DecimalFormat ( " # # 0 . 00 % " ) . format ( percent ) : " ? " ; 
 + } 
 + catch ( UnknownHostException e ) 
 + { 
 + throw new RuntimeException ( e ) ; 
 } 
 + System . out . printf ( format , endpoint , rack , status , state , load , owns , entry . getValue ( ) ) ; 
 } 
 System . out . println ( ) ; 
 }

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 47ff752 . . fb9915e 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 1 . 2 . 10 
 + * Avoid second - guessing out - of - space state ( CASSANDRA - 5605 ) 
 * Tuning knobs for dealing with large blobs and many CFs ( CASSANDRA - 5982 ) 
 * ( Hadoop ) Fix CQLRW for thrift tables ( CASSANDRA - 6002 ) 
 * Fix possible divide - by - zero in HHOM ( CASSANDRA - 5990 ) 
 diff - - git a / src / java / org / apache / cassandra / db / Directories . java b / src / java / org / apache / cassandra / db / Directories . java 
 index 0890d29 . . 351c0c0 100644 
 - - - a / src / java / org / apache / cassandra / db / Directories . java 
 + + + b / src / java / org / apache / cassandra / db / Directories . java 
 @ @ - 19 , 6 + 19 , 7 @ @ package org . apache . cassandra . db ; 
 
 import java . io . File ; 
 import java . io . FileFilter ; 
 + import java . io . IOError ; 
 import java . io . IOException ; 
 import java . util . * ; 
 import java . util . concurrent . atomic . AtomicInteger ; 
 @ @ - 132 , 9 + 133 , 9 @ @ public class Directories 
 return null ; 
 } 
 
 - public File getDirectoryForNewSSTables ( long estimatedSize ) 
 + public File getDirectoryForNewSSTables ( ) 
 { 
 - File path = getLocationWithMaximumAvailableSpace ( estimatedSize ) ; 
 + File path = getWriteableLocationAsFile ( ) ; 
 
 / / Requesting GC has a chance to free space only if we ' re using mmap and a non SUN jvm 
 if ( path = = null 
 @ @ - 154 , 68 + 155 , 37 @ @ public class Directories 
 { 
 throw new AssertionError ( e ) ; 
 } 
 - path = getLocationWithMaximumAvailableSpace ( estimatedSize ) ; 
 + path = getWriteableLocationAsFile ( ) ; 
 } 
 
 return path ; 
 } 
 
 - / * 
 - * Loop through all the disks to see which disk has the max free space 
 - * return the disk with max free space for compactions . If the size of the expected 
 - * compacted file is greater than the max disk space available return null , we cannot 
 - * do compaction in this case . 
 - * / 
 - public File getLocationWithMaximumAvailableSpace ( long estimatedSize ) 
 + public File getWriteableLocationAsFile ( ) 
 { 
 - long maxFreeDisk = 0 ; 
 - File maxLocation = null ; 
 - 
 - for ( File dir : sstableDirectories ) 
 - { 
 - if ( BlacklistedDirectories . isUnwritable ( dir ) ) 
 - continue ; 
 - 
 - long usableSpace = dir . getUsableSpace ( ) ; 
 - if ( maxFreeDisk < usableSpace ) 
 - { 
 - maxFreeDisk = usableSpace ; 
 - maxLocation = dir ; 
 - } 
 - } 
 - / / Load factor of 0 . 9 we do not want to use the entire disk that is too risky . 
 - maxFreeDisk = ( long ) ( 0 . 9 * maxFreeDisk ) ; 
 - logger . debug ( String . format ( " expected data files size is % d ; largest free partition ( % s ) has % d bytes free " , 
 - estimatedSize , maxLocation , maxFreeDisk ) ) ; 
 - 
 - return estimatedSize < maxFreeDisk ? maxLocation : null ; 
 + return getLocationForDisk ( getWriteableLocation ( ) ) ; 
 } 
 
 / * * 
 - * Finds location which is capable of holding given { @ code estimatedSize } . 
 - * Picks a non - blacklisted directory with most free space and least current tasks . 
 - * If no directory can hold given { @ code estimatedSize } , then returns null . 
 + * @ return a non - blacklisted directory with the most free space and least current tasks . 
 * 
 - * @ param estimatedSize estimated size you need to find location to fit 
 - * @ return directory capable of given estimated size , or null if none found 
 + * @ throws IOError if all directories are blacklisted . 
 * / 
 - public DataDirectory getLocationCapableOfSize ( long estimatedSize ) 
 + public DataDirectory getWriteableLocation ( ) 
 { 
 List < DataDirectory > candidates = new ArrayList < DataDirectory > ( ) ; 
 
 / / pick directories with enough space and so that resulting sstable dirs aren ' t blacklisted for writes . 
 for ( DataDirectory dataDir : dataFileLocations ) 
 { 
 - File sstableDir = getLocationForDisk ( dataDir ) ; 
 - 
 - if ( BlacklistedDirectories . isUnwritable ( sstableDir ) ) 
 + if ( BlacklistedDirectories . isUnwritable ( getLocationForDisk ( dataDir ) ) ) 
 continue ; 
 - 
 - / / need a separate check for sstableDir itself - could be a mounted separate disk or SSD just for this CF . 
 - if ( dataDir . getEstimatedAvailableSpace ( ) > estimatedSize & & sstableDir . getUsableSpace ( ) * 0 . 9 > estimatedSize ) 
 - candidates . add ( dataDir ) ; 
 + candidates . add ( dataDir ) ; 
 } 
 
 + if ( candidates . isEmpty ( ) ) 
 + throw new IOError ( new IOException ( " All configured data directories have been blacklisted as unwritable for erroring out " ) ) ; 
 + 
 / / sort directories by free space , in _ descending _ order . 
 Collections . sort ( candidates ) ; 
 
 @ @ - 228 , 7 + 198 , 7 @ @ public class Directories 
 } 
 } ) ; 
 
 - return candidates . isEmpty ( ) ? null : candidates . get ( 0 ) ; 
 + return candidates . get ( 0 ) ; 
 } 
 
 
 @ @ - 265 , 7 + 235 , 7 @ @ public class Directories 
 public long getEstimatedAvailableSpace ( ) 
 { 
 / / Load factor of 0 . 9 we do not want to use the entire disk that is too risky . 
 - return ( long ) ( 0 . 9 * location . getUsableSpace ( ) ) - estimatedWorkingSize . get ( ) ; 
 + return location . getUsableSpace ( ) - estimatedWorkingSize . get ( ) ; 
 } 
 
 public int compareTo ( DataDirectory o ) 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 index 4c9c707 . . 93f3108 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 @ @ - 584 , 7 + 584 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 logger . info ( " Cleaning up " + sstable ) ; 
 / / Calculate the expected compacted filesize 
 long expectedRangeFileSize = cfs . getExpectedCompactedFileSize ( Arrays . asList ( sstable ) , OperationType . CLEANUP ) ; 
 - File compactionFileLocation = cfs . directories . getDirectoryForNewSSTables ( expectedRangeFileSize ) ; 
 + File compactionFileLocation = cfs . directories . getDirectoryForNewSSTables ( ) ; 
 if ( compactionFileLocation = = null ) 
 throw new IOException ( " disk full " ) ; 
 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / Scrubber . java b / src / java / org / apache / cassandra / db / compaction / Scrubber . java 
 index cb529cb . . 7b2178b 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / Scrubber . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / Scrubber . java 
 @ @ - 76 , 7 + 76 , 7 @ @ public class Scrubber implements Closeable 
 this . outputHandler = outputHandler ; 
 
 / / Calculate the expected compacted filesize 
 - this . destination = cfs . directories . getDirectoryForNewSSTables ( sstable . onDiskLength ( ) ) ; 
 + this . destination = cfs . directories . getDirectoryForNewSSTables ( ) ; 
 if ( destination = = null ) 
 throw new IOException ( " disk full " ) ; 
 
 diff - - git a / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java b / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java 
 index 1be4803 . . 198a88d 100644 
 - - - a / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java 
 + + + b / src / java / org / apache / cassandra / io / util / DiskAwareRunnable . java 
 @ @ - 34 , 7 + 34 , 7 @ @ public abstract class DiskAwareRunnable extends WrappedRunnable 
 while ( true ) 
 { 
 writeSize = getExpectedWriteSize ( ) ; 
 - directory = getDirectories ( ) . getLocationCapableOfSize ( writeSize ) ; 
 + directory = getDirectories ( ) . getWriteableLocation ( ) ; 
 if ( directory ! = null | | ! reduceScopeForLimitedSpace ( ) ) 
 break ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamIn . java b / src / java / org / apache / cassandra / streaming / StreamIn . java 
 index 740b430 . . 85ea7fa 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamIn . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamIn . java 
 @ @ - 80 , 7 + 80 , 7 @ @ public class StreamIn 
 / / new local sstable 
 Table table = Table . open ( remotedesc . ksname ) ; 
 ColumnFamilyStore cfStore = table . getColumnFamilyStore ( remotedesc . cfname ) ; 
 - Directories . DataDirectory localDir = cfStore . directories . getLocationCapableOfSize ( remote . size ) ; 
 + Directories . DataDirectory localDir = cfStore . directories . getWriteableLocation ( ) ; 
 if ( localDir = = null ) 
 throw new RuntimeException ( " Insufficient disk space to store " + remote . size + " bytes " ) ; 
 Descriptor localdesc = Descriptor . fromFilename ( cfStore . getTempSSTablePath ( cfStore . directories . getLocationForDisk ( localDir ) ) ) ; 
 diff - - git a / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java b / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java 
 index a394644 . . abe3f05 100644 
 - - - a / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java 
 + + + b / test / unit / org / apache / cassandra / db / ColumnFamilyStoreTest . java 
 @ @ - 837 , 7 + 837 , 7 @ @ public class ColumnFamilyStoreTest extends SchemaLoader 
 
 for ( int version = 1 ; version < = 2 ; + + version ) 
 { 
 - Descriptor existing = new Descriptor ( cfs . directories . getDirectoryForNewSSTables ( 1 ) , " Keyspace2 " , " Standard1 " , version , false ) ; 
 + Descriptor existing = new Descriptor ( cfs . directories . getDirectoryForNewSSTables ( ) , " Keyspace2 " , " Standard1 " , version , false ) ; 
 Descriptor desc = new Descriptor ( Directories . getBackupsDirectory ( existing ) , " Keyspace2 " , " Standard1 " , version , false ) ; 
 for ( Component c : new Component [ ] { Component . DATA , Component . PRIMARY _ INDEX , Component . FILTER , Component . STATS } ) 
 assertTrue ( " can not find backedup file : " + desc . filenameFor ( c ) , new File ( desc . filenameFor ( c ) ) . exists ( ) ) ; 
 diff - - git a / test / unit / org / apache / cassandra / db / DirectoriesTest . java b / test / unit / org / apache / cassandra / db / DirectoriesTest . java 
 index 21e183c . . dce6f87 100644 
 - - - a / test / unit / org / apache / cassandra / db / DirectoriesTest . java 
 + + + b / test / unit / org / apache / cassandra / db / DirectoriesTest . java 
 @ @ - 107 , 7 + 107 , 7 @ @ public class DirectoriesTest 
 for ( String cf : CFS ) 
 { 
 Directories directories = Directories . create ( KS , cf ) ; 
 - Assert . assertEquals ( cfDir ( cf ) , directories . getDirectoryForNewSSTables ( 0 ) ) ; 
 + Assert . assertEquals ( cfDir ( cf ) , directories . getDirectoryForNewSSTables ( ) ) ; 
 
 Descriptor desc = new Descriptor ( cfDir ( cf ) , KS , cf , 1 , false ) ; 
 File snapshotDir = new File ( cfDir ( cf ) , File . separator + Directories . SNAPSHOT _ SUBDIR + File . separator + " 42 " ) ; 
 @ @ - 180 , 7 + 180 , 7 @ @ public class DirectoriesTest 
 { 
 / * files not matching the pattern should just be ignored , with a log warning * / 
 Directories directories = Directories . create ( KS , " bad " ) ; 
 - File dir = directories . getDirectoryForNewSSTables ( 1 ) ; 
 + File dir = directories . getDirectoryForNewSSTables ( ) ; 
 File f = File . createTempFile ( " bad " , " file " , dir . getParentFile ( ) ) ; 
 Directories . migrateSSTables ( ) ; 
 Assert . assertTrue ( f . isFile ( ) ) ; 
 diff - - git a / test / unit / org / apache / cassandra / db / ScrubTest . java b / test / unit / org / apache / cassandra / db / ScrubTest . java 
 index 26f0e78 . . c26939a 100644 
 - - - a / test / unit / org / apache / cassandra / db / ScrubTest . java 
 + + + b / test / unit / org / apache / cassandra / db / ScrubTest . java 
 @ @ - 55 , 7 + 55 , 7 @ @ public class ScrubTest extends SchemaLoader 
 File rootDir = new File ( root ) ; 
 assert rootDir . isDirectory ( ) ; 
 
 - File destDir = Directories . create ( TABLE , cf ) . getDirectoryForNewSSTables ( 1 ) ; 
 + File destDir = Directories . create ( TABLE , cf ) . getDirectoryForNewSSTables ( ) ; 
 
 String corruptSSTableName = null ; 
 
 diff - - git a / test / unit / org / apache / cassandra / io / sstable / SSTableReaderTest . java b / test / unit / org / apache / cassandra / io / sstable / SSTableReaderTest . java 
 index d0670a0 . . 02b6855 100644 
 - - - a / test / unit / org / apache / cassandra / io / sstable / SSTableReaderTest . java 
 + + + b / test / unit / org / apache / cassandra / io / sstable / SSTableReaderTest . java 
 @ @ - 28 , 7 + 28 , 6 @ @ import java . util . ArrayList ; 
 import java . util . Arrays ; 
 import java . util . List ; 
 import java . util . concurrent . ExecutionException ; 
 - import java . util . * ; 
 
 import org . junit . Test ; 
 import org . junit . runner . RunWith ; 
 @ @ - 230 , 7 + 229 , 7 @ @ public class SSTableReaderTest extends SchemaLoader 
 File rootDir = new File ( root + File . separator + " hb " + File . separator + " Keyspace1 " ) ; 
 assert rootDir . isDirectory ( ) ; 
 
 - File destDir = Directories . create ( " Keyspace1 " , " Indexed1 " ) . getDirectoryForNewSSTables ( 0 ) ; 
 + File destDir = Directories . create ( " Keyspace1 " , " Indexed1 " ) . getDirectoryForNewSSTables ( ) ; 
 assert destDir ! = null ; 
 
 FileUtils . createDirectory ( destDir ) ; 
 diff - - git a / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java b / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java 
 index 6efdc9b . . ce569b9 100644 
 - - - a / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java 
 + + + b / test / unit / org / apache / cassandra / io / sstable / SSTableSimpleWriterTest . java 
 @ @ - 43 , 7 + 43 , 7 @ @ public class SSTableSimpleWriterTest extends SchemaLoader 
 String cfname = " StandardInteger1 " ; 
 
 Table t = Table . open ( tablename ) ; / / make sure we create the directory 
 - File dir = Directories . create ( tablename , cfname ) . getDirectoryForNewSSTables ( 0 ) ; 
 + File dir = Directories . create ( tablename , cfname ) . getDirectoryForNewSSTables ( ) ; 
 assert dir . exists ( ) ; 
 
 IPartitioner partitioner = StorageService . getPartitioner ( ) ;
