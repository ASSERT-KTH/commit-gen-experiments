BLEU SCORE: 0.06220117374063391

TEST MSG: Optimize pending ranges computation
GENERATED MSG: synchronize BiMap of bootstrapping tokens

TEST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / locator / TokenMetadata . java b / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> index db0b609 . . 00d8ee9 100644 <nl> - - - a / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> + + + b / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> @ @ - 82 , 7 + 82 , 7 @ @ public class TokenMetadata <nl> / / ( don ' t need to record Token here since it ' s still part of tokenToEndpointMap until it ' s done leaving ) <nl> private final Set < InetAddress > leavingEndpoints = new HashSet < > ( ) ; <nl> / / this is a cache of the calculation from { tokenToEndpointMap , bootstrapTokens , leavingEndpoints } <nl> - private final ConcurrentMap < String , Multimap < Range < Token > , InetAddress > > pendingRanges = new ConcurrentHashMap < > ( ) ; <nl> + private final ConcurrentMap < String , PendingRangeMaps > pendingRanges = new ConcurrentHashMap < String , PendingRangeMaps > ( ) ; <nl> <nl> / / nodes which are migrating to the new tokens in the ring <nl> private final Set < Pair < Token , InetAddress > > movingEndpoints = new HashSet < > ( ) ; <nl> @ @ - 673 , 23 + 673 , 30 @ @ public class TokenMetadata <nl> return sortedTokens ; <nl> } <nl> <nl> - private Multimap < Range < Token > , InetAddress > getPendingRangesMM ( String keyspaceName ) <nl> + public Multimap < Range < Token > , InetAddress > getPendingRangesMM ( String keyspaceName ) <nl> { <nl> - Multimap < Range < Token > , InetAddress > map = pendingRanges . get ( keyspaceName ) ; <nl> - if ( map = = null ) <nl> + Multimap < Range < Token > , InetAddress > map = HashMultimap . create ( ) ; <nl> + PendingRangeMaps pendingRangeMaps = this . pendingRanges . get ( keyspaceName ) ; <nl> + <nl> + if ( pendingRangeMaps ! = null ) <nl> { <nl> - map = HashMultimap . create ( ) ; <nl> - Multimap < Range < Token > , InetAddress > priorMap = pendingRanges . putIfAbsent ( keyspaceName , map ) ; <nl> - if ( priorMap ! = null ) <nl> - map = priorMap ; <nl> + for ( Map . Entry < Range < Token > , List < InetAddress > > entry : pendingRangeMaps ) <nl> + { <nl> + Range < Token > range = entry . getKey ( ) ; <nl> + for ( InetAddress address : entry . getValue ( ) ) <nl> + { <nl> + map . put ( range , address ) ; <nl> + } <nl> + } <nl> } <nl> + <nl> return map ; <nl> } <nl> <nl> / * * a mutable map may be returned but caller should not modify it * / <nl> - public Map < Range < Token > , Collection < InetAddress > > getPendingRanges ( String keyspaceName ) <nl> + public PendingRangeMaps getPendingRanges ( String keyspaceName ) <nl> { <nl> - return getPendingRangesMM ( keyspaceName ) . asMap ( ) ; <nl> + return this . pendingRanges . get ( keyspaceName ) ; <nl> } <nl> <nl> public List < Range < Token > > getPendingRanges ( String keyspaceName , InetAddress endpoint ) <nl> @ @ - 733 , 7 + 740 , 7 @ @ public class TokenMetadata <nl> lock . readLock ( ) . lock ( ) ; <nl> try <nl> { <nl> - Multimap < Range < Token > , InetAddress > newPendingRanges = HashMultimap . create ( ) ; <nl> + PendingRangeMaps newPendingRanges = new PendingRangeMaps ( ) ; <nl> <nl> if ( bootstrapTokens . isEmpty ( ) & & leavingEndpoints . isEmpty ( ) & & movingEndpoints . isEmpty ( ) ) <nl> { <nl> @ @ - 761 , 7 + 768 , 10 @ @ public class TokenMetadata <nl> { <nl> Set < InetAddress > currentEndpoints = ImmutableSet . copyOf ( strategy . calculateNaturalEndpoints ( range . right , metadata ) ) ; <nl> Set < InetAddress > newEndpoints = ImmutableSet . copyOf ( strategy . calculateNaturalEndpoints ( range . right , allLeftMetadata ) ) ; <nl> - newPendingRanges . putAll ( range , Sets . difference ( newEndpoints , currentEndpoints ) ) ; <nl> + for ( InetAddress address : Sets . difference ( newEndpoints , currentEndpoints ) ) <nl> + { <nl> + newPendingRanges . addPendingRange ( range , address ) ; <nl> + } <nl> } <nl> <nl> / / At this stage newPendingRanges has been updated according to leave operations . We can <nl> @ @ - 776 , 7 + 786 , 9 @ @ public class TokenMetadata <nl> <nl> allLeftMetadata . updateNormalTokens ( tokens , endpoint ) ; <nl> for ( Range < Token > range : strategy . getAddressRanges ( allLeftMetadata ) . get ( endpoint ) ) <nl> - newPendingRanges . put ( range , endpoint ) ; <nl> + { <nl> + newPendingRanges . addPendingRange ( range , endpoint ) ; <nl> + } <nl> allLeftMetadata . removeEndpoint ( endpoint ) ; <nl> } <nl> <nl> @ @ - 794 , 7 + 806 , 7 @ @ public class TokenMetadata <nl> <nl> for ( Range < Token > range : strategy . getAddressRanges ( allLeftMetadata ) . get ( endpoint ) ) <nl> { <nl> - newPendingRanges . put ( range , endpoint ) ; <nl> + newPendingRanges . addPendingRange ( range , endpoint ) ; <nl> } <nl> <nl> allLeftMetadata . removeEndpoint ( endpoint ) ; <nl> @ @ - 1029 , 13 + 1041 , 9 @ @ public class TokenMetadata <nl> { <nl> StringBuilder sb = new StringBuilder ( ) ; <nl> <nl> - for ( Map . Entry < String , Multimap < Range < Token > , InetAddress > > entry : pendingRanges . entrySet ( ) ) <nl> + for ( PendingRangeMaps pendingRangeMaps : pendingRanges . values ( ) ) <nl> { <nl> - for ( Map . Entry < Range < Token > , InetAddress > rmap : entry . getValue ( ) . entries ( ) ) <nl> - { <nl> - sb . append ( rmap . getValue ( ) ) . append ( ' : ' ) . append ( rmap . getKey ( ) ) ; <nl> - sb . append ( System . getProperty ( " line . separator " ) ) ; <nl> - } <nl> + sb . append ( pendingRangeMaps . printPendingRanges ( ) ) ; <nl> } <nl> <nl> return sb . toString ( ) ; <nl> @ @ - 1043 , 18 + 1051 , 11 @ @ public class TokenMetadata <nl> <nl> public Collection < InetAddress > pendingEndpointsFor ( Token token , String keyspaceName ) <nl> { <nl> - Map < Range < Token > , Collection < InetAddress > > ranges = getPendingRanges ( keyspaceName ) ; <nl> - if ( ranges . isEmpty ( ) ) <nl> + PendingRangeMaps pendingRangeMaps = this . pendingRanges . get ( keyspaceName ) ; <nl> + if ( pendingRangeMaps = = null ) <nl> return Collections . emptyList ( ) ; <nl> <nl> - Set < InetAddress > endpoints = new HashSet < > ( ) ; <nl> - for ( Map . Entry < Range < Token > , Collection < InetAddress > > entry : ranges . entrySet ( ) ) <nl> - { <nl> - if ( entry . getKey ( ) . contains ( token ) ) <nl> - endpoints . addAll ( entry . getValue ( ) ) ; <nl> - } <nl> - <nl> - return endpoints ; <nl> + return pendingRangeMaps . pendingEndpointsFor ( token ) ; <nl> } <nl> <nl> / * * <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index e8e7daf . . 84ebd9a 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 1378 , 7 + 1378 , 7 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> keyspace = Schema . instance . getNonSystemKeyspaces ( ) . get ( 0 ) ; <nl> <nl> Map < List < String > , List < String > > map = new HashMap < > ( ) ; <nl> - for ( Map . Entry < Range < Token > , Collection < InetAddress > > entry : tokenMetadata . getPendingRanges ( keyspace ) . entrySet ( ) ) <nl> + for ( Map . Entry < Range < Token > , Collection < InetAddress > > entry : tokenMetadata . getPendingRangesMM ( keyspace ) . asMap ( ) . entrySet ( ) ) <nl> { <nl> List < InetAddress > l = new ArrayList < > ( entry . getValue ( ) ) ; <nl> map . put ( entry . getKey ( ) . asList ( ) , stringify ( l ) ) ;
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 98590fc . . f59e111 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 4 , 6 + 4 , 8 @ @ <nl> * cleanup usage of StorageService . setMode ( ) ( CASANDRA - 3388 ) <nl> * replace compactionlock use in schema migration by checking CFS . isInvalidD <nl> <nl> + 1 . 0 . 2 <nl> + * " defragment " rows for name - based queries under STCS ( CASSANDRA - 2503 ) <nl> <nl> 1 . 0 . 1 <nl> * acquire references during index build to prevent delete problems <nl> @ @ - 39 , 6 + 41 , 15 @ @ <nl> them ( CASSANDRA - 3385 ) <nl> * remove procrun ( bin \ daemon ) from Cassandra source tree and <nl> artifacts ( CASSANDRA - 3331 ) <nl> + * make cassandra compile under JDK7 ( CASSANDRA - 3275 ) <nl> + * remove dependency of clientutil . jar to FBUtilities ( CASSANDRA - 3299 ) <nl> + * avoid truncation errors by using long math on long values ( CASSANDRA - 3364 ) <nl> + * avoid clock drift on some Windows machine ( CASSANDRA - 3375 ) <nl> + * display cache provider in cli ' describe keyspace ' command ( CASSANDRA - 3384 ) <nl> + * fix incomplete topology information in describe _ ring ( CASSANDRA - 3403 ) <nl> + * expire dead gossip states based on time ( CASSANDRA - 2961 ) <nl> + * improve CompactionTask extensibility ( CASSANDRA - 3330 ) <nl> + * Allow one leveled compaction task to kick off another ( CASSANDRA - 3363 ) <nl> Merged from 0 . 8 : <nl> * ( CQL ) update grammar to require key clause in DELETE statement <nl> ( CASSANDRA - 3349 ) <nl> diff - - git a / NEWS . txt b / NEWS . txt <nl> index dd83719 . . 5185ae1 100644 <nl> - - - a / NEWS . txt <nl> + + + b / NEWS . txt <nl> @ @ - 8 , 6 + 8 , 21 @ @ Upgrading <nl> versions would silently perform a LOCAL _ QUORUM read instead . ) <nl> <nl> <nl> + 1 . 0 . 1 <nl> + = = = = = <nl> + <nl> + Upgrading <nl> + - - - - - - - - - <nl> + - If upgrading from a version prior to 1 . 0 . 0 , please see the 1 . 0 Upgrading <nl> + section <nl> + - For running on Windows as a Service , procrun is no longer discributed <nl> + with Cassandra , see README . txt for more information on how to download <nl> + it if necessary . <nl> + - The name given to snapshots directories have been improved for human <nl> + readability . If you had scripts relying on it , you may need to update <nl> + them . <nl> + <nl> + <nl> 1 . 0 <nl> = = = <nl> <nl> diff - - git a / build . xml b / build . xml <nl> index 186e827 . . 5927da0 100644 <nl> - - - a / build . xml <nl> + + + b / build . xml <nl> @ @ - 25 , 7 + 25 , 7 @ @ <nl> < property name = " debuglevel " value = " source , lines , vars " / > <nl> <nl> < ! - - default version and SCM information ( we need the default SCM info as people may checkout with git - svn ) - - > <nl> - < property name = " base . version " value = " 1 . 0 . 0 " / > <nl> + < property name = " base . version " value = " 1 . 0 . 1 " / > <nl> < property name = " scm . default . path " value = " cassandra / branches / cassandra - 1 . 0 . 0 " / > <nl> < property name = " scm . default . connection " value = " scm : svn : http : / / svn . apache . org / repos / asf / $ { scm . default . path } " / > <nl> < property name = " scm . default . developerConnection " value = " scm : svn : https : / / svn . apache . org / repos / asf / $ { scm . default . path } " / > <nl> diff - - git a / debian / changelog b / debian / changelog <nl> index 67eb646 . . 640ae9e 100644 <nl> - - - a / debian / changelog <nl> + + + b / debian / changelog <nl> @ @ - 1 , 3 + 1 , 9 @ @ <nl> + cassandra ( 1 . 0 . 1 ) unstable ; urgency = low <nl> + <nl> + * New release <nl> + <nl> + - - Sylvain Lebresne < slebresne @ apache . org > Fri , 28 Oct 2011 10 : 09 : 34 + 0200 <nl> + <nl> cassandra ( 1 . 0 . 0 ) unstable ; urgency = low <nl> <nl> * New release <nl> diff - - git a / src / java / org / apache / cassandra / db / CollationController . java b / src / java / org / apache / cassandra / db / CollationController . java <nl> index 3451ed1 . . 38d6bd1 100644 <nl> - - - a / src / java / org / apache / cassandra / db / CollationController . java <nl> + + + b / src / java / org / apache / cassandra / db / CollationController . java <nl> @ @ - 19 , 6 + 19 , 7 @ @ <nl> * / <nl> package org . apache . cassandra . db ; <nl> <nl> + import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> <nl> @ @ - 28 , 6 + 29 , 7 @ @ import org . slf4j . LoggerFactory ; <nl> <nl> import org . apache . cassandra . db . columniterator . IColumnIterator ; <nl> import org . apache . cassandra . db . columniterator . SimpleAbstractColumnIterator ; <nl> + import org . apache . cassandra . db . compaction . SizeTieredCompactionStrategy ; <nl> import org . apache . cassandra . db . filter . NamesQueryFilter ; <nl> import org . apache . cassandra . db . filter . QueryFilter ; <nl> import org . apache . cassandra . db . marshal . CounterColumnType ; <nl> @ @ - 35 , 7 + 37 , 6 @ @ import org . apache . cassandra . io . sstable . SSTable ; <nl> import org . apache . cassandra . io . sstable . SSTableReader ; <nl> import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . utils . CloseableIterator ; <nl> - import org . apache . cassandra . utils . IntervalTree . Interval ; <nl> <nl> public class CollationController <nl> { <nl> @ @ - 149 , 6 + 150 , 21 @ @ public class CollationController <nl> ColumnFamily returnCF = container . cloneMeShallow ( ) ; <nl> filter . collateColumns ( returnCF , Collections . singletonList ( toCollate ) , cfs . metadata . comparator , gcBefore ) ; <nl> <nl> + / / " hoist up " the requested data into a more recent sstable <nl> + if ( sstablesIterated > = cfs . getMinimumCompactionThreshold ( ) & & cfs . getCompactionStrategy ( ) instanceof SizeTieredCompactionStrategy ) <nl> + { <nl> + RowMutation rm = new RowMutation ( cfs . table . name , new Row ( filter . key , returnCF ) ) ; <nl> + try <nl> + { <nl> + rm . applyUnsafe ( ) ; / / skipping commitlog is fine since we ' re just de - fragmenting existing data <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + / / log and allow the result to be returned <nl> + logger . error ( " Error re - writing read results " , e ) ; <nl> + } <nl> + } <nl> + <nl> / / Caller is responsible for final removeDeletedCF . This is important for cacheRow to work correctly : <nl> return returnCF ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilySerializer . java b / src / java / org / apache / cassandra / db / ColumnFamilySerializer . java <nl> index 5b3b5ae . . 8c3f7c2 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilySerializer . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilySerializer . java <nl> @ @ - 85 , 10 + 85 , 13 @ @ public class ColumnFamilySerializer implements ISerializer < ColumnFamily > <nl> Collection < IColumn > columns = columnFamily . getSortedColumns ( ) ; <nl> int count = columns . size ( ) ; <nl> dos . writeInt ( count ) ; <nl> + int i = 0 ; <nl> for ( IColumn column : columns ) <nl> { <nl> columnFamily . getColumnSerializer ( ) . serialize ( column , dos ) ; <nl> + i + + ; <nl> } <nl> + assert count = = i : " CF size changed during serialization : was " + count + " initially but " + i + " written " ; <nl> return count ; <nl> } <nl> catch ( IOException e ) <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnSerializer . java b / src / java / org / apache / cassandra / db / ColumnSerializer . java <nl> index 0a2c6df . . b0eb47a 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnSerializer . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnSerializer . java <nl> @ @ - 31 , 6 + 31 , 7 @ @ import org . slf4j . LoggerFactory ; <nl> <nl> import org . apache . cassandra . db . context . CounterContext ; <nl> import org . apache . cassandra . io . IColumnSerializer ; <nl> + import org . apache . cassandra . io . util . FileDataInput ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> <nl> public class ColumnSerializer implements IColumnSerializer <nl> @ @ - 86 , 7 + 87 , 16 @ @ public class ColumnSerializer implements IColumnSerializer <nl> { <nl> ByteBuffer name = ByteBufferUtil . readWithShortLength ( dis ) ; <nl> if ( name . remaining ( ) < = 0 ) <nl> - throw new CorruptColumnException ( " invalid column name length " + name . remaining ( ) ) ; <nl> + { <nl> + String format = " invalid column name length % d % s " ; <nl> + String details = " " ; <nl> + if ( dis instanceof FileDataInput ) <nl> + { <nl> + FileDataInput fdis = ( FileDataInput ) dis ; <nl> + details = String . format ( " ( % s , % d bytes remaining ) " , fdis . getPath ( ) , fdis . bytesRemaining ( ) ) ; <nl> + } <nl> + throw new CorruptColumnException ( String . format ( format , name . remaining ( ) , details ) ) ; <nl> + } <nl> <nl> int b = dis . readUnsignedByte ( ) ; <nl> if ( ( b & COUNTER _ MASK ) ! = 0 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / DataTracker . java b / src / java / org / apache / cassandra / db / DataTracker . java <nl> index 1c4bdca . . db82725 100644 <nl> - - - a / src / java / org / apache / cassandra / db / DataTracker . java <nl> + + + b / src / java / org / apache / cassandra / db / DataTracker . java <nl> @ @ - 623 , 6 + 623 , 7 @ @ public class DataTracker <nl> { <nl> ImmutableSet < SSTableReader > oldSet = ImmutableSet . copyOf ( oldSSTables ) ; <nl> int newSSTablesSize = sstables . size ( ) - oldSSTables . size ( ) + Iterables . size ( replacements ) ; <nl> + assert newSSTablesSize > = Iterables . size ( replacements ) : String . format ( " Incoherent new size % d replacing % s by % s in % s " , newSSTablesSize , oldSSTables , replacements , this ) ; <nl> List < SSTableReader > newSSTables = new ArrayList < SSTableReader > ( newSSTablesSize ) ; <nl> for ( SSTableReader sstable : sstables ) <nl> { <nl> @ @ - 630 , 8 + 631 , 14 @ @ public class DataTracker <nl> newSSTables . add ( sstable ) ; <nl> } <nl> Iterables . addAll ( newSSTables , replacements ) ; <nl> - assert newSSTables . size ( ) = = newSSTablesSize ; <nl> + assert newSSTables . size ( ) = = newSSTablesSize : String . format ( " Expecting new size of % d , got % d while replacing % s by % s in % s " , newSSTablesSize , newSSTables . size ( ) , oldSSTables , replacements , this ) ; <nl> return newSSTables ; <nl> } <nl> + <nl> + @ Override <nl> + public String toString ( ) <nl> + { <nl> + return String . format ( " View ( pending _ count = % d , sstables = % s , compacting = % s ) " , memtablesPendingFlush . size ( ) , sstables , compacting ) ; <nl> + } <nl> } <nl> }

TEST DIFF:
diff - - git a / src / java / org / apache / cassandra / locator / TokenMetadata . java b / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 index db0b609 . . 00d8ee9 100644 
 - - - a / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 + + + b / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 @ @ - 82 , 7 + 82 , 7 @ @ public class TokenMetadata 
 / / ( don ' t need to record Token here since it ' s still part of tokenToEndpointMap until it ' s done leaving ) 
 private final Set < InetAddress > leavingEndpoints = new HashSet < > ( ) ; 
 / / this is a cache of the calculation from { tokenToEndpointMap , bootstrapTokens , leavingEndpoints } 
 - private final ConcurrentMap < String , Multimap < Range < Token > , InetAddress > > pendingRanges = new ConcurrentHashMap < > ( ) ; 
 + private final ConcurrentMap < String , PendingRangeMaps > pendingRanges = new ConcurrentHashMap < String , PendingRangeMaps > ( ) ; 
 
 / / nodes which are migrating to the new tokens in the ring 
 private final Set < Pair < Token , InetAddress > > movingEndpoints = new HashSet < > ( ) ; 
 @ @ - 673 , 23 + 673 , 30 @ @ public class TokenMetadata 
 return sortedTokens ; 
 } 
 
 - private Multimap < Range < Token > , InetAddress > getPendingRangesMM ( String keyspaceName ) 
 + public Multimap < Range < Token > , InetAddress > getPendingRangesMM ( String keyspaceName ) 
 { 
 - Multimap < Range < Token > , InetAddress > map = pendingRanges . get ( keyspaceName ) ; 
 - if ( map = = null ) 
 + Multimap < Range < Token > , InetAddress > map = HashMultimap . create ( ) ; 
 + PendingRangeMaps pendingRangeMaps = this . pendingRanges . get ( keyspaceName ) ; 
 + 
 + if ( pendingRangeMaps ! = null ) 
 { 
 - map = HashMultimap . create ( ) ; 
 - Multimap < Range < Token > , InetAddress > priorMap = pendingRanges . putIfAbsent ( keyspaceName , map ) ; 
 - if ( priorMap ! = null ) 
 - map = priorMap ; 
 + for ( Map . Entry < Range < Token > , List < InetAddress > > entry : pendingRangeMaps ) 
 + { 
 + Range < Token > range = entry . getKey ( ) ; 
 + for ( InetAddress address : entry . getValue ( ) ) 
 + { 
 + map . put ( range , address ) ; 
 + } 
 + } 
 } 
 + 
 return map ; 
 } 
 
 / * * a mutable map may be returned but caller should not modify it * / 
 - public Map < Range < Token > , Collection < InetAddress > > getPendingRanges ( String keyspaceName ) 
 + public PendingRangeMaps getPendingRanges ( String keyspaceName ) 
 { 
 - return getPendingRangesMM ( keyspaceName ) . asMap ( ) ; 
 + return this . pendingRanges . get ( keyspaceName ) ; 
 } 
 
 public List < Range < Token > > getPendingRanges ( String keyspaceName , InetAddress endpoint ) 
 @ @ - 733 , 7 + 740 , 7 @ @ public class TokenMetadata 
 lock . readLock ( ) . lock ( ) ; 
 try 
 { 
 - Multimap < Range < Token > , InetAddress > newPendingRanges = HashMultimap . create ( ) ; 
 + PendingRangeMaps newPendingRanges = new PendingRangeMaps ( ) ; 
 
 if ( bootstrapTokens . isEmpty ( ) & & leavingEndpoints . isEmpty ( ) & & movingEndpoints . isEmpty ( ) ) 
 { 
 @ @ - 761 , 7 + 768 , 10 @ @ public class TokenMetadata 
 { 
 Set < InetAddress > currentEndpoints = ImmutableSet . copyOf ( strategy . calculateNaturalEndpoints ( range . right , metadata ) ) ; 
 Set < InetAddress > newEndpoints = ImmutableSet . copyOf ( strategy . calculateNaturalEndpoints ( range . right , allLeftMetadata ) ) ; 
 - newPendingRanges . putAll ( range , Sets . difference ( newEndpoints , currentEndpoints ) ) ; 
 + for ( InetAddress address : Sets . difference ( newEndpoints , currentEndpoints ) ) 
 + { 
 + newPendingRanges . addPendingRange ( range , address ) ; 
 + } 
 } 
 
 / / At this stage newPendingRanges has been updated according to leave operations . We can 
 @ @ - 776 , 7 + 786 , 9 @ @ public class TokenMetadata 
 
 allLeftMetadata . updateNormalTokens ( tokens , endpoint ) ; 
 for ( Range < Token > range : strategy . getAddressRanges ( allLeftMetadata ) . get ( endpoint ) ) 
 - newPendingRanges . put ( range , endpoint ) ; 
 + { 
 + newPendingRanges . addPendingRange ( range , endpoint ) ; 
 + } 
 allLeftMetadata . removeEndpoint ( endpoint ) ; 
 } 
 
 @ @ - 794 , 7 + 806 , 7 @ @ public class TokenMetadata 
 
 for ( Range < Token > range : strategy . getAddressRanges ( allLeftMetadata ) . get ( endpoint ) ) 
 { 
 - newPendingRanges . put ( range , endpoint ) ; 
 + newPendingRanges . addPendingRange ( range , endpoint ) ; 
 } 
 
 allLeftMetadata . removeEndpoint ( endpoint ) ; 
 @ @ - 1029 , 13 + 1041 , 9 @ @ public class TokenMetadata 
 { 
 StringBuilder sb = new StringBuilder ( ) ; 
 
 - for ( Map . Entry < String , Multimap < Range < Token > , InetAddress > > entry : pendingRanges . entrySet ( ) ) 
 + for ( PendingRangeMaps pendingRangeMaps : pendingRanges . values ( ) ) 
 { 
 - for ( Map . Entry < Range < Token > , InetAddress > rmap : entry . getValue ( ) . entries ( ) ) 
 - { 
 - sb . append ( rmap . getValue ( ) ) . append ( ' : ' ) . append ( rmap . getKey ( ) ) ; 
 - sb . append ( System . getProperty ( " line . separator " ) ) ; 
 - } 
 + sb . append ( pendingRangeMaps . printPendingRanges ( ) ) ; 
 } 
 
 return sb . toString ( ) ; 
 @ @ - 1043 , 18 + 1051 , 11 @ @ public class TokenMetadata 
 
 public Collection < InetAddress > pendingEndpointsFor ( Token token , String keyspaceName ) 
 { 
 - Map < Range < Token > , Collection < InetAddress > > ranges = getPendingRanges ( keyspaceName ) ; 
 - if ( ranges . isEmpty ( ) ) 
 + PendingRangeMaps pendingRangeMaps = this . pendingRanges . get ( keyspaceName ) ; 
 + if ( pendingRangeMaps = = null ) 
 return Collections . emptyList ( ) ; 
 
 - Set < InetAddress > endpoints = new HashSet < > ( ) ; 
 - for ( Map . Entry < Range < Token > , Collection < InetAddress > > entry : ranges . entrySet ( ) ) 
 - { 
 - if ( entry . getKey ( ) . contains ( token ) ) 
 - endpoints . addAll ( entry . getValue ( ) ) ; 
 - } 
 - 
 - return endpoints ; 
 + return pendingRangeMaps . pendingEndpointsFor ( token ) ; 
 } 
 
 / * * 
 diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index e8e7daf . . 84ebd9a 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 1378 , 7 + 1378 , 7 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 keyspace = Schema . instance . getNonSystemKeyspaces ( ) . get ( 0 ) ; 
 
 Map < List < String > , List < String > > map = new HashMap < > ( ) ; 
 - for ( Map . Entry < Range < Token > , Collection < InetAddress > > entry : tokenMetadata . getPendingRanges ( keyspace ) . entrySet ( ) ) 
 + for ( Map . Entry < Range < Token > , Collection < InetAddress > > entry : tokenMetadata . getPendingRangesMM ( keyspace ) . asMap ( ) . entrySet ( ) ) 
 { 
 List < InetAddress > l = new ArrayList < > ( entry . getValue ( ) ) ; 
 map . put ( entry . getKey ( ) . asList ( ) , stringify ( l ) ) ;

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 98590fc . . f59e111 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 4 , 6 + 4 , 8 @ @ 
 * cleanup usage of StorageService . setMode ( ) ( CASANDRA - 3388 ) 
 * replace compactionlock use in schema migration by checking CFS . isInvalidD 
 
 + 1 . 0 . 2 
 + * " defragment " rows for name - based queries under STCS ( CASSANDRA - 2503 ) 
 
 1 . 0 . 1 
 * acquire references during index build to prevent delete problems 
 @ @ - 39 , 6 + 41 , 15 @ @ 
 them ( CASSANDRA - 3385 ) 
 * remove procrun ( bin \ daemon ) from Cassandra source tree and 
 artifacts ( CASSANDRA - 3331 ) 
 + * make cassandra compile under JDK7 ( CASSANDRA - 3275 ) 
 + * remove dependency of clientutil . jar to FBUtilities ( CASSANDRA - 3299 ) 
 + * avoid truncation errors by using long math on long values ( CASSANDRA - 3364 ) 
 + * avoid clock drift on some Windows machine ( CASSANDRA - 3375 ) 
 + * display cache provider in cli ' describe keyspace ' command ( CASSANDRA - 3384 ) 
 + * fix incomplete topology information in describe _ ring ( CASSANDRA - 3403 ) 
 + * expire dead gossip states based on time ( CASSANDRA - 2961 ) 
 + * improve CompactionTask extensibility ( CASSANDRA - 3330 ) 
 + * Allow one leveled compaction task to kick off another ( CASSANDRA - 3363 ) 
 Merged from 0 . 8 : 
 * ( CQL ) update grammar to require key clause in DELETE statement 
 ( CASSANDRA - 3349 ) 
 diff - - git a / NEWS . txt b / NEWS . txt 
 index dd83719 . . 5185ae1 100644 
 - - - a / NEWS . txt 
 + + + b / NEWS . txt 
 @ @ - 8 , 6 + 8 , 21 @ @ Upgrading 
 versions would silently perform a LOCAL _ QUORUM read instead . ) 
 
 
 + 1 . 0 . 1 
 + = = = = = 
 + 
 + Upgrading 
 + - - - - - - - - - 
 + - If upgrading from a version prior to 1 . 0 . 0 , please see the 1 . 0 Upgrading 
 + section 
 + - For running on Windows as a Service , procrun is no longer discributed 
 + with Cassandra , see README . txt for more information on how to download 
 + it if necessary . 
 + - The name given to snapshots directories have been improved for human 
 + readability . If you had scripts relying on it , you may need to update 
 + them . 
 + 
 + 
 1 . 0 
 = = = 
 
 diff - - git a / build . xml b / build . xml 
 index 186e827 . . 5927da0 100644 
 - - - a / build . xml 
 + + + b / build . xml 
 @ @ - 25 , 7 + 25 , 7 @ @ 
 < property name = " debuglevel " value = " source , lines , vars " / > 
 
 < ! - - default version and SCM information ( we need the default SCM info as people may checkout with git - svn ) - - > 
 - < property name = " base . version " value = " 1 . 0 . 0 " / > 
 + < property name = " base . version " value = " 1 . 0 . 1 " / > 
 < property name = " scm . default . path " value = " cassandra / branches / cassandra - 1 . 0 . 0 " / > 
 < property name = " scm . default . connection " value = " scm : svn : http : / / svn . apache . org / repos / asf / $ { scm . default . path } " / > 
 < property name = " scm . default . developerConnection " value = " scm : svn : https : / / svn . apache . org / repos / asf / $ { scm . default . path } " / > 
 diff - - git a / debian / changelog b / debian / changelog 
 index 67eb646 . . 640ae9e 100644 
 - - - a / debian / changelog 
 + + + b / debian / changelog 
 @ @ - 1 , 3 + 1 , 9 @ @ 
 + cassandra ( 1 . 0 . 1 ) unstable ; urgency = low 
 + 
 + * New release 
 + 
 + - - Sylvain Lebresne < slebresne @ apache . org > Fri , 28 Oct 2011 10 : 09 : 34 + 0200 
 + 
 cassandra ( 1 . 0 . 0 ) unstable ; urgency = low 
 
 * New release 
 diff - - git a / src / java / org / apache / cassandra / db / CollationController . java b / src / java / org / apache / cassandra / db / CollationController . java 
 index 3451ed1 . . 38d6bd1 100644 
 - - - a / src / java / org / apache / cassandra / db / CollationController . java 
 + + + b / src / java / org / apache / cassandra / db / CollationController . java 
 @ @ - 19 , 6 + 19 , 7 @ @ 
 * / 
 package org . apache . cassandra . db ; 
 
 + import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 import java . util . * ; 
 
 @ @ - 28 , 6 + 29 , 7 @ @ import org . slf4j . LoggerFactory ; 
 
 import org . apache . cassandra . db . columniterator . IColumnIterator ; 
 import org . apache . cassandra . db . columniterator . SimpleAbstractColumnIterator ; 
 + import org . apache . cassandra . db . compaction . SizeTieredCompactionStrategy ; 
 import org . apache . cassandra . db . filter . NamesQueryFilter ; 
 import org . apache . cassandra . db . filter . QueryFilter ; 
 import org . apache . cassandra . db . marshal . CounterColumnType ; 
 @ @ - 35 , 7 + 37 , 6 @ @ import org . apache . cassandra . io . sstable . SSTable ; 
 import org . apache . cassandra . io . sstable . SSTableReader ; 
 import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . utils . CloseableIterator ; 
 - import org . apache . cassandra . utils . IntervalTree . Interval ; 
 
 public class CollationController 
 { 
 @ @ - 149 , 6 + 150 , 21 @ @ public class CollationController 
 ColumnFamily returnCF = container . cloneMeShallow ( ) ; 
 filter . collateColumns ( returnCF , Collections . singletonList ( toCollate ) , cfs . metadata . comparator , gcBefore ) ; 
 
 + / / " hoist up " the requested data into a more recent sstable 
 + if ( sstablesIterated > = cfs . getMinimumCompactionThreshold ( ) & & cfs . getCompactionStrategy ( ) instanceof SizeTieredCompactionStrategy ) 
 + { 
 + RowMutation rm = new RowMutation ( cfs . table . name , new Row ( filter . key , returnCF ) ) ; 
 + try 
 + { 
 + rm . applyUnsafe ( ) ; / / skipping commitlog is fine since we ' re just de - fragmenting existing data 
 + } 
 + catch ( IOException e ) 
 + { 
 + / / log and allow the result to be returned 
 + logger . error ( " Error re - writing read results " , e ) ; 
 + } 
 + } 
 + 
 / / Caller is responsible for final removeDeletedCF . This is important for cacheRow to work correctly : 
 return returnCF ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilySerializer . java b / src / java / org / apache / cassandra / db / ColumnFamilySerializer . java 
 index 5b3b5ae . . 8c3f7c2 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilySerializer . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilySerializer . java 
 @ @ - 85 , 10 + 85 , 13 @ @ public class ColumnFamilySerializer implements ISerializer < ColumnFamily > 
 Collection < IColumn > columns = columnFamily . getSortedColumns ( ) ; 
 int count = columns . size ( ) ; 
 dos . writeInt ( count ) ; 
 + int i = 0 ; 
 for ( IColumn column : columns ) 
 { 
 columnFamily . getColumnSerializer ( ) . serialize ( column , dos ) ; 
 + i + + ; 
 } 
 + assert count = = i : " CF size changed during serialization : was " + count + " initially but " + i + " written " ; 
 return count ; 
 } 
 catch ( IOException e ) 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnSerializer . java b / src / java / org / apache / cassandra / db / ColumnSerializer . java 
 index 0a2c6df . . b0eb47a 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnSerializer . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnSerializer . java 
 @ @ - 31 , 6 + 31 , 7 @ @ import org . slf4j . LoggerFactory ; 
 
 import org . apache . cassandra . db . context . CounterContext ; 
 import org . apache . cassandra . io . IColumnSerializer ; 
 + import org . apache . cassandra . io . util . FileDataInput ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 
 public class ColumnSerializer implements IColumnSerializer 
 @ @ - 86 , 7 + 87 , 16 @ @ public class ColumnSerializer implements IColumnSerializer 
 { 
 ByteBuffer name = ByteBufferUtil . readWithShortLength ( dis ) ; 
 if ( name . remaining ( ) < = 0 ) 
 - throw new CorruptColumnException ( " invalid column name length " + name . remaining ( ) ) ; 
 + { 
 + String format = " invalid column name length % d % s " ; 
 + String details = " " ; 
 + if ( dis instanceof FileDataInput ) 
 + { 
 + FileDataInput fdis = ( FileDataInput ) dis ; 
 + details = String . format ( " ( % s , % d bytes remaining ) " , fdis . getPath ( ) , fdis . bytesRemaining ( ) ) ; 
 + } 
 + throw new CorruptColumnException ( String . format ( format , name . remaining ( ) , details ) ) ; 
 + } 
 
 int b = dis . readUnsignedByte ( ) ; 
 if ( ( b & COUNTER _ MASK ) ! = 0 ) 
 diff - - git a / src / java / org / apache / cassandra / db / DataTracker . java b / src / java / org / apache / cassandra / db / DataTracker . java 
 index 1c4bdca . . db82725 100644 
 - - - a / src / java / org / apache / cassandra / db / DataTracker . java 
 + + + b / src / java / org / apache / cassandra / db / DataTracker . java 
 @ @ - 623 , 6 + 623 , 7 @ @ public class DataTracker 
 { 
 ImmutableSet < SSTableReader > oldSet = ImmutableSet . copyOf ( oldSSTables ) ; 
 int newSSTablesSize = sstables . size ( ) - oldSSTables . size ( ) + Iterables . size ( replacements ) ; 
 + assert newSSTablesSize > = Iterables . size ( replacements ) : String . format ( " Incoherent new size % d replacing % s by % s in % s " , newSSTablesSize , oldSSTables , replacements , this ) ; 
 List < SSTableReader > newSSTables = new ArrayList < SSTableReader > ( newSSTablesSize ) ; 
 for ( SSTableReader sstable : sstables ) 
 { 
 @ @ - 630 , 8 + 631 , 14 @ @ public class DataTracker 
 newSSTables . add ( sstable ) ; 
 } 
 Iterables . addAll ( newSSTables , replacements ) ; 
 - assert newSSTables . size ( ) = = newSSTablesSize ; 
 + assert newSSTables . size ( ) = = newSSTablesSize : String . format ( " Expecting new size of % d , got % d while replacing % s by % s in % s " , newSSTablesSize , newSSTables . size ( ) , oldSSTables , replacements , this ) ; 
 return newSSTables ; 
 } 
 + 
 + @ Override 
 + public String toString ( ) 
 + { 
 + return String . format ( " View ( pending _ count = % d , sstables = % s , compacting = % s ) " , memtablesPendingFlush . size ( ) , sstables , compacting ) ; 
 + } 
 } 
 }
