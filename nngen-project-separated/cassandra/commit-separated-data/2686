BLEU SCORE: 0.05522397783539471

TEST MSG: Fix NPE on BulkLoader caused by losing StreamEvent
GENERATED MSG: enable skipping bad rows on LazilyCompacted path .

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index d6c9ae6 . . 3e73f91 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 27 , 6 + 27 , 7 @ @ <nl> * Optimize single partition batch statements ( CASSANDRA - 6737 ) <nl> * Disallow post - query re - ordering when paging ( CASSANDRA - 6722 ) <nl> * Fix potential paging bug with deleted columns ( CASSANDRA - 6748 ) <nl> + * Fix NPE on BulkLoader caused by losing StreamEvent ( CASSANDRA - 6636 ) <nl> Merged from 1 . 2 : <nl> * Add CMSClassUnloadingEnabled JVM option ( CASSANDRA - 6541 ) <nl> * Catch memtable flush exceptions during shutdown ( CASSANDRA - 6735 ) <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableLoader . java b / src / java / org / apache / cassandra / io / sstable / SSTableLoader . java <nl> index f867317 . . 1ea4c55 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableLoader . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableLoader . java <nl> @ @ - 144 , 7 + 144 , 7 @ @ public class SSTableLoader implements StreamEventHandler <nl> return stream ( Collections . < InetAddress > emptySet ( ) ) ; <nl> } <nl> <nl> - public StreamResultFuture stream ( Set < InetAddress > toIgnore ) <nl> + public StreamResultFuture stream ( Set < InetAddress > toIgnore , StreamEventHandler . . . listeners ) <nl> { <nl> client . init ( keyspace ) ; <nl> outputHandler . output ( " Established connection to initial hosts " ) ; <nl> @ @ - 175 , 9 + 175 , 8 @ @ public class SSTableLoader implements StreamEventHandler <nl> <nl> plan . transferFiles ( remote , streamingDetails . get ( remote ) ) ; <nl> } <nl> - StreamResultFuture bulkResult = plan . execute ( ) ; <nl> - bulkResult . addEventListener ( this ) ; <nl> - return bulkResult ; <nl> + plan . listeners ( this , listeners ) ; <nl> + return plan . execute ( ) ; <nl> } <nl> <nl> public void onSuccess ( StreamState finalState ) { } <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamPlan . java b / src / java / org / apache / cassandra / streaming / StreamPlan . java <nl> index 288929c . . 740ad66 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamPlan . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamPlan . java <nl> @ @ - 33 , 6 + 33 , 7 @ @ public class StreamPlan <nl> { <nl> private final UUID planId = UUIDGen . getTimeUUID ( ) ; <nl> private final String description ; <nl> + private final List < StreamEventHandler > handlers = new ArrayList < > ( ) ; <nl> <nl> / / sessions per InetAddress of the other end . <nl> private final Map < InetAddress , StreamSession > sessions = new HashMap < > ( ) ; <nl> @ @ - 121 , 6 + 122 , 14 @ @ public class StreamPlan <nl> return this ; <nl> } <nl> <nl> + public StreamPlan listeners ( StreamEventHandler handler , StreamEventHandler . . . handlers ) <nl> + { <nl> + this . handlers . add ( handler ) ; <nl> + if ( handlers ! = null ) <nl> + Collections . addAll ( this . handlers , handlers ) ; <nl> + return this ; <nl> + } <nl> + <nl> / * * <nl> * @ return true if this plan has no plan to execute <nl> * / <nl> @ @ - 136 , 7 + 145 , 7 @ @ public class StreamPlan <nl> * / <nl> public StreamResultFuture execute ( ) <nl> { <nl> - return StreamResultFuture . init ( planId , description , sessions . values ( ) ) ; <nl> + return StreamResultFuture . init ( planId , description , sessions . values ( ) , handlers ) ; <nl> } <nl> <nl> / * * <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamResultFuture . java b / src / java / org / apache / cassandra / streaming / StreamResultFuture . java <nl> index ccd3c92 . . dcffaff 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamResultFuture . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamResultFuture . java <nl> @ @ - 75 , 9 + 75 , 14 @ @ public final class StreamResultFuture extends AbstractFuture < StreamState > <nl> set ( getCurrentState ( ) ) ; <nl> } <nl> <nl> - static StreamResultFuture init ( UUID planId , String description , Collection < StreamSession > sessions ) <nl> + static StreamResultFuture init ( UUID planId , String description , Collection < StreamSession > sessions , Collection < StreamEventHandler > listeners ) <nl> { <nl> StreamResultFuture future = createAndRegister ( planId , description , sessions ) ; <nl> + if ( listeners ! = null ) <nl> + { <nl> + for ( StreamEventHandler listener : listeners ) <nl> + future . addEventListener ( listener ) ; <nl> + } <nl> <nl> logger . info ( " [ Stream # { } ] Executing streaming plan for { } " , planId , description ) ; <nl> / / start sessions <nl> diff - - git a / src / java / org / apache / cassandra / tools / BulkLoader . java b / src / java / org / apache / cassandra / tools / BulkLoader . java <nl> index 6c157e2 . . 37ec635 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / BulkLoader . java <nl> + + + b / src / java / org / apache / cassandra / tools / BulkLoader . java <nl> @ @ - 79 , 7 + 79 , 10 @ @ public class BulkLoader <nl> StreamResultFuture future = null ; <nl> try <nl> { <nl> - future = loader . stream ( options . ignores ) ; <nl> + if ( options . noProgress ) <nl> + future = loader . stream ( options . ignores ) ; <nl> + else <nl> + future = loader . stream ( options . ignores , new ProgressIndicator ( ) ) ; <nl> } <nl> catch ( Exception e ) <nl> { <nl> @ @ - 94 , 8 + 97 , 6 @ @ public class BulkLoader <nl> } <nl> <nl> handler . output ( String . format ( " Streaming session ID : % s " , future . planId ) ) ; <nl> - if ( ! options . noProgress ) <nl> - future . addEventListener ( new ProgressIndicator ( ) ) ; <nl> <nl> try <nl> {
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index b993c48 . . 36050c5 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 15 , 6 + 15 , 7 @ @ dev <nl> * include jna dependency in RPM package ( CASSANDRA - 1690 ) <nl> * add - - skip - keys option to stress . py ( CASSANDRA - 1696 ) <nl> * improve cli handling of non - string column names ( CASSANDRA - 1701 ) <nl> + * enable skipping bad rows on LazilyCompacted path ( CASSANDRA - 1702 ) <nl> <nl> <nl> 0 . 7 . 0 - beta3 <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnSerializer . java b / src / java / org / apache / cassandra / db / ColumnSerializer . java <nl> index 34ac0ac . . 569289d 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnSerializer . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnSerializer . java <nl> @ @ - 64 , 6 + 64 , 9 @ @ public class ColumnSerializer implements ICompactSerializer2 < IColumn > <nl> public Column deserialize ( DataInput dis ) throws IOException <nl> { <nl> ByteBuffer name = FBUtilities . readShortByteArray ( dis ) ; <nl> + if ( name . remaining ( ) < = 0 ) <nl> + throw new CorruptColumnException ( " invalid column name length " + name . remaining ( ) ) ; <nl> + <nl> int b = dis . readUnsignedByte ( ) ; <nl> if ( ( b & EXPIRATION _ MASK ) ! = 0 ) <nl> { <nl> @ @ - 97 , 4 + 100 , 12 @ @ public class ColumnSerializer implements ICompactSerializer2 < IColumn > <nl> } <nl> } <nl> } <nl> + <nl> + private static class CorruptColumnException extends IOException <nl> + { <nl> + public CorruptColumnException ( String s ) <nl> + { <nl> + super ( s ) ; <nl> + } <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> index 057f4a2 . . 077914e 100644 <nl> - - - a / src / java / org / apache / cassandra / db / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> @ @ - 272 , 16 + 272 , 21 @ @ public class CompactionManager implements CompactionManagerMBean <nl> writer = new SSTableWriter ( newFilename , expectedBloomFilterSize , cfs . metadata , cfs . partitioner ) ; <nl> while ( nni . hasNext ( ) ) <nl> { <nl> - AbstractCompactedRow row = nni . next ( ) ; <nl> + writer . mark ( ) ; <nl> try <nl> { <nl> + AbstractCompactedRow row = nni . next ( ) ; <nl> writer . append ( row ) ; <nl> } <nl> - catch ( IOException ex ) <nl> + catch ( Exception e ) <nl> + { <nl> + logger . error ( " non - fatal error during compaction " , e ) ; <nl> + writer . reset ( ) ; <nl> + } <nl> + catch ( IOError e ) <nl> { <nl> - writer . abort ( ) ; <nl> - / / rethrow the exception so that caller knows compaction failed . <nl> - throw ex ; <nl> + logger . error ( " non - fatal error during compaction " , e ) ; <nl> + writer . reset ( ) ; <nl> } <nl> totalkeysWritten + + ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> index 4b3b5f0 . . 523a2c4 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> @ @ - 38 , 6 + 38 , 7 @ @ import org . apache . cassandra . dht . IPartitioner ; <nl> import org . apache . cassandra . io . AbstractCompactedRow ; <nl> import org . apache . cassandra . io . ICompactionInfo ; <nl> import org . apache . cassandra . io . util . BufferedRandomAccessFile ; <nl> + import org . apache . cassandra . io . util . FileMark ; <nl> import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . io . util . SegmentedFile ; <nl> import org . apache . cassandra . service . StorageService ; <nl> @ @ - 55 , 6 + 56 , 7 @ @ public class SSTableWriter extends SSTable <nl> private SegmentedFile . Builder dbuilder ; <nl> private final BufferedRandomAccessFile dataFile ; <nl> private DecoratedKey lastWrittenKey ; <nl> + private FileMark dataMark ; <nl> <nl> public SSTableWriter ( String filename , long keyCount ) throws IOException <nl> { <nl> @ @ - 99 , 6 + 101 , 25 @ @ public class SSTableWriter extends SSTable <nl> } <nl> } <nl> <nl> + public void mark ( ) <nl> + { <nl> + dataMark = dataFile . mark ( ) ; <nl> + iwriter . mark ( ) ; <nl> + } <nl> + <nl> + public void reset ( ) <nl> + { <nl> + try <nl> + { <nl> + dataFile . reset ( dataMark ) ; <nl> + iwriter . reset ( ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new IOError ( e ) ; <nl> + } <nl> + } <nl> + <nl> private long beforeAppend ( DecoratedKey decoratedKey ) throws IOException <nl> { <nl> if ( decoratedKey = = null ) <nl> @ @ - 121 , 8 + 142 , 8 @ @ public class SSTableWriter extends SSTable <nl> <nl> if ( logger . isTraceEnabled ( ) ) <nl> logger . trace ( " wrote " + decoratedKey + " at " + dataPosition ) ; <nl> - dbuilder . addPotentialBoundary ( dataPosition ) ; <nl> iwriter . afterAppend ( decoratedKey , dataPosition ) ; <nl> + dbuilder . addPotentialBoundary ( dataPosition ) ; <nl> } <nl> <nl> public void append ( AbstractCompactedRow row ) throws IOException <nl> @ @ - 176 , 7 + 197 , 9 @ @ public class SSTableWriter extends SSTable <nl> iwriter . close ( ) ; <nl> <nl> / / main data <nl> + long position = dataFile . getFilePointer ( ) ; <nl> dataFile . close ( ) ; / / calls force <nl> + FileUtils . truncate ( dataFile . getPath ( ) , position ) ; <nl> <nl> / / write sstable statistics <nl> writeStatistics ( descriptor , estimatedRowSize , estimatedColumnCount ) ; <nl> @ @ - 358 , 7 + 381 , 8 @ @ public class SSTableWriter extends SSTable <nl> public final SegmentedFile . Builder builder ; <nl> public final IndexSummary summary ; <nl> public final BloomFilter bf ; <nl> - <nl> + private FileMark mark ; <nl> + <nl> IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException <nl> { <nl> this . desc = desc ; <nl> @ @ - 396 , 11 + 420 , 25 @ @ public class SSTableWriter extends SSTable <nl> stream . close ( ) ; <nl> <nl> / / index <nl> - indexFile . getChannel ( ) . force ( true ) ; <nl> - indexFile . close ( ) ; <nl> + long position = indexFile . getFilePointer ( ) ; <nl> + indexFile . close ( ) ; / / calls force <nl> + FileUtils . truncate ( indexFile . getPath ( ) , position ) ; <nl> <nl> / / finalize in - memory index state <nl> summary . complete ( ) ; <nl> } <nl> + <nl> + public void mark ( ) <nl> + { <nl> + mark = indexFile . mark ( ) ; <nl> + } <nl> + <nl> + public void reset ( ) throws IOException <nl> + { <nl> + / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . <nl> + / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so <nl> + / / we assume that if that worked then we won ' t be trying to reset . <nl> + indexFile . reset ( mark ) ; <nl> + } <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / io / util / FileUtils . java b / src / java / org / apache / cassandra / io / util / FileUtils . java <nl> index e2ca78c . . 11c6b4b 100644 <nl> - - - a / src / java / org / apache / cassandra / io / util / FileUtils . java <nl> + + + b / src / java / org / apache / cassandra / io / util / FileUtils . java <nl> @ @ - 19 , 7 + 19 , 9 @ @ <nl> package org . apache . cassandra . io . util ; <nl> <nl> import java . io . File ; <nl> + import java . io . FileNotFoundException ; <nl> import java . io . IOException ; <nl> + import java . io . RandomAccessFile ; <nl> import java . text . DecimalFormat ; <nl> import java . util . Comparator ; <nl> import java . util . List ; <nl> @ @ - 27 , 9 + 29 , 6 @ @ import java . util . List ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> - import com . sun . jna . LastErrorException ; <nl> - import org . apache . cassandra . utils . CLibrary ; <nl> - <nl> <nl> public class FileUtils <nl> { <nl> @ @ - 65 , 6 + 64 , 20 @ @ public class FileUtils <nl> throw new IOException ( String . format ( " Failed to rename % s to % s " , from . getPath ( ) , to . getPath ( ) ) ) ; <nl> } <nl> <nl> + public static void truncate ( String path , long size ) throws IOException <nl> + { <nl> + RandomAccessFile file ; <nl> + try <nl> + { <nl> + file = new RandomAccessFile ( path , " rw " ) ; <nl> + } <nl> + catch ( FileNotFoundException e ) <nl> + { <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> + file . getChannel ( ) . truncate ( size ) ; <nl> + } <nl> + <nl> public static class FileComparator implements Comparator < File > <nl> { <nl> public int compare ( File f , File f2 )

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index d6c9ae6 . . 3e73f91 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 27 , 6 + 27 , 7 @ @ 
 * Optimize single partition batch statements ( CASSANDRA - 6737 ) 
 * Disallow post - query re - ordering when paging ( CASSANDRA - 6722 ) 
 * Fix potential paging bug with deleted columns ( CASSANDRA - 6748 ) 
 + * Fix NPE on BulkLoader caused by losing StreamEvent ( CASSANDRA - 6636 ) 
 Merged from 1 . 2 : 
 * Add CMSClassUnloadingEnabled JVM option ( CASSANDRA - 6541 ) 
 * Catch memtable flush exceptions during shutdown ( CASSANDRA - 6735 ) 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableLoader . java b / src / java / org / apache / cassandra / io / sstable / SSTableLoader . java 
 index f867317 . . 1ea4c55 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableLoader . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableLoader . java 
 @ @ - 144 , 7 + 144 , 7 @ @ public class SSTableLoader implements StreamEventHandler 
 return stream ( Collections . < InetAddress > emptySet ( ) ) ; 
 } 
 
 - public StreamResultFuture stream ( Set < InetAddress > toIgnore ) 
 + public StreamResultFuture stream ( Set < InetAddress > toIgnore , StreamEventHandler . . . listeners ) 
 { 
 client . init ( keyspace ) ; 
 outputHandler . output ( " Established connection to initial hosts " ) ; 
 @ @ - 175 , 9 + 175 , 8 @ @ public class SSTableLoader implements StreamEventHandler 
 
 plan . transferFiles ( remote , streamingDetails . get ( remote ) ) ; 
 } 
 - StreamResultFuture bulkResult = plan . execute ( ) ; 
 - bulkResult . addEventListener ( this ) ; 
 - return bulkResult ; 
 + plan . listeners ( this , listeners ) ; 
 + return plan . execute ( ) ; 
 } 
 
 public void onSuccess ( StreamState finalState ) { } 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamPlan . java b / src / java / org / apache / cassandra / streaming / StreamPlan . java 
 index 288929c . . 740ad66 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamPlan . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamPlan . java 
 @ @ - 33 , 6 + 33 , 7 @ @ public class StreamPlan 
 { 
 private final UUID planId = UUIDGen . getTimeUUID ( ) ; 
 private final String description ; 
 + private final List < StreamEventHandler > handlers = new ArrayList < > ( ) ; 
 
 / / sessions per InetAddress of the other end . 
 private final Map < InetAddress , StreamSession > sessions = new HashMap < > ( ) ; 
 @ @ - 121 , 6 + 122 , 14 @ @ public class StreamPlan 
 return this ; 
 } 
 
 + public StreamPlan listeners ( StreamEventHandler handler , StreamEventHandler . . . handlers ) 
 + { 
 + this . handlers . add ( handler ) ; 
 + if ( handlers ! = null ) 
 + Collections . addAll ( this . handlers , handlers ) ; 
 + return this ; 
 + } 
 + 
 / * * 
 * @ return true if this plan has no plan to execute 
 * / 
 @ @ - 136 , 7 + 145 , 7 @ @ public class StreamPlan 
 * / 
 public StreamResultFuture execute ( ) 
 { 
 - return StreamResultFuture . init ( planId , description , sessions . values ( ) ) ; 
 + return StreamResultFuture . init ( planId , description , sessions . values ( ) , handlers ) ; 
 } 
 
 / * * 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamResultFuture . java b / src / java / org / apache / cassandra / streaming / StreamResultFuture . java 
 index ccd3c92 . . dcffaff 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamResultFuture . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamResultFuture . java 
 @ @ - 75 , 9 + 75 , 14 @ @ public final class StreamResultFuture extends AbstractFuture < StreamState > 
 set ( getCurrentState ( ) ) ; 
 } 
 
 - static StreamResultFuture init ( UUID planId , String description , Collection < StreamSession > sessions ) 
 + static StreamResultFuture init ( UUID planId , String description , Collection < StreamSession > sessions , Collection < StreamEventHandler > listeners ) 
 { 
 StreamResultFuture future = createAndRegister ( planId , description , sessions ) ; 
 + if ( listeners ! = null ) 
 + { 
 + for ( StreamEventHandler listener : listeners ) 
 + future . addEventListener ( listener ) ; 
 + } 
 
 logger . info ( " [ Stream # { } ] Executing streaming plan for { } " , planId , description ) ; 
 / / start sessions 
 diff - - git a / src / java / org / apache / cassandra / tools / BulkLoader . java b / src / java / org / apache / cassandra / tools / BulkLoader . java 
 index 6c157e2 . . 37ec635 100644 
 - - - a / src / java / org / apache / cassandra / tools / BulkLoader . java 
 + + + b / src / java / org / apache / cassandra / tools / BulkLoader . java 
 @ @ - 79 , 7 + 79 , 10 @ @ public class BulkLoader 
 StreamResultFuture future = null ; 
 try 
 { 
 - future = loader . stream ( options . ignores ) ; 
 + if ( options . noProgress ) 
 + future = loader . stream ( options . ignores ) ; 
 + else 
 + future = loader . stream ( options . ignores , new ProgressIndicator ( ) ) ; 
 } 
 catch ( Exception e ) 
 { 
 @ @ - 94 , 8 + 97 , 6 @ @ public class BulkLoader 
 } 
 
 handler . output ( String . format ( " Streaming session ID : % s " , future . planId ) ) ; 
 - if ( ! options . noProgress ) 
 - future . addEventListener ( new ProgressIndicator ( ) ) ; 
 
 try 
 {

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index b993c48 . . 36050c5 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 15 , 6 + 15 , 7 @ @ dev 
 * include jna dependency in RPM package ( CASSANDRA - 1690 ) 
 * add - - skip - keys option to stress . py ( CASSANDRA - 1696 ) 
 * improve cli handling of non - string column names ( CASSANDRA - 1701 ) 
 + * enable skipping bad rows on LazilyCompacted path ( CASSANDRA - 1702 ) 
 
 
 0 . 7 . 0 - beta3 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnSerializer . java b / src / java / org / apache / cassandra / db / ColumnSerializer . java 
 index 34ac0ac . . 569289d 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnSerializer . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnSerializer . java 
 @ @ - 64 , 6 + 64 , 9 @ @ public class ColumnSerializer implements ICompactSerializer2 < IColumn > 
 public Column deserialize ( DataInput dis ) throws IOException 
 { 
 ByteBuffer name = FBUtilities . readShortByteArray ( dis ) ; 
 + if ( name . remaining ( ) < = 0 ) 
 + throw new CorruptColumnException ( " invalid column name length " + name . remaining ( ) ) ; 
 + 
 int b = dis . readUnsignedByte ( ) ; 
 if ( ( b & EXPIRATION _ MASK ) ! = 0 ) 
 { 
 @ @ - 97 , 4 + 100 , 12 @ @ public class ColumnSerializer implements ICompactSerializer2 < IColumn > 
 } 
 } 
 } 
 + 
 + private static class CorruptColumnException extends IOException 
 + { 
 + public CorruptColumnException ( String s ) 
 + { 
 + super ( s ) ; 
 + } 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java 
 index 057f4a2 . . 077914e 100644 
 - - - a / src / java / org / apache / cassandra / db / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / CompactionManager . java 
 @ @ - 272 , 16 + 272 , 21 @ @ public class CompactionManager implements CompactionManagerMBean 
 writer = new SSTableWriter ( newFilename , expectedBloomFilterSize , cfs . metadata , cfs . partitioner ) ; 
 while ( nni . hasNext ( ) ) 
 { 
 - AbstractCompactedRow row = nni . next ( ) ; 
 + writer . mark ( ) ; 
 try 
 { 
 + AbstractCompactedRow row = nni . next ( ) ; 
 writer . append ( row ) ; 
 } 
 - catch ( IOException ex ) 
 + catch ( Exception e ) 
 + { 
 + logger . error ( " non - fatal error during compaction " , e ) ; 
 + writer . reset ( ) ; 
 + } 
 + catch ( IOError e ) 
 { 
 - writer . abort ( ) ; 
 - / / rethrow the exception so that caller knows compaction failed . 
 - throw ex ; 
 + logger . error ( " non - fatal error during compaction " , e ) ; 
 + writer . reset ( ) ; 
 } 
 totalkeysWritten + + ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 index 4b3b5f0 . . 523a2c4 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 @ @ - 38 , 6 + 38 , 7 @ @ import org . apache . cassandra . dht . IPartitioner ; 
 import org . apache . cassandra . io . AbstractCompactedRow ; 
 import org . apache . cassandra . io . ICompactionInfo ; 
 import org . apache . cassandra . io . util . BufferedRandomAccessFile ; 
 + import org . apache . cassandra . io . util . FileMark ; 
 import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . io . util . SegmentedFile ; 
 import org . apache . cassandra . service . StorageService ; 
 @ @ - 55 , 6 + 56 , 7 @ @ public class SSTableWriter extends SSTable 
 private SegmentedFile . Builder dbuilder ; 
 private final BufferedRandomAccessFile dataFile ; 
 private DecoratedKey lastWrittenKey ; 
 + private FileMark dataMark ; 
 
 public SSTableWriter ( String filename , long keyCount ) throws IOException 
 { 
 @ @ - 99 , 6 + 101 , 25 @ @ public class SSTableWriter extends SSTable 
 } 
 } 
 
 + public void mark ( ) 
 + { 
 + dataMark = dataFile . mark ( ) ; 
 + iwriter . mark ( ) ; 
 + } 
 + 
 + public void reset ( ) 
 + { 
 + try 
 + { 
 + dataFile . reset ( dataMark ) ; 
 + iwriter . reset ( ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new IOError ( e ) ; 
 + } 
 + } 
 + 
 private long beforeAppend ( DecoratedKey decoratedKey ) throws IOException 
 { 
 if ( decoratedKey = = null ) 
 @ @ - 121 , 8 + 142 , 8 @ @ public class SSTableWriter extends SSTable 
 
 if ( logger . isTraceEnabled ( ) ) 
 logger . trace ( " wrote " + decoratedKey + " at " + dataPosition ) ; 
 - dbuilder . addPotentialBoundary ( dataPosition ) ; 
 iwriter . afterAppend ( decoratedKey , dataPosition ) ; 
 + dbuilder . addPotentialBoundary ( dataPosition ) ; 
 } 
 
 public void append ( AbstractCompactedRow row ) throws IOException 
 @ @ - 176 , 7 + 197 , 9 @ @ public class SSTableWriter extends SSTable 
 iwriter . close ( ) ; 
 
 / / main data 
 + long position = dataFile . getFilePointer ( ) ; 
 dataFile . close ( ) ; / / calls force 
 + FileUtils . truncate ( dataFile . getPath ( ) , position ) ; 
 
 / / write sstable statistics 
 writeStatistics ( descriptor , estimatedRowSize , estimatedColumnCount ) ; 
 @ @ - 358 , 7 + 381 , 8 @ @ public class SSTableWriter extends SSTable 
 public final SegmentedFile . Builder builder ; 
 public final IndexSummary summary ; 
 public final BloomFilter bf ; 
 - 
 + private FileMark mark ; 
 + 
 IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException 
 { 
 this . desc = desc ; 
 @ @ - 396 , 11 + 420 , 25 @ @ public class SSTableWriter extends SSTable 
 stream . close ( ) ; 
 
 / / index 
 - indexFile . getChannel ( ) . force ( true ) ; 
 - indexFile . close ( ) ; 
 + long position = indexFile . getFilePointer ( ) ; 
 + indexFile . close ( ) ; / / calls force 
 + FileUtils . truncate ( indexFile . getPath ( ) , position ) ; 
 
 / / finalize in - memory index state 
 summary . complete ( ) ; 
 } 
 + 
 + public void mark ( ) 
 + { 
 + mark = indexFile . mark ( ) ; 
 + } 
 + 
 + public void reset ( ) throws IOException 
 + { 
 + / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . 
 + / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so 
 + / / we assume that if that worked then we won ' t be trying to reset . 
 + indexFile . reset ( mark ) ; 
 + } 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / io / util / FileUtils . java b / src / java / org / apache / cassandra / io / util / FileUtils . java 
 index e2ca78c . . 11c6b4b 100644 
 - - - a / src / java / org / apache / cassandra / io / util / FileUtils . java 
 + + + b / src / java / org / apache / cassandra / io / util / FileUtils . java 
 @ @ - 19 , 7 + 19 , 9 @ @ 
 package org . apache . cassandra . io . util ; 
 
 import java . io . File ; 
 + import java . io . FileNotFoundException ; 
 import java . io . IOException ; 
 + import java . io . RandomAccessFile ; 
 import java . text . DecimalFormat ; 
 import java . util . Comparator ; 
 import java . util . List ; 
 @ @ - 27 , 9 + 29 , 6 @ @ import java . util . List ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 - import com . sun . jna . LastErrorException ; 
 - import org . apache . cassandra . utils . CLibrary ; 
 - 
 
 public class FileUtils 
 { 
 @ @ - 65 , 6 + 64 , 20 @ @ public class FileUtils 
 throw new IOException ( String . format ( " Failed to rename % s to % s " , from . getPath ( ) , to . getPath ( ) ) ) ; 
 } 
 
 + public static void truncate ( String path , long size ) throws IOException 
 + { 
 + RandomAccessFile file ; 
 + try 
 + { 
 + file = new RandomAccessFile ( path , " rw " ) ; 
 + } 
 + catch ( FileNotFoundException e ) 
 + { 
 + throw new RuntimeException ( e ) ; 
 + } 
 + file . getChannel ( ) . truncate ( size ) ; 
 + } 
 + 
 public static class FileComparator implements Comparator < File > 
 { 
 public int compare ( File f , File f2 )
