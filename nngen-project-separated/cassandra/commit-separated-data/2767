BLEU SCORE: 0.0033395049215085818

TEST MSG: Correctly handle null in conditions with TTL
GENERATED MSG: Fixes to make BinaryMemtable useful . Highlights are configurable threads for [ binary ] memtable flushing and flushAndShutdown JMX / nodeprobe directive .

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index bba5f20 . . 7ba8044 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 0 . 6 <nl> + * Correctly handle null with IF conditions and TTL ( CASSANDRA - 6623 ) <nl> Merged from 1 . 2 : <nl> * Fix partition and range deletes not triggering flush ( CASSANDRA - 6655 ) <nl> <nl> diff - - git a / src / java / org / apache / cassandra / cql3 / statements / ModificationStatement . java b / src / java / org / apache / cassandra / cql3 / statements / ModificationStatement . java <nl> index c0bf428 . . 2567043 100644 <nl> - - - a / src / java / org / apache / cassandra / cql3 / statements / ModificationStatement . java <nl> + + + b / src / java / org / apache / cassandra / cql3 / statements / ModificationStatement . java <nl> @ @ - 27 , 19 + 27 , 20 @ @ import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . cql3 . * ; <nl> import org . apache . cassandra . db . * ; <nl> import org . apache . cassandra . db . filter . ColumnSlice ; <nl> + import org . apache . cassandra . db . filter . IDiskAtomFilter ; <nl> import org . apache . cassandra . db . filter . SliceQueryFilter ; <nl> import org . apache . cassandra . db . marshal . CompositeType ; <nl> import org . apache . cassandra . db . marshal . UTF8Type ; <nl> import org . apache . cassandra . db . marshal . ListType ; <nl> import org . apache . cassandra . db . marshal . BooleanType ; <nl> import org . apache . cassandra . exceptions . * ; <nl> + import org . apache . cassandra . service . CASConditions ; <nl> import org . apache . cassandra . service . ClientState ; <nl> import org . apache . cassandra . service . QueryState ; <nl> import org . apache . cassandra . service . StorageProxy ; <nl> import org . apache . cassandra . thrift . ThriftValidation ; <nl> import org . apache . cassandra . transport . messages . ResultMessage ; <nl> import org . apache . cassandra . utils . Pair ; <nl> - import org . apache . cassandra . utils . ByteBufferUtil ; <nl> <nl> / * <nl> * Abstract parent class of individual modifications , i . e . INSERT , UPDATE and DELETE . <nl> @ @ - 415 , 16 + 416 , 17 @ @ public abstract class ModificationStatement implements CQLStatement , MeasurableF <nl> UpdateParameters updParams = new UpdateParameters ( cfm , variables , queryState . getTimestamp ( ) , getTimeToLive ( variables ) , null ) ; <nl> ColumnFamily updates = updateForKey ( key , clusteringPrefix , updParams ) ; <nl> <nl> - / / When building the conditions , we should not use the TTL . It ' s not useful , and if a very low ttl ( 1 seconds ) is used , it ' s possible <nl> - / / for it to expire before actually build the conditions which would break since we would then test for the presence of tombstones . <nl> - UpdateParameters condParams = new UpdateParameters ( cfm , variables , queryState . getTimestamp ( ) , 0 , null ) ; <nl> - ColumnFamily expected = buildConditions ( key , clusteringPrefix , condParams ) ; <nl> + / / It ' s cleaner to use the query timestamp below , but it ' s in seconds while the conditions expects microseconds , so just <nl> + / / put it back in millis ( we don ' t really lose precision because the ultimate consumer , Column . isLive , re - divide it ) . <nl> + long now = queryState . getTimestamp ( ) * 1000 ; <nl> + CASConditions conditions = ifNotExists <nl> + ? new NotExistCondition ( clusteringPrefix , now ) <nl> + : new ColumnsConditions ( clusteringPrefix , cfm , key , columnConditions , variables , now ) ; <nl> <nl> ColumnFamily result = StorageProxy . cas ( keyspace ( ) , <nl> columnFamily ( ) , <nl> key , <nl> - clusteringPrefix , <nl> - expected , <nl> + conditions , <nl> updates , <nl> options . getSerialConsistency ( ) , <nl> options . getConsistency ( ) ) ; <nl> @ @ - 542 , 28 + 544 , 91 @ @ public abstract class ModificationStatement implements CQLStatement , MeasurableF <nl> return isCounter ( ) ? new CounterMutation ( rm , cl ) : rm ; <nl> } <nl> <nl> - private ColumnFamily buildConditions ( ByteBuffer key , ColumnNameBuilder clusteringPrefix , UpdateParameters params ) <nl> - throws InvalidRequestException <nl> + private static abstract class CQL3CasConditions implements CASConditions <nl> { <nl> - if ( ifNotExists ) <nl> - return null ; <nl> + protected final ColumnNameBuilder rowPrefix ; <nl> + protected final long now ; <nl> <nl> - ColumnFamily cf = TreeMapBackedSortedColumns . factory . create ( cfm ) ; <nl> + protected CQL3CasConditions ( ColumnNameBuilder rowPrefix , long now ) <nl> + { <nl> + this . rowPrefix = rowPrefix ; <nl> + this . now = now ; <nl> + } <nl> <nl> - / / CQL row marker <nl> - CFDefinition cfDef = cfm . getCfDef ( ) ; <nl> - if ( cfDef . isComposite & & ! cfDef . isCompact & & ! cfm . isSuper ( ) ) <nl> + public IDiskAtomFilter readFilter ( ) <nl> { <nl> - ByteBuffer name = clusteringPrefix . copy ( ) . add ( ByteBufferUtil . EMPTY _ BYTE _ BUFFER ) . build ( ) ; <nl> - cf . addColumn ( params . makeColumn ( name , ByteBufferUtil . EMPTY _ BYTE _ BUFFER ) ) ; <nl> + / / We always read the row entirely as on CAS failure we want to be able to distinguish between " row exists <nl> + / / but all values on why there were conditions are null " and " row doesn ' t exists " , and we can ' t rely on the <nl> + / / row marker for that ( see # 6623 ) <nl> + return new SliceQueryFilter ( rowPrefix . build ( ) , rowPrefix . buildAsEndOfRange ( ) , false , 1 , rowPrefix . componentCount ( ) ) ; <nl> } <nl> + } <nl> <nl> - / / Conditions <nl> - for ( Operation condition : columnConditions ) <nl> - condition . execute ( key , cf , clusteringPrefix . copy ( ) , params ) ; <nl> + private static class NotExistCondition extends CQL3CasConditions <nl> + { <nl> + private NotExistCondition ( ColumnNameBuilder rowPrefix , long now ) <nl> + { <nl> + super ( rowPrefix , now ) ; <nl> + } <nl> + <nl> + public boolean appliesTo ( ColumnFamily current ) <nl> + { <nl> + return current = = null | | current . hasOnlyTombstones ( now ) ; <nl> + } <nl> + } <nl> + <nl> + private static class ColumnsConditions extends CQL3CasConditions <nl> + { <nl> + private final ColumnFamily expected ; <nl> + <nl> + private ColumnsConditions ( ColumnNameBuilder rowPrefix , <nl> + CFMetaData cfm , <nl> + ByteBuffer key , <nl> + Collection < Operation > conditions , <nl> + List < ByteBuffer > variables , <nl> + long now ) throws InvalidRequestException <nl> + { <nl> + super ( rowPrefix , now ) ; <nl> + this . expected = TreeMapBackedSortedColumns . factory . create ( cfm ) ; <nl> <nl> - assert ! cf . isEmpty ( ) ; <nl> - return cf ; <nl> + / / When building the conditions , we should not use a TTL . It ' s not useful , and if a very low ttl ( 1 seconds ) is used , it ' s possible <nl> + / / for it to expire before the actual build of the conditions which would break since we would then testing for the presence of tombstones . <nl> + UpdateParameters params = new UpdateParameters ( cfm , variables , now , 0 , null ) ; <nl> + <nl> + / / Conditions <nl> + for ( Operation condition : conditions ) <nl> + condition . execute ( key , expected , rowPrefix . copy ( ) , params ) ; <nl> + } <nl> + <nl> + public boolean appliesTo ( ColumnFamily current ) <nl> + { <nl> + if ( current = = null ) <nl> + return false ; <nl> + <nl> + for ( Column e : expected ) <nl> + { <nl> + Column c = current . getColumn ( e . name ( ) ) ; <nl> + if ( e . isLive ( now ) ) <nl> + { <nl> + if ( c = = null | | ! c . isLive ( now ) | | ! c . value ( ) . equals ( e . value ( ) ) ) <nl> + return false ; <nl> + } <nl> + else <nl> + { <nl> + / / If we have a tombstone in expected , it means the condition tests that the column is <nl> + / / null , so check that we have no value <nl> + if ( c ! = null & & c . isLive ( now ) ) <nl> + return false ; <nl> + } <nl> + } <nl> + return true ; <nl> + } <nl> + <nl> + @ Override <nl> + public String toString ( ) <nl> + { <nl> + return expected . toString ( ) ; <nl> + } <nl> } <nl> <nl> public static abstract class Parsed extends CFStatement <nl> diff - - git a / src / java / org / apache / cassandra / service / CASConditions . java b / src / java / org / apache / cassandra / service / CASConditions . java <nl> new file mode 100644 <nl> index 0000000 . . d4b3e19 <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / service / CASConditions . java <nl> @ @ - 0 , 0 + 1 , 38 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an " AS IS " BASIS , <nl> + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + * See the License for the specific language governing permissions and <nl> + * limitations under the License . <nl> + * / <nl> + package org . apache . cassandra . service ; <nl> + <nl> + import org . apache . cassandra . db . ColumnFamily ; <nl> + import org . apache . cassandra . db . filter . IDiskAtomFilter ; <nl> + <nl> + / * * <nl> + * Abstract the conditions to be fulfilled by a CAS operation . <nl> + * / <nl> + public interface CASConditions <nl> + { <nl> + / * * <nl> + * The filter to use to fetch the value to compare for the CAS . <nl> + * / <nl> + public IDiskAtomFilter readFilter ( ) ; <nl> + <nl> + / * * <nl> + * Returns whether the provided CF , that represents the values fetched using the <nl> + * readFilter ( ) , match the CAS conditions this object stands for . <nl> + * / <nl> + public boolean appliesTo ( ColumnFamily current ) ; <nl> + } <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageProxy . java b / src / java / org / apache / cassandra / service / StorageProxy . java <nl> index 5671655 . . 8d1f913 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageProxy . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageProxy . java <nl> @ @ - 41 , 11 + 41 , 8 @ @ import org . apache . cassandra . concurrent . StageManager ; <nl> import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . config . Schema ; <nl> - import org . apache . cassandra . cql3 . ColumnNameBuilder ; <nl> import org . apache . cassandra . db . * ; <nl> import org . apache . cassandra . db . Keyspace ; <nl> - import org . apache . cassandra . db . filter . NamesQueryFilter ; <nl> - import org . apache . cassandra . db . filter . SliceQueryFilter ; <nl> import org . apache . cassandra . db . marshal . UUIDType ; <nl> import org . apache . cassandra . dht . AbstractBounds ; <nl> import org . apache . cassandra . dht . Bounds ; <nl> @ @ - 157 , 7 + 154 , 7 @ @ public class StorageProxy implements StorageProxyMBean <nl> <nl> / * * <nl> * Apply @ param updates if and only if the current values in the row for @ param key <nl> - * match the ones given by @ param expected . The algorithm is " raw " Paxos : that is , Paxos <nl> + * match the provided @ param conditions . The algorithm is " raw " Paxos : that is , Paxos <nl> * minus leader election - - any node in the cluster may propose changes for any row , <nl> * which ( that is , the row ) is the unit of values being proposed , not single columns . <nl> * <nl> @ @ - 189 , 23 + 186 , 18 @ @ public class StorageProxy implements StorageProxyMBean <nl> * @ param keyspaceName the keyspace for the CAS <nl> * @ param cfName the column family for the CAS <nl> * @ param key the row key for the row to CAS <nl> - * @ param prefix a column name prefix that selects the CQL3 row to check if { @ code expected } is null . If { @ code expected } <nl> - * is not null , this is ignored . If { @ code expected } is null and this is null , the full row existing is checked ( by querying <nl> - * the first live column of the row ) . <nl> - * @ param expected the expected column values . This can be null to check for existence ( see { @ code prefix } ) . <nl> - * @ param updates the value to insert if { @ code expected matches the current values } . <nl> + * @ param conditions the conditions for the CAS to apply . <nl> + * @ param updates the value to insert if { @ code condtions } matches the current values . <nl> * @ param consistencyForPaxos the consistency for the paxos prepare and propose round . This can only be either SERIAL or LOCAL _ SERIAL . <nl> * @ param consistencyForCommit the consistency for write done during the commit phase . This can be anything , except SERIAL or LOCAL _ SERIAL . <nl> * <nl> - * @ return null if the operation succeeds in updating the row , or the current values for the columns contained in <nl> - * expected ( since , if the CAS doesn ' t succeed , it means the current value do not match the one in expected ) . If <nl> - * expected = = null and the CAS is unsuccessfull , the first live column of the CF is returned . <nl> + * @ return null if the operation succeeds in updating the row , or the current values corresponding to conditions . <nl> + * ( since , if the CAS doesn ' t succeed , it means the current value do not match the conditions ) . <nl> * / <nl> public static ColumnFamily cas ( String keyspaceName , <nl> String cfName , <nl> ByteBuffer key , <nl> - ColumnNameBuilder prefix , <nl> - ColumnFamily expected , <nl> + CASConditions conditions , <nl> ColumnFamily updates , <nl> ConsistencyLevel consistencyForPaxos , <nl> ConsistencyLevel consistencyForCommit ) <nl> @ @ - 227 , 27 + 219 , 15 @ @ public class StorageProxy implements StorageProxyMBean <nl> <nl> UUID ballot = beginAndRepairPaxos ( start , key , metadata , liveEndpoints , requiredParticipants , consistencyForPaxos ) ; <nl> <nl> - / / read the current value and compare with expected <nl> + / / read the current values and check they validate the conditions <nl> Tracing . trace ( " Reading existing values for CAS precondition " ) ; <nl> long timestamp = System . currentTimeMillis ( ) ; <nl> - ReadCommand readCommand ; <nl> - if ( expected = = null | | expected . isEmpty ( ) ) <nl> - { <nl> - SliceQueryFilter filter = prefix = = null <nl> - ? new SliceQueryFilter ( ByteBufferUtil . EMPTY _ BYTE _ BUFFER , ByteBufferUtil . EMPTY _ BYTE _ BUFFER , false , 1 ) <nl> - : new SliceQueryFilter ( prefix . build ( ) , prefix . buildAsEndOfRange ( ) , false , 1 , prefix . componentCount ( ) ) ; <nl> - readCommand = new SliceFromReadCommand ( keyspaceName , key , cfName , timestamp , filter ) ; <nl> - } <nl> - else <nl> - { <nl> - assert ! expected . isEmpty ( ) ; <nl> - readCommand = new SliceByNamesReadCommand ( keyspaceName , key , cfName , timestamp , new NamesQueryFilter ( ImmutableSortedSet . copyOf ( metadata . comparator , expected . getColumnNames ( ) ) ) ) ; <nl> - } <nl> + ReadCommand readCommand = ReadCommand . create ( keyspaceName , key , cfName , timestamp , conditions . readFilter ( ) ) ; <nl> List < Row > rows = read ( Arrays . asList ( readCommand ) , consistencyForPaxos = = ConsistencyLevel . LOCAL _ SERIAL ? ConsistencyLevel . LOCAL _ QUORUM : ConsistencyLevel . QUORUM ) ; <nl> ColumnFamily current = rows . get ( 0 ) . cf ; <nl> - if ( ! casApplies ( expected , current ) ) <nl> + if ( ! conditions . appliesTo ( current ) ) <nl> { <nl> - Tracing . trace ( " CAS precondition { } does not match current values { } " , expected , current ) ; <nl> + Tracing . trace ( " CAS precondition { } does not match current values { } " , conditions , current ) ; <nl> / / We should not return null as this means success <nl> return current = = null ? EmptyColumns . factory . create ( metadata ) : current ; <nl> } <nl> @ @ - 274 , 41 + 254 , 6 @ @ public class StorageProxy implements StorageProxyMBean <nl> throw new WriteTimeoutException ( WriteType . CAS , consistencyForPaxos , 0 , consistencyForPaxos . blockFor ( Keyspace . open ( keyspaceName ) ) ) ; <nl> } <nl> <nl> - private static boolean hasLiveColumns ( ColumnFamily cf , long now ) <nl> - { <nl> - return cf ! = null & & ! cf . hasOnlyTombstones ( now ) ; <nl> - } <nl> - <nl> - private static boolean casApplies ( ColumnFamily expected , ColumnFamily current ) <nl> - { <nl> - long now = System . currentTimeMillis ( ) ; <nl> - <nl> - if ( ! hasLiveColumns ( expected , now ) ) <nl> - return ! hasLiveColumns ( current , now ) ; <nl> - else if ( ! hasLiveColumns ( current , now ) ) <nl> - return false ; <nl> - <nl> - / / current has been built from expected , so we know that it can ' t have columns <nl> - / / that excepted don ' t have . So we just check that for each columns in expected : <nl> - / / - if it is a tombstone , whether current has no column or a tombstone ; <nl> - / / - otherwise , that current has a live column with the same value . <nl> - for ( Column e : expected ) <nl> - { <nl> - Column c = current . getColumn ( e . name ( ) ) ; <nl> - if ( e . isLive ( now ) ) <nl> - { <nl> - if ( ! ( c ! = null & & c . isLive ( now ) & & c . value ( ) . equals ( e . value ( ) ) ) ) <nl> - return false ; <nl> - } <nl> - else <nl> - { <nl> - if ( c ! = null & & c . isLive ( now ) ) <nl> - return false ; <nl> - } <nl> - } <nl> - return true ; <nl> - } <nl> - <nl> private static Predicate < InetAddress > sameDCPredicateFor ( final String dc ) <nl> { <nl> final IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / thrift / CassandraServer . java b / src / java / org / apache / cassandra / thrift / CassandraServer . java <nl> index beaae78 . . ef5eeb8 100644 <nl> - - - a / src / java / org / apache / cassandra / thrift / CassandraServer . java <nl> + + + b / src / java / org / apache / cassandra / thrift / CassandraServer . java <nl> @ @ - 30 , 6 + 30 , 7 @ @ import java . util . zip . Inflater ; <nl> import com . google . common . base . Function ; <nl> import com . google . common . base . Joiner ; <nl> import com . google . common . collect . ImmutableMap ; <nl> + import com . google . common . collect . ImmutableSortedSet ; <nl> import com . google . common . collect . Iterables ; <nl> import com . google . common . collect . Lists ; <nl> import com . google . common . collect . Maps ; <nl> @ @ - 59 , 6 + 60 , 7 @ @ import org . apache . cassandra . locator . DynamicEndpointSnitch ; <nl> import org . apache . cassandra . metrics . ClientMetrics ; <nl> import org . apache . cassandra . scheduler . IRequestScheduler ; <nl> import org . apache . cassandra . serializers . MarshalException ; <nl> + import org . apache . cassandra . service . CASConditions ; <nl> import org . apache . cassandra . service . ClientState ; <nl> import org . apache . cassandra . service . MigrationManager ; <nl> import org . apache . cassandra . service . StorageProxy ; <nl> @ @ - 768 , 8 + 770 , 7 @ @ public class CassandraServer implements Cassandra . Iface <nl> ColumnFamily result = StorageProxy . cas ( cState . getKeyspace ( ) , <nl> column _ family , <nl> key , <nl> - null , <nl> - cfExpected , <nl> + new ThriftCASConditions ( cfExpected ) , <nl> cfUpdates , <nl> ThriftConversion . fromThrift ( serial _ consistency _ level ) , <nl> ThriftConversion . fromThrift ( commit _ consistency _ level ) ) ; <nl> @ @ - 2158 , 5 + 2159 , 62 @ @ public class CassandraServer implements Cassandra . Iface <nl> } <nl> } ) ; <nl> } <nl> - / / main method moved to CassandraDaemon <nl> + <nl> + private static class ThriftCASConditions implements CASConditions <nl> + { <nl> + private final ColumnFamily expected ; <nl> + <nl> + private ThriftCASConditions ( ColumnFamily expected ) <nl> + { <nl> + this . expected = expected ; <nl> + } <nl> + <nl> + public IDiskAtomFilter readFilter ( ) <nl> + { <nl> + return expected = = null | | expected . isEmpty ( ) <nl> + ? new SliceQueryFilter ( ByteBufferUtil . EMPTY _ BYTE _ BUFFER , ByteBufferUtil . EMPTY _ BYTE _ BUFFER , false , 1 ) <nl> + : new NamesQueryFilter ( ImmutableSortedSet . copyOf ( expected . getComparator ( ) , expected . getColumnNames ( ) ) ) ; <nl> + } <nl> + <nl> + public boolean appliesTo ( ColumnFamily current ) <nl> + { <nl> + long now = System . currentTimeMillis ( ) ; <nl> + <nl> + if ( ! hasLiveColumns ( expected , now ) ) <nl> + return ! hasLiveColumns ( current , now ) ; <nl> + else if ( ! hasLiveColumns ( current , now ) ) <nl> + return false ; <nl> + <nl> + / / current has been built from expected , so we know that it can ' t have columns <nl> + / / that excepted don ' t have . So we just check that for each columns in expected : <nl> + / / - if it is a tombstone , whether current has no column or a tombstone ; <nl> + / / - otherwise , that current has a live column with the same value . <nl> + for ( org . apache . cassandra . db . Column e : expected ) <nl> + { <nl> + org . apache . cassandra . db . Column c = current . getColumn ( e . name ( ) ) ; <nl> + if ( e . isLive ( now ) ) <nl> + { <nl> + if ( c = = null | | ! c . isLive ( now ) | | ! c . value ( ) . equals ( e . value ( ) ) ) <nl> + return false ; <nl> + } <nl> + else <nl> + { <nl> + if ( c ! = null & & c . isLive ( now ) ) <nl> + return false ; <nl> + } <nl> + } <nl> + return true ; <nl> + } <nl> + <nl> + private static boolean hasLiveColumns ( ColumnFamily cf , long now ) <nl> + { <nl> + return cf ! = null & & ! cf . hasOnlyTombstones ( now ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public String toString ( ) <nl> + { <nl> + return expected . toString ( ) ; <nl> + } <nl> + } <nl> }
NEAREST DIFF (one line): diff - - git a / conf / storage - conf . xml b / conf / storage - conf . xml <nl> index 8aaeeb6 . . 25d2901 100644 <nl> - - - a / conf / storage - conf . xml <nl> + + + b / conf / storage - conf . xml <nl> @ @ - 308 , 4 + 308 , 19 @ @ <nl> ~ ten days . <nl> - - > <nl> < GCGraceSeconds > 864000 < / GCGraceSeconds > <nl> + <nl> + < ! - - <nl> + ~ Number of threads to run when flushing memtables to disk . Set this to <nl> + ~ the number of disks you physically have in your machine allocated for DataDirectory * 2 . <nl> + ~ If you are planning to use the Binary Memtable , its recommended to increase the max threads <nl> + ~ to maintain a higher quality of service while under load when normal memtables are flushing to disk . <nl> + - - > <nl> + < FlushMinThreads > 1 < / FlushMinThreads > <nl> + < FlushMaxThreads > 1 < / FlushMaxThreads > <nl> + <nl> + < ! - - <nl> + ~ The threshold size in megabytes the binary memtable must grow to , before it ' s submitted for flushing to disk . <nl> + - - > <nl> + < BinaryMemtableSizeInMB > 256 < / BinaryMemtableSizeInMB > <nl> + <nl> < / Storage > <nl> diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> index 9016676 . . e86b134 100644 <nl> - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> @ @ - 74 , 6 + 74 , 9 @ @ public class DatabaseDescriptor <nl> private static int slicedReadBufferSizeInKB _ = 64 ; <nl> private static List < String > tables _ = new ArrayList < String > ( ) ; <nl> private static Set < String > applicationColumnFamilies _ = new HashSet < String > ( ) ; <nl> + private static int flushMinThreads _ = 1 ; <nl> + private static int flushMaxThreads _ = 1 ; <nl> + private static int bmtThreshold _ = 256 ; <nl> <nl> / / Default descriptive names for introspection . The user can override <nl> / / these choices in the config file . These are not case sensitive . <nl> @ @ - 271 , 6 + 274 , 24 @ @ public class DatabaseDescriptor <nl> slicedReadBufferSizeInKB _ = Integer . parseInt ( rawSlicedBuffer ) ; <nl> } <nl> <nl> + String rawflushMinThreads = xmlUtils . getNodeValue ( " / Storage / FlushMinThreads " ) ; <nl> + if ( rawflushMinThreads ! = null ) <nl> + { <nl> + flushMinThreads _ = Integer . parseInt ( rawflushMinThreads ) ; <nl> + } <nl> + <nl> + String rawflushMaxThreads = xmlUtils . getNodeValue ( " / Storage / FlushMaxThreads " ) ; <nl> + if ( rawflushMaxThreads ! = null ) <nl> + { <nl> + flushMaxThreads _ = Integer . parseInt ( rawflushMaxThreads ) ; <nl> + } <nl> + <nl> + String bmtThreshold = xmlUtils . getNodeValue ( " / Storage / BinaryMemtableSizeInMB " ) ; <nl> + if ( bmtThreshold ! = null ) <nl> + { <nl> + bmtThreshold _ = Integer . parseInt ( bmtThreshold ) ; <nl> + } <nl> + <nl> / * TCP port on which the storage system listens * / <nl> String port = xmlUtils . getNodeValue ( " / Storage / StoragePort " ) ; <nl> if ( port ! = null ) <nl> @ @ - 999 , 4 + 1020 , 19 @ @ public class DatabaseDescriptor <nl> { <nl> return slicedReadBufferSizeInKB _ ; <nl> } <nl> + <nl> + public static int getFlushMinThreads ( ) <nl> + { <nl> + return flushMinThreads _ ; <nl> + } <nl> + <nl> + public static int getFlushMaxThreads ( ) <nl> + { <nl> + return flushMaxThreads _ ; <nl> + } <nl> + <nl> + public static int getBMTThreshold ( ) <nl> + { <nl> + return bmtThreshold _ ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / BinaryMemtable . java b / src / java / org / apache / cassandra / db / BinaryMemtable . java <nl> index 2cd439a . . 4530e8b 100644 <nl> - - - a / src / java / org / apache / cassandra / db / BinaryMemtable . java <nl> + + + b / src / java / org / apache / cassandra / db / BinaryMemtable . java <nl> @ @ - 34 , 11 + 34 , 13 @ @ import org . apache . cassandra . config . DatabaseDescriptor ; <nl> <nl> import org . apache . log4j . Logger ; <nl> import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; <nl> + import java . util . * ; <nl> + import org . apache . cassandra . dht . IPartitioner ; <nl> <nl> public class BinaryMemtable <nl> { <nl> private static Logger logger _ = Logger . getLogger ( Memtable . class ) ; <nl> - private int threshold _ = 512 * 1024 * 1024 ; <nl> + private int threshold _ = DatabaseDescriptor . getBMTThreshold ( ) * 1024 * 1024 ; <nl> private AtomicInteger currentSize _ = new AtomicInteger ( 0 ) ; <nl> <nl> / * Table and ColumnFamily name are used to determine the ColumnFamilyStore * / <nl> @ @ - 138 , 10 + 140 , 31 @ @ public class BinaryMemtable <nl> * Use the SSTable to write the contents of the TreeMap <nl> * to disk . <nl> * / <nl> + <nl> + String path ; <nl> + SSTableWriter writer ; <nl> ColumnFamilyStore cfStore = Table . open ( table _ ) . getColumnFamilyStore ( cfName _ ) ; <nl> List < String > keys = new ArrayList < String > ( columnFamilies _ . keySet ( ) ) ; <nl> - SSTableWriter writer = new SSTableWriter ( cfStore . getTempSSTablePath ( ) , keys . size ( ) , StorageService . getPartitioner ( ) ) ; <nl> - Collections . sort ( keys ) ; <nl> + / * <nl> + Adding a lock here so data directories are evenly used . By default currentIndex <nl> + is incremented , not an AtomicInteger . Let ' s fix this ! <nl> + * / <nl> + lock _ . lock ( ) ; <nl> + try <nl> + { <nl> + path = cfStore . getTempSSTablePath ( ) ; <nl> + writer = new SSTableWriter ( path , keys . size ( ) , StorageService . getPartitioner ( ) ) ; <nl> + } <nl> + finally <nl> + { <nl> + lock _ . unlock ( ) ; <nl> + } <nl> + <nl> + final IPartitioner partitioner = StorageService . getPartitioner ( ) ; <nl> + final Comparator < String > dc = partitioner . getDecoratedKeyComparator ( ) ; <nl> + Collections . sort ( keys , dc ) ; <nl> + <nl> + <nl> / * Use this BloomFilter to decide if a key exists in a SSTable * / <nl> for ( String key : keys ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index b08cf6b . . af6e247 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 38 , 6 + 38 , 7 @ @ import org . apache . cassandra . net . EndPoint ; <nl> import org . apache . cassandra . service . StorageService ; <nl> import org . apache . cassandra . utils . * ; <nl> import org . apache . cassandra . concurrent . DebuggableThreadPoolExecutor ; <nl> + import org . apache . cassandra . concurrent . ThreadFactoryImpl ; <nl> import org . apache . cassandra . db . filter . * ; <nl> import org . apache . cassandra . db . marshal . AbstractType ; <nl> <nl> @ @ - 55 , 8 + 56 , 8 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> private static final int BUFSIZE = 128 * 1024 * 1024 ; <nl> <nl> private static NonBlockingHashMap < String , Set < Memtable > > memtablesPendingFlush = new NonBlockingHashMap < String , Set < Memtable > > ( ) ; <nl> - private static ExecutorService flusher _ = new DebuggableThreadPoolExecutor ( " MEMTABLE - FLUSHER - POOL " ) ; <nl> - <nl> + private static ExecutorService flusher _ = new DebuggableThreadPoolExecutor ( DatabaseDescriptor . getFlushMinThreads ( ) , DatabaseDescriptor . getFlushMaxThreads ( ) , Integer . MAX _ VALUE , TimeUnit . SECONDS , new LinkedBlockingQueue < Runnable > ( ) , new ThreadFactoryImpl ( " MEMTABLE - FLUSHER - POOL " ) ) ; <nl> + <nl> private final String table _ ; <nl> public final String columnFamily _ ; <nl> private final boolean isSuper _ ; <nl> @ @ - 457 , 7 + 458 , 7 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> assert oldMemtable . isFlushed ( ) | | oldMemtable . isClean ( ) ; <nl> } <nl> <nl> - void forceFlushBinary ( ) <nl> + public void forceFlushBinary ( ) <nl> { <nl> submitFlush ( binaryMemtable _ . get ( ) ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / Table . java b / src / java / org / apache / cassandra / db / Table . java <nl> index 54389e5 . . 04b28fb 100644 <nl> - - - a / src / java / org / apache / cassandra / db / Table . java <nl> + + + b / src / java / org / apache / cassandra / db / Table . java <nl> @ @ - 642 , 11 + 642 , 11 @ @ public class Table <nl> for ( ColumnFamily columnFamily : row . getColumnFamilies ( ) ) <nl> { <nl> Collection < IColumn > columns = columnFamily . getSortedColumns ( ) ; <nl> - for ( IColumn column : columns ) <nl> + for ( IColumn column : columns ) <nl> { <nl> - ColumnFamilyStore cfStore = columnFamilyStores _ . get ( column . name ( ) ) ; <nl> + ColumnFamilyStore cfStore = columnFamilyStores _ . get ( new String ( column . name ( ) , " UTF - 8 " ) ) ; <nl> cfStore . applyBinary ( key , column . value ( ) ) ; <nl> - 	 } <nl> + } <nl> } <nl> row . clear ( ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / net / MessagingService . java b / src / java / org / apache / cassandra / net / MessagingService . java <nl> index 954324b . . 21f97d2 100644 <nl> - - - a / src / java / org / apache / cassandra / net / MessagingService . java <nl> + + + b / src / java / org / apache / cassandra / net / MessagingService . java <nl> @ @ - 478 , 14 + 478 , 26 @ @ public class MessagingService implements IMessagingService <nl> { <nl> isStreaming _ . set ( bVal ) ; <nl> } <nl> + public static void flushAndshutdown ( ) <nl> + { <nl> + / / safely shutdown and send all writes <nl> + for ( Map . Entry < String , TcpConnectionManager > entry : poolTable _ . entrySet ( ) ) <nl> + { <nl> + for ( TcpConnection connection : entry . getValue ( ) . getConnections ( ) ) <nl> + { <nl> + connection . doPendingWrites ( ) ; <nl> + } <nl> + } <nl> + shutdown ( ) ; <nl> + } <nl> <nl> public static void shutdown ( ) <nl> { <nl> logger _ . info ( " Shutting down . . . " ) ; <nl> - synchronized ( MessagingService . class ) <nl> - { <nl> - / * Stop listening on any socket * / <nl> - for ( SelectionKey skey : listenSockets _ . values ( ) ) <nl> + synchronized ( MessagingService . class ) <nl> + { <nl> + / * Stop listening on any socket * / <nl> + for ( SelectionKey skey : listenSockets _ . values ( ) ) <nl> { <nl> skey . cancel ( ) ; <nl> try <nl> @ @ - 495 , 26 + 507 , 25 @ @ public class MessagingService implements IMessagingService <nl> catch ( IOException e ) { } <nl> } <nl> listenSockets _ . clear ( ) ; <nl> - <nl> - / * Shutdown the threads in the EventQueue ' s * / <nl> - messageDeserializationExecutor _ . shutdownNow ( ) ; <nl> + <nl> + / * Shutdown the threads in the EventQueue ' s * / <nl> + messageDeserializationExecutor _ . shutdownNow ( ) ; <nl> messageSerializerExecutor _ . shutdownNow ( ) ; <nl> messageDeserializerExecutor _ . shutdownNow ( ) ; <nl> streamExecutor _ . shutdownNow ( ) ; <nl> - <nl> + <nl> / * shut down the cachetables * / <nl> taskCompletionMap _ . shutdown ( ) ; <nl> - callbackMap _ . shutdown ( ) ; <nl> - <nl> + callbackMap _ . shutdown ( ) ; <nl> + <nl> / * Interrupt the selector manager thread * / <nl> SelectorManager . getSelectorManager ( ) . interrupt ( ) ; <nl> - <nl> - poolTable _ . clear ( ) ; <nl> - verbHandlers _ . clear ( ) ; <nl> + <nl> + poolTable _ . clear ( ) ; <nl> + verbHandlers _ . clear ( ) ; <nl> bShutdown _ = true ; <nl> } <nl> - if ( logger _ . isDebugEnabled ( ) ) <nl> - logger _ . debug ( " Shutdown invocation complete . " ) ; <nl> + logger _ . info ( " Shutdown invocation complete . " ) ; <nl> } <nl> <nl> public static void receive ( Message message ) <nl> diff - - git a / src / java / org / apache / cassandra / net / TcpConnection . java b / src / java / org / apache / cassandra / net / TcpConnection . java <nl> index 5039833 . . 08afda8 100644 <nl> - - - a / src / java / org / apache / cassandra / net / TcpConnection . java <nl> + + + b / src / java / org / apache / cassandra / net / TcpConnection . java <nl> @ @ - 387 , 7 + 387 , 7 @ @ public class TcpConnection extends SelectionKeyHandler implements Comparable <nl> resumeStreaming ( ) ; <nl> } <nl> <nl> - void doPendingWrites ( ) <nl> + public void doPendingWrites ( ) <nl> { <nl> synchronized ( this ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / net / TcpConnectionManager . java b / src / java / org / apache / cassandra / net / TcpConnectionManager . java <nl> index e29eb9d . . b8fa909 100644 <nl> - - - a / src / java / org / apache / cassandra / net / TcpConnectionManager . java <nl> + + + b / src / java / org / apache / cassandra / net / TcpConnectionManager . java <nl> @ @ - 211 , 4 + 211 , 8 @ @ class TcpConnectionManager <nl> { <nl> return allConnections _ . contains ( connection ) ; <nl> } <nl> + List < TcpConnection > getConnections ( ) <nl> + { <nl> + return allConnections _ ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index 62cc110 . . 0e2dd24 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 778 , 6 + 778 , 24 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> logger _ . debug ( " Cleared out all snapshot directories " ) ; <nl> } <nl> <nl> + public void forceTableFlushBinary ( String tableName ) throws IOException <nl> + { <nl> + if ( DatabaseDescriptor . getTable ( tableName ) = = null ) <nl> + { <nl> + throw new IOException ( " Table " + tableName + " does not exist " ) ; <nl> + } <nl> + <nl> + Table table = Table . open ( tableName ) ; <nl> + Set < String > columnFamilies = table . getColumnFamilies ( ) ; <nl> + for ( String columnFamily : columnFamilies ) <nl> + { <nl> + ColumnFamilyStore cfStore = table . getColumnFamilyStore ( columnFamily ) ; <nl> + logger _ . debug ( " Forcing flush on keyspace " + tableName + " on CF " + columnFamily ) ; <nl> + cfStore . forceFlushBinary ( ) ; <nl> + } <nl> + } <nl> + <nl> + <nl> / * End of MBean interface methods * / <nl> <nl> / * * <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> index 2e21ecb . . 046fb26 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> @ @ - 84 , 4 + 84 , 11 @ @ public interface StorageServiceMBean <nl> * Remove all the existing snapshots . <nl> * / <nl> public void clearSnapshot ( ) throws IOException ; <nl> + <nl> + / * * <nl> + * Flush all binary memtables for a table <nl> + * @ param tableName <nl> + * @ throws IOException <nl> + * / <nl> + public void forceTableFlushBinary ( String tableName ) throws IOException ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / tools / NodeProbe . java b / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> index f0df925 . . b6d846f 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> + + + b / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> @ @ - 257 , 7 + 257 , 16 @ @ public class NodeProbe <nl> { <nl> ssProxy . forceTableCompaction ( ) ; <nl> } <nl> - <nl> + <nl> + / * * <nl> + * Trigger a binary flush on CFs of a table . <nl> + * / <nl> + public void forceTableFlushBinary ( String tableName ) throws IOException <nl> + { <nl> + ssProxy . forceTableFlushBinary ( tableName ) ; <nl> + } <nl> + <nl> + <nl> / * * <nl> * Write a textual representation of the Cassandra ring . <nl> * <nl> @ @ - 517 , 7 + 526 , 7 @ @ public class NodeProbe <nl> { <nl> HelpFormatter hf = new HelpFormatter ( ) ; <nl> String header = String . format ( <nl> - " % nAvailable commands : ring , cluster , info , cleanup , compact , cfstats , snapshot [ name ] , clearsnapshot , bootstrap , tpstats " ) ; <nl> + " % nAvailable commands : ring , cluster , info , cleanup , compact , cfstats , snapshot [ name ] , clearsnapshot , bootstrap , tpstats , flush _ binary " ) ; <nl> String usage = String . format ( " java % s - host < arg > < command > % n " , NodeProbe . class . getName ( ) ) ; <nl> hf . printHelp ( usage , " " , options , header ) ; <nl> } <nl> @ @ - 609 , 6 + 618 , 16 @ @ public class NodeProbe <nl> { <nl> probe . printThreadPoolStats ( System . out ) ; <nl> } <nl> + else if ( cmdName . equals ( " flush _ binary " ) ) <nl> + { <nl> + if ( probe . getArgs ( ) . length < 2 ) <nl> + { <nl> + System . err . println ( " Missing keyspace argument . " ) ; <nl> + NodeProbe . printUsage ( ) ; <nl> + System . exit ( 1 ) ; <nl> + } <nl> + probe . forceTableFlushBinary ( probe . getArgs ( ) [ 1 ] ) ; <nl> + } <nl> else <nl> { <nl> System . err . println ( " Unrecognized command : " + cmdName + " . " ) ;

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index bba5f20 . . 7ba8044 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 0 . 6 
 + * Correctly handle null with IF conditions and TTL ( CASSANDRA - 6623 ) 
 Merged from 1 . 2 : 
 * Fix partition and range deletes not triggering flush ( CASSANDRA - 6655 ) 
 
 diff - - git a / src / java / org / apache / cassandra / cql3 / statements / ModificationStatement . java b / src / java / org / apache / cassandra / cql3 / statements / ModificationStatement . java 
 index c0bf428 . . 2567043 100644 
 - - - a / src / java / org / apache / cassandra / cql3 / statements / ModificationStatement . java 
 + + + b / src / java / org / apache / cassandra / cql3 / statements / ModificationStatement . java 
 @ @ - 27 , 19 + 27 , 20 @ @ import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . cql3 . * ; 
 import org . apache . cassandra . db . * ; 
 import org . apache . cassandra . db . filter . ColumnSlice ; 
 + import org . apache . cassandra . db . filter . IDiskAtomFilter ; 
 import org . apache . cassandra . db . filter . SliceQueryFilter ; 
 import org . apache . cassandra . db . marshal . CompositeType ; 
 import org . apache . cassandra . db . marshal . UTF8Type ; 
 import org . apache . cassandra . db . marshal . ListType ; 
 import org . apache . cassandra . db . marshal . BooleanType ; 
 import org . apache . cassandra . exceptions . * ; 
 + import org . apache . cassandra . service . CASConditions ; 
 import org . apache . cassandra . service . ClientState ; 
 import org . apache . cassandra . service . QueryState ; 
 import org . apache . cassandra . service . StorageProxy ; 
 import org . apache . cassandra . thrift . ThriftValidation ; 
 import org . apache . cassandra . transport . messages . ResultMessage ; 
 import org . apache . cassandra . utils . Pair ; 
 - import org . apache . cassandra . utils . ByteBufferUtil ; 
 
 / * 
 * Abstract parent class of individual modifications , i . e . INSERT , UPDATE and DELETE . 
 @ @ - 415 , 16 + 416 , 17 @ @ public abstract class ModificationStatement implements CQLStatement , MeasurableF 
 UpdateParameters updParams = new UpdateParameters ( cfm , variables , queryState . getTimestamp ( ) , getTimeToLive ( variables ) , null ) ; 
 ColumnFamily updates = updateForKey ( key , clusteringPrefix , updParams ) ; 
 
 - / / When building the conditions , we should not use the TTL . It ' s not useful , and if a very low ttl ( 1 seconds ) is used , it ' s possible 
 - / / for it to expire before actually build the conditions which would break since we would then test for the presence of tombstones . 
 - UpdateParameters condParams = new UpdateParameters ( cfm , variables , queryState . getTimestamp ( ) , 0 , null ) ; 
 - ColumnFamily expected = buildConditions ( key , clusteringPrefix , condParams ) ; 
 + / / It ' s cleaner to use the query timestamp below , but it ' s in seconds while the conditions expects microseconds , so just 
 + / / put it back in millis ( we don ' t really lose precision because the ultimate consumer , Column . isLive , re - divide it ) . 
 + long now = queryState . getTimestamp ( ) * 1000 ; 
 + CASConditions conditions = ifNotExists 
 + ? new NotExistCondition ( clusteringPrefix , now ) 
 + : new ColumnsConditions ( clusteringPrefix , cfm , key , columnConditions , variables , now ) ; 
 
 ColumnFamily result = StorageProxy . cas ( keyspace ( ) , 
 columnFamily ( ) , 
 key , 
 - clusteringPrefix , 
 - expected , 
 + conditions , 
 updates , 
 options . getSerialConsistency ( ) , 
 options . getConsistency ( ) ) ; 
 @ @ - 542 , 28 + 544 , 91 @ @ public abstract class ModificationStatement implements CQLStatement , MeasurableF 
 return isCounter ( ) ? new CounterMutation ( rm , cl ) : rm ; 
 } 
 
 - private ColumnFamily buildConditions ( ByteBuffer key , ColumnNameBuilder clusteringPrefix , UpdateParameters params ) 
 - throws InvalidRequestException 
 + private static abstract class CQL3CasConditions implements CASConditions 
 { 
 - if ( ifNotExists ) 
 - return null ; 
 + protected final ColumnNameBuilder rowPrefix ; 
 + protected final long now ; 
 
 - ColumnFamily cf = TreeMapBackedSortedColumns . factory . create ( cfm ) ; 
 + protected CQL3CasConditions ( ColumnNameBuilder rowPrefix , long now ) 
 + { 
 + this . rowPrefix = rowPrefix ; 
 + this . now = now ; 
 + } 
 
 - / / CQL row marker 
 - CFDefinition cfDef = cfm . getCfDef ( ) ; 
 - if ( cfDef . isComposite & & ! cfDef . isCompact & & ! cfm . isSuper ( ) ) 
 + public IDiskAtomFilter readFilter ( ) 
 { 
 - ByteBuffer name = clusteringPrefix . copy ( ) . add ( ByteBufferUtil . EMPTY _ BYTE _ BUFFER ) . build ( ) ; 
 - cf . addColumn ( params . makeColumn ( name , ByteBufferUtil . EMPTY _ BYTE _ BUFFER ) ) ; 
 + / / We always read the row entirely as on CAS failure we want to be able to distinguish between " row exists 
 + / / but all values on why there were conditions are null " and " row doesn ' t exists " , and we can ' t rely on the 
 + / / row marker for that ( see # 6623 ) 
 + return new SliceQueryFilter ( rowPrefix . build ( ) , rowPrefix . buildAsEndOfRange ( ) , false , 1 , rowPrefix . componentCount ( ) ) ; 
 } 
 + } 
 
 - / / Conditions 
 - for ( Operation condition : columnConditions ) 
 - condition . execute ( key , cf , clusteringPrefix . copy ( ) , params ) ; 
 + private static class NotExistCondition extends CQL3CasConditions 
 + { 
 + private NotExistCondition ( ColumnNameBuilder rowPrefix , long now ) 
 + { 
 + super ( rowPrefix , now ) ; 
 + } 
 + 
 + public boolean appliesTo ( ColumnFamily current ) 
 + { 
 + return current = = null | | current . hasOnlyTombstones ( now ) ; 
 + } 
 + } 
 + 
 + private static class ColumnsConditions extends CQL3CasConditions 
 + { 
 + private final ColumnFamily expected ; 
 + 
 + private ColumnsConditions ( ColumnNameBuilder rowPrefix , 
 + CFMetaData cfm , 
 + ByteBuffer key , 
 + Collection < Operation > conditions , 
 + List < ByteBuffer > variables , 
 + long now ) throws InvalidRequestException 
 + { 
 + super ( rowPrefix , now ) ; 
 + this . expected = TreeMapBackedSortedColumns . factory . create ( cfm ) ; 
 
 - assert ! cf . isEmpty ( ) ; 
 - return cf ; 
 + / / When building the conditions , we should not use a TTL . It ' s not useful , and if a very low ttl ( 1 seconds ) is used , it ' s possible 
 + / / for it to expire before the actual build of the conditions which would break since we would then testing for the presence of tombstones . 
 + UpdateParameters params = new UpdateParameters ( cfm , variables , now , 0 , null ) ; 
 + 
 + / / Conditions 
 + for ( Operation condition : conditions ) 
 + condition . execute ( key , expected , rowPrefix . copy ( ) , params ) ; 
 + } 
 + 
 + public boolean appliesTo ( ColumnFamily current ) 
 + { 
 + if ( current = = null ) 
 + return false ; 
 + 
 + for ( Column e : expected ) 
 + { 
 + Column c = current . getColumn ( e . name ( ) ) ; 
 + if ( e . isLive ( now ) ) 
 + { 
 + if ( c = = null | | ! c . isLive ( now ) | | ! c . value ( ) . equals ( e . value ( ) ) ) 
 + return false ; 
 + } 
 + else 
 + { 
 + / / If we have a tombstone in expected , it means the condition tests that the column is 
 + / / null , so check that we have no value 
 + if ( c ! = null & & c . isLive ( now ) ) 
 + return false ; 
 + } 
 + } 
 + return true ; 
 + } 
 + 
 + @ Override 
 + public String toString ( ) 
 + { 
 + return expected . toString ( ) ; 
 + } 
 } 
 
 public static abstract class Parsed extends CFStatement 
 diff - - git a / src / java / org / apache / cassandra / service / CASConditions . java b / src / java / org / apache / cassandra / service / CASConditions . java 
 new file mode 100644 
 index 0000000 . . d4b3e19 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / service / CASConditions . java 
 @ @ - 0 , 0 + 1 , 38 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , software 
 + * distributed under the License is distributed on an " AS IS " BASIS , 
 + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + * See the License for the specific language governing permissions and 
 + * limitations under the License . 
 + * / 
 + package org . apache . cassandra . service ; 
 + 
 + import org . apache . cassandra . db . ColumnFamily ; 
 + import org . apache . cassandra . db . filter . IDiskAtomFilter ; 
 + 
 + / * * 
 + * Abstract the conditions to be fulfilled by a CAS operation . 
 + * / 
 + public interface CASConditions 
 + { 
 + / * * 
 + * The filter to use to fetch the value to compare for the CAS . 
 + * / 
 + public IDiskAtomFilter readFilter ( ) ; 
 + 
 + / * * 
 + * Returns whether the provided CF , that represents the values fetched using the 
 + * readFilter ( ) , match the CAS conditions this object stands for . 
 + * / 
 + public boolean appliesTo ( ColumnFamily current ) ; 
 + } 
 diff - - git a / src / java / org / apache / cassandra / service / StorageProxy . java b / src / java / org / apache / cassandra / service / StorageProxy . java 
 index 5671655 . . 8d1f913 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageProxy . java 
 + + + b / src / java / org / apache / cassandra / service / StorageProxy . java 
 @ @ - 41 , 11 + 41 , 8 @ @ import org . apache . cassandra . concurrent . StageManager ; 
 import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . config . Schema ; 
 - import org . apache . cassandra . cql3 . ColumnNameBuilder ; 
 import org . apache . cassandra . db . * ; 
 import org . apache . cassandra . db . Keyspace ; 
 - import org . apache . cassandra . db . filter . NamesQueryFilter ; 
 - import org . apache . cassandra . db . filter . SliceQueryFilter ; 
 import org . apache . cassandra . db . marshal . UUIDType ; 
 import org . apache . cassandra . dht . AbstractBounds ; 
 import org . apache . cassandra . dht . Bounds ; 
 @ @ - 157 , 7 + 154 , 7 @ @ public class StorageProxy implements StorageProxyMBean 
 
 / * * 
 * Apply @ param updates if and only if the current values in the row for @ param key 
 - * match the ones given by @ param expected . The algorithm is " raw " Paxos : that is , Paxos 
 + * match the provided @ param conditions . The algorithm is " raw " Paxos : that is , Paxos 
 * minus leader election - - any node in the cluster may propose changes for any row , 
 * which ( that is , the row ) is the unit of values being proposed , not single columns . 
 * 
 @ @ - 189 , 23 + 186 , 18 @ @ public class StorageProxy implements StorageProxyMBean 
 * @ param keyspaceName the keyspace for the CAS 
 * @ param cfName the column family for the CAS 
 * @ param key the row key for the row to CAS 
 - * @ param prefix a column name prefix that selects the CQL3 row to check if { @ code expected } is null . If { @ code expected } 
 - * is not null , this is ignored . If { @ code expected } is null and this is null , the full row existing is checked ( by querying 
 - * the first live column of the row ) . 
 - * @ param expected the expected column values . This can be null to check for existence ( see { @ code prefix } ) . 
 - * @ param updates the value to insert if { @ code expected matches the current values } . 
 + * @ param conditions the conditions for the CAS to apply . 
 + * @ param updates the value to insert if { @ code condtions } matches the current values . 
 * @ param consistencyForPaxos the consistency for the paxos prepare and propose round . This can only be either SERIAL or LOCAL _ SERIAL . 
 * @ param consistencyForCommit the consistency for write done during the commit phase . This can be anything , except SERIAL or LOCAL _ SERIAL . 
 * 
 - * @ return null if the operation succeeds in updating the row , or the current values for the columns contained in 
 - * expected ( since , if the CAS doesn ' t succeed , it means the current value do not match the one in expected ) . If 
 - * expected = = null and the CAS is unsuccessfull , the first live column of the CF is returned . 
 + * @ return null if the operation succeeds in updating the row , or the current values corresponding to conditions . 
 + * ( since , if the CAS doesn ' t succeed , it means the current value do not match the conditions ) . 
 * / 
 public static ColumnFamily cas ( String keyspaceName , 
 String cfName , 
 ByteBuffer key , 
 - ColumnNameBuilder prefix , 
 - ColumnFamily expected , 
 + CASConditions conditions , 
 ColumnFamily updates , 
 ConsistencyLevel consistencyForPaxos , 
 ConsistencyLevel consistencyForCommit ) 
 @ @ - 227 , 27 + 219 , 15 @ @ public class StorageProxy implements StorageProxyMBean 
 
 UUID ballot = beginAndRepairPaxos ( start , key , metadata , liveEndpoints , requiredParticipants , consistencyForPaxos ) ; 
 
 - / / read the current value and compare with expected 
 + / / read the current values and check they validate the conditions 
 Tracing . trace ( " Reading existing values for CAS precondition " ) ; 
 long timestamp = System . currentTimeMillis ( ) ; 
 - ReadCommand readCommand ; 
 - if ( expected = = null | | expected . isEmpty ( ) ) 
 - { 
 - SliceQueryFilter filter = prefix = = null 
 - ? new SliceQueryFilter ( ByteBufferUtil . EMPTY _ BYTE _ BUFFER , ByteBufferUtil . EMPTY _ BYTE _ BUFFER , false , 1 ) 
 - : new SliceQueryFilter ( prefix . build ( ) , prefix . buildAsEndOfRange ( ) , false , 1 , prefix . componentCount ( ) ) ; 
 - readCommand = new SliceFromReadCommand ( keyspaceName , key , cfName , timestamp , filter ) ; 
 - } 
 - else 
 - { 
 - assert ! expected . isEmpty ( ) ; 
 - readCommand = new SliceByNamesReadCommand ( keyspaceName , key , cfName , timestamp , new NamesQueryFilter ( ImmutableSortedSet . copyOf ( metadata . comparator , expected . getColumnNames ( ) ) ) ) ; 
 - } 
 + ReadCommand readCommand = ReadCommand . create ( keyspaceName , key , cfName , timestamp , conditions . readFilter ( ) ) ; 
 List < Row > rows = read ( Arrays . asList ( readCommand ) , consistencyForPaxos = = ConsistencyLevel . LOCAL _ SERIAL ? ConsistencyLevel . LOCAL _ QUORUM : ConsistencyLevel . QUORUM ) ; 
 ColumnFamily current = rows . get ( 0 ) . cf ; 
 - if ( ! casApplies ( expected , current ) ) 
 + if ( ! conditions . appliesTo ( current ) ) 
 { 
 - Tracing . trace ( " CAS precondition { } does not match current values { } " , expected , current ) ; 
 + Tracing . trace ( " CAS precondition { } does not match current values { } " , conditions , current ) ; 
 / / We should not return null as this means success 
 return current = = null ? EmptyColumns . factory . create ( metadata ) : current ; 
 } 
 @ @ - 274 , 41 + 254 , 6 @ @ public class StorageProxy implements StorageProxyMBean 
 throw new WriteTimeoutException ( WriteType . CAS , consistencyForPaxos , 0 , consistencyForPaxos . blockFor ( Keyspace . open ( keyspaceName ) ) ) ; 
 } 
 
 - private static boolean hasLiveColumns ( ColumnFamily cf , long now ) 
 - { 
 - return cf ! = null & & ! cf . hasOnlyTombstones ( now ) ; 
 - } 
 - 
 - private static boolean casApplies ( ColumnFamily expected , ColumnFamily current ) 
 - { 
 - long now = System . currentTimeMillis ( ) ; 
 - 
 - if ( ! hasLiveColumns ( expected , now ) ) 
 - return ! hasLiveColumns ( current , now ) ; 
 - else if ( ! hasLiveColumns ( current , now ) ) 
 - return false ; 
 - 
 - / / current has been built from expected , so we know that it can ' t have columns 
 - / / that excepted don ' t have . So we just check that for each columns in expected : 
 - / / - if it is a tombstone , whether current has no column or a tombstone ; 
 - / / - otherwise , that current has a live column with the same value . 
 - for ( Column e : expected ) 
 - { 
 - Column c = current . getColumn ( e . name ( ) ) ; 
 - if ( e . isLive ( now ) ) 
 - { 
 - if ( ! ( c ! = null & & c . isLive ( now ) & & c . value ( ) . equals ( e . value ( ) ) ) ) 
 - return false ; 
 - } 
 - else 
 - { 
 - if ( c ! = null & & c . isLive ( now ) ) 
 - return false ; 
 - } 
 - } 
 - return true ; 
 - } 
 - 
 private static Predicate < InetAddress > sameDCPredicateFor ( final String dc ) 
 { 
 final IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / thrift / CassandraServer . java b / src / java / org / apache / cassandra / thrift / CassandraServer . java 
 index beaae78 . . ef5eeb8 100644 
 - - - a / src / java / org / apache / cassandra / thrift / CassandraServer . java 
 + + + b / src / java / org / apache / cassandra / thrift / CassandraServer . java 
 @ @ - 30 , 6 + 30 , 7 @ @ import java . util . zip . Inflater ; 
 import com . google . common . base . Function ; 
 import com . google . common . base . Joiner ; 
 import com . google . common . collect . ImmutableMap ; 
 + import com . google . common . collect . ImmutableSortedSet ; 
 import com . google . common . collect . Iterables ; 
 import com . google . common . collect . Lists ; 
 import com . google . common . collect . Maps ; 
 @ @ - 59 , 6 + 60 , 7 @ @ import org . apache . cassandra . locator . DynamicEndpointSnitch ; 
 import org . apache . cassandra . metrics . ClientMetrics ; 
 import org . apache . cassandra . scheduler . IRequestScheduler ; 
 import org . apache . cassandra . serializers . MarshalException ; 
 + import org . apache . cassandra . service . CASConditions ; 
 import org . apache . cassandra . service . ClientState ; 
 import org . apache . cassandra . service . MigrationManager ; 
 import org . apache . cassandra . service . StorageProxy ; 
 @ @ - 768 , 8 + 770 , 7 @ @ public class CassandraServer implements Cassandra . Iface 
 ColumnFamily result = StorageProxy . cas ( cState . getKeyspace ( ) , 
 column _ family , 
 key , 
 - null , 
 - cfExpected , 
 + new ThriftCASConditions ( cfExpected ) , 
 cfUpdates , 
 ThriftConversion . fromThrift ( serial _ consistency _ level ) , 
 ThriftConversion . fromThrift ( commit _ consistency _ level ) ) ; 
 @ @ - 2158 , 5 + 2159 , 62 @ @ public class CassandraServer implements Cassandra . Iface 
 } 
 } ) ; 
 } 
 - / / main method moved to CassandraDaemon 
 + 
 + private static class ThriftCASConditions implements CASConditions 
 + { 
 + private final ColumnFamily expected ; 
 + 
 + private ThriftCASConditions ( ColumnFamily expected ) 
 + { 
 + this . expected = expected ; 
 + } 
 + 
 + public IDiskAtomFilter readFilter ( ) 
 + { 
 + return expected = = null | | expected . isEmpty ( ) 
 + ? new SliceQueryFilter ( ByteBufferUtil . EMPTY _ BYTE _ BUFFER , ByteBufferUtil . EMPTY _ BYTE _ BUFFER , false , 1 ) 
 + : new NamesQueryFilter ( ImmutableSortedSet . copyOf ( expected . getComparator ( ) , expected . getColumnNames ( ) ) ) ; 
 + } 
 + 
 + public boolean appliesTo ( ColumnFamily current ) 
 + { 
 + long now = System . currentTimeMillis ( ) ; 
 + 
 + if ( ! hasLiveColumns ( expected , now ) ) 
 + return ! hasLiveColumns ( current , now ) ; 
 + else if ( ! hasLiveColumns ( current , now ) ) 
 + return false ; 
 + 
 + / / current has been built from expected , so we know that it can ' t have columns 
 + / / that excepted don ' t have . So we just check that for each columns in expected : 
 + / / - if it is a tombstone , whether current has no column or a tombstone ; 
 + / / - otherwise , that current has a live column with the same value . 
 + for ( org . apache . cassandra . db . Column e : expected ) 
 + { 
 + org . apache . cassandra . db . Column c = current . getColumn ( e . name ( ) ) ; 
 + if ( e . isLive ( now ) ) 
 + { 
 + if ( c = = null | | ! c . isLive ( now ) | | ! c . value ( ) . equals ( e . value ( ) ) ) 
 + return false ; 
 + } 
 + else 
 + { 
 + if ( c ! = null & & c . isLive ( now ) ) 
 + return false ; 
 + } 
 + } 
 + return true ; 
 + } 
 + 
 + private static boolean hasLiveColumns ( ColumnFamily cf , long now ) 
 + { 
 + return cf ! = null & & ! cf . hasOnlyTombstones ( now ) ; 
 + } 
 + 
 + @ Override 
 + public String toString ( ) 
 + { 
 + return expected . toString ( ) ; 
 + } 
 + } 
 }

NEAREST DIFF:
diff - - git a / conf / storage - conf . xml b / conf / storage - conf . xml 
 index 8aaeeb6 . . 25d2901 100644 
 - - - a / conf / storage - conf . xml 
 + + + b / conf / storage - conf . xml 
 @ @ - 308 , 4 + 308 , 19 @ @ 
 ~ ten days . 
 - - > 
 < GCGraceSeconds > 864000 < / GCGraceSeconds > 
 + 
 + < ! - - 
 + ~ Number of threads to run when flushing memtables to disk . Set this to 
 + ~ the number of disks you physically have in your machine allocated for DataDirectory * 2 . 
 + ~ If you are planning to use the Binary Memtable , its recommended to increase the max threads 
 + ~ to maintain a higher quality of service while under load when normal memtables are flushing to disk . 
 + - - > 
 + < FlushMinThreads > 1 < / FlushMinThreads > 
 + < FlushMaxThreads > 1 < / FlushMaxThreads > 
 + 
 + < ! - - 
 + ~ The threshold size in megabytes the binary memtable must grow to , before it ' s submitted for flushing to disk . 
 + - - > 
 + < BinaryMemtableSizeInMB > 256 < / BinaryMemtableSizeInMB > 
 + 
 < / Storage > 
 diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 index 9016676 . . e86b134 100644 
 - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 @ @ - 74 , 6 + 74 , 9 @ @ public class DatabaseDescriptor 
 private static int slicedReadBufferSizeInKB _ = 64 ; 
 private static List < String > tables _ = new ArrayList < String > ( ) ; 
 private static Set < String > applicationColumnFamilies _ = new HashSet < String > ( ) ; 
 + private static int flushMinThreads _ = 1 ; 
 + private static int flushMaxThreads _ = 1 ; 
 + private static int bmtThreshold _ = 256 ; 
 
 / / Default descriptive names for introspection . The user can override 
 / / these choices in the config file . These are not case sensitive . 
 @ @ - 271 , 6 + 274 , 24 @ @ public class DatabaseDescriptor 
 slicedReadBufferSizeInKB _ = Integer . parseInt ( rawSlicedBuffer ) ; 
 } 
 
 + String rawflushMinThreads = xmlUtils . getNodeValue ( " / Storage / FlushMinThreads " ) ; 
 + if ( rawflushMinThreads ! = null ) 
 + { 
 + flushMinThreads _ = Integer . parseInt ( rawflushMinThreads ) ; 
 + } 
 + 
 + String rawflushMaxThreads = xmlUtils . getNodeValue ( " / Storage / FlushMaxThreads " ) ; 
 + if ( rawflushMaxThreads ! = null ) 
 + { 
 + flushMaxThreads _ = Integer . parseInt ( rawflushMaxThreads ) ; 
 + } 
 + 
 + String bmtThreshold = xmlUtils . getNodeValue ( " / Storage / BinaryMemtableSizeInMB " ) ; 
 + if ( bmtThreshold ! = null ) 
 + { 
 + bmtThreshold _ = Integer . parseInt ( bmtThreshold ) ; 
 + } 
 + 
 / * TCP port on which the storage system listens * / 
 String port = xmlUtils . getNodeValue ( " / Storage / StoragePort " ) ; 
 if ( port ! = null ) 
 @ @ - 999 , 4 + 1020 , 19 @ @ public class DatabaseDescriptor 
 { 
 return slicedReadBufferSizeInKB _ ; 
 } 
 + 
 + public static int getFlushMinThreads ( ) 
 + { 
 + return flushMinThreads _ ; 
 + } 
 + 
 + public static int getFlushMaxThreads ( ) 
 + { 
 + return flushMaxThreads _ ; 
 + } 
 + 
 + public static int getBMTThreshold ( ) 
 + { 
 + return bmtThreshold _ ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / BinaryMemtable . java b / src / java / org / apache / cassandra / db / BinaryMemtable . java 
 index 2cd439a . . 4530e8b 100644 
 - - - a / src / java / org / apache / cassandra / db / BinaryMemtable . java 
 + + + b / src / java / org / apache / cassandra / db / BinaryMemtable . java 
 @ @ - 34 , 11 + 34 , 13 @ @ import org . apache . cassandra . config . DatabaseDescriptor ; 
 
 import org . apache . log4j . Logger ; 
 import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; 
 + import java . util . * ; 
 + import org . apache . cassandra . dht . IPartitioner ; 
 
 public class BinaryMemtable 
 { 
 private static Logger logger _ = Logger . getLogger ( Memtable . class ) ; 
 - private int threshold _ = 512 * 1024 * 1024 ; 
 + private int threshold _ = DatabaseDescriptor . getBMTThreshold ( ) * 1024 * 1024 ; 
 private AtomicInteger currentSize _ = new AtomicInteger ( 0 ) ; 
 
 / * Table and ColumnFamily name are used to determine the ColumnFamilyStore * / 
 @ @ - 138 , 10 + 140 , 31 @ @ public class BinaryMemtable 
 * Use the SSTable to write the contents of the TreeMap 
 * to disk . 
 * / 
 + 
 + String path ; 
 + SSTableWriter writer ; 
 ColumnFamilyStore cfStore = Table . open ( table _ ) . getColumnFamilyStore ( cfName _ ) ; 
 List < String > keys = new ArrayList < String > ( columnFamilies _ . keySet ( ) ) ; 
 - SSTableWriter writer = new SSTableWriter ( cfStore . getTempSSTablePath ( ) , keys . size ( ) , StorageService . getPartitioner ( ) ) ; 
 - Collections . sort ( keys ) ; 
 + / * 
 + Adding a lock here so data directories are evenly used . By default currentIndex 
 + is incremented , not an AtomicInteger . Let ' s fix this ! 
 + * / 
 + lock _ . lock ( ) ; 
 + try 
 + { 
 + path = cfStore . getTempSSTablePath ( ) ; 
 + writer = new SSTableWriter ( path , keys . size ( ) , StorageService . getPartitioner ( ) ) ; 
 + } 
 + finally 
 + { 
 + lock _ . unlock ( ) ; 
 + } 
 + 
 + final IPartitioner partitioner = StorageService . getPartitioner ( ) ; 
 + final Comparator < String > dc = partitioner . getDecoratedKeyComparator ( ) ; 
 + Collections . sort ( keys , dc ) ; 
 + 
 + 
 / * Use this BloomFilter to decide if a key exists in a SSTable * / 
 for ( String key : keys ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index b08cf6b . . af6e247 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 38 , 6 + 38 , 7 @ @ import org . apache . cassandra . net . EndPoint ; 
 import org . apache . cassandra . service . StorageService ; 
 import org . apache . cassandra . utils . * ; 
 import org . apache . cassandra . concurrent . DebuggableThreadPoolExecutor ; 
 + import org . apache . cassandra . concurrent . ThreadFactoryImpl ; 
 import org . apache . cassandra . db . filter . * ; 
 import org . apache . cassandra . db . marshal . AbstractType ; 
 
 @ @ - 55 , 8 + 56 , 8 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 private static final int BUFSIZE = 128 * 1024 * 1024 ; 
 
 private static NonBlockingHashMap < String , Set < Memtable > > memtablesPendingFlush = new NonBlockingHashMap < String , Set < Memtable > > ( ) ; 
 - private static ExecutorService flusher _ = new DebuggableThreadPoolExecutor ( " MEMTABLE - FLUSHER - POOL " ) ; 
 - 
 + private static ExecutorService flusher _ = new DebuggableThreadPoolExecutor ( DatabaseDescriptor . getFlushMinThreads ( ) , DatabaseDescriptor . getFlushMaxThreads ( ) , Integer . MAX _ VALUE , TimeUnit . SECONDS , new LinkedBlockingQueue < Runnable > ( ) , new ThreadFactoryImpl ( " MEMTABLE - FLUSHER - POOL " ) ) ; 
 + 
 private final String table _ ; 
 public final String columnFamily _ ; 
 private final boolean isSuper _ ; 
 @ @ - 457 , 7 + 458 , 7 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 assert oldMemtable . isFlushed ( ) | | oldMemtable . isClean ( ) ; 
 } 
 
 - void forceFlushBinary ( ) 
 + public void forceFlushBinary ( ) 
 { 
 submitFlush ( binaryMemtable _ . get ( ) ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / Table . java b / src / java / org / apache / cassandra / db / Table . java 
 index 54389e5 . . 04b28fb 100644 
 - - - a / src / java / org / apache / cassandra / db / Table . java 
 + + + b / src / java / org / apache / cassandra / db / Table . java 
 @ @ - 642 , 11 + 642 , 11 @ @ public class Table 
 for ( ColumnFamily columnFamily : row . getColumnFamilies ( ) ) 
 { 
 Collection < IColumn > columns = columnFamily . getSortedColumns ( ) ; 
 - for ( IColumn column : columns ) 
 + for ( IColumn column : columns ) 
 { 
 - ColumnFamilyStore cfStore = columnFamilyStores _ . get ( column . name ( ) ) ; 
 + ColumnFamilyStore cfStore = columnFamilyStores _ . get ( new String ( column . name ( ) , " UTF - 8 " ) ) ; 
 cfStore . applyBinary ( key , column . value ( ) ) ; 
 - 	 } 
 + } 
 } 
 row . clear ( ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / net / MessagingService . java b / src / java / org / apache / cassandra / net / MessagingService . java 
 index 954324b . . 21f97d2 100644 
 - - - a / src / java / org / apache / cassandra / net / MessagingService . java 
 + + + b / src / java / org / apache / cassandra / net / MessagingService . java 
 @ @ - 478 , 14 + 478 , 26 @ @ public class MessagingService implements IMessagingService 
 { 
 isStreaming _ . set ( bVal ) ; 
 } 
 + public static void flushAndshutdown ( ) 
 + { 
 + / / safely shutdown and send all writes 
 + for ( Map . Entry < String , TcpConnectionManager > entry : poolTable _ . entrySet ( ) ) 
 + { 
 + for ( TcpConnection connection : entry . getValue ( ) . getConnections ( ) ) 
 + { 
 + connection . doPendingWrites ( ) ; 
 + } 
 + } 
 + shutdown ( ) ; 
 + } 
 
 public static void shutdown ( ) 
 { 
 logger _ . info ( " Shutting down . . . " ) ; 
 - synchronized ( MessagingService . class ) 
 - { 
 - / * Stop listening on any socket * / 
 - for ( SelectionKey skey : listenSockets _ . values ( ) ) 
 + synchronized ( MessagingService . class ) 
 + { 
 + / * Stop listening on any socket * / 
 + for ( SelectionKey skey : listenSockets _ . values ( ) ) 
 { 
 skey . cancel ( ) ; 
 try 
 @ @ - 495 , 26 + 507 , 25 @ @ public class MessagingService implements IMessagingService 
 catch ( IOException e ) { } 
 } 
 listenSockets _ . clear ( ) ; 
 - 
 - / * Shutdown the threads in the EventQueue ' s * / 
 - messageDeserializationExecutor _ . shutdownNow ( ) ; 
 + 
 + / * Shutdown the threads in the EventQueue ' s * / 
 + messageDeserializationExecutor _ . shutdownNow ( ) ; 
 messageSerializerExecutor _ . shutdownNow ( ) ; 
 messageDeserializerExecutor _ . shutdownNow ( ) ; 
 streamExecutor _ . shutdownNow ( ) ; 
 - 
 + 
 / * shut down the cachetables * / 
 taskCompletionMap _ . shutdown ( ) ; 
 - callbackMap _ . shutdown ( ) ; 
 - 
 + callbackMap _ . shutdown ( ) ; 
 + 
 / * Interrupt the selector manager thread * / 
 SelectorManager . getSelectorManager ( ) . interrupt ( ) ; 
 - 
 - poolTable _ . clear ( ) ; 
 - verbHandlers _ . clear ( ) ; 
 + 
 + poolTable _ . clear ( ) ; 
 + verbHandlers _ . clear ( ) ; 
 bShutdown _ = true ; 
 } 
 - if ( logger _ . isDebugEnabled ( ) ) 
 - logger _ . debug ( " Shutdown invocation complete . " ) ; 
 + logger _ . info ( " Shutdown invocation complete . " ) ; 
 } 
 
 public static void receive ( Message message ) 
 diff - - git a / src / java / org / apache / cassandra / net / TcpConnection . java b / src / java / org / apache / cassandra / net / TcpConnection . java 
 index 5039833 . . 08afda8 100644 
 - - - a / src / java / org / apache / cassandra / net / TcpConnection . java 
 + + + b / src / java / org / apache / cassandra / net / TcpConnection . java 
 @ @ - 387 , 7 + 387 , 7 @ @ public class TcpConnection extends SelectionKeyHandler implements Comparable 
 resumeStreaming ( ) ; 
 } 
 
 - void doPendingWrites ( ) 
 + public void doPendingWrites ( ) 
 { 
 synchronized ( this ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / net / TcpConnectionManager . java b / src / java / org / apache / cassandra / net / TcpConnectionManager . java 
 index e29eb9d . . b8fa909 100644 
 - - - a / src / java / org / apache / cassandra / net / TcpConnectionManager . java 
 + + + b / src / java / org / apache / cassandra / net / TcpConnectionManager . java 
 @ @ - 211 , 4 + 211 , 8 @ @ class TcpConnectionManager 
 { 
 return allConnections _ . contains ( connection ) ; 
 } 
 + List < TcpConnection > getConnections ( ) 
 + { 
 + return allConnections _ ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index 62cc110 . . 0e2dd24 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 778 , 6 + 778 , 24 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 logger _ . debug ( " Cleared out all snapshot directories " ) ; 
 } 
 
 + public void forceTableFlushBinary ( String tableName ) throws IOException 
 + { 
 + if ( DatabaseDescriptor . getTable ( tableName ) = = null ) 
 + { 
 + throw new IOException ( " Table " + tableName + " does not exist " ) ; 
 + } 
 + 
 + Table table = Table . open ( tableName ) ; 
 + Set < String > columnFamilies = table . getColumnFamilies ( ) ; 
 + for ( String columnFamily : columnFamilies ) 
 + { 
 + ColumnFamilyStore cfStore = table . getColumnFamilyStore ( columnFamily ) ; 
 + logger _ . debug ( " Forcing flush on keyspace " + tableName + " on CF " + columnFamily ) ; 
 + cfStore . forceFlushBinary ( ) ; 
 + } 
 + } 
 + 
 + 
 / * End of MBean interface methods * / 
 
 / * * 
 diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 index 2e21ecb . . 046fb26 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 @ @ - 84 , 4 + 84 , 11 @ @ public interface StorageServiceMBean 
 * Remove all the existing snapshots . 
 * / 
 public void clearSnapshot ( ) throws IOException ; 
 + 
 + / * * 
 + * Flush all binary memtables for a table 
 + * @ param tableName 
 + * @ throws IOException 
 + * / 
 + public void forceTableFlushBinary ( String tableName ) throws IOException ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / tools / NodeProbe . java b / src / java / org / apache / cassandra / tools / NodeProbe . java 
 index f0df925 . . b6d846f 100644 
 - - - a / src / java / org / apache / cassandra / tools / NodeProbe . java 
 + + + b / src / java / org / apache / cassandra / tools / NodeProbe . java 
 @ @ - 257 , 7 + 257 , 16 @ @ public class NodeProbe 
 { 
 ssProxy . forceTableCompaction ( ) ; 
 } 
 - 
 + 
 + / * * 
 + * Trigger a binary flush on CFs of a table . 
 + * / 
 + public void forceTableFlushBinary ( String tableName ) throws IOException 
 + { 
 + ssProxy . forceTableFlushBinary ( tableName ) ; 
 + } 
 + 
 + 
 / * * 
 * Write a textual representation of the Cassandra ring . 
 * 
 @ @ - 517 , 7 + 526 , 7 @ @ public class NodeProbe 
 { 
 HelpFormatter hf = new HelpFormatter ( ) ; 
 String header = String . format ( 
 - " % nAvailable commands : ring , cluster , info , cleanup , compact , cfstats , snapshot [ name ] , clearsnapshot , bootstrap , tpstats " ) ; 
 + " % nAvailable commands : ring , cluster , info , cleanup , compact , cfstats , snapshot [ name ] , clearsnapshot , bootstrap , tpstats , flush _ binary " ) ; 
 String usage = String . format ( " java % s - host < arg > < command > % n " , NodeProbe . class . getName ( ) ) ; 
 hf . printHelp ( usage , " " , options , header ) ; 
 } 
 @ @ - 609 , 6 + 618 , 16 @ @ public class NodeProbe 
 { 
 probe . printThreadPoolStats ( System . out ) ; 
 } 
 + else if ( cmdName . equals ( " flush _ binary " ) ) 
 + { 
 + if ( probe . getArgs ( ) . length < 2 ) 
 + { 
 + System . err . println ( " Missing keyspace argument . " ) ; 
 + NodeProbe . printUsage ( ) ; 
 + System . exit ( 1 ) ; 
 + } 
 + probe . forceTableFlushBinary ( probe . getArgs ( ) [ 1 ] ) ; 
 + } 
 else 
 { 
 System . err . println ( " Unrecognized command : " + cmdName + " . " ) ;
