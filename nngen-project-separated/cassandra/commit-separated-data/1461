BLEU SCORE: 0.02383853510228548

TEST MSG: Forward - compatible check for row overlap in pages
GENERATED MSG: Make scrub validate column fields

TEST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / service / pager / RangeSliceQueryPager . java b / src / java / org / apache / cassandra / service / pager / RangeSliceQueryPager . java <nl> index c9a28e8 . . e02bb46 100644 <nl> - - - a / src / java / org / apache / cassandra / service / pager / RangeSliceQueryPager . java <nl> + + + b / src / java / org / apache / cassandra / service / pager / RangeSliceQueryPager . java <nl> @ @ - 19 , 6 + 19 , 8 @ @ package org . apache . cassandra . service . pager ; <nl> <nl> import java . util . List ; <nl> <nl> + import org . apache . cassandra . config . CFMetaData ; <nl> + import org . apache . cassandra . config . Schema ; <nl> import org . apache . cassandra . db . * ; <nl> import org . apache . cassandra . db . composites . CellName ; <nl> import org . apache . cassandra . db . composites . Composite ; <nl> @ @ - 96 , 9 + 98 , 10 @ @ public class RangeSliceQueryPager extends AbstractQueryPager <nl> <nl> / / Same as SliceQueryPager , we ignore a deleted column <nl> Cell firstCell = isReversed ( ) ? lastCell ( first . cf ) : firstNonStaticCell ( first . cf ) ; <nl> + CFMetaData metadata = Schema . instance . getCFMetaData ( command . keyspace , command . columnFamily ) ; <nl> return ! first . cf . deletionInfo ( ) . isDeleted ( firstCell ) <nl> & & firstCell . isLive ( timestamp ( ) ) <nl> - & & lastReturnedName . equals ( firstCell . name ( ) ) ; <nl> + & & firstCell . name ( ) . isSameCQL3RowAs ( metadata . comparator , lastReturnedName ) ; <nl> } <nl> <nl> protected boolean recordLast ( Row last ) <nl> diff - - git a / src / java / org / apache / cassandra / service / pager / SliceQueryPager . java b / src / java / org / apache / cassandra / service / pager / SliceQueryPager . java <nl> index 18045fe . . 520fc34 100644 <nl> - - - a / src / java / org / apache / cassandra / service / pager / SliceQueryPager . java <nl> + + + b / src / java / org / apache / cassandra / service / pager / SliceQueryPager . java <nl> @ @ - 21 , 9 + 21 , 10 @ @ import java . nio . ByteBuffer ; <nl> import java . util . Collections ; <nl> import java . util . List ; <nl> <nl> + import org . apache . cassandra . config . CFMetaData ; <nl> + import org . apache . cassandra . config . Schema ; <nl> import org . apache . cassandra . db . * ; <nl> import org . apache . cassandra . db . composites . CellName ; <nl> - import org . apache . cassandra . db . composites . Composite ; <nl> import org . apache . cassandra . db . filter . SliceQueryFilter ; <nl> import org . apache . cassandra . exceptions . RequestValidationException ; <nl> import org . apache . cassandra . exceptions . RequestExecutionException ; <nl> @ @ - 42 , 7 + 43 , 7 @ @ public class SliceQueryPager extends AbstractQueryPager implements SinglePartiti <nl> private final SliceFromReadCommand command ; <nl> private final ClientState cstate ; <nl> <nl> - private volatile Composite lastReturned ; <nl> + private volatile CellName lastReturned ; <nl> <nl> / / Don ' t use directly , use QueryPagers method instead <nl> SliceQueryPager ( SliceFromReadCommand command , ConsistencyLevel consistencyLevel , ClientState cstate , boolean localQuery ) <nl> @ @ - 58 , 7 + 59 , 9 @ @ public class SliceQueryPager extends AbstractQueryPager implements SinglePartiti <nl> <nl> if ( state ! = null ) <nl> { <nl> - lastReturned = cfm . comparator . fromByteBuffer ( state . cellName ) ; <nl> + / / The only case where this could be a non - CellName Composite is if it ' s Composites . EMPTY , but that ' s not <nl> + / / valid for PagingState . cellName , so we can safely cast to CellName . <nl> + lastReturned = ( CellName ) cfm . comparator . fromByteBuffer ( state . cellName ) ; <nl> restoreState ( state . remaining , true ) ; <nl> } <nl> } <nl> @ @ - 98 , 11 + 101 , 12 @ @ public class SliceQueryPager extends AbstractQueryPager implements SinglePartiti <nl> return false ; <nl> <nl> Cell firstCell = isReversed ( ) ? lastCell ( first . cf ) : firstNonStaticCell ( first . cf ) ; <nl> + CFMetaData metadata = Schema . instance . getCFMetaData ( command . getKeyspace ( ) , command . getColumnFamilyName ( ) ) ; <nl> / / Note : we only return true if the column is the lastReturned * and * it is live . If it is deleted , it is ignored by the <nl> / / rest of the paging code ( it hasn ' t been counted as live in particular ) and we want to act as if it wasn ' t there . <nl> return ! first . cf . deletionInfo ( ) . isDeleted ( firstCell ) <nl> & & firstCell . isLive ( timestamp ( ) ) <nl> - & & lastReturned . equals ( firstCell . name ( ) ) ; <nl> + & & firstCell . name ( ) . isSameCQL3RowAs ( metadata . comparator , lastReturned ) ; <nl> } <nl> <nl> protected boolean recordLast ( Row last )
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 37a3b6b . . d19f0f9 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 30 , 6 + 30 , 7 @ @ <nl> * use 64KB flush buffer instead of in _ memory _ compaction _ limit ( CASSANDRA - 2463 ) <nl> * fix duplicate results from CFS . scan ( CASSANDRA - 2406 ) <nl> * avoid caching token - only decoratedkeys ( CASSANDRA - 2416 ) <nl> + * preserve version when streaming data from old sstables ( CASSANDRA - 2283 ) <nl> <nl> <nl> 0 . 7 . 4 <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index ae81d55 . . 16690d0 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 657 , 23 + 657 , 29 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> return columnFamily ; <nl> } <nl> <nl> + public String getFlushPath ( ) <nl> + { <nl> + return getFlushPath ( Descriptor . CURRENT _ VERSION ) ; <nl> + } <nl> + <nl> / * <nl> * @ return a temporary file name for an sstable . <nl> * When the sstable object is closed , it will be renamed to a non - temporary <nl> * format , so incomplete sstables can be recognized and removed on startup . <nl> * / <nl> - public String getFlushPath ( ) <nl> + public String getFlushPath ( String version ) <nl> { <nl> long guessedSize = 2L * memsize . value ( ) * 1024 * 1024 ; / / 2 * adds room for keys , column indexes <nl> String location = DatabaseDescriptor . getDataFileLocationForTable ( table . name , guessedSize ) ; <nl> if ( location = = null ) <nl> throw new RuntimeException ( " Insufficient disk space to flush " ) ; <nl> - return getTempSSTablePath ( location ) ; <nl> + return getTempSSTablePath ( location , version ) ; <nl> } <nl> <nl> - public String getTempSSTablePath ( String directory ) <nl> + public String getTempSSTablePath ( String directory , String version ) <nl> { <nl> - Descriptor desc = new Descriptor ( new File ( directory ) , <nl> + Descriptor desc = new Descriptor ( version , <nl> + new File ( directory ) , <nl> table . name , <nl> columnFamily , <nl> fileIndexGenerator . incrementAndGet ( ) , <nl> @ @ - 681 , 6 + 687 , 11 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> return desc . filenameFor ( Component . DATA ) ; <nl> } <nl> <nl> + public String getTempSSTablePath ( String directory ) <nl> + { <nl> + return getTempSSTablePath ( directory , Descriptor . CURRENT _ VERSION ) ; <nl> + } <nl> + <nl> / * * flush the given memtable and swap in a new one for its CFS , if it hasn ' t been frozen already . threadsafe . * / <nl> Future < ? > maybeSwitchMemtable ( Memtable oldMemtable , final boolean writeCommitLog ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamIn . java b / src / java / org / apache / cassandra / streaming / StreamIn . java <nl> index f73a8e3 . . b85da70 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamIn . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamIn . java <nl> @ @ - 49 , 11 + 49 , 6 @ @ public class StreamIn <nl> / * * <nl> * Request ranges to be transferred from source to local node <nl> * / <nl> - public static void requestRanges ( InetAddress source , String tableName , Collection < Range > ranges ) <nl> - { <nl> - requestRanges ( source , tableName , ranges , null ) ; <nl> - } <nl> - <nl> public static void requestRanges ( InetAddress source , String tableName , Collection < Range > ranges , Runnable callback ) <nl> { <nl> assert ranges . size ( ) > 0 ; <nl> @ @ - 74 , 7 + 69 , 7 @ @ public class StreamIn <nl> / / new local sstable <nl> Table table = Table . open ( remotedesc . ksname ) ; <nl> ColumnFamilyStore cfStore = table . getColumnFamilyStore ( remotedesc . cfname ) ; <nl> - Descriptor localdesc = Descriptor . fromFilename ( cfStore . getFlushPath ( ) ) ; <nl> + Descriptor localdesc = Descriptor . fromFilename ( cfStore . getFlushPath ( remote . desc . version ) ) ; <nl> <nl> return new PendingFile ( localdesc , remote ) ; <nl> } <nl> diff - - git a / test / unit / org / apache / cassandra / streaming / BootstrapTest . java b / test / unit / org / apache / cassandra / streaming / BootstrapTest . java <nl> index 87d5db6 . . 7e2d869 100644 <nl> - - - a / test / unit / org / apache / cassandra / streaming / BootstrapTest . java <nl> + + + b / test / unit / org / apache / cassandra / streaming / BootstrapTest . java <nl> @ @ - 37 , 6 + 37 , 7 @ @ public class BootstrapTest extends SchemaLoader <nl> public void testGetNewNames ( ) throws IOException <nl> { <nl> Descriptor desc = Descriptor . fromFilename ( new File ( " Keyspace1 " , " Standard1 - 500 - Data . db " ) . toString ( ) ) ; <nl> + assert ! desc . isLatestVersion ; / / deliberately test old version ; see CASSANDRA - 2283 <nl> PendingFile inContext = new PendingFile ( null , desc , " Data . db " , Arrays . asList ( new Pair < Long , Long > ( 0L , 1L ) ) ) ; <nl> <nl> PendingFile outContext = StreamIn . getContextMapping ( inContext ) ; <nl> @ @ - 45 , 7 + 46 , 8 @ @ public class BootstrapTest extends SchemaLoader <nl> <nl> / / nothing else should <nl> assertEquals ( inContext . component , outContext . component ) ; <nl> - assertEquals ( inContext . desc . ksname , outContext . desc . ksname ) ; <nl> - assertEquals ( inContext . desc . cfname , outContext . desc . cfname ) ; <nl> + assertEquals ( desc . ksname , outContext . desc . ksname ) ; <nl> + assertEquals ( desc . cfname , outContext . desc . cfname ) ; <nl> + assertEquals ( desc . version , outContext . desc . version ) ; <nl> } <nl> } <nl> diff - - git a / test / unit / org / apache / cassandra / streaming / SerializationsTest . java b / test / unit / org / apache / cassandra / streaming / SerializationsTest . java <nl> index af268dc . . 2cd913c 100644 <nl> - - - a / test / unit / org / apache / cassandra / streaming / SerializationsTest . java <nl> + + + b / test / unit / org / apache / cassandra / streaming / SerializationsTest . java <nl> @ @ - 50 , 9 + 50 , 9 @ @ public class SerializationsTest extends AbstractSerializationsTester <nl> private void testPendingFileWrite ( ) throws IOException <nl> { <nl> / / make sure to test serializing null and a pf with no sstable . <nl> - PendingFile normal = makePendingFile ( true , " fake _ component " , 100 ) ; <nl> - PendingFile noSections = makePendingFile ( true , " not _ real " , 0 ) ; <nl> - PendingFile noSST = makePendingFile ( false , " also _ fake " , 100 ) ; <nl> + PendingFile normal = makePendingFile ( true , 100 ) ; <nl> + PendingFile noSections = makePendingFile ( true , 0 ) ; <nl> + PendingFile noSST = makePendingFile ( false , 100 ) ; <nl> <nl> DataOutputStream out = getOutput ( " streaming . PendingFile . bin " ) ; <nl> PendingFile . serializer ( ) . serialize ( normal , out ) ; <nl> @ @ - 78 , 14 + 78 , 14 @ @ public class SerializationsTest extends AbstractSerializationsTester <nl> <nl> private void testStreamHeaderWrite ( ) throws IOException <nl> { <nl> - StreamHeader sh0 = new StreamHeader ( " Keyspace1 " , 123L , makePendingFile ( true , " zz " , 100 ) ) ; <nl> - StreamHeader sh1 = new StreamHeader ( " Keyspace1 " , 124L , makePendingFile ( false , " zz " , 100 ) ) ; <nl> + StreamHeader sh0 = new StreamHeader ( " Keyspace1 " , 123L , makePendingFile ( true , 100 ) ) ; <nl> + StreamHeader sh1 = new StreamHeader ( " Keyspace1 " , 124L , makePendingFile ( false , 100 ) ) ; <nl> Collection < PendingFile > files = new ArrayList < PendingFile > ( ) ; <nl> for ( int i = 0 ; i < 50 ; i + + ) <nl> - files . add ( makePendingFile ( i % 2 = = 0 , " aa " , 100 ) ) ; <nl> - StreamHeader sh2 = new StreamHeader ( " Keyspace1 " , 125L , makePendingFile ( true , " bb " , 100 ) , files ) ; <nl> + files . add ( makePendingFile ( i % 2 = = 0 , 100 ) ) ; <nl> + StreamHeader sh2 = new StreamHeader ( " Keyspace1 " , 125L , makePendingFile ( true , 100 ) , files ) ; <nl> StreamHeader sh3 = new StreamHeader ( " Keyspace1 " , 125L , null , files ) ; <nl> - StreamHeader sh4 = new StreamHeader ( " Keyspace1 " , 125L , makePendingFile ( true , " bb " , 100 ) , new ArrayList < PendingFile > ( ) ) ; <nl> + StreamHeader sh4 = new StreamHeader ( " Keyspace1 " , 125L , makePendingFile ( true , 100 ) , new ArrayList < PendingFile > ( ) ) ; <nl> <nl> DataOutputStream out = getOutput ( " streaming . StreamHeader . bin " ) ; <nl> StreamHeader . serializer ( ) . serialize ( sh0 , out ) ; <nl> @ @ - 132 , 13 + 132 , 13 @ @ public class SerializationsTest extends AbstractSerializationsTester <nl> in . close ( ) ; <nl> } <nl> <nl> - private static PendingFile makePendingFile ( boolean sst , String comp , int numSecs ) <nl> + private static PendingFile makePendingFile ( boolean sst , int numSecs ) <nl> { <nl> Descriptor desc = new Descriptor ( " z " , new File ( " path / doesn ' t / matter " ) , " Keyspace1 " , " Standard1 " , 23 , false ) ; <nl> List < Pair < Long , Long > > sections = new ArrayList < Pair < Long , Long > > ( ) ; <nl> for ( int i = 0 ; i < numSecs ; i + + ) <nl> sections . add ( new Pair < Long , Long > ( new Long ( i ) , new Long ( i * i ) ) ) ; <nl> - return new PendingFile ( sst ? makeSSTable ( ) : null , desc , comp , sections ) ; <nl> + return new PendingFile ( sst ? makeSSTable ( ) : null , desc , SSTable . COMPONENT _ DATA , sections ) ; <nl> } <nl> <nl> private void testStreamRequestMessageWrite ( ) throws IOException <nl> @ @ - 147 , 8 + 147 , 8 @ @ public class SerializationsTest extends AbstractSerializationsTester <nl> for ( int i = 0 ; i < 5 ; i + + ) <nl> ranges . add ( new Range ( new BytesToken ( ByteBufferUtil . bytes ( Integer . toString ( 10 * i ) ) ) , new BytesToken ( ByteBufferUtil . bytes ( Integer . toString ( 10 * i + 5 ) ) ) ) ) ; <nl> StreamRequestMessage msg0 = new StreamRequestMessage ( FBUtilities . getLocalAddress ( ) , ranges , " Keyspace1 " , 123L ) ; <nl> - StreamRequestMessage msg1 = new StreamRequestMessage ( FBUtilities . getLocalAddress ( ) , makePendingFile ( true , " aa " , 100 ) , 124L ) ; <nl> - StreamRequestMessage msg2 = new StreamRequestMessage ( FBUtilities . getLocalAddress ( ) , makePendingFile ( false , " aa " , 100 ) , 124L ) ; <nl> + StreamRequestMessage msg1 = new StreamRequestMessage ( FBUtilities . getLocalAddress ( ) , makePendingFile ( true , 100 ) , 124L ) ; <nl> + StreamRequestMessage msg2 = new StreamRequestMessage ( FBUtilities . getLocalAddress ( ) , makePendingFile ( false , 100 ) , 124L ) ; <nl> <nl> DataOutputStream out = getOutput ( " streaming . StreamRequestMessage . bin " ) ; <nl> StreamRequestMessage . serializer ( ) . serialize ( msg0 , out ) ;

TEST DIFF:
diff - - git a / src / java / org / apache / cassandra / service / pager / RangeSliceQueryPager . java b / src / java / org / apache / cassandra / service / pager / RangeSliceQueryPager . java 
 index c9a28e8 . . e02bb46 100644 
 - - - a / src / java / org / apache / cassandra / service / pager / RangeSliceQueryPager . java 
 + + + b / src / java / org / apache / cassandra / service / pager / RangeSliceQueryPager . java 
 @ @ - 19 , 6 + 19 , 8 @ @ package org . apache . cassandra . service . pager ; 
 
 import java . util . List ; 
 
 + import org . apache . cassandra . config . CFMetaData ; 
 + import org . apache . cassandra . config . Schema ; 
 import org . apache . cassandra . db . * ; 
 import org . apache . cassandra . db . composites . CellName ; 
 import org . apache . cassandra . db . composites . Composite ; 
 @ @ - 96 , 9 + 98 , 10 @ @ public class RangeSliceQueryPager extends AbstractQueryPager 
 
 / / Same as SliceQueryPager , we ignore a deleted column 
 Cell firstCell = isReversed ( ) ? lastCell ( first . cf ) : firstNonStaticCell ( first . cf ) ; 
 + CFMetaData metadata = Schema . instance . getCFMetaData ( command . keyspace , command . columnFamily ) ; 
 return ! first . cf . deletionInfo ( ) . isDeleted ( firstCell ) 
 & & firstCell . isLive ( timestamp ( ) ) 
 - & & lastReturnedName . equals ( firstCell . name ( ) ) ; 
 + & & firstCell . name ( ) . isSameCQL3RowAs ( metadata . comparator , lastReturnedName ) ; 
 } 
 
 protected boolean recordLast ( Row last ) 
 diff - - git a / src / java / org / apache / cassandra / service / pager / SliceQueryPager . java b / src / java / org / apache / cassandra / service / pager / SliceQueryPager . java 
 index 18045fe . . 520fc34 100644 
 - - - a / src / java / org / apache / cassandra / service / pager / SliceQueryPager . java 
 + + + b / src / java / org / apache / cassandra / service / pager / SliceQueryPager . java 
 @ @ - 21 , 9 + 21 , 10 @ @ import java . nio . ByteBuffer ; 
 import java . util . Collections ; 
 import java . util . List ; 
 
 + import org . apache . cassandra . config . CFMetaData ; 
 + import org . apache . cassandra . config . Schema ; 
 import org . apache . cassandra . db . * ; 
 import org . apache . cassandra . db . composites . CellName ; 
 - import org . apache . cassandra . db . composites . Composite ; 
 import org . apache . cassandra . db . filter . SliceQueryFilter ; 
 import org . apache . cassandra . exceptions . RequestValidationException ; 
 import org . apache . cassandra . exceptions . RequestExecutionException ; 
 @ @ - 42 , 7 + 43 , 7 @ @ public class SliceQueryPager extends AbstractQueryPager implements SinglePartiti 
 private final SliceFromReadCommand command ; 
 private final ClientState cstate ; 
 
 - private volatile Composite lastReturned ; 
 + private volatile CellName lastReturned ; 
 
 / / Don ' t use directly , use QueryPagers method instead 
 SliceQueryPager ( SliceFromReadCommand command , ConsistencyLevel consistencyLevel , ClientState cstate , boolean localQuery ) 
 @ @ - 58 , 7 + 59 , 9 @ @ public class SliceQueryPager extends AbstractQueryPager implements SinglePartiti 
 
 if ( state ! = null ) 
 { 
 - lastReturned = cfm . comparator . fromByteBuffer ( state . cellName ) ; 
 + / / The only case where this could be a non - CellName Composite is if it ' s Composites . EMPTY , but that ' s not 
 + / / valid for PagingState . cellName , so we can safely cast to CellName . 
 + lastReturned = ( CellName ) cfm . comparator . fromByteBuffer ( state . cellName ) ; 
 restoreState ( state . remaining , true ) ; 
 } 
 } 
 @ @ - 98 , 11 + 101 , 12 @ @ public class SliceQueryPager extends AbstractQueryPager implements SinglePartiti 
 return false ; 
 
 Cell firstCell = isReversed ( ) ? lastCell ( first . cf ) : firstNonStaticCell ( first . cf ) ; 
 + CFMetaData metadata = Schema . instance . getCFMetaData ( command . getKeyspace ( ) , command . getColumnFamilyName ( ) ) ; 
 / / Note : we only return true if the column is the lastReturned * and * it is live . If it is deleted , it is ignored by the 
 / / rest of the paging code ( it hasn ' t been counted as live in particular ) and we want to act as if it wasn ' t there . 
 return ! first . cf . deletionInfo ( ) . isDeleted ( firstCell ) 
 & & firstCell . isLive ( timestamp ( ) ) 
 - & & lastReturned . equals ( firstCell . name ( ) ) ; 
 + & & firstCell . name ( ) . isSameCQL3RowAs ( metadata . comparator , lastReturned ) ; 
 } 
 
 protected boolean recordLast ( Row last )

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 37a3b6b . . d19f0f9 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 30 , 6 + 30 , 7 @ @ 
 * use 64KB flush buffer instead of in _ memory _ compaction _ limit ( CASSANDRA - 2463 ) 
 * fix duplicate results from CFS . scan ( CASSANDRA - 2406 ) 
 * avoid caching token - only decoratedkeys ( CASSANDRA - 2416 ) 
 + * preserve version when streaming data from old sstables ( CASSANDRA - 2283 ) 
 
 
 0 . 7 . 4 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index ae81d55 . . 16690d0 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 657 , 23 + 657 , 29 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 return columnFamily ; 
 } 
 
 + public String getFlushPath ( ) 
 + { 
 + return getFlushPath ( Descriptor . CURRENT _ VERSION ) ; 
 + } 
 + 
 / * 
 * @ return a temporary file name for an sstable . 
 * When the sstable object is closed , it will be renamed to a non - temporary 
 * format , so incomplete sstables can be recognized and removed on startup . 
 * / 
 - public String getFlushPath ( ) 
 + public String getFlushPath ( String version ) 
 { 
 long guessedSize = 2L * memsize . value ( ) * 1024 * 1024 ; / / 2 * adds room for keys , column indexes 
 String location = DatabaseDescriptor . getDataFileLocationForTable ( table . name , guessedSize ) ; 
 if ( location = = null ) 
 throw new RuntimeException ( " Insufficient disk space to flush " ) ; 
 - return getTempSSTablePath ( location ) ; 
 + return getTempSSTablePath ( location , version ) ; 
 } 
 
 - public String getTempSSTablePath ( String directory ) 
 + public String getTempSSTablePath ( String directory , String version ) 
 { 
 - Descriptor desc = new Descriptor ( new File ( directory ) , 
 + Descriptor desc = new Descriptor ( version , 
 + new File ( directory ) , 
 table . name , 
 columnFamily , 
 fileIndexGenerator . incrementAndGet ( ) , 
 @ @ - 681 , 6 + 687 , 11 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 return desc . filenameFor ( Component . DATA ) ; 
 } 
 
 + public String getTempSSTablePath ( String directory ) 
 + { 
 + return getTempSSTablePath ( directory , Descriptor . CURRENT _ VERSION ) ; 
 + } 
 + 
 / * * flush the given memtable and swap in a new one for its CFS , if it hasn ' t been frozen already . threadsafe . * / 
 Future < ? > maybeSwitchMemtable ( Memtable oldMemtable , final boolean writeCommitLog ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamIn . java b / src / java / org / apache / cassandra / streaming / StreamIn . java 
 index f73a8e3 . . b85da70 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamIn . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamIn . java 
 @ @ - 49 , 11 + 49 , 6 @ @ public class StreamIn 
 / * * 
 * Request ranges to be transferred from source to local node 
 * / 
 - public static void requestRanges ( InetAddress source , String tableName , Collection < Range > ranges ) 
 - { 
 - requestRanges ( source , tableName , ranges , null ) ; 
 - } 
 - 
 public static void requestRanges ( InetAddress source , String tableName , Collection < Range > ranges , Runnable callback ) 
 { 
 assert ranges . size ( ) > 0 ; 
 @ @ - 74 , 7 + 69 , 7 @ @ public class StreamIn 
 / / new local sstable 
 Table table = Table . open ( remotedesc . ksname ) ; 
 ColumnFamilyStore cfStore = table . getColumnFamilyStore ( remotedesc . cfname ) ; 
 - Descriptor localdesc = Descriptor . fromFilename ( cfStore . getFlushPath ( ) ) ; 
 + Descriptor localdesc = Descriptor . fromFilename ( cfStore . getFlushPath ( remote . desc . version ) ) ; 
 
 return new PendingFile ( localdesc , remote ) ; 
 } 
 diff - - git a / test / unit / org / apache / cassandra / streaming / BootstrapTest . java b / test / unit / org / apache / cassandra / streaming / BootstrapTest . java 
 index 87d5db6 . . 7e2d869 100644 
 - - - a / test / unit / org / apache / cassandra / streaming / BootstrapTest . java 
 + + + b / test / unit / org / apache / cassandra / streaming / BootstrapTest . java 
 @ @ - 37 , 6 + 37 , 7 @ @ public class BootstrapTest extends SchemaLoader 
 public void testGetNewNames ( ) throws IOException 
 { 
 Descriptor desc = Descriptor . fromFilename ( new File ( " Keyspace1 " , " Standard1 - 500 - Data . db " ) . toString ( ) ) ; 
 + assert ! desc . isLatestVersion ; / / deliberately test old version ; see CASSANDRA - 2283 
 PendingFile inContext = new PendingFile ( null , desc , " Data . db " , Arrays . asList ( new Pair < Long , Long > ( 0L , 1L ) ) ) ; 
 
 PendingFile outContext = StreamIn . getContextMapping ( inContext ) ; 
 @ @ - 45 , 7 + 46 , 8 @ @ public class BootstrapTest extends SchemaLoader 
 
 / / nothing else should 
 assertEquals ( inContext . component , outContext . component ) ; 
 - assertEquals ( inContext . desc . ksname , outContext . desc . ksname ) ; 
 - assertEquals ( inContext . desc . cfname , outContext . desc . cfname ) ; 
 + assertEquals ( desc . ksname , outContext . desc . ksname ) ; 
 + assertEquals ( desc . cfname , outContext . desc . cfname ) ; 
 + assertEquals ( desc . version , outContext . desc . version ) ; 
 } 
 } 
 diff - - git a / test / unit / org / apache / cassandra / streaming / SerializationsTest . java b / test / unit / org / apache / cassandra / streaming / SerializationsTest . java 
 index af268dc . . 2cd913c 100644 
 - - - a / test / unit / org / apache / cassandra / streaming / SerializationsTest . java 
 + + + b / test / unit / org / apache / cassandra / streaming / SerializationsTest . java 
 @ @ - 50 , 9 + 50 , 9 @ @ public class SerializationsTest extends AbstractSerializationsTester 
 private void testPendingFileWrite ( ) throws IOException 
 { 
 / / make sure to test serializing null and a pf with no sstable . 
 - PendingFile normal = makePendingFile ( true , " fake _ component " , 100 ) ; 
 - PendingFile noSections = makePendingFile ( true , " not _ real " , 0 ) ; 
 - PendingFile noSST = makePendingFile ( false , " also _ fake " , 100 ) ; 
 + PendingFile normal = makePendingFile ( true , 100 ) ; 
 + PendingFile noSections = makePendingFile ( true , 0 ) ; 
 + PendingFile noSST = makePendingFile ( false , 100 ) ; 
 
 DataOutputStream out = getOutput ( " streaming . PendingFile . bin " ) ; 
 PendingFile . serializer ( ) . serialize ( normal , out ) ; 
 @ @ - 78 , 14 + 78 , 14 @ @ public class SerializationsTest extends AbstractSerializationsTester 
 
 private void testStreamHeaderWrite ( ) throws IOException 
 { 
 - StreamHeader sh0 = new StreamHeader ( " Keyspace1 " , 123L , makePendingFile ( true , " zz " , 100 ) ) ; 
 - StreamHeader sh1 = new StreamHeader ( " Keyspace1 " , 124L , makePendingFile ( false , " zz " , 100 ) ) ; 
 + StreamHeader sh0 = new StreamHeader ( " Keyspace1 " , 123L , makePendingFile ( true , 100 ) ) ; 
 + StreamHeader sh1 = new StreamHeader ( " Keyspace1 " , 124L , makePendingFile ( false , 100 ) ) ; 
 Collection < PendingFile > files = new ArrayList < PendingFile > ( ) ; 
 for ( int i = 0 ; i < 50 ; i + + ) 
 - files . add ( makePendingFile ( i % 2 = = 0 , " aa " , 100 ) ) ; 
 - StreamHeader sh2 = new StreamHeader ( " Keyspace1 " , 125L , makePendingFile ( true , " bb " , 100 ) , files ) ; 
 + files . add ( makePendingFile ( i % 2 = = 0 , 100 ) ) ; 
 + StreamHeader sh2 = new StreamHeader ( " Keyspace1 " , 125L , makePendingFile ( true , 100 ) , files ) ; 
 StreamHeader sh3 = new StreamHeader ( " Keyspace1 " , 125L , null , files ) ; 
 - StreamHeader sh4 = new StreamHeader ( " Keyspace1 " , 125L , makePendingFile ( true , " bb " , 100 ) , new ArrayList < PendingFile > ( ) ) ; 
 + StreamHeader sh4 = new StreamHeader ( " Keyspace1 " , 125L , makePendingFile ( true , 100 ) , new ArrayList < PendingFile > ( ) ) ; 
 
 DataOutputStream out = getOutput ( " streaming . StreamHeader . bin " ) ; 
 StreamHeader . serializer ( ) . serialize ( sh0 , out ) ; 
 @ @ - 132 , 13 + 132 , 13 @ @ public class SerializationsTest extends AbstractSerializationsTester 
 in . close ( ) ; 
 } 
 
 - private static PendingFile makePendingFile ( boolean sst , String comp , int numSecs ) 
 + private static PendingFile makePendingFile ( boolean sst , int numSecs ) 
 { 
 Descriptor desc = new Descriptor ( " z " , new File ( " path / doesn ' t / matter " ) , " Keyspace1 " , " Standard1 " , 23 , false ) ; 
 List < Pair < Long , Long > > sections = new ArrayList < Pair < Long , Long > > ( ) ; 
 for ( int i = 0 ; i < numSecs ; i + + ) 
 sections . add ( new Pair < Long , Long > ( new Long ( i ) , new Long ( i * i ) ) ) ; 
 - return new PendingFile ( sst ? makeSSTable ( ) : null , desc , comp , sections ) ; 
 + return new PendingFile ( sst ? makeSSTable ( ) : null , desc , SSTable . COMPONENT _ DATA , sections ) ; 
 } 
 
 private void testStreamRequestMessageWrite ( ) throws IOException 
 @ @ - 147 , 8 + 147 , 8 @ @ public class SerializationsTest extends AbstractSerializationsTester 
 for ( int i = 0 ; i < 5 ; i + + ) 
 ranges . add ( new Range ( new BytesToken ( ByteBufferUtil . bytes ( Integer . toString ( 10 * i ) ) ) , new BytesToken ( ByteBufferUtil . bytes ( Integer . toString ( 10 * i + 5 ) ) ) ) ) ; 
 StreamRequestMessage msg0 = new StreamRequestMessage ( FBUtilities . getLocalAddress ( ) , ranges , " Keyspace1 " , 123L ) ; 
 - StreamRequestMessage msg1 = new StreamRequestMessage ( FBUtilities . getLocalAddress ( ) , makePendingFile ( true , " aa " , 100 ) , 124L ) ; 
 - StreamRequestMessage msg2 = new StreamRequestMessage ( FBUtilities . getLocalAddress ( ) , makePendingFile ( false , " aa " , 100 ) , 124L ) ; 
 + StreamRequestMessage msg1 = new StreamRequestMessage ( FBUtilities . getLocalAddress ( ) , makePendingFile ( true , 100 ) , 124L ) ; 
 + StreamRequestMessage msg2 = new StreamRequestMessage ( FBUtilities . getLocalAddress ( ) , makePendingFile ( false , 100 ) , 124L ) ; 
 
 DataOutputStream out = getOutput ( " streaming . StreamRequestMessage . bin " ) ; 
 StreamRequestMessage . serializer ( ) . serialize ( msg0 , out ) ;
