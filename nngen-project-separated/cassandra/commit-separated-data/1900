BLEU SCORE: 0.015445276590783498

TEST MSG: Clean up ARE sendXRequests ( ) methods and ReadCommand # setDigestQuery ( )
GENERATED MSG: merge from 0 . 6

TEST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / db / ReadCommand . java b / src / java / org / apache / cassandra / db / ReadCommand . java <nl> index 299693e . . dedff6f 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ReadCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / ReadCommand . java <nl> @ @ - 89 , 9 + 89 , 10 @ @ public abstract class ReadCommand implements IReadCommand , Pageable <nl> return isDigestQuery ; <nl> } <nl> <nl> - public void setDigestQuery ( boolean isDigestQuery ) <nl> + public ReadCommand setIsDigestQuery ( boolean isDigestQuery ) <nl> { <nl> this . isDigestQuery = isDigestQuery ; <nl> + return this ; <nl> } <nl> <nl> public String getColumnFamilyName ( ) <nl> diff - - git a / src / java / org / apache / cassandra / db / RetriedSliceFromReadCommand . java b / src / java / org / apache / cassandra / db / RetriedSliceFromReadCommand . java <nl> index fe54917 . . 41f5a50 100644 <nl> - - - a / src / java / org / apache / cassandra / db / RetriedSliceFromReadCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / RetriedSliceFromReadCommand . java <nl> @ @ - 38 , 9 + 38 , 7 @ @ public class RetriedSliceFromReadCommand extends SliceFromReadCommand <nl> @ Override <nl> public ReadCommand copy ( ) <nl> { <nl> - ReadCommand readCommand = new RetriedSliceFromReadCommand ( ksName , key , cfName , timestamp , filter , originalCount ) ; <nl> - readCommand . setDigestQuery ( isDigestQuery ( ) ) ; <nl> - return readCommand ; <nl> + return new RetriedSliceFromReadCommand ( ksName , key , cfName , timestamp , filter , originalCount ) . setIsDigestQuery ( isDigestQuery ( ) ) ; <nl> } <nl> <nl> @ Override <nl> diff - - git a / src / java / org / apache / cassandra / db / SliceByNamesReadCommand . java b / src / java / org / apache / cassandra / db / SliceByNamesReadCommand . java <nl> index b1829f3 . . 22f795e 100644 <nl> - - - a / src / java / org / apache / cassandra / db / SliceByNamesReadCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / SliceByNamesReadCommand . java <nl> @ @ - 44 , 9 + 44 , 7 @ @ public class SliceByNamesReadCommand extends ReadCommand <nl> <nl> public ReadCommand copy ( ) <nl> { <nl> - ReadCommand readCommand = new SliceByNamesReadCommand ( ksName , key , cfName , timestamp , filter ) ; <nl> - readCommand . setDigestQuery ( isDigestQuery ( ) ) ; <nl> - return readCommand ; <nl> + return new SliceByNamesReadCommand ( ksName , key , cfName , timestamp , filter ) . setIsDigestQuery ( isDigestQuery ( ) ) ; <nl> } <nl> <nl> public Row getRow ( Keyspace keyspace ) <nl> @ @ - 97 , 9 + 95 , 7 @ @ class SliceByNamesReadCommandSerializer implements IVersionedSerializer < ReadComm <nl> long timestamp = in . readLong ( ) ; <nl> CFMetaData metadata = Schema . instance . getCFMetaData ( keyspaceName , cfName ) ; <nl> NamesQueryFilter filter = metadata . comparator . namesQueryFilterSerializer ( ) . deserialize ( in , version ) ; <nl> - ReadCommand command = new SliceByNamesReadCommand ( keyspaceName , key , cfName , timestamp , filter ) ; <nl> - command . setDigestQuery ( isDigest ) ; <nl> - return command ; <nl> + return new SliceByNamesReadCommand ( keyspaceName , key , cfName , timestamp , filter ) . setIsDigestQuery ( isDigest ) ; <nl> } <nl> <nl> public long serializedSize ( ReadCommand cmd , int version ) <nl> diff - - git a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java <nl> index f06b9dc . . 2259f22 100644 <nl> - - - a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java <nl> @ @ - 48 , 9 + 48 , 7 @ @ public class SliceFromReadCommand extends ReadCommand <nl> <nl> public ReadCommand copy ( ) <nl> { <nl> - ReadCommand readCommand = new SliceFromReadCommand ( ksName , key , cfName , timestamp , filter ) ; <nl> - readCommand . setDigestQuery ( isDigestQuery ( ) ) ; <nl> - return readCommand ; <nl> + return new SliceFromReadCommand ( ksName , key , cfName , timestamp , filter ) . setIsDigestQuery ( isDigestQuery ( ) ) ; <nl> } <nl> <nl> public Row getRow ( Keyspace keyspace ) <nl> @ @ - 151 , 9 + 149 , 7 @ @ class SliceFromReadCommandSerializer implements IVersionedSerializer < ReadCommand <nl> long timestamp = in . readLong ( ) ; <nl> CFMetaData metadata = Schema . instance . getCFMetaData ( keyspaceName , cfName ) ; <nl> SliceQueryFilter filter = metadata . comparator . sliceQueryFilterSerializer ( ) . deserialize ( in , version ) ; <nl> - ReadCommand command = new SliceFromReadCommand ( keyspaceName , key , cfName , timestamp , filter ) ; <nl> - command . setDigestQuery ( isDigest ) ; <nl> - return command ; <nl> + return new SliceFromReadCommand ( keyspaceName , key , cfName , timestamp , filter ) . setIsDigestQuery ( isDigest ) ; <nl> } <nl> <nl> public long serializedSize ( ReadCommand cmd , int version ) <nl> diff - - git a / src / java / org / apache / cassandra / service / AbstractReadExecutor . java b / src / java / org / apache / cassandra / service / AbstractReadExecutor . java <nl> index 2c3261f . . 0546e27 100644 <nl> - - - a / src / java / org / apache / cassandra / service / AbstractReadExecutor . java <nl> + + + b / src / java / org / apache / cassandra / service / AbstractReadExecutor . java <nl> @ @ - 77 , 43 + 77 , 38 @ @ public abstract class AbstractReadExecutor <nl> <nl> protected void makeDataRequests ( Iterable < InetAddress > endpoints ) <nl> { <nl> - boolean readLocal = false ; <nl> - for ( InetAddress endpoint : endpoints ) <nl> - { <nl> - if ( isLocalRequest ( endpoint ) ) <nl> - { <nl> - readLocal = true ; <nl> - } <nl> - else <nl> - { <nl> - logger . trace ( " reading data from { } " , endpoint ) ; <nl> - MessagingService . instance ( ) . sendRR ( command . createMessage ( ) , endpoint , handler ) ; <nl> - } <nl> - } <nl> - if ( readLocal ) <nl> - { <nl> - logger . trace ( " reading data locally " ) ; <nl> - StageManager . getStage ( Stage . READ ) . maybeExecuteImmediately ( new LocalReadRunnable ( command , handler ) ) ; <nl> - } <nl> + makeRequests ( command , endpoints ) ; <nl> } <nl> <nl> protected void makeDigestRequests ( Iterable < InetAddress > endpoints ) <nl> { <nl> - ReadCommand digestCommand = command . copy ( ) ; <nl> - digestCommand . setDigestQuery ( true ) ; <nl> - MessageOut < ? > message = digestCommand . createMessage ( ) ; <nl> + makeRequests ( command . copy ( ) . setIsDigestQuery ( true ) , endpoints ) ; <nl> + } <nl> + <nl> + private void makeRequests ( ReadCommand readCommand , Iterable < InetAddress > endpoints ) <nl> + { <nl> + MessageOut < ReadCommand > message = null ; <nl> + boolean hasLocalEndpoint = false ; <nl> + <nl> for ( InetAddress endpoint : endpoints ) <nl> { <nl> if ( isLocalRequest ( endpoint ) ) <nl> { <nl> - logger . trace ( " reading digest locally " ) ; <nl> - StageManager . getStage ( Stage . READ ) . execute ( new LocalReadRunnable ( digestCommand , handler ) ) ; <nl> - } <nl> - else <nl> - { <nl> - logger . trace ( " reading digest from { } " , endpoint ) ; <nl> - MessagingService . instance ( ) . sendRR ( message , endpoint , handler ) ; <nl> + hasLocalEndpoint = true ; <nl> + continue ; <nl> } <nl> + <nl> + logger . trace ( " reading { } from { } " , readCommand . isDigestQuery ( ) ? " digest " : " data " , endpoint ) ; <nl> + if ( message = = null ) <nl> + message = readCommand . createMessage ( ) ; <nl> + MessagingService . instance ( ) . sendRR ( message , endpoint , handler ) ; <nl> + } <nl> + <nl> + / / We delay the local ( potentially blocking ) read till the end to avoid stalling remote requests . <nl> + if ( hasLocalEndpoint ) <nl> + { <nl> + logger . trace ( " reading { } locally " , readCommand . isDigestQuery ( ) ? " digest " : " data " ) ; <nl> + StageManager . getStage ( Stage . READ ) . maybeExecuteImmediately ( new LocalReadRunnable ( command , handler ) ) ; <nl> } <nl> } <nl> <nl> @ @ - 278 , 10 + 273 , 7 @ @ public abstract class AbstractReadExecutor <nl> / / Could be waiting on the data , or on enough digests . <nl> ReadCommand retryCommand = command ; <nl> if ( resolver . getData ( ) ! = null ) <nl> - { <nl> - retryCommand = command . copy ( ) ; <nl> - retryCommand . setDigestQuery ( true ) ; <nl> - } <nl> + retryCommand = command . copy ( ) . setIsDigestQuery ( true ) ; <nl> <nl> InetAddress extraReplica = Iterables . getLast ( targetReplicas ) ; <nl> logger . trace ( " speculating read retry on { } " , extraReplica ) ;
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 8d9e2ea . . c97b17f 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 7 + 1 , 10 @ @ <nl> dev <nl> * sstable versioning ( CASSANDRA - 389 ) <nl> <nl> - 0 . 6 . 0 - dev <nl> + 0 . 6 . 0 - RC1 <nl> + * fix compaction bucketing bug ( CASSANDRA - 814 ) <nl> + <nl> + 0 . 6 . 0 - beta1 / beta2 <nl> * add batch _ mutate thrift command , deprecating batch _ insert ( CASSANDRA - 336 ) <nl> * remove get _ key _ range Thrift API , deprecated in 0 . 5 ( CASSANDRA - 710 ) <nl> * add optional login ( ) Thrift call for authentication ( CASSANDRA - 547 ) <nl> @ @ - 42 , 7 + 45 , 9 @ @ dev <nl> * allow larger numbers of keys ( > 140M ) in a sstable bloom filter <nl> ( CASSANDRA - 790 ) <nl> * include jvm argument improvements from CASSANDRA - 504 in debian package <nl> - * change streaming chunk size to 32MB ( was 64MB ) ( CASSANDRA - 795 ) <nl> + * change streaming chunk size to 32MB to accomodate Windows XP limitations <nl> + ( was 64MB ) ( CASSANDRA - 795 ) <nl> + * fix get _ range _ slice returning results in the wrong order ( CASSANDRA - 781 ) <nl> <nl> <nl> 0 . 5 . 0 final <nl> diff - - git a / build . xml b / build . xml <nl> index ea79876 . . 54ef12d 100644 <nl> - - - a / build . xml <nl> + + + b / build . xml <nl> @ @ - 314 , 6 + 314 , 7 @ @ <nl> < include name = " * * " / > <nl> < exclude name = " build / * * " / > <nl> < exclude name = " src / gen - java / * * " / > <nl> + < exclude name = " interface / avro / * * " / > <nl> < / tarfileset > <nl> < / tar > <nl> < / target > <nl> diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> index fbd5ebb . . 1b5b6b1 100644 <nl> - - - a / src / java / org / apache / cassandra / db / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / CompactionManager . java <nl> @ @ - 89 , 7 + 89 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> return 0 ; <nl> } <nl> logger . debug ( " Checking to see if compaction of " + cfs . columnFamily _ + " would be useful " ) ; <nl> - Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> + Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> updateEstimateFor ( cfs , buckets ) ; <nl> <nl> for ( List < SSTableReader > sstables : buckets ) <nl> @ @ - 441 , 7 + 441 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> / * <nl> * Group files of similar size into buckets . <nl> * / <nl> - static Set < List < SSTableReader > > getCompactionBuckets ( Iterable < SSTableReader > files , long min ) <nl> + static Set < List < SSTableReader > > getBuckets ( Iterable < SSTableReader > files , long min ) <nl> { <nl> Map < List < SSTableReader > , Long > buckets = new HashMap < List < SSTableReader > , Long > ( ) ; <nl> for ( SSTableReader sstable : files ) <nl> @ @ - 461 , 7 + 461 , 8 @ @ public class CompactionManager implements CompactionManagerMBean <nl> { <nl> / / remove and re - add because adding changes the hash <nl> buckets . remove ( bucket ) ; <nl> - averageSize = ( averageSize + size ) / 2 ; <nl> + long totalSize = bucket . size ( ) * averageSize ; <nl> + averageSize = ( totalSize + size ) / ( bucket . size ( ) + 1 ) ; <nl> bucket . add ( sstable ) ; <nl> buckets . put ( bucket , averageSize ) ; <nl> bFound = true ; <nl> @ @ - 538 , 7 + 539 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> public void run ( ) <nl> { <nl> logger . debug ( " Estimating compactions for " + cfs . columnFamily _ ) ; <nl> - final Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> + final Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; <nl> updateEstimateFor ( cfs , buckets ) ; <nl> } <nl> } ;

TEST DIFF:
diff - - git a / src / java / org / apache / cassandra / db / ReadCommand . java b / src / java / org / apache / cassandra / db / ReadCommand . java 
 index 299693e . . dedff6f 100644 
 - - - a / src / java / org / apache / cassandra / db / ReadCommand . java 
 + + + b / src / java / org / apache / cassandra / db / ReadCommand . java 
 @ @ - 89 , 9 + 89 , 10 @ @ public abstract class ReadCommand implements IReadCommand , Pageable 
 return isDigestQuery ; 
 } 
 
 - public void setDigestQuery ( boolean isDigestQuery ) 
 + public ReadCommand setIsDigestQuery ( boolean isDigestQuery ) 
 { 
 this . isDigestQuery = isDigestQuery ; 
 + return this ; 
 } 
 
 public String getColumnFamilyName ( ) 
 diff - - git a / src / java / org / apache / cassandra / db / RetriedSliceFromReadCommand . java b / src / java / org / apache / cassandra / db / RetriedSliceFromReadCommand . java 
 index fe54917 . . 41f5a50 100644 
 - - - a / src / java / org / apache / cassandra / db / RetriedSliceFromReadCommand . java 
 + + + b / src / java / org / apache / cassandra / db / RetriedSliceFromReadCommand . java 
 @ @ - 38 , 9 + 38 , 7 @ @ public class RetriedSliceFromReadCommand extends SliceFromReadCommand 
 @ Override 
 public ReadCommand copy ( ) 
 { 
 - ReadCommand readCommand = new RetriedSliceFromReadCommand ( ksName , key , cfName , timestamp , filter , originalCount ) ; 
 - readCommand . setDigestQuery ( isDigestQuery ( ) ) ; 
 - return readCommand ; 
 + return new RetriedSliceFromReadCommand ( ksName , key , cfName , timestamp , filter , originalCount ) . setIsDigestQuery ( isDigestQuery ( ) ) ; 
 } 
 
 @ Override 
 diff - - git a / src / java / org / apache / cassandra / db / SliceByNamesReadCommand . java b / src / java / org / apache / cassandra / db / SliceByNamesReadCommand . java 
 index b1829f3 . . 22f795e 100644 
 - - - a / src / java / org / apache / cassandra / db / SliceByNamesReadCommand . java 
 + + + b / src / java / org / apache / cassandra / db / SliceByNamesReadCommand . java 
 @ @ - 44 , 9 + 44 , 7 @ @ public class SliceByNamesReadCommand extends ReadCommand 
 
 public ReadCommand copy ( ) 
 { 
 - ReadCommand readCommand = new SliceByNamesReadCommand ( ksName , key , cfName , timestamp , filter ) ; 
 - readCommand . setDigestQuery ( isDigestQuery ( ) ) ; 
 - return readCommand ; 
 + return new SliceByNamesReadCommand ( ksName , key , cfName , timestamp , filter ) . setIsDigestQuery ( isDigestQuery ( ) ) ; 
 } 
 
 public Row getRow ( Keyspace keyspace ) 
 @ @ - 97 , 9 + 95 , 7 @ @ class SliceByNamesReadCommandSerializer implements IVersionedSerializer < ReadComm 
 long timestamp = in . readLong ( ) ; 
 CFMetaData metadata = Schema . instance . getCFMetaData ( keyspaceName , cfName ) ; 
 NamesQueryFilter filter = metadata . comparator . namesQueryFilterSerializer ( ) . deserialize ( in , version ) ; 
 - ReadCommand command = new SliceByNamesReadCommand ( keyspaceName , key , cfName , timestamp , filter ) ; 
 - command . setDigestQuery ( isDigest ) ; 
 - return command ; 
 + return new SliceByNamesReadCommand ( keyspaceName , key , cfName , timestamp , filter ) . setIsDigestQuery ( isDigest ) ; 
 } 
 
 public long serializedSize ( ReadCommand cmd , int version ) 
 diff - - git a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java 
 index f06b9dc . . 2259f22 100644 
 - - - a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java 
 + + + b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java 
 @ @ - 48 , 9 + 48 , 7 @ @ public class SliceFromReadCommand extends ReadCommand 
 
 public ReadCommand copy ( ) 
 { 
 - ReadCommand readCommand = new SliceFromReadCommand ( ksName , key , cfName , timestamp , filter ) ; 
 - readCommand . setDigestQuery ( isDigestQuery ( ) ) ; 
 - return readCommand ; 
 + return new SliceFromReadCommand ( ksName , key , cfName , timestamp , filter ) . setIsDigestQuery ( isDigestQuery ( ) ) ; 
 } 
 
 public Row getRow ( Keyspace keyspace ) 
 @ @ - 151 , 9 + 149 , 7 @ @ class SliceFromReadCommandSerializer implements IVersionedSerializer < ReadCommand 
 long timestamp = in . readLong ( ) ; 
 CFMetaData metadata = Schema . instance . getCFMetaData ( keyspaceName , cfName ) ; 
 SliceQueryFilter filter = metadata . comparator . sliceQueryFilterSerializer ( ) . deserialize ( in , version ) ; 
 - ReadCommand command = new SliceFromReadCommand ( keyspaceName , key , cfName , timestamp , filter ) ; 
 - command . setDigestQuery ( isDigest ) ; 
 - return command ; 
 + return new SliceFromReadCommand ( keyspaceName , key , cfName , timestamp , filter ) . setIsDigestQuery ( isDigest ) ; 
 } 
 
 public long serializedSize ( ReadCommand cmd , int version ) 
 diff - - git a / src / java / org / apache / cassandra / service / AbstractReadExecutor . java b / src / java / org / apache / cassandra / service / AbstractReadExecutor . java 
 index 2c3261f . . 0546e27 100644 
 - - - a / src / java / org / apache / cassandra / service / AbstractReadExecutor . java 
 + + + b / src / java / org / apache / cassandra / service / AbstractReadExecutor . java 
 @ @ - 77 , 43 + 77 , 38 @ @ public abstract class AbstractReadExecutor 
 
 protected void makeDataRequests ( Iterable < InetAddress > endpoints ) 
 { 
 - boolean readLocal = false ; 
 - for ( InetAddress endpoint : endpoints ) 
 - { 
 - if ( isLocalRequest ( endpoint ) ) 
 - { 
 - readLocal = true ; 
 - } 
 - else 
 - { 
 - logger . trace ( " reading data from { } " , endpoint ) ; 
 - MessagingService . instance ( ) . sendRR ( command . createMessage ( ) , endpoint , handler ) ; 
 - } 
 - } 
 - if ( readLocal ) 
 - { 
 - logger . trace ( " reading data locally " ) ; 
 - StageManager . getStage ( Stage . READ ) . maybeExecuteImmediately ( new LocalReadRunnable ( command , handler ) ) ; 
 - } 
 + makeRequests ( command , endpoints ) ; 
 } 
 
 protected void makeDigestRequests ( Iterable < InetAddress > endpoints ) 
 { 
 - ReadCommand digestCommand = command . copy ( ) ; 
 - digestCommand . setDigestQuery ( true ) ; 
 - MessageOut < ? > message = digestCommand . createMessage ( ) ; 
 + makeRequests ( command . copy ( ) . setIsDigestQuery ( true ) , endpoints ) ; 
 + } 
 + 
 + private void makeRequests ( ReadCommand readCommand , Iterable < InetAddress > endpoints ) 
 + { 
 + MessageOut < ReadCommand > message = null ; 
 + boolean hasLocalEndpoint = false ; 
 + 
 for ( InetAddress endpoint : endpoints ) 
 { 
 if ( isLocalRequest ( endpoint ) ) 
 { 
 - logger . trace ( " reading digest locally " ) ; 
 - StageManager . getStage ( Stage . READ ) . execute ( new LocalReadRunnable ( digestCommand , handler ) ) ; 
 - } 
 - else 
 - { 
 - logger . trace ( " reading digest from { } " , endpoint ) ; 
 - MessagingService . instance ( ) . sendRR ( message , endpoint , handler ) ; 
 + hasLocalEndpoint = true ; 
 + continue ; 
 } 
 + 
 + logger . trace ( " reading { } from { } " , readCommand . isDigestQuery ( ) ? " digest " : " data " , endpoint ) ; 
 + if ( message = = null ) 
 + message = readCommand . createMessage ( ) ; 
 + MessagingService . instance ( ) . sendRR ( message , endpoint , handler ) ; 
 + } 
 + 
 + / / We delay the local ( potentially blocking ) read till the end to avoid stalling remote requests . 
 + if ( hasLocalEndpoint ) 
 + { 
 + logger . trace ( " reading { } locally " , readCommand . isDigestQuery ( ) ? " digest " : " data " ) ; 
 + StageManager . getStage ( Stage . READ ) . maybeExecuteImmediately ( new LocalReadRunnable ( command , handler ) ) ; 
 } 
 } 
 
 @ @ - 278 , 10 + 273 , 7 @ @ public abstract class AbstractReadExecutor 
 / / Could be waiting on the data , or on enough digests . 
 ReadCommand retryCommand = command ; 
 if ( resolver . getData ( ) ! = null ) 
 - { 
 - retryCommand = command . copy ( ) ; 
 - retryCommand . setDigestQuery ( true ) ; 
 - } 
 + retryCommand = command . copy ( ) . setIsDigestQuery ( true ) ; 
 
 InetAddress extraReplica = Iterables . getLast ( targetReplicas ) ; 
 logger . trace ( " speculating read retry on { } " , extraReplica ) ;

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 8d9e2ea . . c97b17f 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 7 + 1 , 10 @ @ 
 dev 
 * sstable versioning ( CASSANDRA - 389 ) 
 
 - 0 . 6 . 0 - dev 
 + 0 . 6 . 0 - RC1 
 + * fix compaction bucketing bug ( CASSANDRA - 814 ) 
 + 
 + 0 . 6 . 0 - beta1 / beta2 
 * add batch _ mutate thrift command , deprecating batch _ insert ( CASSANDRA - 336 ) 
 * remove get _ key _ range Thrift API , deprecated in 0 . 5 ( CASSANDRA - 710 ) 
 * add optional login ( ) Thrift call for authentication ( CASSANDRA - 547 ) 
 @ @ - 42 , 7 + 45 , 9 @ @ dev 
 * allow larger numbers of keys ( > 140M ) in a sstable bloom filter 
 ( CASSANDRA - 790 ) 
 * include jvm argument improvements from CASSANDRA - 504 in debian package 
 - * change streaming chunk size to 32MB ( was 64MB ) ( CASSANDRA - 795 ) 
 + * change streaming chunk size to 32MB to accomodate Windows XP limitations 
 + ( was 64MB ) ( CASSANDRA - 795 ) 
 + * fix get _ range _ slice returning results in the wrong order ( CASSANDRA - 781 ) 
 
 
 0 . 5 . 0 final 
 diff - - git a / build . xml b / build . xml 
 index ea79876 . . 54ef12d 100644 
 - - - a / build . xml 
 + + + b / build . xml 
 @ @ - 314 , 6 + 314 , 7 @ @ 
 < include name = " * * " / > 
 < exclude name = " build / * * " / > 
 < exclude name = " src / gen - java / * * " / > 
 + < exclude name = " interface / avro / * * " / > 
 < / tarfileset > 
 < / tar > 
 < / target > 
 diff - - git a / src / java / org / apache / cassandra / db / CompactionManager . java b / src / java / org / apache / cassandra / db / CompactionManager . java 
 index fbd5ebb . . 1b5b6b1 100644 
 - - - a / src / java / org / apache / cassandra / db / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / CompactionManager . java 
 @ @ - 89 , 7 + 89 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 return 0 ; 
 } 
 logger . debug ( " Checking to see if compaction of " + cfs . columnFamily _ + " would be useful " ) ; 
 - Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 + Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 updateEstimateFor ( cfs , buckets ) ; 
 
 for ( List < SSTableReader > sstables : buckets ) 
 @ @ - 441 , 7 + 441 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 / * 
 * Group files of similar size into buckets . 
 * / 
 - static Set < List < SSTableReader > > getCompactionBuckets ( Iterable < SSTableReader > files , long min ) 
 + static Set < List < SSTableReader > > getBuckets ( Iterable < SSTableReader > files , long min ) 
 { 
 Map < List < SSTableReader > , Long > buckets = new HashMap < List < SSTableReader > , Long > ( ) ; 
 for ( SSTableReader sstable : files ) 
 @ @ - 461 , 7 + 461 , 8 @ @ public class CompactionManager implements CompactionManagerMBean 
 { 
 / / remove and re - add because adding changes the hash 
 buckets . remove ( bucket ) ; 
 - averageSize = ( averageSize + size ) / 2 ; 
 + long totalSize = bucket . size ( ) * averageSize ; 
 + averageSize = ( totalSize + size ) / ( bucket . size ( ) + 1 ) ; 
 bucket . add ( sstable ) ; 
 buckets . put ( bucket , averageSize ) ; 
 bFound = true ; 
 @ @ - 538 , 7 + 539 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 public void run ( ) 
 { 
 logger . debug ( " Estimating compactions for " + cfs . columnFamily _ ) ; 
 - final Set < List < SSTableReader > > buckets = getCompactionBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 + final Set < List < SSTableReader > > buckets = getBuckets ( cfs . getSSTables ( ) , 50L * 1024L * 1024L ) ; 
 updateEstimateFor ( cfs , buckets ) ; 
 } 
 } ;
