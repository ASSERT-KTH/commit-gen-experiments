BLEU SCORE: 0.12872632311973017

TEST MSG: cqlsh : Fix potential COPY deadlock
GENERATED MSG: cqlsh : Improve backoff policy for COPY FROM

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 76d3673 . . 4a91a58 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 6 @ @ <nl> 2 . 1 . 14 <nl> + * ( cqlsh ) Fix potential COPY deadlock when parent process is terminating child <nl> + processes ( CASSANDRA - 11505 ) <nl> * Replace sstables on DataTracker before marking them as non - compacting during anti - compaction ( CASSANDRA - 11548 ) <nl> * Checking if an unlogged batch is local is inefficient ( CASSANDRA - 11529 ) <nl> * Fix paging for COMPACT tables without clustering columns ( CASSANDRA - 11467 ) <nl> diff - - git a / pylib / cqlshlib / copyutil . py b / pylib / cqlshlib / copyutil . py <nl> index 28e08b1 . . 12239d8 100644 <nl> - - - a / pylib / cqlshlib / copyutil . py <nl> + + + b / pylib / cqlshlib / copyutil . py <nl> @ @ - 28 , 8 + 28 , 8 @ @ import random <nl> import re <nl> import struct <nl> import sys <nl> - import time <nl> import threading <nl> + import time <nl> import traceback <nl> <nl> from bisect import bisect _ right <nl> @ @ - 57 , 6 + 57 , 7 @ @ from sslhandling import ssl _ settings <nl> <nl> PROFILE _ ON = False <nl> STRACE _ ON = False <nl> + DEBUG = False # This may be set to True when initializing the task <nl> IS _ LINUX = platform . system ( ) = = ' Linux ' <nl> <nl> CopyOptions = namedtuple ( ' CopyOptions ' , ' copy dialect unrecognized ' ) <nl> @ @ - 70 , 6 + 71 , 16 @ @ def safe _ normpath ( fname ) : <nl> return os . path . normpath ( os . path . expanduser ( fname ) ) if fname else fname <nl> <nl> <nl> + def printdebugmsg ( msg ) : <nl> + if DEBUG : <nl> + printmsg ( msg ) <nl> + <nl> + <nl> + def printmsg ( msg , eol = ' \ n ' ) : <nl> + sys . stdout . write ( msg + eol ) <nl> + sys . stdout . flush ( ) <nl> + <nl> + <nl> class OneWayChannel ( object ) : <nl> " " " <nl> A one way pipe protected by two process level locks , one for reading and one for writing . <nl> @ @ - 78 , 11 + 89 , 49 @ @ class OneWayChannel ( object ) : <nl> self . reader , self . writer = mp . Pipe ( duplex = False ) <nl> self . rlock = mp . Lock ( ) <nl> self . wlock = mp . Lock ( ) <nl> + self . feeding _ thread = None <nl> + self . pending _ messages = None <nl> + <nl> + def init _ feeding _ thread ( self ) : <nl> + " " " <nl> + Initialize a thread that fetches messages from a queue and sends them to the channel . <nl> + We initialize the feeding thread lazily to avoid the fork ( ) , since the channels are passed to child processes . <nl> + " " " <nl> + if self . feeding _ thread is not None or self . pending _ messages is not None : <nl> + raise RuntimeError ( " Feeding thread already initialized " ) <nl> + <nl> + self . pending _ messages = Queue ( ) <nl> + <nl> + def feed ( ) : <nl> + send = self . _ send <nl> + pending _ messages = self . pending _ messages <nl> + <nl> + while True : <nl> + try : <nl> + msg = pending _ messages . get ( ) <nl> + send ( msg ) <nl> + except Exception , e : <nl> + printmsg ( ' % s : % s ' % ( e . _ _ class _ _ . _ _ name _ _ , e . message ) ) <nl> + <nl> + feeding _ thread = threading . Thread ( target = feed ) <nl> + feeding _ thread . setDaemon ( True ) <nl> + feeding _ thread . start ( ) <nl> + <nl> + self . feeding _ thread = feeding _ thread <nl> <nl> def send ( self , obj ) : <nl> + if self . feeding _ thread is None : <nl> + self . init _ feeding _ thread ( ) <nl> + <nl> + self . pending _ messages . put ( obj ) <nl> + <nl> + def _ send ( self , obj ) : <nl> with self . wlock : <nl> self . writer . send ( obj ) <nl> <nl> + def num _ pending ( self ) : <nl> + return self . pending _ messages . qsize ( ) if self . pending _ messages else 0 <nl> + <nl> def recv ( self ) : <nl> with self . rlock : <nl> return self . reader . recv ( ) <nl> @ @ - 157 , 8 + 206 , 15 @ @ class CopyTask ( object ) : <nl> self . fname = safe _ normpath ( fname ) <nl> self . protocol _ version = protocol _ version <nl> self . config _ file = config _ file <nl> - # do not display messages when exporting to STDOUT <nl> - self . printmsg = self . _ printmsg if self . fname is not None or direction = = ' from ' else lambda _ , eol = ' \ n ' : None <nl> + <nl> + # if cqlsh is invoked with - - debug then set the global debug flag to True <nl> + if shell . debug : <nl> + global DEBUG <nl> + DEBUG = True <nl> + <nl> + # do not display messages when exporting to STDOUT unless - - debug is set <nl> + self . printmsg = printmsg if self . fname is not None or direction = = ' from ' or DEBUG \ <nl> + else lambda _ , eol = ' \ n ' : None <nl> self . options = self . parse _ options ( opts , direction ) <nl> <nl> self . num _ processes = self . options . copy [ ' numprocesses ' ] <nl> @ @ - 174 , 11 + 230 , 6 @ @ class CopyTask ( object ) : <nl> self . columns = CopyTask . get _ columns ( shell , ks , table , columns ) <nl> self . time _ start = time . time ( ) <nl> <nl> - @ staticmethod <nl> - def _ printmsg ( msg , eol = ' \ n ' ) : <nl> - sys . stdout . write ( msg + eol ) <nl> - sys . stdout . flush ( ) <nl> - <nl> def maybe _ read _ config _ file ( self , opts , direction ) : <nl> " " " <nl> Read optional sections from a configuration file that was specified in the command options or from the default <nl> @ @ - 758 , 7 + 809 , 7 @ @ class FilesReader ( object ) : <nl> try : <nl> return open ( fname , ' rb ' ) <nl> except IOError , e : <nl> - self . printmsg ( " Can ' t open % r for reading : % s " % ( fname , e ) ) <nl> + printdebugmsg ( " Can ' t open % r for reading : % s " % ( fname , e ) ) <nl> return None <nl> <nl> for path in paths . split ( ' , ' ) : <nl> @ @ - 769 , 11 + 820 , 6 @ @ class FilesReader ( object ) : <nl> for f in glob . glob ( path ) : <nl> yield ( make _ source ( f ) ) <nl> <nl> - @ staticmethod <nl> - def printmsg ( msg , eol = ' \ n ' ) : <nl> - sys . stdout . write ( msg + eol ) <nl> - sys . stdout . flush ( ) <nl> - <nl> def start ( self ) : <nl> self . sources = self . get _ source ( self . fname ) <nl> self . next _ source ( ) <nl> @ @ - 921 , 7 + 967 , 6 @ @ class ImportErrorHandler ( object ) : <nl> def _ _ init _ _ ( self , task ) : <nl> self . shell = task . shell <nl> self . options = task . options <nl> - self . printmsg = task . printmsg <nl> self . max _ attempts = self . options . copy [ ' maxattempts ' ] <nl> self . max _ parse _ errors = self . options . copy [ ' maxparseerrors ' ] <nl> self . max _ insert _ errors = self . options . copy [ ' maxinserterrors ' ] <nl> @ @ - 933 , 7 + 978 , 7 @ @ class ImportErrorHandler ( object ) : <nl> if os . path . isfile ( self . err _ file ) : <nl> now = datetime . datetime . now ( ) <nl> old _ err _ file = self . err _ file + now . strftime ( ' . % Y % m % d _ % H % M % S ' ) <nl> - self . printmsg ( " Renaming existing % s to % s \ n " % ( self . err _ file , old _ err _ file ) ) <nl> + printdebugmsg ( " Renaming existing % s to % s \ n " % ( self . err _ file , old _ err _ file ) ) <nl> os . rename ( self . err _ file , old _ err _ file ) <nl> <nl> def max _ exceeded ( self ) : <nl> @ @ - 1088 , 17 + 1133 , 18 @ @ class ImportTask ( CopyTask ) : <nl> self . shell . printerr ( " { } child process ( es ) died unexpectedly , aborting " <nl> . format ( self . num _ processes - self . num _ live _ processes ( ) ) ) <nl> else : <nl> - # it is only safe to write to processes if they are all running because the feeder process <nl> - # at the moment hangs whilst sending messages to a crashed worker process ; in future <nl> - # we could do something about this by using a BoundedSemaphore to keep track of how many messages are <nl> - # queued on a pipe <nl> + if self . error _ handler . max _ exceeded ( ) : <nl> + self . processes [ - 1 ] . terminate ( ) # kill the feeder <nl> + <nl> for i , _ in enumerate ( self . processes ) : <nl> - self . outmsg . channels [ i ] . send ( None ) <nl> + if self . processes [ i ] . is _ alive ( ) : <nl> + self . outmsg . channels [ i ] . send ( None ) <nl> <nl> - if PROFILE _ ON : <nl> - # allow time for worker processes to write profile results ( only works if processes received <nl> - # the poison pill above ) <nl> - time . sleep ( 5 ) <nl> + # allow time for worker processes to exit cleanly <nl> + attempts = 50 # 100 milliseconds per attempt , so 5 seconds total <nl> + while attempts > 0 and self . num _ live _ processes ( ) > 0 : <nl> + time . sleep ( 0 . 1 ) <nl> + attempts - = 1 <nl> <nl> self . printmsg ( " \ n % d rows imported from % d files in % s ( % d skipped ) . " % <nl> ( self . receive _ meter . get _ total _ records ( ) , <nl> @ @ - 1239 , 12 + 1285 , 8 @ @ class ChildProcess ( mp . Process ) : <nl> else : <nl> self . test _ failures = None <nl> <nl> - def printdebugmsg ( self , text ) : <nl> - if self . debug : <nl> - sys . stdout . write ( text + ' \ n ' ) <nl> - <nl> def close ( self ) : <nl> - self . printdebugmsg ( " Closing queues . . . " ) <nl> + printdebugmsg ( " Closing queues . . . " ) <nl> self . inmsg . close ( ) <nl> self . outmsg . close ( ) <nl> <nl> @ @ - 1256 , 7 + 1298 , 6 @ @ class ExpBackoffRetryPolicy ( RetryPolicy ) : <nl> def _ _ init _ _ ( self , parent _ process ) : <nl> RetryPolicy . _ _ init _ _ ( self ) <nl> self . max _ attempts = parent _ process . max _ attempts <nl> - self . printdebugmsg = parent _ process . printdebugmsg <nl> <nl> def on _ read _ timeout ( self , query , consistency , required _ responses , <nl> received _ responses , data _ retrieved , retry _ num ) : <nl> @ @ - 1269 , 14 + 1310 , 14 @ @ class ExpBackoffRetryPolicy ( RetryPolicy ) : <nl> def _ handle _ timeout ( self , consistency , retry _ num ) : <nl> delay = self . backoff ( retry _ num ) <nl> if delay > 0 : <nl> - self . printdebugmsg ( " Timeout received , retrying after % d seconds " % ( delay , ) ) <nl> + printdebugmsg ( " Timeout received , retrying after % d seconds " % ( delay , ) ) <nl> time . sleep ( delay ) <nl> return self . RETRY , consistency <nl> elif delay = = 0 : <nl> - self . printdebugmsg ( " Timeout received , retrying immediately " ) <nl> + printdebugmsg ( " Timeout received , retrying immediately " ) <nl> return self . RETRY , consistency <nl> else : <nl> - self . printdebugmsg ( " Timeout received , giving up after % d attempts " % ( retry _ num + 1 ) ) <nl> + printdebugmsg ( " Timeout received , giving up after % d attempts " % ( retry _ num + 1 ) ) <nl> return self . RETHROW , None <nl> <nl> def backoff ( self , retry _ num ) : <nl> @ @ - 1309 , 8 + 1350 , 8 @ @ class ExportSession ( object ) : <nl> session . default _ fetch _ size = export _ process . options . copy [ ' pagesize ' ] <nl> session . default _ timeout = export _ process . options . copy [ ' pagetimeout ' ] <nl> <nl> - export _ process . printdebugmsg ( " Created connection to % s with page size % d and timeout % d seconds per page " <nl> - % ( cluster . contact _ points , session . default _ fetch _ size , session . default _ timeout ) ) <nl> + printdebugmsg ( " Created connection to % s with page size % d and timeout % d seconds per page " <nl> + % ( cluster . contact _ points , session . default _ fetch _ size , session . default _ timeout ) ) <nl> <nl> self . cluster = cluster <nl> self . session = session <nl> @ @ - 1353 , 7 + 1394 , 6 @ @ class ExportProcess ( ChildProcess ) : <nl> self . hosts _ to _ sessions = dict ( ) <nl> self . formatters = dict ( ) <nl> self . options = options <nl> - self . responses = None <nl> <nl> def run ( self ) : <nl> try : <nl> @ @ - 1371 , 8 + 1411 , 6 @ @ class ExportProcess ( ChildProcess ) : <nl> we can signal a global error by sending ( None , error ) . <nl> We terminate when the inbound queue is closed . <nl> " " " <nl> - self . init _ feeder _ thread ( ) <nl> - <nl> while True : <nl> if self . num _ requests ( ) > self . max _ requests : <nl> time . sleep ( 0 . 001 ) # 1 millisecond <nl> @ @ - 1381 , 56 + 1419 , 25 @ @ class ExportProcess ( ChildProcess ) : <nl> token _ range , info = self . inmsg . recv ( ) <nl> self . start _ request ( token _ range , info ) <nl> <nl> - def init _ feeder _ thread ( self ) : <nl> - " " " <nl> - Start a thread to feed response messages to the parent process . <nl> - <nl> - It is not safe to write on the pipe from the main thread if the parent process is still sending work and <nl> - not receiving yet . This will in fact block the main thread on the send , which in turn won ' t be able to call <nl> - recv ( ) , and will therefore block the parent process on its send ( ) . <nl> - <nl> - It is also not safe to write on the pipe from the driver receiving thread whilst the parent process is <nl> - sending work , because if the receiving thread stops making progress , then the main thread may no longer <nl> - call recv ( ) due to the check on the maximum number of requests in inner _ run ( ) . <nl> - <nl> - These deadlocks are easiest to reproduce with a single worker process , but may well affect multiple worker <nl> - processes too . <nl> - <nl> - It is important that the order of the responses in the queue is respected , or else the parent process may <nl> - kill off worker processes before it has received all the pages of the last token range . <nl> - " " " <nl> - def feed _ errors ( ) : <nl> - while True : <nl> - try : <nl> - self . outmsg . send ( self . responses . get ( ) ) <nl> - except Exception , e : <nl> - self . printdebugmsg ( e . message ) <nl> - <nl> - self . responses = Queue ( ) <nl> - <nl> - thread = threading . Thread ( target = feed _ errors ) <nl> - thread . setDaemon ( True ) <nl> - thread . start ( ) <nl> - <nl> @ staticmethod <nl> def get _ error _ message ( err , print _ traceback = False ) : <nl> if isinstance ( err , str ) : <nl> msg = err <nl> elif isinstance ( err , BaseException ) : <nl> msg = " % s - % s " % ( err . _ _ class _ _ . _ _ name _ _ , err ) <nl> - if print _ traceback : <nl> - traceback . print _ exc ( err ) <nl> + if print _ traceback and sys . exc _ info ( ) [ 1 ] = = err : <nl> + traceback . print _ exc ( ) <nl> else : <nl> msg = str ( err ) <nl> return msg <nl> <nl> def report _ error ( self , err , token _ range ) : <nl> msg = self . get _ error _ message ( err , print _ traceback = self . debug ) <nl> - self . printdebugmsg ( msg ) <nl> + printdebugmsg ( msg ) <nl> self . send ( ( token _ range , Exception ( msg ) ) ) <nl> <nl> def send ( self , response ) : <nl> - self . responses . put ( response ) <nl> + self . outmsg . send ( response ) <nl> <nl> def start _ request ( self , token _ range , info ) : <nl> " " " <nl> @ @ - 1470 , 7 + 1477 , 7 @ @ class ExportProcess ( ChildProcess ) : <nl> <nl> if ret : <nl> if errors : <nl> - self . printdebugmsg ( " Warning : failed to connect to some replicas : % s " % ( errors , ) ) <nl> + printdebugmsg ( " Warning : failed to connect to some replicas : % s " % ( errors , ) ) <nl> return ret <nl> <nl> self . report _ error ( " Failed to connect to all replicas % s for % s , errors : % s " % ( hosts , token _ range , errors ) , <nl> @ @ - 1623 , 7 + 1630 , 6 @ @ class ImportConversion ( object ) : <nl> self . table = parent . table <nl> self . columns = parent . valid _ columns <nl> self . nullval = parent . nullval <nl> - self . printdebugmsg = parent . printdebugmsg <nl> self . decimal _ sep = parent . decimal _ sep <nl> self . thousands _ sep = parent . thousands _ sep <nl> self . boolean _ styles = parent . boolean _ styles <nl> @ @ - 1822 , 7 + 1828 , 7 @ @ class ImportConversion ( object ) : <nl> elif issubclass ( ct , ReversedType ) : <nl> return convert _ single _ subtype ( val , ct = ct ) <nl> <nl> - self . printdebugmsg ( " Unknown type % s ( % s ) for val % s " % ( ct , ct . typename , val ) ) <nl> + printdebugmsg ( " Unknown type % s ( % s ) for val % s " % ( ct , ct . typename , val ) ) <nl> return val <nl> <nl> converters = { <nl> @ @ - 2104 , 9 + 2110 , 10 @ @ class ImportProcess ( ChildProcess ) : <nl> chunk [ ' rows ' ] = convert _ rows ( conv , chunk ) <nl> for replicas , batch in split _ into _ batches ( chunk , conv , tm ) : <nl> statement = make _ statement ( query , conv , chunk , batch , replicas ) <nl> - future = session . execute _ async ( statement ) <nl> - future . add _ callbacks ( callback = result _ callback , callback _ args = ( batch , chunk ) , <nl> - errback = err _ callback , errback _ args = ( batch , chunk , replicas ) ) <nl> + if statement : <nl> + future = session . execute _ async ( statement ) <nl> + future . add _ callbacks ( callback = result _ callback , callback _ args = ( batch , chunk ) , <nl> + errback = err _ callback , errback _ args = ( batch , chunk , replicas ) ) <nl> <nl> except Exception , exc : <nl> self . report _ error ( exc , chunk , chunk [ ' rows ' ] ) <nl> @ @ - 2288 , 8 + 2295 , 8 @ @ class ImportProcess ( ChildProcess ) : <nl> errback = self . err _ callback , errback _ args = ( batch , chunk , replicas ) ) <nl> <nl> def report _ error ( self , err , chunk , rows = None , attempts = 1 , final = True ) : <nl> - if self . debug : <nl> - traceback . print _ exc ( err ) <nl> + if self . debug and sys . exc _ info ( ) [ 1 ] = = err : <nl> + traceback . print _ exc ( ) <nl> self . outmsg . send ( ImportTaskError ( err . _ _ class _ _ . _ _ name _ _ , str ( err ) , rows , attempts , final ) ) <nl> if final : <nl> self . update _ chunk ( rows , chunk )
NEAREST DIFF (one line): ELIMINATEDSENTENCE

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 76d3673 . . 4a91a58 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 6 @ @ 
 2 . 1 . 14 
 + * ( cqlsh ) Fix potential COPY deadlock when parent process is terminating child 
 + processes ( CASSANDRA - 11505 ) 
 * Replace sstables on DataTracker before marking them as non - compacting during anti - compaction ( CASSANDRA - 11548 ) 
 * Checking if an unlogged batch is local is inefficient ( CASSANDRA - 11529 ) 
 * Fix paging for COMPACT tables without clustering columns ( CASSANDRA - 11467 ) 
 diff - - git a / pylib / cqlshlib / copyutil . py b / pylib / cqlshlib / copyutil . py 
 index 28e08b1 . . 12239d8 100644 
 - - - a / pylib / cqlshlib / copyutil . py 
 + + + b / pylib / cqlshlib / copyutil . py 
 @ @ - 28 , 8 + 28 , 8 @ @ import random 
 import re 
 import struct 
 import sys 
 - import time 
 import threading 
 + import time 
 import traceback 
 
 from bisect import bisect _ right 
 @ @ - 57 , 6 + 57 , 7 @ @ from sslhandling import ssl _ settings 
 
 PROFILE _ ON = False 
 STRACE _ ON = False 
 + DEBUG = False # This may be set to True when initializing the task 
 IS _ LINUX = platform . system ( ) = = ' Linux ' 
 
 CopyOptions = namedtuple ( ' CopyOptions ' , ' copy dialect unrecognized ' ) 
 @ @ - 70 , 6 + 71 , 16 @ @ def safe _ normpath ( fname ) : 
 return os . path . normpath ( os . path . expanduser ( fname ) ) if fname else fname 
 
 
 + def printdebugmsg ( msg ) : 
 + if DEBUG : 
 + printmsg ( msg ) 
 + 
 + 
 + def printmsg ( msg , eol = ' \ n ' ) : 
 + sys . stdout . write ( msg + eol ) 
 + sys . stdout . flush ( ) 
 + 
 + 
 class OneWayChannel ( object ) : 
 " " " 
 A one way pipe protected by two process level locks , one for reading and one for writing . 
 @ @ - 78 , 11 + 89 , 49 @ @ class OneWayChannel ( object ) : 
 self . reader , self . writer = mp . Pipe ( duplex = False ) 
 self . rlock = mp . Lock ( ) 
 self . wlock = mp . Lock ( ) 
 + self . feeding _ thread = None 
 + self . pending _ messages = None 
 + 
 + def init _ feeding _ thread ( self ) : 
 + " " " 
 + Initialize a thread that fetches messages from a queue and sends them to the channel . 
 + We initialize the feeding thread lazily to avoid the fork ( ) , since the channels are passed to child processes . 
 + " " " 
 + if self . feeding _ thread is not None or self . pending _ messages is not None : 
 + raise RuntimeError ( " Feeding thread already initialized " ) 
 + 
 + self . pending _ messages = Queue ( ) 
 + 
 + def feed ( ) : 
 + send = self . _ send 
 + pending _ messages = self . pending _ messages 
 + 
 + while True : 
 + try : 
 + msg = pending _ messages . get ( ) 
 + send ( msg ) 
 + except Exception , e : 
 + printmsg ( ' % s : % s ' % ( e . _ _ class _ _ . _ _ name _ _ , e . message ) ) 
 + 
 + feeding _ thread = threading . Thread ( target = feed ) 
 + feeding _ thread . setDaemon ( True ) 
 + feeding _ thread . start ( ) 
 + 
 + self . feeding _ thread = feeding _ thread 
 
 def send ( self , obj ) : 
 + if self . feeding _ thread is None : 
 + self . init _ feeding _ thread ( ) 
 + 
 + self . pending _ messages . put ( obj ) 
 + 
 + def _ send ( self , obj ) : 
 with self . wlock : 
 self . writer . send ( obj ) 
 
 + def num _ pending ( self ) : 
 + return self . pending _ messages . qsize ( ) if self . pending _ messages else 0 
 + 
 def recv ( self ) : 
 with self . rlock : 
 return self . reader . recv ( ) 
 @ @ - 157 , 8 + 206 , 15 @ @ class CopyTask ( object ) : 
 self . fname = safe _ normpath ( fname ) 
 self . protocol _ version = protocol _ version 
 self . config _ file = config _ file 
 - # do not display messages when exporting to STDOUT 
 - self . printmsg = self . _ printmsg if self . fname is not None or direction = = ' from ' else lambda _ , eol = ' \ n ' : None 
 + 
 + # if cqlsh is invoked with - - debug then set the global debug flag to True 
 + if shell . debug : 
 + global DEBUG 
 + DEBUG = True 
 + 
 + # do not display messages when exporting to STDOUT unless - - debug is set 
 + self . printmsg = printmsg if self . fname is not None or direction = = ' from ' or DEBUG \ 
 + else lambda _ , eol = ' \ n ' : None 
 self . options = self . parse _ options ( opts , direction ) 
 
 self . num _ processes = self . options . copy [ ' numprocesses ' ] 
 @ @ - 174 , 11 + 230 , 6 @ @ class CopyTask ( object ) : 
 self . columns = CopyTask . get _ columns ( shell , ks , table , columns ) 
 self . time _ start = time . time ( ) 
 
 - @ staticmethod 
 - def _ printmsg ( msg , eol = ' \ n ' ) : 
 - sys . stdout . write ( msg + eol ) 
 - sys . stdout . flush ( ) 
 - 
 def maybe _ read _ config _ file ( self , opts , direction ) : 
 " " " 
 Read optional sections from a configuration file that was specified in the command options or from the default 
 @ @ - 758 , 7 + 809 , 7 @ @ class FilesReader ( object ) : 
 try : 
 return open ( fname , ' rb ' ) 
 except IOError , e : 
 - self . printmsg ( " Can ' t open % r for reading : % s " % ( fname , e ) ) 
 + printdebugmsg ( " Can ' t open % r for reading : % s " % ( fname , e ) ) 
 return None 
 
 for path in paths . split ( ' , ' ) : 
 @ @ - 769 , 11 + 820 , 6 @ @ class FilesReader ( object ) : 
 for f in glob . glob ( path ) : 
 yield ( make _ source ( f ) ) 
 
 - @ staticmethod 
 - def printmsg ( msg , eol = ' \ n ' ) : 
 - sys . stdout . write ( msg + eol ) 
 - sys . stdout . flush ( ) 
 - 
 def start ( self ) : 
 self . sources = self . get _ source ( self . fname ) 
 self . next _ source ( ) 
 @ @ - 921 , 7 + 967 , 6 @ @ class ImportErrorHandler ( object ) : 
 def _ _ init _ _ ( self , task ) : 
 self . shell = task . shell 
 self . options = task . options 
 - self . printmsg = task . printmsg 
 self . max _ attempts = self . options . copy [ ' maxattempts ' ] 
 self . max _ parse _ errors = self . options . copy [ ' maxparseerrors ' ] 
 self . max _ insert _ errors = self . options . copy [ ' maxinserterrors ' ] 
 @ @ - 933 , 7 + 978 , 7 @ @ class ImportErrorHandler ( object ) : 
 if os . path . isfile ( self . err _ file ) : 
 now = datetime . datetime . now ( ) 
 old _ err _ file = self . err _ file + now . strftime ( ' . % Y % m % d _ % H % M % S ' ) 
 - self . printmsg ( " Renaming existing % s to % s \ n " % ( self . err _ file , old _ err _ file ) ) 
 + printdebugmsg ( " Renaming existing % s to % s \ n " % ( self . err _ file , old _ err _ file ) ) 
 os . rename ( self . err _ file , old _ err _ file ) 
 
 def max _ exceeded ( self ) : 
 @ @ - 1088 , 17 + 1133 , 18 @ @ class ImportTask ( CopyTask ) : 
 self . shell . printerr ( " { } child process ( es ) died unexpectedly , aborting " 
 . format ( self . num _ processes - self . num _ live _ processes ( ) ) ) 
 else : 
 - # it is only safe to write to processes if they are all running because the feeder process 
 - # at the moment hangs whilst sending messages to a crashed worker process ; in future 
 - # we could do something about this by using a BoundedSemaphore to keep track of how many messages are 
 - # queued on a pipe 
 + if self . error _ handler . max _ exceeded ( ) : 
 + self . processes [ - 1 ] . terminate ( ) # kill the feeder 
 + 
 for i , _ in enumerate ( self . processes ) : 
 - self . outmsg . channels [ i ] . send ( None ) 
 + if self . processes [ i ] . is _ alive ( ) : 
 + self . outmsg . channels [ i ] . send ( None ) 
 
 - if PROFILE _ ON : 
 - # allow time for worker processes to write profile results ( only works if processes received 
 - # the poison pill above ) 
 - time . sleep ( 5 ) 
 + # allow time for worker processes to exit cleanly 
 + attempts = 50 # 100 milliseconds per attempt , so 5 seconds total 
 + while attempts > 0 and self . num _ live _ processes ( ) > 0 : 
 + time . sleep ( 0 . 1 ) 
 + attempts - = 1 
 
 self . printmsg ( " \ n % d rows imported from % d files in % s ( % d skipped ) . " % 
 ( self . receive _ meter . get _ total _ records ( ) , 
 @ @ - 1239 , 12 + 1285 , 8 @ @ class ChildProcess ( mp . Process ) : 
 else : 
 self . test _ failures = None 
 
 - def printdebugmsg ( self , text ) : 
 - if self . debug : 
 - sys . stdout . write ( text + ' \ n ' ) 
 - 
 def close ( self ) : 
 - self . printdebugmsg ( " Closing queues . . . " ) 
 + printdebugmsg ( " Closing queues . . . " ) 
 self . inmsg . close ( ) 
 self . outmsg . close ( ) 
 
 @ @ - 1256 , 7 + 1298 , 6 @ @ class ExpBackoffRetryPolicy ( RetryPolicy ) : 
 def _ _ init _ _ ( self , parent _ process ) : 
 RetryPolicy . _ _ init _ _ ( self ) 
 self . max _ attempts = parent _ process . max _ attempts 
 - self . printdebugmsg = parent _ process . printdebugmsg 
 
 def on _ read _ timeout ( self , query , consistency , required _ responses , 
 received _ responses , data _ retrieved , retry _ num ) : 
 @ @ - 1269 , 14 + 1310 , 14 @ @ class ExpBackoffRetryPolicy ( RetryPolicy ) : 
 def _ handle _ timeout ( self , consistency , retry _ num ) : 
 delay = self . backoff ( retry _ num ) 
 if delay > 0 : 
 - self . printdebugmsg ( " Timeout received , retrying after % d seconds " % ( delay , ) ) 
 + printdebugmsg ( " Timeout received , retrying after % d seconds " % ( delay , ) ) 
 time . sleep ( delay ) 
 return self . RETRY , consistency 
 elif delay = = 0 : 
 - self . printdebugmsg ( " Timeout received , retrying immediately " ) 
 + printdebugmsg ( " Timeout received , retrying immediately " ) 
 return self . RETRY , consistency 
 else : 
 - self . printdebugmsg ( " Timeout received , giving up after % d attempts " % ( retry _ num + 1 ) ) 
 + printdebugmsg ( " Timeout received , giving up after % d attempts " % ( retry _ num + 1 ) ) 
 return self . RETHROW , None 
 
 def backoff ( self , retry _ num ) : 
 @ @ - 1309 , 8 + 1350 , 8 @ @ class ExportSession ( object ) : 
 session . default _ fetch _ size = export _ process . options . copy [ ' pagesize ' ] 
 session . default _ timeout = export _ process . options . copy [ ' pagetimeout ' ] 
 
 - export _ process . printdebugmsg ( " Created connection to % s with page size % d and timeout % d seconds per page " 
 - % ( cluster . contact _ points , session . default _ fetch _ size , session . default _ timeout ) ) 
 + printdebugmsg ( " Created connection to % s with page size % d and timeout % d seconds per page " 
 + % ( cluster . contact _ points , session . default _ fetch _ size , session . default _ timeout ) ) 
 
 self . cluster = cluster 
 self . session = session 
 @ @ - 1353 , 7 + 1394 , 6 @ @ class ExportProcess ( ChildProcess ) : 
 self . hosts _ to _ sessions = dict ( ) 
 self . formatters = dict ( ) 
 self . options = options 
 - self . responses = None 
 
 def run ( self ) : 
 try : 
 @ @ - 1371 , 8 + 1411 , 6 @ @ class ExportProcess ( ChildProcess ) : 
 we can signal a global error by sending ( None , error ) . 
 We terminate when the inbound queue is closed . 
 " " " 
 - self . init _ feeder _ thread ( ) 
 - 
 while True : 
 if self . num _ requests ( ) > self . max _ requests : 
 time . sleep ( 0 . 001 ) # 1 millisecond 
 @ @ - 1381 , 56 + 1419 , 25 @ @ class ExportProcess ( ChildProcess ) : 
 token _ range , info = self . inmsg . recv ( ) 
 self . start _ request ( token _ range , info ) 
 
 - def init _ feeder _ thread ( self ) : 
 - " " " 
 - Start a thread to feed response messages to the parent process . 
 - 
 - It is not safe to write on the pipe from the main thread if the parent process is still sending work and 
 - not receiving yet . This will in fact block the main thread on the send , which in turn won ' t be able to call 
 - recv ( ) , and will therefore block the parent process on its send ( ) . 
 - 
 - It is also not safe to write on the pipe from the driver receiving thread whilst the parent process is 
 - sending work , because if the receiving thread stops making progress , then the main thread may no longer 
 - call recv ( ) due to the check on the maximum number of requests in inner _ run ( ) . 
 - 
 - These deadlocks are easiest to reproduce with a single worker process , but may well affect multiple worker 
 - processes too . 
 - 
 - It is important that the order of the responses in the queue is respected , or else the parent process may 
 - kill off worker processes before it has received all the pages of the last token range . 
 - " " " 
 - def feed _ errors ( ) : 
 - while True : 
 - try : 
 - self . outmsg . send ( self . responses . get ( ) ) 
 - except Exception , e : 
 - self . printdebugmsg ( e . message ) 
 - 
 - self . responses = Queue ( ) 
 - 
 - thread = threading . Thread ( target = feed _ errors ) 
 - thread . setDaemon ( True ) 
 - thread . start ( ) 
 - 
 @ staticmethod 
 def get _ error _ message ( err , print _ traceback = False ) : 
 if isinstance ( err , str ) : 
 msg = err 
 elif isinstance ( err , BaseException ) : 
 msg = " % s - % s " % ( err . _ _ class _ _ . _ _ name _ _ , err ) 
 - if print _ traceback : 
 - traceback . print _ exc ( err ) 
 + if print _ traceback and sys . exc _ info ( ) [ 1 ] = = err : 
 + traceback . print _ exc ( ) 
 else : 
 msg = str ( err ) 
 return msg 
 
 def report _ error ( self , err , token _ range ) : 
 msg = self . get _ error _ message ( err , print _ traceback = self . debug ) 
 - self . printdebugmsg ( msg ) 
 + printdebugmsg ( msg ) 
 self . send ( ( token _ range , Exception ( msg ) ) ) 
 
 def send ( self , response ) : 
 - self . responses . put ( response ) 
 + self . outmsg . send ( response ) 
 
 def start _ request ( self , token _ range , info ) : 
 " " " 
 @ @ - 1470 , 7 + 1477 , 7 @ @ class ExportProcess ( ChildProcess ) : 
 
 if ret : 
 if errors : 
 - self . printdebugmsg ( " Warning : failed to connect to some replicas : % s " % ( errors , ) ) 
 + printdebugmsg ( " Warning : failed to connect to some replicas : % s " % ( errors , ) ) 
 return ret 
 
 self . report _ error ( " Failed to connect to all replicas % s for % s , errors : % s " % ( hosts , token _ range , errors ) , 
 @ @ - 1623 , 7 + 1630 , 6 @ @ class ImportConversion ( object ) : 
 self . table = parent . table 
 self . columns = parent . valid _ columns 
 self . nullval = parent . nullval 
 - self . printdebugmsg = parent . printdebugmsg 
 self . decimal _ sep = parent . decimal _ sep 
 self . thousands _ sep = parent . thousands _ sep 
 self . boolean _ styles = parent . boolean _ styles 
 @ @ - 1822 , 7 + 1828 , 7 @ @ class ImportConversion ( object ) : 
 elif issubclass ( ct , ReversedType ) : 
 return convert _ single _ subtype ( val , ct = ct ) 
 
 - self . printdebugmsg ( " Unknown type % s ( % s ) for val % s " % ( ct , ct . typename , val ) ) 
 + printdebugmsg ( " Unknown type % s ( % s ) for val % s " % ( ct , ct . typename , val ) ) 
 return val 
 
 converters = { 
 @ @ - 2104 , 9 + 2110 , 10 @ @ class ImportProcess ( ChildProcess ) : 
 chunk [ ' rows ' ] = convert _ rows ( conv , chunk ) 
 for replicas , batch in split _ into _ batches ( chunk , conv , tm ) : 
 statement = make _ statement ( query , conv , chunk , batch , replicas ) 
 - future = session . execute _ async ( statement ) 
 - future . add _ callbacks ( callback = result _ callback , callback _ args = ( batch , chunk ) , 
 - errback = err _ callback , errback _ args = ( batch , chunk , replicas ) ) 
 + if statement : 
 + future = session . execute _ async ( statement ) 
 + future . add _ callbacks ( callback = result _ callback , callback _ args = ( batch , chunk ) , 
 + errback = err _ callback , errback _ args = ( batch , chunk , replicas ) ) 
 
 except Exception , exc : 
 self . report _ error ( exc , chunk , chunk [ ' rows ' ] ) 
 @ @ - 2288 , 8 + 2295 , 8 @ @ class ImportProcess ( ChildProcess ) : 
 errback = self . err _ callback , errback _ args = ( batch , chunk , replicas ) ) 
 
 def report _ error ( self , err , chunk , rows = None , attempts = 1 , final = True ) : 
 - if self . debug : 
 - traceback . print _ exc ( err ) 
 + if self . debug and sys . exc _ info ( ) [ 1 ] = = err : 
 + traceback . print _ exc ( ) 
 self . outmsg . send ( ImportTaskError ( err . _ _ class _ _ . _ _ name _ _ , str ( err ) , rows , attempts , final ) ) 
 if final : 
 self . update _ chunk ( rows , chunk )

NEAREST DIFF:
ELIMINATEDSENTENCE
