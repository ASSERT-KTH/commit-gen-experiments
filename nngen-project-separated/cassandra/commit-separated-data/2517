BLEU SCORE: 0.018977423949228533

TEST MSG: Document lack of order guarantees for BATCH statements
GENERATED MSG: Never allow partition range queries in CQL3 without token ( )

TEST DIFF (one line): diff - - git a / doc / cql3 / CQL . textile b / doc / cql3 / CQL . textile <nl> index f6208bf . . bedd189 100644 <nl> - - - a / doc / cql3 / CQL . textile <nl> + + + b / doc / cql3 / CQL . textile <nl> @ @ - 614 , 7 + 614 , 11 @ @ The @ BATCH @ statement group multiple modification statements ( insertions / updates <nl> # It saves network round - trips between the client and the server ( and sometimes between the server coordinator and the replicas ) when batching multiple updates . <nl> # All updates in a @ BATCH @ belonging to a given partition key are performed in isolation . <nl> # By default , all operations in the batch are performed atomically . See the notes on " @ UNLOGGED @ " : # unloggedBatch for more details . <nl> - Note however that the @ BATCH @ statement only allows @ UPDATE @ , @ INSERT @ and @ DELETE @ statements and is _ not _ a full analogue for SQL transactions . <nl> + <nl> + Note that : <nl> + * @ BATCH @ statements may only contain @ UPDATE @ , @ INSERT @ and @ DELETE @ statements . <nl> + * Batches are _ not _ a full analogue for SQL transactions . <nl> + * If a timestamp is not specified for each operation , then all operations will be applied with the same timestamp . Due to Cassandra ' s conflict resolution procedure in the case of " timestamp ties " : http : / / wiki . apache . org / cassandra / FAQ # clocktie , operations may be applied in an order that is different from the order they are listed in the @ BATCH @ statement . To force a particular operation ordering , you must specify per - operation timestamps . <nl> <nl> h4 ( # unloggedBatch ) . @ UNLOGGED @ <nl>
NEAREST DIFF (one line): diff - - git a / NEWS . txt b / NEWS . txt <nl> index 5cb06da . . dbc9aab 100644 <nl> - - - a / NEWS . txt <nl> + + + b / NEWS . txt <nl> @ @ - 8 , 6 + 8 , 11 @ @ upgrade , just in case you need to roll back to the previous version . <nl> ( Cassandra version X + 1 will always be able to read data files created <nl> by version X , but the inverse is not necessarily the case . ) <nl> <nl> + When upgrading major versions of Cassandra , you will be unable to <nl> + restore snapshots created with the previous major version using the <nl> + ' sstableloader ' tool . You can upgrade the file format of your snapshots <nl> + using the provided ' sstableupgrade ' tool . <nl> + <nl> 1 . 2 . 6 <nl> = = = = = <nl> <nl> @ @ - 217 , 7 + 222 , 7 @ @ Features <nl> - num _ tokens can now be specified in cassandra . yaml . This defines the <nl> number of tokens assigned to the host on the ring ( default : 1 ) . <nl> Also specifying initial _ token will override any num _ tokens setting . <nl> - - disk _ failure _ policy allows blacklisting failed disks in JBOD <nl> + - disk _ failure _ policy allows blacklisting failed disks in JBOD <nl> configuration instead of erroring out indefinitely <nl> - event tracing can be configured per - connection ( " trace _ next _ query " ) <nl> or globally / probabilistically ( " nodetool settraceprobability " ) <nl> @ @ - 314 , 7 + 319 , 7 @ @ Upgrading <nl> throw an InvalidRequestException when used for reads . ( Previous <nl> versions would silently perform a ONE read for range queries ; <nl> single - row and multiget reads already rejected ANY . ) <nl> - - The largest mutation batch accepted by the commitlog is now 128MB . <nl> + - The largest mutation batch accepted by the commitlog is now 128MB . <nl> ( In practice , batches larger than ~ 10MB always caused poor <nl> performance due to load volatility and GC promotion failures . ) <nl> Larger batches will continue to be accepted but will not be <nl> @ @ - 514 , 7 + 519 , 7 @ @ Upgrading <nl> - Upgrading from version 0 . 7 . 1 + or 0 . 8 . 2 + can be done with a rolling <nl> restart , one node at a time . ( 0 . 8 . 0 or 0 . 8 . 1 are NOT network - compatible <nl> with 1 . 0 : upgrade to the most recent 0 . 8 release first . ) <nl> - You do not need to bring down the whole cluster at once . <nl> + You do not need to bring down the whole cluster at once . <nl> - After upgrading , run nodetool scrub against each node before running <nl> repair , moving nodes , or adding new ones . <nl> - CQL inserts / updates now generate microsecond resolution timestamps <nl> @ @ - 695 , 7 + 700 , 7 @ @ Upgrading <nl> - - - - - - - - - <nl> - Upgrading from version 0 . 7 . 1 or later can be done with a rolling <nl> restart , one node at a time . You do not need to bring down the <nl> - whole cluster at once . <nl> + whole cluster at once . <nl> - After upgrading , run nodetool scrub against each node before running <nl> repair , moving nodes , or adding new ones . <nl> - Running nodetool drain before shutting down the 0 . 7 node is <nl> @ @ - 706 , 8 + 711 , 8 @ @ Upgrading <nl> to use your 0 . 7 clients . <nl> - Avro record classes used in map / reduce and Hadoop streaming code have <nl> been removed . Map / reduce can be switched to Thrift by changing <nl> - org . apache . cassandra . avro in import statements to <nl> - org . apache . cassandra . thrift ( no class names change ) . Streaming support <nl> + org . apache . cassandra . avro in import statements to <nl> + org . apache . cassandra . thrift ( no class names change ) . Streaming support <nl> has been removed for the time being . <nl> - The loadbalance command has been removed from nodetool . For similar <nl> behavior , decommission then rebootstrap with empty initial _ token . <nl> @ @ - 721 , 15 + 726 , 15 @ @ Features <nl> - - - - - - - - <nl> - added CQL client API and JDBC / DBAPI2 - compliant drivers for Java and <nl> Python , respectively ( see : drivers / subdirectory and doc / cql ) <nl> - - added distributed Counters feature ; <nl> + - added distributed Counters feature ; <nl> see http : / / wiki . apache . org / cassandra / Counters <nl> - optional intranode encryption ; see comments around ' encryption _ options ' <nl> in cassandra . yaml <nl> - - compaction multithreading and rate - limiting ; see <nl> + - compaction multithreading and rate - limiting ; see <nl> ' concurrent _ compactors ' and ' compaction _ throughput _ mb _ per _ sec ' in <nl> cassandra . yaml <nl> - cassandra will limit total memtable memory usage to 1 / 3 of the heap <nl> - by default . This can be ajusted or disabled with the <nl> + by default . This can be ajusted or disabled with the <nl> memtable _ total _ space _ in _ mb option . The old per - ColumnFamily <nl> throughput , operations , and age settings are still respected but <nl> will be removed in a future major release once we are satisfied that <nl> @ @ - 738 , 7 + 743 , 7 @ @ Features <nl> Tools <nl> - - - - - <nl> - stress and py _ stress moved from contrib / to tools / <nl> - - clustertool was removed ( see <nl> + - clustertool was removed ( see <nl> https : / / issues . apache . org / jira / browse / CASSANDRA - 2607 for examples <nl> of how to script nodetool across the cluster instead ) <nl> <nl> @ @ - 814 , 7 + 819 , 7 @ @ Upgrading <nl> - 0 . 7 . 1 and 0 . 7 . 2 shipped with a bug that caused incorrect row - level <nl> bloom filters to be generated when compacting sstables generated <nl> with earlier versions . This would manifest in IOExceptions during <nl> - column name - based queries . 0 . 7 . 3 provides " nodetool scrub " to <nl> + column name - based queries . 0 . 7 . 3 provides " nodetool scrub " to <nl> rebuild sstables with correct bloom filters , with no data lost . <nl> ( If your cluster was never on 0 . 7 . 0 or earlier , you don ' t have to <nl> worry about this . ) Note that nodetool scrub will snapshot your <nl> @ @ - 862 , 10 + 867 , 10 @ @ Features <nl> - Row size limit increased from 2GB to 2 billion columns . rows <nl> are no longer read into memory during compaction . <nl> - Keyspace and ColumnFamily definitions may be added and modified live <nl> - - Streaming data for repair or node movement no longer requires <nl> + - Streaming data for repair or node movement no longer requires <nl> anticompaction step first <nl> - - NetworkTopologyStrategy ( formerly DatacenterShardStrategy ) is ready for <nl> - use , enabling ConsistencyLevel . DCQUORUM and DCQUORUMSYNC . See comments <nl> + - NetworkTopologyStrategy ( formerly DatacenterShardStrategy ) is ready for <nl> + use , enabling ConsistencyLevel . DCQUORUM and DCQUORUMSYNC . See comments <nl> in ` cassandra . yaml . ` <nl> - Optional per - Column time - to - live field allows expiring data without <nl> have to issue explicit remove commands <nl> @ @ - 879 , 9 + 884 , 9 @ @ Features <nl> - Optional round - robin scheduling between keyspaces for multitenant <nl> clusters <nl> - Dynamic endpoint snitch mitigates the impact of impaired nodes <nl> - - New ` IntegerType ` , faster than LongType and allows integers of <nl> + - New ` IntegerType ` , faster than LongType and allows integers of <nl> both less and more bits than Long ' s 64 <nl> - - A revamped authentication system that decouples authorization and <nl> + - A revamped authentication system that decouples authorization and <nl> allows finer - grained control of resources . <nl> <nl> Upgrading <nl> @ @ - 893 , 9 + 898 , 9 @ @ Upgrading <nl> The Cassandra inter - node protocol is incompatible with 0 . 6 . x <nl> releases ( and with 0 . 7 beta1 ) , meaning you will have to bring your <nl> cluster down prior to upgrading : you cannot mix 0 . 6 and 0 . 7 nodes . <nl> - <nl> + <nl> The hints schema was changed from 0 . 6 to 0 . 7 . Cassandra automatically <nl> - snapshots and then truncates the hints column family as part of <nl> + snapshots and then truncates the hints column family as part of <nl> starting up 0 . 7 for the first time . <nl> <nl> Keyspace and ColumnFamily definitions are stored in the system <nl> @ @ - 904 , 13 + 909 , 13 @ @ Upgrading <nl> The process to upgrade is : <nl> 1 ) run " nodetool drain " on _ each _ 0 . 6 node . When drain finishes ( log <nl> message " Node is drained " appears ) , stop the process . <nl> - 2 ) Convert your storage - conf . xml to the new cassandra . yaml using <nl> - " bin / config - converter " . <nl> + 2 ) Convert your storage - conf . xml to the new cassandra . yaml using <nl> + " bin / config - converter " . <nl> 3 ) Rename any of your keyspace or column family names that do not adhere <nl> to the ' ^ \ w + ' regex convention . <nl> 4 ) Start up your cluster with the 0 . 7 version . <nl> - 5 ) Initialize your Keyspace and ColumnFamily definitions using <nl> - " bin / schematool < host > < jmxport > import " . _ You only need to do <nl> + 5 ) Initialize your Keyspace and ColumnFamily definitions using <nl> + " bin / schematool < host > < jmxport > import " . _ You only need to do <nl> this to one node _ . <nl> <nl> Thrift API <nl> @ @ - 935 , 7 + 940 , 7 @ @ Configuraton <nl> - - - - - - - - - - - - <nl> - Configuration file renamed to cassandra . yaml and log4j . properties to <nl> log4j - server . properties <nl> - - PropertyFileSnitch configuration file renamed to <nl> + - PropertyFileSnitch configuration file renamed to <nl> cassandra - topology . properties <nl> - The ThriftAddress and ThriftPort directives have been renamed to <nl> RPCAddress and RPCPort respectively . <nl> @ @ - 952 , 7 + 957 , 7 @ @ Configuraton <nl> one node _ . <nl> - In addition to an authenticator , an authority must be configured as <nl> well . Users of SimpleAuthenticator should use SimpleAuthority for this <nl> - value ( the default is AllowAllAuthority , which corresponds with <nl> + value ( the default is AllowAllAuthority , which corresponds with <nl> AllowAllAuthenticator ) . <nl> - The format of access . properties has changed , see the sample configuration <nl> conf / access . properties for documentation on the new format . <nl> @ @ - 1011 , 7 + 1016 , 7 @ @ Features <nl> Configuraton <nl> - - - - - - - - - - - - <nl> - MemtableSizeInMB has been replaced by MemtableThroughputInMB which <nl> - triggers a memtable flush when the specified amount of data has <nl> + triggers a memtable flush when the specified amount of data has <nl> been written , including overwrites . <nl> - MemtableObjectCountInMillions has been replaced by the <nl> MemtableOperationsInMillions directive which causes a memtable flush <nl> @ @ - 1047 , 7 + 1052 , 7 @ @ JMX metrics <nl> progress of the current compaction has been added . <nl> - commitlog JMX metrics are moved to org . apache . cassandra . db . Commitlog <nl> - progress of data streaming during bootstrap , loadbalance , or other <nl> - data migration , is available under <nl> + data migration , is available under <nl> org . apache . cassandra . streaming . StreamingService . <nl> See http : / / wiki . apache . org / cassandra / Streaming for details . <nl> <nl> @ @ - 1061 , 8 + 1066 , 8 @ @ Installation / Upgrade <nl> 0 . 5 . 0 <nl> = = = = = <nl> <nl> - 0 . The commitlog format has changed ( but sstable format has not ) . <nl> - When upgrading from 0 . 4 , empty the commitlog either by running <nl> + 0 . The commitlog format has changed ( but sstable format has not ) . <nl> + When upgrading from 0 . 4 , empty the commitlog either by running <nl> bin / nodeprobe flush on each machine and waiting for the flush to finish , <nl> or simply remove the commitlog directory if you only have test data . <nl> ( If more writes come in after the flush command , starting 0 . 5 will error <nl> @ @ - 1083 , 7 + 1088 , 7 @ @ Installation / Upgrade <nl> <nl> 3 . Configuration : <nl> - Added " comment " field to ColumnFamily definition . <nl> - - Added MemtableFlushAfterMinutes , a global replacement for the <nl> + - Added MemtableFlushAfterMinutes , a global replacement for the <nl> old per - CF FlushPeriodInMinutes setting <nl> - Key cache settings <nl> <nl> @ @ - 1121 , 7 + 1126 , 7 @ @ Installation / Upgrade <nl> create and modify ColumnFamilies at will without worrying about <nl> collisions with others in the same cluster . <nl> <nl> - 3 . Many Thrift API changes and documentation . See <nl> + 3 . Many Thrift API changes and documentation . See <nl> http : / / wiki . apache . org / cassandra / API <nl> <nl> 4 . Removed the web interface in favor of JMX and bin / nodeprobe , which <nl> @ @ - 1166 , 4 + 1171 , 4 @ @ key in a given ColumnFamily ) is limited by available memory , because <nl> compaction deserializes each row before merging . <nl> <nl> See https : / / issues . apache . org / jira / browse / CASSANDRA - 16 <nl> - <nl> + <nl> diff - - git a / bin / sstableupgrade b / bin / sstableupgrade <nl> new file mode 100755 <nl> index 0000000 . . b5ddd6a <nl> - - - / dev / null <nl> + + + b / bin / sstableupgrade <nl> @ @ - 0 , 0 + 1 , 55 @ @ <nl> + # ! / bin / sh <nl> + <nl> + # Licensed to the Apache Software Foundation ( ASF ) under one <nl> + # or more contributor license agreements . See the NOTICE file <nl> + # distributed with this work for additional information <nl> + # regarding copyright ownership . The ASF licenses this file <nl> + # to you under the Apache License , Version 2 . 0 ( the <nl> + # " License " ) ; you may not use this file except in compliance <nl> + # with the License . You may obtain a copy of the License at <nl> + # <nl> + # http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + # <nl> + # Unless required by applicable law or agreed to in writing , software <nl> + # distributed under the License is distributed on an " AS IS " BASIS , <nl> + # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + # See the License for the specific language governing permissions and <nl> + # limitations under the License . <nl> + <nl> + if [ " x $ CASSANDRA _ INCLUDE " = " x " ] ; then <nl> + for include in / usr / share / cassandra / cassandra . in . sh \ <nl> + / usr / local / share / cassandra / cassandra . in . sh \ <nl> + / opt / cassandra / cassandra . in . sh \ <nl> + ~ / . cassandra . in . sh \ <nl> + ` dirname $ 0 ` / cassandra . in . sh ; do <nl> + if [ - r $ include ] ; then <nl> + . $ include <nl> + break <nl> + fi <nl> + done <nl> + elif [ - r $ CASSANDRA _ INCLUDE ] ; then <nl> + . $ CASSANDRA _ INCLUDE <nl> + fi <nl> + <nl> + # Use JAVA _ HOME if set , otherwise look for java in PATH <nl> + if [ - x $ JAVA _ HOME / bin / java ] ; then <nl> + JAVA = $ JAVA _ HOME / bin / java <nl> + else <nl> + JAVA = ` which java ` <nl> + fi <nl> + <nl> + if [ - z $ CLASSPATH ] ; then <nl> + echo " You must set the CLASSPATH var " > & 2 <nl> + exit 1 <nl> + fi <nl> + <nl> + if [ " x $ MAX _ HEAP _ SIZE " = " x " ] ; then <nl> + MAX _ HEAP _ SIZE = " 256M " <nl> + fi <nl> + <nl> + $ JAVA - ea - cp $ CLASSPATH - Xmx $ MAX _ HEAP _ SIZE \ <nl> + - Dlog4j . configuration = log4j - tools . properties \ <nl> + org . apache . cassandra . tools . StandaloneUpgrader " $ @ " <nl> + <nl> + # vi : ai sw = 4 ts = 4 tw = 0 et <nl> + <nl> diff - - git a / debian / cassandra . install b / debian / cassandra . install <nl> index 6d7ba8f . . a504b78 100644 <nl> - - - a / debian / cassandra . install <nl> + + + b / debian / cassandra . install <nl> @ @ - 17 , 6 + 17 , 7 @ @ bin / sstablekeys usr / bin <nl> bin / sstableloader usr / bin <nl> bin / cqlsh usr / bin <nl> bin / sstablescrub usr / bin <nl> + bin / sstableupgrade usr / bin <nl> bin / cassandra - shuffle usr / bin <nl> tools / bin / cassandra - stress usr / bin <nl> tools / bin / token - generator usr / bin <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / Upgrader . java b / src / java / org / apache / cassandra / db / compaction / Upgrader . java <nl> new file mode 100644 <nl> index 0000000 . . e7211ba <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / db / compaction / Upgrader . java <nl> @ @ - 0 , 0 + 1 , 167 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an " AS IS " BASIS , <nl> + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + * See the License for the specific language governing permissions and <nl> + * limitations under the License . <nl> + * / <nl> + package org . apache . cassandra . db . compaction ; <nl> + <nl> + import java . io . File ; <nl> + import java . io . IOException ; <nl> + import java . io . IOError ; <nl> + import java . util . * ; <nl> + <nl> + import com . google . common . base . Throwables ; <nl> + <nl> + import org . apache . cassandra . config . DatabaseDescriptor ; <nl> + import org . apache . cassandra . db . ColumnFamilyStore ; <nl> + import org . apache . cassandra . db . DecoratedKey ; <nl> + import org . apache . cassandra . db . RowIndexEntry ; <nl> + import org . apache . cassandra . db . compaction . AbstractCompactedRow ; <nl> + import org . apache . cassandra . db . compaction . AbstractCompactionStrategy ; <nl> + import org . apache . cassandra . db . compaction . AbstractCompactionIterable ; <nl> + import org . apache . cassandra . db . compaction . CompactionIterable ; <nl> + import org . apache . cassandra . db . compaction . CompactionController ; <nl> + import org . apache . cassandra . db . compaction . CompactionManager ; <nl> + import org . apache . cassandra . db . compaction . CompactionTask ; <nl> + import org . apache . cassandra . db . compaction . OperationType ; <nl> + import org . apache . cassandra . io . sstable . * ; <nl> + import org . apache . cassandra . io . util . RandomAccessReader ; <nl> + import org . apache . cassandra . utils . CloseableIterator ; <nl> + import org . apache . cassandra . utils . OutputHandler ; <nl> + <nl> + public class Upgrader <nl> + { <nl> + private final ColumnFamilyStore cfs ; <nl> + private final SSTableReader sstable ; <nl> + private final Collection < SSTableReader > toUpgrade ; <nl> + private final File directory ; <nl> + <nl> + private final OperationType compactionType = OperationType . UPGRADE _ SSTABLES ; <nl> + private final CompactionController controller ; <nl> + private final AbstractCompactionStrategy strategy ; <nl> + private final long estimatedRows ; <nl> + <nl> + private final int gcBefore = CompactionManager . NO _ GC ; <nl> + <nl> + private final OutputHandler outputHandler ; <nl> + <nl> + public Upgrader ( ColumnFamilyStore cfs , SSTableReader sstable , OutputHandler outputHandler ) <nl> + { <nl> + this . cfs = cfs ; <nl> + this . sstable = sstable ; <nl> + this . toUpgrade = Collections . singletonList ( sstable ) ; <nl> + this . outputHandler = outputHandler ; <nl> + <nl> + this . directory = new File ( sstable . getFilename ( ) ) . getParentFile ( ) ; <nl> + <nl> + this . controller = new UpgradeController ( cfs ) ; <nl> + <nl> + this . strategy = cfs . getCompactionStrategy ( ) ; <nl> + long estimatedTotalKeys = Math . max ( DatabaseDescriptor . getIndexInterval ( ) , SSTableReader . getApproximateKeyCount ( toUpgrade ) ) ; <nl> + long estimatedSSTables = Math . max ( 1 , SSTable . getTotalBytes ( this . toUpgrade ) / strategy . getMaxSSTableSize ( ) ) ; <nl> + this . estimatedRows = ( long ) Math . ceil ( ( double ) estimatedTotalKeys / estimatedSSTables ) ; <nl> + } <nl> + <nl> + private SSTableWriter createCompactionWriter ( ) <nl> + { <nl> + SSTableMetadata . Collector sstableMetadataCollector = SSTableMetadata . createCollector ( ) ; <nl> + <nl> + / / Get the max timestamp of the precompacted sstables <nl> + / / and adds generation of live ancestors <nl> + for ( SSTableReader sstable : toUpgrade ) <nl> + { <nl> + sstableMetadataCollector . addAncestor ( sstable . descriptor . generation ) ; <nl> + for ( Integer i : sstable . getAncestors ( ) ) <nl> + { <nl> + if ( new File ( sstable . descriptor . withGeneration ( i ) . filenameFor ( Component . DATA ) ) . exists ( ) ) <nl> + sstableMetadataCollector . addAncestor ( i ) ; <nl> + } <nl> + } <nl> + <nl> + return new SSTableWriter ( cfs . getTempSSTablePath ( directory ) , estimatedRows , cfs . metadata , cfs . partitioner , sstableMetadataCollector ) ; <nl> + } <nl> + <nl> + public void upgrade ( ) <nl> + { <nl> + outputHandler . output ( " Upgrading " + sstable ) ; <nl> + <nl> + <nl> + AbstractCompactionIterable ci = new CompactionIterable ( compactionType , strategy . getScanners ( this . toUpgrade ) , controller ) ; <nl> + <nl> + CloseableIterator < AbstractCompactedRow > iter = ci . iterator ( ) ; <nl> + <nl> + Collection < SSTableReader > sstables = new ArrayList < SSTableReader > ( ) ; <nl> + Collection < SSTableWriter > writers = new ArrayList < SSTableWriter > ( ) ; <nl> + <nl> + try <nl> + { <nl> + SSTableWriter writer = createCompactionWriter ( ) ; <nl> + writers . add ( writer ) ; <nl> + while ( iter . hasNext ( ) ) <nl> + { <nl> + AbstractCompactedRow row = iter . next ( ) ; <nl> + <nl> + RowIndexEntry indexEntry = writer . append ( row ) ; <nl> + } <nl> + <nl> + long maxAge = CompactionTask . getMaxDataAge ( this . toUpgrade ) ; <nl> + for ( SSTableWriter completedWriter : writers ) <nl> + sstables . add ( completedWriter . closeAndOpenReader ( maxAge ) ) ; <nl> + <nl> + outputHandler . output ( " Upgrade of " + sstable + " complete . " ) ; <nl> + <nl> + } <nl> + catch ( Throwable t ) <nl> + { <nl> + for ( SSTableWriter writer : writers ) <nl> + writer . abort ( ) ; <nl> + / / also remove already completed SSTables <nl> + for ( SSTableReader sstable : sstables ) <nl> + { <nl> + sstable . markCompacted ( ) ; <nl> + sstable . releaseReference ( ) ; <nl> + } <nl> + throw Throwables . propagate ( t ) ; <nl> + } <nl> + finally <nl> + { <nl> + controller . close ( ) ; <nl> + <nl> + try <nl> + { <nl> + iter . close ( ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + private static class UpgradeController extends CompactionController <nl> + { <nl> + public UpgradeController ( ColumnFamilyStore cfs ) <nl> + { <nl> + super ( cfs , Integer . MAX _ VALUE ) ; <nl> + } <nl> + <nl> + @ Override <nl> + public boolean shouldPurge ( DecoratedKey key , long delTimestamp ) <nl> + { <nl> + return false ; <nl> + } <nl> + } <nl> + } <nl> + <nl> diff - - git a / src / java / org / apache / cassandra / tools / StandaloneUpgrader . java b / src / java / org / apache / cassandra / tools / StandaloneUpgrader . java <nl> new file mode 100644 <nl> index 0000000 . . 357e99c <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / tools / StandaloneUpgrader . java <nl> @ @ - 0 , 0 + 1 , 223 @ @ <nl> + / * * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , <nl> + * software distributed under the License is distributed on an <nl> + * " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY <nl> + * KIND , either express or implied . See the License for the <nl> + * specific language governing permissions and limitations <nl> + * under the License . <nl> + * / <nl> + package org . apache . cassandra . tools ; <nl> + <nl> + import java . io . File ; <nl> + import java . io . IOException ; <nl> + import java . util . * ; <nl> + <nl> + import com . google . common . base . Throwables ; <nl> + <nl> + import org . apache . commons . cli . * ; <nl> + <nl> + import org . apache . cassandra . config . DatabaseDescriptor ; <nl> + import org . apache . cassandra . config . Schema ; <nl> + import org . apache . cassandra . db . ColumnFamilyStore ; <nl> + import org . apache . cassandra . db . Directories ; <nl> + import org . apache . cassandra . db . Table ; <nl> + import org . apache . cassandra . db . compaction . Upgrader ; <nl> + import org . apache . cassandra . io . sstable . * ; <nl> + import org . apache . cassandra . service . CassandraDaemon ; <nl> + import org . apache . cassandra . utils . OutputHandler ; <nl> + <nl> + import static org . apache . cassandra . tools . BulkLoader . CmdLineOptions ; <nl> + <nl> + public class StandaloneUpgrader <nl> + { <nl> + static <nl> + { <nl> + CassandraDaemon . initLog4j ( ) ; <nl> + } <nl> + <nl> + private static final String TOOL _ NAME = " sstableupgrade " ; <nl> + private static final String DEBUG _ OPTION = " debug " ; <nl> + private static final String HELP _ OPTION = " help " ; <nl> + <nl> + public static void main ( String args [ ] ) throws IOException <nl> + { <nl> + Options options = Options . parseArgs ( args ) ; <nl> + try <nl> + { <nl> + / / load keyspace descriptions . <nl> + DatabaseDescriptor . loadSchemas ( ) ; <nl> + <nl> + if ( Schema . instance . getCFMetaData ( options . keyspace , options . cf ) = = null ) <nl> + throw new IllegalArgumentException ( String . format ( " Unknown keyspace / columnFamily % s . % s " , <nl> + options . keyspace , <nl> + options . cf ) ) ; <nl> + <nl> + Table table = Table . openWithoutSSTables ( options . keyspace ) ; <nl> + ColumnFamilyStore cfs = table . getColumnFamilyStore ( options . cf ) ; <nl> + <nl> + OutputHandler handler = new OutputHandler . SystemOutput ( false , options . debug ) ; <nl> + Directories . SSTableLister lister = cfs . directories . sstableLister ( ) ; <nl> + if ( options . snapshot ! = null ) <nl> + lister . onlyBackups ( true ) . snapshots ( options . snapshot ) ; <nl> + else <nl> + lister . includeBackups ( false ) ; <nl> + <nl> + Collection < SSTableReader > readers = new ArrayList < SSTableReader > ( ) ; <nl> + <nl> + / / Upgrade sstables <nl> + for ( Map . Entry < Descriptor , Set < Component > > entry : lister . list ( ) . entrySet ( ) ) <nl> + { <nl> + Set < Component > components = entry . getValue ( ) ; <nl> + if ( ! components . contains ( Component . DATA ) | | ! components . contains ( Component . PRIMARY _ INDEX ) ) <nl> + continue ; <nl> + <nl> + try <nl> + { <nl> + SSTableReader sstable = SSTableReader . openNoValidation ( entry . getKey ( ) , components , cfs . metadata ) ; <nl> + if ( sstable . descriptor . version . equals ( Descriptor . Version . CURRENT ) ) <nl> + continue ; <nl> + readers . add ( sstable ) ; <nl> + } <nl> + catch ( Exception e ) <nl> + { <nl> + System . err . println ( String . format ( " Error Loading % s : % s " , entry . getKey ( ) , e . getMessage ( ) ) ) ; <nl> + if ( options . debug ) <nl> + e . printStackTrace ( System . err ) ; <nl> + <nl> + continue ; <nl> + } <nl> + } <nl> + <nl> + int numSSTables = readers . size ( ) ; <nl> + handler . output ( " Found " + numSSTables + " sstables that need upgrading . " ) ; <nl> + <nl> + for ( SSTableReader sstable : readers ) <nl> + { <nl> + try <nl> + { <nl> + Upgrader upgrader = new Upgrader ( cfs , sstable , handler ) ; <nl> + upgrader . upgrade ( ) ; <nl> + <nl> + sstable . markCompacted ( ) ; <nl> + sstable . releaseReference ( ) ; <nl> + } <nl> + catch ( Exception e ) <nl> + { <nl> + System . err . println ( String . format ( " Error upgrading % s : % s " , sstable , e . getMessage ( ) ) ) ; <nl> + if ( options . debug ) <nl> + e . printStackTrace ( System . err ) ; <nl> + } <nl> + } <nl> + <nl> + SSTableDeletingTask . waitForDeletions ( ) ; <nl> + System . exit ( 0 ) ; <nl> + } <nl> + catch ( Exception e ) <nl> + { <nl> + System . err . println ( e . getMessage ( ) ) ; <nl> + if ( options . debug ) <nl> + e . printStackTrace ( System . err ) ; <nl> + System . exit ( 1 ) ; <nl> + } <nl> + } <nl> + <nl> + private static class Options <nl> + { <nl> + public final String keyspace ; <nl> + public final String cf ; <nl> + public final String snapshot ; <nl> + <nl> + public boolean debug ; <nl> + <nl> + private Options ( String keyspace , String cf , String snapshot ) <nl> + { <nl> + this . keyspace = keyspace ; <nl> + this . cf = cf ; <nl> + this . snapshot = snapshot ; <nl> + } <nl> + <nl> + public static Options parseArgs ( String cmdArgs [ ] ) <nl> + { <nl> + CommandLineParser parser = new GnuParser ( ) ; <nl> + CmdLineOptions options = getCmdLineOptions ( ) ; <nl> + try <nl> + { <nl> + CommandLine cmd = parser . parse ( options , cmdArgs , false ) ; <nl> + <nl> + if ( cmd . hasOption ( HELP _ OPTION ) ) <nl> + { <nl> + printUsage ( options ) ; <nl> + System . exit ( 0 ) ; <nl> + } <nl> + <nl> + String [ ] args = cmd . getArgs ( ) ; <nl> + if ( args . length > = 4 | | args . length < 2 ) <nl> + { <nl> + String msg = args . length < 2 ? " Missing arguments " : " Too many arguments " ; <nl> + errorMsg ( msg , options ) ; <nl> + System . exit ( 1 ) ; <nl> + } <nl> + <nl> + String keyspace = args [ 0 ] ; <nl> + String cf = args [ 1 ] ; <nl> + String snapshot = null ; <nl> + if ( args . length = = 3 ) <nl> + snapshot = args [ 2 ] ; <nl> + <nl> + Options opts = new Options ( keyspace , cf , snapshot ) ; <nl> + <nl> + opts . debug = cmd . hasOption ( DEBUG _ OPTION ) ; <nl> + <nl> + return opts ; <nl> + } <nl> + catch ( ParseException e ) <nl> + { <nl> + errorMsg ( e . getMessage ( ) , options ) ; <nl> + return null ; <nl> + } <nl> + } <nl> + <nl> + private static void errorMsg ( String msg , CmdLineOptions options ) <nl> + { <nl> + System . err . println ( msg ) ; <nl> + printUsage ( options ) ; <nl> + System . exit ( 1 ) ; <nl> + } <nl> + <nl> + private static CmdLineOptions getCmdLineOptions ( ) <nl> + { <nl> + CmdLineOptions options = new CmdLineOptions ( ) ; <nl> + options . addOption ( null , DEBUG _ OPTION , " display stack traces " ) ; <nl> + options . addOption ( " h " , HELP _ OPTION , " display this help message " ) ; <nl> + return options ; <nl> + } <nl> + <nl> + public static void printUsage ( CmdLineOptions options ) <nl> + { <nl> + String usage = String . format ( " % s [ options ] < keyspace > < cf > [ snapshot ] " , TOOL _ NAME ) ; <nl> + StringBuilder header = new StringBuilder ( ) ; <nl> + header . append ( " - - \ n " ) ; <nl> + header . append ( " Upgrade the sstables in the given cf ( or snapshot ) to the current version of Cassandra . " ) ; <nl> + header . append ( " This operation will rewrite the sstables in the specified cf to match the " ) ; <nl> + header . append ( " currently installed version of Cassandra . \ n " ) ; <nl> + header . append ( " The snapshot option will only upgrade the specified snapshot . Upgrading " ) ; <nl> + header . append ( " snapshots is required before attempting to restore a snapshot taken in a " ) ; <nl> + header . append ( " major version older than the major version Cassandra is currently running . " ) ; <nl> + header . append ( " This will replace the files in the given snapshot as well as break any " ) ; <nl> + header . append ( " hard links to live sstables . " ) ; <nl> + header . append ( " \ n - - \ n " ) ; <nl> + header . append ( " Options are : " ) ; <nl> + new HelpFormatter ( ) . printHelp ( usage , header . toString ( ) , options , " " ) ; <nl> + } <nl> + } <nl> + } <nl> +

TEST DIFF:
diff - - git a / doc / cql3 / CQL . textile b / doc / cql3 / CQL . textile 
 index f6208bf . . bedd189 100644 
 - - - a / doc / cql3 / CQL . textile 
 + + + b / doc / cql3 / CQL . textile 
 @ @ - 614 , 7 + 614 , 11 @ @ The @ BATCH @ statement group multiple modification statements ( insertions / updates 
 # It saves network round - trips between the client and the server ( and sometimes between the server coordinator and the replicas ) when batching multiple updates . 
 # All updates in a @ BATCH @ belonging to a given partition key are performed in isolation . 
 # By default , all operations in the batch are performed atomically . See the notes on " @ UNLOGGED @ " : # unloggedBatch for more details . 
 - Note however that the @ BATCH @ statement only allows @ UPDATE @ , @ INSERT @ and @ DELETE @ statements and is _ not _ a full analogue for SQL transactions . 
 + 
 + Note that : 
 + * @ BATCH @ statements may only contain @ UPDATE @ , @ INSERT @ and @ DELETE @ statements . 
 + * Batches are _ not _ a full analogue for SQL transactions . 
 + * If a timestamp is not specified for each operation , then all operations will be applied with the same timestamp . Due to Cassandra ' s conflict resolution procedure in the case of " timestamp ties " : http : / / wiki . apache . org / cassandra / FAQ # clocktie , operations may be applied in an order that is different from the order they are listed in the @ BATCH @ statement . To force a particular operation ordering , you must specify per - operation timestamps . 
 
 h4 ( # unloggedBatch ) . @ UNLOGGED @ 


NEAREST DIFF:
diff - - git a / NEWS . txt b / NEWS . txt 
 index 5cb06da . . dbc9aab 100644 
 - - - a / NEWS . txt 
 + + + b / NEWS . txt 
 @ @ - 8 , 6 + 8 , 11 @ @ upgrade , just in case you need to roll back to the previous version . 
 ( Cassandra version X + 1 will always be able to read data files created 
 by version X , but the inverse is not necessarily the case . ) 
 
 + When upgrading major versions of Cassandra , you will be unable to 
 + restore snapshots created with the previous major version using the 
 + ' sstableloader ' tool . You can upgrade the file format of your snapshots 
 + using the provided ' sstableupgrade ' tool . 
 + 
 1 . 2 . 6 
 = = = = = 
 
 @ @ - 217 , 7 + 222 , 7 @ @ Features 
 - num _ tokens can now be specified in cassandra . yaml . This defines the 
 number of tokens assigned to the host on the ring ( default : 1 ) . 
 Also specifying initial _ token will override any num _ tokens setting . 
 - - disk _ failure _ policy allows blacklisting failed disks in JBOD 
 + - disk _ failure _ policy allows blacklisting failed disks in JBOD 
 configuration instead of erroring out indefinitely 
 - event tracing can be configured per - connection ( " trace _ next _ query " ) 
 or globally / probabilistically ( " nodetool settraceprobability " ) 
 @ @ - 314 , 7 + 319 , 7 @ @ Upgrading 
 throw an InvalidRequestException when used for reads . ( Previous 
 versions would silently perform a ONE read for range queries ; 
 single - row and multiget reads already rejected ANY . ) 
 - - The largest mutation batch accepted by the commitlog is now 128MB . 
 + - The largest mutation batch accepted by the commitlog is now 128MB . 
 ( In practice , batches larger than ~ 10MB always caused poor 
 performance due to load volatility and GC promotion failures . ) 
 Larger batches will continue to be accepted but will not be 
 @ @ - 514 , 7 + 519 , 7 @ @ Upgrading 
 - Upgrading from version 0 . 7 . 1 + or 0 . 8 . 2 + can be done with a rolling 
 restart , one node at a time . ( 0 . 8 . 0 or 0 . 8 . 1 are NOT network - compatible 
 with 1 . 0 : upgrade to the most recent 0 . 8 release first . ) 
 - You do not need to bring down the whole cluster at once . 
 + You do not need to bring down the whole cluster at once . 
 - After upgrading , run nodetool scrub against each node before running 
 repair , moving nodes , or adding new ones . 
 - CQL inserts / updates now generate microsecond resolution timestamps 
 @ @ - 695 , 7 + 700 , 7 @ @ Upgrading 
 - - - - - - - - - 
 - Upgrading from version 0 . 7 . 1 or later can be done with a rolling 
 restart , one node at a time . You do not need to bring down the 
 - whole cluster at once . 
 + whole cluster at once . 
 - After upgrading , run nodetool scrub against each node before running 
 repair , moving nodes , or adding new ones . 
 - Running nodetool drain before shutting down the 0 . 7 node is 
 @ @ - 706 , 8 + 711 , 8 @ @ Upgrading 
 to use your 0 . 7 clients . 
 - Avro record classes used in map / reduce and Hadoop streaming code have 
 been removed . Map / reduce can be switched to Thrift by changing 
 - org . apache . cassandra . avro in import statements to 
 - org . apache . cassandra . thrift ( no class names change ) . Streaming support 
 + org . apache . cassandra . avro in import statements to 
 + org . apache . cassandra . thrift ( no class names change ) . Streaming support 
 has been removed for the time being . 
 - The loadbalance command has been removed from nodetool . For similar 
 behavior , decommission then rebootstrap with empty initial _ token . 
 @ @ - 721 , 15 + 726 , 15 @ @ Features 
 - - - - - - - - 
 - added CQL client API and JDBC / DBAPI2 - compliant drivers for Java and 
 Python , respectively ( see : drivers / subdirectory and doc / cql ) 
 - - added distributed Counters feature ; 
 + - added distributed Counters feature ; 
 see http : / / wiki . apache . org / cassandra / Counters 
 - optional intranode encryption ; see comments around ' encryption _ options ' 
 in cassandra . yaml 
 - - compaction multithreading and rate - limiting ; see 
 + - compaction multithreading and rate - limiting ; see 
 ' concurrent _ compactors ' and ' compaction _ throughput _ mb _ per _ sec ' in 
 cassandra . yaml 
 - cassandra will limit total memtable memory usage to 1 / 3 of the heap 
 - by default . This can be ajusted or disabled with the 
 + by default . This can be ajusted or disabled with the 
 memtable _ total _ space _ in _ mb option . The old per - ColumnFamily 
 throughput , operations , and age settings are still respected but 
 will be removed in a future major release once we are satisfied that 
 @ @ - 738 , 7 + 743 , 7 @ @ Features 
 Tools 
 - - - - - 
 - stress and py _ stress moved from contrib / to tools / 
 - - clustertool was removed ( see 
 + - clustertool was removed ( see 
 https : / / issues . apache . org / jira / browse / CASSANDRA - 2607 for examples 
 of how to script nodetool across the cluster instead ) 
 
 @ @ - 814 , 7 + 819 , 7 @ @ Upgrading 
 - 0 . 7 . 1 and 0 . 7 . 2 shipped with a bug that caused incorrect row - level 
 bloom filters to be generated when compacting sstables generated 
 with earlier versions . This would manifest in IOExceptions during 
 - column name - based queries . 0 . 7 . 3 provides " nodetool scrub " to 
 + column name - based queries . 0 . 7 . 3 provides " nodetool scrub " to 
 rebuild sstables with correct bloom filters , with no data lost . 
 ( If your cluster was never on 0 . 7 . 0 or earlier , you don ' t have to 
 worry about this . ) Note that nodetool scrub will snapshot your 
 @ @ - 862 , 10 + 867 , 10 @ @ Features 
 - Row size limit increased from 2GB to 2 billion columns . rows 
 are no longer read into memory during compaction . 
 - Keyspace and ColumnFamily definitions may be added and modified live 
 - - Streaming data for repair or node movement no longer requires 
 + - Streaming data for repair or node movement no longer requires 
 anticompaction step first 
 - - NetworkTopologyStrategy ( formerly DatacenterShardStrategy ) is ready for 
 - use , enabling ConsistencyLevel . DCQUORUM and DCQUORUMSYNC . See comments 
 + - NetworkTopologyStrategy ( formerly DatacenterShardStrategy ) is ready for 
 + use , enabling ConsistencyLevel . DCQUORUM and DCQUORUMSYNC . See comments 
 in ` cassandra . yaml . ` 
 - Optional per - Column time - to - live field allows expiring data without 
 have to issue explicit remove commands 
 @ @ - 879 , 9 + 884 , 9 @ @ Features 
 - Optional round - robin scheduling between keyspaces for multitenant 
 clusters 
 - Dynamic endpoint snitch mitigates the impact of impaired nodes 
 - - New ` IntegerType ` , faster than LongType and allows integers of 
 + - New ` IntegerType ` , faster than LongType and allows integers of 
 both less and more bits than Long ' s 64 
 - - A revamped authentication system that decouples authorization and 
 + - A revamped authentication system that decouples authorization and 
 allows finer - grained control of resources . 
 
 Upgrading 
 @ @ - 893 , 9 + 898 , 9 @ @ Upgrading 
 The Cassandra inter - node protocol is incompatible with 0 . 6 . x 
 releases ( and with 0 . 7 beta1 ) , meaning you will have to bring your 
 cluster down prior to upgrading : you cannot mix 0 . 6 and 0 . 7 nodes . 
 - 
 + 
 The hints schema was changed from 0 . 6 to 0 . 7 . Cassandra automatically 
 - snapshots and then truncates the hints column family as part of 
 + snapshots and then truncates the hints column family as part of 
 starting up 0 . 7 for the first time . 
 
 Keyspace and ColumnFamily definitions are stored in the system 
 @ @ - 904 , 13 + 909 , 13 @ @ Upgrading 
 The process to upgrade is : 
 1 ) run " nodetool drain " on _ each _ 0 . 6 node . When drain finishes ( log 
 message " Node is drained " appears ) , stop the process . 
 - 2 ) Convert your storage - conf . xml to the new cassandra . yaml using 
 - " bin / config - converter " . 
 + 2 ) Convert your storage - conf . xml to the new cassandra . yaml using 
 + " bin / config - converter " . 
 3 ) Rename any of your keyspace or column family names that do not adhere 
 to the ' ^ \ w + ' regex convention . 
 4 ) Start up your cluster with the 0 . 7 version . 
 - 5 ) Initialize your Keyspace and ColumnFamily definitions using 
 - " bin / schematool < host > < jmxport > import " . _ You only need to do 
 + 5 ) Initialize your Keyspace and ColumnFamily definitions using 
 + " bin / schematool < host > < jmxport > import " . _ You only need to do 
 this to one node _ . 
 
 Thrift API 
 @ @ - 935 , 7 + 940 , 7 @ @ Configuraton 
 - - - - - - - - - - - - 
 - Configuration file renamed to cassandra . yaml and log4j . properties to 
 log4j - server . properties 
 - - PropertyFileSnitch configuration file renamed to 
 + - PropertyFileSnitch configuration file renamed to 
 cassandra - topology . properties 
 - The ThriftAddress and ThriftPort directives have been renamed to 
 RPCAddress and RPCPort respectively . 
 @ @ - 952 , 7 + 957 , 7 @ @ Configuraton 
 one node _ . 
 - In addition to an authenticator , an authority must be configured as 
 well . Users of SimpleAuthenticator should use SimpleAuthority for this 
 - value ( the default is AllowAllAuthority , which corresponds with 
 + value ( the default is AllowAllAuthority , which corresponds with 
 AllowAllAuthenticator ) . 
 - The format of access . properties has changed , see the sample configuration 
 conf / access . properties for documentation on the new format . 
 @ @ - 1011 , 7 + 1016 , 7 @ @ Features 
 Configuraton 
 - - - - - - - - - - - - 
 - MemtableSizeInMB has been replaced by MemtableThroughputInMB which 
 - triggers a memtable flush when the specified amount of data has 
 + triggers a memtable flush when the specified amount of data has 
 been written , including overwrites . 
 - MemtableObjectCountInMillions has been replaced by the 
 MemtableOperationsInMillions directive which causes a memtable flush 
 @ @ - 1047 , 7 + 1052 , 7 @ @ JMX metrics 
 progress of the current compaction has been added . 
 - commitlog JMX metrics are moved to org . apache . cassandra . db . Commitlog 
 - progress of data streaming during bootstrap , loadbalance , or other 
 - data migration , is available under 
 + data migration , is available under 
 org . apache . cassandra . streaming . StreamingService . 
 See http : / / wiki . apache . org / cassandra / Streaming for details . 
 
 @ @ - 1061 , 8 + 1066 , 8 @ @ Installation / Upgrade 
 0 . 5 . 0 
 = = = = = 
 
 - 0 . The commitlog format has changed ( but sstable format has not ) . 
 - When upgrading from 0 . 4 , empty the commitlog either by running 
 + 0 . The commitlog format has changed ( but sstable format has not ) . 
 + When upgrading from 0 . 4 , empty the commitlog either by running 
 bin / nodeprobe flush on each machine and waiting for the flush to finish , 
 or simply remove the commitlog directory if you only have test data . 
 ( If more writes come in after the flush command , starting 0 . 5 will error 
 @ @ - 1083 , 7 + 1088 , 7 @ @ Installation / Upgrade 
 
 3 . Configuration : 
 - Added " comment " field to ColumnFamily definition . 
 - - Added MemtableFlushAfterMinutes , a global replacement for the 
 + - Added MemtableFlushAfterMinutes , a global replacement for the 
 old per - CF FlushPeriodInMinutes setting 
 - Key cache settings 
 
 @ @ - 1121 , 7 + 1126 , 7 @ @ Installation / Upgrade 
 create and modify ColumnFamilies at will without worrying about 
 collisions with others in the same cluster . 
 
 - 3 . Many Thrift API changes and documentation . See 
 + 3 . Many Thrift API changes and documentation . See 
 http : / / wiki . apache . org / cassandra / API 
 
 4 . Removed the web interface in favor of JMX and bin / nodeprobe , which 
 @ @ - 1166 , 4 + 1171 , 4 @ @ key in a given ColumnFamily ) is limited by available memory , because 
 compaction deserializes each row before merging . 
 
 See https : / / issues . apache . org / jira / browse / CASSANDRA - 16 
 - 
 + 
 diff - - git a / bin / sstableupgrade b / bin / sstableupgrade 
 new file mode 100755 
 index 0000000 . . b5ddd6a 
 - - - / dev / null 
 + + + b / bin / sstableupgrade 
 @ @ - 0 , 0 + 1 , 55 @ @ 
 + # ! / bin / sh 
 + 
 + # Licensed to the Apache Software Foundation ( ASF ) under one 
 + # or more contributor license agreements . See the NOTICE file 
 + # distributed with this work for additional information 
 + # regarding copyright ownership . The ASF licenses this file 
 + # to you under the Apache License , Version 2 . 0 ( the 
 + # " License " ) ; you may not use this file except in compliance 
 + # with the License . You may obtain a copy of the License at 
 + # 
 + # http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + # 
 + # Unless required by applicable law or agreed to in writing , software 
 + # distributed under the License is distributed on an " AS IS " BASIS , 
 + # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + # See the License for the specific language governing permissions and 
 + # limitations under the License . 
 + 
 + if [ " x $ CASSANDRA _ INCLUDE " = " x " ] ; then 
 + for include in / usr / share / cassandra / cassandra . in . sh \ 
 + / usr / local / share / cassandra / cassandra . in . sh \ 
 + / opt / cassandra / cassandra . in . sh \ 
 + ~ / . cassandra . in . sh \ 
 + ` dirname $ 0 ` / cassandra . in . sh ; do 
 + if [ - r $ include ] ; then 
 + . $ include 
 + break 
 + fi 
 + done 
 + elif [ - r $ CASSANDRA _ INCLUDE ] ; then 
 + . $ CASSANDRA _ INCLUDE 
 + fi 
 + 
 + # Use JAVA _ HOME if set , otherwise look for java in PATH 
 + if [ - x $ JAVA _ HOME / bin / java ] ; then 
 + JAVA = $ JAVA _ HOME / bin / java 
 + else 
 + JAVA = ` which java ` 
 + fi 
 + 
 + if [ - z $ CLASSPATH ] ; then 
 + echo " You must set the CLASSPATH var " > & 2 
 + exit 1 
 + fi 
 + 
 + if [ " x $ MAX _ HEAP _ SIZE " = " x " ] ; then 
 + MAX _ HEAP _ SIZE = " 256M " 
 + fi 
 + 
 + $ JAVA - ea - cp $ CLASSPATH - Xmx $ MAX _ HEAP _ SIZE \ 
 + - Dlog4j . configuration = log4j - tools . properties \ 
 + org . apache . cassandra . tools . StandaloneUpgrader " $ @ " 
 + 
 + # vi : ai sw = 4 ts = 4 tw = 0 et 
 + 
 diff - - git a / debian / cassandra . install b / debian / cassandra . install 
 index 6d7ba8f . . a504b78 100644 
 - - - a / debian / cassandra . install 
 + + + b / debian / cassandra . install 
 @ @ - 17 , 6 + 17 , 7 @ @ bin / sstablekeys usr / bin 
 bin / sstableloader usr / bin 
 bin / cqlsh usr / bin 
 bin / sstablescrub usr / bin 
 + bin / sstableupgrade usr / bin 
 bin / cassandra - shuffle usr / bin 
 tools / bin / cassandra - stress usr / bin 
 tools / bin / token - generator usr / bin 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / Upgrader . java b / src / java / org / apache / cassandra / db / compaction / Upgrader . java 
 new file mode 100644 
 index 0000000 . . e7211ba 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / db / compaction / Upgrader . java 
 @ @ - 0 , 0 + 1 , 167 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , software 
 + * distributed under the License is distributed on an " AS IS " BASIS , 
 + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + * See the License for the specific language governing permissions and 
 + * limitations under the License . 
 + * / 
 + package org . apache . cassandra . db . compaction ; 
 + 
 + import java . io . File ; 
 + import java . io . IOException ; 
 + import java . io . IOError ; 
 + import java . util . * ; 
 + 
 + import com . google . common . base . Throwables ; 
 + 
 + import org . apache . cassandra . config . DatabaseDescriptor ; 
 + import org . apache . cassandra . db . ColumnFamilyStore ; 
 + import org . apache . cassandra . db . DecoratedKey ; 
 + import org . apache . cassandra . db . RowIndexEntry ; 
 + import org . apache . cassandra . db . compaction . AbstractCompactedRow ; 
 + import org . apache . cassandra . db . compaction . AbstractCompactionStrategy ; 
 + import org . apache . cassandra . db . compaction . AbstractCompactionIterable ; 
 + import org . apache . cassandra . db . compaction . CompactionIterable ; 
 + import org . apache . cassandra . db . compaction . CompactionController ; 
 + import org . apache . cassandra . db . compaction . CompactionManager ; 
 + import org . apache . cassandra . db . compaction . CompactionTask ; 
 + import org . apache . cassandra . db . compaction . OperationType ; 
 + import org . apache . cassandra . io . sstable . * ; 
 + import org . apache . cassandra . io . util . RandomAccessReader ; 
 + import org . apache . cassandra . utils . CloseableIterator ; 
 + import org . apache . cassandra . utils . OutputHandler ; 
 + 
 + public class Upgrader 
 + { 
 + private final ColumnFamilyStore cfs ; 
 + private final SSTableReader sstable ; 
 + private final Collection < SSTableReader > toUpgrade ; 
 + private final File directory ; 
 + 
 + private final OperationType compactionType = OperationType . UPGRADE _ SSTABLES ; 
 + private final CompactionController controller ; 
 + private final AbstractCompactionStrategy strategy ; 
 + private final long estimatedRows ; 
 + 
 + private final int gcBefore = CompactionManager . NO _ GC ; 
 + 
 + private final OutputHandler outputHandler ; 
 + 
 + public Upgrader ( ColumnFamilyStore cfs , SSTableReader sstable , OutputHandler outputHandler ) 
 + { 
 + this . cfs = cfs ; 
 + this . sstable = sstable ; 
 + this . toUpgrade = Collections . singletonList ( sstable ) ; 
 + this . outputHandler = outputHandler ; 
 + 
 + this . directory = new File ( sstable . getFilename ( ) ) . getParentFile ( ) ; 
 + 
 + this . controller = new UpgradeController ( cfs ) ; 
 + 
 + this . strategy = cfs . getCompactionStrategy ( ) ; 
 + long estimatedTotalKeys = Math . max ( DatabaseDescriptor . getIndexInterval ( ) , SSTableReader . getApproximateKeyCount ( toUpgrade ) ) ; 
 + long estimatedSSTables = Math . max ( 1 , SSTable . getTotalBytes ( this . toUpgrade ) / strategy . getMaxSSTableSize ( ) ) ; 
 + this . estimatedRows = ( long ) Math . ceil ( ( double ) estimatedTotalKeys / estimatedSSTables ) ; 
 + } 
 + 
 + private SSTableWriter createCompactionWriter ( ) 
 + { 
 + SSTableMetadata . Collector sstableMetadataCollector = SSTableMetadata . createCollector ( ) ; 
 + 
 + / / Get the max timestamp of the precompacted sstables 
 + / / and adds generation of live ancestors 
 + for ( SSTableReader sstable : toUpgrade ) 
 + { 
 + sstableMetadataCollector . addAncestor ( sstable . descriptor . generation ) ; 
 + for ( Integer i : sstable . getAncestors ( ) ) 
 + { 
 + if ( new File ( sstable . descriptor . withGeneration ( i ) . filenameFor ( Component . DATA ) ) . exists ( ) ) 
 + sstableMetadataCollector . addAncestor ( i ) ; 
 + } 
 + } 
 + 
 + return new SSTableWriter ( cfs . getTempSSTablePath ( directory ) , estimatedRows , cfs . metadata , cfs . partitioner , sstableMetadataCollector ) ; 
 + } 
 + 
 + public void upgrade ( ) 
 + { 
 + outputHandler . output ( " Upgrading " + sstable ) ; 
 + 
 + 
 + AbstractCompactionIterable ci = new CompactionIterable ( compactionType , strategy . getScanners ( this . toUpgrade ) , controller ) ; 
 + 
 + CloseableIterator < AbstractCompactedRow > iter = ci . iterator ( ) ; 
 + 
 + Collection < SSTableReader > sstables = new ArrayList < SSTableReader > ( ) ; 
 + Collection < SSTableWriter > writers = new ArrayList < SSTableWriter > ( ) ; 
 + 
 + try 
 + { 
 + SSTableWriter writer = createCompactionWriter ( ) ; 
 + writers . add ( writer ) ; 
 + while ( iter . hasNext ( ) ) 
 + { 
 + AbstractCompactedRow row = iter . next ( ) ; 
 + 
 + RowIndexEntry indexEntry = writer . append ( row ) ; 
 + } 
 + 
 + long maxAge = CompactionTask . getMaxDataAge ( this . toUpgrade ) ; 
 + for ( SSTableWriter completedWriter : writers ) 
 + sstables . add ( completedWriter . closeAndOpenReader ( maxAge ) ) ; 
 + 
 + outputHandler . output ( " Upgrade of " + sstable + " complete . " ) ; 
 + 
 + } 
 + catch ( Throwable t ) 
 + { 
 + for ( SSTableWriter writer : writers ) 
 + writer . abort ( ) ; 
 + / / also remove already completed SSTables 
 + for ( SSTableReader sstable : sstables ) 
 + { 
 + sstable . markCompacted ( ) ; 
 + sstable . releaseReference ( ) ; 
 + } 
 + throw Throwables . propagate ( t ) ; 
 + } 
 + finally 
 + { 
 + controller . close ( ) ; 
 + 
 + try 
 + { 
 + iter . close ( ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new RuntimeException ( e ) ; 
 + } 
 + } 
 + } 
 + 
 + private static class UpgradeController extends CompactionController 
 + { 
 + public UpgradeController ( ColumnFamilyStore cfs ) 
 + { 
 + super ( cfs , Integer . MAX _ VALUE ) ; 
 + } 
 + 
 + @ Override 
 + public boolean shouldPurge ( DecoratedKey key , long delTimestamp ) 
 + { 
 + return false ; 
 + } 
 + } 
 + } 
 + 
 diff - - git a / src / java / org / apache / cassandra / tools / StandaloneUpgrader . java b / src / java / org / apache / cassandra / tools / StandaloneUpgrader . java 
 new file mode 100644 
 index 0000000 . . 357e99c 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / tools / StandaloneUpgrader . java 
 @ @ - 0 , 0 + 1 , 223 @ @ 
 + / * * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , 
 + * software distributed under the License is distributed on an 
 + * " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY 
 + * KIND , either express or implied . See the License for the 
 + * specific language governing permissions and limitations 
 + * under the License . 
 + * / 
 + package org . apache . cassandra . tools ; 
 + 
 + import java . io . File ; 
 + import java . io . IOException ; 
 + import java . util . * ; 
 + 
 + import com . google . common . base . Throwables ; 
 + 
 + import org . apache . commons . cli . * ; 
 + 
 + import org . apache . cassandra . config . DatabaseDescriptor ; 
 + import org . apache . cassandra . config . Schema ; 
 + import org . apache . cassandra . db . ColumnFamilyStore ; 
 + import org . apache . cassandra . db . Directories ; 
 + import org . apache . cassandra . db . Table ; 
 + import org . apache . cassandra . db . compaction . Upgrader ; 
 + import org . apache . cassandra . io . sstable . * ; 
 + import org . apache . cassandra . service . CassandraDaemon ; 
 + import org . apache . cassandra . utils . OutputHandler ; 
 + 
 + import static org . apache . cassandra . tools . BulkLoader . CmdLineOptions ; 
 + 
 + public class StandaloneUpgrader 
 + { 
 + static 
 + { 
 + CassandraDaemon . initLog4j ( ) ; 
 + } 
 + 
 + private static final String TOOL _ NAME = " sstableupgrade " ; 
 + private static final String DEBUG _ OPTION = " debug " ; 
 + private static final String HELP _ OPTION = " help " ; 
 + 
 + public static void main ( String args [ ] ) throws IOException 
 + { 
 + Options options = Options . parseArgs ( args ) ; 
 + try 
 + { 
 + / / load keyspace descriptions . 
 + DatabaseDescriptor . loadSchemas ( ) ; 
 + 
 + if ( Schema . instance . getCFMetaData ( options . keyspace , options . cf ) = = null ) 
 + throw new IllegalArgumentException ( String . format ( " Unknown keyspace / columnFamily % s . % s " , 
 + options . keyspace , 
 + options . cf ) ) ; 
 + 
 + Table table = Table . openWithoutSSTables ( options . keyspace ) ; 
 + ColumnFamilyStore cfs = table . getColumnFamilyStore ( options . cf ) ; 
 + 
 + OutputHandler handler = new OutputHandler . SystemOutput ( false , options . debug ) ; 
 + Directories . SSTableLister lister = cfs . directories . sstableLister ( ) ; 
 + if ( options . snapshot ! = null ) 
 + lister . onlyBackups ( true ) . snapshots ( options . snapshot ) ; 
 + else 
 + lister . includeBackups ( false ) ; 
 + 
 + Collection < SSTableReader > readers = new ArrayList < SSTableReader > ( ) ; 
 + 
 + / / Upgrade sstables 
 + for ( Map . Entry < Descriptor , Set < Component > > entry : lister . list ( ) . entrySet ( ) ) 
 + { 
 + Set < Component > components = entry . getValue ( ) ; 
 + if ( ! components . contains ( Component . DATA ) | | ! components . contains ( Component . PRIMARY _ INDEX ) ) 
 + continue ; 
 + 
 + try 
 + { 
 + SSTableReader sstable = SSTableReader . openNoValidation ( entry . getKey ( ) , components , cfs . metadata ) ; 
 + if ( sstable . descriptor . version . equals ( Descriptor . Version . CURRENT ) ) 
 + continue ; 
 + readers . add ( sstable ) ; 
 + } 
 + catch ( Exception e ) 
 + { 
 + System . err . println ( String . format ( " Error Loading % s : % s " , entry . getKey ( ) , e . getMessage ( ) ) ) ; 
 + if ( options . debug ) 
 + e . printStackTrace ( System . err ) ; 
 + 
 + continue ; 
 + } 
 + } 
 + 
 + int numSSTables = readers . size ( ) ; 
 + handler . output ( " Found " + numSSTables + " sstables that need upgrading . " ) ; 
 + 
 + for ( SSTableReader sstable : readers ) 
 + { 
 + try 
 + { 
 + Upgrader upgrader = new Upgrader ( cfs , sstable , handler ) ; 
 + upgrader . upgrade ( ) ; 
 + 
 + sstable . markCompacted ( ) ; 
 + sstable . releaseReference ( ) ; 
 + } 
 + catch ( Exception e ) 
 + { 
 + System . err . println ( String . format ( " Error upgrading % s : % s " , sstable , e . getMessage ( ) ) ) ; 
 + if ( options . debug ) 
 + e . printStackTrace ( System . err ) ; 
 + } 
 + } 
 + 
 + SSTableDeletingTask . waitForDeletions ( ) ; 
 + System . exit ( 0 ) ; 
 + } 
 + catch ( Exception e ) 
 + { 
 + System . err . println ( e . getMessage ( ) ) ; 
 + if ( options . debug ) 
 + e . printStackTrace ( System . err ) ; 
 + System . exit ( 1 ) ; 
 + } 
 + } 
 + 
 + private static class Options 
 + { 
 + public final String keyspace ; 
 + public final String cf ; 
 + public final String snapshot ; 
 + 
 + public boolean debug ; 
 + 
 + private Options ( String keyspace , String cf , String snapshot ) 
 + { 
 + this . keyspace = keyspace ; 
 + this . cf = cf ; 
 + this . snapshot = snapshot ; 
 + } 
 + 
 + public static Options parseArgs ( String cmdArgs [ ] ) 
 + { 
 + CommandLineParser parser = new GnuParser ( ) ; 
 + CmdLineOptions options = getCmdLineOptions ( ) ; 
 + try 
 + { 
 + CommandLine cmd = parser . parse ( options , cmdArgs , false ) ; 
 + 
 + if ( cmd . hasOption ( HELP _ OPTION ) ) 
 + { 
 + printUsage ( options ) ; 
 + System . exit ( 0 ) ; 
 + } 
 + 
 + String [ ] args = cmd . getArgs ( ) ; 
 + if ( args . length > = 4 | | args . length < 2 ) 
 + { 
 + String msg = args . length < 2 ? " Missing arguments " : " Too many arguments " ; 
 + errorMsg ( msg , options ) ; 
 + System . exit ( 1 ) ; 
 + } 
 + 
 + String keyspace = args [ 0 ] ; 
 + String cf = args [ 1 ] ; 
 + String snapshot = null ; 
 + if ( args . length = = 3 ) 
 + snapshot = args [ 2 ] ; 
 + 
 + Options opts = new Options ( keyspace , cf , snapshot ) ; 
 + 
 + opts . debug = cmd . hasOption ( DEBUG _ OPTION ) ; 
 + 
 + return opts ; 
 + } 
 + catch ( ParseException e ) 
 + { 
 + errorMsg ( e . getMessage ( ) , options ) ; 
 + return null ; 
 + } 
 + } 
 + 
 + private static void errorMsg ( String msg , CmdLineOptions options ) 
 + { 
 + System . err . println ( msg ) ; 
 + printUsage ( options ) ; 
 + System . exit ( 1 ) ; 
 + } 
 + 
 + private static CmdLineOptions getCmdLineOptions ( ) 
 + { 
 + CmdLineOptions options = new CmdLineOptions ( ) ; 
 + options . addOption ( null , DEBUG _ OPTION , " display stack traces " ) ; 
 + options . addOption ( " h " , HELP _ OPTION , " display this help message " ) ; 
 + return options ; 
 + } 
 + 
 + public static void printUsage ( CmdLineOptions options ) 
 + { 
 + String usage = String . format ( " % s [ options ] < keyspace > < cf > [ snapshot ] " , TOOL _ NAME ) ; 
 + StringBuilder header = new StringBuilder ( ) ; 
 + header . append ( " - - \ n " ) ; 
 + header . append ( " Upgrade the sstables in the given cf ( or snapshot ) to the current version of Cassandra . " ) ; 
 + header . append ( " This operation will rewrite the sstables in the specified cf to match the " ) ; 
 + header . append ( " currently installed version of Cassandra . \ n " ) ; 
 + header . append ( " The snapshot option will only upgrade the specified snapshot . Upgrading " ) ; 
 + header . append ( " snapshots is required before attempting to restore a snapshot taken in a " ) ; 
 + header . append ( " major version older than the major version Cassandra is currently running . " ) ; 
 + header . append ( " This will replace the files in the given snapshot as well as break any " ) ; 
 + header . append ( " hard links to live sstables . " ) ; 
 + header . append ( " \ n - - \ n " ) ; 
 + header . append ( " Options are : " ) ; 
 + new HelpFormatter ( ) . printHelp ( usage , header . toString ( ) , options , " " ) ; 
 + } 
 + } 
 + } 
 +
