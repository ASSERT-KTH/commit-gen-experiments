BLEU SCORE: 0.03089055318156698

TEST MSG: Move batch size error news to 2 . 2 section ( ninja )
GENERATED MSG: Fix trunk NEWS . txt

TEST DIFF (one line): diff - - git a / NEWS . txt b / NEWS . txt <nl> index 2d6d927 . . e8db40d 100644 <nl> - - - a / NEWS . txt <nl> + + + b / NEWS . txt <nl> @ @ - 32 , 6 + 32 , 8 @ @ New features <nl> <nl> New features <nl> - - - - - - - - - - - - <nl> + - Very large batches will now be rejected ( defaults to 50kb ) . This <nl> + can be customized by modifying batch _ size _ fail _ threshold _ in _ kb . <nl> - Selecting columns , scalar functions , UDT fields , writetime or ttl together <nl> with aggregated is now possible . The value returned for the columns , <nl> scalar functions , UDT fields , writetime and ttl will be the ones for <nl> @ @ - 167 , 8 + 169 , 6 @ @ Upgrading <nl> GossipingPropertyFileSnitch instead . <nl> - CQL2 has been removed entirely in this release ( previously deprecated <nl> in 2 . 0 . 0 ) . Please switch to CQL3 if you haven ' t already done so . <nl> - - Very large batches will now be rejected ( defaults to 50kb ) . This <nl> - can be customized by modifying batch _ size _ fail _ threshold _ in _ kb . <nl> - The results of CQL3 queries containing an IN restriction will be ordered <nl> in the normal order and not anymore in the order in which the column values were <nl> specified in the IN restriction .
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index d27c495 . . 0532a45 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 13 , 6 + 13 , 7 @ @ <nl> * Remove blocking flushes in gossip thread ( CASSANDRA - 6297 ) <nl> * Fix potential socket leak in connectionpool creation ( CASSANDRA - 6308 ) <nl> * Allow LOCAL _ ONE / LOCAL _ QUORUM to work with SimpleSrrategy ( CASSANDRA - 6238 ) <nl> + * cqlsh : handle ' null ' as session duration ( CASSANDRA - 6317 ) <nl> <nl> <nl> 1 . 2 . 11 <nl> diff - - git a / pylib / cqlshlib / tracing . py b / pylib / cqlshlib / tracing . py <nl> index fb8525d . . 3dc0ba7 100644 <nl> - - - a / pylib / cqlshlib / tracing . py <nl> + + + b / pylib / cqlshlib / tracing . py <nl> @ @ - 43 , 7 + 43 , 6 @ @ def fetch _ trace _ session ( cursor , session _ id ) : <nl> " WHERE session _ id = % s " % ( TRACING _ KS , SESSIONS _ CF , session _ id ) , <nl> consistency _ level = ' ONE ' ) <nl> ( request , coordinator , started _ at , duration ) = cursor . fetchone ( ) <nl> - <nl> cursor . execute ( " SELECT activity , event _ id , source , source _ elapsed " <nl> " FROM % s . % s " <nl> " WHERE session _ id = % s " % ( TRACING _ KS , EVENTS _ CF , session _ id ) , <nl> @ @ - 57 , 8 + 56 , 12 @ @ def fetch _ trace _ session ( cursor , session _ id ) : <nl> for activity , event _ id , source , source _ elapsed in events : <nl> rows . append ( [ activity , format _ timeuuid ( event _ id ) , source , source _ elapsed ] ) <nl> # append footer row ( from sessions table ) . <nl> - finished _ at = started _ at + ( duration / 1000000 . ) <nl> - rows . append ( [ ' Request complete ' , format _ timestamp ( finished _ at ) , coordinator , duration ] ) <nl> + if duration : <nl> + finished _ at = format _ timestamp ( started _ at + ( duration / 1000000 . ) ) <nl> + else : <nl> + finished _ at = duration = " - - " <nl> + <nl> + rows . append ( [ ' Request complete ' , finished _ at , coordinator , duration ] ) <nl> <nl> return rows <nl>

TEST DIFF:
diff - - git a / NEWS . txt b / NEWS . txt 
 index 2d6d927 . . e8db40d 100644 
 - - - a / NEWS . txt 
 + + + b / NEWS . txt 
 @ @ - 32 , 6 + 32 , 8 @ @ New features 
 
 New features 
 - - - - - - - - - - - - 
 + - Very large batches will now be rejected ( defaults to 50kb ) . This 
 + can be customized by modifying batch _ size _ fail _ threshold _ in _ kb . 
 - Selecting columns , scalar functions , UDT fields , writetime or ttl together 
 with aggregated is now possible . The value returned for the columns , 
 scalar functions , UDT fields , writetime and ttl will be the ones for 
 @ @ - 167 , 8 + 169 , 6 @ @ Upgrading 
 GossipingPropertyFileSnitch instead . 
 - CQL2 has been removed entirely in this release ( previously deprecated 
 in 2 . 0 . 0 ) . Please switch to CQL3 if you haven ' t already done so . 
 - - Very large batches will now be rejected ( defaults to 50kb ) . This 
 - can be customized by modifying batch _ size _ fail _ threshold _ in _ kb . 
 - The results of CQL3 queries containing an IN restriction will be ordered 
 in the normal order and not anymore in the order in which the column values were 
 specified in the IN restriction .

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index d27c495 . . 0532a45 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 13 , 6 + 13 , 7 @ @ 
 * Remove blocking flushes in gossip thread ( CASSANDRA - 6297 ) 
 * Fix potential socket leak in connectionpool creation ( CASSANDRA - 6308 ) 
 * Allow LOCAL _ ONE / LOCAL _ QUORUM to work with SimpleSrrategy ( CASSANDRA - 6238 ) 
 + * cqlsh : handle ' null ' as session duration ( CASSANDRA - 6317 ) 
 
 
 1 . 2 . 11 
 diff - - git a / pylib / cqlshlib / tracing . py b / pylib / cqlshlib / tracing . py 
 index fb8525d . . 3dc0ba7 100644 
 - - - a / pylib / cqlshlib / tracing . py 
 + + + b / pylib / cqlshlib / tracing . py 
 @ @ - 43 , 7 + 43 , 6 @ @ def fetch _ trace _ session ( cursor , session _ id ) : 
 " WHERE session _ id = % s " % ( TRACING _ KS , SESSIONS _ CF , session _ id ) , 
 consistency _ level = ' ONE ' ) 
 ( request , coordinator , started _ at , duration ) = cursor . fetchone ( ) 
 - 
 cursor . execute ( " SELECT activity , event _ id , source , source _ elapsed " 
 " FROM % s . % s " 
 " WHERE session _ id = % s " % ( TRACING _ KS , EVENTS _ CF , session _ id ) , 
 @ @ - 57 , 8 + 56 , 12 @ @ def fetch _ trace _ session ( cursor , session _ id ) : 
 for activity , event _ id , source , source _ elapsed in events : 
 rows . append ( [ activity , format _ timeuuid ( event _ id ) , source , source _ elapsed ] ) 
 # append footer row ( from sessions table ) . 
 - finished _ at = started _ at + ( duration / 1000000 . ) 
 - rows . append ( [ ' Request complete ' , format _ timestamp ( finished _ at ) , coordinator , duration ] ) 
 + if duration : 
 + finished _ at = format _ timestamp ( started _ at + ( duration / 1000000 . ) ) 
 + else : 
 + finished _ at = duration = " - - " 
 + 
 + rows . append ( [ ' Request complete ' , finished _ at , coordinator , duration ] ) 
 
 return rows 

