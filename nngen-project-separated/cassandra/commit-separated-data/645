BLEU SCORE: 1.0

TEST MSG: If CF has no clustering columns , any row cache is full partition cache ( CASSANDRA - 12499 )
GENERATED MSG: If CF has no clustering columns , any row cache is full partition cache ( CASSANDRA - 12499 )

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index e847f8b . . 15fb000 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 80 , 6 + 80 , 7 @ @ Merged from 3 . 0 : <nl> * Disk failure policy should not be invoked on out of space ( CASSANDRA - 12385 ) <nl> * Calculate last compacted key on startup ( CASSANDRA - 6216 ) <nl> * Add schema to snapshot manifest , add USING TIMESTAMP clause to ALTER TABLE statements ( CASSANDRA - 7190 ) <nl> + * If CF has no clustering columns , any row cache is full partition cache ( CASSANDRA - 12499 ) <nl> Merged from 2 . 2 : <nl> * cqlshlib tests : increase default execute timeout ( CASSANDRA - 12481 ) <nl> * Forward writes to replacement node when replace _ address ! = broadcast _ address ( CASSANDRA - 8523 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java b / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java <nl> index ad73a17 . . 67e0d45 100644 <nl> - - - a / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java <nl> @ @ - 423 , 7 + 423 , 11 @ @ public class SinglePartitionReadCommand extends ReadCommand <nl> cfs . metric . rowCacheMiss . inc ( ) ; <nl> Tracing . trace ( " Row cache miss " ) ; <nl> <nl> - boolean cacheFullPartitions = metadata ( ) . params . caching . cacheAllRows ( ) ; <nl> + / / Note that on tables with no clustering keys , any positive value of <nl> + / / rowsToCache implies caching the full partition <nl> + boolean cacheFullPartitions = metadata ( ) . clusteringColumns ( ) . size ( ) > 0 ? <nl> + metadata ( ) . params . caching . cacheAllRows ( ) : <nl> + metadata ( ) . params . caching . cacheRows ( ) ; <nl> <nl> / / To be able to cache what we read , what we read must at least covers what the cache holds , that <nl> / / is the ' rowsToCache ' first rows of the partition . We could read those ' rowsToCache ' first rows <nl> diff - - git a / test / unit / org / apache / cassandra / SchemaLoader . java b / test / unit / org / apache / cassandra / SchemaLoader . java <nl> index d9c322f . . d6819e1 100644 <nl> - - - a / test / unit / org / apache / cassandra / SchemaLoader . java <nl> + + + b / test / unit / org / apache / cassandra / SchemaLoader . java <nl> @ @ - 217 , 6 + 217 , 7 @ @ public class SchemaLoader <nl> Tables . of ( <nl> standardCFMD ( ks _ rcs , " CFWithoutCache " ) . caching ( CachingParams . CACHE _ NOTHING ) , <nl> standardCFMD ( ks _ rcs , " CachedCF " ) . caching ( CachingParams . CACHE _ EVERYTHING ) , <nl> + standardCFMD ( ks _ rcs , " CachedNoClustering " , 1 , IntegerType . instance , IntegerType . instance , null ) . caching ( CachingParams . CACHE _ EVERYTHING ) , <nl> standardCFMD ( ks _ rcs , " CachedIntCF " ) . <nl> caching ( new CachingParams ( true , 100 ) ) ) ) ) ; <nl> <nl> @ @ - 362 , 18 + 363 , 22 @ @ public class SchemaLoader <nl> <nl> public static CFMetaData standardCFMD ( String ksName , String cfName , int columnCount , AbstractType < ? > keyType , AbstractType < ? > valType , AbstractType < ? > clusteringType ) <nl> { <nl> - CFMetaData . Builder builder = CFMetaData . Builder . create ( ksName , cfName ) <nl> - . addPartitionKey ( " key " , keyType ) <nl> - . addClusteringColumn ( " name " , clusteringType ) <nl> - . addRegularColumn ( " val " , valType ) ; <nl> + CFMetaData . Builder builder ; <nl> + builder = CFMetaData . Builder . create ( ksName , cfName ) <nl> + . addPartitionKey ( " key " , keyType ) <nl> + . addRegularColumn ( " val " , valType ) ; <nl> + <nl> + if ( clusteringType ! = null ) <nl> + builder = builder . addClusteringColumn ( " name " , clusteringType ) ; <nl> <nl> for ( int i = 0 ; i < columnCount ; i + + ) <nl> builder . addRegularColumn ( " val " + i , AsciiType . instance ) ; <nl> <nl> return builder . build ( ) <nl> - . compression ( getCompressionParameters ( ) ) ; <nl> + . compression ( getCompressionParameters ( ) ) ; <nl> } <nl> <nl> + <nl> public static CFMetaData denseCFMD ( String ksName , String cfName ) <nl> { <nl> return denseCFMD ( ksName , cfName , AsciiType . instance ) ; <nl> @ @ - 783 , 11 + 788 , 15 @ @ public class SchemaLoader <nl> for ( int i = offset ; i < offset + numberOfRows ; i + + ) <nl> { <nl> RowUpdateBuilder builder = new RowUpdateBuilder ( cfm , FBUtilities . timestampMicros ( ) , ByteBufferUtil . bytes ( " key " + i ) ) ; <nl> - builder . clustering ( ByteBufferUtil . bytes ( " col " + i ) ) . add ( " val " , ByteBufferUtil . bytes ( " val " + i ) ) ; <nl> + if ( cfm . clusteringColumns ( ) ! = null & & ! cfm . clusteringColumns ( ) . isEmpty ( ) ) <nl> + builder . clustering ( ByteBufferUtil . bytes ( " col " + i ) ) . add ( " val " , ByteBufferUtil . bytes ( " val " + i ) ) ; <nl> + else <nl> + builder . add ( " val " , ByteBufferUtil . bytes ( " val " + i ) ) ; <nl> builder . build ( ) . apply ( ) ; <nl> } <nl> } <nl> <nl> + <nl> public static void cleanupSavedCaches ( ) <nl> { <nl> File cachesDir = new File ( DatabaseDescriptor . getSavedCachesLocation ( ) ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / db / RowCacheTest . java b / test / unit / org / apache / cassandra / db / RowCacheTest . java <nl> index 21d7b8f . . 7b90c8f 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / RowCacheTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / RowCacheTest . java <nl> @ @ - 34 , 6 + 34 , 7 @ @ import org . apache . cassandra . Util ; <nl> import org . apache . cassandra . cache . RowCacheKey ; <nl> import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . Schema ; <nl> + import org . apache . cassandra . db . marshal . AsciiType ; <nl> import org . apache . cassandra . db . rows . * ; <nl> import org . apache . cassandra . db . compaction . CompactionManager ; <nl> import org . apache . cassandra . db . filter . ColumnFilter ; <nl> @ @ - 58 , 6 + 59 , 7 @ @ public class RowCacheTest <nl> private static final String KEYSPACE _ CACHED = " RowCacheTest " ; <nl> private static final String CF _ CACHED = " CachedCF " ; <nl> private static final String CF _ CACHEDINT = " CachedIntCF " ; <nl> + private static final String CF _ CACHEDNOCLUSTER = " CachedNoClustering " ; <nl> <nl> @ BeforeClass <nl> public static void defineSchema ( ) throws ConfigurationException <nl> @ @ - 65 , 6 + 67 , 8 @ @ public class RowCacheTest <nl> SchemaLoader . prepareServer ( ) ; <nl> SchemaLoader . createKeyspace ( KEYSPACE _ CACHED , <nl> KeyspaceParams . simple ( 1 ) , <nl> + SchemaLoader . standardCFMD ( KEYSPACE _ CACHED , CF _ CACHEDNOCLUSTER , 1 , AsciiType . instance , AsciiType . instance , null ) <nl> + . caching ( new CachingParams ( true , 100 ) ) , <nl> SchemaLoader . standardCFMD ( KEYSPACE _ CACHED , CF _ CACHED ) . caching ( CachingParams . CACHE _ EVERYTHING ) , <nl> SchemaLoader . standardCFMD ( KEYSPACE _ CACHED , CF _ CACHEDINT , 1 , IntegerType . instance ) <nl> . caching ( new CachingParams ( true , 100 ) ) ) ; <nl> @ @ - 206 , 6 + 210 , 74 @ @ public class RowCacheTest <nl> } <nl> <nl> @ Test <nl> + public void testRowCacheNoClustering ( ) throws Exception <nl> + { <nl> + CompactionManager . instance . disableAutoCompaction ( ) ; <nl> + <nl> + Keyspace keyspace = Keyspace . open ( KEYSPACE _ CACHED ) ; <nl> + ColumnFamilyStore cachedStore = keyspace . getColumnFamilyStore ( CF _ CACHEDNOCLUSTER ) ; <nl> + <nl> + / / empty the row cache <nl> + CacheService . instance . invalidateRowCache ( ) ; <nl> + <nl> + / / set global row cache size to 1 MB <nl> + CacheService . instance . setRowCacheCapacityInMB ( 1 ) ; <nl> + <nl> + / / inserting 100 rows into column family <nl> + SchemaLoader . insertData ( KEYSPACE _ CACHED , CF _ CACHEDNOCLUSTER , 0 , 100 ) ; <nl> + <nl> + / / now reading rows one by one and checking if row cache grows <nl> + for ( int i = 0 ; i < 100 ; i + + ) <nl> + { <nl> + DecoratedKey key = Util . dk ( " key " + i ) ; <nl> + <nl> + Util . getAll ( Util . cmd ( cachedStore , key ) . build ( ) ) ; <nl> + <nl> + assertEquals ( CacheService . instance . rowCache . size ( ) , i + 1 ) ; <nl> + assert ( cachedStore . containsCachedParition ( key ) ) ; / / current key should be stored in the cache <nl> + } <nl> + <nl> + / / insert 10 more keys <nl> + SchemaLoader . insertData ( KEYSPACE _ CACHED , CF _ CACHEDNOCLUSTER , 100 , 10 ) ; <nl> + <nl> + for ( int i = 100 ; i < 110 ; i + + ) <nl> + { <nl> + DecoratedKey key = Util . dk ( " key " + i ) ; <nl> + <nl> + Util . getAll ( Util . cmd ( cachedStore , key ) . build ( ) ) ; <nl> + assert cachedStore . containsCachedParition ( key ) ; / / cache should be populated with the latest rows read ( old ones should be popped ) <nl> + <nl> + / / checking if cell is read correctly after cache <nl> + CachedPartition cp = cachedStore . getRawCachedPartition ( key ) ; <nl> + try ( UnfilteredRowIterator ai = cp . unfilteredIterator ( ColumnFilter . selection ( cp . columns ( ) ) , Slices . ALL , false ) ) <nl> + { <nl> + assert ai . hasNext ( ) ; <nl> + Row r = ( Row ) ai . next ( ) ; <nl> + assertFalse ( ai . hasNext ( ) ) ; <nl> + <nl> + Iterator < Cell > ci = r . cells ( ) . iterator ( ) ; <nl> + assert ( ci . hasNext ( ) ) ; <nl> + Cell cell = ci . next ( ) ; <nl> + <nl> + assert cell . column ( ) . name . bytes . equals ( ByteBufferUtil . bytes ( " val " ) ) ; <nl> + assert cell . value ( ) . equals ( ByteBufferUtil . bytes ( " val " + i ) ) ; <nl> + } <nl> + } <nl> + <nl> + / / clear 100 rows from the cache <nl> + int keysLeft = 109 ; <nl> + for ( int i = 109 ; i > = 10 ; i - - ) <nl> + { <nl> + cachedStore . invalidateCachedPartition ( Util . dk ( " key " + i ) ) ; <nl> + assert CacheService . instance . rowCache . size ( ) = = keysLeft ; <nl> + keysLeft - - ; <nl> + } <nl> + <nl> + CacheService . instance . setRowCacheCapacityInMB ( 0 ) ; <nl> + <nl> + } <nl> + <nl> + @ Test <nl> public void testRowCacheLoad ( ) throws Exception <nl> { <nl> CacheService . instance . setRowCacheCapacityInMB ( 1 ) ;
NEAREST DIFF (one line): ELIMINATEDSENTENCE

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index e847f8b . . 15fb000 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 80 , 6 + 80 , 7 @ @ Merged from 3 . 0 : 
 * Disk failure policy should not be invoked on out of space ( CASSANDRA - 12385 ) 
 * Calculate last compacted key on startup ( CASSANDRA - 6216 ) 
 * Add schema to snapshot manifest , add USING TIMESTAMP clause to ALTER TABLE statements ( CASSANDRA - 7190 ) 
 + * If CF has no clustering columns , any row cache is full partition cache ( CASSANDRA - 12499 ) 
 Merged from 2 . 2 : 
 * cqlshlib tests : increase default execute timeout ( CASSANDRA - 12481 ) 
 * Forward writes to replacement node when replace _ address ! = broadcast _ address ( CASSANDRA - 8523 ) 
 diff - - git a / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java b / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java 
 index ad73a17 . . 67e0d45 100644 
 - - - a / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java 
 + + + b / src / java / org / apache / cassandra / db / SinglePartitionReadCommand . java 
 @ @ - 423 , 7 + 423 , 11 @ @ public class SinglePartitionReadCommand extends ReadCommand 
 cfs . metric . rowCacheMiss . inc ( ) ; 
 Tracing . trace ( " Row cache miss " ) ; 
 
 - boolean cacheFullPartitions = metadata ( ) . params . caching . cacheAllRows ( ) ; 
 + / / Note that on tables with no clustering keys , any positive value of 
 + / / rowsToCache implies caching the full partition 
 + boolean cacheFullPartitions = metadata ( ) . clusteringColumns ( ) . size ( ) > 0 ? 
 + metadata ( ) . params . caching . cacheAllRows ( ) : 
 + metadata ( ) . params . caching . cacheRows ( ) ; 
 
 / / To be able to cache what we read , what we read must at least covers what the cache holds , that 
 / / is the ' rowsToCache ' first rows of the partition . We could read those ' rowsToCache ' first rows 
 diff - - git a / test / unit / org / apache / cassandra / SchemaLoader . java b / test / unit / org / apache / cassandra / SchemaLoader . java 
 index d9c322f . . d6819e1 100644 
 - - - a / test / unit / org / apache / cassandra / SchemaLoader . java 
 + + + b / test / unit / org / apache / cassandra / SchemaLoader . java 
 @ @ - 217 , 6 + 217 , 7 @ @ public class SchemaLoader 
 Tables . of ( 
 standardCFMD ( ks _ rcs , " CFWithoutCache " ) . caching ( CachingParams . CACHE _ NOTHING ) , 
 standardCFMD ( ks _ rcs , " CachedCF " ) . caching ( CachingParams . CACHE _ EVERYTHING ) , 
 + standardCFMD ( ks _ rcs , " CachedNoClustering " , 1 , IntegerType . instance , IntegerType . instance , null ) . caching ( CachingParams . CACHE _ EVERYTHING ) , 
 standardCFMD ( ks _ rcs , " CachedIntCF " ) . 
 caching ( new CachingParams ( true , 100 ) ) ) ) ) ; 
 
 @ @ - 362 , 18 + 363 , 22 @ @ public class SchemaLoader 
 
 public static CFMetaData standardCFMD ( String ksName , String cfName , int columnCount , AbstractType < ? > keyType , AbstractType < ? > valType , AbstractType < ? > clusteringType ) 
 { 
 - CFMetaData . Builder builder = CFMetaData . Builder . create ( ksName , cfName ) 
 - . addPartitionKey ( " key " , keyType ) 
 - . addClusteringColumn ( " name " , clusteringType ) 
 - . addRegularColumn ( " val " , valType ) ; 
 + CFMetaData . Builder builder ; 
 + builder = CFMetaData . Builder . create ( ksName , cfName ) 
 + . addPartitionKey ( " key " , keyType ) 
 + . addRegularColumn ( " val " , valType ) ; 
 + 
 + if ( clusteringType ! = null ) 
 + builder = builder . addClusteringColumn ( " name " , clusteringType ) ; 
 
 for ( int i = 0 ; i < columnCount ; i + + ) 
 builder . addRegularColumn ( " val " + i , AsciiType . instance ) ; 
 
 return builder . build ( ) 
 - . compression ( getCompressionParameters ( ) ) ; 
 + . compression ( getCompressionParameters ( ) ) ; 
 } 
 
 + 
 public static CFMetaData denseCFMD ( String ksName , String cfName ) 
 { 
 return denseCFMD ( ksName , cfName , AsciiType . instance ) ; 
 @ @ - 783 , 11 + 788 , 15 @ @ public class SchemaLoader 
 for ( int i = offset ; i < offset + numberOfRows ; i + + ) 
 { 
 RowUpdateBuilder builder = new RowUpdateBuilder ( cfm , FBUtilities . timestampMicros ( ) , ByteBufferUtil . bytes ( " key " + i ) ) ; 
 - builder . clustering ( ByteBufferUtil . bytes ( " col " + i ) ) . add ( " val " , ByteBufferUtil . bytes ( " val " + i ) ) ; 
 + if ( cfm . clusteringColumns ( ) ! = null & & ! cfm . clusteringColumns ( ) . isEmpty ( ) ) 
 + builder . clustering ( ByteBufferUtil . bytes ( " col " + i ) ) . add ( " val " , ByteBufferUtil . bytes ( " val " + i ) ) ; 
 + else 
 + builder . add ( " val " , ByteBufferUtil . bytes ( " val " + i ) ) ; 
 builder . build ( ) . apply ( ) ; 
 } 
 } 
 
 + 
 public static void cleanupSavedCaches ( ) 
 { 
 File cachesDir = new File ( DatabaseDescriptor . getSavedCachesLocation ( ) ) ; 
 diff - - git a / test / unit / org / apache / cassandra / db / RowCacheTest . java b / test / unit / org / apache / cassandra / db / RowCacheTest . java 
 index 21d7b8f . . 7b90c8f 100644 
 - - - a / test / unit / org / apache / cassandra / db / RowCacheTest . java 
 + + + b / test / unit / org / apache / cassandra / db / RowCacheTest . java 
 @ @ - 34 , 6 + 34 , 7 @ @ import org . apache . cassandra . Util ; 
 import org . apache . cassandra . cache . RowCacheKey ; 
 import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . Schema ; 
 + import org . apache . cassandra . db . marshal . AsciiType ; 
 import org . apache . cassandra . db . rows . * ; 
 import org . apache . cassandra . db . compaction . CompactionManager ; 
 import org . apache . cassandra . db . filter . ColumnFilter ; 
 @ @ - 58 , 6 + 59 , 7 @ @ public class RowCacheTest 
 private static final String KEYSPACE _ CACHED = " RowCacheTest " ; 
 private static final String CF _ CACHED = " CachedCF " ; 
 private static final String CF _ CACHEDINT = " CachedIntCF " ; 
 + private static final String CF _ CACHEDNOCLUSTER = " CachedNoClustering " ; 
 
 @ BeforeClass 
 public static void defineSchema ( ) throws ConfigurationException 
 @ @ - 65 , 6 + 67 , 8 @ @ public class RowCacheTest 
 SchemaLoader . prepareServer ( ) ; 
 SchemaLoader . createKeyspace ( KEYSPACE _ CACHED , 
 KeyspaceParams . simple ( 1 ) , 
 + SchemaLoader . standardCFMD ( KEYSPACE _ CACHED , CF _ CACHEDNOCLUSTER , 1 , AsciiType . instance , AsciiType . instance , null ) 
 + . caching ( new CachingParams ( true , 100 ) ) , 
 SchemaLoader . standardCFMD ( KEYSPACE _ CACHED , CF _ CACHED ) . caching ( CachingParams . CACHE _ EVERYTHING ) , 
 SchemaLoader . standardCFMD ( KEYSPACE _ CACHED , CF _ CACHEDINT , 1 , IntegerType . instance ) 
 . caching ( new CachingParams ( true , 100 ) ) ) ; 
 @ @ - 206 , 6 + 210 , 74 @ @ public class RowCacheTest 
 } 
 
 @ Test 
 + public void testRowCacheNoClustering ( ) throws Exception 
 + { 
 + CompactionManager . instance . disableAutoCompaction ( ) ; 
 + 
 + Keyspace keyspace = Keyspace . open ( KEYSPACE _ CACHED ) ; 
 + ColumnFamilyStore cachedStore = keyspace . getColumnFamilyStore ( CF _ CACHEDNOCLUSTER ) ; 
 + 
 + / / empty the row cache 
 + CacheService . instance . invalidateRowCache ( ) ; 
 + 
 + / / set global row cache size to 1 MB 
 + CacheService . instance . setRowCacheCapacityInMB ( 1 ) ; 
 + 
 + / / inserting 100 rows into column family 
 + SchemaLoader . insertData ( KEYSPACE _ CACHED , CF _ CACHEDNOCLUSTER , 0 , 100 ) ; 
 + 
 + / / now reading rows one by one and checking if row cache grows 
 + for ( int i = 0 ; i < 100 ; i + + ) 
 + { 
 + DecoratedKey key = Util . dk ( " key " + i ) ; 
 + 
 + Util . getAll ( Util . cmd ( cachedStore , key ) . build ( ) ) ; 
 + 
 + assertEquals ( CacheService . instance . rowCache . size ( ) , i + 1 ) ; 
 + assert ( cachedStore . containsCachedParition ( key ) ) ; / / current key should be stored in the cache 
 + } 
 + 
 + / / insert 10 more keys 
 + SchemaLoader . insertData ( KEYSPACE _ CACHED , CF _ CACHEDNOCLUSTER , 100 , 10 ) ; 
 + 
 + for ( int i = 100 ; i < 110 ; i + + ) 
 + { 
 + DecoratedKey key = Util . dk ( " key " + i ) ; 
 + 
 + Util . getAll ( Util . cmd ( cachedStore , key ) . build ( ) ) ; 
 + assert cachedStore . containsCachedParition ( key ) ; / / cache should be populated with the latest rows read ( old ones should be popped ) 
 + 
 + / / checking if cell is read correctly after cache 
 + CachedPartition cp = cachedStore . getRawCachedPartition ( key ) ; 
 + try ( UnfilteredRowIterator ai = cp . unfilteredIterator ( ColumnFilter . selection ( cp . columns ( ) ) , Slices . ALL , false ) ) 
 + { 
 + assert ai . hasNext ( ) ; 
 + Row r = ( Row ) ai . next ( ) ; 
 + assertFalse ( ai . hasNext ( ) ) ; 
 + 
 + Iterator < Cell > ci = r . cells ( ) . iterator ( ) ; 
 + assert ( ci . hasNext ( ) ) ; 
 + Cell cell = ci . next ( ) ; 
 + 
 + assert cell . column ( ) . name . bytes . equals ( ByteBufferUtil . bytes ( " val " ) ) ; 
 + assert cell . value ( ) . equals ( ByteBufferUtil . bytes ( " val " + i ) ) ; 
 + } 
 + } 
 + 
 + / / clear 100 rows from the cache 
 + int keysLeft = 109 ; 
 + for ( int i = 109 ; i > = 10 ; i - - ) 
 + { 
 + cachedStore . invalidateCachedPartition ( Util . dk ( " key " + i ) ) ; 
 + assert CacheService . instance . rowCache . size ( ) = = keysLeft ; 
 + keysLeft - - ; 
 + } 
 + 
 + CacheService . instance . setRowCacheCapacityInMB ( 0 ) ; 
 + 
 + } 
 + 
 + @ Test 
 public void testRowCacheLoad ( ) throws Exception 
 { 
 CacheService . instance . setRowCacheCapacityInMB ( 1 ) ;

NEAREST DIFF:
ELIMINATEDSENTENCE
