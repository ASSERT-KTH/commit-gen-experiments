BLEU SCORE: 0.04767707020457096

TEST MSG: Fixed handling of non - intersecting ranges in anticompaction
GENERATED MSG: Fix wrong purge of deleted cf during compaction

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 28c39e6 . . ea9a05c 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 1 . 0 <nl> + * Fixed IllegalStateException in anticompaction ( CASSANDRA - 7892 ) <nl> * cqlsh : DESCRIBE support for frozen UDTs , tuples ( CASSANDRA - 7863 ) <nl> * Avoid exposing internal classes over JMX ( CASSANDRA - 7879 ) <nl> * Add null check for keys when freezing collection ( CASSANDRA - 7869 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> index 09c068f . . 33a750b 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> @ @ - 430 , 6 + 430 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> logger . info ( " SSTable { } ( { } ) does not intersect repaired range { } , not touching repairedAt . " , sstable , sstableRange , r ) ; <nl> nonAnticompacting . add ( sstable ) ; <nl> sstableIterator . remove ( ) ; <nl> + break ; <nl> } <nl> else <nl> { <nl> diff - - git a / test / unit / org / apache / cassandra / db / compaction / AntiCompactionTest . java b / test / unit / org / apache / cassandra / db / compaction / AntiCompactionTest . java <nl> index b8637a8 . . 6e1ac5f 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / compaction / AntiCompactionTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / compaction / AntiCompactionTest . java <nl> @ @ - 17 , 12 + 17 , 17 @ @ <nl> * / <nl> package org . apache . cassandra . db . compaction ; <nl> <nl> + import static org . hamcrest . CoreMatchers . is ; <nl> + import static org . junit . Assert . assertEquals ; <nl> + import static org . junit . Assert . assertFalse ; <nl> + import static org . junit . Assert . assertThat ; <nl> + import static org . junit . Assert . assertTrue ; <nl> + <nl> import java . io . IOException ; <nl> import java . util . Arrays ; <nl> import java . util . Collection ; <nl> import java . util . List ; <nl> import java . util . concurrent . ExecutionException ; <nl> - import org . junit . Test ; <nl> <nl> import org . apache . cassandra . SchemaLoader ; <nl> import org . apache . cassandra . Util ; <nl> @ @ - 37 , 9 + 42 , 10 @ @ import org . apache . cassandra . io . sstable . SSTableIdentityIterator ; <nl> import org . apache . cassandra . io . sstable . SSTableReader ; <nl> import org . apache . cassandra . io . sstable . SSTableScanner ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> - import static junit . framework . Assert . assertFalse ; <nl> - import static org . junit . Assert . assertEquals ; <nl> - import static org . junit . Assert . assertTrue ; <nl> + import org . junit . After ; <nl> + import org . junit . Test ; <nl> + <nl> + import com . google . common . collect . Iterables ; <nl> <nl> public class AntiCompactionTest extends SchemaLoader <nl> { <nl> @ @ - 49 , 22 + 55 , 7 @ @ public class AntiCompactionTest extends SchemaLoader <nl> @ Test <nl> public void antiCompactOne ( ) throws InterruptedException , ExecutionException , IOException <nl> { <nl> - Keyspace keyspace = Keyspace . open ( KEYSPACE1 ) ; <nl> - ColumnFamilyStore store = keyspace . getColumnFamilyStore ( CF ) ; <nl> - store . disableAutoCompaction ( ) ; <nl> - long timestamp = System . currentTimeMillis ( ) ; <nl> - for ( int i = 0 ; i < 10 ; i + + ) <nl> - { <nl> - DecoratedKey key = Util . dk ( Integer . toString ( i ) ) ; <nl> - Mutation rm = new Mutation ( KEYSPACE1 , key . getKey ( ) ) ; <nl> - for ( int j = 0 ; j < 10 ; j + + ) <nl> - rm . add ( " Standard1 " , Util . cellname ( Integer . toString ( j ) ) , <nl> - ByteBufferUtil . EMPTY _ BYTE _ BUFFER , <nl> - timestamp , <nl> - 0 ) ; <nl> - rm . apply ( ) ; <nl> - } <nl> - store . forceBlockingFlush ( ) ; <nl> + ColumnFamilyStore store = prepareColumnFamilyStore ( ) ; <nl> Collection < SSTableReader > sstables = store . getUnrepairedSSTables ( ) ; <nl> assertEquals ( store . getSSTables ( ) . size ( ) , sstables . size ( ) ) ; <nl> Range < Token > range = new Range < Token > ( new BytesToken ( " 0 " . getBytes ( ) ) , new BytesToken ( " 4 " . getBytes ( ) ) ) ; <nl> @ @ - 98 , 4 + 89 , 49 @ @ public class AntiCompactionTest extends SchemaLoader <nl> assertEquals ( repairedKeys , 4 ) ; <nl> assertEquals ( nonRepairedKeys , 6 ) ; <nl> } <nl> + <nl> + @ Test <nl> + public void shouldSkipAntiCompactionForNonIntersectingRange ( ) throws InterruptedException , ExecutionException , IOException <nl> + { <nl> + ColumnFamilyStore store = prepareColumnFamilyStore ( ) ; <nl> + Collection < SSTableReader > sstables = store . getUnrepairedSSTables ( ) ; <nl> + assertEquals ( store . getSSTables ( ) . size ( ) , sstables . size ( ) ) ; <nl> + Range < Token > range = new Range < Token > ( new BytesToken ( " - 10 " . getBytes ( ) ) , new BytesToken ( " - 1 " . getBytes ( ) ) ) ; <nl> + List < Range < Token > > ranges = Arrays . asList ( range ) ; <nl> + <nl> + SSTableReader . acquireReferences ( sstables ) ; <nl> + CompactionManager . instance . performAnticompaction ( store , ranges , sstables , 0 ) ; <nl> + <nl> + assertThat ( store . getSSTables ( ) . size ( ) , is ( 1 ) ) ; <nl> + assertThat ( Iterables . get ( store . getSSTables ( ) , 0 ) . isRepaired ( ) , is ( false ) ) ; <nl> + } <nl> + <nl> + private ColumnFamilyStore prepareColumnFamilyStore ( ) <nl> + { <nl> + Keyspace keyspace = Keyspace . open ( KEYSPACE1 ) ; <nl> + ColumnFamilyStore store = keyspace . getColumnFamilyStore ( CF ) ; <nl> + store . disableAutoCompaction ( ) ; <nl> + long timestamp = System . currentTimeMillis ( ) ; <nl> + for ( int i = 0 ; i < 10 ; i + + ) <nl> + { <nl> + DecoratedKey key = Util . dk ( Integer . toString ( i ) ) ; <nl> + Mutation rm = new Mutation ( KEYSPACE1 , key . getKey ( ) ) ; <nl> + for ( int j = 0 ; j < 10 ; j + + ) <nl> + rm . add ( " Standard1 " , Util . cellname ( Integer . toString ( j ) ) , <nl> + ByteBufferUtil . EMPTY _ BYTE _ BUFFER , <nl> + timestamp , <nl> + 0 ) ; <nl> + rm . apply ( ) ; <nl> + } <nl> + store . forceBlockingFlush ( ) ; <nl> + return store ; <nl> + } <nl> + <nl> + @ After <nl> + public void truncateCF ( ) <nl> + { <nl> + Keyspace keyspace = Keyspace . open ( KEYSPACE1 ) ; <nl> + ColumnFamilyStore store = keyspace . getColumnFamilyStore ( CF ) ; <nl> + store . truncateBlocking ( ) ; <nl> + } <nl> }
NEAREST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> index 0eb13f1 . . ca0b8aa 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> @ @ - 832 , 7 + 832 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> public Future < SSTableReader > submitSSTableBuild ( final Descriptor desc , OperationType type ) <nl> { <nl> / / invalid descriptions due to missing or dropped CFS are handled by SSTW and StreamInSession . <nl> - final SSTableWriter . Builder builder = SSTableWriter . createBuilder ( desc , type ) ; <nl> + final Rebuilder builder = SSTableWriter . createBuilder ( desc , type ) ; <nl> Callable < SSTableReader > callable = new Callable < SSTableReader > ( ) <nl> { <nl> public SSTableReader call ( ) throws IOException <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / IndexWriter . java b / src / java / org / apache / cassandra / io / sstable / IndexWriter . java <nl> new file mode 100644 <nl> index 0000000 . . 8510241 <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / io / sstable / IndexWriter . java <nl> @ @ - 0 , 0 + 1 , 93 @ @ <nl> + package org . apache . cassandra . io . sstable ; <nl> + <nl> + import java . io . DataOutputStream ; <nl> + import java . io . File ; <nl> + import java . io . FileOutputStream ; <nl> + import java . io . IOException ; <nl> + <nl> + import org . slf4j . Logger ; <nl> + import org . slf4j . LoggerFactory ; <nl> + <nl> + import org . apache . cassandra . config . DatabaseDescriptor ; <nl> + import org . apache . cassandra . db . DecoratedKey ; <nl> + import org . apache . cassandra . dht . IPartitioner ; <nl> + import org . apache . cassandra . io . util . BufferedRandomAccessFile ; <nl> + import org . apache . cassandra . io . util . FileMark ; <nl> + import org . apache . cassandra . io . util . FileUtils ; <nl> + import org . apache . cassandra . io . util . SegmentedFile ; <nl> + import org . apache . cassandra . utils . BloomFilter ; <nl> + import org . apache . cassandra . utils . ByteBufferUtil ; <nl> + <nl> + / * * <nl> + * Encapsulates writing the index and filter for an SSTable . The state of this object is not valid until it has been closed . <nl> + * / <nl> + class IndexWriter <nl> + { <nl> + private static final Logger logger = LoggerFactory . getLogger ( SSTableWriter . class ) ; <nl> + <nl> + private final BufferedRandomAccessFile indexFile ; <nl> + public final Descriptor desc ; <nl> + public final IPartitioner partitioner ; <nl> + public final SegmentedFile . Builder builder ; <nl> + public final IndexSummary summary ; <nl> + public final BloomFilter bf ; <nl> + private FileMark mark ; <nl> + <nl> + IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException <nl> + { <nl> + this . desc = desc ; <nl> + this . partitioner = part ; <nl> + indexFile = new BufferedRandomAccessFile ( new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) , " rw " , 8 * 1024 * 1024 , true ) ; <nl> + builder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; <nl> + summary = new IndexSummary ( keyCount ) ; <nl> + bf = BloomFilter . getFilter ( keyCount , 15 ) ; <nl> + } <nl> + <nl> + public void afterAppend ( DecoratedKey key , long dataPosition ) throws IOException <nl> + { <nl> + bf . add ( key . key ) ; <nl> + long indexPosition = indexFile . getFilePointer ( ) ; <nl> + ByteBufferUtil . writeWithShortLength ( key . key , indexFile ) ; <nl> + indexFile . writeLong ( dataPosition ) ; <nl> + if ( logger . isTraceEnabled ( ) ) <nl> + logger . trace ( " wrote index of " + key + " at " + indexPosition ) ; <nl> + <nl> + summary . maybeAddEntry ( key , indexPosition ) ; <nl> + builder . addPotentialBoundary ( indexPosition ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Closes the index and bloomfilter , making the public state of this writer valid for consumption . <nl> + * / <nl> + public void close ( ) throws IOException <nl> + { <nl> + / / bloom filter <nl> + FileOutputStream fos = new FileOutputStream ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; <nl> + DataOutputStream stream = new DataOutputStream ( fos ) ; <nl> + BloomFilter . serializer ( ) . serialize ( bf , stream ) ; <nl> + stream . flush ( ) ; <nl> + fos . getFD ( ) . sync ( ) ; <nl> + stream . close ( ) ; <nl> + <nl> + / / index <nl> + long position = indexFile . getFilePointer ( ) ; <nl> + indexFile . close ( ) ; / / calls force <nl> + FileUtils . truncate ( indexFile . getPath ( ) , position ) ; <nl> + <nl> + / / finalize in - memory index state <nl> + summary . complete ( ) ; <nl> + } <nl> + <nl> + public void mark ( ) <nl> + { <nl> + mark = indexFile . mark ( ) ; <nl> + } <nl> + <nl> + public void reset ( ) throws IOException <nl> + { <nl> + / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . <nl> + / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so <nl> + / / we assume that if that worked then we won ' t be trying to reset . <nl> + indexFile . reset ( mark ) ; <nl> + } <nl> + } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / Rebuilder . java b / src / java / org / apache / cassandra / io / sstable / Rebuilder . java <nl> new file mode 100644 <nl> index 0000000 . . 803eb64 <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / io / sstable / Rebuilder . java <nl> @ @ - 0 , 0 + 1 , 92 @ @ <nl> + package org . apache . cassandra . io . sstable ; <nl> + <nl> + import java . io . File ; <nl> + import java . io . IOError ; <nl> + import java . io . IOException ; <nl> + <nl> + import org . slf4j . Logger ; <nl> + import org . slf4j . LoggerFactory ; <nl> + <nl> + import org . apache . cassandra . db . ColumnFamilyStore ; <nl> + import org . apache . cassandra . db . Table ; <nl> + import org . apache . cassandra . db . compaction . CompactionInfo ; <nl> + import org . apache . cassandra . db . compaction . CompactionType ; <nl> + import org . apache . cassandra . streaming . OperationType ; <nl> + <nl> + / * * <nl> + * Removes the given SSTable from temporary status and opens it , rebuilding the <nl> + * bloom filter and row index from the data file . <nl> + * / <nl> + public class Rebuilder implements CompactionInfo . Holder <nl> + { <nl> + private static final Logger logger = LoggerFactory . getLogger ( SSTableWriter . class ) ; <nl> + <nl> + private final Descriptor desc ; <nl> + private final OperationType type ; <nl> + private final ColumnFamilyStore cfs ; <nl> + private SSTableWriter . RowIndexer indexer ; <nl> + <nl> + public Rebuilder ( Descriptor desc , OperationType type ) <nl> + { <nl> + this . desc = desc ; <nl> + this . type = type ; <nl> + cfs = Table . open ( desc . ksname ) . getColumnFamilyStore ( desc . cfname ) ; <nl> + } <nl> + <nl> + public CompactionInfo getCompactionInfo ( ) <nl> + { <nl> + maybeOpenIndexer ( ) ; <nl> + try <nl> + { <nl> + / / both file offsets are still valid post - close <nl> + return new CompactionInfo ( desc . ksname , <nl> + desc . cfname , <nl> + CompactionType . SSTABLE _ BUILD , <nl> + indexer . dfile . getFilePointer ( ) , <nl> + indexer . dfile . length ( ) ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new IOError ( e ) ; <nl> + } <nl> + } <nl> + <nl> + / / lazy - initialize the file to avoid opening it until it ' s actually executing on the CompactionManager , <nl> + / / since the 8MB buffers can use up heap quickly <nl> + private void maybeOpenIndexer ( ) <nl> + { <nl> + if ( indexer ! = null ) <nl> + return ; <nl> + try <nl> + { <nl> + if ( cfs . metadata . getDefaultValidator ( ) . isCommutative ( ) ) <nl> + indexer = new SSTableWriter . CommutativeRowIndexer ( desc , cfs , type ) ; <nl> + else <nl> + indexer = new SSTableWriter . RowIndexer ( desc , cfs , type ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new IOError ( e ) ; <nl> + } <nl> + } <nl> + <nl> + public SSTableReader build ( ) throws IOException <nl> + { <nl> + if ( cfs . isInvalid ( ) ) <nl> + return null ; <nl> + maybeOpenIndexer ( ) ; <nl> + <nl> + File ifile = new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) ; <nl> + File ffile = new File ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; <nl> + assert ! ifile . exists ( ) ; <nl> + assert ! ffile . exists ( ) ; <nl> + <nl> + long estimatedRows = indexer . prepareIndexing ( ) ; <nl> + <nl> + / / build the index and filter <nl> + long rows = indexer . index ( ) ; <nl> + <nl> + logger . debug ( " estimated row count was { } of real count " , ( ( double ) estimatedRows ) / rows ) ; <nl> + return SSTableReader . open ( SSTableWriter . rename ( desc , SSTable . componentsFor ( desc , false ) ) ) ; <nl> + } <nl> + } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> index da179e9 . . fa902b3 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> @ @ - 19 , 7 + 19 , 9 @ @ <nl> <nl> package org . apache . cassandra . io . sstable ; <nl> <nl> - import java . io . * ; <nl> + import java . io . File ; <nl> + import java . io . IOError ; <nl> + import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . Arrays ; <nl> import java . util . Collections ; <nl> @ @ - 27 , 10 + 29 , 6 @ @ import java . util . HashSet ; <nl> import java . util . Set ; <nl> <nl> import com . google . common . collect . Sets ; <nl> - <nl> - import org . apache . cassandra . db . commitlog . ReplayPosition ; <nl> - import org . apache . cassandra . db . compaction . * ; <nl> - import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 39 , 7 + 37 , 10 @ @ import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . db . ColumnFamily ; <nl> import org . apache . cassandra . db . ColumnFamilyStore ; <nl> import org . apache . cassandra . db . DecoratedKey ; <nl> - import org . apache . cassandra . db . Table ; <nl> + import org . apache . cassandra . db . commitlog . ReplayPosition ; <nl> + import org . apache . cassandra . db . compaction . AbstractCompactedRow ; <nl> + import org . apache . cassandra . db . compaction . CompactionController ; <nl> + import org . apache . cassandra . db . compaction . PrecompactedRow ; <nl> import org . apache . cassandra . dht . IPartitioner ; <nl> import org . apache . cassandra . io . util . BufferedRandomAccessFile ; <nl> import org . apache . cassandra . io . util . FileMark ; <nl> @ @ - 47 , 7 + 48 , 7 @ @ import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . io . util . SegmentedFile ; <nl> import org . apache . cassandra . service . StorageService ; <nl> import org . apache . cassandra . streaming . OperationType ; <nl> - import org . apache . cassandra . utils . BloomFilter ; <nl> + import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . apache . cassandra . utils . EstimatedHistogram ; <nl> import org . apache . cassandra . utils . FBUtilities ; <nl> <nl> @ @ - 232 , 7 + 233 , 7 @ @ public class SSTableWriter extends SSTable <nl> return dataFile . getFilePointer ( ) ; <nl> } <nl> <nl> - public static Builder createBuilder ( Descriptor desc , OperationType type ) <nl> + public static Rebuilder createBuilder ( Descriptor desc , OperationType type ) <nl> { <nl> if ( ! desc . isLatestVersion ) <nl> / / TODO : streaming between different versions will fail : need support for <nl> @ @ - 240 , 83 + 241 , 7 @ @ public class SSTableWriter extends SSTable <nl> throw new RuntimeException ( String . format ( " Cannot recover SSTable with version % s ( current version % s ) . " , <nl> desc . version , Descriptor . CURRENT _ VERSION ) ) ; <nl> <nl> - return new Builder ( desc , type ) ; <nl> - } <nl> - <nl> - / * * <nl> - * Removes the given SSTable from temporary status and opens it , rebuilding the <nl> - * bloom filter and row index from the data file . <nl> - * / <nl> - public static class Builder implements CompactionInfo . Holder <nl> - { <nl> - private final Descriptor desc ; <nl> - private final OperationType type ; <nl> - private final ColumnFamilyStore cfs ; <nl> - private RowIndexer indexer ; <nl> - <nl> - public Builder ( Descriptor desc , OperationType type ) <nl> - { <nl> - this . desc = desc ; <nl> - this . type = type ; <nl> - cfs = Table . open ( desc . ksname ) . getColumnFamilyStore ( desc . cfname ) ; <nl> - } <nl> - <nl> - public CompactionInfo getCompactionInfo ( ) <nl> - { <nl> - maybeOpenIndexer ( ) ; <nl> - try <nl> - { <nl> - / / both file offsets are still valid post - close <nl> - return new CompactionInfo ( desc . ksname , <nl> - desc . cfname , <nl> - CompactionType . SSTABLE _ BUILD , <nl> - indexer . dfile . getFilePointer ( ) , <nl> - indexer . dfile . length ( ) ) ; <nl> - } <nl> - catch ( IOException e ) <nl> - { <nl> - throw new IOError ( e ) ; <nl> - } <nl> - } <nl> - <nl> - / / lazy - initialize the file to avoid opening it until it ' s actually executing on the CompactionManager , <nl> - / / since the 8MB buffers can use up heap quickly <nl> - private void maybeOpenIndexer ( ) <nl> - { <nl> - if ( indexer ! = null ) <nl> - return ; <nl> - try <nl> - { <nl> - if ( cfs . metadata . getDefaultValidator ( ) . isCommutative ( ) ) <nl> - indexer = new CommutativeRowIndexer ( desc , cfs , type ) ; <nl> - else <nl> - indexer = new RowIndexer ( desc , cfs , type ) ; <nl> - } <nl> - catch ( IOException e ) <nl> - { <nl> - throw new IOError ( e ) ; <nl> - } <nl> - } <nl> - <nl> - public SSTableReader build ( ) throws IOException <nl> - { <nl> - if ( cfs . isInvalid ( ) ) <nl> - return null ; <nl> - maybeOpenIndexer ( ) ; <nl> - <nl> - File ifile = new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) ; <nl> - File ffile = new File ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; <nl> - assert ! ifile . exists ( ) ; <nl> - assert ! ffile . exists ( ) ; <nl> - <nl> - long estimatedRows = indexer . prepareIndexing ( ) ; <nl> - <nl> - / / build the index and filter <nl> - long rows = indexer . index ( ) ; <nl> - <nl> - logger . debug ( " estimated row count was { } of real count " , ( ( double ) estimatedRows ) / rows ) ; <nl> - return SSTableReader . open ( rename ( desc , SSTable . componentsFor ( desc , false ) ) ) ; <nl> - } <nl> + return new Rebuilder ( desc , type ) ; <nl> } <nl> <nl> static class RowIndexer <nl> @ @ - 540 , 75 + 465 , 4 @ @ public class SSTableWriter extends SSTable <nl> } <nl> } <nl> <nl> - / * * <nl> - * Encapsulates writing the index and filter for an SSTable . The state of this object is not valid until it has been closed . <nl> - * / <nl> - static class IndexWriter <nl> - { <nl> - private final BufferedRandomAccessFile indexFile ; <nl> - public final Descriptor desc ; <nl> - public final IPartitioner partitioner ; <nl> - public final SegmentedFile . Builder builder ; <nl> - public final IndexSummary summary ; <nl> - public final BloomFilter bf ; <nl> - private FileMark mark ; <nl> - <nl> - IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException <nl> - { <nl> - this . desc = desc ; <nl> - this . partitioner = part ; <nl> - indexFile = new BufferedRandomAccessFile ( new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) , " rw " , 8 * 1024 * 1024 , true ) ; <nl> - builder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; <nl> - summary = new IndexSummary ( keyCount ) ; <nl> - bf = BloomFilter . getFilter ( keyCount , 15 ) ; <nl> - } <nl> - <nl> - public void afterAppend ( DecoratedKey key , long dataPosition ) throws IOException <nl> - { <nl> - bf . add ( key . key ) ; <nl> - long indexPosition = indexFile . getFilePointer ( ) ; <nl> - ByteBufferUtil . writeWithShortLength ( key . key , indexFile ) ; <nl> - indexFile . writeLong ( dataPosition ) ; <nl> - if ( logger . isTraceEnabled ( ) ) <nl> - logger . trace ( " wrote index of " + key + " at " + indexPosition ) ; <nl> - <nl> - summary . maybeAddEntry ( key , indexPosition ) ; <nl> - builder . addPotentialBoundary ( indexPosition ) ; <nl> - } <nl> - <nl> - / * * <nl> - * Closes the index and bloomfilter , making the public state of this writer valid for consumption . <nl> - * / <nl> - public void close ( ) throws IOException <nl> - { <nl> - / / bloom filter <nl> - FileOutputStream fos = new FileOutputStream ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; <nl> - DataOutputStream stream = new DataOutputStream ( fos ) ; <nl> - BloomFilter . serializer ( ) . serialize ( bf , stream ) ; <nl> - stream . flush ( ) ; <nl> - fos . getFD ( ) . sync ( ) ; <nl> - stream . close ( ) ; <nl> - <nl> - / / index <nl> - long position = indexFile . getFilePointer ( ) ; <nl> - indexFile . close ( ) ; / / calls force <nl> - FileUtils . truncate ( indexFile . getPath ( ) , position ) ; <nl> - <nl> - / / finalize in - memory index state <nl> - summary . complete ( ) ; <nl> - } <nl> - <nl> - public void mark ( ) <nl> - { <nl> - mark = indexFile . mark ( ) ; <nl> - } <nl> - <nl> - public void reset ( ) throws IOException <nl> - { <nl> - / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . <nl> - / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so <nl> - / / we assume that if that worked then we won ' t be trying to reset . <nl> - indexFile . reset ( mark ) ; <nl> - } <nl> - } <nl> }

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 28c39e6 . . ea9a05c 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 1 . 0 
 + * Fixed IllegalStateException in anticompaction ( CASSANDRA - 7892 ) 
 * cqlsh : DESCRIBE support for frozen UDTs , tuples ( CASSANDRA - 7863 ) 
 * Avoid exposing internal classes over JMX ( CASSANDRA - 7879 ) 
 * Add null check for keys when freezing collection ( CASSANDRA - 7869 ) 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 index 09c068f . . 33a750b 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 @ @ - 430 , 6 + 430 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 logger . info ( " SSTable { } ( { } ) does not intersect repaired range { } , not touching repairedAt . " , sstable , sstableRange , r ) ; 
 nonAnticompacting . add ( sstable ) ; 
 sstableIterator . remove ( ) ; 
 + break ; 
 } 
 else 
 { 
 diff - - git a / test / unit / org / apache / cassandra / db / compaction / AntiCompactionTest . java b / test / unit / org / apache / cassandra / db / compaction / AntiCompactionTest . java 
 index b8637a8 . . 6e1ac5f 100644 
 - - - a / test / unit / org / apache / cassandra / db / compaction / AntiCompactionTest . java 
 + + + b / test / unit / org / apache / cassandra / db / compaction / AntiCompactionTest . java 
 @ @ - 17 , 12 + 17 , 17 @ @ 
 * / 
 package org . apache . cassandra . db . compaction ; 
 
 + import static org . hamcrest . CoreMatchers . is ; 
 + import static org . junit . Assert . assertEquals ; 
 + import static org . junit . Assert . assertFalse ; 
 + import static org . junit . Assert . assertThat ; 
 + import static org . junit . Assert . assertTrue ; 
 + 
 import java . io . IOException ; 
 import java . util . Arrays ; 
 import java . util . Collection ; 
 import java . util . List ; 
 import java . util . concurrent . ExecutionException ; 
 - import org . junit . Test ; 
 
 import org . apache . cassandra . SchemaLoader ; 
 import org . apache . cassandra . Util ; 
 @ @ - 37 , 9 + 42 , 10 @ @ import org . apache . cassandra . io . sstable . SSTableIdentityIterator ; 
 import org . apache . cassandra . io . sstable . SSTableReader ; 
 import org . apache . cassandra . io . sstable . SSTableScanner ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 - import static junit . framework . Assert . assertFalse ; 
 - import static org . junit . Assert . assertEquals ; 
 - import static org . junit . Assert . assertTrue ; 
 + import org . junit . After ; 
 + import org . junit . Test ; 
 + 
 + import com . google . common . collect . Iterables ; 
 
 public class AntiCompactionTest extends SchemaLoader 
 { 
 @ @ - 49 , 22 + 55 , 7 @ @ public class AntiCompactionTest extends SchemaLoader 
 @ Test 
 public void antiCompactOne ( ) throws InterruptedException , ExecutionException , IOException 
 { 
 - Keyspace keyspace = Keyspace . open ( KEYSPACE1 ) ; 
 - ColumnFamilyStore store = keyspace . getColumnFamilyStore ( CF ) ; 
 - store . disableAutoCompaction ( ) ; 
 - long timestamp = System . currentTimeMillis ( ) ; 
 - for ( int i = 0 ; i < 10 ; i + + ) 
 - { 
 - DecoratedKey key = Util . dk ( Integer . toString ( i ) ) ; 
 - Mutation rm = new Mutation ( KEYSPACE1 , key . getKey ( ) ) ; 
 - for ( int j = 0 ; j < 10 ; j + + ) 
 - rm . add ( " Standard1 " , Util . cellname ( Integer . toString ( j ) ) , 
 - ByteBufferUtil . EMPTY _ BYTE _ BUFFER , 
 - timestamp , 
 - 0 ) ; 
 - rm . apply ( ) ; 
 - } 
 - store . forceBlockingFlush ( ) ; 
 + ColumnFamilyStore store = prepareColumnFamilyStore ( ) ; 
 Collection < SSTableReader > sstables = store . getUnrepairedSSTables ( ) ; 
 assertEquals ( store . getSSTables ( ) . size ( ) , sstables . size ( ) ) ; 
 Range < Token > range = new Range < Token > ( new BytesToken ( " 0 " . getBytes ( ) ) , new BytesToken ( " 4 " . getBytes ( ) ) ) ; 
 @ @ - 98 , 4 + 89 , 49 @ @ public class AntiCompactionTest extends SchemaLoader 
 assertEquals ( repairedKeys , 4 ) ; 
 assertEquals ( nonRepairedKeys , 6 ) ; 
 } 
 + 
 + @ Test 
 + public void shouldSkipAntiCompactionForNonIntersectingRange ( ) throws InterruptedException , ExecutionException , IOException 
 + { 
 + ColumnFamilyStore store = prepareColumnFamilyStore ( ) ; 
 + Collection < SSTableReader > sstables = store . getUnrepairedSSTables ( ) ; 
 + assertEquals ( store . getSSTables ( ) . size ( ) , sstables . size ( ) ) ; 
 + Range < Token > range = new Range < Token > ( new BytesToken ( " - 10 " . getBytes ( ) ) , new BytesToken ( " - 1 " . getBytes ( ) ) ) ; 
 + List < Range < Token > > ranges = Arrays . asList ( range ) ; 
 + 
 + SSTableReader . acquireReferences ( sstables ) ; 
 + CompactionManager . instance . performAnticompaction ( store , ranges , sstables , 0 ) ; 
 + 
 + assertThat ( store . getSSTables ( ) . size ( ) , is ( 1 ) ) ; 
 + assertThat ( Iterables . get ( store . getSSTables ( ) , 0 ) . isRepaired ( ) , is ( false ) ) ; 
 + } 
 + 
 + private ColumnFamilyStore prepareColumnFamilyStore ( ) 
 + { 
 + Keyspace keyspace = Keyspace . open ( KEYSPACE1 ) ; 
 + ColumnFamilyStore store = keyspace . getColumnFamilyStore ( CF ) ; 
 + store . disableAutoCompaction ( ) ; 
 + long timestamp = System . currentTimeMillis ( ) ; 
 + for ( int i = 0 ; i < 10 ; i + + ) 
 + { 
 + DecoratedKey key = Util . dk ( Integer . toString ( i ) ) ; 
 + Mutation rm = new Mutation ( KEYSPACE1 , key . getKey ( ) ) ; 
 + for ( int j = 0 ; j < 10 ; j + + ) 
 + rm . add ( " Standard1 " , Util . cellname ( Integer . toString ( j ) ) , 
 + ByteBufferUtil . EMPTY _ BYTE _ BUFFER , 
 + timestamp , 
 + 0 ) ; 
 + rm . apply ( ) ; 
 + } 
 + store . forceBlockingFlush ( ) ; 
 + return store ; 
 + } 
 + 
 + @ After 
 + public void truncateCF ( ) 
 + { 
 + Keyspace keyspace = Keyspace . open ( KEYSPACE1 ) ; 
 + ColumnFamilyStore store = keyspace . getColumnFamilyStore ( CF ) ; 
 + store . truncateBlocking ( ) ; 
 + } 
 }

NEAREST DIFF:
diff - - git a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 index 0eb13f1 . . ca0b8aa 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 @ @ - 832 , 7 + 832 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 public Future < SSTableReader > submitSSTableBuild ( final Descriptor desc , OperationType type ) 
 { 
 / / invalid descriptions due to missing or dropped CFS are handled by SSTW and StreamInSession . 
 - final SSTableWriter . Builder builder = SSTableWriter . createBuilder ( desc , type ) ; 
 + final Rebuilder builder = SSTableWriter . createBuilder ( desc , type ) ; 
 Callable < SSTableReader > callable = new Callable < SSTableReader > ( ) 
 { 
 public SSTableReader call ( ) throws IOException 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / IndexWriter . java b / src / java / org / apache / cassandra / io / sstable / IndexWriter . java 
 new file mode 100644 
 index 0000000 . . 8510241 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / io / sstable / IndexWriter . java 
 @ @ - 0 , 0 + 1 , 93 @ @ 
 + package org . apache . cassandra . io . sstable ; 
 + 
 + import java . io . DataOutputStream ; 
 + import java . io . File ; 
 + import java . io . FileOutputStream ; 
 + import java . io . IOException ; 
 + 
 + import org . slf4j . Logger ; 
 + import org . slf4j . LoggerFactory ; 
 + 
 + import org . apache . cassandra . config . DatabaseDescriptor ; 
 + import org . apache . cassandra . db . DecoratedKey ; 
 + import org . apache . cassandra . dht . IPartitioner ; 
 + import org . apache . cassandra . io . util . BufferedRandomAccessFile ; 
 + import org . apache . cassandra . io . util . FileMark ; 
 + import org . apache . cassandra . io . util . FileUtils ; 
 + import org . apache . cassandra . io . util . SegmentedFile ; 
 + import org . apache . cassandra . utils . BloomFilter ; 
 + import org . apache . cassandra . utils . ByteBufferUtil ; 
 + 
 + / * * 
 + * Encapsulates writing the index and filter for an SSTable . The state of this object is not valid until it has been closed . 
 + * / 
 + class IndexWriter 
 + { 
 + private static final Logger logger = LoggerFactory . getLogger ( SSTableWriter . class ) ; 
 + 
 + private final BufferedRandomAccessFile indexFile ; 
 + public final Descriptor desc ; 
 + public final IPartitioner partitioner ; 
 + public final SegmentedFile . Builder builder ; 
 + public final IndexSummary summary ; 
 + public final BloomFilter bf ; 
 + private FileMark mark ; 
 + 
 + IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException 
 + { 
 + this . desc = desc ; 
 + this . partitioner = part ; 
 + indexFile = new BufferedRandomAccessFile ( new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) , " rw " , 8 * 1024 * 1024 , true ) ; 
 + builder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; 
 + summary = new IndexSummary ( keyCount ) ; 
 + bf = BloomFilter . getFilter ( keyCount , 15 ) ; 
 + } 
 + 
 + public void afterAppend ( DecoratedKey key , long dataPosition ) throws IOException 
 + { 
 + bf . add ( key . key ) ; 
 + long indexPosition = indexFile . getFilePointer ( ) ; 
 + ByteBufferUtil . writeWithShortLength ( key . key , indexFile ) ; 
 + indexFile . writeLong ( dataPosition ) ; 
 + if ( logger . isTraceEnabled ( ) ) 
 + logger . trace ( " wrote index of " + key + " at " + indexPosition ) ; 
 + 
 + summary . maybeAddEntry ( key , indexPosition ) ; 
 + builder . addPotentialBoundary ( indexPosition ) ; 
 + } 
 + 
 + / * * 
 + * Closes the index and bloomfilter , making the public state of this writer valid for consumption . 
 + * / 
 + public void close ( ) throws IOException 
 + { 
 + / / bloom filter 
 + FileOutputStream fos = new FileOutputStream ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; 
 + DataOutputStream stream = new DataOutputStream ( fos ) ; 
 + BloomFilter . serializer ( ) . serialize ( bf , stream ) ; 
 + stream . flush ( ) ; 
 + fos . getFD ( ) . sync ( ) ; 
 + stream . close ( ) ; 
 + 
 + / / index 
 + long position = indexFile . getFilePointer ( ) ; 
 + indexFile . close ( ) ; / / calls force 
 + FileUtils . truncate ( indexFile . getPath ( ) , position ) ; 
 + 
 + / / finalize in - memory index state 
 + summary . complete ( ) ; 
 + } 
 + 
 + public void mark ( ) 
 + { 
 + mark = indexFile . mark ( ) ; 
 + } 
 + 
 + public void reset ( ) throws IOException 
 + { 
 + / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . 
 + / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so 
 + / / we assume that if that worked then we won ' t be trying to reset . 
 + indexFile . reset ( mark ) ; 
 + } 
 + } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / Rebuilder . java b / src / java / org / apache / cassandra / io / sstable / Rebuilder . java 
 new file mode 100644 
 index 0000000 . . 803eb64 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / io / sstable / Rebuilder . java 
 @ @ - 0 , 0 + 1 , 92 @ @ 
 + package org . apache . cassandra . io . sstable ; 
 + 
 + import java . io . File ; 
 + import java . io . IOError ; 
 + import java . io . IOException ; 
 + 
 + import org . slf4j . Logger ; 
 + import org . slf4j . LoggerFactory ; 
 + 
 + import org . apache . cassandra . db . ColumnFamilyStore ; 
 + import org . apache . cassandra . db . Table ; 
 + import org . apache . cassandra . db . compaction . CompactionInfo ; 
 + import org . apache . cassandra . db . compaction . CompactionType ; 
 + import org . apache . cassandra . streaming . OperationType ; 
 + 
 + / * * 
 + * Removes the given SSTable from temporary status and opens it , rebuilding the 
 + * bloom filter and row index from the data file . 
 + * / 
 + public class Rebuilder implements CompactionInfo . Holder 
 + { 
 + private static final Logger logger = LoggerFactory . getLogger ( SSTableWriter . class ) ; 
 + 
 + private final Descriptor desc ; 
 + private final OperationType type ; 
 + private final ColumnFamilyStore cfs ; 
 + private SSTableWriter . RowIndexer indexer ; 
 + 
 + public Rebuilder ( Descriptor desc , OperationType type ) 
 + { 
 + this . desc = desc ; 
 + this . type = type ; 
 + cfs = Table . open ( desc . ksname ) . getColumnFamilyStore ( desc . cfname ) ; 
 + } 
 + 
 + public CompactionInfo getCompactionInfo ( ) 
 + { 
 + maybeOpenIndexer ( ) ; 
 + try 
 + { 
 + / / both file offsets are still valid post - close 
 + return new CompactionInfo ( desc . ksname , 
 + desc . cfname , 
 + CompactionType . SSTABLE _ BUILD , 
 + indexer . dfile . getFilePointer ( ) , 
 + indexer . dfile . length ( ) ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new IOError ( e ) ; 
 + } 
 + } 
 + 
 + / / lazy - initialize the file to avoid opening it until it ' s actually executing on the CompactionManager , 
 + / / since the 8MB buffers can use up heap quickly 
 + private void maybeOpenIndexer ( ) 
 + { 
 + if ( indexer ! = null ) 
 + return ; 
 + try 
 + { 
 + if ( cfs . metadata . getDefaultValidator ( ) . isCommutative ( ) ) 
 + indexer = new SSTableWriter . CommutativeRowIndexer ( desc , cfs , type ) ; 
 + else 
 + indexer = new SSTableWriter . RowIndexer ( desc , cfs , type ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new IOError ( e ) ; 
 + } 
 + } 
 + 
 + public SSTableReader build ( ) throws IOException 
 + { 
 + if ( cfs . isInvalid ( ) ) 
 + return null ; 
 + maybeOpenIndexer ( ) ; 
 + 
 + File ifile = new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) ; 
 + File ffile = new File ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; 
 + assert ! ifile . exists ( ) ; 
 + assert ! ffile . exists ( ) ; 
 + 
 + long estimatedRows = indexer . prepareIndexing ( ) ; 
 + 
 + / / build the index and filter 
 + long rows = indexer . index ( ) ; 
 + 
 + logger . debug ( " estimated row count was { } of real count " , ( ( double ) estimatedRows ) / rows ) ; 
 + return SSTableReader . open ( SSTableWriter . rename ( desc , SSTable . componentsFor ( desc , false ) ) ) ; 
 + } 
 + } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 index da179e9 . . fa902b3 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 @ @ - 19 , 7 + 19 , 9 @ @ 
 
 package org . apache . cassandra . io . sstable ; 
 
 - import java . io . * ; 
 + import java . io . File ; 
 + import java . io . IOError ; 
 + import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 import java . util . Arrays ; 
 import java . util . Collections ; 
 @ @ - 27 , 10 + 29 , 6 @ @ import java . util . HashSet ; 
 import java . util . Set ; 
 
 import com . google . common . collect . Sets ; 
 - 
 - import org . apache . cassandra . db . commitlog . ReplayPosition ; 
 - import org . apache . cassandra . db . compaction . * ; 
 - import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 39 , 7 + 37 , 10 @ @ import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . db . ColumnFamily ; 
 import org . apache . cassandra . db . ColumnFamilyStore ; 
 import org . apache . cassandra . db . DecoratedKey ; 
 - import org . apache . cassandra . db . Table ; 
 + import org . apache . cassandra . db . commitlog . ReplayPosition ; 
 + import org . apache . cassandra . db . compaction . AbstractCompactedRow ; 
 + import org . apache . cassandra . db . compaction . CompactionController ; 
 + import org . apache . cassandra . db . compaction . PrecompactedRow ; 
 import org . apache . cassandra . dht . IPartitioner ; 
 import org . apache . cassandra . io . util . BufferedRandomAccessFile ; 
 import org . apache . cassandra . io . util . FileMark ; 
 @ @ - 47 , 7 + 48 , 7 @ @ import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . io . util . SegmentedFile ; 
 import org . apache . cassandra . service . StorageService ; 
 import org . apache . cassandra . streaming . OperationType ; 
 - import org . apache . cassandra . utils . BloomFilter ; 
 + import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . apache . cassandra . utils . EstimatedHistogram ; 
 import org . apache . cassandra . utils . FBUtilities ; 
 
 @ @ - 232 , 7 + 233 , 7 @ @ public class SSTableWriter extends SSTable 
 return dataFile . getFilePointer ( ) ; 
 } 
 
 - public static Builder createBuilder ( Descriptor desc , OperationType type ) 
 + public static Rebuilder createBuilder ( Descriptor desc , OperationType type ) 
 { 
 if ( ! desc . isLatestVersion ) 
 / / TODO : streaming between different versions will fail : need support for 
 @ @ - 240 , 83 + 241 , 7 @ @ public class SSTableWriter extends SSTable 
 throw new RuntimeException ( String . format ( " Cannot recover SSTable with version % s ( current version % s ) . " , 
 desc . version , Descriptor . CURRENT _ VERSION ) ) ; 
 
 - return new Builder ( desc , type ) ; 
 - } 
 - 
 - / * * 
 - * Removes the given SSTable from temporary status and opens it , rebuilding the 
 - * bloom filter and row index from the data file . 
 - * / 
 - public static class Builder implements CompactionInfo . Holder 
 - { 
 - private final Descriptor desc ; 
 - private final OperationType type ; 
 - private final ColumnFamilyStore cfs ; 
 - private RowIndexer indexer ; 
 - 
 - public Builder ( Descriptor desc , OperationType type ) 
 - { 
 - this . desc = desc ; 
 - this . type = type ; 
 - cfs = Table . open ( desc . ksname ) . getColumnFamilyStore ( desc . cfname ) ; 
 - } 
 - 
 - public CompactionInfo getCompactionInfo ( ) 
 - { 
 - maybeOpenIndexer ( ) ; 
 - try 
 - { 
 - / / both file offsets are still valid post - close 
 - return new CompactionInfo ( desc . ksname , 
 - desc . cfname , 
 - CompactionType . SSTABLE _ BUILD , 
 - indexer . dfile . getFilePointer ( ) , 
 - indexer . dfile . length ( ) ) ; 
 - } 
 - catch ( IOException e ) 
 - { 
 - throw new IOError ( e ) ; 
 - } 
 - } 
 - 
 - / / lazy - initialize the file to avoid opening it until it ' s actually executing on the CompactionManager , 
 - / / since the 8MB buffers can use up heap quickly 
 - private void maybeOpenIndexer ( ) 
 - { 
 - if ( indexer ! = null ) 
 - return ; 
 - try 
 - { 
 - if ( cfs . metadata . getDefaultValidator ( ) . isCommutative ( ) ) 
 - indexer = new CommutativeRowIndexer ( desc , cfs , type ) ; 
 - else 
 - indexer = new RowIndexer ( desc , cfs , type ) ; 
 - } 
 - catch ( IOException e ) 
 - { 
 - throw new IOError ( e ) ; 
 - } 
 - } 
 - 
 - public SSTableReader build ( ) throws IOException 
 - { 
 - if ( cfs . isInvalid ( ) ) 
 - return null ; 
 - maybeOpenIndexer ( ) ; 
 - 
 - File ifile = new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) ; 
 - File ffile = new File ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; 
 - assert ! ifile . exists ( ) ; 
 - assert ! ffile . exists ( ) ; 
 - 
 - long estimatedRows = indexer . prepareIndexing ( ) ; 
 - 
 - / / build the index and filter 
 - long rows = indexer . index ( ) ; 
 - 
 - logger . debug ( " estimated row count was { } of real count " , ( ( double ) estimatedRows ) / rows ) ; 
 - return SSTableReader . open ( rename ( desc , SSTable . componentsFor ( desc , false ) ) ) ; 
 - } 
 + return new Rebuilder ( desc , type ) ; 
 } 
 
 static class RowIndexer 
 @ @ - 540 , 75 + 465 , 4 @ @ public class SSTableWriter extends SSTable 
 } 
 } 
 
 - / * * 
 - * Encapsulates writing the index and filter for an SSTable . The state of this object is not valid until it has been closed . 
 - * / 
 - static class IndexWriter 
 - { 
 - private final BufferedRandomAccessFile indexFile ; 
 - public final Descriptor desc ; 
 - public final IPartitioner partitioner ; 
 - public final SegmentedFile . Builder builder ; 
 - public final IndexSummary summary ; 
 - public final BloomFilter bf ; 
 - private FileMark mark ; 
 - 
 - IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException 
 - { 
 - this . desc = desc ; 
 - this . partitioner = part ; 
 - indexFile = new BufferedRandomAccessFile ( new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) , " rw " , 8 * 1024 * 1024 , true ) ; 
 - builder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; 
 - summary = new IndexSummary ( keyCount ) ; 
 - bf = BloomFilter . getFilter ( keyCount , 15 ) ; 
 - } 
 - 
 - public void afterAppend ( DecoratedKey key , long dataPosition ) throws IOException 
 - { 
 - bf . add ( key . key ) ; 
 - long indexPosition = indexFile . getFilePointer ( ) ; 
 - ByteBufferUtil . writeWithShortLength ( key . key , indexFile ) ; 
 - indexFile . writeLong ( dataPosition ) ; 
 - if ( logger . isTraceEnabled ( ) ) 
 - logger . trace ( " wrote index of " + key + " at " + indexPosition ) ; 
 - 
 - summary . maybeAddEntry ( key , indexPosition ) ; 
 - builder . addPotentialBoundary ( indexPosition ) ; 
 - } 
 - 
 - / * * 
 - * Closes the index and bloomfilter , making the public state of this writer valid for consumption . 
 - * / 
 - public void close ( ) throws IOException 
 - { 
 - / / bloom filter 
 - FileOutputStream fos = new FileOutputStream ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; 
 - DataOutputStream stream = new DataOutputStream ( fos ) ; 
 - BloomFilter . serializer ( ) . serialize ( bf , stream ) ; 
 - stream . flush ( ) ; 
 - fos . getFD ( ) . sync ( ) ; 
 - stream . close ( ) ; 
 - 
 - / / index 
 - long position = indexFile . getFilePointer ( ) ; 
 - indexFile . close ( ) ; / / calls force 
 - FileUtils . truncate ( indexFile . getPath ( ) , position ) ; 
 - 
 - / / finalize in - memory index state 
 - summary . complete ( ) ; 
 - } 
 - 
 - public void mark ( ) 
 - { 
 - mark = indexFile . mark ( ) ; 
 - } 
 - 
 - public void reset ( ) throws IOException 
 - { 
 - / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . 
 - / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so 
 - / / we assume that if that worked then we won ' t be trying to reset . 
 - indexFile . reset ( mark ) ; 
 - } 
 - } 
 }
