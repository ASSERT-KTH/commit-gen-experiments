BLEU SCORE: 0.0208362582256928

TEST MSG: Move MeteredFlusher to its own thread
GENERATED MSG: Tuning knobs for dealing with large blobs and many CFs

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index bd128f5 . . 57ab5b4 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 0 . 12 : <nl> + * Move MeteredFlusher to its own thread ( CASSANDRA - 8485 ) <nl> * Fix non - distinct results in DISTNCT queries on static columns when <nl> paging is enabled ( CASSANDRA - 8087 ) <nl> * Move all hints related tasks to hints internal executor ( CASSANDRA - 8285 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / MeteredFlusher . java b / src / java / org / apache / cassandra / db / MeteredFlusher . java <nl> index 4f06bc6 . . 30dbb23 100644 <nl> - - - a / src / java / org / apache / cassandra / db / MeteredFlusher . java <nl> + + + b / src / java / org / apache / cassandra / db / MeteredFlusher . java <nl> @ @ - 21 , 16 + 21 , 33 @ @ import java . util . ArrayList ; <nl> import java . util . Collections ; <nl> import java . util . Comparator ; <nl> import java . util . List ; <nl> + import java . util . concurrent . ScheduledExecutorService ; <nl> + import java . util . concurrent . TimeUnit ; <nl> <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> + import org . apache . cassandra . concurrent . DebuggableScheduledThreadPoolExecutor ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> <nl> public class MeteredFlusher implements Runnable <nl> { <nl> private static final Logger logger = LoggerFactory . getLogger ( MeteredFlusher . class ) ; <nl> <nl> + public static final MeteredFlusher instance = new MeteredFlusher ( ) ; <nl> + <nl> + private final ScheduledExecutorService executor ; <nl> + <nl> + private MeteredFlusher ( ) <nl> + { <nl> + executor = new DebuggableScheduledThreadPoolExecutor ( " MeteredFlusher " ) ; <nl> + } <nl> + <nl> + public void start ( ) <nl> + { <nl> + executor . scheduleWithFixedDelay ( this , 1 , 1 , TimeUnit . SECONDS ) ; <nl> + } <nl> + <nl> public void run ( ) <nl> { <nl> long allowedSize = calculateAllowedSize ( ) ; <nl> @ @ - 55 , 7 + 72 , 7 @ @ public class MeteredFlusher implements Runnable <nl> long size = cfs . getTotalMemtableLiveSize ( ) ; <nl> if ( allowedSize > flushingSize & & size > ( allowedSize - flushingSize ) / maxInFlight ) <nl> { <nl> - logger . info ( " flushing high - traffic column family { } ( estimated { } bytes ) " , cfs , size ) ; <nl> + logger . info ( " Flushing high - traffic column family { } ( estimated { } bytes ) " , cfs , size ) ; <nl> cfs . forceFlush ( ) ; <nl> } <nl> else <nl> @ @ - 66 , 7 + 83 , 7 @ @ public class MeteredFlusher implements Runnable <nl> <nl> if ( liveSize + flushingSize < = allowedSize ) <nl> return ; <nl> - logger . info ( " estimated { } live and { } flushing bytes used by all memtables " , liveSize , flushingSize ) ; <nl> + logger . info ( " Estimated { } live and { } flushing bytes used by all memtables " , liveSize , flushingSize ) ; <nl> <nl> Collections . sort ( affectedCFs , new Comparator < ColumnFamilyStore > ( ) <nl> { <nl> @ @ - 89 , 16 + 106 , 16 @ @ public class MeteredFlusher implements Runnable <nl> long size = cfs . getTotalMemtableLiveSize ( ) ; <nl> if ( size > 0 ) <nl> { <nl> - logger . info ( " flushing { } to free up { } bytes " , cfs , size ) ; <nl> + logger . info ( " Flushing { } to free up { } bytes " , cfs , size ) ; <nl> liveSize - = size ; <nl> cfs . forceFlush ( ) ; <nl> } <nl> } <nl> <nl> - logger . trace ( " memtable memory usage is { } bytes with { } live " , liveSize + flushingSize , liveSize ) ; <nl> + logger . trace ( " Memtable memory usage is { } bytes with { } live " , liveSize + flushingSize , liveSize ) ; <nl> } <nl> <nl> - private static List < ColumnFamilyStore > affectedColumnFamilies ( ) <nl> + private List < ColumnFamilyStore > affectedColumnFamilies ( ) <nl> { <nl> List < ColumnFamilyStore > affected = new ArrayList < > ( ) ; <nl> / / filter out column families that aren ' t affected by MeteredFlusher <nl> @ @ - 108 , 7 + 125 , 7 @ @ public class MeteredFlusher implements Runnable <nl> return affected ; <nl> } <nl> <nl> - private static long calculateAllowedSize ( ) <nl> + private long calculateAllowedSize ( ) <nl> { <nl> long allowed = DatabaseDescriptor . getTotalMemtableSpaceInMB ( ) * 1048576L ; <nl> / / deduct the combined memory limit of the tables unaffected by the metered flusher ( we don ' t flush them , we <nl> @ @ - 119 , 7 + 136 , 7 @ @ public class MeteredFlusher implements Runnable <nl> return allowed ; <nl> } <nl> <nl> - private static long calculateFlushingSize ( ) <nl> + private long calculateFlushingSize ( ) <nl> { <nl> ColumnFamilyStore measuredCFS = Memtable . activelyMeasuring ; <nl> long flushing = measuredCFS ! = null & & measuredCFS . getCompactionStrategy ( ) . isAffectedByMeteredFlusher ( ) <nl> diff - - git a / src / java / org / apache / cassandra / service / CassandraDaemon . java b / src / java / org / apache / cassandra / service / CassandraDaemon . java <nl> index 89d2bb0 . . cad1658 100644 <nl> - - - a / src / java / org / apache / cassandra / service / CassandraDaemon . java <nl> + + + b / src / java / org / apache / cassandra / service / CassandraDaemon . java <nl> @ @ - 328 , 7 + 328 , 7 @ @ public class CassandraDaemon <nl> <nl> / / MeteredFlusher can block if flush queue fills up , so don ' t put on scheduledTasks <nl> / / Start it before commit log , so memtables can flush during commit log replay <nl> - StorageService . optionalTasks . scheduleWithFixedDelay ( new MeteredFlusher ( ) , 1000 , 1000 , TimeUnit . MILLISECONDS ) ; <nl> + MeteredFlusher . instance . start ( ) ; <nl> <nl> / / replay the log if necessary <nl> try
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index f48fb5c . . 2192fe9 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 20 , 7 + 20 , 8 @ @ <nl> * Fix potential AssertionError during tracing ( CASSANDRA - 6041 ) <nl> * Fix NPE in sstablesplit ( CASSANDRA - 6027 ) <nl> Merged from 1 . 2 : <nl> - 1 . 2 . 10 <nl> + * Tuning knobs for dealing with large blobs and many CFs ( CASSANDRA - 5982 ) <nl> + * ( Hadoop ) Fix CQLRW for thrift tables ( CASSANDRA - 6002 ) <nl> * Fix possible divide - by - zero in HHOM ( CASSANDRA - 5990 ) <nl> * Allow local batchlog writes for CL . ANY ( CASSANDRA - 5967 ) <nl> * Optimize name query performance in wide rows ( CASSANDRA - 5966 ) <nl> diff - - git a / conf / cassandra . yaml b / conf / cassandra . yaml <nl> index aef3e60 . . 4decf6c 100644 <nl> - - - a / conf / cassandra . yaml <nl> + + + b / conf / cassandra . yaml <nl> @ @ - 194 , 9 + 194 , 13 @ @ saved _ caches _ directory : / var / lib / cassandra / saved _ caches <nl> # <nl> # the other option is " periodic " where writes may be acked immediately <nl> # and the CommitLog is simply synced every commitlog _ sync _ period _ in _ ms <nl> - # milliseconds . <nl> + # milliseconds . By default this allows 1024 * ( CPU cores ) pending <nl> + # entries on the commitlog queue . If you are writing very large blobs , <nl> + # you should reduce that ; 16 * cores works reasonably well for 1MB blobs . <nl> + # It should be at least as large as the concurrent _ writes setting . <nl> commitlog _ sync : periodic <nl> commitlog _ sync _ period _ in _ ms : 10000 <nl> + # commitlog _ periodic _ queue _ size : <nl> <nl> # The size of the individual commitlog file segments . A commitlog <nl> # segment may be archived , deleted , or recycled once all the data <nl> diff - - git a / src / java / org / apache / cassandra / config / Config . java b / src / java / org / apache / cassandra / config / Config . java <nl> index 99fd833 . . dd0728c 100644 <nl> - - - a / src / java / org / apache / cassandra / config / Config . java <nl> + + + b / src / java / org / apache / cassandra / config / Config . java <nl> @ @ - 126 , 6 + 126 , 7 @ @ public class Config <nl> public Double commitlog _ sync _ batch _ window _ in _ ms ; <nl> public Integer commitlog _ sync _ period _ in _ ms ; <nl> public int commitlog _ segment _ size _ in _ mb = 32 ; <nl> + public int commitlog _ periodic _ queue _ size = 1024 * FBUtilities . getAvailableProcessors ( ) ; <nl> <nl> public String endpoint _ snitch ; <nl> public Boolean dynamic _ snitch = true ; <nl> diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> index 1e1b9a2 . . c2f3fa6 100644 <nl> - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> @ @ - 989 , 10 + 989 , 16 @ @ public class DatabaseDescriptor <nl> return conf . commitlog _ sync _ batch _ window _ in _ ms ; <nl> } <nl> <nl> - public static int getCommitLogSyncPeriod ( ) { <nl> + public static int getCommitLogSyncPeriod ( ) <nl> + { <nl> return conf . commitlog _ sync _ period _ in _ ms ; <nl> } <nl> <nl> + public static int getCommitLogPeriodicQueueSize ( ) <nl> + { <nl> + return conf . commitlog _ periodic _ queue _ size ; <nl> + } <nl> + <nl> public static Config . CommitLogSync getCommitLogSync ( ) <nl> { <nl> return conf . commitlog _ sync ; <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index 93b8905 . . 4c9f72d 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 108 , 7 + 108 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> public final Directories directories ; <nl> <nl> / * * ratio of in - memory memtable size , to serialized size * / <nl> - volatile double liveRatio = 1 . 0 ; <nl> + volatile double liveRatio = 10 . 0 ; / / reasonable default until we compute what it is based on actual data <nl> / * * ops count last time we computed liveRatio * / <nl> private final AtomicLong liveRatioComputedAt = new AtomicLong ( 32 ) ; <nl> <nl> @ @ - 1103 , 7 + 1103 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> return ( int ) metric . memtableSwitchCount . count ( ) ; <nl> } <nl> <nl> - private Memtable getMemtableThreadSafe ( ) <nl> + Memtable getMemtableThreadSafe ( ) <nl> { <nl> return data . getMemtable ( ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / Memtable . java b / src / java / org / apache / cassandra / db / Memtable . java <nl> index 2b3ca1e . . 4cca602 100644 <nl> - - - a / src / java / org / apache / cassandra / db / Memtable . java <nl> + + + b / src / java / org / apache / cassandra / db / Memtable . java <nl> @ @ - 28 , 7 + 28 , 6 @ @ import org . cliffc . high _ scale _ lib . NonBlockingHashSet ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> - import org . apache . cassandra . concurrent . DebuggableThreadPoolExecutor ; <nl> import org . apache . cassandra . concurrent . JMXEnabledThreadPoolExecutor ; <nl> import org . apache . cassandra . concurrent . NamedThreadFactory ; <nl> import org . apache . cassandra . concurrent . StageManager ; <nl> @ @ - 78 , 24 + 77 , 15 @ @ public class Memtable <nl> / / outstanding / running meterings to a maximum of one per CFS using this set ; the executor ' s queue is unbounded but <nl> / / will implicitly be bounded by the number of CFS : s . <nl> private static final Set < ColumnFamilyStore > meteringInProgress = new NonBlockingHashSet < ColumnFamilyStore > ( ) ; <nl> - private static final ExecutorService meterExecutor = new DebuggableThreadPoolExecutor ( 1 , <nl> - 1 , <nl> + private static final ExecutorService meterExecutor = new JMXEnabledThreadPoolExecutor ( 1 , <nl> Integer . MAX _ VALUE , <nl> TimeUnit . MILLISECONDS , <nl> new LinkedBlockingQueue < Runnable > ( ) , <nl> - new NamedThreadFactory ( " MemoryMeter " ) ) <nl> - { <nl> - @ Override <nl> - protected void afterExecute ( Runnable r , Throwable t ) <nl> - { <nl> - super . afterExecute ( r , t ) ; <nl> - DebuggableThreadPoolExecutor . logExceptionsAfterExecute ( r , t ) ; <nl> - } <nl> - } ; <nl> - <nl> + new NamedThreadFactory ( " MemoryMeter " ) , <nl> + " internal " ) ; <nl> private final MemoryMeter meter ; <nl> <nl> - volatile static Memtable activelyMeasuring ; <nl> + volatile static ColumnFamilyStore activelyMeasuring ; <nl> <nl> private final AtomicLong currentSize = new AtomicLong ( 0 ) ; <nl> private final AtomicLong currentOperations = new AtomicLong ( 0 ) ; <nl> @ @ - 175 , 8 + 165 , 9 @ @ public class Memtable <nl> if ( ! MemoryMeter . isInitialized ( ) ) <nl> { <nl> / / hack for openjdk . we log a warning about this in the startup script too . <nl> - logger . warn ( " MemoryMeter uninitialized ( jamm not specified as java agent ) ; assuming liveRatio of 10 . 0 . Usually this means cassandra - env . sh disabled jamm because you are using a buggy JRE ; upgrade to the Sun JRE instead " ) ; <nl> - cfs . liveRatio = 10 . 0 ; <nl> + logger . warn ( " MemoryMeter uninitialized ( jamm not specified as java agent ) ; assuming liveRatio of { } . " <nl> + + " Usually this means cassandra - env . sh disabled jamm because you are using a buggy JRE ; " <nl> + + " upgrade to the Sun JRE instead " , cfs . liveRatio ) ; <nl> return ; <nl> } <nl> <nl> @ @ - 186 , 56 + 177 , 7 @ @ public class Memtable <nl> return ; <nl> } <nl> <nl> - Runnable runnable = new Runnable ( ) <nl> - { <nl> - public void run ( ) <nl> - { <nl> - try <nl> - { <nl> - activelyMeasuring = Memtable . this ; <nl> - <nl> - long start = System . nanoTime ( ) ; <nl> - / / ConcurrentSkipListMap has cycles , so measureDeep will have to track a reference to EACH object it visits . <nl> - / / So to reduce the memory overhead of doing a measurement , we break it up to row - at - a - time . <nl> - long deepSize = meter . measure ( rows ) ; <nl> - int objects = 0 ; <nl> - for ( Map . Entry < RowPosition , AtomicSortedColumns > entry : rows . entrySet ( ) ) <nl> - { <nl> - deepSize + = meter . measureDeep ( entry . getKey ( ) ) + meter . measureDeep ( entry . getValue ( ) ) ; <nl> - objects + = entry . getValue ( ) . getColumnCount ( ) ; <nl> - } <nl> - double newRatio = ( double ) deepSize / currentSize . get ( ) ; <nl> - <nl> - if ( newRatio < MIN _ SANE _ LIVE _ RATIO ) <nl> - { <nl> - logger . warn ( " setting live ratio to minimum of { } instead of { } " , MIN _ SANE _ LIVE _ RATIO , newRatio ) ; <nl> - newRatio = MIN _ SANE _ LIVE _ RATIO ; <nl> - } <nl> - if ( newRatio > MAX _ SANE _ LIVE _ RATIO ) <nl> - { <nl> - logger . warn ( " setting live ratio to maximum of { } instead of { } " , MAX _ SANE _ LIVE _ RATIO , newRatio ) ; <nl> - newRatio = MAX _ SANE _ LIVE _ RATIO ; <nl> - } <nl> - <nl> - / / we want to be very conservative about our estimate , since the penalty for guessing low is OOM <nl> - / / death . thus , higher estimates are believed immediately ; lower ones are averaged w / the old <nl> - if ( newRatio > cfs . liveRatio ) <nl> - cfs . liveRatio = newRatio ; <nl> - else <nl> - cfs . liveRatio = ( cfs . liveRatio + newRatio ) / 2 . 0 ; <nl> - <nl> - logger . info ( " { } liveRatio is { } ( just - counted was { } ) . calculation took { } ms for { } columns " , <nl> - cfs , cfs . liveRatio , newRatio , TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - start ) , objects ) ; <nl> - activelyMeasuring = null ; <nl> - } <nl> - finally <nl> - { <nl> - meteringInProgress . remove ( cfs ) ; <nl> - } <nl> - } <nl> - } ; <nl> - <nl> - meterExecutor . submit ( runnable ) ; <nl> + meterExecutor . submit ( new MeteringRunnable ( cfs ) ) ; <nl> } <nl> <nl> private void resolve ( DecoratedKey key , ColumnFamily cf , SecondaryIndexManager . Updater indexer ) <nl> @ @ - 448 , 4 + 390 , 63 @ @ public class Memtable <nl> sstableMetadataCollector ) ; <nl> } <nl> } <nl> + <nl> + private static class MeteringRunnable implements Runnable <nl> + { <nl> + / / we might need to wait in the meter queue for a while . measure whichever memtable is active at that point , <nl> + / / rather than keeping the original memtable referenced ( and thus un - freeable ) until this runs . <nl> + private final ColumnFamilyStore cfs ; <nl> + <nl> + public MeteringRunnable ( ColumnFamilyStore cfs ) <nl> + { <nl> + this . cfs = cfs ; <nl> + } <nl> + <nl> + public void run ( ) <nl> + { <nl> + try <nl> + { <nl> + activelyMeasuring = cfs ; <nl> + Memtable memtable = cfs . getMemtableThreadSafe ( ) ; <nl> + <nl> + long start = System . nanoTime ( ) ; <nl> + / / ConcurrentSkipListMap has cycles , so measureDeep will have to track a reference to EACH object it visits . <nl> + / / So to reduce the memory overhead of doing a measurement , we break it up to row - at - a - time . <nl> + long deepSize = memtable . meter . measure ( memtable . rows ) ; <nl> + int objects = 0 ; <nl> + for ( Map . Entry < RowPosition , AtomicSortedColumns > entry : memtable . rows . entrySet ( ) ) <nl> + { <nl> + deepSize + = memtable . meter . measureDeep ( entry . getKey ( ) ) + memtable . meter . measureDeep ( entry . getValue ( ) ) ; <nl> + objects + = entry . getValue ( ) . getColumnCount ( ) ; <nl> + } <nl> + double newRatio = ( double ) deepSize / memtable . currentSize . get ( ) ; <nl> + <nl> + if ( newRatio < MIN _ SANE _ LIVE _ RATIO ) <nl> + { <nl> + logger . warn ( " setting live ratio to minimum of { } instead of { } " , MIN _ SANE _ LIVE _ RATIO , newRatio ) ; <nl> + newRatio = MIN _ SANE _ LIVE _ RATIO ; <nl> + } <nl> + if ( newRatio > MAX _ SANE _ LIVE _ RATIO ) <nl> + { <nl> + logger . warn ( " setting live ratio to maximum of { } instead of { } " , MAX _ SANE _ LIVE _ RATIO , newRatio ) ; <nl> + newRatio = MAX _ SANE _ LIVE _ RATIO ; <nl> + } <nl> + <nl> + / / we want to be very conservative about our estimate , since the penalty for guessing low is OOM <nl> + / / death . thus , higher estimates are believed immediately ; lower ones are averaged w / the old <nl> + if ( newRatio > cfs . liveRatio ) <nl> + cfs . liveRatio = newRatio ; <nl> + else <nl> + cfs . liveRatio = ( cfs . liveRatio + newRatio ) / 2 . 0 ; <nl> + <nl> + logger . info ( " { } liveRatio is { } ( just - counted was { } ) . calculation took { } ms for { } columns " , <nl> + cfs , cfs . liveRatio , newRatio , TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - start ) , objects ) ; <nl> + } <nl> + finally <nl> + { <nl> + activelyMeasuring = null ; <nl> + meteringInProgress . remove ( cfs ) ; <nl> + } <nl> + } <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / MeteredFlusher . java b / src / java / org / apache / cassandra / db / MeteredFlusher . java <nl> index 408727c . . f16b8a0 100644 <nl> - - - a / src / java / org / apache / cassandra / db / MeteredFlusher . java <nl> + + + b / src / java / org / apache / cassandra / db / MeteredFlusher . java <nl> @ @ - 35 , 16 + 35 , 22 @ @ public class MeteredFlusher implements Runnable <nl> <nl> public void run ( ) <nl> { <nl> + long totalMemtableBytesAllowed = DatabaseDescriptor . getTotalMemtableSpaceInMB ( ) * 1048576L ; <nl> + <nl> / / first , find how much memory non - active memtables are using <nl> - Memtable activelyMeasuring = Memtable . activelyMeasuring ; <nl> - long flushingBytes = activelyMeasuring = = null ? 0 : activelyMeasuring . getLiveSize ( ) ; <nl> + long flushingBytes = Memtable . activelyMeasuring = = null <nl> + ? 0 <nl> + : Memtable . activelyMeasuring . getMemtableThreadSafe ( ) . getLiveSize ( ) ; <nl> flushingBytes + = countFlushingBytes ( ) ; <nl> + if ( flushingBytes > 0 ) <nl> + logger . debug ( " Currently flushing { } bytes of { } max " , flushingBytes , totalMemtableBytesAllowed ) ; <nl> <nl> / / next , flush CFs using more than 1 / ( maximum number of memtables it could have in the pipeline ) <nl> / / of the total size allotted . Then , flush other CFs in order of size if necessary . <nl> long liveBytes = 0 ; <nl> try <nl> { <nl> + long totalMemtableBytesUnused = totalMemtableBytesAllowed - flushingBytes ; <nl> for ( ColumnFamilyStore cfs : ColumnFamilyStore . all ( ) ) <nl> { <nl> long size = cfs . getTotalMemtableLiveSize ( ) ; <nl> @ @ - 53 , 7 + 59 , 7 @ @ public class MeteredFlusher implements Runnable <nl> + DatabaseDescriptor . getFlushWriters ( ) <nl> + DatabaseDescriptor . getFlushQueueSize ( ) ) <nl> / ( 1 + cfs . indexManager . getIndexesBackedByCfs ( ) . size ( ) ) ) ; <nl> - if ( size > ( DatabaseDescriptor . getTotalMemtableSpaceInMB ( ) * 1048576L - flushingBytes ) / maxInFlight ) <nl> + if ( totalMemtableBytesUnused > 0 & & size > totalMemtableBytesUnused / maxInFlight ) <nl> { <nl> logger . info ( " flushing high - traffic column family { } ( estimated { } bytes ) " , cfs , size ) ; <nl> cfs . forceFlush ( ) ; <nl> @ @ - 64 , 10 + 70 , 10 @ @ public class MeteredFlusher implements Runnable <nl> } <nl> } <nl> <nl> - if ( flushingBytes + liveBytes < = DatabaseDescriptor . getTotalMemtableSpaceInMB ( ) * 1048576L ) <nl> + if ( flushingBytes + liveBytes < = totalMemtableBytesAllowed ) <nl> return ; <nl> <nl> - logger . info ( " estimated { } bytes used by all memtables pre - flush " , liveBytes ) ; <nl> + logger . info ( " estimated { } live and { } flushing bytes used by all memtables " , liveBytes , flushingBytes ) ; <nl> <nl> / / sort memtables by size <nl> List < ColumnFamilyStore > sorted = new ArrayList < ColumnFamilyStore > ( ) ; <nl> @ @ - 89 , 14 + 95 , 16 @ @ public class MeteredFlusher implements Runnable <nl> / / flush largest first until we get below our threshold . <nl> / / although it looks like liveBytes + flushingBytes will stay a constant , it will not if flushes finish <nl> / / while we loop , which is especially likely to happen if the flush queue fills up ( so further forceFlush calls block ) <nl> - while ( true ) <nl> + while ( ! sorted . isEmpty ( ) ) <nl> { <nl> flushingBytes = countFlushingBytes ( ) ; <nl> - if ( liveBytes + flushingBytes < = DatabaseDescriptor . getTotalMemtableSpaceInMB ( ) * 1048576L | | sorted . isEmpty ( ) ) <nl> + if ( liveBytes + flushingBytes < = totalMemtableBytesAllowed ) <nl> break ; <nl> <nl> ColumnFamilyStore cfs = sorted . remove ( sorted . size ( ) - 1 ) ; <nl> long size = cfs . getTotalMemtableLiveSize ( ) ; <nl> + if ( size = = 0 ) <nl> + break ; <nl> logger . info ( " flushing { } to free up { } bytes " , cfs , size ) ; <nl> liveBytes - = size ; <nl> cfs . forceFlush ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / commitlog / PeriodicCommitLogExecutorService . java b / src / java / org / apache / cassandra / db / commitlog / PeriodicCommitLogExecutorService . java <nl> index 7a0a761 . . 30f33b6 100644 <nl> - - - a / src / java / org / apache / cassandra / db / commitlog / PeriodicCommitLogExecutorService . java <nl> + + + b / src / java / org / apache / cassandra / db / commitlog / PeriodicCommitLogExecutorService . java <nl> @ @ - 35 , 7 + 35 , 7 @ @ class PeriodicCommitLogExecutorService implements ICommitLogExecutorService <nl> <nl> public PeriodicCommitLogExecutorService ( final CommitLog commitLog ) <nl> { <nl> - queue = new LinkedBlockingQueue < Runnable > ( 1024 * FBUtilities . getAvailableProcessors ( ) ) ; <nl> + queue = new LinkedBlockingQueue < Runnable > ( DatabaseDescriptor . getCommitLogPeriodicQueueSize ( ) ) ; <nl> Runnable runnable = new WrappedRunnable ( ) <nl> { <nl> public void runMayThrow ( ) throws Exception <nl> diff - - git a / src / java / org / apache / cassandra / utils / StatusLogger . java b / src / java / org / apache / cassandra / utils / StatusLogger . java <nl> index 2b9627f . . 939c81f 100644 <nl> - - - a / src / java / org / apache / cassandra / utils / StatusLogger . java <nl> + + + b / src / java / org / apache / cassandra / utils / StatusLogger . java <nl> @ @ - 19 , 6 + 19 , 8 @ @ package org . apache . cassandra . utils ; <nl> <nl> import java . lang . management . ManagementFactory ; <nl> import java . util . Set ; <nl> + import java . util . concurrent . ExecutorService ; <nl> + import java . util . concurrent . ThreadPoolExecutor ; <nl> import javax . management . JMX ; <nl> import javax . management . MBeanServer ; <nl> import javax . management . MalformedObjectNameException ; <nl> @ @ - 34 , 7 + 36 , 9 @ @ import org . slf4j . LoggerFactory ; <nl> import org . apache . cassandra . concurrent . JMXEnabledThreadPoolExecutorMBean ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . db . ColumnFamilyStore ; <nl> + import org . apache . cassandra . db . Memtable ; <nl> import org . apache . cassandra . db . RowIndexEntry ; <nl> + import org . apache . cassandra . db . commitlog . CommitLog ; <nl> import org . apache . cassandra . db . compaction . CompactionManager ; <nl> import org . apache . cassandra . net . MessagingService ; <nl> import org . apache . cassandra . service . CacheService ; <nl> @ @ - 72 , 9 + 76 , 10 @ @ public class StatusLogger <nl> threadPoolProxy . getTotalBlockedTasks ( ) ) ) ; <nl> } <nl> / / one offs <nl> - CompactionManager cm = CompactionManager . instance ; <nl> logger . info ( String . format ( " % - 25s % 10s % 10s " , <nl> - " CompactionManager " , cm . getActiveCompactions ( ) , cm . getPendingTasks ( ) ) ) ; <nl> + " CompactionManager " , CompactionManager . instance . getActiveCompactions ( ) , CompactionManager . instance . getPendingTasks ( ) ) ) ; <nl> + logger . info ( String . format ( " % - 25s % 10s % 10s " , <nl> + " Commitlog " , " n / a " , CommitLog . instance . getPendingTasks ( ) ) ) ; <nl> int pendingCommands = 0 ; <nl> for ( int n : MessagingService . instance ( ) . getCommandPendingTasks ( ) . values ( ) ) <nl> {

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index bd128f5 . . 57ab5b4 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 0 . 12 : 
 + * Move MeteredFlusher to its own thread ( CASSANDRA - 8485 ) 
 * Fix non - distinct results in DISTNCT queries on static columns when 
 paging is enabled ( CASSANDRA - 8087 ) 
 * Move all hints related tasks to hints internal executor ( CASSANDRA - 8285 ) 
 diff - - git a / src / java / org / apache / cassandra / db / MeteredFlusher . java b / src / java / org / apache / cassandra / db / MeteredFlusher . java 
 index 4f06bc6 . . 30dbb23 100644 
 - - - a / src / java / org / apache / cassandra / db / MeteredFlusher . java 
 + + + b / src / java / org / apache / cassandra / db / MeteredFlusher . java 
 @ @ - 21 , 16 + 21 , 33 @ @ import java . util . ArrayList ; 
 import java . util . Collections ; 
 import java . util . Comparator ; 
 import java . util . List ; 
 + import java . util . concurrent . ScheduledExecutorService ; 
 + import java . util . concurrent . TimeUnit ; 
 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 + import org . apache . cassandra . concurrent . DebuggableScheduledThreadPoolExecutor ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 
 public class MeteredFlusher implements Runnable 
 { 
 private static final Logger logger = LoggerFactory . getLogger ( MeteredFlusher . class ) ; 
 
 + public static final MeteredFlusher instance = new MeteredFlusher ( ) ; 
 + 
 + private final ScheduledExecutorService executor ; 
 + 
 + private MeteredFlusher ( ) 
 + { 
 + executor = new DebuggableScheduledThreadPoolExecutor ( " MeteredFlusher " ) ; 
 + } 
 + 
 + public void start ( ) 
 + { 
 + executor . scheduleWithFixedDelay ( this , 1 , 1 , TimeUnit . SECONDS ) ; 
 + } 
 + 
 public void run ( ) 
 { 
 long allowedSize = calculateAllowedSize ( ) ; 
 @ @ - 55 , 7 + 72 , 7 @ @ public class MeteredFlusher implements Runnable 
 long size = cfs . getTotalMemtableLiveSize ( ) ; 
 if ( allowedSize > flushingSize & & size > ( allowedSize - flushingSize ) / maxInFlight ) 
 { 
 - logger . info ( " flushing high - traffic column family { } ( estimated { } bytes ) " , cfs , size ) ; 
 + logger . info ( " Flushing high - traffic column family { } ( estimated { } bytes ) " , cfs , size ) ; 
 cfs . forceFlush ( ) ; 
 } 
 else 
 @ @ - 66 , 7 + 83 , 7 @ @ public class MeteredFlusher implements Runnable 
 
 if ( liveSize + flushingSize < = allowedSize ) 
 return ; 
 - logger . info ( " estimated { } live and { } flushing bytes used by all memtables " , liveSize , flushingSize ) ; 
 + logger . info ( " Estimated { } live and { } flushing bytes used by all memtables " , liveSize , flushingSize ) ; 
 
 Collections . sort ( affectedCFs , new Comparator < ColumnFamilyStore > ( ) 
 { 
 @ @ - 89 , 16 + 106 , 16 @ @ public class MeteredFlusher implements Runnable 
 long size = cfs . getTotalMemtableLiveSize ( ) ; 
 if ( size > 0 ) 
 { 
 - logger . info ( " flushing { } to free up { } bytes " , cfs , size ) ; 
 + logger . info ( " Flushing { } to free up { } bytes " , cfs , size ) ; 
 liveSize - = size ; 
 cfs . forceFlush ( ) ; 
 } 
 } 
 
 - logger . trace ( " memtable memory usage is { } bytes with { } live " , liveSize + flushingSize , liveSize ) ; 
 + logger . trace ( " Memtable memory usage is { } bytes with { } live " , liveSize + flushingSize , liveSize ) ; 
 } 
 
 - private static List < ColumnFamilyStore > affectedColumnFamilies ( ) 
 + private List < ColumnFamilyStore > affectedColumnFamilies ( ) 
 { 
 List < ColumnFamilyStore > affected = new ArrayList < > ( ) ; 
 / / filter out column families that aren ' t affected by MeteredFlusher 
 @ @ - 108 , 7 + 125 , 7 @ @ public class MeteredFlusher implements Runnable 
 return affected ; 
 } 
 
 - private static long calculateAllowedSize ( ) 
 + private long calculateAllowedSize ( ) 
 { 
 long allowed = DatabaseDescriptor . getTotalMemtableSpaceInMB ( ) * 1048576L ; 
 / / deduct the combined memory limit of the tables unaffected by the metered flusher ( we don ' t flush them , we 
 @ @ - 119 , 7 + 136 , 7 @ @ public class MeteredFlusher implements Runnable 
 return allowed ; 
 } 
 
 - private static long calculateFlushingSize ( ) 
 + private long calculateFlushingSize ( ) 
 { 
 ColumnFamilyStore measuredCFS = Memtable . activelyMeasuring ; 
 long flushing = measuredCFS ! = null & & measuredCFS . getCompactionStrategy ( ) . isAffectedByMeteredFlusher ( ) 
 diff - - git a / src / java / org / apache / cassandra / service / CassandraDaemon . java b / src / java / org / apache / cassandra / service / CassandraDaemon . java 
 index 89d2bb0 . . cad1658 100644 
 - - - a / src / java / org / apache / cassandra / service / CassandraDaemon . java 
 + + + b / src / java / org / apache / cassandra / service / CassandraDaemon . java 
 @ @ - 328 , 7 + 328 , 7 @ @ public class CassandraDaemon 
 
 / / MeteredFlusher can block if flush queue fills up , so don ' t put on scheduledTasks 
 / / Start it before commit log , so memtables can flush during commit log replay 
 - StorageService . optionalTasks . scheduleWithFixedDelay ( new MeteredFlusher ( ) , 1000 , 1000 , TimeUnit . MILLISECONDS ) ; 
 + MeteredFlusher . instance . start ( ) ; 
 
 / / replay the log if necessary 
 try

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index f48fb5c . . 2192fe9 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 20 , 7 + 20 , 8 @ @ 
 * Fix potential AssertionError during tracing ( CASSANDRA - 6041 ) 
 * Fix NPE in sstablesplit ( CASSANDRA - 6027 ) 
 Merged from 1 . 2 : 
 - 1 . 2 . 10 
 + * Tuning knobs for dealing with large blobs and many CFs ( CASSANDRA - 5982 ) 
 + * ( Hadoop ) Fix CQLRW for thrift tables ( CASSANDRA - 6002 ) 
 * Fix possible divide - by - zero in HHOM ( CASSANDRA - 5990 ) 
 * Allow local batchlog writes for CL . ANY ( CASSANDRA - 5967 ) 
 * Optimize name query performance in wide rows ( CASSANDRA - 5966 ) 
 diff - - git a / conf / cassandra . yaml b / conf / cassandra . yaml 
 index aef3e60 . . 4decf6c 100644 
 - - - a / conf / cassandra . yaml 
 + + + b / conf / cassandra . yaml 
 @ @ - 194 , 9 + 194 , 13 @ @ saved _ caches _ directory : / var / lib / cassandra / saved _ caches 
 # 
 # the other option is " periodic " where writes may be acked immediately 
 # and the CommitLog is simply synced every commitlog _ sync _ period _ in _ ms 
 - # milliseconds . 
 + # milliseconds . By default this allows 1024 * ( CPU cores ) pending 
 + # entries on the commitlog queue . If you are writing very large blobs , 
 + # you should reduce that ; 16 * cores works reasonably well for 1MB blobs . 
 + # It should be at least as large as the concurrent _ writes setting . 
 commitlog _ sync : periodic 
 commitlog _ sync _ period _ in _ ms : 10000 
 + # commitlog _ periodic _ queue _ size : 
 
 # The size of the individual commitlog file segments . A commitlog 
 # segment may be archived , deleted , or recycled once all the data 
 diff - - git a / src / java / org / apache / cassandra / config / Config . java b / src / java / org / apache / cassandra / config / Config . java 
 index 99fd833 . . dd0728c 100644 
 - - - a / src / java / org / apache / cassandra / config / Config . java 
 + + + b / src / java / org / apache / cassandra / config / Config . java 
 @ @ - 126 , 6 + 126 , 7 @ @ public class Config 
 public Double commitlog _ sync _ batch _ window _ in _ ms ; 
 public Integer commitlog _ sync _ period _ in _ ms ; 
 public int commitlog _ segment _ size _ in _ mb = 32 ; 
 + public int commitlog _ periodic _ queue _ size = 1024 * FBUtilities . getAvailableProcessors ( ) ; 
 
 public String endpoint _ snitch ; 
 public Boolean dynamic _ snitch = true ; 
 diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 index 1e1b9a2 . . c2f3fa6 100644 
 - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 @ @ - 989 , 10 + 989 , 16 @ @ public class DatabaseDescriptor 
 return conf . commitlog _ sync _ batch _ window _ in _ ms ; 
 } 
 
 - public static int getCommitLogSyncPeriod ( ) { 
 + public static int getCommitLogSyncPeriod ( ) 
 + { 
 return conf . commitlog _ sync _ period _ in _ ms ; 
 } 
 
 + public static int getCommitLogPeriodicQueueSize ( ) 
 + { 
 + return conf . commitlog _ periodic _ queue _ size ; 
 + } 
 + 
 public static Config . CommitLogSync getCommitLogSync ( ) 
 { 
 return conf . commitlog _ sync ; 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index 93b8905 . . 4c9f72d 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 108 , 7 + 108 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 public final Directories directories ; 
 
 / * * ratio of in - memory memtable size , to serialized size * / 
 - volatile double liveRatio = 1 . 0 ; 
 + volatile double liveRatio = 10 . 0 ; / / reasonable default until we compute what it is based on actual data 
 / * * ops count last time we computed liveRatio * / 
 private final AtomicLong liveRatioComputedAt = new AtomicLong ( 32 ) ; 
 
 @ @ - 1103 , 7 + 1103 , 7 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 return ( int ) metric . memtableSwitchCount . count ( ) ; 
 } 
 
 - private Memtable getMemtableThreadSafe ( ) 
 + Memtable getMemtableThreadSafe ( ) 
 { 
 return data . getMemtable ( ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / Memtable . java b / src / java / org / apache / cassandra / db / Memtable . java 
 index 2b3ca1e . . 4cca602 100644 
 - - - a / src / java / org / apache / cassandra / db / Memtable . java 
 + + + b / src / java / org / apache / cassandra / db / Memtable . java 
 @ @ - 28 , 7 + 28 , 6 @ @ import org . cliffc . high _ scale _ lib . NonBlockingHashSet ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 - import org . apache . cassandra . concurrent . DebuggableThreadPoolExecutor ; 
 import org . apache . cassandra . concurrent . JMXEnabledThreadPoolExecutor ; 
 import org . apache . cassandra . concurrent . NamedThreadFactory ; 
 import org . apache . cassandra . concurrent . StageManager ; 
 @ @ - 78 , 24 + 77 , 15 @ @ public class Memtable 
 / / outstanding / running meterings to a maximum of one per CFS using this set ; the executor ' s queue is unbounded but 
 / / will implicitly be bounded by the number of CFS : s . 
 private static final Set < ColumnFamilyStore > meteringInProgress = new NonBlockingHashSet < ColumnFamilyStore > ( ) ; 
 - private static final ExecutorService meterExecutor = new DebuggableThreadPoolExecutor ( 1 , 
 - 1 , 
 + private static final ExecutorService meterExecutor = new JMXEnabledThreadPoolExecutor ( 1 , 
 Integer . MAX _ VALUE , 
 TimeUnit . MILLISECONDS , 
 new LinkedBlockingQueue < Runnable > ( ) , 
 - new NamedThreadFactory ( " MemoryMeter " ) ) 
 - { 
 - @ Override 
 - protected void afterExecute ( Runnable r , Throwable t ) 
 - { 
 - super . afterExecute ( r , t ) ; 
 - DebuggableThreadPoolExecutor . logExceptionsAfterExecute ( r , t ) ; 
 - } 
 - } ; 
 - 
 + new NamedThreadFactory ( " MemoryMeter " ) , 
 + " internal " ) ; 
 private final MemoryMeter meter ; 
 
 - volatile static Memtable activelyMeasuring ; 
 + volatile static ColumnFamilyStore activelyMeasuring ; 
 
 private final AtomicLong currentSize = new AtomicLong ( 0 ) ; 
 private final AtomicLong currentOperations = new AtomicLong ( 0 ) ; 
 @ @ - 175 , 8 + 165 , 9 @ @ public class Memtable 
 if ( ! MemoryMeter . isInitialized ( ) ) 
 { 
 / / hack for openjdk . we log a warning about this in the startup script too . 
 - logger . warn ( " MemoryMeter uninitialized ( jamm not specified as java agent ) ; assuming liveRatio of 10 . 0 . Usually this means cassandra - env . sh disabled jamm because you are using a buggy JRE ; upgrade to the Sun JRE instead " ) ; 
 - cfs . liveRatio = 10 . 0 ; 
 + logger . warn ( " MemoryMeter uninitialized ( jamm not specified as java agent ) ; assuming liveRatio of { } . " 
 + + " Usually this means cassandra - env . sh disabled jamm because you are using a buggy JRE ; " 
 + + " upgrade to the Sun JRE instead " , cfs . liveRatio ) ; 
 return ; 
 } 
 
 @ @ - 186 , 56 + 177 , 7 @ @ public class Memtable 
 return ; 
 } 
 
 - Runnable runnable = new Runnable ( ) 
 - { 
 - public void run ( ) 
 - { 
 - try 
 - { 
 - activelyMeasuring = Memtable . this ; 
 - 
 - long start = System . nanoTime ( ) ; 
 - / / ConcurrentSkipListMap has cycles , so measureDeep will have to track a reference to EACH object it visits . 
 - / / So to reduce the memory overhead of doing a measurement , we break it up to row - at - a - time . 
 - long deepSize = meter . measure ( rows ) ; 
 - int objects = 0 ; 
 - for ( Map . Entry < RowPosition , AtomicSortedColumns > entry : rows . entrySet ( ) ) 
 - { 
 - deepSize + = meter . measureDeep ( entry . getKey ( ) ) + meter . measureDeep ( entry . getValue ( ) ) ; 
 - objects + = entry . getValue ( ) . getColumnCount ( ) ; 
 - } 
 - double newRatio = ( double ) deepSize / currentSize . get ( ) ; 
 - 
 - if ( newRatio < MIN _ SANE _ LIVE _ RATIO ) 
 - { 
 - logger . warn ( " setting live ratio to minimum of { } instead of { } " , MIN _ SANE _ LIVE _ RATIO , newRatio ) ; 
 - newRatio = MIN _ SANE _ LIVE _ RATIO ; 
 - } 
 - if ( newRatio > MAX _ SANE _ LIVE _ RATIO ) 
 - { 
 - logger . warn ( " setting live ratio to maximum of { } instead of { } " , MAX _ SANE _ LIVE _ RATIO , newRatio ) ; 
 - newRatio = MAX _ SANE _ LIVE _ RATIO ; 
 - } 
 - 
 - / / we want to be very conservative about our estimate , since the penalty for guessing low is OOM 
 - / / death . thus , higher estimates are believed immediately ; lower ones are averaged w / the old 
 - if ( newRatio > cfs . liveRatio ) 
 - cfs . liveRatio = newRatio ; 
 - else 
 - cfs . liveRatio = ( cfs . liveRatio + newRatio ) / 2 . 0 ; 
 - 
 - logger . info ( " { } liveRatio is { } ( just - counted was { } ) . calculation took { } ms for { } columns " , 
 - cfs , cfs . liveRatio , newRatio , TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - start ) , objects ) ; 
 - activelyMeasuring = null ; 
 - } 
 - finally 
 - { 
 - meteringInProgress . remove ( cfs ) ; 
 - } 
 - } 
 - } ; 
 - 
 - meterExecutor . submit ( runnable ) ; 
 + meterExecutor . submit ( new MeteringRunnable ( cfs ) ) ; 
 } 
 
 private void resolve ( DecoratedKey key , ColumnFamily cf , SecondaryIndexManager . Updater indexer ) 
 @ @ - 448 , 4 + 390 , 63 @ @ public class Memtable 
 sstableMetadataCollector ) ; 
 } 
 } 
 + 
 + private static class MeteringRunnable implements Runnable 
 + { 
 + / / we might need to wait in the meter queue for a while . measure whichever memtable is active at that point , 
 + / / rather than keeping the original memtable referenced ( and thus un - freeable ) until this runs . 
 + private final ColumnFamilyStore cfs ; 
 + 
 + public MeteringRunnable ( ColumnFamilyStore cfs ) 
 + { 
 + this . cfs = cfs ; 
 + } 
 + 
 + public void run ( ) 
 + { 
 + try 
 + { 
 + activelyMeasuring = cfs ; 
 + Memtable memtable = cfs . getMemtableThreadSafe ( ) ; 
 + 
 + long start = System . nanoTime ( ) ; 
 + / / ConcurrentSkipListMap has cycles , so measureDeep will have to track a reference to EACH object it visits . 
 + / / So to reduce the memory overhead of doing a measurement , we break it up to row - at - a - time . 
 + long deepSize = memtable . meter . measure ( memtable . rows ) ; 
 + int objects = 0 ; 
 + for ( Map . Entry < RowPosition , AtomicSortedColumns > entry : memtable . rows . entrySet ( ) ) 
 + { 
 + deepSize + = memtable . meter . measureDeep ( entry . getKey ( ) ) + memtable . meter . measureDeep ( entry . getValue ( ) ) ; 
 + objects + = entry . getValue ( ) . getColumnCount ( ) ; 
 + } 
 + double newRatio = ( double ) deepSize / memtable . currentSize . get ( ) ; 
 + 
 + if ( newRatio < MIN _ SANE _ LIVE _ RATIO ) 
 + { 
 + logger . warn ( " setting live ratio to minimum of { } instead of { } " , MIN _ SANE _ LIVE _ RATIO , newRatio ) ; 
 + newRatio = MIN _ SANE _ LIVE _ RATIO ; 
 + } 
 + if ( newRatio > MAX _ SANE _ LIVE _ RATIO ) 
 + { 
 + logger . warn ( " setting live ratio to maximum of { } instead of { } " , MAX _ SANE _ LIVE _ RATIO , newRatio ) ; 
 + newRatio = MAX _ SANE _ LIVE _ RATIO ; 
 + } 
 + 
 + / / we want to be very conservative about our estimate , since the penalty for guessing low is OOM 
 + / / death . thus , higher estimates are believed immediately ; lower ones are averaged w / the old 
 + if ( newRatio > cfs . liveRatio ) 
 + cfs . liveRatio = newRatio ; 
 + else 
 + cfs . liveRatio = ( cfs . liveRatio + newRatio ) / 2 . 0 ; 
 + 
 + logger . info ( " { } liveRatio is { } ( just - counted was { } ) . calculation took { } ms for { } columns " , 
 + cfs , cfs . liveRatio , newRatio , TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - start ) , objects ) ; 
 + } 
 + finally 
 + { 
 + activelyMeasuring = null ; 
 + meteringInProgress . remove ( cfs ) ; 
 + } 
 + } 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / MeteredFlusher . java b / src / java / org / apache / cassandra / db / MeteredFlusher . java 
 index 408727c . . f16b8a0 100644 
 - - - a / src / java / org / apache / cassandra / db / MeteredFlusher . java 
 + + + b / src / java / org / apache / cassandra / db / MeteredFlusher . java 
 @ @ - 35 , 16 + 35 , 22 @ @ public class MeteredFlusher implements Runnable 
 
 public void run ( ) 
 { 
 + long totalMemtableBytesAllowed = DatabaseDescriptor . getTotalMemtableSpaceInMB ( ) * 1048576L ; 
 + 
 / / first , find how much memory non - active memtables are using 
 - Memtable activelyMeasuring = Memtable . activelyMeasuring ; 
 - long flushingBytes = activelyMeasuring = = null ? 0 : activelyMeasuring . getLiveSize ( ) ; 
 + long flushingBytes = Memtable . activelyMeasuring = = null 
 + ? 0 
 + : Memtable . activelyMeasuring . getMemtableThreadSafe ( ) . getLiveSize ( ) ; 
 flushingBytes + = countFlushingBytes ( ) ; 
 + if ( flushingBytes > 0 ) 
 + logger . debug ( " Currently flushing { } bytes of { } max " , flushingBytes , totalMemtableBytesAllowed ) ; 
 
 / / next , flush CFs using more than 1 / ( maximum number of memtables it could have in the pipeline ) 
 / / of the total size allotted . Then , flush other CFs in order of size if necessary . 
 long liveBytes = 0 ; 
 try 
 { 
 + long totalMemtableBytesUnused = totalMemtableBytesAllowed - flushingBytes ; 
 for ( ColumnFamilyStore cfs : ColumnFamilyStore . all ( ) ) 
 { 
 long size = cfs . getTotalMemtableLiveSize ( ) ; 
 @ @ - 53 , 7 + 59 , 7 @ @ public class MeteredFlusher implements Runnable 
 + DatabaseDescriptor . getFlushWriters ( ) 
 + DatabaseDescriptor . getFlushQueueSize ( ) ) 
 / ( 1 + cfs . indexManager . getIndexesBackedByCfs ( ) . size ( ) ) ) ; 
 - if ( size > ( DatabaseDescriptor . getTotalMemtableSpaceInMB ( ) * 1048576L - flushingBytes ) / maxInFlight ) 
 + if ( totalMemtableBytesUnused > 0 & & size > totalMemtableBytesUnused / maxInFlight ) 
 { 
 logger . info ( " flushing high - traffic column family { } ( estimated { } bytes ) " , cfs , size ) ; 
 cfs . forceFlush ( ) ; 
 @ @ - 64 , 10 + 70 , 10 @ @ public class MeteredFlusher implements Runnable 
 } 
 } 
 
 - if ( flushingBytes + liveBytes < = DatabaseDescriptor . getTotalMemtableSpaceInMB ( ) * 1048576L ) 
 + if ( flushingBytes + liveBytes < = totalMemtableBytesAllowed ) 
 return ; 
 
 - logger . info ( " estimated { } bytes used by all memtables pre - flush " , liveBytes ) ; 
 + logger . info ( " estimated { } live and { } flushing bytes used by all memtables " , liveBytes , flushingBytes ) ; 
 
 / / sort memtables by size 
 List < ColumnFamilyStore > sorted = new ArrayList < ColumnFamilyStore > ( ) ; 
 @ @ - 89 , 14 + 95 , 16 @ @ public class MeteredFlusher implements Runnable 
 / / flush largest first until we get below our threshold . 
 / / although it looks like liveBytes + flushingBytes will stay a constant , it will not if flushes finish 
 / / while we loop , which is especially likely to happen if the flush queue fills up ( so further forceFlush calls block ) 
 - while ( true ) 
 + while ( ! sorted . isEmpty ( ) ) 
 { 
 flushingBytes = countFlushingBytes ( ) ; 
 - if ( liveBytes + flushingBytes < = DatabaseDescriptor . getTotalMemtableSpaceInMB ( ) * 1048576L | | sorted . isEmpty ( ) ) 
 + if ( liveBytes + flushingBytes < = totalMemtableBytesAllowed ) 
 break ; 
 
 ColumnFamilyStore cfs = sorted . remove ( sorted . size ( ) - 1 ) ; 
 long size = cfs . getTotalMemtableLiveSize ( ) ; 
 + if ( size = = 0 ) 
 + break ; 
 logger . info ( " flushing { } to free up { } bytes " , cfs , size ) ; 
 liveBytes - = size ; 
 cfs . forceFlush ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / commitlog / PeriodicCommitLogExecutorService . java b / src / java / org / apache / cassandra / db / commitlog / PeriodicCommitLogExecutorService . java 
 index 7a0a761 . . 30f33b6 100644 
 - - - a / src / java / org / apache / cassandra / db / commitlog / PeriodicCommitLogExecutorService . java 
 + + + b / src / java / org / apache / cassandra / db / commitlog / PeriodicCommitLogExecutorService . java 
 @ @ - 35 , 7 + 35 , 7 @ @ class PeriodicCommitLogExecutorService implements ICommitLogExecutorService 
 
 public PeriodicCommitLogExecutorService ( final CommitLog commitLog ) 
 { 
 - queue = new LinkedBlockingQueue < Runnable > ( 1024 * FBUtilities . getAvailableProcessors ( ) ) ; 
 + queue = new LinkedBlockingQueue < Runnable > ( DatabaseDescriptor . getCommitLogPeriodicQueueSize ( ) ) ; 
 Runnable runnable = new WrappedRunnable ( ) 
 { 
 public void runMayThrow ( ) throws Exception 
 diff - - git a / src / java / org / apache / cassandra / utils / StatusLogger . java b / src / java / org / apache / cassandra / utils / StatusLogger . java 
 index 2b9627f . . 939c81f 100644 
 - - - a / src / java / org / apache / cassandra / utils / StatusLogger . java 
 + + + b / src / java / org / apache / cassandra / utils / StatusLogger . java 
 @ @ - 19 , 6 + 19 , 8 @ @ package org . apache . cassandra . utils ; 
 
 import java . lang . management . ManagementFactory ; 
 import java . util . Set ; 
 + import java . util . concurrent . ExecutorService ; 
 + import java . util . concurrent . ThreadPoolExecutor ; 
 import javax . management . JMX ; 
 import javax . management . MBeanServer ; 
 import javax . management . MalformedObjectNameException ; 
 @ @ - 34 , 7 + 36 , 9 @ @ import org . slf4j . LoggerFactory ; 
 import org . apache . cassandra . concurrent . JMXEnabledThreadPoolExecutorMBean ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . db . ColumnFamilyStore ; 
 + import org . apache . cassandra . db . Memtable ; 
 import org . apache . cassandra . db . RowIndexEntry ; 
 + import org . apache . cassandra . db . commitlog . CommitLog ; 
 import org . apache . cassandra . db . compaction . CompactionManager ; 
 import org . apache . cassandra . net . MessagingService ; 
 import org . apache . cassandra . service . CacheService ; 
 @ @ - 72 , 9 + 76 , 10 @ @ public class StatusLogger 
 threadPoolProxy . getTotalBlockedTasks ( ) ) ) ; 
 } 
 / / one offs 
 - CompactionManager cm = CompactionManager . instance ; 
 logger . info ( String . format ( " % - 25s % 10s % 10s " , 
 - " CompactionManager " , cm . getActiveCompactions ( ) , cm . getPendingTasks ( ) ) ) ; 
 + " CompactionManager " , CompactionManager . instance . getActiveCompactions ( ) , CompactionManager . instance . getPendingTasks ( ) ) ) ; 
 + logger . info ( String . format ( " % - 25s % 10s % 10s " , 
 + " Commitlog " , " n / a " , CommitLog . instance . getPendingTasks ( ) ) ) ; 
 int pendingCommands = 0 ; 
 for ( int n : MessagingService . instance ( ) . getCommandPendingTasks ( ) . values ( ) ) 
 {
