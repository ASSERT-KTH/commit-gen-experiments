BLEU SCORE: 0.011246923682765546

TEST MSG: Efficent BTree removal
GENERATED MSG: refactor Filter heirarchy , making hash generation easily customizable . Use Murmur

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 0294efc . . 4149d91 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 3 . 2 <nl> + * More efficient BTree removal ( CASSANDRA - 9991 ) <nl> * Make tablehistograms accept the same syntax as tablestats ( CASSANDRA - 10149 ) <nl> * Group pending compactions based on table ( CASSANDRA - 10718 ) <nl> * Add compressor name in sstablemetadata output ( CASSANDRA - 9879 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / Columns . java b / src / java / org / apache / cassandra / db / Columns . java <nl> index cad295c . . e3c30fa 100644 <nl> - - - a / src / java / org / apache / cassandra / db / Columns . java <nl> + + + b / src / java / org / apache / cassandra / db / Columns . java <nl> @ @ - 38 , 6 + 38 , 7 @ @ import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . apache . cassandra . utils . SearchIterator ; <nl> import org . apache . cassandra . utils . btree . BTree ; <nl> import org . apache . cassandra . utils . btree . BTreeSearchIterator ; <nl> + import org . apache . cassandra . utils . btree . BTreeRemoval ; <nl> import org . apache . cassandra . utils . btree . UpdateFunction ; <nl> <nl> / * * <nl> @ @ - 343 , 7 + 344 , 7 @ @ public class Columns extends AbstractCollection < ColumnDefinition > implements Col <nl> if ( ! contains ( column ) ) <nl> return this ; <nl> <nl> - Object [ ] newColumns = BTree . < ColumnDefinition > transformAndFilter ( columns , ( c ) - > c . equals ( column ) ? null : c ) ; <nl> + Object [ ] newColumns = BTreeRemoval . < ColumnDefinition > remove ( columns , Comparator . naturalOrder ( ) , column ) ; <nl> return new Columns ( newColumns ) ; <nl> } <nl> <nl> diff - - git a / src / java / org / apache / cassandra / utils / btree / BTree . java b / src / java / org / apache / cassandra / utils / btree / BTree . java <nl> index fe08011 . . 1c3d2e2 100644 <nl> - - - a / src / java / org / apache / cassandra / utils / btree / BTree . java <nl> + + + b / src / java / org / apache / cassandra / utils / btree / BTree . java <nl> @ @ - 67 , 6 + 67 , 8 @ @ public class BTree <nl> / / NB we encode Path indexes as Bytes , so this needs to be less than Byte . MAX _ VALUE / 2 <nl> static final int FAN _ FACTOR = 1 < < FAN _ SHIFT ; <nl> <nl> + static final int MINIMAL _ NODE _ SIZE = FAN _ FACTOR > > 1 ; <nl> + <nl> / / An empty BTree Leaf - which is the same as an empty BTree <nl> static final Object [ ] EMPTY _ LEAF = new Object [ 1 ] ; <nl> <nl> @ @ - 296 , 6 + 298 , 40 @ @ public class BTree <nl> <nl> / * * <nl> * Modifies the provided btree directly . THIS SHOULD NOT BE USED WITHOUT EXTREME CARE as BTrees are meant to be immutable . <nl> + * Finds and replaces the item provided by index in the tree . <nl> + * / <nl> + public static < V > void replaceInSitu ( Object [ ] tree , int index , V replace ) <nl> + { <nl> + / / WARNING : if semantics change , see also InternalCursor . seekTo , which mirrors this implementation <nl> + if ( ( index < 0 ) | ( index > = size ( tree ) ) ) <nl> + throw new IndexOutOfBoundsException ( index + " not in range [ 0 . . " + size ( tree ) + " ) " ) ; <nl> + <nl> + while ( ! isLeaf ( tree ) ) <nl> + { <nl> + final int [ ] sizeMap = getSizeMap ( tree ) ; <nl> + int boundary = Arrays . binarySearch ( sizeMap , index ) ; <nl> + if ( boundary > = 0 ) <nl> + { <nl> + / / exact match , in this branch node <nl> + assert boundary < sizeMap . length - 1 ; <nl> + tree [ boundary ] = replace ; <nl> + return ; <nl> + } <nl> + <nl> + boundary = - 1 - boundary ; <nl> + if ( boundary > 0 ) <nl> + { <nl> + assert boundary < sizeMap . length ; <nl> + index - = ( 1 + sizeMap [ boundary - 1 ] ) ; <nl> + } <nl> + tree = ( Object [ ] ) tree [ getChildStart ( tree ) + boundary ] ; <nl> + } <nl> + assert index < getLeafKeyEnd ( tree ) ; <nl> + tree [ index ] = replace ; <nl> + } <nl> + <nl> + / * * <nl> + * Modifies the provided btree directly . THIS SHOULD NOT BE USED WITHOUT EXTREME CARE as BTrees are meant to be immutable . <nl> * Finds and replaces the provided item in the tree . Both should sort as equal to each other ( although this is not enforced ) <nl> * / <nl> public static < V > void replaceInSitu ( Object [ ] node , Comparator < ? super V > comparator , V find , V replace ) <nl> @ @ - 1073 , 11 + 1109 , 20 @ @ public class BTree <nl> return node . length > = FAN _ FACTOR / 2 & & node . length < = FAN _ FACTOR + 1 ; <nl> } <nl> <nl> + final int keyCount = getBranchKeyEnd ( node ) ; <nl> + if ( ( ! isRoot & & keyCount < FAN _ FACTOR / 2 ) | | keyCount > FAN _ FACTOR + 1 ) <nl> + return false ; <nl> + <nl> int type = 0 ; <nl> + int size = - 1 ; <nl> + int [ ] sizeMap = getSizeMap ( node ) ; <nl> / / compare each child node with the branch element at the head of this node it corresponds with <nl> for ( int i = getChildStart ( node ) ; i < getChildEnd ( node ) ; i + + ) <nl> { <nl> Object [ ] child = ( Object [ ] ) node [ i ] ; <nl> + size + = size ( child ) + 1 ; <nl> + if ( sizeMap [ i - getChildStart ( node ) ] ! = size ) <nl> + return false ; <nl> Object localmax = i < node . length - 2 ? node [ i - getChildStart ( node ) ] : max ; <nl> if ( ! isWellFormed ( cmp , child , false , min , localmax ) ) <nl> return false ; <nl> diff - - git a / src / java / org / apache / cassandra / utils / btree / BTreeRemoval . java b / src / java / org / apache / cassandra / utils / btree / BTreeRemoval . java <nl> new file mode 100644 <nl> index 0000000 . . 74fa402 <nl> - - - / dev / null <nl> + + + b / src / java / org / apache / cassandra / utils / btree / BTreeRemoval . java <nl> @ @ - 0 , 0 + 1 , 338 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , <nl> + * software distributed under the License is distributed on an <nl> + * " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY <nl> + * KIND , either express or implied . See the License for the <nl> + * specific language governing permissions and limitations <nl> + * under the License . <nl> + * / <nl> + package org . apache . cassandra . utils . btree ; <nl> + <nl> + import java . util . Arrays ; <nl> + import java . util . Comparator ; <nl> + <nl> + public class BTreeRemoval <nl> + { <nl> + / * * <nl> + * Remove | elem | from | btree | . If it ' s not present then return | btree | itself . <nl> + * / <nl> + public static < V > Object [ ] remove ( final Object [ ] btree , final Comparator < ? super V > comparator , final V elem ) <nl> + { <nl> + if ( BTree . isEmpty ( btree ) ) <nl> + return btree ; <nl> + int index = - 1 ; <nl> + V elemToSwap = null ; <nl> + int lb = 0 ; <nl> + Object [ ] node = btree ; <nl> + while ( true ) <nl> + { <nl> + int keyEnd = BTree . getKeyEnd ( node ) ; <nl> + int i = Arrays . binarySearch ( ( V [ ] ) node , 0 , keyEnd , elem , comparator ) ; <nl> + <nl> + if ( i > = 0 ) <nl> + { <nl> + if ( BTree . isLeaf ( node ) ) <nl> + index = lb + i ; <nl> + else <nl> + { <nl> + final int indexInNode = BTree . getSizeMap ( node ) [ i ] ; <nl> + index = lb + indexInNode - 1 ; <nl> + elemToSwap = BTree . findByIndex ( node , indexInNode - 1 ) ; <nl> + } <nl> + break ; <nl> + } <nl> + if ( BTree . isLeaf ( node ) ) <nl> + return btree ; <nl> + <nl> + i = - 1 - i ; <nl> + if ( i > 0 ) <nl> + lb + = BTree . getSizeMap ( node ) [ i - 1 ] + 1 ; <nl> + <nl> + node = ( Object [ ] ) node [ keyEnd + i ] ; <nl> + } <nl> + if ( BTree . size ( btree ) = = 1 ) <nl> + return BTree . empty ( ) ; <nl> + Object [ ] result = removeFromLeaf ( btree , index ) ; <nl> + if ( elemToSwap ! = null ) <nl> + BTree . replaceInSitu ( result , index , elemToSwap ) ; <nl> + return result ; <nl> + } <nl> + <nl> + / * * <nl> + * Remove | elem | from | btree | . It has to be present and it has to reside in a leaf node . <nl> + * / <nl> + private static < V > Object [ ] removeFromLeaf ( Object [ ] node , int index ) <nl> + { <nl> + Object [ ] result = null ; <nl> + Object [ ] prevNode = null ; <nl> + int prevI = - 1 ; <nl> + boolean needsCopy = true ; <nl> + while ( ! BTree . isLeaf ( node ) ) <nl> + { <nl> + final int keyEnd = BTree . getBranchKeyEnd ( node ) ; <nl> + int i = - 1 - Arrays . binarySearch ( BTree . getSizeMap ( node ) , index ) ; <nl> + if ( i > 0 ) <nl> + index - = ( 1 + BTree . getSizeMap ( node ) [ i - 1 ] ) ; <nl> + Object [ ] nextNode = ( Object [ ] ) node [ keyEnd + i ] ; <nl> + boolean nextNodeNeedsCopy = true ; <nl> + if ( BTree . getKeyEnd ( nextNode ) > BTree . MINIMAL _ NODE _ SIZE ) <nl> + node = copyIfNeeded ( node , needsCopy ) ; <nl> + else if ( i > 0 & & BTree . getKeyEnd ( ( Object [ ] ) node [ keyEnd + i - 1 ] ) > BTree . MINIMAL _ NODE _ SIZE ) <nl> + { <nl> + node = copyIfNeeded ( node , needsCopy ) ; <nl> + final Object [ ] leftNeighbour = ( Object [ ] ) node [ keyEnd + i - 1 ] ; <nl> + index + + ; <nl> + if ( ! BTree . isLeaf ( leftNeighbour ) ) <nl> + index + = BTree . size ( ( Object [ ] ) leftNeighbour [ BTree . getChildEnd ( leftNeighbour ) - 1 ] ) ; <nl> + nextNode = rotateLeft ( node , i ) ; <nl> + } <nl> + else if ( i < keyEnd & & BTree . getKeyEnd ( ( Object [ ] ) node [ keyEnd + i + 1 ] ) > BTree . MINIMAL _ NODE _ SIZE ) <nl> + { <nl> + node = copyIfNeeded ( node , needsCopy ) ; <nl> + nextNode = rotateRight ( node , i ) ; <nl> + } <nl> + else <nl> + { <nl> + nextNodeNeedsCopy = false ; <nl> + if ( i > 0 ) <nl> + { <nl> + final Object [ ] leftNeighbour = ( Object [ ] ) node [ keyEnd + i - 1 ] ; <nl> + final V nodeKey = ( V ) node [ i - 1 ] ; <nl> + node = keyEnd = = 1 ? null : copyWithKeyAndChildRemoved ( node , i - 1 , i - 1 , false ) ; <nl> + nextNode = merge ( leftNeighbour , nextNode , nodeKey ) ; <nl> + i = i - 1 ; <nl> + index + = BTree . size ( leftNeighbour ) + 1 ; <nl> + } <nl> + else <nl> + { <nl> + final Object [ ] rightNeighbour = ( Object [ ] ) node [ keyEnd + i + 1 ] ; <nl> + final V nodeKey = ( V ) node [ i ] ; <nl> + node = keyEnd = = 1 ? null : copyWithKeyAndChildRemoved ( node , i , i , false ) ; <nl> + nextNode = merge ( nextNode , rightNeighbour , nodeKey ) ; <nl> + } <nl> + } <nl> + <nl> + if ( node ! = null ) <nl> + { <nl> + final int [ ] sizeMap = BTree . getSizeMap ( node ) ; <nl> + for ( int j = i ; j < sizeMap . length ; + + j ) <nl> + sizeMap [ j ] - = 1 ; <nl> + if ( prevNode ! = null ) <nl> + prevNode [ prevI ] = node ; <nl> + else <nl> + result = node ; <nl> + prevNode = node ; <nl> + prevI = BTree . getChildStart ( node ) + i ; <nl> + } <nl> + <nl> + node = nextNode ; <nl> + needsCopy = nextNodeNeedsCopy ; <nl> + } <nl> + final int keyEnd = BTree . getLeafKeyEnd ( node ) ; <nl> + final Object [ ] newLeaf = new Object [ ( keyEnd & 1 ) = = 1 ? keyEnd : keyEnd - 1 ] ; <nl> + copyKeys ( node , newLeaf , 0 , index ) ; <nl> + if ( prevNode ! = null ) <nl> + prevNode [ prevI ] = newLeaf ; <nl> + else <nl> + result = newLeaf ; <nl> + return result ; <nl> + } <nl> + <nl> + private static < V > Object [ ] rotateRight ( final Object [ ] node , final int i ) { <nl> + final int keyEnd = BTree . getBranchKeyEnd ( node ) ; <nl> + final Object [ ] nextNode = ( Object [ ] ) node [ keyEnd + i ] ; <nl> + final Object [ ] rightNeighbour = ( Object [ ] ) node [ keyEnd + i + 1 ] ; <nl> + final boolean leaves = BTree . isLeaf ( nextNode ) ; <nl> + final int nextKeyEnd = BTree . getKeyEnd ( nextNode ) ; <nl> + final Object [ ] newChild = leaves ? null : ( Object [ ] ) rightNeighbour [ BTree . getChildStart ( rightNeighbour ) ] ; <nl> + final Object [ ] newNextNode = <nl> + copyWithKeyAndChildInserted ( nextNode , nextKeyEnd , node [ i ] , BTree . getChildCount ( nextNode ) , newChild ) ; <nl> + node [ i ] = rightNeighbour [ 0 ] ; <nl> + node [ keyEnd + i + 1 ] = copyWithKeyAndChildRemoved ( rightNeighbour , 0 , 0 , true ) ; <nl> + BTree . getSizeMap ( node ) [ i ] + = <nl> + leaves ? 1 : 1 + BTree . size ( ( Object [ ] ) newNextNode [ BTree . getChildEnd ( newNextNode ) - 1 ] ) ; <nl> + return newNextNode ; <nl> + } <nl> + <nl> + private static Object [ ] rotateLeft ( final Object [ ] node , final int i ) { <nl> + final int keyEnd = BTree . getBranchKeyEnd ( node ) ; <nl> + final Object [ ] nextNode = ( Object [ ] ) node [ keyEnd + i ] ; <nl> + final Object [ ] leftNeighbour = ( Object [ ] ) node [ keyEnd + i - 1 ] ; <nl> + final int leftNeighbourEndKey = BTree . getKeyEnd ( leftNeighbour ) ; <nl> + final boolean leaves = BTree . isLeaf ( nextNode ) ; <nl> + final Object [ ] newChild = leaves ? null : ( Object [ ] ) leftNeighbour [ BTree . getChildEnd ( leftNeighbour ) - 1 ] ; <nl> + final Object [ ] newNextNode = copyWithKeyAndChildInserted ( nextNode , 0 , node [ i - 1 ] , 0 , newChild ) ; <nl> + node [ i - 1 ] = leftNeighbour [ leftNeighbourEndKey - 1 ] ; <nl> + node [ keyEnd + i - 1 ] = copyWithKeyAndChildRemoved ( leftNeighbour , leftNeighbourEndKey - 1 , leftNeighbourEndKey , true ) ; <nl> + BTree . getSizeMap ( node ) [ i - 1 ] - = leaves ? 1 : 1 + BTree . getSizeMap ( newNextNode ) [ 0 ] ; <nl> + return newNextNode ; <nl> + } <nl> + <nl> + private static < V > Object [ ] copyWithKeyAndChildInserted ( final Object [ ] node , final int keyIndex , final V key , final int childIndex , final Object [ ] child ) <nl> + { <nl> + final boolean leaf = BTree . isLeaf ( node ) ; <nl> + final int keyEnd = BTree . getKeyEnd ( node ) ; <nl> + final Object [ ] copy ; <nl> + if ( leaf ) <nl> + copy = new Object [ keyEnd + ( ( keyEnd & 1 ) = = 1 ? 2 : 1 ) ] ; <nl> + else <nl> + copy = new Object [ node . length + 2 ] ; <nl> + <nl> + if ( keyIndex > 0 ) <nl> + System . arraycopy ( node , 0 , copy , 0 , keyIndex ) ; <nl> + copy [ keyIndex ] = key ; <nl> + if ( keyIndex < keyEnd ) <nl> + System . arraycopy ( node , keyIndex , copy , keyIndex + 1 , keyEnd - keyIndex ) ; <nl> + <nl> + if ( ! leaf ) <nl> + { <nl> + if ( childIndex > 0 ) <nl> + System . arraycopy ( node , <nl> + BTree . getChildStart ( node ) , <nl> + copy , <nl> + keyEnd + 1 , <nl> + childIndex ) ; <nl> + copy [ keyEnd + 1 + childIndex ] = child ; <nl> + if ( childIndex < = keyEnd ) <nl> + System . arraycopy ( node , <nl> + BTree . getChildStart ( node ) + childIndex , <nl> + copy , <nl> + keyEnd + childIndex + 2 , <nl> + keyEnd - childIndex + 1 ) ; <nl> + final int [ ] sizeMap = BTree . getSizeMap ( node ) ; <nl> + final int [ ] newSizeMap = new int [ sizeMap . length + 1 ] ; <nl> + if ( childIndex > 0 ) <nl> + System . arraycopy ( sizeMap , 0 , newSizeMap , 0 , childIndex ) ; <nl> + final int childSize = BTree . size ( child ) ; <nl> + newSizeMap [ childIndex ] = childSize + ( ( childIndex = = 0 ) ? 0 : newSizeMap [ childIndex - 1 ] + 1 ) ; <nl> + for ( int i = childIndex + 1 ; i < newSizeMap . length ; + + i ) <nl> + newSizeMap [ i ] = sizeMap [ i - 1 ] + childSize + 1 ; <nl> + copy [ copy . length - 1 ] = newSizeMap ; <nl> + } <nl> + return copy ; <nl> + } <nl> + <nl> + private static < V > Object [ ] copyWithKeyAndChildRemoved ( final Object [ ] node , final int keyIndex , final int childIndex , final boolean substractSize ) <nl> + { <nl> + final boolean leaf = BTree . isLeaf ( node ) ; <nl> + final int keyEnd = BTree . getKeyEnd ( node ) ; <nl> + final Object [ ] newNode ; <nl> + if ( leaf ) <nl> + newNode = new Object [ keyEnd - ( ( keyEnd & 1 ) = = 1 ? 0 : 1 ) ] ; <nl> + else <nl> + newNode = new Object [ node . length - 2 ] ; <nl> + int offset = copyKeys ( node , newNode , 0 , keyIndex ) ; <nl> + if ( ! leaf ) <nl> + { <nl> + offset = copyChildren ( node , newNode , offset , childIndex ) ; <nl> + final int [ ] nodeSizeMap = BTree . getSizeMap ( node ) ; <nl> + final int [ ] newNodeSizeMap = new int [ nodeSizeMap . length - 1 ] ; <nl> + int pos = 0 ; <nl> + final int sizeToRemove = BTree . size ( ( Object [ ] ) node [ BTree . getChildStart ( node ) + childIndex ] ) + 1 ; <nl> + for ( int i = 0 ; i < nodeSizeMap . length ; + + i ) <nl> + if ( i ! = childIndex ) <nl> + newNodeSizeMap [ pos + + ] = nodeSizeMap [ i ] - <nl> + ( ( substractSize & & i > childIndex ) ? sizeToRemove : 0 ) ; <nl> + newNode [ offset ] = newNodeSizeMap ; <nl> + } <nl> + return newNode ; <nl> + } <nl> + <nl> + private static < V > Object [ ] merge ( final Object [ ] left , final Object [ ] right , final V nodeKey ) { <nl> + assert BTree . getKeyEnd ( left ) = = BTree . MINIMAL _ NODE _ SIZE ; <nl> + assert BTree . getKeyEnd ( right ) = = BTree . MINIMAL _ NODE _ SIZE ; <nl> + final boolean leaves = BTree . isLeaf ( left ) ; <nl> + final Object [ ] result ; <nl> + if ( leaves ) <nl> + result = new Object [ BTree . MINIMAL _ NODE _ SIZE * 2 + 1 ] ; <nl> + else <nl> + result = new Object [ left . length + right . length ] ; <nl> + int offset = 0 ; <nl> + offset = copyKeys ( left , result , offset ) ; <nl> + result [ offset + + ] = nodeKey ; <nl> + offset = copyKeys ( right , result , offset ) ; <nl> + if ( ! leaves ) <nl> + { <nl> + offset = copyChildren ( left , result , offset ) ; <nl> + offset = copyChildren ( right , result , offset ) ; <nl> + final int [ ] leftSizeMap = BTree . getSizeMap ( left ) ; <nl> + final int [ ] rightSizeMap = BTree . getSizeMap ( right ) ; <nl> + final int [ ] newSizeMap = new int [ leftSizeMap . length + rightSizeMap . length ] ; <nl> + offset = 0 ; <nl> + offset = copySizeMap ( leftSizeMap , newSizeMap , offset , 0 ) ; <nl> + offset = copySizeMap ( rightSizeMap , newSizeMap , offset , leftSizeMap [ leftSizeMap . length - 1 ] + 1 ) ; <nl> + result [ result . length - 1 ] = newSizeMap ; <nl> + } <nl> + return result ; <nl> + } <nl> + <nl> + private static int copyKeys ( final Object [ ] from , final Object [ ] to , final int offset ) <nl> + { <nl> + final int keysCount = BTree . getKeyEnd ( from ) ; <nl> + System . arraycopy ( from , 0 , to , offset , keysCount ) ; <nl> + return offset + keysCount ; <nl> + } <nl> + <nl> + private static int copyKeys ( final Object [ ] from , final Object [ ] to , final int offset , final int skipIndex ) <nl> + { <nl> + final int keysCount = BTree . getKeyEnd ( from ) ; <nl> + if ( skipIndex > 0 ) <nl> + System . arraycopy ( from , 0 , to , offset , skipIndex ) ; <nl> + if ( skipIndex + 1 < keysCount ) <nl> + System . arraycopy ( from , skipIndex + 1 , to , offset + skipIndex , keysCount - skipIndex - 1 ) ; <nl> + return offset + keysCount - 1 ; <nl> + } <nl> + <nl> + private static int copyChildren ( final Object [ ] from , final Object [ ] to , final int offset ) <nl> + { <nl> + assert ! BTree . isLeaf ( from ) ; <nl> + final int start = BTree . getChildStart ( from ) ; <nl> + final int childCount = BTree . getChildCount ( from ) ; <nl> + System . arraycopy ( from , start , to , offset , childCount ) ; <nl> + return offset + childCount ; <nl> + } <nl> + <nl> + private static int copyChildren ( final Object [ ] from , final Object [ ] to , final int offset , final int skipIndex ) <nl> + { <nl> + assert ! BTree . isLeaf ( from ) ; <nl> + final int start = BTree . getChildStart ( from ) ; <nl> + final int childCount = BTree . getChildCount ( from ) ; <nl> + if ( skipIndex > 0 ) <nl> + System . arraycopy ( from , start , to , offset , skipIndex ) ; <nl> + if ( skipIndex + 1 < = childCount ) <nl> + System . arraycopy ( from , start + skipIndex + 1 , to , offset + skipIndex , childCount - skipIndex - 1 ) ; <nl> + return offset + childCount - 1 ; <nl> + } <nl> + <nl> + private static int copySizeMap ( final int [ ] from , final int [ ] to , final int offset , final int extra ) <nl> + { <nl> + for ( int i = 0 ; i < from . length ; + + i ) <nl> + to [ offset + i ] = from [ i ] + extra ; <nl> + return offset + from . length ; <nl> + } <nl> + <nl> + private static Object [ ] copyIfNeeded ( final Object [ ] node , boolean needCopy ) <nl> + { <nl> + if ( ! needCopy ) return node ; <nl> + final Object [ ] copy = new Object [ node . length ] ; <nl> + System . arraycopy ( node , 0 , copy , 0 , node . length ) ; <nl> + if ( ! BTree . isLeaf ( node ) ) <nl> + { <nl> + final int [ ] sizeMap = BTree . getSizeMap ( node ) ; <nl> + final int [ ] copySizeMap = new int [ sizeMap . length ] ; <nl> + System . arraycopy ( sizeMap , 0 , copySizeMap , 0 , sizeMap . length ) ; <nl> + copy [ copy . length - 1 ] = copySizeMap ; <nl> + } <nl> + return copy ; <nl> + } <nl> + } <nl> diff - - git a / test / unit / org / apache / cassandra / utils / btree / BTreeRemovalTest . java b / test / unit / org / apache / cassandra / utils / btree / BTreeRemovalTest . java <nl> new file mode 100644 <nl> index 0000000 . . a9cf383 <nl> - - - / dev / null <nl> + + + b / test / unit / org / apache / cassandra / utils / btree / BTreeRemovalTest . java <nl> @ @ - 0 , 0 + 1 , 385 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , software <nl> + * distributed under the License is distributed on an " AS IS " BASIS , <nl> + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . <nl> + * See the License for the specific language governing permissions and <nl> + * limitations under the License . <nl> + * / <nl> + package org . apache . cassandra . utils . btree ; <nl> + <nl> + import static org . apache . cassandra . utils . btree . BTreeRemoval . remove ; <nl> + import static org . junit . Assert . assertArrayEquals ; <nl> + import static org . junit . Assert . assertEquals ; <nl> + import static org . junit . Assert . assertNotNull ; <nl> + import static org . junit . Assert . assertNull ; <nl> + import static org . junit . Assert . assertTrue ; <nl> + <nl> + import java . util . Comparator ; <nl> + import java . util . Random ; <nl> + import java . util . SortedSet ; <nl> + import java . util . TreeSet ; <nl> + <nl> + import org . junit . Test ; <nl> + <nl> + import com . google . common . collect . Iterables ; <nl> + <nl> + public class BTreeRemovalTest <nl> + { <nl> + static <nl> + { <nl> + System . setProperty ( " cassandra . btree . fanfactor " , " 8 " ) ; <nl> + } <nl> + <nl> + private static final Comparator < Integer > CMP = new Comparator < Integer > ( ) <nl> + { <nl> + public int compare ( Integer o1 , Integer o2 ) <nl> + { <nl> + return Integer . compare ( o1 , o2 ) ; <nl> + } <nl> + } ; <nl> + <nl> + private static Object [ ] copy ( final Object [ ] btree ) <nl> + { <nl> + final Object [ ] result = new Object [ btree . length ] ; <nl> + System . arraycopy ( btree , 0 , result , 0 , btree . length ) ; <nl> + if ( ! BTree . isLeaf ( btree ) ) <nl> + { <nl> + for ( int i = BTree . getChildStart ( btree ) ; i < BTree . getChildEnd ( btree ) ; + + i ) <nl> + result [ i ] = copy ( ( Object [ ] ) btree [ i ] ) ; <nl> + final int [ ] sizeMap = BTree . getSizeMap ( btree ) ; <nl> + final int [ ] resultSizeMap = new int [ sizeMap . length ] ; <nl> + System . arraycopy ( sizeMap , 0 , resultSizeMap , 0 , sizeMap . length ) ; <nl> + result [ result . length - 1 ] = resultSizeMap ; <nl> + } <nl> + return result ; <nl> + } <nl> + <nl> + private static Object [ ] assertRemove ( final Object [ ] btree , final int key ) <nl> + { <nl> + final Object [ ] btreeBeforeRemoval = copy ( btree ) ; <nl> + final Object [ ] result = remove ( btree , CMP , key ) ; <nl> + assertBTree ( btreeBeforeRemoval , btree ) ; <nl> + assertTrue ( BTree . isWellFormed ( result , CMP ) ) ; <nl> + assertEquals ( BTree . size ( btree ) - 1 , BTree . size ( result ) ) ; <nl> + assertNull ( BTree . find ( result , CMP , key ) ) ; <nl> + <nl> + for ( Integer k : BTree . < Integer > iterable ( btree ) ) <nl> + if ( k ! = key ) <nl> + assertNotNull ( BTree . find ( result , CMP , k ) ) ; <nl> + <nl> + return result ; <nl> + } <nl> + <nl> + private static void assertBTree ( final Object [ ] expected , final Object [ ] result ) <nl> + { <nl> + assertEquals ( BTree . isEmpty ( expected ) , BTree . isEmpty ( result ) ) ; <nl> + assertEquals ( BTree . isLeaf ( expected ) , BTree . isLeaf ( result ) ) ; <nl> + assertEquals ( expected . length , result . length ) ; <nl> + if ( BTree . isLeaf ( expected ) ) <nl> + { <nl> + assertArrayEquals ( expected , result ) ; <nl> + } <nl> + else <nl> + { <nl> + for ( int i = 0 ; i < BTree . getBranchKeyEnd ( expected ) ; + + i ) <nl> + assertEquals ( expected [ i ] , result [ i ] ) ; <nl> + for ( int i = BTree . getChildStart ( expected ) ; i < BTree . getChildEnd ( expected ) ; + + i ) <nl> + assertBTree ( ( Object [ ] ) expected [ i ] , ( Object [ ] ) result [ i ] ) ; <nl> + assertArrayEquals ( BTree . getSizeMap ( expected ) , BTree . getSizeMap ( result ) ) ; <nl> + } <nl> + } <nl> + <nl> + private static Object [ ] generateLeaf ( int from , int size ) <nl> + { <nl> + final Object [ ] result = new Object [ ( size & 1 ) = = 1 ? size : size + 1 ] ; <nl> + for ( int i = 0 ; i < size ; + + i ) <nl> + result [ i ] = from + i ; <nl> + return result ; <nl> + } <nl> + <nl> + private static Object [ ] generateBranch ( int [ ] keys , Object [ ] [ ] children ) <nl> + { <nl> + assert keys . length > 0 ; <nl> + assert children . length > 1 ; <nl> + assert children . length = = keys . length + 1 ; <nl> + final Object [ ] result = new Object [ keys . length + children . length + 1 ] ; <nl> + for ( int i = 0 ; i < keys . length ; + + i ) <nl> + result [ i ] = keys [ i ] ; <nl> + for ( int i = 0 ; i < children . length ; + + i ) <nl> + result [ keys . length + i ] = children [ i ] ; <nl> + final int [ ] sizeMap = new int [ children . length ] ; <nl> + sizeMap [ 0 ] = BTree . size ( children [ 0 ] ) ; <nl> + for ( int i = 1 ; i < children . length ; + + i ) <nl> + sizeMap [ i ] = sizeMap [ i - 1 ] + BTree . size ( children [ i ] ) + 1 ; <nl> + result [ result . length - 1 ] = sizeMap ; <nl> + return result ; <nl> + } <nl> + <nl> + private static Object [ ] generateSampleTwoLevelsTree ( final int [ ] leafSizes ) <nl> + { <nl> + assert leafSizes . length > 1 ; <nl> + final Object [ ] [ ] leaves = new Object [ leafSizes . length ] [ ] ; <nl> + for ( int i = 0 ; i < leaves . length ; + + i ) <nl> + leaves [ i ] = generateLeaf ( 10 * i + 1 , leafSizes [ i ] ) ; <nl> + final int [ ] keys = new int [ leafSizes . length - 1 ] ; <nl> + for ( int i = 0 ; i < keys . length ; + + i ) <nl> + keys [ i ] = 10 * ( i + 1 ) ; <nl> + final Object [ ] btree = generateBranch ( keys , leaves ) ; <nl> + assertTrue ( BTree . isWellFormed ( btree , CMP ) ) ; <nl> + return btree ; <nl> + } <nl> + <nl> + private static Object [ ] generateSampleThreeLevelsTree ( final int [ ] middleNodeSizes ) <nl> + { <nl> + assert middleNodeSizes . length > 1 ; <nl> + final Object [ ] [ ] middleNodes = new Object [ middleNodeSizes . length ] [ ] ; <nl> + for ( int i = 0 ; i < middleNodes . length ; + + i ) <nl> + { <nl> + final Object [ ] [ ] leaves = new Object [ middleNodeSizes [ i ] ] [ ] ; <nl> + for ( int j = 0 ; j < middleNodeSizes [ i ] ; + + j ) <nl> + leaves [ j ] = generateLeaf ( 100 * i + 10 * j + 1 , 4 ) ; <nl> + final int [ ] keys = new int [ middleNodeSizes [ i ] - 1 ] ; <nl> + for ( int j = 0 ; j < keys . length ; + + j ) <nl> + keys [ j ] = 100 * i + 10 * ( j + 1 ) ; <nl> + middleNodes [ i ] = generateBranch ( keys , leaves ) ; <nl> + } <nl> + final int [ ] keys = new int [ middleNodeSizes . length - 1 ] ; <nl> + for ( int i = 0 ; i < keys . length ; + + i ) <nl> + keys [ i ] = 100 * ( i + 1 ) ; <nl> + final Object [ ] btree = generateBranch ( keys , middleNodes ) ; <nl> + assertTrue ( BTree . isWellFormed ( btree , CMP ) ) ; <nl> + return btree ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromEmpty ( ) <nl> + { <nl> + assertBTree ( BTree . empty ( ) , remove ( BTree . empty ( ) , CMP , 1 ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveNonexistingElement ( ) <nl> + { <nl> + final Object [ ] btree = new Object [ ] { 1 , 2 , 3 , 4 , null } ; <nl> + assertBTree ( btree , remove ( btree , CMP , 5 ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveLastElement ( ) <nl> + { <nl> + final Object [ ] btree = new Object [ ] { 1 } ; <nl> + assertBTree ( BTree . empty ( ) , remove ( btree , CMP , 1 ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromRootWhichIsALeaf ( ) <nl> + { <nl> + for ( int size = 1 ; size < 9 ; + + size ) <nl> + { <nl> + final Object [ ] btree = new Object [ ( size & 1 ) = = 1 ? size : size + 1 ] ; <nl> + for ( int i = 0 ; i < size ; + + i ) <nl> + btree [ i ] = i + 1 ; <nl> + for ( int i = 0 ; i < size ; + + i ) <nl> + { <nl> + final Object [ ] result = remove ( btree , CMP , i + 1 ) ; <nl> + assertTrue ( " size " + size , BTree . isWellFormed ( result , CMP ) ) ; <nl> + for ( int j = 0 ; j < i ; + + j ) <nl> + assertEquals ( " size " + size + " elem " + j , btree [ j ] , result [ j ] ) ; <nl> + for ( int j = i ; j < size - 1 ; + + j ) <nl> + assertEquals ( " size " + size + " elem " + j , btree [ j + 1 ] , result [ j ] ) ; <nl> + for ( int j = size - 1 ; j < result . length ; + + j ) <nl> + assertNull ( " size " + size + " elem " + j , result [ j ] ) ; <nl> + } <nl> + <nl> + { <nl> + final Object [ ] result = remove ( btree , CMP , 0 ) ; <nl> + assertTrue ( " size " + size , BTree . isWellFormed ( result , CMP ) ) ; <nl> + assertBTree ( btree , result ) ; <nl> + } <nl> + <nl> + { <nl> + final Object [ ] result = remove ( btree , CMP , size + 1 ) ; <nl> + assertTrue ( " size " + size , BTree . isWellFormed ( result , CMP ) ) ; <nl> + assertBTree ( btree , result ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromNonMinimalLeaf ( ) <nl> + { <nl> + for ( int size = 5 ; size < 9 ; + + size ) <nl> + { <nl> + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { size , 4 , 4 , 4 , 4 } ) ; <nl> + <nl> + for ( int i = 1 ; i < size + 1 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafRotateLeft ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 5 , 5 , 5 , 5 } ) ; <nl> + <nl> + for ( int i = 11 ; i < 15 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafRotateRight1 ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 5 , 5 , 5 , 5 } ) ; <nl> + <nl> + for ( int i = 1 ; i < 5 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafRotateRight2 ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 , 5 , 5 , 5 } ) ; <nl> + <nl> + for ( int i = 11 ; i < 15 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafMergeWithLeft1 ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 , 4 , 4 , 4 } ) ; <nl> + <nl> + for ( int i = 11 ; i < 15 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafMergeWithLeft2 ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 , 4 , 4 , 4 } ) ; <nl> + <nl> + for ( int i = 41 ; i < 45 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafMergeWithRight ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 , 4 , 4 , 4 } ) ; <nl> + <nl> + for ( int i = 1 ; i < 5 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafWhenSingleKeyRootMergeWithLeft ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 } ) ; <nl> + <nl> + for ( int i = 1 ; i < 5 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafWhenSingleKeyRootMergeWithRight ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 } ) ; <nl> + <nl> + for ( int i = 11 ; i < 15 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafWithBranchLeftRotation ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 6 , 5 , 5 , 5 , 5 } ) ; <nl> + for ( int i = 101 ; i < 105 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafWithBranchRightRotation1 ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 6 , 5 , 5 , 5 } ) ; <nl> + for ( int i = 1 ; i < 5 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafWithBranchRightRotation2 ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 6 , 5 , 5 } ) ; <nl> + for ( int i = 101 ; i < 105 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafWithBranchMergeWithLeft1 ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 5 , 5 , 5 } ) ; <nl> + for ( int i = 101 ; i < 105 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafWithBranchMergeWithLeft2 ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 5 , 5 , 5 } ) ; <nl> + for ( int i = 401 ; i < 405 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMinimalLeafWithBranchMergeWithRight ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 5 , 5 , 5 } ) ; <nl> + for ( int i = 1 ; i < 5 ; + + i ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromMiddleBranch ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 5 , 5 , 5 } ) ; <nl> + for ( int i = 10 ; i < 50 ; i + = 10 ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testRemoveFromRootBranch ( ) <nl> + { <nl> + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 5 , 5 , 5 } ) ; <nl> + for ( int i = 100 ; i < 500 ; i + = 100 ) <nl> + assertRemove ( btree , i ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void randomizedTest ( ) <nl> + { <nl> + Random rand = new Random ( 2 ) ; <nl> + SortedSet < Integer > data = new TreeSet < > ( ) ; <nl> + for ( int i = 0 ; i < 1000 ; + + i ) <nl> + data . add ( rand . nextInt ( ) ) ; <nl> + Object [ ] btree = BTree . build ( data , UpdateFunction . < Integer > noOp ( ) ) ; <nl> + <nl> + assertTrue ( BTree . isWellFormed ( btree , CMP ) ) ; <nl> + assertTrue ( Iterables . elementsEqual ( data , BTree . iterable ( btree ) ) ) ; <nl> + while ( btree ! = BTree . empty ( ) ) <nl> + { <nl> + int idx = rand . nextInt ( BTree . size ( btree ) ) ; <nl> + Integer val = BTree . findByIndex ( btree , idx ) ; <nl> + assertTrue ( data . remove ( val ) ) ; <nl> + btree = assertRemove ( btree , val ) ; <nl> + } <nl> + } <nl> + }
NEAREST DIFF (one line): diff - - git a / src / org / apache / cassandra / utils / BloomCalculations . java b / src / org / apache / cassandra / utils / BloomCalculations . java <nl> index 5b21d7f . . 0962f3e 100644 <nl> - - - a / src / org / apache / cassandra / utils / BloomCalculations . java <nl> + + + b / src / org / apache / cassandra / utils / BloomCalculations . java <nl> @ @ - 30 , 106 + 30 , 103 @ @ package org . apache . cassandra . utils ; <nl> * / <nl> public class BloomCalculations { <nl> <nl> - private static final int maxBits = 15 ; <nl> - private static final int minBits = 2 ; <nl> + private static final int maxBuckets = 15 ; <nl> + private static final int minBuckets = 2 ; <nl> private static final int minK = 1 ; <nl> private static final int maxK = 8 ; <nl> - private static final int [ ] optKPerBits = <nl> - new int [ ] { 1 , / / dummy K for 0 bits per element <nl> - 1 , / / dummy K for 1 bits per element <nl> + private static final int [ ] optKPerBuckets = <nl> + new int [ ] { 1 , / / dummy K for 0 buckets per element <nl> + 1 , / / dummy K for 1 buckets per element <nl> 1 , 2 , 3 , 3 , 4 , 5 , 5 , 6 , 7 , 8 , 8 , 8 , 8 , 8 } ; <nl> <nl> / * * <nl> - * In the following table , the row ' i ' shows false positive rates if i bits <nl> + * In the following table , the row ' i ' shows false positive rates if i buckets <nl> * per element are used . Column ' j ' shows false positive rates if j hash <nl> * functions are used . The first row is ' i = 0 ' , the first column is ' j = 0 ' . <nl> - * Each cell ( i , j ) the false positive rate determined by using i bits per <nl> + * Each cell ( i , j ) the false positive rate determined by using i buckets per <nl> * element and j hash functions . <nl> * / <nl> - private static final double [ ] [ ] probs = new double [ ] [ ] { <nl> - { 1 . 0 } , / / dummy row representing 0 bits per element <nl> - { 1 . 0 , 1 . 0 } , / / dummy row representing 1 bits per element <nl> + static final double [ ] [ ] probs = new double [ ] [ ] { <nl> + { 1 . 0 } , / / dummy row representing 0 buckets per element <nl> + { 1 . 0 , 1 . 0 } , / / dummy row representing 1 buckets per element <nl> { 1 . 0 , 0 . 393 , 0 . 400 } , <nl> { 1 . 0 , 0 . 283 , 0 . 237 , 0 . 253 } , <nl> { 1 . 0 , 0 . 221 , 0 . 155 , 0 . 147 , 0 . 160 } , <nl> - { 1 . 0 , 0 . 181 , 0 . 109 , 0 . 092 , 0 . 092 , 0 . 101 } , <nl> + { 1 . 0 , 0 . 181 , 0 . 109 , 0 . 092 , 0 . 092 , 0 . 101 } , / / 5 <nl> { 1 . 0 , 0 . 154 , 0 . 0804 , 0 . 0609 , 0 . 0561 , 0 . 0578 , 0 . 0638 } , <nl> { 1 . 0 , 0 . 133 , 0 . 0618 , 0 . 0423 , 0 . 0359 , 0 . 0347 , 0 . 0364 } , <nl> { 1 . 0 , 0 . 118 , 0 . 0489 , 0 . 0306 , 0 . 024 , 0 . 0217 , 0 . 0216 , 0 . 0229 } , <nl> - { 1 . 0 , 0 . 105 , 0 . 0397 , 0 . 0228 , 0 . 0166 , 0 . 0141 , 0 . 0133 , 0 . 0135 , 0 . 0145 } , <nl> + { 1 . 0 , 0 . 105 , 0 . 0397 , 0 . 0228 , 0 . 0166 , 0 . 0141 , 0 . 0133 , 0 . 0135 , 0 . 0145 } , / / 9 <nl> { 1 . 0 , 0 . 0952 , 0 . 0329 , 0 . 0174 , 0 . 0118 , 0 . 00943 , 0 . 00844 , 0 . 00819 , 0 . 00846 } , <nl> { 1 . 0 , 0 . 0869 , 0 . 0276 , 0 . 0136 , 0 . 00864 , 0 . 0065 , 0 . 00552 , 0 . 00513 , 0 . 00509 } , <nl> { 1 . 0 , 0 . 08 , 0 . 0236 , 0 . 0108 , 0 . 00646 , 0 . 00459 , 0 . 00371 , 0 . 00329 , 0 . 00314 } , <nl> { 1 . 0 , 0 . 074 , 0 . 0203 , 0 . 00875 , 0 . 00492 , 0 . 00332 , 0 . 00255 , 0 . 00217 , 0 . 00199 } , <nl> { 1 . 0 , 0 . 0689 , 0 . 0177 , 0 . 00718 , 0 . 00381 , 0 . 00244 , 0 . 00179 , 0 . 00146 , 0 . 00129 } , <nl> - { 1 . 0 , 0 . 0645 , 0 . 0156 , 0 . 00596 , 0 . 003 , 0 . 00183 , 0 . 00128 , 0 . 001 , 0 . 000852 } <nl> + { 1 . 0 , 0 . 0645 , 0 . 0156 , 0 . 00596 , 0 . 003 , 0 . 00183 , 0 . 00128 , 0 . 001 , 0 . 000852 } / / 15 <nl> } ; / / the first column is a dummy column representing K = 0 . <nl> <nl> - public static double getFailureRate ( int bitsPerElement ) { <nl> - int k = computeBestK ( bitsPerElement ) ; <nl> - if ( bitsPerElement > = probs . length ) bitsPerElement = probs . length - 1 ; <nl> - return probs [ bitsPerElement ] [ k ] ; <nl> - } <nl> - <nl> / * * <nl> - * Given the number of bits that can be used per element , return the optimal <nl> + * Given the number of buckets that can be used per element , return the optimal <nl> * number of hash functions in order to minimize the false positive rate . <nl> * <nl> - * @ param bitsPerElement <nl> + * @ param bucketsPerElement <nl> * @ return The number of hash functions that minimize the false positive rate . <nl> * / <nl> - public static int computeBestK ( int bitsPerElement ) { <nl> - if ( bitsPerElement < 0 ) <nl> - return optKPerBits [ 0 ] ; <nl> - if ( bitsPerElement > = optKPerBits . length ) <nl> - return optKPerBits [ optKPerBits . length - 1 ] ; <nl> - return optKPerBits [ bitsPerElement ] ; <nl> + public static int computeBestK ( int bucketsPerElement ) { <nl> + assert bucketsPerElement > = 0 ; <nl> + if ( bucketsPerElement > = optKPerBuckets . length ) <nl> + return optKPerBuckets [ optKPerBuckets . length - 1 ] ; <nl> + return optKPerBuckets [ bucketsPerElement ] ; <nl> } <nl> <nl> / * * <nl> * A wrapper class that holds two key parameters for a Bloom Filter : the <nl> - * number of hash functions used , and the number of bits per element used . <nl> + * number of hash functions used , and the number of buckets per element used . <nl> * / <nl> - public static class BloomSpecification { <nl> - int K ; / / number of hash functions . <nl> - int bitsPerElement ; <nl> + public static final class BloomSpecification { <nl> + final int K ; / / number of hash functions . <nl> + final int bucketsPerElement ; <nl> + <nl> + public BloomSpecification ( int k , int bucketsPerElement ) { <nl> + K = k ; <nl> + this . bucketsPerElement = bucketsPerElement ; <nl> + } <nl> } <nl> <nl> / * * <nl> * Given a maximum tolerable false positive probability , compute a Bloom <nl> * specification which will give less than the specified false positive rate , <nl> - * but minimize the number of bits per element and the number of hash <nl> + * but minimize the number of buckets per element and the number of hash <nl> * functions used . Because bandwidth ( and therefore total bitvector size ) <nl> * is considered more expensive than computing power , preference is given <nl> - * to minimizing bits per element rather than number of hash funtions . <nl> + * to minimizing buckets per element rather than number of hash funtions . <nl> * <nl> * @ param maxFalsePosProb The maximum tolerable false positive rate . <nl> * @ return A Bloom Specification which would result in a false positive rate <nl> * less than specified by the function call . <nl> * / <nl> - public static BloomSpecification computeBitsAndK ( double maxFalsePosProb ) { <nl> - BloomSpecification spec = new BloomSpecification ( ) ; <nl> - spec . bitsPerElement = 2 ; <nl> - spec . K = optKPerBits [ spec . bitsPerElement ] ; <nl> - <nl> - / / Handle the trivial cases : <nl> - if ( maxFalsePosProb > = probs [ minBits ] [ minK ] ) return spec ; <nl> - if ( maxFalsePosProb < probs [ maxBits ] [ maxK ] ) { <nl> - spec . bitsPerElement = maxBits ; <nl> - spec . K = maxK ; <nl> - return spec ; <nl> + public static BloomSpecification computeBucketsAndK ( double maxFalsePosProb ) { <nl> + / / Handle the trivial cases <nl> + if ( maxFalsePosProb > = probs [ minBuckets ] [ minK ] ) { <nl> + return new BloomSpecification ( 2 , optKPerBuckets [ 2 ] ) ; <nl> + } <nl> + if ( maxFalsePosProb < probs [ maxBuckets ] [ maxK ] ) { <nl> + return new BloomSpecification ( maxK , maxBuckets ) ; <nl> } <nl> <nl> - / / First find the minimal required number of bits : <nl> - while ( probs [ spec . bitsPerElement ] [ spec . K ] > maxFalsePosProb ) { <nl> - spec . bitsPerElement + + ; <nl> - spec . K = optKPerBits [ spec . bitsPerElement ] ; <nl> + / / First find the minimal required number of buckets : <nl> + int bucketsPerElement = 2 ; <nl> + int K = optKPerBuckets [ 2 ] ; <nl> + while ( probs [ bucketsPerElement ] [ K ] > maxFalsePosProb ) { <nl> + bucketsPerElement + + ; <nl> + K = optKPerBuckets [ bucketsPerElement ] ; <nl> } <nl> - / / Now that the number of bits is sufficient , see if we can relax K <nl> + / / Now that the number of buckets is sufficient , see if we can relax K <nl> / / without losing too much precision . <nl> - while ( probs [ spec . bitsPerElement ] [ spec . K - 1 ] < = maxFalsePosProb ) { <nl> - spec . K - - ; <nl> + while ( probs [ bucketsPerElement ] [ K - 1 ] < = maxFalsePosProb ) { <nl> + K - - ; <nl> } <nl> - return spec ; <nl> + <nl> + return new BloomSpecification ( K , bucketsPerElement ) ; <nl> } <nl> } <nl> diff - - git a / src / org / apache / cassandra / utils / BloomFilter . java b / src / org / apache / cassandra / utils / BloomFilter . java <nl> index 6d8e2a8 . . 01d09b8 100644 <nl> - - - a / src / org / apache / cassandra / utils / BloomFilter . java <nl> + + + b / src / org / apache / cassandra / utils / BloomFilter . java <nl> @ @ - 18 , 48 + 18 , 15 @ @ <nl> <nl> package org . apache . cassandra . utils ; <nl> <nl> - import java . math . * ; <nl> - import java . nio . ByteBuffer ; <nl> - import java . nio . LongBuffer ; <nl> - import java . io . * ; <nl> - import java . security . * ; <nl> - import java . util . ArrayList ; <nl> - import java . util . List ; <nl> - import java . util . Random ; <nl> - import java . util . zip . * ; <nl> + import java . io . DataInputStream ; <nl> + import java . io . DataOutputStream ; <nl> + import java . io . IOException ; <nl> <nl> - import javax . xml . bind . annotation . XmlElement ; <nl> - <nl> - import org . apache . cassandra . io . DataInputBuffer ; <nl> - import org . apache . cassandra . io . DataOutputBuffer ; <nl> import org . apache . cassandra . io . ICompactSerializer ; <nl> - import org . apache . cassandra . io . SSTable ; <nl> - <nl> <nl> - / * * <nl> - * Author : Avinash Lakshman ( alakshman @ facebook . com ) & Prashant Malik ( pmalik @ facebook . com ) <nl> - * / <nl> - <nl> - public class BloomFilter implements Serializable <nl> - { <nl> - private static List < ISimpleHash > hashLibrary _ = new ArrayList < ISimpleHash > ( ) ; <nl> - private static ICompactSerializer < BloomFilter > serializer _ ; <nl> - <nl> - static <nl> - { <nl> - serializer _ = new BloomFilterSerializer ( ) ; <nl> - hashLibrary _ . add ( new RSHash ( ) ) ; <nl> - hashLibrary _ . add ( new JSHash ( ) ) ; <nl> - hashLibrary _ . add ( new PJWHash ( ) ) ; <nl> - hashLibrary _ . add ( new ELFHash ( ) ) ; <nl> - hashLibrary _ . add ( new BKDRHash ( ) ) ; <nl> - hashLibrary _ . add ( new SDBMHash ( ) ) ; <nl> - hashLibrary _ . add ( new DJBHash ( ) ) ; <nl> - hashLibrary _ . add ( new DEKHash ( ) ) ; <nl> - hashLibrary _ . add ( new BPHash ( ) ) ; <nl> - hashLibrary _ . add ( new FNVHash ( ) ) ; <nl> - hashLibrary _ . add ( new APHash ( ) ) ; <nl> - } <nl> + public class BloomFilter extends Filter <nl> + { <nl> + static ICompactSerializer < BloomFilter > serializer _ = new BloomFilterSerializer ( ) ; <nl> <nl> public static ICompactSerializer < BloomFilter > serializer ( ) <nl> { <nl> @ @ - 67 , 52 + 34 , 37 @ @ public class BloomFilter implements Serializable <nl> } <nl> <nl> private BitSet filter _ ; <nl> - private int count _ ; <nl> - private int size _ ; <nl> - private int hashes _ ; <nl> - private Random random _ = new Random ( System . currentTimeMillis ( ) ) ; <nl> <nl> - public BloomFilter ( int numElements , int bitsPerElement ) <nl> + public BloomFilter ( int numElements , int bucketsPerElement ) <nl> { <nl> - / / TODO - - think about the trivial cases more . <nl> - / / Note that it should indeed be possible to send a bloom filter that <nl> - / / encodes the empty set . <nl> - if ( numElements < 0 | | bitsPerElement < 1 ) <nl> - throw new IllegalArgumentException ( " Number of elements and bits " <nl> - + " must be non - negative . " ) ; <nl> - / / Adding a small random number of bits so that even if the set <nl> - / / of elements hasn ' t changed , we ' ll get different false positives . <nl> - count _ = numElements ; <nl> - size _ = numElements * bitsPerElement + 20 + random _ . nextInt ( 64 ) ; <nl> - filter _ = new BitSet ( size _ ) ; <nl> - / / hashes _ = BloomCalculations . computeBestK ( bitsPerElement ) ; <nl> - hashes _ = 8 ; <nl> + this ( BloomCalculations . computeBestK ( bucketsPerElement ) , new BitSet ( numElements * bucketsPerElement + 20 ) ) ; <nl> + } <nl> + <nl> + public BloomFilter ( int numElements , double maxFalsePosProbability ) <nl> + { <nl> + BloomCalculations . BloomSpecification spec = BloomCalculations <nl> + . computeBucketsAndK ( maxFalsePosProbability ) ; <nl> + filter _ = new BitSet ( numElements * spec . bucketsPerElement + 20 ) ; <nl> + hashCount = spec . K ; <nl> } <nl> <nl> / * <nl> - * This version is only used by the deserializer . <nl> + * This version is only used by the deserializer . <nl> * / <nl> - BloomFilter ( int count , int hashes , int size , BitSet filter ) <nl> + BloomFilter ( int hashes , BitSet filter ) <nl> { <nl> - count _ = count ; <nl> - hashes _ = hashes ; <nl> - size _ = size ; <nl> + hashCount = hashes ; <nl> filter _ = filter ; <nl> } <nl> <nl> - int count ( ) <nl> + public void clear ( ) <nl> { <nl> - return count _ ; <nl> - } <nl> - <nl> - int size ( ) <nl> - { <nl> - return size _ ; <nl> + filter _ . clear ( ) ; <nl> } <nl> <nl> - int hashes ( ) <nl> + int buckets ( ) <nl> { <nl> - return hashes _ ; <nl> + return filter _ . size ( ) ; <nl> } <nl> <nl> BitSet filter ( ) <nl> @ @ - 122 , 19 + 74 , 14 @ @ public class BloomFilter implements Serializable <nl> <nl> public boolean isPresent ( String key ) <nl> { <nl> - boolean bVal = true ; <nl> - for ( int i = 0 ; i < hashes _ ; + + i ) <nl> + for ( int bucketIndex : getHashBuckets ( key ) ) <nl> { <nl> - ISimpleHash hash = hashLibrary _ . get ( i ) ; <nl> - int hashValue = hash . hash ( key ) ; <nl> - int index = Math . abs ( hashValue % size _ ) ; <nl> - if ( ! filter _ . get ( index ) ) <nl> + if ( ! filter _ . get ( bucketIndex ) ) <nl> { <nl> - bVal = false ; <nl> - break ; <nl> + return false ; <nl> } <nl> } <nl> - return bVal ; <nl> + return true ; <nl> } <nl> <nl> / * <nl> @ @ - 144 , 12 + 91 , 9 @ @ public class BloomFilter implements Serializable <nl> * / <nl> public void add ( String key ) <nl> { <nl> - for ( int i = 0 ; i < hashes _ ; + + i ) <nl> + for ( int bucketIndex : getHashBuckets ( key ) ) <nl> { <nl> - ISimpleHash hash = hashLibrary _ . get ( i ) ; <nl> - int hashValue = hash . hash ( key ) ; <nl> - int index = Math . abs ( hashValue % size _ ) ; <nl> - filter _ . set ( index ) ; <nl> + filter _ . set ( bucketIndex ) ; <nl> } <nl> } <nl> <nl> @ @ - 157 , 218 + 101 , 39 @ @ public class BloomFilter implements Serializable <nl> { <nl> return filter _ . toString ( ) ; <nl> } <nl> - } <nl> - <nl> - class BloomFilterSerializer implements ICompactSerializer < BloomFilter > <nl> - { <nl> - / * <nl> - * The following methods are used for compact representation <nl> - * of BloomFilter . This is essential , since we want to determine <nl> - * the size of the serialized Bloom Filter blob before it is <nl> - * populated armed with the knowledge of how many elements are <nl> - * going to reside in it . <nl> - * / <nl> - <nl> - public void serialize ( BloomFilter bf , DataOutputStream dos ) throws IOException <nl> - { <nl> - / * write out the count of the BloomFilter * / <nl> - dos . writeInt ( bf . count ( ) ) ; <nl> - / * write the number of hash functions used * / <nl> - dos . writeInt ( bf . hashes ( ) ) ; <nl> - / * write the size of the BloomFilter * / <nl> - dos . writeInt ( bf . size ( ) ) ; <nl> - BitSet . serializer ( ) . serialize ( bf . filter ( ) , dos ) ; <nl> - } <nl> <nl> - public BloomFilter deserialize ( DataInputStream dis ) throws IOException <nl> + ICompactSerializer tserializer ( ) <nl> { <nl> - / * read the count of the BloomFilter * / <nl> - int count = dis . readInt ( ) ; <nl> - / * read the number of hash functions * / <nl> - int hashes = dis . readInt ( ) ; <nl> - / * read the size of the bloom filter * / <nl> - int size = dis . readInt ( ) ; <nl> - BitSet bs = BitSet . serializer ( ) . deserialize ( dis ) ; <nl> - return new BloomFilter ( count , hashes , size , bs ) ; <nl> - } <nl> - } <nl> - <nl> - interface ISimpleHash <nl> - { <nl> - public int hash ( String str ) ; <nl> - } <nl> - <nl> - class RSHash implements ISimpleHash <nl> - { <nl> - public int hash ( String str ) <nl> - { <nl> - int b = 378551 ; <nl> - int a = 63689 ; <nl> - int hash = 0 ; <nl> - <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> - { <nl> - hash = hash * a + str . charAt ( i ) ; <nl> - a = a * b ; <nl> - } <nl> - return hash ; <nl> - } <nl> - } <nl> - <nl> - class JSHash implements ISimpleHash <nl> - { <nl> - public int hash ( String str ) <nl> - { <nl> - int hash = 1315423911 ; <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> - { <nl> - hash ^ = ( ( hash < < 5 ) + str . charAt ( i ) + ( hash > > 2 ) ) ; <nl> - } <nl> - return hash ; <nl> - } <nl> - } <nl> - <nl> - class PJWHash implements ISimpleHash <nl> - { <nl> - public int hash ( String str ) <nl> - { <nl> - int bitsInUnsignedInt = ( 4 * 8 ) ; <nl> - int threeQuarters = ( bitsInUnsignedInt * 3 ) / 4 ; <nl> - int oneEighth = bitsInUnsignedInt / 8 ; <nl> - int highBits = ( 0xFFFFFFFF ) < < ( bitsInUnsignedInt - oneEighth ) ; <nl> - int hash = 0 ; <nl> - int test = 0 ; <nl> - <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> - { <nl> - hash = ( hash < < oneEighth ) + str . charAt ( i ) ; <nl> - <nl> - if ( ( test = hash & highBits ) ! = 0 ) <nl> - { <nl> - hash = ( ( hash ^ ( test > > threeQuarters ) ) & ( ~ highBits ) ) ; <nl> - } <nl> - } <nl> - return hash ; <nl> + return serializer _ ; <nl> } <nl> - } <nl> <nl> - class ELFHash implements ISimpleHash <nl> - { <nl> - public int hash ( String str ) <nl> + int emptyBuckets ( ) <nl> { <nl> - int hash = 0 ; <nl> - int x = 0 ; <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> + int n = 0 ; <nl> + for ( int i = 0 ; i < buckets ( ) ; i + + ) <nl> { <nl> - hash = ( hash < < 4 ) + str . charAt ( i ) ; <nl> - <nl> - if ( ( x = hash & 0xF0000000 ) ! = 0 ) <nl> + if ( ! filter _ . get ( i ) ) <nl> { <nl> - hash ^ = ( x > > 24 ) ; <nl> + n + + ; <nl> } <nl> - hash & = ~ x ; <nl> - } <nl> - return hash ; <nl> - } <nl> - } <nl> - <nl> - class BKDRHash implements ISimpleHash <nl> - { <nl> - public int hash ( String str ) <nl> - { <nl> - int seed = 131 ; / / 31 131 1313 13131 131313 etc . . <nl> - int hash = 0 ; <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> - { <nl> - hash = ( hash * seed ) + str . charAt ( i ) ; <nl> - } <nl> - return hash ; <nl> - } <nl> - } <nl> - <nl> - class SDBMHash implements ISimpleHash <nl> - { <nl> - public int hash ( String str ) <nl> - { <nl> - int hash = 0 ; <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> - { <nl> - hash = str . charAt ( i ) + ( hash < < 6 ) + ( hash < < 16 ) - hash ; <nl> - } <nl> - return hash ; <nl> - } <nl> - } <nl> - <nl> - class DJBHash implements ISimpleHash <nl> - { <nl> - public int hash ( String str ) <nl> - { <nl> - int hash = 5381 ; <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> - { <nl> - hash = ( ( hash < < 5 ) + hash ) + str . charAt ( i ) ; <nl> - } <nl> - return hash ; <nl> - } <nl> - } <nl> - <nl> - class DEKHash implements ISimpleHash <nl> - { <nl> - public int hash ( String str ) <nl> - { <nl> - int hash = str . length ( ) ; <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> - { <nl> - hash = ( ( hash < < 5 ) ^ ( hash > > 27 ) ) ^ str . charAt ( i ) ; <nl> - } <nl> - return hash ; <nl> - } <nl> - } <nl> - <nl> - class BPHash implements ISimpleHash <nl> - { <nl> - public int hash ( String str ) <nl> - { <nl> - int hash = 0 ; <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> - { <nl> - hash = hash < < 7 ^ str . charAt ( i ) ; <nl> } <nl> - return hash ; <nl> + return n ; <nl> } <nl> } <nl> <nl> - class FNVHash implements ISimpleHash <nl> + class BloomFilterSerializer implements ICompactSerializer < BloomFilter > <nl> { <nl> - public int hash ( String str ) <nl> + public void serialize ( BloomFilter bf , DataOutputStream dos ) <nl> + throws IOException <nl> { <nl> - int fnv _ prime = 0x811C9DC5 ; <nl> - int hash = 0 ; <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> - { <nl> - hash * = fnv _ prime ; <nl> - hash ^ = str . charAt ( i ) ; <nl> - } <nl> - return hash ; <nl> + dos . writeInt ( bf . getHashCount ( ) ) ; <nl> + BitSet . serializer ( ) . serialize ( bf . filter ( ) , dos ) ; <nl> } <nl> - } <nl> <nl> - class APHash implements ISimpleHash <nl> - { <nl> - public int hash ( String str ) <nl> + public BloomFilter deserialize ( DataInputStream dis ) throws IOException <nl> { <nl> - int hash = 0xAAAAAAAA ; <nl> - for ( int i = 0 ; i < str . length ( ) ; i + + ) <nl> - { <nl> - if ( ( i & 1 ) = = 0 ) <nl> - { <nl> - hash ^ = ( ( hash < < 7 ) ^ str . charAt ( i ) ^ ( hash > > 3 ) ) ; <nl> - } <nl> - else <nl> - { <nl> - hash ^ = ( ~ ( ( hash < < 11 ) ^ str . charAt ( i ) ^ ( hash > > 5 ) ) ) ; <nl> - } <nl> - } <nl> - return hash ; <nl> + int hashes = dis . readInt ( ) ; <nl> + BitSet bs = BitSet . serializer ( ) . deserialize ( dis ) ; <nl> + return new BloomFilter ( hashes , bs ) ; <nl> } <nl> } <nl> diff - - git a / src / org / apache / cassandra / utils / Filter . java b / src / org / apache / cassandra / utils / Filter . java <nl> new file mode 100644 <nl> index 0000000 . . 287cee5 <nl> - - - / dev / null <nl> + + + b / src / org / apache / cassandra / utils / Filter . java <nl> @ @ - 0 , 0 + 1 , 72 @ @ <nl> + package org . apache . cassandra . utils ; <nl> + <nl> + import java . io . UnsupportedEncodingException ; <nl> + import java . lang . reflect . Method ; <nl> + <nl> + import org . apache . cassandra . io . ICompactSerializer ; <nl> + <nl> + public abstract class Filter <nl> + { <nl> + int hashCount ; <nl> + <nl> + private static MurmurHash hasher = new MurmurHash ( ) ; <nl> + <nl> + int getHashCount ( ) <nl> + { <nl> + return hashCount ; <nl> + } <nl> + <nl> + public int [ ] getHashBuckets ( String key ) <nl> + { <nl> + return Filter . getHashBuckets ( key , hashCount , buckets ( ) ) ; <nl> + } <nl> + <nl> + abstract int buckets ( ) ; <nl> + <nl> + public abstract void add ( String key ) ; <nl> + <nl> + public abstract boolean isPresent ( String key ) ; <nl> + <nl> + / / for testing <nl> + abstract int emptyBuckets ( ) ; <nl> + <nl> + ICompactSerializer < Filter > getSerializer ( ) <nl> + { <nl> + Method method = null ; <nl> + try <nl> + { <nl> + method = getClass ( ) . getMethod ( " serializer " ) ; <nl> + return ( ICompactSerializer < Filter > ) method . invoke ( null ) ; <nl> + } <nl> + catch ( Exception e ) <nl> + { <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> + } <nl> + <nl> + / / murmur is faster than a sha - based approach and provides as - good collision <nl> + / / resistance . the combinatorial generation approach described in <nl> + / / http : / / www . eecs . harvard . edu / ~ kirsch / pubs / bbbf / esa06 . pdf <nl> + / / does prove to work in actual tests , and is obviously faster <nl> + / / than performing further iterations of murmur . <nl> + static int [ ] getHashBuckets ( String key , int hashCount , int max ) <nl> + { <nl> + byte [ ] b ; <nl> + try <nl> + { <nl> + b = key . getBytes ( " UTF - 16 " ) ; <nl> + } <nl> + catch ( UnsupportedEncodingException e ) <nl> + { <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> + int [ ] result = new int [ hashCount ] ; <nl> + int hash1 = hasher . hash ( b , b . length , 0 ) ; <nl> + int hash2 = hasher . hash ( b , b . length , hash1 ) ; <nl> + for ( int i = 0 ; i < hashCount ; i + + ) <nl> + { <nl> + result [ i ] = Math . abs ( ( hash1 + i * hash2 ) % max ) ; <nl> + } <nl> + return result ; <nl> + } <nl> + } <nl> \ No newline at end of file <nl> diff - - git a / test / org / apache / cassandra / utils / BloomFilterTest . java b / test / org / apache / cassandra / utils / BloomFilterTest . java <nl> new file mode 100644 <nl> index 0000000 . . f518afd <nl> - - - / dev / null <nl> + + + b / test / org / apache / cassandra / utils / BloomFilterTest . java <nl> @ @ - 0 , 0 + 1 , 98 @ @ <nl> + package org . apache . cassandra . utils ; <nl> + <nl> + import java . io . IOException ; <nl> + <nl> + import org . testng . annotations . BeforeMethod ; <nl> + import org . testng . annotations . Test ; <nl> + <nl> + public class BloomFilterTest <nl> + { <nl> + public BloomFilter bf ; <nl> + public BloomCalculations . BloomSpecification spec = BloomCalculations . computeBucketsAndK ( 0 . 0001 ) ; <nl> + static final int ELEMENTS = 10000 ; <nl> + <nl> + public BloomFilterTest ( ) <nl> + { <nl> + bf = new BloomFilter ( ELEMENTS , spec . bucketsPerElement ) ; <nl> + assert bf ! = null ; <nl> + } <nl> + <nl> + @ BeforeMethod <nl> + public void clear ( ) <nl> + { <nl> + bf . clear ( ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testOne ( ) <nl> + { <nl> + bf . add ( " a " ) ; <nl> + assert bf . isPresent ( " a " ) ; <nl> + assert ! bf . isPresent ( " b " ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testFalsePositivesInt ( ) <nl> + { <nl> + FilterTest . testFalsePositives ( bf , FilterTest . intKeys ( ) , FilterTest . randomKeys2 ( ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testFalsePositivesRandom ( ) <nl> + { <nl> + FilterTest . testFalsePositives ( bf , FilterTest . randomKeys ( ) , FilterTest . randomKeys2 ( ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testWords ( ) <nl> + { <nl> + if ( KeyGenerator . WordGenerator . WORDS = = 0 ) <nl> + { <nl> + return ; <nl> + } <nl> + BloomFilter bf2 = new BloomFilter ( KeyGenerator . WordGenerator . WORDS / 2 , FilterTest . spec . bucketsPerElement ) ; <nl> + int skipEven = KeyGenerator . WordGenerator . WORDS % 2 = = 0 ? 0 : 2 ; <nl> + FilterTest . testFalsePositives ( bf2 , <nl> + new KeyGenerator . WordGenerator ( skipEven , 2 ) , <nl> + new KeyGenerator . WordGenerator ( 1 , 2 ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testSerialize ( ) throws IOException <nl> + { <nl> + FilterTest . testSerialize ( bf ) ; <nl> + } <nl> + <nl> + / * TODO move these into a nightly suite ( they take 5 - 10 minutes each ) <nl> + @ Test <nl> + / / run with - mx1G <nl> + public void testBigInt ( ) { <nl> + int size = 100 * 1000 * 1000 ; <nl> + bf = new BloomFilter ( size , FilterTest . spec . bucketsPerElement ) ; <nl> + FilterTest . testFalsePositives ( bf , <nl> + new KeyGenerator . IntGenerator ( size ) , <nl> + new KeyGenerator . IntGenerator ( size , size * 2 ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testBigRandom ( ) { <nl> + int size = 100 * 1000 * 1000 ; <nl> + bf = new BloomFilter ( size , FilterTest . spec . bucketsPerElement ) ; <nl> + FilterTest . testFalsePositives ( bf , <nl> + new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , size ) , <nl> + new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , size ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void timeit ( ) { <nl> + int size = 300 * FilterTest . ELEMENTS ; <nl> + bf = new BloomFilter ( size , FilterTest . spec . bucketsPerElement ) ; <nl> + for ( int i = 0 ; i < 10 ; i + + ) { <nl> + FilterTest . testFalsePositives ( bf , <nl> + new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , size ) , <nl> + new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , size ) ) ; <nl> + bf . clear ( ) ; <nl> + } <nl> + } <nl> + * / <nl> + } <nl> diff - - git a / test / org / apache / cassandra / utils / FilterTest . java b / test / org / apache / cassandra / utils / FilterTest . java <nl> new file mode 100644 <nl> index 0000000 . . 6c8e535 <nl> - - - / dev / null <nl> + + + b / test / org / apache / cassandra / utils / FilterTest . java <nl> @ @ - 0 , 0 + 1 , 95 @ @ <nl> + package org . apache . cassandra . utils ; <nl> + <nl> + import java . util . Iterator ; <nl> + import java . util . Set ; <nl> + import java . util . HashSet ; <nl> + import java . io . IOException ; <nl> + <nl> + import org . testng . annotations . Test ; <nl> + import org . apache . cassandra . io . DataInputBuffer ; <nl> + import org . apache . cassandra . io . DataOutputBuffer ; <nl> + <nl> + public class FilterTest <nl> + { <nl> + public void testManyHashes ( Iterator < String > keys ) <nl> + { <nl> + int MAX _ HASH _ COUNT = 128 ; <nl> + Set < Integer > hashes = new HashSet < Integer > ( ) ; <nl> + int collisions = 0 ; <nl> + while ( keys . hasNext ( ) ) <nl> + { <nl> + hashes . clear ( ) ; <nl> + for ( int hashIndex : Filter . getHashBuckets ( keys . next ( ) , MAX _ HASH _ COUNT , 1024 * 1024 ) ) <nl> + { <nl> + hashes . add ( hashIndex ) ; <nl> + } <nl> + collisions + = ( MAX _ HASH _ COUNT - hashes . size ( ) ) ; <nl> + } <nl> + assert collisions < = 100 ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testManyRandom ( ) <nl> + { <nl> + testManyHashes ( randomKeys ( ) ) ; <nl> + } <nl> + <nl> + / / used by filter subclass tests <nl> + <nl> + static final double MAX _ FAILURE _ RATE = 0 . 1 ; <nl> + public static final BloomCalculations . BloomSpecification spec = BloomCalculations . computeBucketsAndK ( MAX _ FAILURE _ RATE ) ; <nl> + static final int ELEMENTS = 10000 ; <nl> + <nl> + static final ResetableIterator < String > intKeys ( ) <nl> + { <nl> + return new KeyGenerator . IntGenerator ( ELEMENTS ) ; <nl> + } <nl> + <nl> + static final ResetableIterator < String > randomKeys ( ) <nl> + { <nl> + return new KeyGenerator . RandomStringGenerator ( 314159 , ELEMENTS ) ; <nl> + } <nl> + <nl> + static final ResetableIterator < String > randomKeys2 ( ) <nl> + { <nl> + return new KeyGenerator . RandomStringGenerator ( 271828 , ELEMENTS ) ; <nl> + } <nl> + <nl> + public static void testFalsePositives ( Filter f , ResetableIterator < String > keys , ResetableIterator < String > otherkeys ) <nl> + { <nl> + assert keys . size ( ) = = otherkeys . size ( ) ; <nl> + <nl> + while ( keys . hasNext ( ) ) <nl> + { <nl> + f . add ( keys . next ( ) ) ; <nl> + } <nl> + <nl> + int fp = 0 ; <nl> + while ( otherkeys . hasNext ( ) ) <nl> + { <nl> + if ( f . isPresent ( otherkeys . next ( ) ) ) <nl> + { <nl> + fp + + ; <nl> + } <nl> + } <nl> + <nl> + double fp _ ratio = fp / ( keys . size ( ) * BloomCalculations . probs [ spec . bucketsPerElement ] [ spec . K ] ) ; <nl> + assert fp _ ratio < 1 . 03 : fp _ ratio ; <nl> + } <nl> + <nl> + public static Filter testSerialize ( Filter f ) throws IOException <nl> + { <nl> + f . add ( " a " ) ; <nl> + DataOutputBuffer out = new DataOutputBuffer ( ) ; <nl> + f . getSerializer ( ) . serialize ( f , out ) ; <nl> + <nl> + DataInputBuffer in = new DataInputBuffer ( ) ; <nl> + in . reset ( out . getData ( ) , out . getLength ( ) ) ; <nl> + Filter f2 = f . getSerializer ( ) . deserialize ( in ) ; <nl> + <nl> + assert f2 . isPresent ( " a " ) ; <nl> + assert ! f2 . isPresent ( " b " ) ; <nl> + return f2 ; <nl> + } <nl> + <nl> + } <nl> diff - - git a / test / org / apache / cassandra / utils / KeyGenerator . java b / test / org / apache / cassandra / utils / KeyGenerator . java <nl> index 99ddef0 . . fafd0d3 100644 <nl> - - - a / test / org / apache / cassandra / utils / KeyGenerator . java <nl> + + + b / test / org / apache / cassandra / utils / KeyGenerator . java <nl> @ @ - 90 , 7 + 90 , 7 @ @ public class KeyGenerator { <nl> WORDS + + ; <nl> } <nl> } catch ( IOException e ) { <nl> - throw new RuntimeException ( e ) ; <nl> + WORDS = 0 ; <nl> } <nl> } <nl>

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 0294efc . . 4149d91 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 3 . 2 
 + * More efficient BTree removal ( CASSANDRA - 9991 ) 
 * Make tablehistograms accept the same syntax as tablestats ( CASSANDRA - 10149 ) 
 * Group pending compactions based on table ( CASSANDRA - 10718 ) 
 * Add compressor name in sstablemetadata output ( CASSANDRA - 9879 ) 
 diff - - git a / src / java / org / apache / cassandra / db / Columns . java b / src / java / org / apache / cassandra / db / Columns . java 
 index cad295c . . e3c30fa 100644 
 - - - a / src / java / org / apache / cassandra / db / Columns . java 
 + + + b / src / java / org / apache / cassandra / db / Columns . java 
 @ @ - 38 , 6 + 38 , 7 @ @ import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . apache . cassandra . utils . SearchIterator ; 
 import org . apache . cassandra . utils . btree . BTree ; 
 import org . apache . cassandra . utils . btree . BTreeSearchIterator ; 
 + import org . apache . cassandra . utils . btree . BTreeRemoval ; 
 import org . apache . cassandra . utils . btree . UpdateFunction ; 
 
 / * * 
 @ @ - 343 , 7 + 344 , 7 @ @ public class Columns extends AbstractCollection < ColumnDefinition > implements Col 
 if ( ! contains ( column ) ) 
 return this ; 
 
 - Object [ ] newColumns = BTree . < ColumnDefinition > transformAndFilter ( columns , ( c ) - > c . equals ( column ) ? null : c ) ; 
 + Object [ ] newColumns = BTreeRemoval . < ColumnDefinition > remove ( columns , Comparator . naturalOrder ( ) , column ) ; 
 return new Columns ( newColumns ) ; 
 } 
 
 diff - - git a / src / java / org / apache / cassandra / utils / btree / BTree . java b / src / java / org / apache / cassandra / utils / btree / BTree . java 
 index fe08011 . . 1c3d2e2 100644 
 - - - a / src / java / org / apache / cassandra / utils / btree / BTree . java 
 + + + b / src / java / org / apache / cassandra / utils / btree / BTree . java 
 @ @ - 67 , 6 + 67 , 8 @ @ public class BTree 
 / / NB we encode Path indexes as Bytes , so this needs to be less than Byte . MAX _ VALUE / 2 
 static final int FAN _ FACTOR = 1 < < FAN _ SHIFT ; 
 
 + static final int MINIMAL _ NODE _ SIZE = FAN _ FACTOR > > 1 ; 
 + 
 / / An empty BTree Leaf - which is the same as an empty BTree 
 static final Object [ ] EMPTY _ LEAF = new Object [ 1 ] ; 
 
 @ @ - 296 , 6 + 298 , 40 @ @ public class BTree 
 
 / * * 
 * Modifies the provided btree directly . THIS SHOULD NOT BE USED WITHOUT EXTREME CARE as BTrees are meant to be immutable . 
 + * Finds and replaces the item provided by index in the tree . 
 + * / 
 + public static < V > void replaceInSitu ( Object [ ] tree , int index , V replace ) 
 + { 
 + / / WARNING : if semantics change , see also InternalCursor . seekTo , which mirrors this implementation 
 + if ( ( index < 0 ) | ( index > = size ( tree ) ) ) 
 + throw new IndexOutOfBoundsException ( index + " not in range [ 0 . . " + size ( tree ) + " ) " ) ; 
 + 
 + while ( ! isLeaf ( tree ) ) 
 + { 
 + final int [ ] sizeMap = getSizeMap ( tree ) ; 
 + int boundary = Arrays . binarySearch ( sizeMap , index ) ; 
 + if ( boundary > = 0 ) 
 + { 
 + / / exact match , in this branch node 
 + assert boundary < sizeMap . length - 1 ; 
 + tree [ boundary ] = replace ; 
 + return ; 
 + } 
 + 
 + boundary = - 1 - boundary ; 
 + if ( boundary > 0 ) 
 + { 
 + assert boundary < sizeMap . length ; 
 + index - = ( 1 + sizeMap [ boundary - 1 ] ) ; 
 + } 
 + tree = ( Object [ ] ) tree [ getChildStart ( tree ) + boundary ] ; 
 + } 
 + assert index < getLeafKeyEnd ( tree ) ; 
 + tree [ index ] = replace ; 
 + } 
 + 
 + / * * 
 + * Modifies the provided btree directly . THIS SHOULD NOT BE USED WITHOUT EXTREME CARE as BTrees are meant to be immutable . 
 * Finds and replaces the provided item in the tree . Both should sort as equal to each other ( although this is not enforced ) 
 * / 
 public static < V > void replaceInSitu ( Object [ ] node , Comparator < ? super V > comparator , V find , V replace ) 
 @ @ - 1073 , 11 + 1109 , 20 @ @ public class BTree 
 return node . length > = FAN _ FACTOR / 2 & & node . length < = FAN _ FACTOR + 1 ; 
 } 
 
 + final int keyCount = getBranchKeyEnd ( node ) ; 
 + if ( ( ! isRoot & & keyCount < FAN _ FACTOR / 2 ) | | keyCount > FAN _ FACTOR + 1 ) 
 + return false ; 
 + 
 int type = 0 ; 
 + int size = - 1 ; 
 + int [ ] sizeMap = getSizeMap ( node ) ; 
 / / compare each child node with the branch element at the head of this node it corresponds with 
 for ( int i = getChildStart ( node ) ; i < getChildEnd ( node ) ; i + + ) 
 { 
 Object [ ] child = ( Object [ ] ) node [ i ] ; 
 + size + = size ( child ) + 1 ; 
 + if ( sizeMap [ i - getChildStart ( node ) ] ! = size ) 
 + return false ; 
 Object localmax = i < node . length - 2 ? node [ i - getChildStart ( node ) ] : max ; 
 if ( ! isWellFormed ( cmp , child , false , min , localmax ) ) 
 return false ; 
 diff - - git a / src / java / org / apache / cassandra / utils / btree / BTreeRemoval . java b / src / java / org / apache / cassandra / utils / btree / BTreeRemoval . java 
 new file mode 100644 
 index 0000000 . . 74fa402 
 - - - / dev / null 
 + + + b / src / java / org / apache / cassandra / utils / btree / BTreeRemoval . java 
 @ @ - 0 , 0 + 1 , 338 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , 
 + * software distributed under the License is distributed on an 
 + * " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY 
 + * KIND , either express or implied . See the License for the 
 + * specific language governing permissions and limitations 
 + * under the License . 
 + * / 
 + package org . apache . cassandra . utils . btree ; 
 + 
 + import java . util . Arrays ; 
 + import java . util . Comparator ; 
 + 
 + public class BTreeRemoval 
 + { 
 + / * * 
 + * Remove | elem | from | btree | . If it ' s not present then return | btree | itself . 
 + * / 
 + public static < V > Object [ ] remove ( final Object [ ] btree , final Comparator < ? super V > comparator , final V elem ) 
 + { 
 + if ( BTree . isEmpty ( btree ) ) 
 + return btree ; 
 + int index = - 1 ; 
 + V elemToSwap = null ; 
 + int lb = 0 ; 
 + Object [ ] node = btree ; 
 + while ( true ) 
 + { 
 + int keyEnd = BTree . getKeyEnd ( node ) ; 
 + int i = Arrays . binarySearch ( ( V [ ] ) node , 0 , keyEnd , elem , comparator ) ; 
 + 
 + if ( i > = 0 ) 
 + { 
 + if ( BTree . isLeaf ( node ) ) 
 + index = lb + i ; 
 + else 
 + { 
 + final int indexInNode = BTree . getSizeMap ( node ) [ i ] ; 
 + index = lb + indexInNode - 1 ; 
 + elemToSwap = BTree . findByIndex ( node , indexInNode - 1 ) ; 
 + } 
 + break ; 
 + } 
 + if ( BTree . isLeaf ( node ) ) 
 + return btree ; 
 + 
 + i = - 1 - i ; 
 + if ( i > 0 ) 
 + lb + = BTree . getSizeMap ( node ) [ i - 1 ] + 1 ; 
 + 
 + node = ( Object [ ] ) node [ keyEnd + i ] ; 
 + } 
 + if ( BTree . size ( btree ) = = 1 ) 
 + return BTree . empty ( ) ; 
 + Object [ ] result = removeFromLeaf ( btree , index ) ; 
 + if ( elemToSwap ! = null ) 
 + BTree . replaceInSitu ( result , index , elemToSwap ) ; 
 + return result ; 
 + } 
 + 
 + / * * 
 + * Remove | elem | from | btree | . It has to be present and it has to reside in a leaf node . 
 + * / 
 + private static < V > Object [ ] removeFromLeaf ( Object [ ] node , int index ) 
 + { 
 + Object [ ] result = null ; 
 + Object [ ] prevNode = null ; 
 + int prevI = - 1 ; 
 + boolean needsCopy = true ; 
 + while ( ! BTree . isLeaf ( node ) ) 
 + { 
 + final int keyEnd = BTree . getBranchKeyEnd ( node ) ; 
 + int i = - 1 - Arrays . binarySearch ( BTree . getSizeMap ( node ) , index ) ; 
 + if ( i > 0 ) 
 + index - = ( 1 + BTree . getSizeMap ( node ) [ i - 1 ] ) ; 
 + Object [ ] nextNode = ( Object [ ] ) node [ keyEnd + i ] ; 
 + boolean nextNodeNeedsCopy = true ; 
 + if ( BTree . getKeyEnd ( nextNode ) > BTree . MINIMAL _ NODE _ SIZE ) 
 + node = copyIfNeeded ( node , needsCopy ) ; 
 + else if ( i > 0 & & BTree . getKeyEnd ( ( Object [ ] ) node [ keyEnd + i - 1 ] ) > BTree . MINIMAL _ NODE _ SIZE ) 
 + { 
 + node = copyIfNeeded ( node , needsCopy ) ; 
 + final Object [ ] leftNeighbour = ( Object [ ] ) node [ keyEnd + i - 1 ] ; 
 + index + + ; 
 + if ( ! BTree . isLeaf ( leftNeighbour ) ) 
 + index + = BTree . size ( ( Object [ ] ) leftNeighbour [ BTree . getChildEnd ( leftNeighbour ) - 1 ] ) ; 
 + nextNode = rotateLeft ( node , i ) ; 
 + } 
 + else if ( i < keyEnd & & BTree . getKeyEnd ( ( Object [ ] ) node [ keyEnd + i + 1 ] ) > BTree . MINIMAL _ NODE _ SIZE ) 
 + { 
 + node = copyIfNeeded ( node , needsCopy ) ; 
 + nextNode = rotateRight ( node , i ) ; 
 + } 
 + else 
 + { 
 + nextNodeNeedsCopy = false ; 
 + if ( i > 0 ) 
 + { 
 + final Object [ ] leftNeighbour = ( Object [ ] ) node [ keyEnd + i - 1 ] ; 
 + final V nodeKey = ( V ) node [ i - 1 ] ; 
 + node = keyEnd = = 1 ? null : copyWithKeyAndChildRemoved ( node , i - 1 , i - 1 , false ) ; 
 + nextNode = merge ( leftNeighbour , nextNode , nodeKey ) ; 
 + i = i - 1 ; 
 + index + = BTree . size ( leftNeighbour ) + 1 ; 
 + } 
 + else 
 + { 
 + final Object [ ] rightNeighbour = ( Object [ ] ) node [ keyEnd + i + 1 ] ; 
 + final V nodeKey = ( V ) node [ i ] ; 
 + node = keyEnd = = 1 ? null : copyWithKeyAndChildRemoved ( node , i , i , false ) ; 
 + nextNode = merge ( nextNode , rightNeighbour , nodeKey ) ; 
 + } 
 + } 
 + 
 + if ( node ! = null ) 
 + { 
 + final int [ ] sizeMap = BTree . getSizeMap ( node ) ; 
 + for ( int j = i ; j < sizeMap . length ; + + j ) 
 + sizeMap [ j ] - = 1 ; 
 + if ( prevNode ! = null ) 
 + prevNode [ prevI ] = node ; 
 + else 
 + result = node ; 
 + prevNode = node ; 
 + prevI = BTree . getChildStart ( node ) + i ; 
 + } 
 + 
 + node = nextNode ; 
 + needsCopy = nextNodeNeedsCopy ; 
 + } 
 + final int keyEnd = BTree . getLeafKeyEnd ( node ) ; 
 + final Object [ ] newLeaf = new Object [ ( keyEnd & 1 ) = = 1 ? keyEnd : keyEnd - 1 ] ; 
 + copyKeys ( node , newLeaf , 0 , index ) ; 
 + if ( prevNode ! = null ) 
 + prevNode [ prevI ] = newLeaf ; 
 + else 
 + result = newLeaf ; 
 + return result ; 
 + } 
 + 
 + private static < V > Object [ ] rotateRight ( final Object [ ] node , final int i ) { 
 + final int keyEnd = BTree . getBranchKeyEnd ( node ) ; 
 + final Object [ ] nextNode = ( Object [ ] ) node [ keyEnd + i ] ; 
 + final Object [ ] rightNeighbour = ( Object [ ] ) node [ keyEnd + i + 1 ] ; 
 + final boolean leaves = BTree . isLeaf ( nextNode ) ; 
 + final int nextKeyEnd = BTree . getKeyEnd ( nextNode ) ; 
 + final Object [ ] newChild = leaves ? null : ( Object [ ] ) rightNeighbour [ BTree . getChildStart ( rightNeighbour ) ] ; 
 + final Object [ ] newNextNode = 
 + copyWithKeyAndChildInserted ( nextNode , nextKeyEnd , node [ i ] , BTree . getChildCount ( nextNode ) , newChild ) ; 
 + node [ i ] = rightNeighbour [ 0 ] ; 
 + node [ keyEnd + i + 1 ] = copyWithKeyAndChildRemoved ( rightNeighbour , 0 , 0 , true ) ; 
 + BTree . getSizeMap ( node ) [ i ] + = 
 + leaves ? 1 : 1 + BTree . size ( ( Object [ ] ) newNextNode [ BTree . getChildEnd ( newNextNode ) - 1 ] ) ; 
 + return newNextNode ; 
 + } 
 + 
 + private static Object [ ] rotateLeft ( final Object [ ] node , final int i ) { 
 + final int keyEnd = BTree . getBranchKeyEnd ( node ) ; 
 + final Object [ ] nextNode = ( Object [ ] ) node [ keyEnd + i ] ; 
 + final Object [ ] leftNeighbour = ( Object [ ] ) node [ keyEnd + i - 1 ] ; 
 + final int leftNeighbourEndKey = BTree . getKeyEnd ( leftNeighbour ) ; 
 + final boolean leaves = BTree . isLeaf ( nextNode ) ; 
 + final Object [ ] newChild = leaves ? null : ( Object [ ] ) leftNeighbour [ BTree . getChildEnd ( leftNeighbour ) - 1 ] ; 
 + final Object [ ] newNextNode = copyWithKeyAndChildInserted ( nextNode , 0 , node [ i - 1 ] , 0 , newChild ) ; 
 + node [ i - 1 ] = leftNeighbour [ leftNeighbourEndKey - 1 ] ; 
 + node [ keyEnd + i - 1 ] = copyWithKeyAndChildRemoved ( leftNeighbour , leftNeighbourEndKey - 1 , leftNeighbourEndKey , true ) ; 
 + BTree . getSizeMap ( node ) [ i - 1 ] - = leaves ? 1 : 1 + BTree . getSizeMap ( newNextNode ) [ 0 ] ; 
 + return newNextNode ; 
 + } 
 + 
 + private static < V > Object [ ] copyWithKeyAndChildInserted ( final Object [ ] node , final int keyIndex , final V key , final int childIndex , final Object [ ] child ) 
 + { 
 + final boolean leaf = BTree . isLeaf ( node ) ; 
 + final int keyEnd = BTree . getKeyEnd ( node ) ; 
 + final Object [ ] copy ; 
 + if ( leaf ) 
 + copy = new Object [ keyEnd + ( ( keyEnd & 1 ) = = 1 ? 2 : 1 ) ] ; 
 + else 
 + copy = new Object [ node . length + 2 ] ; 
 + 
 + if ( keyIndex > 0 ) 
 + System . arraycopy ( node , 0 , copy , 0 , keyIndex ) ; 
 + copy [ keyIndex ] = key ; 
 + if ( keyIndex < keyEnd ) 
 + System . arraycopy ( node , keyIndex , copy , keyIndex + 1 , keyEnd - keyIndex ) ; 
 + 
 + if ( ! leaf ) 
 + { 
 + if ( childIndex > 0 ) 
 + System . arraycopy ( node , 
 + BTree . getChildStart ( node ) , 
 + copy , 
 + keyEnd + 1 , 
 + childIndex ) ; 
 + copy [ keyEnd + 1 + childIndex ] = child ; 
 + if ( childIndex < = keyEnd ) 
 + System . arraycopy ( node , 
 + BTree . getChildStart ( node ) + childIndex , 
 + copy , 
 + keyEnd + childIndex + 2 , 
 + keyEnd - childIndex + 1 ) ; 
 + final int [ ] sizeMap = BTree . getSizeMap ( node ) ; 
 + final int [ ] newSizeMap = new int [ sizeMap . length + 1 ] ; 
 + if ( childIndex > 0 ) 
 + System . arraycopy ( sizeMap , 0 , newSizeMap , 0 , childIndex ) ; 
 + final int childSize = BTree . size ( child ) ; 
 + newSizeMap [ childIndex ] = childSize + ( ( childIndex = = 0 ) ? 0 : newSizeMap [ childIndex - 1 ] + 1 ) ; 
 + for ( int i = childIndex + 1 ; i < newSizeMap . length ; + + i ) 
 + newSizeMap [ i ] = sizeMap [ i - 1 ] + childSize + 1 ; 
 + copy [ copy . length - 1 ] = newSizeMap ; 
 + } 
 + return copy ; 
 + } 
 + 
 + private static < V > Object [ ] copyWithKeyAndChildRemoved ( final Object [ ] node , final int keyIndex , final int childIndex , final boolean substractSize ) 
 + { 
 + final boolean leaf = BTree . isLeaf ( node ) ; 
 + final int keyEnd = BTree . getKeyEnd ( node ) ; 
 + final Object [ ] newNode ; 
 + if ( leaf ) 
 + newNode = new Object [ keyEnd - ( ( keyEnd & 1 ) = = 1 ? 0 : 1 ) ] ; 
 + else 
 + newNode = new Object [ node . length - 2 ] ; 
 + int offset = copyKeys ( node , newNode , 0 , keyIndex ) ; 
 + if ( ! leaf ) 
 + { 
 + offset = copyChildren ( node , newNode , offset , childIndex ) ; 
 + final int [ ] nodeSizeMap = BTree . getSizeMap ( node ) ; 
 + final int [ ] newNodeSizeMap = new int [ nodeSizeMap . length - 1 ] ; 
 + int pos = 0 ; 
 + final int sizeToRemove = BTree . size ( ( Object [ ] ) node [ BTree . getChildStart ( node ) + childIndex ] ) + 1 ; 
 + for ( int i = 0 ; i < nodeSizeMap . length ; + + i ) 
 + if ( i ! = childIndex ) 
 + newNodeSizeMap [ pos + + ] = nodeSizeMap [ i ] - 
 + ( ( substractSize & & i > childIndex ) ? sizeToRemove : 0 ) ; 
 + newNode [ offset ] = newNodeSizeMap ; 
 + } 
 + return newNode ; 
 + } 
 + 
 + private static < V > Object [ ] merge ( final Object [ ] left , final Object [ ] right , final V nodeKey ) { 
 + assert BTree . getKeyEnd ( left ) = = BTree . MINIMAL _ NODE _ SIZE ; 
 + assert BTree . getKeyEnd ( right ) = = BTree . MINIMAL _ NODE _ SIZE ; 
 + final boolean leaves = BTree . isLeaf ( left ) ; 
 + final Object [ ] result ; 
 + if ( leaves ) 
 + result = new Object [ BTree . MINIMAL _ NODE _ SIZE * 2 + 1 ] ; 
 + else 
 + result = new Object [ left . length + right . length ] ; 
 + int offset = 0 ; 
 + offset = copyKeys ( left , result , offset ) ; 
 + result [ offset + + ] = nodeKey ; 
 + offset = copyKeys ( right , result , offset ) ; 
 + if ( ! leaves ) 
 + { 
 + offset = copyChildren ( left , result , offset ) ; 
 + offset = copyChildren ( right , result , offset ) ; 
 + final int [ ] leftSizeMap = BTree . getSizeMap ( left ) ; 
 + final int [ ] rightSizeMap = BTree . getSizeMap ( right ) ; 
 + final int [ ] newSizeMap = new int [ leftSizeMap . length + rightSizeMap . length ] ; 
 + offset = 0 ; 
 + offset = copySizeMap ( leftSizeMap , newSizeMap , offset , 0 ) ; 
 + offset = copySizeMap ( rightSizeMap , newSizeMap , offset , leftSizeMap [ leftSizeMap . length - 1 ] + 1 ) ; 
 + result [ result . length - 1 ] = newSizeMap ; 
 + } 
 + return result ; 
 + } 
 + 
 + private static int copyKeys ( final Object [ ] from , final Object [ ] to , final int offset ) 
 + { 
 + final int keysCount = BTree . getKeyEnd ( from ) ; 
 + System . arraycopy ( from , 0 , to , offset , keysCount ) ; 
 + return offset + keysCount ; 
 + } 
 + 
 + private static int copyKeys ( final Object [ ] from , final Object [ ] to , final int offset , final int skipIndex ) 
 + { 
 + final int keysCount = BTree . getKeyEnd ( from ) ; 
 + if ( skipIndex > 0 ) 
 + System . arraycopy ( from , 0 , to , offset , skipIndex ) ; 
 + if ( skipIndex + 1 < keysCount ) 
 + System . arraycopy ( from , skipIndex + 1 , to , offset + skipIndex , keysCount - skipIndex - 1 ) ; 
 + return offset + keysCount - 1 ; 
 + } 
 + 
 + private static int copyChildren ( final Object [ ] from , final Object [ ] to , final int offset ) 
 + { 
 + assert ! BTree . isLeaf ( from ) ; 
 + final int start = BTree . getChildStart ( from ) ; 
 + final int childCount = BTree . getChildCount ( from ) ; 
 + System . arraycopy ( from , start , to , offset , childCount ) ; 
 + return offset + childCount ; 
 + } 
 + 
 + private static int copyChildren ( final Object [ ] from , final Object [ ] to , final int offset , final int skipIndex ) 
 + { 
 + assert ! BTree . isLeaf ( from ) ; 
 + final int start = BTree . getChildStart ( from ) ; 
 + final int childCount = BTree . getChildCount ( from ) ; 
 + if ( skipIndex > 0 ) 
 + System . arraycopy ( from , start , to , offset , skipIndex ) ; 
 + if ( skipIndex + 1 < = childCount ) 
 + System . arraycopy ( from , start + skipIndex + 1 , to , offset + skipIndex , childCount - skipIndex - 1 ) ; 
 + return offset + childCount - 1 ; 
 + } 
 + 
 + private static int copySizeMap ( final int [ ] from , final int [ ] to , final int offset , final int extra ) 
 + { 
 + for ( int i = 0 ; i < from . length ; + + i ) 
 + to [ offset + i ] = from [ i ] + extra ; 
 + return offset + from . length ; 
 + } 
 + 
 + private static Object [ ] copyIfNeeded ( final Object [ ] node , boolean needCopy ) 
 + { 
 + if ( ! needCopy ) return node ; 
 + final Object [ ] copy = new Object [ node . length ] ; 
 + System . arraycopy ( node , 0 , copy , 0 , node . length ) ; 
 + if ( ! BTree . isLeaf ( node ) ) 
 + { 
 + final int [ ] sizeMap = BTree . getSizeMap ( node ) ; 
 + final int [ ] copySizeMap = new int [ sizeMap . length ] ; 
 + System . arraycopy ( sizeMap , 0 , copySizeMap , 0 , sizeMap . length ) ; 
 + copy [ copy . length - 1 ] = copySizeMap ; 
 + } 
 + return copy ; 
 + } 
 + } 
 diff - - git a / test / unit / org / apache / cassandra / utils / btree / BTreeRemovalTest . java b / test / unit / org / apache / cassandra / utils / btree / BTreeRemovalTest . java 
 new file mode 100644 
 index 0000000 . . a9cf383 
 - - - / dev / null 
 + + + b / test / unit / org / apache / cassandra / utils / btree / BTreeRemovalTest . java 
 @ @ - 0 , 0 + 1 , 385 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , software 
 + * distributed under the License is distributed on an " AS IS " BASIS , 
 + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . 
 + * See the License for the specific language governing permissions and 
 + * limitations under the License . 
 + * / 
 + package org . apache . cassandra . utils . btree ; 
 + 
 + import static org . apache . cassandra . utils . btree . BTreeRemoval . remove ; 
 + import static org . junit . Assert . assertArrayEquals ; 
 + import static org . junit . Assert . assertEquals ; 
 + import static org . junit . Assert . assertNotNull ; 
 + import static org . junit . Assert . assertNull ; 
 + import static org . junit . Assert . assertTrue ; 
 + 
 + import java . util . Comparator ; 
 + import java . util . Random ; 
 + import java . util . SortedSet ; 
 + import java . util . TreeSet ; 
 + 
 + import org . junit . Test ; 
 + 
 + import com . google . common . collect . Iterables ; 
 + 
 + public class BTreeRemovalTest 
 + { 
 + static 
 + { 
 + System . setProperty ( " cassandra . btree . fanfactor " , " 8 " ) ; 
 + } 
 + 
 + private static final Comparator < Integer > CMP = new Comparator < Integer > ( ) 
 + { 
 + public int compare ( Integer o1 , Integer o2 ) 
 + { 
 + return Integer . compare ( o1 , o2 ) ; 
 + } 
 + } ; 
 + 
 + private static Object [ ] copy ( final Object [ ] btree ) 
 + { 
 + final Object [ ] result = new Object [ btree . length ] ; 
 + System . arraycopy ( btree , 0 , result , 0 , btree . length ) ; 
 + if ( ! BTree . isLeaf ( btree ) ) 
 + { 
 + for ( int i = BTree . getChildStart ( btree ) ; i < BTree . getChildEnd ( btree ) ; + + i ) 
 + result [ i ] = copy ( ( Object [ ] ) btree [ i ] ) ; 
 + final int [ ] sizeMap = BTree . getSizeMap ( btree ) ; 
 + final int [ ] resultSizeMap = new int [ sizeMap . length ] ; 
 + System . arraycopy ( sizeMap , 0 , resultSizeMap , 0 , sizeMap . length ) ; 
 + result [ result . length - 1 ] = resultSizeMap ; 
 + } 
 + return result ; 
 + } 
 + 
 + private static Object [ ] assertRemove ( final Object [ ] btree , final int key ) 
 + { 
 + final Object [ ] btreeBeforeRemoval = copy ( btree ) ; 
 + final Object [ ] result = remove ( btree , CMP , key ) ; 
 + assertBTree ( btreeBeforeRemoval , btree ) ; 
 + assertTrue ( BTree . isWellFormed ( result , CMP ) ) ; 
 + assertEquals ( BTree . size ( btree ) - 1 , BTree . size ( result ) ) ; 
 + assertNull ( BTree . find ( result , CMP , key ) ) ; 
 + 
 + for ( Integer k : BTree . < Integer > iterable ( btree ) ) 
 + if ( k ! = key ) 
 + assertNotNull ( BTree . find ( result , CMP , k ) ) ; 
 + 
 + return result ; 
 + } 
 + 
 + private static void assertBTree ( final Object [ ] expected , final Object [ ] result ) 
 + { 
 + assertEquals ( BTree . isEmpty ( expected ) , BTree . isEmpty ( result ) ) ; 
 + assertEquals ( BTree . isLeaf ( expected ) , BTree . isLeaf ( result ) ) ; 
 + assertEquals ( expected . length , result . length ) ; 
 + if ( BTree . isLeaf ( expected ) ) 
 + { 
 + assertArrayEquals ( expected , result ) ; 
 + } 
 + else 
 + { 
 + for ( int i = 0 ; i < BTree . getBranchKeyEnd ( expected ) ; + + i ) 
 + assertEquals ( expected [ i ] , result [ i ] ) ; 
 + for ( int i = BTree . getChildStart ( expected ) ; i < BTree . getChildEnd ( expected ) ; + + i ) 
 + assertBTree ( ( Object [ ] ) expected [ i ] , ( Object [ ] ) result [ i ] ) ; 
 + assertArrayEquals ( BTree . getSizeMap ( expected ) , BTree . getSizeMap ( result ) ) ; 
 + } 
 + } 
 + 
 + private static Object [ ] generateLeaf ( int from , int size ) 
 + { 
 + final Object [ ] result = new Object [ ( size & 1 ) = = 1 ? size : size + 1 ] ; 
 + for ( int i = 0 ; i < size ; + + i ) 
 + result [ i ] = from + i ; 
 + return result ; 
 + } 
 + 
 + private static Object [ ] generateBranch ( int [ ] keys , Object [ ] [ ] children ) 
 + { 
 + assert keys . length > 0 ; 
 + assert children . length > 1 ; 
 + assert children . length = = keys . length + 1 ; 
 + final Object [ ] result = new Object [ keys . length + children . length + 1 ] ; 
 + for ( int i = 0 ; i < keys . length ; + + i ) 
 + result [ i ] = keys [ i ] ; 
 + for ( int i = 0 ; i < children . length ; + + i ) 
 + result [ keys . length + i ] = children [ i ] ; 
 + final int [ ] sizeMap = new int [ children . length ] ; 
 + sizeMap [ 0 ] = BTree . size ( children [ 0 ] ) ; 
 + for ( int i = 1 ; i < children . length ; + + i ) 
 + sizeMap [ i ] = sizeMap [ i - 1 ] + BTree . size ( children [ i ] ) + 1 ; 
 + result [ result . length - 1 ] = sizeMap ; 
 + return result ; 
 + } 
 + 
 + private static Object [ ] generateSampleTwoLevelsTree ( final int [ ] leafSizes ) 
 + { 
 + assert leafSizes . length > 1 ; 
 + final Object [ ] [ ] leaves = new Object [ leafSizes . length ] [ ] ; 
 + for ( int i = 0 ; i < leaves . length ; + + i ) 
 + leaves [ i ] = generateLeaf ( 10 * i + 1 , leafSizes [ i ] ) ; 
 + final int [ ] keys = new int [ leafSizes . length - 1 ] ; 
 + for ( int i = 0 ; i < keys . length ; + + i ) 
 + keys [ i ] = 10 * ( i + 1 ) ; 
 + final Object [ ] btree = generateBranch ( keys , leaves ) ; 
 + assertTrue ( BTree . isWellFormed ( btree , CMP ) ) ; 
 + return btree ; 
 + } 
 + 
 + private static Object [ ] generateSampleThreeLevelsTree ( final int [ ] middleNodeSizes ) 
 + { 
 + assert middleNodeSizes . length > 1 ; 
 + final Object [ ] [ ] middleNodes = new Object [ middleNodeSizes . length ] [ ] ; 
 + for ( int i = 0 ; i < middleNodes . length ; + + i ) 
 + { 
 + final Object [ ] [ ] leaves = new Object [ middleNodeSizes [ i ] ] [ ] ; 
 + for ( int j = 0 ; j < middleNodeSizes [ i ] ; + + j ) 
 + leaves [ j ] = generateLeaf ( 100 * i + 10 * j + 1 , 4 ) ; 
 + final int [ ] keys = new int [ middleNodeSizes [ i ] - 1 ] ; 
 + for ( int j = 0 ; j < keys . length ; + + j ) 
 + keys [ j ] = 100 * i + 10 * ( j + 1 ) ; 
 + middleNodes [ i ] = generateBranch ( keys , leaves ) ; 
 + } 
 + final int [ ] keys = new int [ middleNodeSizes . length - 1 ] ; 
 + for ( int i = 0 ; i < keys . length ; + + i ) 
 + keys [ i ] = 100 * ( i + 1 ) ; 
 + final Object [ ] btree = generateBranch ( keys , middleNodes ) ; 
 + assertTrue ( BTree . isWellFormed ( btree , CMP ) ) ; 
 + return btree ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromEmpty ( ) 
 + { 
 + assertBTree ( BTree . empty ( ) , remove ( BTree . empty ( ) , CMP , 1 ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveNonexistingElement ( ) 
 + { 
 + final Object [ ] btree = new Object [ ] { 1 , 2 , 3 , 4 , null } ; 
 + assertBTree ( btree , remove ( btree , CMP , 5 ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveLastElement ( ) 
 + { 
 + final Object [ ] btree = new Object [ ] { 1 } ; 
 + assertBTree ( BTree . empty ( ) , remove ( btree , CMP , 1 ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromRootWhichIsALeaf ( ) 
 + { 
 + for ( int size = 1 ; size < 9 ; + + size ) 
 + { 
 + final Object [ ] btree = new Object [ ( size & 1 ) = = 1 ? size : size + 1 ] ; 
 + for ( int i = 0 ; i < size ; + + i ) 
 + btree [ i ] = i + 1 ; 
 + for ( int i = 0 ; i < size ; + + i ) 
 + { 
 + final Object [ ] result = remove ( btree , CMP , i + 1 ) ; 
 + assertTrue ( " size " + size , BTree . isWellFormed ( result , CMP ) ) ; 
 + for ( int j = 0 ; j < i ; + + j ) 
 + assertEquals ( " size " + size + " elem " + j , btree [ j ] , result [ j ] ) ; 
 + for ( int j = i ; j < size - 1 ; + + j ) 
 + assertEquals ( " size " + size + " elem " + j , btree [ j + 1 ] , result [ j ] ) ; 
 + for ( int j = size - 1 ; j < result . length ; + + j ) 
 + assertNull ( " size " + size + " elem " + j , result [ j ] ) ; 
 + } 
 + 
 + { 
 + final Object [ ] result = remove ( btree , CMP , 0 ) ; 
 + assertTrue ( " size " + size , BTree . isWellFormed ( result , CMP ) ) ; 
 + assertBTree ( btree , result ) ; 
 + } 
 + 
 + { 
 + final Object [ ] result = remove ( btree , CMP , size + 1 ) ; 
 + assertTrue ( " size " + size , BTree . isWellFormed ( result , CMP ) ) ; 
 + assertBTree ( btree , result ) ; 
 + } 
 + } 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromNonMinimalLeaf ( ) 
 + { 
 + for ( int size = 5 ; size < 9 ; + + size ) 
 + { 
 + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { size , 4 , 4 , 4 , 4 } ) ; 
 + 
 + for ( int i = 1 ; i < size + 1 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafRotateLeft ( ) 
 + { 
 + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 5 , 5 , 5 , 5 } ) ; 
 + 
 + for ( int i = 11 ; i < 15 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafRotateRight1 ( ) 
 + { 
 + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 5 , 5 , 5 , 5 } ) ; 
 + 
 + for ( int i = 1 ; i < 5 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafRotateRight2 ( ) 
 + { 
 + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 , 5 , 5 , 5 } ) ; 
 + 
 + for ( int i = 11 ; i < 15 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafMergeWithLeft1 ( ) 
 + { 
 + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 , 4 , 4 , 4 } ) ; 
 + 
 + for ( int i = 11 ; i < 15 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafMergeWithLeft2 ( ) 
 + { 
 + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 , 4 , 4 , 4 } ) ; 
 + 
 + for ( int i = 41 ; i < 45 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafMergeWithRight ( ) 
 + { 
 + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 , 4 , 4 , 4 } ) ; 
 + 
 + for ( int i = 1 ; i < 5 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafWhenSingleKeyRootMergeWithLeft ( ) 
 + { 
 + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 } ) ; 
 + 
 + for ( int i = 1 ; i < 5 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafWhenSingleKeyRootMergeWithRight ( ) 
 + { 
 + final Object [ ] btree = generateSampleTwoLevelsTree ( new int [ ] { 4 , 4 } ) ; 
 + 
 + for ( int i = 11 ; i < 15 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafWithBranchLeftRotation ( ) 
 + { 
 + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 6 , 5 , 5 , 5 , 5 } ) ; 
 + for ( int i = 101 ; i < 105 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafWithBranchRightRotation1 ( ) 
 + { 
 + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 6 , 5 , 5 , 5 } ) ; 
 + for ( int i = 1 ; i < 5 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafWithBranchRightRotation2 ( ) 
 + { 
 + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 6 , 5 , 5 } ) ; 
 + for ( int i = 101 ; i < 105 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafWithBranchMergeWithLeft1 ( ) 
 + { 
 + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 5 , 5 , 5 } ) ; 
 + for ( int i = 101 ; i < 105 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafWithBranchMergeWithLeft2 ( ) 
 + { 
 + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 5 , 5 , 5 } ) ; 
 + for ( int i = 401 ; i < 405 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMinimalLeafWithBranchMergeWithRight ( ) 
 + { 
 + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 5 , 5 , 5 } ) ; 
 + for ( int i = 1 ; i < 5 ; + + i ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromMiddleBranch ( ) 
 + { 
 + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 5 , 5 , 5 } ) ; 
 + for ( int i = 10 ; i < 50 ; i + = 10 ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void testRemoveFromRootBranch ( ) 
 + { 
 + final Object [ ] btree = generateSampleThreeLevelsTree ( new int [ ] { 5 , 5 , 5 , 5 , 5 } ) ; 
 + for ( int i = 100 ; i < 500 ; i + = 100 ) 
 + assertRemove ( btree , i ) ; 
 + } 
 + 
 + @ Test 
 + public void randomizedTest ( ) 
 + { 
 + Random rand = new Random ( 2 ) ; 
 + SortedSet < Integer > data = new TreeSet < > ( ) ; 
 + for ( int i = 0 ; i < 1000 ; + + i ) 
 + data . add ( rand . nextInt ( ) ) ; 
 + Object [ ] btree = BTree . build ( data , UpdateFunction . < Integer > noOp ( ) ) ; 
 + 
 + assertTrue ( BTree . isWellFormed ( btree , CMP ) ) ; 
 + assertTrue ( Iterables . elementsEqual ( data , BTree . iterable ( btree ) ) ) ; 
 + while ( btree ! = BTree . empty ( ) ) 
 + { 
 + int idx = rand . nextInt ( BTree . size ( btree ) ) ; 
 + Integer val = BTree . findByIndex ( btree , idx ) ; 
 + assertTrue ( data . remove ( val ) ) ; 
 + btree = assertRemove ( btree , val ) ; 
 + } 
 + } 
 + }

NEAREST DIFF:
diff - - git a / src / org / apache / cassandra / utils / BloomCalculations . java b / src / org / apache / cassandra / utils / BloomCalculations . java 
 index 5b21d7f . . 0962f3e 100644 
 - - - a / src / org / apache / cassandra / utils / BloomCalculations . java 
 + + + b / src / org / apache / cassandra / utils / BloomCalculations . java 
 @ @ - 30 , 106 + 30 , 103 @ @ package org . apache . cassandra . utils ; 
 * / 
 public class BloomCalculations { 
 
 - private static final int maxBits = 15 ; 
 - private static final int minBits = 2 ; 
 + private static final int maxBuckets = 15 ; 
 + private static final int minBuckets = 2 ; 
 private static final int minK = 1 ; 
 private static final int maxK = 8 ; 
 - private static final int [ ] optKPerBits = 
 - new int [ ] { 1 , / / dummy K for 0 bits per element 
 - 1 , / / dummy K for 1 bits per element 
 + private static final int [ ] optKPerBuckets = 
 + new int [ ] { 1 , / / dummy K for 0 buckets per element 
 + 1 , / / dummy K for 1 buckets per element 
 1 , 2 , 3 , 3 , 4 , 5 , 5 , 6 , 7 , 8 , 8 , 8 , 8 , 8 } ; 
 
 / * * 
 - * In the following table , the row ' i ' shows false positive rates if i bits 
 + * In the following table , the row ' i ' shows false positive rates if i buckets 
 * per element are used . Column ' j ' shows false positive rates if j hash 
 * functions are used . The first row is ' i = 0 ' , the first column is ' j = 0 ' . 
 - * Each cell ( i , j ) the false positive rate determined by using i bits per 
 + * Each cell ( i , j ) the false positive rate determined by using i buckets per 
 * element and j hash functions . 
 * / 
 - private static final double [ ] [ ] probs = new double [ ] [ ] { 
 - { 1 . 0 } , / / dummy row representing 0 bits per element 
 - { 1 . 0 , 1 . 0 } , / / dummy row representing 1 bits per element 
 + static final double [ ] [ ] probs = new double [ ] [ ] { 
 + { 1 . 0 } , / / dummy row representing 0 buckets per element 
 + { 1 . 0 , 1 . 0 } , / / dummy row representing 1 buckets per element 
 { 1 . 0 , 0 . 393 , 0 . 400 } , 
 { 1 . 0 , 0 . 283 , 0 . 237 , 0 . 253 } , 
 { 1 . 0 , 0 . 221 , 0 . 155 , 0 . 147 , 0 . 160 } , 
 - { 1 . 0 , 0 . 181 , 0 . 109 , 0 . 092 , 0 . 092 , 0 . 101 } , 
 + { 1 . 0 , 0 . 181 , 0 . 109 , 0 . 092 , 0 . 092 , 0 . 101 } , / / 5 
 { 1 . 0 , 0 . 154 , 0 . 0804 , 0 . 0609 , 0 . 0561 , 0 . 0578 , 0 . 0638 } , 
 { 1 . 0 , 0 . 133 , 0 . 0618 , 0 . 0423 , 0 . 0359 , 0 . 0347 , 0 . 0364 } , 
 { 1 . 0 , 0 . 118 , 0 . 0489 , 0 . 0306 , 0 . 024 , 0 . 0217 , 0 . 0216 , 0 . 0229 } , 
 - { 1 . 0 , 0 . 105 , 0 . 0397 , 0 . 0228 , 0 . 0166 , 0 . 0141 , 0 . 0133 , 0 . 0135 , 0 . 0145 } , 
 + { 1 . 0 , 0 . 105 , 0 . 0397 , 0 . 0228 , 0 . 0166 , 0 . 0141 , 0 . 0133 , 0 . 0135 , 0 . 0145 } , / / 9 
 { 1 . 0 , 0 . 0952 , 0 . 0329 , 0 . 0174 , 0 . 0118 , 0 . 00943 , 0 . 00844 , 0 . 00819 , 0 . 00846 } , 
 { 1 . 0 , 0 . 0869 , 0 . 0276 , 0 . 0136 , 0 . 00864 , 0 . 0065 , 0 . 00552 , 0 . 00513 , 0 . 00509 } , 
 { 1 . 0 , 0 . 08 , 0 . 0236 , 0 . 0108 , 0 . 00646 , 0 . 00459 , 0 . 00371 , 0 . 00329 , 0 . 00314 } , 
 { 1 . 0 , 0 . 074 , 0 . 0203 , 0 . 00875 , 0 . 00492 , 0 . 00332 , 0 . 00255 , 0 . 00217 , 0 . 00199 } , 
 { 1 . 0 , 0 . 0689 , 0 . 0177 , 0 . 00718 , 0 . 00381 , 0 . 00244 , 0 . 00179 , 0 . 00146 , 0 . 00129 } , 
 - { 1 . 0 , 0 . 0645 , 0 . 0156 , 0 . 00596 , 0 . 003 , 0 . 00183 , 0 . 00128 , 0 . 001 , 0 . 000852 } 
 + { 1 . 0 , 0 . 0645 , 0 . 0156 , 0 . 00596 , 0 . 003 , 0 . 00183 , 0 . 00128 , 0 . 001 , 0 . 000852 } / / 15 
 } ; / / the first column is a dummy column representing K = 0 . 
 
 - public static double getFailureRate ( int bitsPerElement ) { 
 - int k = computeBestK ( bitsPerElement ) ; 
 - if ( bitsPerElement > = probs . length ) bitsPerElement = probs . length - 1 ; 
 - return probs [ bitsPerElement ] [ k ] ; 
 - } 
 - 
 / * * 
 - * Given the number of bits that can be used per element , return the optimal 
 + * Given the number of buckets that can be used per element , return the optimal 
 * number of hash functions in order to minimize the false positive rate . 
 * 
 - * @ param bitsPerElement 
 + * @ param bucketsPerElement 
 * @ return The number of hash functions that minimize the false positive rate . 
 * / 
 - public static int computeBestK ( int bitsPerElement ) { 
 - if ( bitsPerElement < 0 ) 
 - return optKPerBits [ 0 ] ; 
 - if ( bitsPerElement > = optKPerBits . length ) 
 - return optKPerBits [ optKPerBits . length - 1 ] ; 
 - return optKPerBits [ bitsPerElement ] ; 
 + public static int computeBestK ( int bucketsPerElement ) { 
 + assert bucketsPerElement > = 0 ; 
 + if ( bucketsPerElement > = optKPerBuckets . length ) 
 + return optKPerBuckets [ optKPerBuckets . length - 1 ] ; 
 + return optKPerBuckets [ bucketsPerElement ] ; 
 } 
 
 / * * 
 * A wrapper class that holds two key parameters for a Bloom Filter : the 
 - * number of hash functions used , and the number of bits per element used . 
 + * number of hash functions used , and the number of buckets per element used . 
 * / 
 - public static class BloomSpecification { 
 - int K ; / / number of hash functions . 
 - int bitsPerElement ; 
 + public static final class BloomSpecification { 
 + final int K ; / / number of hash functions . 
 + final int bucketsPerElement ; 
 + 
 + public BloomSpecification ( int k , int bucketsPerElement ) { 
 + K = k ; 
 + this . bucketsPerElement = bucketsPerElement ; 
 + } 
 } 
 
 / * * 
 * Given a maximum tolerable false positive probability , compute a Bloom 
 * specification which will give less than the specified false positive rate , 
 - * but minimize the number of bits per element and the number of hash 
 + * but minimize the number of buckets per element and the number of hash 
 * functions used . Because bandwidth ( and therefore total bitvector size ) 
 * is considered more expensive than computing power , preference is given 
 - * to minimizing bits per element rather than number of hash funtions . 
 + * to minimizing buckets per element rather than number of hash funtions . 
 * 
 * @ param maxFalsePosProb The maximum tolerable false positive rate . 
 * @ return A Bloom Specification which would result in a false positive rate 
 * less than specified by the function call . 
 * / 
 - public static BloomSpecification computeBitsAndK ( double maxFalsePosProb ) { 
 - BloomSpecification spec = new BloomSpecification ( ) ; 
 - spec . bitsPerElement = 2 ; 
 - spec . K = optKPerBits [ spec . bitsPerElement ] ; 
 - 
 - / / Handle the trivial cases : 
 - if ( maxFalsePosProb > = probs [ minBits ] [ minK ] ) return spec ; 
 - if ( maxFalsePosProb < probs [ maxBits ] [ maxK ] ) { 
 - spec . bitsPerElement = maxBits ; 
 - spec . K = maxK ; 
 - return spec ; 
 + public static BloomSpecification computeBucketsAndK ( double maxFalsePosProb ) { 
 + / / Handle the trivial cases 
 + if ( maxFalsePosProb > = probs [ minBuckets ] [ minK ] ) { 
 + return new BloomSpecification ( 2 , optKPerBuckets [ 2 ] ) ; 
 + } 
 + if ( maxFalsePosProb < probs [ maxBuckets ] [ maxK ] ) { 
 + return new BloomSpecification ( maxK , maxBuckets ) ; 
 } 
 
 - / / First find the minimal required number of bits : 
 - while ( probs [ spec . bitsPerElement ] [ spec . K ] > maxFalsePosProb ) { 
 - spec . bitsPerElement + + ; 
 - spec . K = optKPerBits [ spec . bitsPerElement ] ; 
 + / / First find the minimal required number of buckets : 
 + int bucketsPerElement = 2 ; 
 + int K = optKPerBuckets [ 2 ] ; 
 + while ( probs [ bucketsPerElement ] [ K ] > maxFalsePosProb ) { 
 + bucketsPerElement + + ; 
 + K = optKPerBuckets [ bucketsPerElement ] ; 
 } 
 - / / Now that the number of bits is sufficient , see if we can relax K 
 + / / Now that the number of buckets is sufficient , see if we can relax K 
 / / without losing too much precision . 
 - while ( probs [ spec . bitsPerElement ] [ spec . K - 1 ] < = maxFalsePosProb ) { 
 - spec . K - - ; 
 + while ( probs [ bucketsPerElement ] [ K - 1 ] < = maxFalsePosProb ) { 
 + K - - ; 
 } 
 - return spec ; 
 + 
 + return new BloomSpecification ( K , bucketsPerElement ) ; 
 } 
 } 
 diff - - git a / src / org / apache / cassandra / utils / BloomFilter . java b / src / org / apache / cassandra / utils / BloomFilter . java 
 index 6d8e2a8 . . 01d09b8 100644 
 - - - a / src / org / apache / cassandra / utils / BloomFilter . java 
 + + + b / src / org / apache / cassandra / utils / BloomFilter . java 
 @ @ - 18 , 48 + 18 , 15 @ @ 
 
 package org . apache . cassandra . utils ; 
 
 - import java . math . * ; 
 - import java . nio . ByteBuffer ; 
 - import java . nio . LongBuffer ; 
 - import java . io . * ; 
 - import java . security . * ; 
 - import java . util . ArrayList ; 
 - import java . util . List ; 
 - import java . util . Random ; 
 - import java . util . zip . * ; 
 + import java . io . DataInputStream ; 
 + import java . io . DataOutputStream ; 
 + import java . io . IOException ; 
 
 - import javax . xml . bind . annotation . XmlElement ; 
 - 
 - import org . apache . cassandra . io . DataInputBuffer ; 
 - import org . apache . cassandra . io . DataOutputBuffer ; 
 import org . apache . cassandra . io . ICompactSerializer ; 
 - import org . apache . cassandra . io . SSTable ; 
 - 
 
 - / * * 
 - * Author : Avinash Lakshman ( alakshman @ facebook . com ) & Prashant Malik ( pmalik @ facebook . com ) 
 - * / 
 - 
 - public class BloomFilter implements Serializable 
 - { 
 - private static List < ISimpleHash > hashLibrary _ = new ArrayList < ISimpleHash > ( ) ; 
 - private static ICompactSerializer < BloomFilter > serializer _ ; 
 - 
 - static 
 - { 
 - serializer _ = new BloomFilterSerializer ( ) ; 
 - hashLibrary _ . add ( new RSHash ( ) ) ; 
 - hashLibrary _ . add ( new JSHash ( ) ) ; 
 - hashLibrary _ . add ( new PJWHash ( ) ) ; 
 - hashLibrary _ . add ( new ELFHash ( ) ) ; 
 - hashLibrary _ . add ( new BKDRHash ( ) ) ; 
 - hashLibrary _ . add ( new SDBMHash ( ) ) ; 
 - hashLibrary _ . add ( new DJBHash ( ) ) ; 
 - hashLibrary _ . add ( new DEKHash ( ) ) ; 
 - hashLibrary _ . add ( new BPHash ( ) ) ; 
 - hashLibrary _ . add ( new FNVHash ( ) ) ; 
 - hashLibrary _ . add ( new APHash ( ) ) ; 
 - } 
 + public class BloomFilter extends Filter 
 + { 
 + static ICompactSerializer < BloomFilter > serializer _ = new BloomFilterSerializer ( ) ; 
 
 public static ICompactSerializer < BloomFilter > serializer ( ) 
 { 
 @ @ - 67 , 52 + 34 , 37 @ @ public class BloomFilter implements Serializable 
 } 
 
 private BitSet filter _ ; 
 - private int count _ ; 
 - private int size _ ; 
 - private int hashes _ ; 
 - private Random random _ = new Random ( System . currentTimeMillis ( ) ) ; 
 
 - public BloomFilter ( int numElements , int bitsPerElement ) 
 + public BloomFilter ( int numElements , int bucketsPerElement ) 
 { 
 - / / TODO - - think about the trivial cases more . 
 - / / Note that it should indeed be possible to send a bloom filter that 
 - / / encodes the empty set . 
 - if ( numElements < 0 | | bitsPerElement < 1 ) 
 - throw new IllegalArgumentException ( " Number of elements and bits " 
 - + " must be non - negative . " ) ; 
 - / / Adding a small random number of bits so that even if the set 
 - / / of elements hasn ' t changed , we ' ll get different false positives . 
 - count _ = numElements ; 
 - size _ = numElements * bitsPerElement + 20 + random _ . nextInt ( 64 ) ; 
 - filter _ = new BitSet ( size _ ) ; 
 - / / hashes _ = BloomCalculations . computeBestK ( bitsPerElement ) ; 
 - hashes _ = 8 ; 
 + this ( BloomCalculations . computeBestK ( bucketsPerElement ) , new BitSet ( numElements * bucketsPerElement + 20 ) ) ; 
 + } 
 + 
 + public BloomFilter ( int numElements , double maxFalsePosProbability ) 
 + { 
 + BloomCalculations . BloomSpecification spec = BloomCalculations 
 + . computeBucketsAndK ( maxFalsePosProbability ) ; 
 + filter _ = new BitSet ( numElements * spec . bucketsPerElement + 20 ) ; 
 + hashCount = spec . K ; 
 } 
 
 / * 
 - * This version is only used by the deserializer . 
 + * This version is only used by the deserializer . 
 * / 
 - BloomFilter ( int count , int hashes , int size , BitSet filter ) 
 + BloomFilter ( int hashes , BitSet filter ) 
 { 
 - count _ = count ; 
 - hashes _ = hashes ; 
 - size _ = size ; 
 + hashCount = hashes ; 
 filter _ = filter ; 
 } 
 
 - int count ( ) 
 + public void clear ( ) 
 { 
 - return count _ ; 
 - } 
 - 
 - int size ( ) 
 - { 
 - return size _ ; 
 + filter _ . clear ( ) ; 
 } 
 
 - int hashes ( ) 
 + int buckets ( ) 
 { 
 - return hashes _ ; 
 + return filter _ . size ( ) ; 
 } 
 
 BitSet filter ( ) 
 @ @ - 122 , 19 + 74 , 14 @ @ public class BloomFilter implements Serializable 
 
 public boolean isPresent ( String key ) 
 { 
 - boolean bVal = true ; 
 - for ( int i = 0 ; i < hashes _ ; + + i ) 
 + for ( int bucketIndex : getHashBuckets ( key ) ) 
 { 
 - ISimpleHash hash = hashLibrary _ . get ( i ) ; 
 - int hashValue = hash . hash ( key ) ; 
 - int index = Math . abs ( hashValue % size _ ) ; 
 - if ( ! filter _ . get ( index ) ) 
 + if ( ! filter _ . get ( bucketIndex ) ) 
 { 
 - bVal = false ; 
 - break ; 
 + return false ; 
 } 
 } 
 - return bVal ; 
 + return true ; 
 } 
 
 / * 
 @ @ - 144 , 12 + 91 , 9 @ @ public class BloomFilter implements Serializable 
 * / 
 public void add ( String key ) 
 { 
 - for ( int i = 0 ; i < hashes _ ; + + i ) 
 + for ( int bucketIndex : getHashBuckets ( key ) ) 
 { 
 - ISimpleHash hash = hashLibrary _ . get ( i ) ; 
 - int hashValue = hash . hash ( key ) ; 
 - int index = Math . abs ( hashValue % size _ ) ; 
 - filter _ . set ( index ) ; 
 + filter _ . set ( bucketIndex ) ; 
 } 
 } 
 
 @ @ - 157 , 218 + 101 , 39 @ @ public class BloomFilter implements Serializable 
 { 
 return filter _ . toString ( ) ; 
 } 
 - } 
 - 
 - class BloomFilterSerializer implements ICompactSerializer < BloomFilter > 
 - { 
 - / * 
 - * The following methods are used for compact representation 
 - * of BloomFilter . This is essential , since we want to determine 
 - * the size of the serialized Bloom Filter blob before it is 
 - * populated armed with the knowledge of how many elements are 
 - * going to reside in it . 
 - * / 
 - 
 - public void serialize ( BloomFilter bf , DataOutputStream dos ) throws IOException 
 - { 
 - / * write out the count of the BloomFilter * / 
 - dos . writeInt ( bf . count ( ) ) ; 
 - / * write the number of hash functions used * / 
 - dos . writeInt ( bf . hashes ( ) ) ; 
 - / * write the size of the BloomFilter * / 
 - dos . writeInt ( bf . size ( ) ) ; 
 - BitSet . serializer ( ) . serialize ( bf . filter ( ) , dos ) ; 
 - } 
 
 - public BloomFilter deserialize ( DataInputStream dis ) throws IOException 
 + ICompactSerializer tserializer ( ) 
 { 
 - / * read the count of the BloomFilter * / 
 - int count = dis . readInt ( ) ; 
 - / * read the number of hash functions * / 
 - int hashes = dis . readInt ( ) ; 
 - / * read the size of the bloom filter * / 
 - int size = dis . readInt ( ) ; 
 - BitSet bs = BitSet . serializer ( ) . deserialize ( dis ) ; 
 - return new BloomFilter ( count , hashes , size , bs ) ; 
 - } 
 - } 
 - 
 - interface ISimpleHash 
 - { 
 - public int hash ( String str ) ; 
 - } 
 - 
 - class RSHash implements ISimpleHash 
 - { 
 - public int hash ( String str ) 
 - { 
 - int b = 378551 ; 
 - int a = 63689 ; 
 - int hash = 0 ; 
 - 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 - { 
 - hash = hash * a + str . charAt ( i ) ; 
 - a = a * b ; 
 - } 
 - return hash ; 
 - } 
 - } 
 - 
 - class JSHash implements ISimpleHash 
 - { 
 - public int hash ( String str ) 
 - { 
 - int hash = 1315423911 ; 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 - { 
 - hash ^ = ( ( hash < < 5 ) + str . charAt ( i ) + ( hash > > 2 ) ) ; 
 - } 
 - return hash ; 
 - } 
 - } 
 - 
 - class PJWHash implements ISimpleHash 
 - { 
 - public int hash ( String str ) 
 - { 
 - int bitsInUnsignedInt = ( 4 * 8 ) ; 
 - int threeQuarters = ( bitsInUnsignedInt * 3 ) / 4 ; 
 - int oneEighth = bitsInUnsignedInt / 8 ; 
 - int highBits = ( 0xFFFFFFFF ) < < ( bitsInUnsignedInt - oneEighth ) ; 
 - int hash = 0 ; 
 - int test = 0 ; 
 - 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 - { 
 - hash = ( hash < < oneEighth ) + str . charAt ( i ) ; 
 - 
 - if ( ( test = hash & highBits ) ! = 0 ) 
 - { 
 - hash = ( ( hash ^ ( test > > threeQuarters ) ) & ( ~ highBits ) ) ; 
 - } 
 - } 
 - return hash ; 
 + return serializer _ ; 
 } 
 - } 
 
 - class ELFHash implements ISimpleHash 
 - { 
 - public int hash ( String str ) 
 + int emptyBuckets ( ) 
 { 
 - int hash = 0 ; 
 - int x = 0 ; 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 + int n = 0 ; 
 + for ( int i = 0 ; i < buckets ( ) ; i + + ) 
 { 
 - hash = ( hash < < 4 ) + str . charAt ( i ) ; 
 - 
 - if ( ( x = hash & 0xF0000000 ) ! = 0 ) 
 + if ( ! filter _ . get ( i ) ) 
 { 
 - hash ^ = ( x > > 24 ) ; 
 + n + + ; 
 } 
 - hash & = ~ x ; 
 - } 
 - return hash ; 
 - } 
 - } 
 - 
 - class BKDRHash implements ISimpleHash 
 - { 
 - public int hash ( String str ) 
 - { 
 - int seed = 131 ; / / 31 131 1313 13131 131313 etc . . 
 - int hash = 0 ; 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 - { 
 - hash = ( hash * seed ) + str . charAt ( i ) ; 
 - } 
 - return hash ; 
 - } 
 - } 
 - 
 - class SDBMHash implements ISimpleHash 
 - { 
 - public int hash ( String str ) 
 - { 
 - int hash = 0 ; 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 - { 
 - hash = str . charAt ( i ) + ( hash < < 6 ) + ( hash < < 16 ) - hash ; 
 - } 
 - return hash ; 
 - } 
 - } 
 - 
 - class DJBHash implements ISimpleHash 
 - { 
 - public int hash ( String str ) 
 - { 
 - int hash = 5381 ; 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 - { 
 - hash = ( ( hash < < 5 ) + hash ) + str . charAt ( i ) ; 
 - } 
 - return hash ; 
 - } 
 - } 
 - 
 - class DEKHash implements ISimpleHash 
 - { 
 - public int hash ( String str ) 
 - { 
 - int hash = str . length ( ) ; 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 - { 
 - hash = ( ( hash < < 5 ) ^ ( hash > > 27 ) ) ^ str . charAt ( i ) ; 
 - } 
 - return hash ; 
 - } 
 - } 
 - 
 - class BPHash implements ISimpleHash 
 - { 
 - public int hash ( String str ) 
 - { 
 - int hash = 0 ; 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 - { 
 - hash = hash < < 7 ^ str . charAt ( i ) ; 
 } 
 - return hash ; 
 + return n ; 
 } 
 } 
 
 - class FNVHash implements ISimpleHash 
 + class BloomFilterSerializer implements ICompactSerializer < BloomFilter > 
 { 
 - public int hash ( String str ) 
 + public void serialize ( BloomFilter bf , DataOutputStream dos ) 
 + throws IOException 
 { 
 - int fnv _ prime = 0x811C9DC5 ; 
 - int hash = 0 ; 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 - { 
 - hash * = fnv _ prime ; 
 - hash ^ = str . charAt ( i ) ; 
 - } 
 - return hash ; 
 + dos . writeInt ( bf . getHashCount ( ) ) ; 
 + BitSet . serializer ( ) . serialize ( bf . filter ( ) , dos ) ; 
 } 
 - } 
 
 - class APHash implements ISimpleHash 
 - { 
 - public int hash ( String str ) 
 + public BloomFilter deserialize ( DataInputStream dis ) throws IOException 
 { 
 - int hash = 0xAAAAAAAA ; 
 - for ( int i = 0 ; i < str . length ( ) ; i + + ) 
 - { 
 - if ( ( i & 1 ) = = 0 ) 
 - { 
 - hash ^ = ( ( hash < < 7 ) ^ str . charAt ( i ) ^ ( hash > > 3 ) ) ; 
 - } 
 - else 
 - { 
 - hash ^ = ( ~ ( ( hash < < 11 ) ^ str . charAt ( i ) ^ ( hash > > 5 ) ) ) ; 
 - } 
 - } 
 - return hash ; 
 + int hashes = dis . readInt ( ) ; 
 + BitSet bs = BitSet . serializer ( ) . deserialize ( dis ) ; 
 + return new BloomFilter ( hashes , bs ) ; 
 } 
 } 
 diff - - git a / src / org / apache / cassandra / utils / Filter . java b / src / org / apache / cassandra / utils / Filter . java 
 new file mode 100644 
 index 0000000 . . 287cee5 
 - - - / dev / null 
 + + + b / src / org / apache / cassandra / utils / Filter . java 
 @ @ - 0 , 0 + 1 , 72 @ @ 
 + package org . apache . cassandra . utils ; 
 + 
 + import java . io . UnsupportedEncodingException ; 
 + import java . lang . reflect . Method ; 
 + 
 + import org . apache . cassandra . io . ICompactSerializer ; 
 + 
 + public abstract class Filter 
 + { 
 + int hashCount ; 
 + 
 + private static MurmurHash hasher = new MurmurHash ( ) ; 
 + 
 + int getHashCount ( ) 
 + { 
 + return hashCount ; 
 + } 
 + 
 + public int [ ] getHashBuckets ( String key ) 
 + { 
 + return Filter . getHashBuckets ( key , hashCount , buckets ( ) ) ; 
 + } 
 + 
 + abstract int buckets ( ) ; 
 + 
 + public abstract void add ( String key ) ; 
 + 
 + public abstract boolean isPresent ( String key ) ; 
 + 
 + / / for testing 
 + abstract int emptyBuckets ( ) ; 
 + 
 + ICompactSerializer < Filter > getSerializer ( ) 
 + { 
 + Method method = null ; 
 + try 
 + { 
 + method = getClass ( ) . getMethod ( " serializer " ) ; 
 + return ( ICompactSerializer < Filter > ) method . invoke ( null ) ; 
 + } 
 + catch ( Exception e ) 
 + { 
 + throw new RuntimeException ( e ) ; 
 + } 
 + } 
 + 
 + / / murmur is faster than a sha - based approach and provides as - good collision 
 + / / resistance . the combinatorial generation approach described in 
 + / / http : / / www . eecs . harvard . edu / ~ kirsch / pubs / bbbf / esa06 . pdf 
 + / / does prove to work in actual tests , and is obviously faster 
 + / / than performing further iterations of murmur . 
 + static int [ ] getHashBuckets ( String key , int hashCount , int max ) 
 + { 
 + byte [ ] b ; 
 + try 
 + { 
 + b = key . getBytes ( " UTF - 16 " ) ; 
 + } 
 + catch ( UnsupportedEncodingException e ) 
 + { 
 + throw new RuntimeException ( e ) ; 
 + } 
 + int [ ] result = new int [ hashCount ] ; 
 + int hash1 = hasher . hash ( b , b . length , 0 ) ; 
 + int hash2 = hasher . hash ( b , b . length , hash1 ) ; 
 + for ( int i = 0 ; i < hashCount ; i + + ) 
 + { 
 + result [ i ] = Math . abs ( ( hash1 + i * hash2 ) % max ) ; 
 + } 
 + return result ; 
 + } 
 + } 
 \ No newline at end of file 
 diff - - git a / test / org / apache / cassandra / utils / BloomFilterTest . java b / test / org / apache / cassandra / utils / BloomFilterTest . java 
 new file mode 100644 
 index 0000000 . . f518afd 
 - - - / dev / null 
 + + + b / test / org / apache / cassandra / utils / BloomFilterTest . java 
 @ @ - 0 , 0 + 1 , 98 @ @ 
 + package org . apache . cassandra . utils ; 
 + 
 + import java . io . IOException ; 
 + 
 + import org . testng . annotations . BeforeMethod ; 
 + import org . testng . annotations . Test ; 
 + 
 + public class BloomFilterTest 
 + { 
 + public BloomFilter bf ; 
 + public BloomCalculations . BloomSpecification spec = BloomCalculations . computeBucketsAndK ( 0 . 0001 ) ; 
 + static final int ELEMENTS = 10000 ; 
 + 
 + public BloomFilterTest ( ) 
 + { 
 + bf = new BloomFilter ( ELEMENTS , spec . bucketsPerElement ) ; 
 + assert bf ! = null ; 
 + } 
 + 
 + @ BeforeMethod 
 + public void clear ( ) 
 + { 
 + bf . clear ( ) ; 
 + } 
 + 
 + @ Test 
 + public void testOne ( ) 
 + { 
 + bf . add ( " a " ) ; 
 + assert bf . isPresent ( " a " ) ; 
 + assert ! bf . isPresent ( " b " ) ; 
 + } 
 + 
 + @ Test 
 + public void testFalsePositivesInt ( ) 
 + { 
 + FilterTest . testFalsePositives ( bf , FilterTest . intKeys ( ) , FilterTest . randomKeys2 ( ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testFalsePositivesRandom ( ) 
 + { 
 + FilterTest . testFalsePositives ( bf , FilterTest . randomKeys ( ) , FilterTest . randomKeys2 ( ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testWords ( ) 
 + { 
 + if ( KeyGenerator . WordGenerator . WORDS = = 0 ) 
 + { 
 + return ; 
 + } 
 + BloomFilter bf2 = new BloomFilter ( KeyGenerator . WordGenerator . WORDS / 2 , FilterTest . spec . bucketsPerElement ) ; 
 + int skipEven = KeyGenerator . WordGenerator . WORDS % 2 = = 0 ? 0 : 2 ; 
 + FilterTest . testFalsePositives ( bf2 , 
 + new KeyGenerator . WordGenerator ( skipEven , 2 ) , 
 + new KeyGenerator . WordGenerator ( 1 , 2 ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testSerialize ( ) throws IOException 
 + { 
 + FilterTest . testSerialize ( bf ) ; 
 + } 
 + 
 + / * TODO move these into a nightly suite ( they take 5 - 10 minutes each ) 
 + @ Test 
 + / / run with - mx1G 
 + public void testBigInt ( ) { 
 + int size = 100 * 1000 * 1000 ; 
 + bf = new BloomFilter ( size , FilterTest . spec . bucketsPerElement ) ; 
 + FilterTest . testFalsePositives ( bf , 
 + new KeyGenerator . IntGenerator ( size ) , 
 + new KeyGenerator . IntGenerator ( size , size * 2 ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testBigRandom ( ) { 
 + int size = 100 * 1000 * 1000 ; 
 + bf = new BloomFilter ( size , FilterTest . spec . bucketsPerElement ) ; 
 + FilterTest . testFalsePositives ( bf , 
 + new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , size ) , 
 + new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , size ) ) ; 
 + } 
 + 
 + @ Test 
 + public void timeit ( ) { 
 + int size = 300 * FilterTest . ELEMENTS ; 
 + bf = new BloomFilter ( size , FilterTest . spec . bucketsPerElement ) ; 
 + for ( int i = 0 ; i < 10 ; i + + ) { 
 + FilterTest . testFalsePositives ( bf , 
 + new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , size ) , 
 + new KeyGenerator . RandomStringGenerator ( new Random ( ) . nextInt ( ) , size ) ) ; 
 + bf . clear ( ) ; 
 + } 
 + } 
 + * / 
 + } 
 diff - - git a / test / org / apache / cassandra / utils / FilterTest . java b / test / org / apache / cassandra / utils / FilterTest . java 
 new file mode 100644 
 index 0000000 . . 6c8e535 
 - - - / dev / null 
 + + + b / test / org / apache / cassandra / utils / FilterTest . java 
 @ @ - 0 , 0 + 1 , 95 @ @ 
 + package org . apache . cassandra . utils ; 
 + 
 + import java . util . Iterator ; 
 + import java . util . Set ; 
 + import java . util . HashSet ; 
 + import java . io . IOException ; 
 + 
 + import org . testng . annotations . Test ; 
 + import org . apache . cassandra . io . DataInputBuffer ; 
 + import org . apache . cassandra . io . DataOutputBuffer ; 
 + 
 + public class FilterTest 
 + { 
 + public void testManyHashes ( Iterator < String > keys ) 
 + { 
 + int MAX _ HASH _ COUNT = 128 ; 
 + Set < Integer > hashes = new HashSet < Integer > ( ) ; 
 + int collisions = 0 ; 
 + while ( keys . hasNext ( ) ) 
 + { 
 + hashes . clear ( ) ; 
 + for ( int hashIndex : Filter . getHashBuckets ( keys . next ( ) , MAX _ HASH _ COUNT , 1024 * 1024 ) ) 
 + { 
 + hashes . add ( hashIndex ) ; 
 + } 
 + collisions + = ( MAX _ HASH _ COUNT - hashes . size ( ) ) ; 
 + } 
 + assert collisions < = 100 ; 
 + } 
 + 
 + @ Test 
 + public void testManyRandom ( ) 
 + { 
 + testManyHashes ( randomKeys ( ) ) ; 
 + } 
 + 
 + / / used by filter subclass tests 
 + 
 + static final double MAX _ FAILURE _ RATE = 0 . 1 ; 
 + public static final BloomCalculations . BloomSpecification spec = BloomCalculations . computeBucketsAndK ( MAX _ FAILURE _ RATE ) ; 
 + static final int ELEMENTS = 10000 ; 
 + 
 + static final ResetableIterator < String > intKeys ( ) 
 + { 
 + return new KeyGenerator . IntGenerator ( ELEMENTS ) ; 
 + } 
 + 
 + static final ResetableIterator < String > randomKeys ( ) 
 + { 
 + return new KeyGenerator . RandomStringGenerator ( 314159 , ELEMENTS ) ; 
 + } 
 + 
 + static final ResetableIterator < String > randomKeys2 ( ) 
 + { 
 + return new KeyGenerator . RandomStringGenerator ( 271828 , ELEMENTS ) ; 
 + } 
 + 
 + public static void testFalsePositives ( Filter f , ResetableIterator < String > keys , ResetableIterator < String > otherkeys ) 
 + { 
 + assert keys . size ( ) = = otherkeys . size ( ) ; 
 + 
 + while ( keys . hasNext ( ) ) 
 + { 
 + f . add ( keys . next ( ) ) ; 
 + } 
 + 
 + int fp = 0 ; 
 + while ( otherkeys . hasNext ( ) ) 
 + { 
 + if ( f . isPresent ( otherkeys . next ( ) ) ) 
 + { 
 + fp + + ; 
 + } 
 + } 
 + 
 + double fp _ ratio = fp / ( keys . size ( ) * BloomCalculations . probs [ spec . bucketsPerElement ] [ spec . K ] ) ; 
 + assert fp _ ratio < 1 . 03 : fp _ ratio ; 
 + } 
 + 
 + public static Filter testSerialize ( Filter f ) throws IOException 
 + { 
 + f . add ( " a " ) ; 
 + DataOutputBuffer out = new DataOutputBuffer ( ) ; 
 + f . getSerializer ( ) . serialize ( f , out ) ; 
 + 
 + DataInputBuffer in = new DataInputBuffer ( ) ; 
 + in . reset ( out . getData ( ) , out . getLength ( ) ) ; 
 + Filter f2 = f . getSerializer ( ) . deserialize ( in ) ; 
 + 
 + assert f2 . isPresent ( " a " ) ; 
 + assert ! f2 . isPresent ( " b " ) ; 
 + return f2 ; 
 + } 
 + 
 + } 
 diff - - git a / test / org / apache / cassandra / utils / KeyGenerator . java b / test / org / apache / cassandra / utils / KeyGenerator . java 
 index 99ddef0 . . fafd0d3 100644 
 - - - a / test / org / apache / cassandra / utils / KeyGenerator . java 
 + + + b / test / org / apache / cassandra / utils / KeyGenerator . java 
 @ @ - 90 , 7 + 90 , 7 @ @ public class KeyGenerator { 
 WORDS + + ; 
 } 
 } catch ( IOException e ) { 
 - throw new RuntimeException ( e ) ; 
 + WORDS = 0 ; 
 } 
 } 

