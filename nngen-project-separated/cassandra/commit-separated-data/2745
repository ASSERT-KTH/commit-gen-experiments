BLEU SCORE: 0.016932492841722675

TEST MSG: Use EB HadoopCompat for compat with Hadoop 0 . 2 . x
GENERATED MSG: fix typo in SICST class name

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index a8114a3 . . 16cbd0a 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 0 . 6 <nl> + * Add compatibility for Hadoop 0 . 2 . x ( CASSANDRA - 5201 ) <nl> * Fix EstimatedHistogram races ( CASSANDRA - 6682 ) <nl> * Failure detector correctly converts initial value to nanos ( CASSANDRA - 6658 ) <nl> * Add nodetool taketoken to relocate vnodes ( CASSANDRA - 4445 ) <nl> diff - - git a / build . xml b / build . xml <nl> index bfbd8b2 . . fb774f6 100644 <nl> - - - a / build . xml <nl> + + + b / build . xml <nl> @ @ - 367 , 6 + 367 , 7 @ @ <nl> < / dependency > <nl> < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - core " version = " 1 . 0 . 3 " / > <nl> < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - minicluster " version = " 1 . 0 . 3 " / > <nl> + < dependency groupId = " com . twitter . elephantbird " artifactId = " elephant - bird - hadoop - compat " version = " 4 . 3 " / > <nl> < dependency groupId = " org . apache . pig " artifactId = " pig " version = " 0 . 10 . 0 " / > <nl> < dependency groupId = " net . java . dev . jna " artifactId = " jna " version = " 3 . 2 . 7 " / > <nl> <nl> @ @ - 408 , 6 + 409 , 7 @ @ <nl> < dependency groupId = " org . apache . rat " artifactId = " apache - rat " / > <nl> < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - core " / > <nl> 	 < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - minicluster " / > <nl> + < dependency groupId = " com . twitter . elephantbird " artifactId = " elephant - bird - hadoop - compat " / > <nl> < dependency groupId = " org . apache . pig " artifactId = " pig " / > <nl> <nl> < dependency groupId = " net . java . dev . jna " artifactId = " jna " / > <nl> @ @ - 470 , 6 + 472 , 7 @ @ <nl> < ! - - don ' t need hadoop classes to run , but if you use the hadoop stuff - - > <nl> < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - core " optional = " true " / > <nl> < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - minicluster " optional = " true " / > <nl> + < dependency groupId = " com . twitter . elephantbird " artifactId = " elephant - bird - hadoop - compat " optional = " true " / > <nl> < dependency groupId = " org . apache . pig " artifactId = " pig " optional = " true " / > <nl> <nl> < ! - - don ' t need jna to run , but nice to have - - > <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyInputFormat . java b / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyInputFormat . java <nl> index 6c45a35 . . f547fd0 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyInputFormat . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyInputFormat . java <nl> @ @ - 29 , 6 + 29 , 7 @ @ import java . util . concurrent . TimeUnit ; <nl> <nl> import com . google . common . collect . ImmutableList ; <nl> import com . google . common . collect . Lists ; <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 117 , 16 + 118 , 16 @ @ public abstract class AbstractColumnFamilyInputFormat < K , Y > extends InputFormat < <nl> <nl> public List < InputSplit > getSplits ( JobContext context ) throws IOException <nl> { <nl> - Configuration conf = context . getConfiguration ( ) ; <nl> + Configuration conf = HadoopCompat . getConfiguration ( context ) ; ; <nl> <nl> validateConfiguration ( conf ) ; <nl> <nl> / / cannonical ranges and nodes holding replicas <nl> List < TokenRange > masterRangeNodes = getRangeMap ( conf ) ; <nl> <nl> - keyspace = ConfigHelper . getInputKeyspace ( context . getConfiguration ( ) ) ; <nl> - cfName = ConfigHelper . getInputColumnFamily ( context . getConfiguration ( ) ) ; <nl> - partitioner = ConfigHelper . getInputPartitioner ( context . getConfiguration ( ) ) ; <nl> + keyspace = ConfigHelper . getInputKeyspace ( conf ) ; <nl> + cfName = ConfigHelper . getInputColumnFamily ( conf ) ; <nl> + partitioner = ConfigHelper . getInputPartitioner ( conf ) ; <nl> logger . debug ( " partitioner is " + partitioner ) ; <nl> <nl> <nl> @ @ - 344 , 7 + 345 , 7 @ @ public abstract class AbstractColumnFamilyInputFormat < K , Y > extends InputFormat < <nl> / / <nl> public org . apache . hadoop . mapred . InputSplit [ ] getSplits ( JobConf jobConf , int numSplits ) throws IOException <nl> { <nl> - TaskAttemptContext tac = new TaskAttemptContext ( jobConf , new TaskAttemptID ( ) ) ; <nl> + TaskAttemptContext tac = HadoopCompat . newTaskAttemptContext ( jobConf , new TaskAttemptID ( ) ) ; <nl> List < org . apache . hadoop . mapreduce . InputSplit > newInputSplits = this . getSplits ( tac ) ; <nl> org . apache . hadoop . mapred . InputSplit [ ] oldInputSplits = new org . apache . hadoop . mapred . InputSplit [ newInputSplits . size ( ) ] ; <nl> for ( int i = 0 ; i < newInputSplits . size ( ) ; i + + ) <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyOutputFormat . java b / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyOutputFormat . java <nl> index 2040f61 . . a3c4234 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyOutputFormat . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyOutputFormat . java <nl> @ @ - 22 , 6 + 22 , 7 @ @ import java . io . IOException ; <nl> import java . util . HashMap ; <nl> import java . util . Map ; <nl> <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 72 , 7 + 73 , 7 @ @ public abstract class AbstractColumnFamilyOutputFormat < K , Y > extends OutputForma <nl> * / <nl> public void checkOutputSpecs ( JobContext context ) <nl> { <nl> - checkOutputSpecs ( context . getConfiguration ( ) ) ; <nl> + checkOutputSpecs ( HadoopCompat . getConfiguration ( context ) ) ; <nl> } <nl> <nl> protected void checkOutputSpecs ( Configuration conf ) <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / BulkOutputFormat . java b / src / java / org / apache / cassandra / hadoop / BulkOutputFormat . java <nl> index f1c5f39 . . 566d5ee 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / BulkOutputFormat . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / BulkOutputFormat . java <nl> @ @ - 22 , 6 + 22 , 7 @ @ import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . List ; <nl> <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . apache . cassandra . thrift . Mutation ; <nl> import org . apache . hadoop . conf . Configuration ; <nl> import org . apache . hadoop . mapreduce . * ; <nl> @ @ - 32 , 7 + 33 , 7 @ @ public class BulkOutputFormat extends OutputFormat < ByteBuffer , List < Mutation > > <nl> @ Override <nl> public void checkOutputSpecs ( JobContext context ) <nl> { <nl> - checkOutputSpecs ( context . getConfiguration ( ) ) ; <nl> + checkOutputSpecs ( HadoopCompat . getConfiguration ( context ) ) ; <nl> } <nl> <nl> private void checkOutputSpecs ( Configuration conf ) <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / BulkRecordWriter . java b / src / java / org / apache / cassandra / hadoop / BulkRecordWriter . java <nl> index b6a7e75 . . 28c6d2c 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / BulkRecordWriter . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / BulkRecordWriter . java <nl> @ @ - 28 , 6 + 28 , 7 @ @ import java . util . concurrent . Future ; <nl> import java . util . concurrent . TimeUnit ; <nl> import java . util . concurrent . TimeoutException ; <nl> <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 85 , 7 + 86 , 7 @ @ implements org . apache . hadoop . mapred . RecordWriter < ByteBuffer , List < Mutation > > <nl> <nl> BulkRecordWriter ( TaskAttemptContext context ) <nl> { <nl> - this ( context . getConfiguration ( ) ) ; <nl> + this ( HadoopCompat . getConfiguration ( context ) ) ; <nl> this . progress = new Progressable ( context ) ; <nl> } <nl> <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / ColumnFamilyInputFormat . java b / src / java / org / apache / cassandra / hadoop / ColumnFamilyInputFormat . java <nl> index 1b5a4e2 . . df59408 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / ColumnFamilyInputFormat . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / ColumnFamilyInputFormat . java <nl> @ @ - 21 , 6 + 21 , 7 @ @ import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . apache . cassandra . db . Column ; <nl> import org . apache . hadoop . conf . Configuration ; <nl> import org . apache . hadoop . mapred . JobConf ; <nl> @ @ - 54 , 14 + 55 , 14 @ @ public class ColumnFamilyInputFormat extends AbstractColumnFamilyInputFormat < Byt <nl> <nl> public org . apache . hadoop . mapred . RecordReader < ByteBuffer , SortedMap < ByteBuffer , Column > > getRecordReader ( org . apache . hadoop . mapred . InputSplit split , JobConf jobConf , final Reporter reporter ) throws IOException <nl> { <nl> - TaskAttemptContext tac = new TaskAttemptContext ( jobConf , TaskAttemptID . forName ( jobConf . get ( MAPRED _ TASK _ ID ) ) ) <nl> - { <nl> - @ Override <nl> - public void progress ( ) <nl> - { <nl> - reporter . progress ( ) ; <nl> - } <nl> - } ; <nl> + TaskAttemptContext tac = HadoopCompat . newMapContext ( <nl> + jobConf , <nl> + TaskAttemptID . forName ( jobConf . get ( MAPRED _ TASK _ ID ) ) , <nl> + null , <nl> + null , <nl> + null , <nl> + new ReporterWrapper ( reporter ) , <nl> + null ) ; <nl> <nl> ColumnFamilyRecordReader recordReader = new ColumnFamilyRecordReader ( jobConf . getInt ( CASSANDRA _ HADOOP _ MAX _ KEY _ SIZE , CASSANDRA _ HADOOP _ MAX _ KEY _ SIZE _ DEFAULT ) ) ; <nl> recordReader . initialize ( ( org . apache . hadoop . mapreduce . InputSplit ) split , tac ) ; <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordReader . java b / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordReader . java <nl> index e33aea9 . . 22d614e 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordReader . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordReader . java <nl> @ @ - 24 , 6 + 24 , 7 @ @ import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> <nl> import com . google . common . collect . * ; <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 132 , 7 + 133 , 7 @ @ public class ColumnFamilyRecordReader extends RecordReader < ByteBuffer , SortedMap <nl> public void initialize ( InputSplit split , TaskAttemptContext context ) throws IOException <nl> { <nl> this . split = ( ColumnFamilySplit ) split ; <nl> - Configuration conf = context . getConfiguration ( ) ; <nl> + Configuration conf = HadoopCompat . getConfiguration ( context ) ; <nl> KeyRange jobRange = ConfigHelper . getInputKeyRange ( conf ) ; <nl> filter = jobRange = = null ? null : jobRange . row _ filter ; <nl> predicate = ConfigHelper . getInputSlicePredicate ( conf ) ; <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordWriter . java b / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordWriter . java <nl> index 6823342 . . 0ae2a67 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordWriter . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordWriter . java <nl> @ @ - 23 , 6 + 23 , 7 @ @ import java . net . InetAddress ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . apache . cassandra . dht . Range ; <nl> import org . apache . cassandra . dht . Token ; <nl> import org . apache . cassandra . thrift . * ; <nl> @ @ - 60 , 7 + 61 , 7 @ @ final class ColumnFamilyRecordWriter extends AbstractColumnFamilyRecordWriter < By <nl> * / <nl> ColumnFamilyRecordWriter ( TaskAttemptContext context ) <nl> { <nl> - this ( context . getConfiguration ( ) ) ; <nl> + this ( HadoopCompat . getConfiguration ( context ) ) ; <nl> this . progressable = new Progressable ( context ) ; <nl> } <nl> <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingInputFormat . java b / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingInputFormat . java <nl> index 0e1509e . . 6f4478e 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingInputFormat . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingInputFormat . java <nl> @ @ - 21 , 7 + 21 , 9 @ @ import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . Map ; <nl> <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . apache . cassandra . hadoop . AbstractColumnFamilyInputFormat ; <nl> + import org . apache . cassandra . hadoop . ReporterWrapper ; <nl> import org . apache . hadoop . mapred . InputSplit ; <nl> import org . apache . hadoop . mapred . JobConf ; <nl> import org . apache . hadoop . mapred . RecordReader ; <nl> @ @ - 58 , 14 + 60 , 14 @ @ public class CqlPagingInputFormat extends AbstractColumnFamilyInputFormat < Map < St <nl> public RecordReader < Map < String , ByteBuffer > , Map < String , ByteBuffer > > getRecordReader ( InputSplit split , JobConf jobConf , final Reporter reporter ) <nl> throws IOException <nl> { <nl> - TaskAttemptContext tac = new TaskAttemptContext ( jobConf , TaskAttemptID . forName ( jobConf . get ( MAPRED _ TASK _ ID ) ) ) <nl> - { <nl> - @ Override <nl> - public void progress ( ) <nl> - { <nl> - reporter . progress ( ) ; <nl> - } <nl> - } ; <nl> + TaskAttemptContext tac = HadoopCompat . newMapContext ( <nl> + jobConf , <nl> + TaskAttemptID . forName ( jobConf . get ( MAPRED _ TASK _ ID ) ) , <nl> + null , <nl> + null , <nl> + null , <nl> + new ReporterWrapper ( reporter ) , <nl> + null ) ; <nl> <nl> CqlPagingRecordReader recordReader = new CqlPagingRecordReader ( ) ; <nl> recordReader . initialize ( ( org . apache . hadoop . mapreduce . InputSplit ) split , tac ) ; <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingRecordReader . java b / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingRecordReader . java <nl> index d9b9a39 . . da278d8 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingRecordReader . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingRecordReader . java <nl> @ @ - 26 , 6 + 26 , 7 @ @ import java . util . * ; <nl> <nl> import com . google . common . collect . AbstractIterator ; <nl> import com . google . common . collect . Iterables ; <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 104 , 7 + 105 , 7 @ @ public class CqlPagingRecordReader extends RecordReader < Map < String , ByteBuffer > , <nl> public void initialize ( InputSplit split , TaskAttemptContext context ) throws IOException <nl> { <nl> this . split = ( ColumnFamilySplit ) split ; <nl> - Configuration conf = context . getConfiguration ( ) ; <nl> + Configuration conf = HadoopCompat . getConfiguration ( context ) ; <nl> totalRowCount = ( this . split . getLength ( ) < Long . MAX _ VALUE ) <nl> ? ( int ) this . split . getLength ( ) <nl> : ConfigHelper . getInputSplitSize ( conf ) ; <nl> @ @ - 123 , 7 + 124 , 7 @ @ public class CqlPagingRecordReader extends RecordReader < Map < String , ByteBuffer > , <nl> pageRowSize = DEFAULT _ CQL _ PAGE _ LIMIT ; <nl> } <nl> <nl> - partitioner = ConfigHelper . getInputPartitioner ( context . getConfiguration ( ) ) ; <nl> + partitioner = ConfigHelper . getInputPartitioner ( HadoopCompat . getConfiguration ( context ) ) ; <nl> <nl> try <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / cql3 / CqlRecordWriter . java b / src / java / org / apache / cassandra / hadoop / cql3 / CqlRecordWriter . java <nl> index 4746f8a . . e2b90f1 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / cql3 / CqlRecordWriter . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / cql3 / CqlRecordWriter . java <nl> @ @ - 23 , 6 + 23 , 7 @ @ import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> import java . util . concurrent . ConcurrentHashMap ; <nl> <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 84 , 7 + 85 , 7 @ @ final class CqlRecordWriter extends AbstractColumnFamilyRecordWriter < Map < String , <nl> * / <nl> CqlRecordWriter ( TaskAttemptContext context ) throws IOException <nl> { <nl> - this ( context . getConfiguration ( ) ) ; <nl> + this ( HadoopCompat . getConfiguration ( context ) ) ; <nl> this . progressable = new Progressable ( context ) ; <nl> } <nl> <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / pig / CassandraStorage . java b / src / java / org / apache / cassandra / hadoop / pig / CassandraStorage . java <nl> index aeec4a6 . . 3c34167 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / pig / CassandraStorage . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / pig / CassandraStorage . java <nl> @ @ - 22 , 6 + 22 , 7 @ @ import java . nio . ByteBuffer ; <nl> import java . nio . charset . CharacterCodingException ; <nl> import java . util . * ; <nl> <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 282 , 7 + 283 , 7 @ @ public class CassandraStorage extends AbstractCassandraStorage <nl> / * * set read configuration settings * / <nl> public void setLocation ( String location , Job job ) throws IOException <nl> { <nl> - conf = job . getConfiguration ( ) ; <nl> + conf = HadoopCompat . getConfiguration ( job ) ; <nl> setLocationFromUri ( location ) ; <nl> <nl> if ( ConfigHelper . getInputSlicePredicate ( conf ) = = null ) <nl> @ @ - 339 , 7 + 340 , 7 @ @ public class CassandraStorage extends AbstractCassandraStorage <nl> / * * set store configuration settings * / <nl> public void setStoreLocation ( String location , Job job ) throws IOException <nl> { <nl> - conf = job . getConfiguration ( ) ; <nl> + conf = HadoopCompat . getConfiguration ( job ) ; <nl> <nl> / / don ' t combine mappers to a single mapper per node <nl> conf . setBoolean ( " pig . noSplitCombination " , true ) ; <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / pig / CqlStorage . java b / src / java / org / apache / cassandra / hadoop / pig / CqlStorage . java <nl> index 5fbce21 . . c6db82f 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / pig / CqlStorage . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / pig / CqlStorage . java <nl> @ @ - 23 , 6 + 23 , 7 @ @ import java . nio . charset . CharacterCodingException ; <nl> import java . util . * ; <nl> <nl> <nl> + import com . twitter . elephantbird . util . HadoopCompat ; <nl> import org . apache . cassandra . cql3 . CFDefinition ; <nl> import org . apache . cassandra . cql3 . ColumnIdentifier ; <nl> import org . apache . cassandra . db . Column ; <nl> @ @ - 197 , 7 + 198 , 7 @ @ public class CqlStorage extends AbstractCassandraStorage <nl> / * * set read configuration settings * / <nl> public void setLocation ( String location , Job job ) throws IOException <nl> { <nl> - conf = job . getConfiguration ( ) ; <nl> + conf = HadoopCompat . getConfiguration ( job ) ; <nl> setLocationFromUri ( location ) ; <nl> <nl> if ( username ! = null & & password ! = null ) <nl> @ @ - 256 , 7 + 257 , 7 @ @ public class CqlStorage extends AbstractCassandraStorage <nl> / * * set store configuration settings * / <nl> public void setStoreLocation ( String location , Job job ) throws IOException <nl> { <nl> - conf = job . getConfiguration ( ) ; <nl> + conf = HadoopCompat . getConfiguration ( job ) ; <nl> setLocationFromUri ( location ) ; <nl> <nl> if ( username ! = null & & password ! = null )
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 84db73d . . bcf56b7 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 21 , 6 + 21 , 7 @ @ <nl> * fix nodetool ' s setcompactionthreshold command ( CASSANDRA - 4455 ) <nl> * Ensure compacted files are never used , to avoid counter overcount ( CASSANDRA - 4436 ) <nl> Merged from 1 . 0 : <nl> + * Push the validation of secondary index values to the SecondaryIndexManager ( CASSANDRA - 4240 ) <nl> * allow dropping columns shadowed by not - yet - expired supercolumn or row <nl> tombstones in PrecompactedRow ( CASSANDRA - 4396 ) <nl> * fix 1 . 0 . x node join to mixed version cluster , other nodes > = 1 . 1 ( CASSANDRA - 4195 ) <nl> @ @ - 156 , 6 + 157 , 8 @ @ Merged from 1 . 0 : <nl> * improve ability of STCS . getBuckets to deal with 100s of 1000s of <nl> sstables , such as when convertinb back from LCS ( CASSANDRA - 4287 ) <nl> * Oversize integer in CQL throws NumberFormatException ( CASSANDRA - 4291 ) <nl> + * fix 1 . 0 . x node join to mixed version cluster , other nodes > = 1 . 1 ( CASSANDRA - 4195 ) <nl> + * Fix LCS splitting sstable base on uncompressed size ( CASSANDRA - 4419 ) <nl> <nl> <nl> 1 . 1 . 0 - final <nl> diff - - git a / src / java / org / apache / cassandra / db / index / PerColumnSecondaryIndex . java b / src / java / org / apache / cassandra / db / index / PerColumnSecondaryIndex . java <nl> index ba7360d . . 05fa70b 100644 <nl> - - - a / src / java / org / apache / cassandra / db / index / PerColumnSecondaryIndex . java <nl> + + + b / src / java / org / apache / cassandra / db / index / PerColumnSecondaryIndex . java <nl> @ @ - 22 , 6 + 22 , 8 @ @ import java . nio . ByteBuffer ; <nl> <nl> import org . apache . cassandra . db . DecoratedKey ; <nl> import org . apache . cassandra . db . IColumn ; <nl> + import org . apache . cassandra . thrift . Column ; <nl> + import org . apache . cassandra . utils . FBUtilities ; <nl> <nl> / * * <nl> * Base class for Secondary indexes that implement a unique index per column <nl> @ @ - 60 , 4 + 62 , 10 @ @ public abstract class PerColumnSecondaryIndex extends SecondaryIndex <nl> { <nl> return getIndexName ( ) ; <nl> } <nl> + <nl> + @ Override <nl> + public boolean validate ( Column column ) <nl> + { <nl> + return column . value . remaining ( ) < FBUtilities . MAX _ UNSIGNED _ SHORT ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / index / PerRowSecondaryIndex . java b / src / java / org / apache / cassandra / db / index / PerRowSecondaryIndex . java <nl> index df5a41d . . 2b05bee 100644 <nl> - - - a / src / java / org / apache / cassandra / db / index / PerRowSecondaryIndex . java <nl> + + + b / src / java / org / apache / cassandra / db / index / PerRowSecondaryIndex . java <nl> @ @ - 26 , 6 + 26 , 7 @ @ import java . util . SortedSet ; <nl> import org . apache . cassandra . db . ColumnFamily ; <nl> import org . apache . cassandra . db . DecoratedKey ; <nl> import org . apache . cassandra . db . IColumn ; <nl> + import org . apache . cassandra . thrift . Column ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> <nl> / * * <nl> @ @ - 70 , 4 + 71 , 10 @ @ public abstract class PerRowSecondaryIndex extends SecondaryIndex <nl> throw new RuntimeException ( e ) ; <nl> } <nl> } <nl> + <nl> + @ Override <nl> + public boolean validate ( Column column ) <nl> + { <nl> + return true ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / index / SecondaryIndex . java b / src / java / org / apache / cassandra / db / index / SecondaryIndex . java <nl> index 64a696d . . 3732086 100644 <nl> - - - a / src / java / org / apache / cassandra / db / index / SecondaryIndex . java <nl> + + + b / src / java / org / apache / cassandra / db / index / SecondaryIndex . java <nl> @ @ - 31 , 6 + 31 , 7 @ @ import org . apache . cassandra . db . compaction . CompactionManager ; <nl> import org . apache . cassandra . db . index . keys . KeysIndex ; <nl> import org . apache . cassandra . io . sstable . ReducingKeyIterator ; <nl> import org . apache . cassandra . io . sstable . SSTableReader ; <nl> + import org . apache . cassandra . thrift . Column ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . apache . commons . lang . StringUtils ; <nl> import org . slf4j . Logger ; <nl> @ @ - 330 , 4 + 331 , 6 @ @ public abstract class SecondaryIndex <nl> <nl> return index ; <nl> } <nl> + <nl> + public abstract boolean validate ( Column column ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / index / SecondaryIndexManager . java b / src / java / org / apache / cassandra / db / index / SecondaryIndexManager . java <nl> index ba066e2 . . e923575 100644 <nl> - - - a / src / java / org / apache / cassandra / db / index / SecondaryIndexManager . java <nl> + + + b / src / java / org / apache / cassandra / db / index / SecondaryIndexManager . java <nl> @ @ - 20 , 7 + 20 , 14 @ @ package org . apache . cassandra . db . index ; <nl> import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> - import java . util . concurrent . * ; <nl> + import java . util . concurrent . ConcurrentNavigableMap ; <nl> + import java . util . concurrent . ConcurrentSkipListMap ; <nl> + import java . util . concurrent . ExecutionException ; <nl> + import java . util . concurrent . Future ; <nl> + <nl> + import org . apache . commons . lang . StringUtils ; <nl> + import org . slf4j . Logger ; <nl> + import org . slf4j . LoggerFactory ; <nl> <nl> import org . apache . cassandra . config . ColumnDefinition ; <nl> import org . apache . cassandra . config . ConfigurationException ; <nl> @ @ - 31 , 11 + 38 , 9 @ @ import org . apache . cassandra . dht . AbstractBounds ; <nl> import org . apache . cassandra . dht . LocalToken ; <nl> import org . apache . cassandra . io . sstable . ReducingKeyIterator ; <nl> import org . apache . cassandra . io . sstable . SSTableReader ; <nl> + import org . apache . cassandra . thrift . Column ; <nl> import org . apache . cassandra . thrift . IndexExpression ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> - import org . apache . commons . lang . StringUtils ; <nl> - import org . slf4j . Logger ; <nl> - import org . slf4j . LoggerFactory ; <nl> <nl> / * * <nl> * Manages all the indexes associated with a given CFS <nl> @ @ - 606 , 4 + 611 , 10 @ @ public class SecondaryIndexManager <nl> for ( ByteBuffer colName : indexes ) <nl> indexesByColumn . get ( colName ) . setIndexRemoved ( colName ) ; <nl> } <nl> + <nl> + public boolean validate ( Column column ) <nl> + { <nl> + SecondaryIndex index = getIndexForColumn ( column . name ) ; <nl> + return index ! = null ? index . validate ( column ) : true ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / thrift / ThriftValidation . java b / src / java / org / apache / cassandra / thrift / ThriftValidation . java <nl> index a77bfb6 . . fe53060 100644 <nl> - - - a / src / java / org / apache / cassandra / thrift / ThriftValidation . java <nl> + + + b / src / java / org / apache / cassandra / thrift / ThriftValidation . java <nl> @ @ - 441 , 13 + 441 , 13 @ @ public class ThriftValidation <nl> ( isSubColumn ? metadata . subcolumnComparator : metadata . comparator ) . getString ( column . name ) ) ) ; <nl> } <nl> <nl> - / / Indexed column values cannot be larger than 64K . See CASSANDRA - 3057 for more details <nl> - if ( columnDef ! = null & & columnDef . getIndexType ( ) ! = null & & column . value . remaining ( ) > FBUtilities . MAX _ UNSIGNED _ SHORT ) <nl> - throw new InvalidRequestException ( String . format ( " Can ' t index column value of size % d for index % s in CF % s of KS % s " , <nl> - column . value . remaining ( ) , <nl> - columnDef . getIndexName ( ) , <nl> - metadata . cfName , <nl> - metadata . ksName ) ) ; <nl> + / / Indexed column values cannot be larger than 64K . See CASSANDRA - 3057 / 4240 for more details <nl> + if ( ! Table . open ( metadata . ksName ) . getColumnFamilyStore ( metadata . cfName ) . indexManager . validate ( column ) ) <nl> + throw new InvalidRequestException ( String . format ( " Can ' t index column value of size % d for index % s in CF % s of KS % s " , <nl> + column . value . remaining ( ) , <nl> + columnDef . getIndexName ( ) , <nl> + metadata . cfName , <nl> + metadata . ksName ) ) ; <nl> } <nl> <nl> / * * <nl> diff - - git a / test / unit / org / apache / cassandra / db / SecondaryIndexColumnSizeTest . java b / test / unit / org / apache / cassandra / db / SecondaryIndexColumnSizeTest . java <nl> new file mode 100644 <nl> index 0000000 . . 89479e9 <nl> - - - / dev / null <nl> + + + b / test / unit / org / apache / cassandra / db / SecondaryIndexColumnSizeTest . java <nl> @ @ - 0 , 0 + 1 , 215 @ @ <nl> + / * <nl> + * Licensed to the Apache Software Foundation ( ASF ) under one <nl> + * or more contributor license agreements . See the NOTICE file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . The ASF licenses this file <nl> + * to you under the Apache License , Version 2 . 0 ( the <nl> + * " License " ) ; you may not use this file except in compliance <nl> + * with the License . You may obtain a copy of the License at <nl> + * <nl> + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 <nl> + * <nl> + * Unless required by applicable law or agreed to in writing , <nl> + * software distributed under the License is distributed on an <nl> + * " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY <nl> + * KIND , either express or implied . See the License for the <nl> + * specific language governing permissions and limitations <nl> + * under the License . <nl> + * / <nl> + package org . apache . cassandra . db ; <nl> + <nl> + import java . io . IOException ; <nl> + import java . nio . ByteBuffer ; <nl> + import java . util . List ; <nl> + import java . util . Set ; <nl> + import java . util . SortedSet ; <nl> + <nl> + import org . junit . Test ; <nl> + <nl> + import org . apache . cassandra . config . ConfigurationException ; <nl> + import org . apache . cassandra . db . index . PerColumnSecondaryIndex ; <nl> + import org . apache . cassandra . db . index . PerRowSecondaryIndex ; <nl> + import org . apache . cassandra . db . index . SecondaryIndexSearcher ; <nl> + import org . apache . cassandra . thrift . Column ; <nl> + import org . apache . cassandra . utils . ByteBufferUtil ; <nl> + <nl> + import static org . junit . Assert . assertFalse ; <nl> + import static org . junit . Assert . assertTrue ; <nl> + <nl> + public class SecondaryIndexColumnSizeTest <nl> + { <nl> + @ Test <nl> + public void test64kColumn ( ) <nl> + { <nl> + Column column = new Column ( ) ; <nl> + column . name = ByteBufferUtil . bytes ( " test " ) ; <nl> + <nl> + / / a byte buffer more than 64k <nl> + ByteBuffer buffer = ByteBuffer . allocate ( 1024 * 65 ) ; <nl> + buffer . clear ( ) ; <nl> + <nl> + / / read more than 64k <nl> + for ( int i = 0 ; i < 1024 * 64 / 4 + 1 ; i + + ) <nl> + buffer . putInt ( 0 ) ; <nl> + <nl> + / / for read <nl> + buffer . flip ( ) ; <nl> + column . value = buffer ; <nl> + <nl> + MockRowIndex mockRowIndex = new MockRowIndex ( ) ; <nl> + MockColumnIndex mockColumnIndex = new MockColumnIndex ( ) ; <nl> + <nl> + assertTrue ( mockRowIndex . validate ( column ) ) ; <nl> + assertFalse ( mockColumnIndex . validate ( column ) ) ; <nl> + <nl> + / / test less than 64k value <nl> + buffer . flip ( ) ; <nl> + buffer . clear ( ) ; <nl> + buffer . putInt ( 20 ) ; <nl> + buffer . flip ( ) ; <nl> + <nl> + assertTrue ( mockRowIndex . validate ( column ) ) ; <nl> + assertTrue ( mockColumnIndex . validate ( column ) ) ; <nl> + } <nl> + <nl> + private class MockRowIndex extends PerRowSecondaryIndex <nl> + { <nl> + @ Override <nl> + public void applyIndexUpdates ( ByteBuffer rowKey , ColumnFamily cf , SortedSet < ByteBuffer > mutatedIndexedColumns , ColumnFamily oldIndexedColumns ) throws IOException <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void init ( ) <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void validateOptions ( ) throws ConfigurationException <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public String getIndexName ( ) <nl> + { <nl> + return null ; <nl> + } <nl> + <nl> + @ Override <nl> + protected SecondaryIndexSearcher createSecondaryIndexSearcher ( Set < ByteBuffer > columns ) <nl> + { <nl> + return null ; <nl> + } <nl> + <nl> + @ Override <nl> + public void forceBlockingFlush ( ) throws IOException <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public long getLiveSize ( ) <nl> + { <nl> + return 0 ; <nl> + } <nl> + <nl> + @ Override <nl> + public ColumnFamilyStore getIndexCfs ( ) <nl> + { <nl> + return null ; <nl> + } <nl> + <nl> + @ Override <nl> + public void removeIndex ( ByteBuffer columnName ) throws IOException <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void invalidate ( ) <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void truncate ( long truncatedAt ) <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void deleteFromIndex ( DecoratedKey < ? > key , List < IColumn > indexedColumnsInRow ) <nl> + { <nl> + } <nl> + <nl> + } <nl> + <nl> + <nl> + private class MockColumnIndex extends PerColumnSecondaryIndex <nl> + { <nl> + @ Override <nl> + public void init ( ) <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void validateOptions ( ) throws ConfigurationException <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public String getIndexName ( ) <nl> + { <nl> + return null ; <nl> + } <nl> + <nl> + @ Override <nl> + protected SecondaryIndexSearcher createSecondaryIndexSearcher ( Set < ByteBuffer > columns ) <nl> + { <nl> + return null ; <nl> + } <nl> + <nl> + @ Override <nl> + public void forceBlockingFlush ( ) throws IOException <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public long getLiveSize ( ) <nl> + { <nl> + return 0 ; <nl> + } <nl> + <nl> + @ Override <nl> + public ColumnFamilyStore getIndexCfs ( ) <nl> + { <nl> + return null ; <nl> + } <nl> + <nl> + @ Override <nl> + public void removeIndex ( ByteBuffer columnName ) throws IOException <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void invalidate ( ) <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void truncate ( long truncatedAt ) <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void deleteColumn ( DecoratedKey valueKey , ByteBuffer rowKey , IColumn col ) throws IOException <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void insertColumn ( DecoratedKey valueKey , ByteBuffer rowKey , IColumn col ) throws IOException <nl> + { <nl> + } <nl> + <nl> + @ Override <nl> + public void updateColumn ( DecoratedKey valueKey , ByteBuffer rowKey , IColumn col ) throws IOException <nl> + { <nl> + } <nl> + } <nl> + } <nl> diff - - git a / test / unit / org / apache / cassandra / thrift / ThriftValidationTest . java b / test / unit / org / apache / cassandra / thrift / ThriftValidationTest . java <nl> index 9c131f9 . . af0e668 100644 <nl> - - - a / test / unit / org / apache / cassandra / thrift / ThriftValidationTest . java <nl> + + + b / test / unit / org / apache / cassandra / thrift / ThriftValidationTest . java <nl> @ @ - 21 , 8 + 21 , 6 @ @ package org . apache . cassandra . thrift ; <nl> * / <nl> <nl> <nl> - import java . nio . ByteBuffer ; <nl> - <nl> import org . junit . Test ; <nl> <nl> import org . apache . cassandra . SchemaLoader ; <nl> @ @ - 35 , 7 + 33 , 6 @ @ import org . apache . cassandra . db . marshal . AsciiType ; <nl> import org . apache . cassandra . db . marshal . UTF8Type ; <nl> import org . apache . cassandra . locator . LocalStrategy ; <nl> import org . apache . cassandra . locator . NetworkTopologyStrategy ; <nl> - import org . apache . cassandra . utils . FBUtilities ; <nl> <nl> public class ThriftValidationTest extends SchemaLoader <nl> { <nl> @ @ - 52 , 55 + 49 , 6 @ @ public class ThriftValidationTest extends SchemaLoader <nl> } <nl> <nl> @ Test <nl> - public void testColumnValueSizeForIndexedColumn ( ) throws ConfigurationException , InvalidRequestException <nl> - { <nl> - CfDef cfDef = Schema . instance . getCFMetaData ( " Keyspace1 " , " Standard1 " ) . toThrift ( ) ; <nl> - ByteBuffer columnName = AsciiType . instance . fromString ( " indexed " ) ; <nl> - <nl> - / / add an indexed column definition <nl> - cfDef . addToColumn _ metadata ( new ColumnDef ( columnName , UTF8Type . class . getCanonicalName ( ) ) <nl> - . setIndex _ type ( IndexType . KEYS ) <nl> - . setIndex _ name ( " indexed _ col " ) ) ; <nl> - <nl> - CFMetaData metaData = CFMetaData . fromThrift ( cfDef ) ; <nl> - <nl> - Column column = new Column ( columnName ) <nl> - . setValue ( new byte [ FBUtilities . MAX _ UNSIGNED _ SHORT + 1 ] ) <nl> - . setTimestamp ( System . currentTimeMillis ( ) ) ; <nl> - <nl> - boolean gotException = false ; <nl> - <nl> - try <nl> - { <nl> - / / this run should throw an exception <nl> - ThriftValidation . validateColumnData ( metaData , column , false ) ; <nl> - } <nl> - catch ( InvalidRequestException e ) <nl> - { <nl> - gotException = true ; <nl> - } <nl> - <nl> - assert gotException : " expected InvalidRequestException but not received . " ; <nl> - <nl> - / / change value to be less than unsigned short size <nl> - column . setValue ( new byte [ 12 ] ) ; <nl> - <nl> - gotException = false ; / / reset flag <nl> - <nl> - try <nl> - { <nl> - / / this run should run clean <nl> - ThriftValidation . validateColumnData ( metaData , column , false ) ; <nl> - } <nl> - catch ( InvalidRequestException e ) <nl> - { <nl> - gotException = true ; <nl> - } <nl> - <nl> - assert ! gotException : " got unexpected InvalidRequestException " ; <nl> - } <nl> - <nl> - @ Test <nl> public void testColumnNameEqualToKeyAlias ( ) <nl> { <nl> CFMetaData metaData = Schema . instance . getCFMetaData ( " Keyspace1 " , " Standard1 " ) ;

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index a8114a3 . . 16cbd0a 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 0 . 6 
 + * Add compatibility for Hadoop 0 . 2 . x ( CASSANDRA - 5201 ) 
 * Fix EstimatedHistogram races ( CASSANDRA - 6682 ) 
 * Failure detector correctly converts initial value to nanos ( CASSANDRA - 6658 ) 
 * Add nodetool taketoken to relocate vnodes ( CASSANDRA - 4445 ) 
 diff - - git a / build . xml b / build . xml 
 index bfbd8b2 . . fb774f6 100644 
 - - - a / build . xml 
 + + + b / build . xml 
 @ @ - 367 , 6 + 367 , 7 @ @ 
 < / dependency > 
 < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - core " version = " 1 . 0 . 3 " / > 
 < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - minicluster " version = " 1 . 0 . 3 " / > 
 + < dependency groupId = " com . twitter . elephantbird " artifactId = " elephant - bird - hadoop - compat " version = " 4 . 3 " / > 
 < dependency groupId = " org . apache . pig " artifactId = " pig " version = " 0 . 10 . 0 " / > 
 < dependency groupId = " net . java . dev . jna " artifactId = " jna " version = " 3 . 2 . 7 " / > 
 
 @ @ - 408 , 6 + 409 , 7 @ @ 
 < dependency groupId = " org . apache . rat " artifactId = " apache - rat " / > 
 < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - core " / > 
 	 < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - minicluster " / > 
 + < dependency groupId = " com . twitter . elephantbird " artifactId = " elephant - bird - hadoop - compat " / > 
 < dependency groupId = " org . apache . pig " artifactId = " pig " / > 
 
 < dependency groupId = " net . java . dev . jna " artifactId = " jna " / > 
 @ @ - 470 , 6 + 472 , 7 @ @ 
 < ! - - don ' t need hadoop classes to run , but if you use the hadoop stuff - - > 
 < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - core " optional = " true " / > 
 < dependency groupId = " org . apache . hadoop " artifactId = " hadoop - minicluster " optional = " true " / > 
 + < dependency groupId = " com . twitter . elephantbird " artifactId = " elephant - bird - hadoop - compat " optional = " true " / > 
 < dependency groupId = " org . apache . pig " artifactId = " pig " optional = " true " / > 
 
 < ! - - don ' t need jna to run , but nice to have - - > 
 diff - - git a / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyInputFormat . java b / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyInputFormat . java 
 index 6c45a35 . . f547fd0 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyInputFormat . java 
 + + + b / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyInputFormat . java 
 @ @ - 29 , 6 + 29 , 7 @ @ import java . util . concurrent . TimeUnit ; 
 
 import com . google . common . collect . ImmutableList ; 
 import com . google . common . collect . Lists ; 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 117 , 16 + 118 , 16 @ @ public abstract class AbstractColumnFamilyInputFormat < K , Y > extends InputFormat < 
 
 public List < InputSplit > getSplits ( JobContext context ) throws IOException 
 { 
 - Configuration conf = context . getConfiguration ( ) ; 
 + Configuration conf = HadoopCompat . getConfiguration ( context ) ; ; 
 
 validateConfiguration ( conf ) ; 
 
 / / cannonical ranges and nodes holding replicas 
 List < TokenRange > masterRangeNodes = getRangeMap ( conf ) ; 
 
 - keyspace = ConfigHelper . getInputKeyspace ( context . getConfiguration ( ) ) ; 
 - cfName = ConfigHelper . getInputColumnFamily ( context . getConfiguration ( ) ) ; 
 - partitioner = ConfigHelper . getInputPartitioner ( context . getConfiguration ( ) ) ; 
 + keyspace = ConfigHelper . getInputKeyspace ( conf ) ; 
 + cfName = ConfigHelper . getInputColumnFamily ( conf ) ; 
 + partitioner = ConfigHelper . getInputPartitioner ( conf ) ; 
 logger . debug ( " partitioner is " + partitioner ) ; 
 
 
 @ @ - 344 , 7 + 345 , 7 @ @ public abstract class AbstractColumnFamilyInputFormat < K , Y > extends InputFormat < 
 / / 
 public org . apache . hadoop . mapred . InputSplit [ ] getSplits ( JobConf jobConf , int numSplits ) throws IOException 
 { 
 - TaskAttemptContext tac = new TaskAttemptContext ( jobConf , new TaskAttemptID ( ) ) ; 
 + TaskAttemptContext tac = HadoopCompat . newTaskAttemptContext ( jobConf , new TaskAttemptID ( ) ) ; 
 List < org . apache . hadoop . mapreduce . InputSplit > newInputSplits = this . getSplits ( tac ) ; 
 org . apache . hadoop . mapred . InputSplit [ ] oldInputSplits = new org . apache . hadoop . mapred . InputSplit [ newInputSplits . size ( ) ] ; 
 for ( int i = 0 ; i < newInputSplits . size ( ) ; i + + ) 
 diff - - git a / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyOutputFormat . java b / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyOutputFormat . java 
 index 2040f61 . . a3c4234 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyOutputFormat . java 
 + + + b / src / java / org / apache / cassandra / hadoop / AbstractColumnFamilyOutputFormat . java 
 @ @ - 22 , 6 + 22 , 7 @ @ import java . io . IOException ; 
 import java . util . HashMap ; 
 import java . util . Map ; 
 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 72 , 7 + 73 , 7 @ @ public abstract class AbstractColumnFamilyOutputFormat < K , Y > extends OutputForma 
 * / 
 public void checkOutputSpecs ( JobContext context ) 
 { 
 - checkOutputSpecs ( context . getConfiguration ( ) ) ; 
 + checkOutputSpecs ( HadoopCompat . getConfiguration ( context ) ) ; 
 } 
 
 protected void checkOutputSpecs ( Configuration conf ) 
 diff - - git a / src / java / org / apache / cassandra / hadoop / BulkOutputFormat . java b / src / java / org / apache / cassandra / hadoop / BulkOutputFormat . java 
 index f1c5f39 . . 566d5ee 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / BulkOutputFormat . java 
 + + + b / src / java / org / apache / cassandra / hadoop / BulkOutputFormat . java 
 @ @ - 22 , 6 + 22 , 7 @ @ import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 import java . util . List ; 
 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . apache . cassandra . thrift . Mutation ; 
 import org . apache . hadoop . conf . Configuration ; 
 import org . apache . hadoop . mapreduce . * ; 
 @ @ - 32 , 7 + 33 , 7 @ @ public class BulkOutputFormat extends OutputFormat < ByteBuffer , List < Mutation > > 
 @ Override 
 public void checkOutputSpecs ( JobContext context ) 
 { 
 - checkOutputSpecs ( context . getConfiguration ( ) ) ; 
 + checkOutputSpecs ( HadoopCompat . getConfiguration ( context ) ) ; 
 } 
 
 private void checkOutputSpecs ( Configuration conf ) 
 diff - - git a / src / java / org / apache / cassandra / hadoop / BulkRecordWriter . java b / src / java / org / apache / cassandra / hadoop / BulkRecordWriter . java 
 index b6a7e75 . . 28c6d2c 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / BulkRecordWriter . java 
 + + + b / src / java / org / apache / cassandra / hadoop / BulkRecordWriter . java 
 @ @ - 28 , 6 + 28 , 7 @ @ import java . util . concurrent . Future ; 
 import java . util . concurrent . TimeUnit ; 
 import java . util . concurrent . TimeoutException ; 
 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 85 , 7 + 86 , 7 @ @ implements org . apache . hadoop . mapred . RecordWriter < ByteBuffer , List < Mutation > > 
 
 BulkRecordWriter ( TaskAttemptContext context ) 
 { 
 - this ( context . getConfiguration ( ) ) ; 
 + this ( HadoopCompat . getConfiguration ( context ) ) ; 
 this . progress = new Progressable ( context ) ; 
 } 
 
 diff - - git a / src / java / org / apache / cassandra / hadoop / ColumnFamilyInputFormat . java b / src / java / org / apache / cassandra / hadoop / ColumnFamilyInputFormat . java 
 index 1b5a4e2 . . df59408 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / ColumnFamilyInputFormat . java 
 + + + b / src / java / org / apache / cassandra / hadoop / ColumnFamilyInputFormat . java 
 @ @ - 21 , 6 + 21 , 7 @ @ import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 import java . util . * ; 
 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . apache . cassandra . db . Column ; 
 import org . apache . hadoop . conf . Configuration ; 
 import org . apache . hadoop . mapred . JobConf ; 
 @ @ - 54 , 14 + 55 , 14 @ @ public class ColumnFamilyInputFormat extends AbstractColumnFamilyInputFormat < Byt 
 
 public org . apache . hadoop . mapred . RecordReader < ByteBuffer , SortedMap < ByteBuffer , Column > > getRecordReader ( org . apache . hadoop . mapred . InputSplit split , JobConf jobConf , final Reporter reporter ) throws IOException 
 { 
 - TaskAttemptContext tac = new TaskAttemptContext ( jobConf , TaskAttemptID . forName ( jobConf . get ( MAPRED _ TASK _ ID ) ) ) 
 - { 
 - @ Override 
 - public void progress ( ) 
 - { 
 - reporter . progress ( ) ; 
 - } 
 - } ; 
 + TaskAttemptContext tac = HadoopCompat . newMapContext ( 
 + jobConf , 
 + TaskAttemptID . forName ( jobConf . get ( MAPRED _ TASK _ ID ) ) , 
 + null , 
 + null , 
 + null , 
 + new ReporterWrapper ( reporter ) , 
 + null ) ; 
 
 ColumnFamilyRecordReader recordReader = new ColumnFamilyRecordReader ( jobConf . getInt ( CASSANDRA _ HADOOP _ MAX _ KEY _ SIZE , CASSANDRA _ HADOOP _ MAX _ KEY _ SIZE _ DEFAULT ) ) ; 
 recordReader . initialize ( ( org . apache . hadoop . mapreduce . InputSplit ) split , tac ) ; 
 diff - - git a / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordReader . java b / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordReader . java 
 index e33aea9 . . 22d614e 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordReader . java 
 + + + b / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordReader . java 
 @ @ - 24 , 6 + 24 , 7 @ @ import java . nio . ByteBuffer ; 
 import java . util . * ; 
 
 import com . google . common . collect . * ; 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 132 , 7 + 133 , 7 @ @ public class ColumnFamilyRecordReader extends RecordReader < ByteBuffer , SortedMap 
 public void initialize ( InputSplit split , TaskAttemptContext context ) throws IOException 
 { 
 this . split = ( ColumnFamilySplit ) split ; 
 - Configuration conf = context . getConfiguration ( ) ; 
 + Configuration conf = HadoopCompat . getConfiguration ( context ) ; 
 KeyRange jobRange = ConfigHelper . getInputKeyRange ( conf ) ; 
 filter = jobRange = = null ? null : jobRange . row _ filter ; 
 predicate = ConfigHelper . getInputSlicePredicate ( conf ) ; 
 diff - - git a / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordWriter . java b / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordWriter . java 
 index 6823342 . . 0ae2a67 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordWriter . java 
 + + + b / src / java / org / apache / cassandra / hadoop / ColumnFamilyRecordWriter . java 
 @ @ - 23 , 6 + 23 , 7 @ @ import java . net . InetAddress ; 
 import java . nio . ByteBuffer ; 
 import java . util . * ; 
 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . apache . cassandra . dht . Range ; 
 import org . apache . cassandra . dht . Token ; 
 import org . apache . cassandra . thrift . * ; 
 @ @ - 60 , 7 + 61 , 7 @ @ final class ColumnFamilyRecordWriter extends AbstractColumnFamilyRecordWriter < By 
 * / 
 ColumnFamilyRecordWriter ( TaskAttemptContext context ) 
 { 
 - this ( context . getConfiguration ( ) ) ; 
 + this ( HadoopCompat . getConfiguration ( context ) ) ; 
 this . progressable = new Progressable ( context ) ; 
 } 
 
 diff - - git a / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingInputFormat . java b / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingInputFormat . java 
 index 0e1509e . . 6f4478e 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingInputFormat . java 
 + + + b / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingInputFormat . java 
 @ @ - 21 , 7 + 21 , 9 @ @ import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 import java . util . Map ; 
 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . apache . cassandra . hadoop . AbstractColumnFamilyInputFormat ; 
 + import org . apache . cassandra . hadoop . ReporterWrapper ; 
 import org . apache . hadoop . mapred . InputSplit ; 
 import org . apache . hadoop . mapred . JobConf ; 
 import org . apache . hadoop . mapred . RecordReader ; 
 @ @ - 58 , 14 + 60 , 14 @ @ public class CqlPagingInputFormat extends AbstractColumnFamilyInputFormat < Map < St 
 public RecordReader < Map < String , ByteBuffer > , Map < String , ByteBuffer > > getRecordReader ( InputSplit split , JobConf jobConf , final Reporter reporter ) 
 throws IOException 
 { 
 - TaskAttemptContext tac = new TaskAttemptContext ( jobConf , TaskAttemptID . forName ( jobConf . get ( MAPRED _ TASK _ ID ) ) ) 
 - { 
 - @ Override 
 - public void progress ( ) 
 - { 
 - reporter . progress ( ) ; 
 - } 
 - } ; 
 + TaskAttemptContext tac = HadoopCompat . newMapContext ( 
 + jobConf , 
 + TaskAttemptID . forName ( jobConf . get ( MAPRED _ TASK _ ID ) ) , 
 + null , 
 + null , 
 + null , 
 + new ReporterWrapper ( reporter ) , 
 + null ) ; 
 
 CqlPagingRecordReader recordReader = new CqlPagingRecordReader ( ) ; 
 recordReader . initialize ( ( org . apache . hadoop . mapreduce . InputSplit ) split , tac ) ; 
 diff - - git a / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingRecordReader . java b / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingRecordReader . java 
 index d9b9a39 . . da278d8 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingRecordReader . java 
 + + + b / src / java / org / apache / cassandra / hadoop / cql3 / CqlPagingRecordReader . java 
 @ @ - 26 , 6 + 26 , 7 @ @ import java . util . * ; 
 
 import com . google . common . collect . AbstractIterator ; 
 import com . google . common . collect . Iterables ; 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 104 , 7 + 105 , 7 @ @ public class CqlPagingRecordReader extends RecordReader < Map < String , ByteBuffer > , 
 public void initialize ( InputSplit split , TaskAttemptContext context ) throws IOException 
 { 
 this . split = ( ColumnFamilySplit ) split ; 
 - Configuration conf = context . getConfiguration ( ) ; 
 + Configuration conf = HadoopCompat . getConfiguration ( context ) ; 
 totalRowCount = ( this . split . getLength ( ) < Long . MAX _ VALUE ) 
 ? ( int ) this . split . getLength ( ) 
 : ConfigHelper . getInputSplitSize ( conf ) ; 
 @ @ - 123 , 7 + 124 , 7 @ @ public class CqlPagingRecordReader extends RecordReader < Map < String , ByteBuffer > , 
 pageRowSize = DEFAULT _ CQL _ PAGE _ LIMIT ; 
 } 
 
 - partitioner = ConfigHelper . getInputPartitioner ( context . getConfiguration ( ) ) ; 
 + partitioner = ConfigHelper . getInputPartitioner ( HadoopCompat . getConfiguration ( context ) ) ; 
 
 try 
 { 
 diff - - git a / src / java / org / apache / cassandra / hadoop / cql3 / CqlRecordWriter . java b / src / java / org / apache / cassandra / hadoop / cql3 / CqlRecordWriter . java 
 index 4746f8a . . e2b90f1 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / cql3 / CqlRecordWriter . java 
 + + + b / src / java / org / apache / cassandra / hadoop / cql3 / CqlRecordWriter . java 
 @ @ - 23 , 6 + 23 , 7 @ @ import java . nio . ByteBuffer ; 
 import java . util . * ; 
 import java . util . concurrent . ConcurrentHashMap ; 
 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 84 , 7 + 85 , 7 @ @ final class CqlRecordWriter extends AbstractColumnFamilyRecordWriter < Map < String , 
 * / 
 CqlRecordWriter ( TaskAttemptContext context ) throws IOException 
 { 
 - this ( context . getConfiguration ( ) ) ; 
 + this ( HadoopCompat . getConfiguration ( context ) ) ; 
 this . progressable = new Progressable ( context ) ; 
 } 
 
 diff - - git a / src / java / org / apache / cassandra / hadoop / pig / CassandraStorage . java b / src / java / org / apache / cassandra / hadoop / pig / CassandraStorage . java 
 index aeec4a6 . . 3c34167 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / pig / CassandraStorage . java 
 + + + b / src / java / org / apache / cassandra / hadoop / pig / CassandraStorage . java 
 @ @ - 22 , 6 + 22 , 7 @ @ import java . nio . ByteBuffer ; 
 import java . nio . charset . CharacterCodingException ; 
 import java . util . * ; 
 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 282 , 7 + 283 , 7 @ @ public class CassandraStorage extends AbstractCassandraStorage 
 / * * set read configuration settings * / 
 public void setLocation ( String location , Job job ) throws IOException 
 { 
 - conf = job . getConfiguration ( ) ; 
 + conf = HadoopCompat . getConfiguration ( job ) ; 
 setLocationFromUri ( location ) ; 
 
 if ( ConfigHelper . getInputSlicePredicate ( conf ) = = null ) 
 @ @ - 339 , 7 + 340 , 7 @ @ public class CassandraStorage extends AbstractCassandraStorage 
 / * * set store configuration settings * / 
 public void setStoreLocation ( String location , Job job ) throws IOException 
 { 
 - conf = job . getConfiguration ( ) ; 
 + conf = HadoopCompat . getConfiguration ( job ) ; 
 
 / / don ' t combine mappers to a single mapper per node 
 conf . setBoolean ( " pig . noSplitCombination " , true ) ; 
 diff - - git a / src / java / org / apache / cassandra / hadoop / pig / CqlStorage . java b / src / java / org / apache / cassandra / hadoop / pig / CqlStorage . java 
 index 5fbce21 . . c6db82f 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / pig / CqlStorage . java 
 + + + b / src / java / org / apache / cassandra / hadoop / pig / CqlStorage . java 
 @ @ - 23 , 6 + 23 , 7 @ @ import java . nio . charset . CharacterCodingException ; 
 import java . util . * ; 
 
 
 + import com . twitter . elephantbird . util . HadoopCompat ; 
 import org . apache . cassandra . cql3 . CFDefinition ; 
 import org . apache . cassandra . cql3 . ColumnIdentifier ; 
 import org . apache . cassandra . db . Column ; 
 @ @ - 197 , 7 + 198 , 7 @ @ public class CqlStorage extends AbstractCassandraStorage 
 / * * set read configuration settings * / 
 public void setLocation ( String location , Job job ) throws IOException 
 { 
 - conf = job . getConfiguration ( ) ; 
 + conf = HadoopCompat . getConfiguration ( job ) ; 
 setLocationFromUri ( location ) ; 
 
 if ( username ! = null & & password ! = null ) 
 @ @ - 256 , 7 + 257 , 7 @ @ public class CqlStorage extends AbstractCassandraStorage 
 / * * set store configuration settings * / 
 public void setStoreLocation ( String location , Job job ) throws IOException 
 { 
 - conf = job . getConfiguration ( ) ; 
 + conf = HadoopCompat . getConfiguration ( job ) ; 
 setLocationFromUri ( location ) ; 
 
 if ( username ! = null & & password ! = null )

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 84db73d . . bcf56b7 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 21 , 6 + 21 , 7 @ @ 
 * fix nodetool ' s setcompactionthreshold command ( CASSANDRA - 4455 ) 
 * Ensure compacted files are never used , to avoid counter overcount ( CASSANDRA - 4436 ) 
 Merged from 1 . 0 : 
 + * Push the validation of secondary index values to the SecondaryIndexManager ( CASSANDRA - 4240 ) 
 * allow dropping columns shadowed by not - yet - expired supercolumn or row 
 tombstones in PrecompactedRow ( CASSANDRA - 4396 ) 
 * fix 1 . 0 . x node join to mixed version cluster , other nodes > = 1 . 1 ( CASSANDRA - 4195 ) 
 @ @ - 156 , 6 + 157 , 8 @ @ Merged from 1 . 0 : 
 * improve ability of STCS . getBuckets to deal with 100s of 1000s of 
 sstables , such as when convertinb back from LCS ( CASSANDRA - 4287 ) 
 * Oversize integer in CQL throws NumberFormatException ( CASSANDRA - 4291 ) 
 + * fix 1 . 0 . x node join to mixed version cluster , other nodes > = 1 . 1 ( CASSANDRA - 4195 ) 
 + * Fix LCS splitting sstable base on uncompressed size ( CASSANDRA - 4419 ) 
 
 
 1 . 1 . 0 - final 
 diff - - git a / src / java / org / apache / cassandra / db / index / PerColumnSecondaryIndex . java b / src / java / org / apache / cassandra / db / index / PerColumnSecondaryIndex . java 
 index ba7360d . . 05fa70b 100644 
 - - - a / src / java / org / apache / cassandra / db / index / PerColumnSecondaryIndex . java 
 + + + b / src / java / org / apache / cassandra / db / index / PerColumnSecondaryIndex . java 
 @ @ - 22 , 6 + 22 , 8 @ @ import java . nio . ByteBuffer ; 
 
 import org . apache . cassandra . db . DecoratedKey ; 
 import org . apache . cassandra . db . IColumn ; 
 + import org . apache . cassandra . thrift . Column ; 
 + import org . apache . cassandra . utils . FBUtilities ; 
 
 / * * 
 * Base class for Secondary indexes that implement a unique index per column 
 @ @ - 60 , 4 + 62 , 10 @ @ public abstract class PerColumnSecondaryIndex extends SecondaryIndex 
 { 
 return getIndexName ( ) ; 
 } 
 + 
 + @ Override 
 + public boolean validate ( Column column ) 
 + { 
 + return column . value . remaining ( ) < FBUtilities . MAX _ UNSIGNED _ SHORT ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / index / PerRowSecondaryIndex . java b / src / java / org / apache / cassandra / db / index / PerRowSecondaryIndex . java 
 index df5a41d . . 2b05bee 100644 
 - - - a / src / java / org / apache / cassandra / db / index / PerRowSecondaryIndex . java 
 + + + b / src / java / org / apache / cassandra / db / index / PerRowSecondaryIndex . java 
 @ @ - 26 , 6 + 26 , 7 @ @ import java . util . SortedSet ; 
 import org . apache . cassandra . db . ColumnFamily ; 
 import org . apache . cassandra . db . DecoratedKey ; 
 import org . apache . cassandra . db . IColumn ; 
 + import org . apache . cassandra . thrift . Column ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 
 / * * 
 @ @ - 70 , 4 + 71 , 10 @ @ public abstract class PerRowSecondaryIndex extends SecondaryIndex 
 throw new RuntimeException ( e ) ; 
 } 
 } 
 + 
 + @ Override 
 + public boolean validate ( Column column ) 
 + { 
 + return true ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / index / SecondaryIndex . java b / src / java / org / apache / cassandra / db / index / SecondaryIndex . java 
 index 64a696d . . 3732086 100644 
 - - - a / src / java / org / apache / cassandra / db / index / SecondaryIndex . java 
 + + + b / src / java / org / apache / cassandra / db / index / SecondaryIndex . java 
 @ @ - 31 , 6 + 31 , 7 @ @ import org . apache . cassandra . db . compaction . CompactionManager ; 
 import org . apache . cassandra . db . index . keys . KeysIndex ; 
 import org . apache . cassandra . io . sstable . ReducingKeyIterator ; 
 import org . apache . cassandra . io . sstable . SSTableReader ; 
 + import org . apache . cassandra . thrift . Column ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . apache . commons . lang . StringUtils ; 
 import org . slf4j . Logger ; 
 @ @ - 330 , 4 + 331 , 6 @ @ public abstract class SecondaryIndex 
 
 return index ; 
 } 
 + 
 + public abstract boolean validate ( Column column ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / index / SecondaryIndexManager . java b / src / java / org / apache / cassandra / db / index / SecondaryIndexManager . java 
 index ba066e2 . . e923575 100644 
 - - - a / src / java / org / apache / cassandra / db / index / SecondaryIndexManager . java 
 + + + b / src / java / org / apache / cassandra / db / index / SecondaryIndexManager . java 
 @ @ - 20 , 7 + 20 , 14 @ @ package org . apache . cassandra . db . index ; 
 import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 import java . util . * ; 
 - import java . util . concurrent . * ; 
 + import java . util . concurrent . ConcurrentNavigableMap ; 
 + import java . util . concurrent . ConcurrentSkipListMap ; 
 + import java . util . concurrent . ExecutionException ; 
 + import java . util . concurrent . Future ; 
 + 
 + import org . apache . commons . lang . StringUtils ; 
 + import org . slf4j . Logger ; 
 + import org . slf4j . LoggerFactory ; 
 
 import org . apache . cassandra . config . ColumnDefinition ; 
 import org . apache . cassandra . config . ConfigurationException ; 
 @ @ - 31 , 11 + 38 , 9 @ @ import org . apache . cassandra . dht . AbstractBounds ; 
 import org . apache . cassandra . dht . LocalToken ; 
 import org . apache . cassandra . io . sstable . ReducingKeyIterator ; 
 import org . apache . cassandra . io . sstable . SSTableReader ; 
 + import org . apache . cassandra . thrift . Column ; 
 import org . apache . cassandra . thrift . IndexExpression ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 - import org . apache . commons . lang . StringUtils ; 
 - import org . slf4j . Logger ; 
 - import org . slf4j . LoggerFactory ; 
 
 / * * 
 * Manages all the indexes associated with a given CFS 
 @ @ - 606 , 4 + 611 , 10 @ @ public class SecondaryIndexManager 
 for ( ByteBuffer colName : indexes ) 
 indexesByColumn . get ( colName ) . setIndexRemoved ( colName ) ; 
 } 
 + 
 + public boolean validate ( Column column ) 
 + { 
 + SecondaryIndex index = getIndexForColumn ( column . name ) ; 
 + return index ! = null ? index . validate ( column ) : true ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / thrift / ThriftValidation . java b / src / java / org / apache / cassandra / thrift / ThriftValidation . java 
 index a77bfb6 . . fe53060 100644 
 - - - a / src / java / org / apache / cassandra / thrift / ThriftValidation . java 
 + + + b / src / java / org / apache / cassandra / thrift / ThriftValidation . java 
 @ @ - 441 , 13 + 441 , 13 @ @ public class ThriftValidation 
 ( isSubColumn ? metadata . subcolumnComparator : metadata . comparator ) . getString ( column . name ) ) ) ; 
 } 
 
 - / / Indexed column values cannot be larger than 64K . See CASSANDRA - 3057 for more details 
 - if ( columnDef ! = null & & columnDef . getIndexType ( ) ! = null & & column . value . remaining ( ) > FBUtilities . MAX _ UNSIGNED _ SHORT ) 
 - throw new InvalidRequestException ( String . format ( " Can ' t index column value of size % d for index % s in CF % s of KS % s " , 
 - column . value . remaining ( ) , 
 - columnDef . getIndexName ( ) , 
 - metadata . cfName , 
 - metadata . ksName ) ) ; 
 + / / Indexed column values cannot be larger than 64K . See CASSANDRA - 3057 / 4240 for more details 
 + if ( ! Table . open ( metadata . ksName ) . getColumnFamilyStore ( metadata . cfName ) . indexManager . validate ( column ) ) 
 + throw new InvalidRequestException ( String . format ( " Can ' t index column value of size % d for index % s in CF % s of KS % s " , 
 + column . value . remaining ( ) , 
 + columnDef . getIndexName ( ) , 
 + metadata . cfName , 
 + metadata . ksName ) ) ; 
 } 
 
 / * * 
 diff - - git a / test / unit / org / apache / cassandra / db / SecondaryIndexColumnSizeTest . java b / test / unit / org / apache / cassandra / db / SecondaryIndexColumnSizeTest . java 
 new file mode 100644 
 index 0000000 . . 89479e9 
 - - - / dev / null 
 + + + b / test / unit / org / apache / cassandra / db / SecondaryIndexColumnSizeTest . java 
 @ @ - 0 , 0 + 1 , 215 @ @ 
 + / * 
 + * Licensed to the Apache Software Foundation ( ASF ) under one 
 + * or more contributor license agreements . See the NOTICE file 
 + * distributed with this work for additional information 
 + * regarding copyright ownership . The ASF licenses this file 
 + * to you under the Apache License , Version 2 . 0 ( the 
 + * " License " ) ; you may not use this file except in compliance 
 + * with the License . You may obtain a copy of the License at 
 + * 
 + * http : / / www . apache . org / licenses / LICENSE - 2 . 0 
 + * 
 + * Unless required by applicable law or agreed to in writing , 
 + * software distributed under the License is distributed on an 
 + * " AS IS " BASIS , WITHOUT WARRANTIES OR CONDITIONS OF ANY 
 + * KIND , either express or implied . See the License for the 
 + * specific language governing permissions and limitations 
 + * under the License . 
 + * / 
 + package org . apache . cassandra . db ; 
 + 
 + import java . io . IOException ; 
 + import java . nio . ByteBuffer ; 
 + import java . util . List ; 
 + import java . util . Set ; 
 + import java . util . SortedSet ; 
 + 
 + import org . junit . Test ; 
 + 
 + import org . apache . cassandra . config . ConfigurationException ; 
 + import org . apache . cassandra . db . index . PerColumnSecondaryIndex ; 
 + import org . apache . cassandra . db . index . PerRowSecondaryIndex ; 
 + import org . apache . cassandra . db . index . SecondaryIndexSearcher ; 
 + import org . apache . cassandra . thrift . Column ; 
 + import org . apache . cassandra . utils . ByteBufferUtil ; 
 + 
 + import static org . junit . Assert . assertFalse ; 
 + import static org . junit . Assert . assertTrue ; 
 + 
 + public class SecondaryIndexColumnSizeTest 
 + { 
 + @ Test 
 + public void test64kColumn ( ) 
 + { 
 + Column column = new Column ( ) ; 
 + column . name = ByteBufferUtil . bytes ( " test " ) ; 
 + 
 + / / a byte buffer more than 64k 
 + ByteBuffer buffer = ByteBuffer . allocate ( 1024 * 65 ) ; 
 + buffer . clear ( ) ; 
 + 
 + / / read more than 64k 
 + for ( int i = 0 ; i < 1024 * 64 / 4 + 1 ; i + + ) 
 + buffer . putInt ( 0 ) ; 
 + 
 + / / for read 
 + buffer . flip ( ) ; 
 + column . value = buffer ; 
 + 
 + MockRowIndex mockRowIndex = new MockRowIndex ( ) ; 
 + MockColumnIndex mockColumnIndex = new MockColumnIndex ( ) ; 
 + 
 + assertTrue ( mockRowIndex . validate ( column ) ) ; 
 + assertFalse ( mockColumnIndex . validate ( column ) ) ; 
 + 
 + / / test less than 64k value 
 + buffer . flip ( ) ; 
 + buffer . clear ( ) ; 
 + buffer . putInt ( 20 ) ; 
 + buffer . flip ( ) ; 
 + 
 + assertTrue ( mockRowIndex . validate ( column ) ) ; 
 + assertTrue ( mockColumnIndex . validate ( column ) ) ; 
 + } 
 + 
 + private class MockRowIndex extends PerRowSecondaryIndex 
 + { 
 + @ Override 
 + public void applyIndexUpdates ( ByteBuffer rowKey , ColumnFamily cf , SortedSet < ByteBuffer > mutatedIndexedColumns , ColumnFamily oldIndexedColumns ) throws IOException 
 + { 
 + } 
 + 
 + @ Override 
 + public void init ( ) 
 + { 
 + } 
 + 
 + @ Override 
 + public void validateOptions ( ) throws ConfigurationException 
 + { 
 + } 
 + 
 + @ Override 
 + public String getIndexName ( ) 
 + { 
 + return null ; 
 + } 
 + 
 + @ Override 
 + protected SecondaryIndexSearcher createSecondaryIndexSearcher ( Set < ByteBuffer > columns ) 
 + { 
 + return null ; 
 + } 
 + 
 + @ Override 
 + public void forceBlockingFlush ( ) throws IOException 
 + { 
 + } 
 + 
 + @ Override 
 + public long getLiveSize ( ) 
 + { 
 + return 0 ; 
 + } 
 + 
 + @ Override 
 + public ColumnFamilyStore getIndexCfs ( ) 
 + { 
 + return null ; 
 + } 
 + 
 + @ Override 
 + public void removeIndex ( ByteBuffer columnName ) throws IOException 
 + { 
 + } 
 + 
 + @ Override 
 + public void invalidate ( ) 
 + { 
 + } 
 + 
 + @ Override 
 + public void truncate ( long truncatedAt ) 
 + { 
 + } 
 + 
 + @ Override 
 + public void deleteFromIndex ( DecoratedKey < ? > key , List < IColumn > indexedColumnsInRow ) 
 + { 
 + } 
 + 
 + } 
 + 
 + 
 + private class MockColumnIndex extends PerColumnSecondaryIndex 
 + { 
 + @ Override 
 + public void init ( ) 
 + { 
 + } 
 + 
 + @ Override 
 + public void validateOptions ( ) throws ConfigurationException 
 + { 
 + } 
 + 
 + @ Override 
 + public String getIndexName ( ) 
 + { 
 + return null ; 
 + } 
 + 
 + @ Override 
 + protected SecondaryIndexSearcher createSecondaryIndexSearcher ( Set < ByteBuffer > columns ) 
 + { 
 + return null ; 
 + } 
 + 
 + @ Override 
 + public void forceBlockingFlush ( ) throws IOException 
 + { 
 + } 
 + 
 + @ Override 
 + public long getLiveSize ( ) 
 + { 
 + return 0 ; 
 + } 
 + 
 + @ Override 
 + public ColumnFamilyStore getIndexCfs ( ) 
 + { 
 + return null ; 
 + } 
 + 
 + @ Override 
 + public void removeIndex ( ByteBuffer columnName ) throws IOException 
 + { 
 + } 
 + 
 + @ Override 
 + public void invalidate ( ) 
 + { 
 + } 
 + 
 + @ Override 
 + public void truncate ( long truncatedAt ) 
 + { 
 + } 
 + 
 + @ Override 
 + public void deleteColumn ( DecoratedKey valueKey , ByteBuffer rowKey , IColumn col ) throws IOException 
 + { 
 + } 
 + 
 + @ Override 
 + public void insertColumn ( DecoratedKey valueKey , ByteBuffer rowKey , IColumn col ) throws IOException 
 + { 
 + } 
 + 
 + @ Override 
 + public void updateColumn ( DecoratedKey valueKey , ByteBuffer rowKey , IColumn col ) throws IOException 
 + { 
 + } 
 + } 
 + } 
 diff - - git a / test / unit / org / apache / cassandra / thrift / ThriftValidationTest . java b / test / unit / org / apache / cassandra / thrift / ThriftValidationTest . java 
 index 9c131f9 . . af0e668 100644 
 - - - a / test / unit / org / apache / cassandra / thrift / ThriftValidationTest . java 
 + + + b / test / unit / org / apache / cassandra / thrift / ThriftValidationTest . java 
 @ @ - 21 , 8 + 21 , 6 @ @ package org . apache . cassandra . thrift ; 
 * / 
 
 
 - import java . nio . ByteBuffer ; 
 - 
 import org . junit . Test ; 
 
 import org . apache . cassandra . SchemaLoader ; 
 @ @ - 35 , 7 + 33 , 6 @ @ import org . apache . cassandra . db . marshal . AsciiType ; 
 import org . apache . cassandra . db . marshal . UTF8Type ; 
 import org . apache . cassandra . locator . LocalStrategy ; 
 import org . apache . cassandra . locator . NetworkTopologyStrategy ; 
 - import org . apache . cassandra . utils . FBUtilities ; 
 
 public class ThriftValidationTest extends SchemaLoader 
 { 
 @ @ - 52 , 55 + 49 , 6 @ @ public class ThriftValidationTest extends SchemaLoader 
 } 
 
 @ Test 
 - public void testColumnValueSizeForIndexedColumn ( ) throws ConfigurationException , InvalidRequestException 
 - { 
 - CfDef cfDef = Schema . instance . getCFMetaData ( " Keyspace1 " , " Standard1 " ) . toThrift ( ) ; 
 - ByteBuffer columnName = AsciiType . instance . fromString ( " indexed " ) ; 
 - 
 - / / add an indexed column definition 
 - cfDef . addToColumn _ metadata ( new ColumnDef ( columnName , UTF8Type . class . getCanonicalName ( ) ) 
 - . setIndex _ type ( IndexType . KEYS ) 
 - . setIndex _ name ( " indexed _ col " ) ) ; 
 - 
 - CFMetaData metaData = CFMetaData . fromThrift ( cfDef ) ; 
 - 
 - Column column = new Column ( columnName ) 
 - . setValue ( new byte [ FBUtilities . MAX _ UNSIGNED _ SHORT + 1 ] ) 
 - . setTimestamp ( System . currentTimeMillis ( ) ) ; 
 - 
 - boolean gotException = false ; 
 - 
 - try 
 - { 
 - / / this run should throw an exception 
 - ThriftValidation . validateColumnData ( metaData , column , false ) ; 
 - } 
 - catch ( InvalidRequestException e ) 
 - { 
 - gotException = true ; 
 - } 
 - 
 - assert gotException : " expected InvalidRequestException but not received . " ; 
 - 
 - / / change value to be less than unsigned short size 
 - column . setValue ( new byte [ 12 ] ) ; 
 - 
 - gotException = false ; / / reset flag 
 - 
 - try 
 - { 
 - / / this run should run clean 
 - ThriftValidation . validateColumnData ( metaData , column , false ) ; 
 - } 
 - catch ( InvalidRequestException e ) 
 - { 
 - gotException = true ; 
 - } 
 - 
 - assert ! gotException : " got unexpected InvalidRequestException " ; 
 - } 
 - 
 - @ Test 
 public void testColumnNameEqualToKeyAlias ( ) 
 { 
 CFMetaData metaData = Schema . instance . getCFMetaData ( " Keyspace1 " , " Standard1 " ) ;
