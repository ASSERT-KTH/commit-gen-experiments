BLEU SCORE: 0.010697691669654345

TEST MSG: stream to private IP when available
GENERATED MSG: Add max _ streaming _ retries instead of relying solely on the FD .

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 544cf9a . . 4ed7bed 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 56 , 6 + 56 , 7 @ @ <nl> * Fix possible infinite loop in creating repair range ( CASSANDRA - 7983 ) <nl> * Fix unit in nodetool for streaming throughput ( CASSANDRA - 7375 ) <nl> * Do not exit nodetool repair when receiving JMX NOTIF _ LOST ( CASSANDRA - 7909 ) <nl> + * Stream to private IP when available ( CASSANDRA - 8084 ) <nl> Merged from 1 . 2 : <nl> * Don ' t index tombstones ( CASSANDRA - 7828 ) <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / SystemKeyspace . java b / src / java / org / apache / cassandra / db / SystemKeyspace . java <nl> index 5b77f63 . . 30e6d47 100644 <nl> - - - a / src / java / org / apache / cassandra / db / SystemKeyspace . java <nl> + + + b / src / java / org / apache / cassandra / db / SystemKeyspace . java <nl> @ @ - 497 , 13 + 497 , 19 @ @ public class SystemKeyspace <nl> return hostIdMap ; <nl> } <nl> <nl> + / * * <nl> + * Get preferred IP for given endpoint if it is known . Otherwise this returns given endpoint itself . <nl> + * <nl> + * @ param ep endpoint address to check <nl> + * @ return Preferred IP for given endpoint if present , otherwise returns given ep <nl> + * / <nl> public static InetAddress getPreferredIP ( InetAddress ep ) <nl> { <nl> String req = " SELECT preferred _ ip FROM system . % s WHERE peer = ' % s ' " ; <nl> UntypedResultSet result = processInternal ( String . format ( req , PEERS _ CF , ep . getHostAddress ( ) ) ) ; <nl> if ( ! result . isEmpty ( ) & & result . one ( ) . has ( " preferred _ ip " ) ) <nl> return result . one ( ) . getInetAddress ( " preferred _ ip " ) ; <nl> - return null ; <nl> + return ep ; <nl> } <nl> <nl> / * * <nl> diff - - git a / src / java / org / apache / cassandra / dht / RangeStreamer . java b / src / java / org / apache / cassandra / dht / RangeStreamer . java <nl> index 1e6d9b8 . . 4e925d3 100644 <nl> - - - a / src / java / org / apache / cassandra / dht / RangeStreamer . java <nl> + + + b / src / java / org / apache / cassandra / dht / RangeStreamer . java <nl> @ @ - 29 , 6 + 29 , 7 @ @ import org . slf4j . LoggerFactory ; <nl> <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . db . Keyspace ; <nl> + import org . apache . cassandra . db . SystemKeyspace ; <nl> import org . apache . cassandra . gms . FailureDetector ; <nl> import org . apache . cassandra . gms . IFailureDetector ; <nl> import org . apache . cassandra . locator . AbstractReplicationStrategy ; <nl> @ @ - 221 , 11 + 222 , 12 @ @ public class RangeStreamer <nl> { <nl> String keyspace = entry . getKey ( ) ; <nl> InetAddress source = entry . getValue ( ) . getKey ( ) ; <nl> + InetAddress preferred = SystemKeyspace . getPreferredIP ( source ) ; <nl> Collection < Range < Token > > ranges = entry . getValue ( ) . getValue ( ) ; <nl> / * Send messages to respective folks to stream data over to me * / <nl> if ( logger . isDebugEnabled ( ) ) <nl> logger . debug ( " " + description + " ing from " + source + " ranges " + StringUtils . join ( ranges , " , " ) ) ; <nl> - streamPlan . requestRanges ( source , keyspace , ranges ) ; <nl> + streamPlan . requestRanges ( source , preferred , keyspace , ranges ) ; <nl> } <nl> <nl> return streamPlan . execute ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / net / OutboundTcpConnectionPool . java b / src / java / org / apache / cassandra / net / OutboundTcpConnectionPool . java <nl> index c45fc53 . . 66a0362 100644 <nl> - - - a / src / java / org / apache / cassandra / net / OutboundTcpConnectionPool . java <nl> + + + b / src / java / org / apache / cassandra / net / OutboundTcpConnectionPool . java <nl> @ @ - 41 , 14 + 41 , 14 @ @ public class OutboundTcpConnectionPool <nl> private final CountDownLatch started ; <nl> public final OutboundTcpConnection cmdCon ; <nl> public final OutboundTcpConnection ackCon ; <nl> - / / pointer to the reseted Address . <nl> - private InetAddress resetedEndpoint ; <nl> + / / pointer to the reset Address . <nl> + private InetAddress resetEndpoint ; <nl> private ConnectionMetrics metrics ; <nl> <nl> OutboundTcpConnectionPool ( InetAddress remoteEp ) <nl> { <nl> id = remoteEp ; <nl> - resetedEndpoint = SystemKeyspace . getPreferredIP ( remoteEp ) ; <nl> + resetEndpoint = SystemKeyspace . getPreferredIP ( remoteEp ) ; <nl> started = new CountDownLatch ( 1 ) ; <nl> <nl> cmdCon = new OutboundTcpConnection ( this ) ; <nl> @ @ - 90 , 13 + 90 , 13 @ @ public class OutboundTcpConnectionPool <nl> public void reset ( InetAddress remoteEP ) <nl> { <nl> SystemKeyspace . updatePreferredIP ( id , remoteEP ) ; <nl> - resetedEndpoint = remoteEP ; <nl> + resetEndpoint = remoteEP ; <nl> for ( OutboundTcpConnection conn : new OutboundTcpConnection [ ] { cmdCon , ackCon } ) <nl> conn . softCloseSocket ( ) ; <nl> <nl> / / release previous metrics and create new one with reset address <nl> metrics . release ( ) ; <nl> - metrics = new ConnectionMetrics ( resetedEndpoint , this ) ; <nl> + metrics = new ConnectionMetrics ( resetEndpoint , this ) ; <nl> } <nl> <nl> public long getTimeouts ( ) <nl> @ @ - 142 , 7 + 142 , 7 @ @ public class OutboundTcpConnectionPool <nl> { <nl> if ( id . equals ( FBUtilities . getBroadcastAddress ( ) ) ) <nl> return FBUtilities . getLocalAddress ( ) ; <nl> - return resetedEndpoint = = null ? id : resetedEndpoint ; <nl> + return resetEndpoint ; <nl> } <nl> <nl> public static boolean isEncryptedChannel ( InetAddress address ) <nl> diff - - git a / src / java / org / apache / cassandra / repair / StreamingRepairTask . java b / src / java / org / apache / cassandra / repair / StreamingRepairTask . java <nl> index f7203a4 . . 4226184 100644 <nl> - - - a / src / java / org / apache / cassandra / repair / StreamingRepairTask . java <nl> + + + b / src / java / org / apache / cassandra / repair / StreamingRepairTask . java <nl> @ @ - 17 , 9 + 17 , 12 @ @ <nl> * / <nl> package org . apache . cassandra . repair ; <nl> <nl> + import java . net . InetAddress ; <nl> + <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> + import org . apache . cassandra . db . SystemKeyspace ; <nl> import org . apache . cassandra . net . MessagingService ; <nl> import org . apache . cassandra . repair . messages . SyncComplete ; <nl> import org . apache . cassandra . repair . messages . SyncRequest ; <nl> @ @ - 56 , 13 + 59 , 15 @ @ public class StreamingRepairTask implements Runnable , StreamEventHandler <nl> <nl> private void initiateStreaming ( ) <nl> { <nl> + InetAddress dest = request . dst ; <nl> + InetAddress preferred = SystemKeyspace . getPreferredIP ( dest ) ; <nl> logger . info ( String . format ( " [ streaming task # % s ] Performing streaming repair of % d ranges with % s " , desc . sessionId , request . ranges . size ( ) , request . dst ) ) ; <nl> StreamResultFuture op = new StreamPlan ( " Repair " ) <nl> . flushBeforeTransfer ( true ) <nl> / / request ranges from the remote node <nl> - . requestRanges ( request . dst , desc . keyspace , request . ranges , desc . columnFamily ) <nl> + . requestRanges ( dest , preferred , desc . keyspace , request . ranges , desc . columnFamily ) <nl> / / send ranges to the remote node <nl> - . transferRanges ( request . dst , desc . keyspace , request . ranges , desc . columnFamily ) <nl> + . transferRanges ( dest , preferred , desc . keyspace , request . ranges , desc . columnFamily ) <nl> . execute ( ) ; <nl> op . addEventListener ( this ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index 56056ab . . 4973e40 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 1890 , 11 + 1890 , 12 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> { <nl> for ( Map . Entry < InetAddress , Collection < Range < Token > > > entry : rangesToFetch . get ( keyspaceName ) ) <nl> { <nl> - final InetAddress source = entry . getKey ( ) ; <nl> + InetAddress source = entry . getKey ( ) ; <nl> + InetAddress preferred = SystemKeyspace . getPreferredIP ( source ) ; <nl> Collection < Range < Token > > ranges = entry . getValue ( ) ; <nl> if ( logger . isDebugEnabled ( ) ) <nl> logger . debug ( " Requesting from " + source + " ranges " + StringUtils . join ( ranges , " , " ) ) ; <nl> - stream . requestRanges ( source , keyspaceName , ranges ) ; <nl> + stream . requestRanges ( source , preferred , keyspaceName , ranges ) ; <nl> } <nl> } <nl> StreamResultFuture future = stream . execute ( ) ; <nl> @ @ - 3022 , 12 + 3023 , 14 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> / / stream to the closest peer as chosen by the snitch <nl> DatabaseDescriptor . getEndpointSnitch ( ) . sortByProximity ( FBUtilities . getBroadcastAddress ( ) , candidates ) ; <nl> InetAddress hintsDestinationHost = candidates . get ( 0 ) ; <nl> + InetAddress preferred = SystemKeyspace . getPreferredIP ( hintsDestinationHost ) ; <nl> <nl> / / stream all hints - - range list will be a singleton of " the entire ring " <nl> Token token = StorageService . getPartitioner ( ) . getMinimumToken ( ) ; <nl> List < Range < Token > > ranges = Collections . singletonList ( new Range < Token > ( token , token ) ) ; <nl> <nl> return new StreamPlan ( " Hints " ) . transferRanges ( hintsDestinationHost , <nl> + preferred , <nl> Keyspace . SYSTEM _ KS , <nl> ranges , <nl> SystemKeyspace . HINTS _ CF ) <nl> @ @ - 3182 , 15 + 3185 , 20 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> <nl> / / stream ranges <nl> for ( InetAddress address : endpointRanges . keySet ( ) ) <nl> - streamPlan . transferRanges ( address , keyspace , endpointRanges . get ( address ) ) ; <nl> + { <nl> + InetAddress preferred = SystemKeyspace . getPreferredIP ( address ) ; <nl> + streamPlan . transferRanges ( address , preferred , keyspace , endpointRanges . get ( address ) ) ; <nl> + } <nl> <nl> / / stream requests <nl> Multimap < InetAddress , Range < Token > > workMap = RangeStreamer . getWorkMap ( rangesToFetchWithPreferredEndpoints ) ; <nl> for ( InetAddress address : workMap . keySet ( ) ) <nl> - streamPlan . requestRanges ( address , keyspace , workMap . get ( address ) ) ; <nl> + { <nl> + InetAddress preferred = SystemKeyspace . getPreferredIP ( address ) ; <nl> + streamPlan . requestRanges ( address , preferred , keyspace , workMap . get ( address ) ) ; <nl> + } <nl> <nl> - if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " Keyspace { } : work map { } . " , keyspace , workMap ) ; <nl> + logger . debug ( " Keyspace { } : work map { } . " , keyspace , workMap ) ; <nl> } <nl> } <nl> } <nl> @ @ - 3648 , 9 + 3656 , 10 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> { <nl> final List < Range < Token > > ranges = rangesEntry . getValue ( ) ; <nl> final InetAddress newEndpoint = rangesEntry . getKey ( ) ; <nl> + final InetAddress preferred = SystemKeyspace . getPreferredIP ( newEndpoint ) ; <nl> <nl> / / TODO each call to transferRanges re - flushes , this is potentially a lot of waste <nl> - streamPlan . transferRanges ( newEndpoint , keyspaceName , ranges ) ; <nl> + streamPlan . transferRanges ( newEndpoint , preferred , keyspaceName , ranges ) ; <nl> } <nl> } <nl> return streamPlan . execute ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / streaming / SessionInfo . java b / src / java / org / apache / cassandra / streaming / SessionInfo . java <nl> index b722ecf . . 4f80461 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / SessionInfo . java <nl> + + + b / src / java / org / apache / cassandra / streaming / SessionInfo . java <nl> @ @ - 33 , 6 + 33 , 7 @ @ import com . google . common . collect . Iterables ; <nl> public final class SessionInfo implements Serializable <nl> { <nl> public final InetAddress peer ; <nl> + public final InetAddress connecting ; <nl> / * * Immutable collection of receiving summaries * / <nl> public final Collection < StreamSummary > receivingSummaries ; <nl> / * * Immutable collection of sending summaries * / <nl> @ @ - 44 , 11 + 45 , 13 @ @ public final class SessionInfo implements Serializable <nl> private final Map < String , ProgressInfo > sendingFiles ; <nl> <nl> public SessionInfo ( InetAddress peer , <nl> + InetAddress connecting , <nl> Collection < StreamSummary > receivingSummaries , <nl> Collection < StreamSummary > sendingSummaries , <nl> StreamSession . State state ) <nl> { <nl> this . peer = peer ; <nl> + this . connecting = connecting ; <nl> this . receivingSummaries = ImmutableSet . copyOf ( receivingSummaries ) ; <nl> this . sendingSummaries = ImmutableSet . copyOf ( sendingSummaries ) ; <nl> this . receivingFiles = new ConcurrentHashMap < > ( ) ; <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamPlan . java b / src / java / org / apache / cassandra / streaming / StreamPlan . java <nl> index e582c79 . . 326bf48 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamPlan . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamPlan . java <nl> @ @ - 56 , 56 + 56 , 70 @ @ public class StreamPlan <nl> * Request data in { @ code keyspace } and { @ code ranges } from specific node . <nl> * <nl> * @ param from endpoint address to fetch data from . <nl> + * @ param connecting Actual connecting address for the endpoint <nl> * @ param keyspace name of keyspace <nl> * @ param ranges ranges to fetch <nl> * @ return this object for chaining <nl> * / <nl> - public StreamPlan requestRanges ( InetAddress from , String keyspace , Collection < Range < Token > > ranges ) <nl> + public StreamPlan requestRanges ( InetAddress from , InetAddress connecting , String keyspace , Collection < Range < Token > > ranges ) <nl> { <nl> - return requestRanges ( from , keyspace , ranges , new String [ 0 ] ) ; <nl> + return requestRanges ( from , connecting , keyspace , ranges , new String [ 0 ] ) ; <nl> } <nl> <nl> / * * <nl> * Request data in { @ code columnFamilies } under { @ code keyspace } and { @ code ranges } from specific node . <nl> * <nl> * @ param from endpoint address to fetch data from . <nl> + * @ param connecting Actual connecting address for the endpoint <nl> * @ param keyspace name of keyspace <nl> * @ param ranges ranges to fetch <nl> * @ param columnFamilies specific column families <nl> * @ return this object for chaining <nl> * / <nl> - public StreamPlan requestRanges ( InetAddress from , String keyspace , Collection < Range < Token > > ranges , String . . . columnFamilies ) <nl> + public StreamPlan requestRanges ( InetAddress from , InetAddress connecting , String keyspace , Collection < Range < Token > > ranges , String . . . columnFamilies ) <nl> { <nl> - StreamSession session = getOrCreateSession ( from ) ; <nl> + StreamSession session = getOrCreateSession ( from , connecting ) ; <nl> session . addStreamRequest ( keyspace , ranges , Arrays . asList ( columnFamilies ) ) ; <nl> return this ; <nl> } <nl> <nl> / * * <nl> + * Add transfer task to send data of specific { @ code columnFamilies } under { @ code keyspace } and { @ code ranges } . <nl> + * <nl> + * @ see # transferRanges ( java . net . InetAddress , java . net . InetAddress , String , java . util . Collection , String . . . ) <nl> + * / <nl> + public StreamPlan transferRanges ( InetAddress to , String keyspace , Collection < Range < Token > > ranges , String . . . columnFamilies ) <nl> + { <nl> + return transferRanges ( to , to , keyspace , ranges , columnFamilies ) ; <nl> + } <nl> + <nl> + / * * <nl> * Add transfer task to send data of specific keyspace and ranges . <nl> * <nl> * @ param to endpoint address of receiver <nl> + * @ param connecting Actual connecting address of the endpoint <nl> * @ param keyspace name of keyspace <nl> * @ param ranges ranges to send <nl> * @ return this object for chaining <nl> * / <nl> - public StreamPlan transferRanges ( InetAddress to , String keyspace , Collection < Range < Token > > ranges ) <nl> + public StreamPlan transferRanges ( InetAddress to , InetAddress connecting , String keyspace , Collection < Range < Token > > ranges ) <nl> { <nl> - return transferRanges ( to , keyspace , ranges , new String [ 0 ] ) ; <nl> + return transferRanges ( to , connecting , keyspace , ranges , new String [ 0 ] ) ; <nl> } <nl> <nl> / * * <nl> * Add transfer task to send data of specific { @ code columnFamilies } under { @ code keyspace } and { @ code ranges } . <nl> * <nl> * @ param to endpoint address of receiver <nl> + * @ param connecting Actual connecting address of the endpoint <nl> * @ param keyspace name of keyspace <nl> * @ param ranges ranges to send <nl> * @ param columnFamilies specific column families <nl> * @ return this object for chaining <nl> * / <nl> - public StreamPlan transferRanges ( InetAddress to , String keyspace , Collection < Range < Token > > ranges , String . . . columnFamilies ) <nl> + public StreamPlan transferRanges ( InetAddress to , InetAddress connecting , String keyspace , Collection < Range < Token > > ranges , String . . . columnFamilies ) <nl> { <nl> - StreamSession session = getOrCreateSession ( to ) ; <nl> + StreamSession session = getOrCreateSession ( to , connecting ) ; <nl> session . addTransferRanges ( keyspace , ranges , Arrays . asList ( columnFamilies ) , flushBeforeTransfer ) ; <nl> return this ; <nl> } <nl> @ @ - 120 , 7 + 134 , 7 @ @ public class StreamPlan <nl> * / <nl> public StreamPlan transferFiles ( InetAddress to , Collection < StreamSession . SSTableStreamingSections > sstableDetails ) <nl> { <nl> - StreamSession session = getOrCreateSession ( to ) ; <nl> + StreamSession session = getOrCreateSession ( to , to ) ; <nl> session . addTransferFiles ( sstableDetails ) ; <nl> return this ; <nl> } <nl> @ @ - 176 , 12 + 190 , 12 @ @ public class StreamPlan <nl> return this ; <nl> } <nl> <nl> - private StreamSession getOrCreateSession ( InetAddress peer ) <nl> + private StreamSession getOrCreateSession ( InetAddress peer , InetAddress preferred ) <nl> { <nl> StreamSession session = sessions . get ( peer ) ; <nl> if ( session = = null ) <nl> { <nl> - session = new StreamSession ( peer , connectionFactory ) ; <nl> + session = new StreamSession ( peer , preferred , connectionFactory ) ; <nl> sessions . put ( peer , session ) ; <nl> } <nl> return session ; <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamResultFuture . java b / src / java / org / apache / cassandra / streaming / StreamResultFuture . java <nl> index add14f7 . . bde5934 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamResultFuture . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamResultFuture . java <nl> @ @ - 106 , 7 + 106 , 7 @ @ public final class StreamResultFuture extends AbstractFuture < StreamState > <nl> StreamResultFuture future = StreamManager . instance . getReceivingStream ( planId ) ; <nl> if ( future = = null ) <nl> { <nl> - final StreamSession session = new StreamSession ( from , null ) ; <nl> + final StreamSession session = new StreamSession ( from , socket . getInetAddress ( ) , null ) ; <nl> <nl> / / The main reason we create a StreamResultFuture on the receiving side is for JMX exposure . <nl> future = new StreamResultFuture ( planId , description , Collections . singleton ( session ) ) ; <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamSession . java b / src / java / org / apache / cassandra / streaming / StreamSession . java <nl> index 4fcbe36 . . db0c484 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamSession . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamSession . java <nl> @ @ - 70 , 7 + 70 , 7 @ @ import org . apache . cassandra . utils . Pair ; <nl> * <nl> * ( a ) This phase is started when the initiator onInitializationComplete ( ) method is called . This method sends a <nl> * PrepareMessage that includes what files / sections this node will stream to the follower <nl> - * ( stored in a StreamTranferTask , each column family has it ' s own transfer task ) and what <nl> + * ( stored in a StreamTransferTask , each column family has it ' s own transfer task ) and what <nl> * the follower needs to stream back ( StreamReceiveTask , same as above ) . If the initiator has <nl> * nothing to receive from the follower , it goes directly to its Streaming phase . Otherwise , <nl> * it waits for the follower PrepareMessage . <nl> @ @ - 117 , 7 + 117 , 15 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe <nl> / / is directly handled by the ConnectionHandler incoming and outgoing threads . <nl> private static final DebuggableThreadPoolExecutor streamExecutor = DebuggableThreadPoolExecutor . createWithFixedPoolSize ( " StreamConnectionEstablisher " , <nl> FBUtilities . getAvailableProcessors ( ) ) ; <nl> + <nl> + / * * <nl> + * Streaming endpoint . <nl> + * <nl> + * Each { @ code StreamSession } is identified by this InetAddress which is broadcast address of the node streaming . <nl> + * / <nl> public final InetAddress peer ; <nl> + / * * Actual connecting address . Can be the same as { @ linkplain # peer } . * / <nl> + public final InetAddress connecting ; <nl> <nl> / / should not be null when session is started <nl> private StreamResultFuture streamResult ; <nl> @ @ - 155 , 14 + 163 , 16 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe <nl> * Create new streaming session with the peer . <nl> * <nl> * @ param peer Address of streaming peer <nl> + * @ param connecting Actual connecting address <nl> * @ param factory is used for establishing connection <nl> * / <nl> - public StreamSession ( InetAddress peer , StreamConnectionFactory factory ) <nl> + public StreamSession ( InetAddress peer , InetAddress connecting , StreamConnectionFactory factory ) <nl> { <nl> this . peer = peer ; <nl> + this . connecting = connecting ; <nl> this . factory = factory ; <nl> this . handler = new ConnectionHandler ( this ) ; <nl> - this . metrics = StreamingMetrics . get ( peer ) ; <nl> + this . metrics = StreamingMetrics . get ( connecting ) ; <nl> } <nl> <nl> public UUID planId ( ) <nl> @ @ - 205 , 6 + 215 , 9 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe <nl> { <nl> try <nl> { <nl> + logger . info ( " [ Stream # { } ] Starting streaming to { } { } " , planId ( ) , <nl> + peer , <nl> + peer . equals ( connecting ) ? " " : " through " + connecting ) ; <nl> handler . initiate ( ) ; <nl> onInitializationComplete ( ) ; <nl> } <nl> @ @ - 219 , 7 + 232 , 7 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe <nl> public Socket createConnection ( ) throws IOException <nl> { <nl> assert factory ! = null ; <nl> - return factory . createConnection ( peer ) ; <nl> + return factory . createConnection ( connecting ) ; <nl> } <nl> <nl> / * * <nl> @ @ - 591 , 7 + 604 , 7 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe <nl> List < StreamSummary > transferSummaries = Lists . newArrayList ( ) ; <nl> for ( StreamTask transfer : transfers . values ( ) ) <nl> transferSummaries . add ( transfer . getSummary ( ) ) ; <nl> - return new SessionInfo ( peer , receivingSummaries , transferSummaries , state ) ; <nl> + return new SessionInfo ( peer , connecting , receivingSummaries , transferSummaries , state ) ; <nl> } <nl> <nl> public synchronized void taskCompleted ( StreamReceiveTask completedTask ) <nl> diff - - git a / src / java / org / apache / cassandra / streaming / management / SessionInfoCompositeData . java b / src / java / org / apache / cassandra / streaming / management / SessionInfoCompositeData . java <nl> index 658facf . . 809bc0d 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / management / SessionInfoCompositeData . java <nl> + + + b / src / java / org / apache / cassandra / streaming / management / SessionInfoCompositeData . java <nl> @ @ - 36 , 6 + 36 , 7 @ @ public class SessionInfoCompositeData <nl> { <nl> private static final String [ ] ITEM _ NAMES = new String [ ] { " planId " , <nl> " peer " , <nl> + " connecting " , <nl> " receivingSummaries " , <nl> " sendingSummaries " , <nl> " state " , <nl> @ @ - 43 , 6 + 44 , 7 @ @ public class SessionInfoCompositeData <nl> " sendingFiles " } ; <nl> private static final String [ ] ITEM _ DESCS = new String [ ] { " Plan ID " , <nl> " Session peer " , <nl> + " Connecting address " , <nl> " Summaries of receiving data " , <nl> " Summaries of sending data " , <nl> " Current session state " , <nl> @ @ - 56 , 6 + 58 , 7 @ @ public class SessionInfoCompositeData <nl> { <nl> ITEM _ TYPES = new OpenType [ ] { SimpleType . STRING , <nl> SimpleType . STRING , <nl> + SimpleType . STRING , <nl> ArrayType . getArrayType ( StreamSummaryCompositeData . COMPOSITE _ TYPE ) , <nl> ArrayType . getArrayType ( StreamSummaryCompositeData . COMPOSITE _ TYPE ) , <nl> SimpleType . STRING , <nl> @ @ - 78 , 6 + 81 , 7 @ @ public class SessionInfoCompositeData <nl> Map < String , Object > valueMap = new HashMap < > ( ) ; <nl> valueMap . put ( ITEM _ NAMES [ 0 ] , planId . toString ( ) ) ; <nl> valueMap . put ( ITEM _ NAMES [ 1 ] , sessionInfo . peer . getHostAddress ( ) ) ; <nl> + valueMap . put ( ITEM _ NAMES [ 2 ] , sessionInfo . connecting . getHostAddress ( ) ) ; <nl> Function < StreamSummary , CompositeData > fromStreamSummary = new Function < StreamSummary , CompositeData > ( ) <nl> { <nl> public CompositeData apply ( StreamSummary input ) <nl> @ @ - 85 , 9 + 89 , 9 @ @ public class SessionInfoCompositeData <nl> return StreamSummaryCompositeData . toCompositeData ( input ) ; <nl> } <nl> } ; <nl> - valueMap . put ( ITEM _ NAMES [ 2 ] , toArrayOfCompositeData ( sessionInfo . receivingSummaries , fromStreamSummary ) ) ; <nl> - valueMap . put ( ITEM _ NAMES [ 3 ] , toArrayOfCompositeData ( sessionInfo . sendingSummaries , fromStreamSummary ) ) ; <nl> - valueMap . put ( ITEM _ NAMES [ 4 ] , sessionInfo . state . name ( ) ) ; <nl> + valueMap . put ( ITEM _ NAMES [ 3 ] , toArrayOfCompositeData ( sessionInfo . receivingSummaries , fromStreamSummary ) ) ; <nl> + valueMap . put ( ITEM _ NAMES [ 4 ] , toArrayOfCompositeData ( sessionInfo . sendingSummaries , fromStreamSummary ) ) ; <nl> + valueMap . put ( ITEM _ NAMES [ 5 ] , sessionInfo . state . name ( ) ) ; <nl> Function < ProgressInfo , CompositeData > fromProgressInfo = new Function < ProgressInfo , CompositeData > ( ) <nl> { <nl> public CompositeData apply ( ProgressInfo input ) <nl> @ @ - 95 , 8 + 99 , 8 @ @ public class SessionInfoCompositeData <nl> return ProgressInfoCompositeData . toCompositeData ( planId , input ) ; <nl> } <nl> } ; <nl> - valueMap . put ( ITEM _ NAMES [ 5 ] , toArrayOfCompositeData ( sessionInfo . getReceivingFiles ( ) , fromProgressInfo ) ) ; <nl> - valueMap . put ( ITEM _ NAMES [ 6 ] , toArrayOfCompositeData ( sessionInfo . getSendingFiles ( ) , fromProgressInfo ) ) ; <nl> + valueMap . put ( ITEM _ NAMES [ 6 ] , toArrayOfCompositeData ( sessionInfo . getReceivingFiles ( ) , fromProgressInfo ) ) ; <nl> + valueMap . put ( ITEM _ NAMES [ 7 ] , toArrayOfCompositeData ( sessionInfo . getSendingFiles ( ) , fromProgressInfo ) ) ; <nl> try <nl> { <nl> return new CompositeDataSupport ( COMPOSITE _ TYPE , valueMap ) ; <nl> @ @ - 112 , 10 + 116 , 11 @ @ public class SessionInfoCompositeData <nl> assert cd . getCompositeType ( ) . equals ( COMPOSITE _ TYPE ) ; <nl> <nl> Object [ ] values = cd . getAll ( ITEM _ NAMES ) ; <nl> - InetAddress peer ; <nl> + InetAddress peer , connecting ; <nl> try <nl> { <nl> peer = InetAddress . getByName ( ( String ) values [ 1 ] ) ; <nl> + connecting = InetAddress . getByName ( ( String ) values [ 2 ] ) ; <nl> } <nl> catch ( UnknownHostException e ) <nl> { <nl> @ @ - 129 , 9 + 134 , 10 @ @ public class SessionInfoCompositeData <nl> } <nl> } ; <nl> SessionInfo info = new SessionInfo ( peer , <nl> - fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 2 ] , toStreamSummary ) , <nl> + connecting , <nl> fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 3 ] , toStreamSummary ) , <nl> - StreamSession . State . valueOf ( ( String ) values [ 4 ] ) ) ; <nl> + fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 4 ] , toStreamSummary ) , <nl> + StreamSession . State . valueOf ( ( String ) values [ 5 ] ) ) ; <nl> Function < CompositeData , ProgressInfo > toProgressInfo = new Function < CompositeData , ProgressInfo > ( ) <nl> { <nl> public ProgressInfo apply ( CompositeData input ) <nl> @ @ - 139 , 11 + 145 , 11 @ @ public class SessionInfoCompositeData <nl> return ProgressInfoCompositeData . fromCompositeData ( input ) ; <nl> } <nl> } ; <nl> - for ( ProgressInfo progress : fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 5 ] , toProgressInfo ) ) <nl> + for ( ProgressInfo progress : fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 6 ] , toProgressInfo ) ) <nl> { <nl> info . updateProgress ( progress ) ; <nl> } <nl> - for ( ProgressInfo progress : fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 6 ] , toProgressInfo ) ) <nl> + for ( ProgressInfo progress : fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 7 ] , toProgressInfo ) ) <nl> { <nl> info . updateProgress ( progress ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / tools / NodeCmd . java b / src / java / org / apache / cassandra / tools / NodeCmd . java <nl> index 27b50a7 . . d9f3607 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / NodeCmd . java <nl> + + + b / src / java / org / apache / cassandra / tools / NodeCmd . java <nl> @ @ - 706 , 7 + 706 , 13 @ @ public class NodeCmd <nl> outs . printf ( " % s % s % n " , status . description , status . planId . toString ( ) ) ; <nl> for ( SessionInfo info : status . sessions ) <nl> { <nl> - outs . printf ( " % s % n " , info . peer . toString ( ) ) ; <nl> + outs . printf ( " % s " , info . peer . toString ( ) ) ; <nl> + / / print private IP when it is used <nl> + if ( ! info . peer . equals ( info . connecting ) ) <nl> + { <nl> + outs . printf ( " ( using % s ) " , info . connecting . toString ( ) ) ; <nl> + } <nl> + outs . printf ( " % n " ) ; <nl> if ( ! info . receivingSummaries . isEmpty ( ) ) <nl> { <nl> outs . printf ( " Receiving % d files , % d bytes total % n " , info . getTotalFilesToReceive ( ) , info . getTotalSizeToReceive ( ) ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / streaming / SessionInfoTest . java b / test / unit / org / apache / cassandra / streaming / SessionInfoTest . java <nl> index 60fbf40 . . c8b6254 100644 <nl> - - - a / test / unit / org / apache / cassandra / streaming / SessionInfoTest . java <nl> + + + b / test / unit / org / apache / cassandra / streaming / SessionInfoTest . java <nl> @ @ - 46 , 7 + 46 , 7 @ @ public class SessionInfoTest <nl> } <nl> <nl> StreamSummary sending = new StreamSummary ( cfId , 10 , 100 ) ; <nl> - SessionInfo info = new SessionInfo ( local , summaries , Collections . singleton ( sending ) , StreamSession . State . PREPARING ) ; <nl> + SessionInfo info = new SessionInfo ( local , local , summaries , Collections . singleton ( sending ) , StreamSession . State . PREPARING ) ; <nl> <nl> assert info . getTotalFilesToReceive ( ) = = 45 ; <nl> assert info . getTotalFilesToSend ( ) = = 10 ; <nl> diff - - git a / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java b / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java <nl> index ce0f9d0 . . b51f75b 100644 <nl> - - - a / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java <nl> + + + b / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java <nl> @ @ - 17 , 6 + 17 , 7 @ @ <nl> * / <nl> package org . apache . cassandra . streaming ; <nl> <nl> + import java . net . InetAddress ; <nl> import java . util . ArrayList ; <nl> import java . util . List ; <nl> import java . util . concurrent . ScheduledFuture ; <nl> @ @ - 43 , 7 + 44 , 8 @ @ public class StreamTransferTaskTest extends SchemaLoader <nl> String ks = " Keyspace1 " ; <nl> String cf = " Standard1 " ; <nl> <nl> - StreamSession session = new StreamSession ( FBUtilities . getBroadcastAddress ( ) , null ) ; <nl> + InetAddress peer = FBUtilities . getBroadcastAddress ( ) ; <nl> + StreamSession session = new StreamSession ( peer , peer , null ) ; <nl> ColumnFamilyStore cfs = Keyspace . open ( ks ) . getColumnFamilyStore ( cf ) ; <nl> <nl> / / create two sstables <nl> diff - - git a / test / unit / org / apache / cassandra / streaming / StreamingTransferTest . java b / test / unit / org / apache / cassandra / streaming / StreamingTransferTest . java <nl> index 4cd578d . . d2047fc 100644 <nl> - - - a / test / unit / org / apache / cassandra / streaming / StreamingTransferTest . java <nl> + + + b / test / unit / org / apache / cassandra / streaming / StreamingTransferTest . java <nl> @ @ - 107 , 7 + 107 , 7 @ @ public class StreamingTransferTest extends SchemaLoader <nl> ranges . add ( new Range < > ( p . getToken ( ByteBufferUtil . bytes ( " key2 " ) ) , p . getMinimumToken ( ) ) ) ; <nl> <nl> StreamResultFuture futureResult = new StreamPlan ( " StreamingTransferTest " ) <nl> - . requestRanges ( LOCAL , " Keyspace2 " , ranges ) <nl> + . requestRanges ( LOCAL , LOCAL , " Keyspace2 " , ranges ) <nl> . execute ( ) ; <nl> <nl> UUID planId = futureResult . planId ;
NEAREST DIFF (one line): diff - - git a / conf / cassandra . yaml b / conf / cassandra . yaml <nl> index 4010d74 . . 866319c 100644 <nl> - - - a / conf / cassandra . yaml <nl> + + + b / conf / cassandra . yaml <nl> @ @ - 77 , 8 + 77 , 8 @ @ commitlog _ directory : / var / lib / cassandra / commitlog <nl> # <nl> # NOTE : if you reduce the size , you may not get you hottest keys loaded on startup . <nl> # <nl> - # Default value is " auto " ( min ( 5 % of Heap ( in MB ) , 100MB ) ) . Set to 0 to disable key cache . <nl> - key _ cache _ size _ in _ mb : auto <nl> + # Default value is empty to make it " auto " ( min ( 5 % of Heap ( in MB ) , 100MB ) ) . Set to 0 to disable key cache . <nl> + key _ cache _ size _ in _ mb : <nl> <nl> # Duration in seconds after which Cassandra should <nl> # safe the keys cache . Caches are saved to saved _ caches _ directory as <nl> diff - - git a / src / java / org / apache / cassandra / config / Config . java b / src / java / org / apache / cassandra / config / Config . java <nl> index 7adce69 . . b17efac 100644 <nl> - - - a / src / java / org / apache / cassandra / config / Config . java <nl> + + + b / src / java / org / apache / cassandra / config / Config . java <nl> @ @ - 126 , 7 + 126 , 7 @ @ public class Config <nl> public boolean trickle _ fsync = false ; <nl> public int trickle _ fsync _ interval _ in _ kb = 10240 ; <nl> <nl> - public String key _ cache _ size _ in _ mb = " auto " ; <nl> + public Integer key _ cache _ size _ in _ mb = null ; <nl> public int key _ cache _ save _ period = 14400 ; <nl> public int key _ cache _ keys _ to _ save = Integer . MAX _ VALUE ; <nl> <nl> diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> index 227a6a3 . . 1648d57 100644 <nl> - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> @ @ - 418 , 9 + 418 , 9 @ @ public class DatabaseDescriptor <nl> try <nl> { <nl> / / if key _ cache _ size _ in _ mb option was set to " auto " then size of the cache should be " min ( 5 % of Heap ( in MB ) , 100MB ) <nl> - keyCacheSizeInMB = " auto " . equalsIgnoreCase ( conf . key _ cache _ size _ in _ mb ) <nl> + keyCacheSizeInMB = ( conf . key _ cache _ size _ in _ mb = = null ) <nl> ? Math . min ( ( int ) ( Runtime . getRuntime ( ) . totalMemory ( ) * 0 . 05 / 1024 / 1024 ) , 100 ) <nl> - : Integer . valueOf ( conf . key _ cache _ size _ in _ mb ) ; <nl> + : conf . key _ cache _ size _ in _ mb ; <nl> <nl> if ( keyCacheSizeInMB < 0 ) <nl> throw new NumberFormatException ( ) ; / / to escape duplicating error message <nl> @ @ - 428 , 7 + 428 , 7 @ @ public class DatabaseDescriptor <nl> catch ( NumberFormatException e ) <nl> { <nl> throw new ConfigurationException ( " key _ cache _ size _ in _ mb option was set incorrectly to ' " <nl> - + conf . key _ cache _ size _ in _ mb + " ' , supported values are ' auto ' and < integer > > = 0 . " ) ; <nl> + + conf . key _ cache _ size _ in _ mb + " ' , supported values are < integer > > = 0 . " ) ; <nl> } <nl> <nl> rowCacheProvider = FBUtilities . newCacheProvider ( conf . row _ cache _ provider ) ;

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 544cf9a . . 4ed7bed 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 56 , 6 + 56 , 7 @ @ 
 * Fix possible infinite loop in creating repair range ( CASSANDRA - 7983 ) 
 * Fix unit in nodetool for streaming throughput ( CASSANDRA - 7375 ) 
 * Do not exit nodetool repair when receiving JMX NOTIF _ LOST ( CASSANDRA - 7909 ) 
 + * Stream to private IP when available ( CASSANDRA - 8084 ) 
 Merged from 1 . 2 : 
 * Don ' t index tombstones ( CASSANDRA - 7828 ) 
 
 diff - - git a / src / java / org / apache / cassandra / db / SystemKeyspace . java b / src / java / org / apache / cassandra / db / SystemKeyspace . java 
 index 5b77f63 . . 30e6d47 100644 
 - - - a / src / java / org / apache / cassandra / db / SystemKeyspace . java 
 + + + b / src / java / org / apache / cassandra / db / SystemKeyspace . java 
 @ @ - 497 , 13 + 497 , 19 @ @ public class SystemKeyspace 
 return hostIdMap ; 
 } 
 
 + / * * 
 + * Get preferred IP for given endpoint if it is known . Otherwise this returns given endpoint itself . 
 + * 
 + * @ param ep endpoint address to check 
 + * @ return Preferred IP for given endpoint if present , otherwise returns given ep 
 + * / 
 public static InetAddress getPreferredIP ( InetAddress ep ) 
 { 
 String req = " SELECT preferred _ ip FROM system . % s WHERE peer = ' % s ' " ; 
 UntypedResultSet result = processInternal ( String . format ( req , PEERS _ CF , ep . getHostAddress ( ) ) ) ; 
 if ( ! result . isEmpty ( ) & & result . one ( ) . has ( " preferred _ ip " ) ) 
 return result . one ( ) . getInetAddress ( " preferred _ ip " ) ; 
 - return null ; 
 + return ep ; 
 } 
 
 / * * 
 diff - - git a / src / java / org / apache / cassandra / dht / RangeStreamer . java b / src / java / org / apache / cassandra / dht / RangeStreamer . java 
 index 1e6d9b8 . . 4e925d3 100644 
 - - - a / src / java / org / apache / cassandra / dht / RangeStreamer . java 
 + + + b / src / java / org / apache / cassandra / dht / RangeStreamer . java 
 @ @ - 29 , 6 + 29 , 7 @ @ import org . slf4j . LoggerFactory ; 
 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . db . Keyspace ; 
 + import org . apache . cassandra . db . SystemKeyspace ; 
 import org . apache . cassandra . gms . FailureDetector ; 
 import org . apache . cassandra . gms . IFailureDetector ; 
 import org . apache . cassandra . locator . AbstractReplicationStrategy ; 
 @ @ - 221 , 11 + 222 , 12 @ @ public class RangeStreamer 
 { 
 String keyspace = entry . getKey ( ) ; 
 InetAddress source = entry . getValue ( ) . getKey ( ) ; 
 + InetAddress preferred = SystemKeyspace . getPreferredIP ( source ) ; 
 Collection < Range < Token > > ranges = entry . getValue ( ) . getValue ( ) ; 
 / * Send messages to respective folks to stream data over to me * / 
 if ( logger . isDebugEnabled ( ) ) 
 logger . debug ( " " + description + " ing from " + source + " ranges " + StringUtils . join ( ranges , " , " ) ) ; 
 - streamPlan . requestRanges ( source , keyspace , ranges ) ; 
 + streamPlan . requestRanges ( source , preferred , keyspace , ranges ) ; 
 } 
 
 return streamPlan . execute ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / net / OutboundTcpConnectionPool . java b / src / java / org / apache / cassandra / net / OutboundTcpConnectionPool . java 
 index c45fc53 . . 66a0362 100644 
 - - - a / src / java / org / apache / cassandra / net / OutboundTcpConnectionPool . java 
 + + + b / src / java / org / apache / cassandra / net / OutboundTcpConnectionPool . java 
 @ @ - 41 , 14 + 41 , 14 @ @ public class OutboundTcpConnectionPool 
 private final CountDownLatch started ; 
 public final OutboundTcpConnection cmdCon ; 
 public final OutboundTcpConnection ackCon ; 
 - / / pointer to the reseted Address . 
 - private InetAddress resetedEndpoint ; 
 + / / pointer to the reset Address . 
 + private InetAddress resetEndpoint ; 
 private ConnectionMetrics metrics ; 
 
 OutboundTcpConnectionPool ( InetAddress remoteEp ) 
 { 
 id = remoteEp ; 
 - resetedEndpoint = SystemKeyspace . getPreferredIP ( remoteEp ) ; 
 + resetEndpoint = SystemKeyspace . getPreferredIP ( remoteEp ) ; 
 started = new CountDownLatch ( 1 ) ; 
 
 cmdCon = new OutboundTcpConnection ( this ) ; 
 @ @ - 90 , 13 + 90 , 13 @ @ public class OutboundTcpConnectionPool 
 public void reset ( InetAddress remoteEP ) 
 { 
 SystemKeyspace . updatePreferredIP ( id , remoteEP ) ; 
 - resetedEndpoint = remoteEP ; 
 + resetEndpoint = remoteEP ; 
 for ( OutboundTcpConnection conn : new OutboundTcpConnection [ ] { cmdCon , ackCon } ) 
 conn . softCloseSocket ( ) ; 
 
 / / release previous metrics and create new one with reset address 
 metrics . release ( ) ; 
 - metrics = new ConnectionMetrics ( resetedEndpoint , this ) ; 
 + metrics = new ConnectionMetrics ( resetEndpoint , this ) ; 
 } 
 
 public long getTimeouts ( ) 
 @ @ - 142 , 7 + 142 , 7 @ @ public class OutboundTcpConnectionPool 
 { 
 if ( id . equals ( FBUtilities . getBroadcastAddress ( ) ) ) 
 return FBUtilities . getLocalAddress ( ) ; 
 - return resetedEndpoint = = null ? id : resetedEndpoint ; 
 + return resetEndpoint ; 
 } 
 
 public static boolean isEncryptedChannel ( InetAddress address ) 
 diff - - git a / src / java / org / apache / cassandra / repair / StreamingRepairTask . java b / src / java / org / apache / cassandra / repair / StreamingRepairTask . java 
 index f7203a4 . . 4226184 100644 
 - - - a / src / java / org / apache / cassandra / repair / StreamingRepairTask . java 
 + + + b / src / java / org / apache / cassandra / repair / StreamingRepairTask . java 
 @ @ - 17 , 9 + 17 , 12 @ @ 
 * / 
 package org . apache . cassandra . repair ; 
 
 + import java . net . InetAddress ; 
 + 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 + import org . apache . cassandra . db . SystemKeyspace ; 
 import org . apache . cassandra . net . MessagingService ; 
 import org . apache . cassandra . repair . messages . SyncComplete ; 
 import org . apache . cassandra . repair . messages . SyncRequest ; 
 @ @ - 56 , 13 + 59 , 15 @ @ public class StreamingRepairTask implements Runnable , StreamEventHandler 
 
 private void initiateStreaming ( ) 
 { 
 + InetAddress dest = request . dst ; 
 + InetAddress preferred = SystemKeyspace . getPreferredIP ( dest ) ; 
 logger . info ( String . format ( " [ streaming task # % s ] Performing streaming repair of % d ranges with % s " , desc . sessionId , request . ranges . size ( ) , request . dst ) ) ; 
 StreamResultFuture op = new StreamPlan ( " Repair " ) 
 . flushBeforeTransfer ( true ) 
 / / request ranges from the remote node 
 - . requestRanges ( request . dst , desc . keyspace , request . ranges , desc . columnFamily ) 
 + . requestRanges ( dest , preferred , desc . keyspace , request . ranges , desc . columnFamily ) 
 / / send ranges to the remote node 
 - . transferRanges ( request . dst , desc . keyspace , request . ranges , desc . columnFamily ) 
 + . transferRanges ( dest , preferred , desc . keyspace , request . ranges , desc . columnFamily ) 
 . execute ( ) ; 
 op . addEventListener ( this ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index 56056ab . . 4973e40 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 1890 , 11 + 1890 , 12 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 { 
 for ( Map . Entry < InetAddress , Collection < Range < Token > > > entry : rangesToFetch . get ( keyspaceName ) ) 
 { 
 - final InetAddress source = entry . getKey ( ) ; 
 + InetAddress source = entry . getKey ( ) ; 
 + InetAddress preferred = SystemKeyspace . getPreferredIP ( source ) ; 
 Collection < Range < Token > > ranges = entry . getValue ( ) ; 
 if ( logger . isDebugEnabled ( ) ) 
 logger . debug ( " Requesting from " + source + " ranges " + StringUtils . join ( ranges , " , " ) ) ; 
 - stream . requestRanges ( source , keyspaceName , ranges ) ; 
 + stream . requestRanges ( source , preferred , keyspaceName , ranges ) ; 
 } 
 } 
 StreamResultFuture future = stream . execute ( ) ; 
 @ @ - 3022 , 12 + 3023 , 14 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 / / stream to the closest peer as chosen by the snitch 
 DatabaseDescriptor . getEndpointSnitch ( ) . sortByProximity ( FBUtilities . getBroadcastAddress ( ) , candidates ) ; 
 InetAddress hintsDestinationHost = candidates . get ( 0 ) ; 
 + InetAddress preferred = SystemKeyspace . getPreferredIP ( hintsDestinationHost ) ; 
 
 / / stream all hints - - range list will be a singleton of " the entire ring " 
 Token token = StorageService . getPartitioner ( ) . getMinimumToken ( ) ; 
 List < Range < Token > > ranges = Collections . singletonList ( new Range < Token > ( token , token ) ) ; 
 
 return new StreamPlan ( " Hints " ) . transferRanges ( hintsDestinationHost , 
 + preferred , 
 Keyspace . SYSTEM _ KS , 
 ranges , 
 SystemKeyspace . HINTS _ CF ) 
 @ @ - 3182 , 15 + 3185 , 20 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 
 / / stream ranges 
 for ( InetAddress address : endpointRanges . keySet ( ) ) 
 - streamPlan . transferRanges ( address , keyspace , endpointRanges . get ( address ) ) ; 
 + { 
 + InetAddress preferred = SystemKeyspace . getPreferredIP ( address ) ; 
 + streamPlan . transferRanges ( address , preferred , keyspace , endpointRanges . get ( address ) ) ; 
 + } 
 
 / / stream requests 
 Multimap < InetAddress , Range < Token > > workMap = RangeStreamer . getWorkMap ( rangesToFetchWithPreferredEndpoints ) ; 
 for ( InetAddress address : workMap . keySet ( ) ) 
 - streamPlan . requestRanges ( address , keyspace , workMap . get ( address ) ) ; 
 + { 
 + InetAddress preferred = SystemKeyspace . getPreferredIP ( address ) ; 
 + streamPlan . requestRanges ( address , preferred , keyspace , workMap . get ( address ) ) ; 
 + } 
 
 - if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " Keyspace { } : work map { } . " , keyspace , workMap ) ; 
 + logger . debug ( " Keyspace { } : work map { } . " , keyspace , workMap ) ; 
 } 
 } 
 } 
 @ @ - 3648 , 9 + 3656 , 10 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 { 
 final List < Range < Token > > ranges = rangesEntry . getValue ( ) ; 
 final InetAddress newEndpoint = rangesEntry . getKey ( ) ; 
 + final InetAddress preferred = SystemKeyspace . getPreferredIP ( newEndpoint ) ; 
 
 / / TODO each call to transferRanges re - flushes , this is potentially a lot of waste 
 - streamPlan . transferRanges ( newEndpoint , keyspaceName , ranges ) ; 
 + streamPlan . transferRanges ( newEndpoint , preferred , keyspaceName , ranges ) ; 
 } 
 } 
 return streamPlan . execute ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / streaming / SessionInfo . java b / src / java / org / apache / cassandra / streaming / SessionInfo . java 
 index b722ecf . . 4f80461 100644 
 - - - a / src / java / org / apache / cassandra / streaming / SessionInfo . java 
 + + + b / src / java / org / apache / cassandra / streaming / SessionInfo . java 
 @ @ - 33 , 6 + 33 , 7 @ @ import com . google . common . collect . Iterables ; 
 public final class SessionInfo implements Serializable 
 { 
 public final InetAddress peer ; 
 + public final InetAddress connecting ; 
 / * * Immutable collection of receiving summaries * / 
 public final Collection < StreamSummary > receivingSummaries ; 
 / * * Immutable collection of sending summaries * / 
 @ @ - 44 , 11 + 45 , 13 @ @ public final class SessionInfo implements Serializable 
 private final Map < String , ProgressInfo > sendingFiles ; 
 
 public SessionInfo ( InetAddress peer , 
 + InetAddress connecting , 
 Collection < StreamSummary > receivingSummaries , 
 Collection < StreamSummary > sendingSummaries , 
 StreamSession . State state ) 
 { 
 this . peer = peer ; 
 + this . connecting = connecting ; 
 this . receivingSummaries = ImmutableSet . copyOf ( receivingSummaries ) ; 
 this . sendingSummaries = ImmutableSet . copyOf ( sendingSummaries ) ; 
 this . receivingFiles = new ConcurrentHashMap < > ( ) ; 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamPlan . java b / src / java / org / apache / cassandra / streaming / StreamPlan . java 
 index e582c79 . . 326bf48 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamPlan . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamPlan . java 
 @ @ - 56 , 56 + 56 , 70 @ @ public class StreamPlan 
 * Request data in { @ code keyspace } and { @ code ranges } from specific node . 
 * 
 * @ param from endpoint address to fetch data from . 
 + * @ param connecting Actual connecting address for the endpoint 
 * @ param keyspace name of keyspace 
 * @ param ranges ranges to fetch 
 * @ return this object for chaining 
 * / 
 - public StreamPlan requestRanges ( InetAddress from , String keyspace , Collection < Range < Token > > ranges ) 
 + public StreamPlan requestRanges ( InetAddress from , InetAddress connecting , String keyspace , Collection < Range < Token > > ranges ) 
 { 
 - return requestRanges ( from , keyspace , ranges , new String [ 0 ] ) ; 
 + return requestRanges ( from , connecting , keyspace , ranges , new String [ 0 ] ) ; 
 } 
 
 / * * 
 * Request data in { @ code columnFamilies } under { @ code keyspace } and { @ code ranges } from specific node . 
 * 
 * @ param from endpoint address to fetch data from . 
 + * @ param connecting Actual connecting address for the endpoint 
 * @ param keyspace name of keyspace 
 * @ param ranges ranges to fetch 
 * @ param columnFamilies specific column families 
 * @ return this object for chaining 
 * / 
 - public StreamPlan requestRanges ( InetAddress from , String keyspace , Collection < Range < Token > > ranges , String . . . columnFamilies ) 
 + public StreamPlan requestRanges ( InetAddress from , InetAddress connecting , String keyspace , Collection < Range < Token > > ranges , String . . . columnFamilies ) 
 { 
 - StreamSession session = getOrCreateSession ( from ) ; 
 + StreamSession session = getOrCreateSession ( from , connecting ) ; 
 session . addStreamRequest ( keyspace , ranges , Arrays . asList ( columnFamilies ) ) ; 
 return this ; 
 } 
 
 / * * 
 + * Add transfer task to send data of specific { @ code columnFamilies } under { @ code keyspace } and { @ code ranges } . 
 + * 
 + * @ see # transferRanges ( java . net . InetAddress , java . net . InetAddress , String , java . util . Collection , String . . . ) 
 + * / 
 + public StreamPlan transferRanges ( InetAddress to , String keyspace , Collection < Range < Token > > ranges , String . . . columnFamilies ) 
 + { 
 + return transferRanges ( to , to , keyspace , ranges , columnFamilies ) ; 
 + } 
 + 
 + / * * 
 * Add transfer task to send data of specific keyspace and ranges . 
 * 
 * @ param to endpoint address of receiver 
 + * @ param connecting Actual connecting address of the endpoint 
 * @ param keyspace name of keyspace 
 * @ param ranges ranges to send 
 * @ return this object for chaining 
 * / 
 - public StreamPlan transferRanges ( InetAddress to , String keyspace , Collection < Range < Token > > ranges ) 
 + public StreamPlan transferRanges ( InetAddress to , InetAddress connecting , String keyspace , Collection < Range < Token > > ranges ) 
 { 
 - return transferRanges ( to , keyspace , ranges , new String [ 0 ] ) ; 
 + return transferRanges ( to , connecting , keyspace , ranges , new String [ 0 ] ) ; 
 } 
 
 / * * 
 * Add transfer task to send data of specific { @ code columnFamilies } under { @ code keyspace } and { @ code ranges } . 
 * 
 * @ param to endpoint address of receiver 
 + * @ param connecting Actual connecting address of the endpoint 
 * @ param keyspace name of keyspace 
 * @ param ranges ranges to send 
 * @ param columnFamilies specific column families 
 * @ return this object for chaining 
 * / 
 - public StreamPlan transferRanges ( InetAddress to , String keyspace , Collection < Range < Token > > ranges , String . . . columnFamilies ) 
 + public StreamPlan transferRanges ( InetAddress to , InetAddress connecting , String keyspace , Collection < Range < Token > > ranges , String . . . columnFamilies ) 
 { 
 - StreamSession session = getOrCreateSession ( to ) ; 
 + StreamSession session = getOrCreateSession ( to , connecting ) ; 
 session . addTransferRanges ( keyspace , ranges , Arrays . asList ( columnFamilies ) , flushBeforeTransfer ) ; 
 return this ; 
 } 
 @ @ - 120 , 7 + 134 , 7 @ @ public class StreamPlan 
 * / 
 public StreamPlan transferFiles ( InetAddress to , Collection < StreamSession . SSTableStreamingSections > sstableDetails ) 
 { 
 - StreamSession session = getOrCreateSession ( to ) ; 
 + StreamSession session = getOrCreateSession ( to , to ) ; 
 session . addTransferFiles ( sstableDetails ) ; 
 return this ; 
 } 
 @ @ - 176 , 12 + 190 , 12 @ @ public class StreamPlan 
 return this ; 
 } 
 
 - private StreamSession getOrCreateSession ( InetAddress peer ) 
 + private StreamSession getOrCreateSession ( InetAddress peer , InetAddress preferred ) 
 { 
 StreamSession session = sessions . get ( peer ) ; 
 if ( session = = null ) 
 { 
 - session = new StreamSession ( peer , connectionFactory ) ; 
 + session = new StreamSession ( peer , preferred , connectionFactory ) ; 
 sessions . put ( peer , session ) ; 
 } 
 return session ; 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamResultFuture . java b / src / java / org / apache / cassandra / streaming / StreamResultFuture . java 
 index add14f7 . . bde5934 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamResultFuture . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamResultFuture . java 
 @ @ - 106 , 7 + 106 , 7 @ @ public final class StreamResultFuture extends AbstractFuture < StreamState > 
 StreamResultFuture future = StreamManager . instance . getReceivingStream ( planId ) ; 
 if ( future = = null ) 
 { 
 - final StreamSession session = new StreamSession ( from , null ) ; 
 + final StreamSession session = new StreamSession ( from , socket . getInetAddress ( ) , null ) ; 
 
 / / The main reason we create a StreamResultFuture on the receiving side is for JMX exposure . 
 future = new StreamResultFuture ( planId , description , Collections . singleton ( session ) ) ; 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamSession . java b / src / java / org / apache / cassandra / streaming / StreamSession . java 
 index 4fcbe36 . . db0c484 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamSession . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamSession . java 
 @ @ - 70 , 7 + 70 , 7 @ @ import org . apache . cassandra . utils . Pair ; 
 * 
 * ( a ) This phase is started when the initiator onInitializationComplete ( ) method is called . This method sends a 
 * PrepareMessage that includes what files / sections this node will stream to the follower 
 - * ( stored in a StreamTranferTask , each column family has it ' s own transfer task ) and what 
 + * ( stored in a StreamTransferTask , each column family has it ' s own transfer task ) and what 
 * the follower needs to stream back ( StreamReceiveTask , same as above ) . If the initiator has 
 * nothing to receive from the follower , it goes directly to its Streaming phase . Otherwise , 
 * it waits for the follower PrepareMessage . 
 @ @ - 117 , 7 + 117 , 15 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe 
 / / is directly handled by the ConnectionHandler incoming and outgoing threads . 
 private static final DebuggableThreadPoolExecutor streamExecutor = DebuggableThreadPoolExecutor . createWithFixedPoolSize ( " StreamConnectionEstablisher " , 
 FBUtilities . getAvailableProcessors ( ) ) ; 
 + 
 + / * * 
 + * Streaming endpoint . 
 + * 
 + * Each { @ code StreamSession } is identified by this InetAddress which is broadcast address of the node streaming . 
 + * / 
 public final InetAddress peer ; 
 + / * * Actual connecting address . Can be the same as { @ linkplain # peer } . * / 
 + public final InetAddress connecting ; 
 
 / / should not be null when session is started 
 private StreamResultFuture streamResult ; 
 @ @ - 155 , 14 + 163 , 16 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe 
 * Create new streaming session with the peer . 
 * 
 * @ param peer Address of streaming peer 
 + * @ param connecting Actual connecting address 
 * @ param factory is used for establishing connection 
 * / 
 - public StreamSession ( InetAddress peer , StreamConnectionFactory factory ) 
 + public StreamSession ( InetAddress peer , InetAddress connecting , StreamConnectionFactory factory ) 
 { 
 this . peer = peer ; 
 + this . connecting = connecting ; 
 this . factory = factory ; 
 this . handler = new ConnectionHandler ( this ) ; 
 - this . metrics = StreamingMetrics . get ( peer ) ; 
 + this . metrics = StreamingMetrics . get ( connecting ) ; 
 } 
 
 public UUID planId ( ) 
 @ @ - 205 , 6 + 215 , 9 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe 
 { 
 try 
 { 
 + logger . info ( " [ Stream # { } ] Starting streaming to { } { } " , planId ( ) , 
 + peer , 
 + peer . equals ( connecting ) ? " " : " through " + connecting ) ; 
 handler . initiate ( ) ; 
 onInitializationComplete ( ) ; 
 } 
 @ @ - 219 , 7 + 232 , 7 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe 
 public Socket createConnection ( ) throws IOException 
 { 
 assert factory ! = null ; 
 - return factory . createConnection ( peer ) ; 
 + return factory . createConnection ( connecting ) ; 
 } 
 
 / * * 
 @ @ - 591 , 7 + 604 , 7 @ @ public class StreamSession implements IEndpointStateChangeSubscriber , IFailureDe 
 List < StreamSummary > transferSummaries = Lists . newArrayList ( ) ; 
 for ( StreamTask transfer : transfers . values ( ) ) 
 transferSummaries . add ( transfer . getSummary ( ) ) ; 
 - return new SessionInfo ( peer , receivingSummaries , transferSummaries , state ) ; 
 + return new SessionInfo ( peer , connecting , receivingSummaries , transferSummaries , state ) ; 
 } 
 
 public synchronized void taskCompleted ( StreamReceiveTask completedTask ) 
 diff - - git a / src / java / org / apache / cassandra / streaming / management / SessionInfoCompositeData . java b / src / java / org / apache / cassandra / streaming / management / SessionInfoCompositeData . java 
 index 658facf . . 809bc0d 100644 
 - - - a / src / java / org / apache / cassandra / streaming / management / SessionInfoCompositeData . java 
 + + + b / src / java / org / apache / cassandra / streaming / management / SessionInfoCompositeData . java 
 @ @ - 36 , 6 + 36 , 7 @ @ public class SessionInfoCompositeData 
 { 
 private static final String [ ] ITEM _ NAMES = new String [ ] { " planId " , 
 " peer " , 
 + " connecting " , 
 " receivingSummaries " , 
 " sendingSummaries " , 
 " state " , 
 @ @ - 43 , 6 + 44 , 7 @ @ public class SessionInfoCompositeData 
 " sendingFiles " } ; 
 private static final String [ ] ITEM _ DESCS = new String [ ] { " Plan ID " , 
 " Session peer " , 
 + " Connecting address " , 
 " Summaries of receiving data " , 
 " Summaries of sending data " , 
 " Current session state " , 
 @ @ - 56 , 6 + 58 , 7 @ @ public class SessionInfoCompositeData 
 { 
 ITEM _ TYPES = new OpenType [ ] { SimpleType . STRING , 
 SimpleType . STRING , 
 + SimpleType . STRING , 
 ArrayType . getArrayType ( StreamSummaryCompositeData . COMPOSITE _ TYPE ) , 
 ArrayType . getArrayType ( StreamSummaryCompositeData . COMPOSITE _ TYPE ) , 
 SimpleType . STRING , 
 @ @ - 78 , 6 + 81 , 7 @ @ public class SessionInfoCompositeData 
 Map < String , Object > valueMap = new HashMap < > ( ) ; 
 valueMap . put ( ITEM _ NAMES [ 0 ] , planId . toString ( ) ) ; 
 valueMap . put ( ITEM _ NAMES [ 1 ] , sessionInfo . peer . getHostAddress ( ) ) ; 
 + valueMap . put ( ITEM _ NAMES [ 2 ] , sessionInfo . connecting . getHostAddress ( ) ) ; 
 Function < StreamSummary , CompositeData > fromStreamSummary = new Function < StreamSummary , CompositeData > ( ) 
 { 
 public CompositeData apply ( StreamSummary input ) 
 @ @ - 85 , 9 + 89 , 9 @ @ public class SessionInfoCompositeData 
 return StreamSummaryCompositeData . toCompositeData ( input ) ; 
 } 
 } ; 
 - valueMap . put ( ITEM _ NAMES [ 2 ] , toArrayOfCompositeData ( sessionInfo . receivingSummaries , fromStreamSummary ) ) ; 
 - valueMap . put ( ITEM _ NAMES [ 3 ] , toArrayOfCompositeData ( sessionInfo . sendingSummaries , fromStreamSummary ) ) ; 
 - valueMap . put ( ITEM _ NAMES [ 4 ] , sessionInfo . state . name ( ) ) ; 
 + valueMap . put ( ITEM _ NAMES [ 3 ] , toArrayOfCompositeData ( sessionInfo . receivingSummaries , fromStreamSummary ) ) ; 
 + valueMap . put ( ITEM _ NAMES [ 4 ] , toArrayOfCompositeData ( sessionInfo . sendingSummaries , fromStreamSummary ) ) ; 
 + valueMap . put ( ITEM _ NAMES [ 5 ] , sessionInfo . state . name ( ) ) ; 
 Function < ProgressInfo , CompositeData > fromProgressInfo = new Function < ProgressInfo , CompositeData > ( ) 
 { 
 public CompositeData apply ( ProgressInfo input ) 
 @ @ - 95 , 8 + 99 , 8 @ @ public class SessionInfoCompositeData 
 return ProgressInfoCompositeData . toCompositeData ( planId , input ) ; 
 } 
 } ; 
 - valueMap . put ( ITEM _ NAMES [ 5 ] , toArrayOfCompositeData ( sessionInfo . getReceivingFiles ( ) , fromProgressInfo ) ) ; 
 - valueMap . put ( ITEM _ NAMES [ 6 ] , toArrayOfCompositeData ( sessionInfo . getSendingFiles ( ) , fromProgressInfo ) ) ; 
 + valueMap . put ( ITEM _ NAMES [ 6 ] , toArrayOfCompositeData ( sessionInfo . getReceivingFiles ( ) , fromProgressInfo ) ) ; 
 + valueMap . put ( ITEM _ NAMES [ 7 ] , toArrayOfCompositeData ( sessionInfo . getSendingFiles ( ) , fromProgressInfo ) ) ; 
 try 
 { 
 return new CompositeDataSupport ( COMPOSITE _ TYPE , valueMap ) ; 
 @ @ - 112 , 10 + 116 , 11 @ @ public class SessionInfoCompositeData 
 assert cd . getCompositeType ( ) . equals ( COMPOSITE _ TYPE ) ; 
 
 Object [ ] values = cd . getAll ( ITEM _ NAMES ) ; 
 - InetAddress peer ; 
 + InetAddress peer , connecting ; 
 try 
 { 
 peer = InetAddress . getByName ( ( String ) values [ 1 ] ) ; 
 + connecting = InetAddress . getByName ( ( String ) values [ 2 ] ) ; 
 } 
 catch ( UnknownHostException e ) 
 { 
 @ @ - 129 , 9 + 134 , 10 @ @ public class SessionInfoCompositeData 
 } 
 } ; 
 SessionInfo info = new SessionInfo ( peer , 
 - fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 2 ] , toStreamSummary ) , 
 + connecting , 
 fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 3 ] , toStreamSummary ) , 
 - StreamSession . State . valueOf ( ( String ) values [ 4 ] ) ) ; 
 + fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 4 ] , toStreamSummary ) , 
 + StreamSession . State . valueOf ( ( String ) values [ 5 ] ) ) ; 
 Function < CompositeData , ProgressInfo > toProgressInfo = new Function < CompositeData , ProgressInfo > ( ) 
 { 
 public ProgressInfo apply ( CompositeData input ) 
 @ @ - 139 , 11 + 145 , 11 @ @ public class SessionInfoCompositeData 
 return ProgressInfoCompositeData . fromCompositeData ( input ) ; 
 } 
 } ; 
 - for ( ProgressInfo progress : fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 5 ] , toProgressInfo ) ) 
 + for ( ProgressInfo progress : fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 6 ] , toProgressInfo ) ) 
 { 
 info . updateProgress ( progress ) ; 
 } 
 - for ( ProgressInfo progress : fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 6 ] , toProgressInfo ) ) 
 + for ( ProgressInfo progress : fromArrayOfCompositeData ( ( CompositeData [ ] ) values [ 7 ] , toProgressInfo ) ) 
 { 
 info . updateProgress ( progress ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / tools / NodeCmd . java b / src / java / org / apache / cassandra / tools / NodeCmd . java 
 index 27b50a7 . . d9f3607 100644 
 - - - a / src / java / org / apache / cassandra / tools / NodeCmd . java 
 + + + b / src / java / org / apache / cassandra / tools / NodeCmd . java 
 @ @ - 706 , 7 + 706 , 13 @ @ public class NodeCmd 
 outs . printf ( " % s % s % n " , status . description , status . planId . toString ( ) ) ; 
 for ( SessionInfo info : status . sessions ) 
 { 
 - outs . printf ( " % s % n " , info . peer . toString ( ) ) ; 
 + outs . printf ( " % s " , info . peer . toString ( ) ) ; 
 + / / print private IP when it is used 
 + if ( ! info . peer . equals ( info . connecting ) ) 
 + { 
 + outs . printf ( " ( using % s ) " , info . connecting . toString ( ) ) ; 
 + } 
 + outs . printf ( " % n " ) ; 
 if ( ! info . receivingSummaries . isEmpty ( ) ) 
 { 
 outs . printf ( " Receiving % d files , % d bytes total % n " , info . getTotalFilesToReceive ( ) , info . getTotalSizeToReceive ( ) ) ; 
 diff - - git a / test / unit / org / apache / cassandra / streaming / SessionInfoTest . java b / test / unit / org / apache / cassandra / streaming / SessionInfoTest . java 
 index 60fbf40 . . c8b6254 100644 
 - - - a / test / unit / org / apache / cassandra / streaming / SessionInfoTest . java 
 + + + b / test / unit / org / apache / cassandra / streaming / SessionInfoTest . java 
 @ @ - 46 , 7 + 46 , 7 @ @ public class SessionInfoTest 
 } 
 
 StreamSummary sending = new StreamSummary ( cfId , 10 , 100 ) ; 
 - SessionInfo info = new SessionInfo ( local , summaries , Collections . singleton ( sending ) , StreamSession . State . PREPARING ) ; 
 + SessionInfo info = new SessionInfo ( local , local , summaries , Collections . singleton ( sending ) , StreamSession . State . PREPARING ) ; 
 
 assert info . getTotalFilesToReceive ( ) = = 45 ; 
 assert info . getTotalFilesToSend ( ) = = 10 ; 
 diff - - git a / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java b / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java 
 index ce0f9d0 . . b51f75b 100644 
 - - - a / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java 
 + + + b / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java 
 @ @ - 17 , 6 + 17 , 7 @ @ 
 * / 
 package org . apache . cassandra . streaming ; 
 
 + import java . net . InetAddress ; 
 import java . util . ArrayList ; 
 import java . util . List ; 
 import java . util . concurrent . ScheduledFuture ; 
 @ @ - 43 , 7 + 44 , 8 @ @ public class StreamTransferTaskTest extends SchemaLoader 
 String ks = " Keyspace1 " ; 
 String cf = " Standard1 " ; 
 
 - StreamSession session = new StreamSession ( FBUtilities . getBroadcastAddress ( ) , null ) ; 
 + InetAddress peer = FBUtilities . getBroadcastAddress ( ) ; 
 + StreamSession session = new StreamSession ( peer , peer , null ) ; 
 ColumnFamilyStore cfs = Keyspace . open ( ks ) . getColumnFamilyStore ( cf ) ; 
 
 / / create two sstables 
 diff - - git a / test / unit / org / apache / cassandra / streaming / StreamingTransferTest . java b / test / unit / org / apache / cassandra / streaming / StreamingTransferTest . java 
 index 4cd578d . . d2047fc 100644 
 - - - a / test / unit / org / apache / cassandra / streaming / StreamingTransferTest . java 
 + + + b / test / unit / org / apache / cassandra / streaming / StreamingTransferTest . java 
 @ @ - 107 , 7 + 107 , 7 @ @ public class StreamingTransferTest extends SchemaLoader 
 ranges . add ( new Range < > ( p . getToken ( ByteBufferUtil . bytes ( " key2 " ) ) , p . getMinimumToken ( ) ) ) ; 
 
 StreamResultFuture futureResult = new StreamPlan ( " StreamingTransferTest " ) 
 - . requestRanges ( LOCAL , " Keyspace2 " , ranges ) 
 + . requestRanges ( LOCAL , LOCAL , " Keyspace2 " , ranges ) 
 . execute ( ) ; 
 
 UUID planId = futureResult . planId ;

NEAREST DIFF:
diff - - git a / conf / cassandra . yaml b / conf / cassandra . yaml 
 index 4010d74 . . 866319c 100644 
 - - - a / conf / cassandra . yaml 
 + + + b / conf / cassandra . yaml 
 @ @ - 77 , 8 + 77 , 8 @ @ commitlog _ directory : / var / lib / cassandra / commitlog 
 # 
 # NOTE : if you reduce the size , you may not get you hottest keys loaded on startup . 
 # 
 - # Default value is " auto " ( min ( 5 % of Heap ( in MB ) , 100MB ) ) . Set to 0 to disable key cache . 
 - key _ cache _ size _ in _ mb : auto 
 + # Default value is empty to make it " auto " ( min ( 5 % of Heap ( in MB ) , 100MB ) ) . Set to 0 to disable key cache . 
 + key _ cache _ size _ in _ mb : 
 
 # Duration in seconds after which Cassandra should 
 # safe the keys cache . Caches are saved to saved _ caches _ directory as 
 diff - - git a / src / java / org / apache / cassandra / config / Config . java b / src / java / org / apache / cassandra / config / Config . java 
 index 7adce69 . . b17efac 100644 
 - - - a / src / java / org / apache / cassandra / config / Config . java 
 + + + b / src / java / org / apache / cassandra / config / Config . java 
 @ @ - 126 , 7 + 126 , 7 @ @ public class Config 
 public boolean trickle _ fsync = false ; 
 public int trickle _ fsync _ interval _ in _ kb = 10240 ; 
 
 - public String key _ cache _ size _ in _ mb = " auto " ; 
 + public Integer key _ cache _ size _ in _ mb = null ; 
 public int key _ cache _ save _ period = 14400 ; 
 public int key _ cache _ keys _ to _ save = Integer . MAX _ VALUE ; 
 
 diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 index 227a6a3 . . 1648d57 100644 
 - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 @ @ - 418 , 9 + 418 , 9 @ @ public class DatabaseDescriptor 
 try 
 { 
 / / if key _ cache _ size _ in _ mb option was set to " auto " then size of the cache should be " min ( 5 % of Heap ( in MB ) , 100MB ) 
 - keyCacheSizeInMB = " auto " . equalsIgnoreCase ( conf . key _ cache _ size _ in _ mb ) 
 + keyCacheSizeInMB = ( conf . key _ cache _ size _ in _ mb = = null ) 
 ? Math . min ( ( int ) ( Runtime . getRuntime ( ) . totalMemory ( ) * 0 . 05 / 1024 / 1024 ) , 100 ) 
 - : Integer . valueOf ( conf . key _ cache _ size _ in _ mb ) ; 
 + : conf . key _ cache _ size _ in _ mb ; 
 
 if ( keyCacheSizeInMB < 0 ) 
 throw new NumberFormatException ( ) ; / / to escape duplicating error message 
 @ @ - 428 , 7 + 428 , 7 @ @ public class DatabaseDescriptor 
 catch ( NumberFormatException e ) 
 { 
 throw new ConfigurationException ( " key _ cache _ size _ in _ mb option was set incorrectly to ' " 
 - + conf . key _ cache _ size _ in _ mb + " ' , supported values are ' auto ' and < integer > > = 0 . " ) ; 
 + + conf . key _ cache _ size _ in _ mb + " ' , supported values are < integer > > = 0 . " ) ; 
 } 
 
 rowCacheProvider = FBUtilities . newCacheProvider ( conf . row _ cache _ provider ) ;
