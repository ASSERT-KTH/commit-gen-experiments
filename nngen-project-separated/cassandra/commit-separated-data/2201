BLEU SCORE: 0.040583489434387374

TEST MSG: Fix NPE in FileCacheService . sizeInBytes
GENERATED MSG: drain method

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 04902ad . . 4306de5 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 0 . 10 <nl> + * Fix NPE in FileCacheService . sizeInBytes ( CASSANDRA - 7756 ) <nl> * ( cqlsh ) cqlsh should automatically disable tracing when selecting <nl> from system _ traces ( CASSANDRA - 7641 ) <nl> * ( Hadoop ) Add CqlOutputFormat ( CASSANDRA - 6927 ) <nl> diff - - git a / src / java / org / apache / cassandra / io / util / RandomAccessReader . java b / src / java / org / apache / cassandra / io / util / RandomAccessReader . java <nl> index 9a03480 . . 09ecac0 100644 <nl> - - - a / src / java / org / apache / cassandra / io / util / RandomAccessReader . java <nl> + + + b / src / java / org / apache / cassandra / io / util / RandomAccessReader . java <nl> @ @ - 154 , 7 + 154 , 10 @ @ public class RandomAccessReader extends RandomAccessFile implements FileDataInpu <nl> <nl> public int getTotalBufferSize ( ) <nl> { <nl> - return buffer . length ; <nl> + / / This may NPE so we make a ref <nl> + / / https : / / issues . apache . org / jira / browse / CASSANDRA - 7756 <nl> + byte [ ] ref = buffer ; <nl> + return ref ! = null ? ref . length : 0 ; <nl> } <nl> <nl> public void reset ( ) <nl> diff - - git a / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java b / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java <nl> index 90c27e3 . . a16b291 100644 <nl> - - - a / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java <nl> + + + b / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java <nl> @ @ - 19 , 6 + 19 , 7 @ @ <nl> * / <nl> package org . apache . cassandra . io . util ; <nl> <nl> + import org . apache . cassandra . service . FileCacheService ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> <nl> import java . io . File ; <nl> @ @ - 28 , 6 + 29 , 11 @ @ import java . nio . ByteBuffer ; <nl> import java . nio . channels . ClosedChannelException ; <nl> import java . util . Arrays ; <nl> import java . util . concurrent . Callable ; <nl> + import java . util . concurrent . CountDownLatch ; <nl> + import java . util . concurrent . ExecutorService ; <nl> + import java . util . concurrent . Executors ; <nl> + import java . util . concurrent . atomic . AtomicBoolean ; <nl> + import java . util . concurrent . atomic . AtomicInteger ; <nl> <nl> import static org . apache . cassandra . Util . expectEOF ; <nl> import static org . apache . cassandra . Util . expectException ; <nl> @ @ - 508 , 6 + 514 , 70 @ @ public class BufferedRandomAccessFileTest <nl> } <nl> <nl> @ Test <nl> + public void testFileCacheService ( ) throws IOException , InterruptedException <nl> + { <nl> + / / see https : / / issues . apache . org / jira / browse / CASSANDRA - 7756 <nl> + <nl> + final int THREAD _ COUNT = 40 ; <nl> + ExecutorService executorService = Executors . newFixedThreadPool ( THREAD _ COUNT ) ; <nl> + <nl> + SequentialWriter w1 = createTempFile ( " fscache1 " ) ; <nl> + SequentialWriter w2 = createTempFile ( " fscache2 " ) ; <nl> + <nl> + w1 . write ( new byte [ 30 ] ) ; <nl> + w1 . close ( ) ; <nl> + <nl> + w2 . write ( new byte [ 30 ] ) ; <nl> + w2 . close ( ) ; <nl> + <nl> + for ( int i = 0 ; i < 20 ; i + + ) <nl> + { <nl> + <nl> + <nl> + RandomAccessReader r1 = RandomAccessReader . open ( w1 ) ; <nl> + RandomAccessReader r2 = RandomAccessReader . open ( w2 ) ; <nl> + <nl> + <nl> + FileCacheService . instance . put ( r1 ) ; <nl> + FileCacheService . instance . put ( r2 ) ; <nl> + <nl> + final CountDownLatch finished = new CountDownLatch ( THREAD _ COUNT ) ; <nl> + final AtomicBoolean hadError = new AtomicBoolean ( false ) ; <nl> + <nl> + for ( int k = 0 ; k < THREAD _ COUNT ; k + + ) <nl> + { <nl> + executorService . execute ( new Runnable ( ) <nl> + { <nl> + @ Override <nl> + public void run ( ) <nl> + { <nl> + try <nl> + { <nl> + long size = FileCacheService . instance . sizeInBytes ( ) ; <nl> + <nl> + while ( size > 0 ) <nl> + size = FileCacheService . instance . sizeInBytes ( ) ; <nl> + } <nl> + catch ( Throwable t ) <nl> + { <nl> + t . printStackTrace ( ) ; <nl> + hadError . set ( true ) ; <nl> + } <nl> + finally <nl> + { <nl> + finished . countDown ( ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> + <nl> + } <nl> + <nl> + finished . await ( ) ; <nl> + assert ! hadError . get ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ Test <nl> public void testReadOnly ( ) throws IOException <nl> { <nl> SequentialWriter file = createTempFile ( " brafReadOnlyTest " ) ;
NEAREST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java <nl> index 6c20cd0 . . a1a6d15 100644 <nl> - - - a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java <nl> + + + b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java <nl> @ @ - 39 , 6 + 39 , 7 @ @ import org . slf4j . LoggerFactory ; <nl> <nl> import java . io . * ; <nl> import java . util . * ; <nl> + import java . util . concurrent . atomic . AtomicInteger ; <nl> import java . util . zip . Checksum ; <nl> import java . util . zip . CRC32 ; <nl> import java . util . concurrent . Callable ; <nl> @ @ - 173 , 12 + 174 , 10 @ @ public class CommitLog <nl> logger . info ( " Log replay complete " ) ; <nl> } <nl> <nl> - <nl> public static void recover ( File [ ] clogs ) throws IOException <nl> { <nl> Set < Table > tablesRecovered = new HashSet < Table > ( ) ; <nl> - assert StageManager . getStage ( StageManager . MUTATION _ STAGE ) . getCompletedTaskCount ( ) = = 0 ; <nl> - int rows = 0 ; <nl> + final AtomicInteger counter = new AtomicInteger ( 0 ) ; <nl> for ( File file : clogs ) <nl> { <nl> int bufferSize = ( int ) Math . min ( file . length ( ) , 32 * 1024 * 1024 ) ; <nl> @ @ - 263 , 16 + 262 , 17 @ @ public class CommitLog <nl> { <nl> Table . open ( newRm . getTable ( ) ) . apply ( newRm , null , false ) ; <nl> } <nl> + counter . decrementAndGet ( ) ; <nl> } <nl> } ; <nl> - StageManager . getStage ( StageManager . MUTATION _ STAGE ) . execute ( runnable ) ; <nl> - rows + + ; <nl> + counter . incrementAndGet ( ) ; <nl> + StageManager . getStage ( StageManager . MUTATION _ STAGE ) . submit ( runnable ) ; <nl> } <nl> reader . close ( ) ; <nl> } <nl> <nl> / / wait for all the writes to finish on the mutation stage <nl> - while ( StageManager . getStage ( StageManager . MUTATION _ STAGE ) . getCompletedTaskCount ( ) < rows ) <nl> + while ( counter . get ( ) > 0 ) <nl> { <nl> try <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / io / DeletionService . java b / src / java / org / apache / cassandra / io / DeletionService . java <nl> index 9a534fe . . ae8a271 100644 <nl> - - - a / src / java / org / apache / cassandra / io / DeletionService . java <nl> + + + b / src / java / org / apache / cassandra / io / DeletionService . java <nl> @ @ - 23 , 6 + 23 , 7 @ @ package org . apache . cassandra . io ; <nl> <nl> import java . io . File ; <nl> import java . io . IOException ; <nl> + import java . util . concurrent . ExecutionException ; <nl> import java . util . concurrent . ExecutorService ; <nl> <nl> import org . apache . cassandra . concurrent . JMXEnabledThreadPoolExecutor ; <nl> @ @ - 48 , 6 + 49 , 11 @ @ public class DeletionService <nl> } ; <nl> executor . submit ( deleter ) ; <nl> } <nl> + <nl> + public static void waitFor ( ) throws InterruptedException , ExecutionException <nl> + { <nl> + executor . submit ( new Runnable ( ) { public void run ( ) { } } ) . get ( ) ; <nl> + } <nl> <nl> public static void submitDeleteWithRetry ( String file ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java <nl> index 02453f1 . . 79a4458 100644 <nl> - - - a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java <nl> + + + b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java <nl> @ @ - 164 , 7 + 164 , 7 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> { <nl> if ( syncNeeded _ ) <nl> { <nl> - flush ( ) ; <nl> + flushBuffer ( ) ; <nl> getChannel ( ) . force ( true ) ; / / true , because file length counts as " metadata " <nl> syncNeeded _ = false ; <nl> } <nl> @ @ - 172 , 20 + 172 , 11 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa <nl> <nl> public void close ( ) throws IOException <nl> { <nl> - this . flush ( ) ; <nl> + sync ( ) ; <nl> this . buff _ = null ; <nl> super . close ( ) ; <nl> } <nl> <nl> - / * * <nl> - * Flush any bytes in the file ' s buffer that have not yet been written to <nl> - * disk . If the file was created read - only , this method is a no - op . <nl> - * / <nl> - public void flush ( ) throws IOException <nl> - { <nl> - this . flushBuffer ( ) ; <nl> - } <nl> - <nl> / * Flush any dirty bytes in the buffer to disk . * / <nl> private void flushBuffer ( ) throws IOException <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / net / MessagingService . java b / src / java / org / apache / cassandra / net / MessagingService . java <nl> index 409a21e . . e0329c7 100644 <nl> - - - a / src / java / org / apache / cassandra / net / MessagingService . java <nl> + + + b / src / java / org / apache / cassandra / net / MessagingService . java <nl> @ @ - 32 , 12 + 32 , 14 @ @ import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> + import java . io . IOError ; <nl> import java . io . IOException ; <nl> import java . net . ServerSocket ; <nl> import java . net . InetAddress ; <nl> import java . net . InetSocketAddress ; <nl> import java . net . Socket ; <nl> import java . nio . ByteBuffer ; <nl> + import java . nio . channels . AsynchronousCloseException ; <nl> import java . nio . channels . ServerSocketChannel ; <nl> import java . security . MessageDigest ; <nl> import java . util . * ; <nl> @ @ - 74 , 6 + 76 , 8 @ @ public class MessagingService implements IFailureDetectionEventListener <nl> private static Logger logger _ = LoggerFactory . getLogger ( MessagingService . class ) ; <nl> <nl> public static final MessagingService instance = new MessagingService ( ) ; <nl> + <nl> + private SocketThread socketThread ; <nl> <nl> public static int getVersion ( ) <nl> { <nl> @ @ - 141 , 25 + 145 , 9 @ @ public class MessagingService implements IFailureDetectionEventListener <nl> final ServerSocket ss = serverChannel . socket ( ) ; <nl> ss . setReuseAddress ( true ) ; <nl> ss . bind ( new InetSocketAddress ( localEp , DatabaseDescriptor . getStoragePort ( ) ) ) ; <nl> + socketThread = new SocketThread ( ss , " ACCEPT - " + localEp ) ; <nl> + socketThread . start ( ) ; <nl> <nl> - new Thread ( new Runnable ( ) <nl> - { <nl> - public void run ( ) <nl> - { <nl> - while ( true ) <nl> - { <nl> - try <nl> - { <nl> - Socket socket = ss . accept ( ) ; <nl> - new IncomingTcpConnection ( socket ) . start ( ) ; <nl> - } <nl> - catch ( IOException e ) <nl> - { <nl> - throw new RuntimeException ( e ) ; <nl> - } <nl> - } <nl> - } <nl> - } , " ACCEPT - " + localEp ) . start ( ) ; <nl> } <nl> <nl> public static OutboundTcpConnectionPool getConnectionPool ( InetAddress to ) <nl> @ @ - 338 , 14 + 326 , 31 @ @ public class MessagingService implements IFailureDetectionEventListener <nl> Runnable streamingTask = new FileStreamTask ( file , startPosition , endPosition , from , to ) ; <nl> streamExecutor _ . execute ( streamingTask ) ; <nl> } <nl> + <nl> + / * * blocks until the processing pools are empty and done . * / <nl> + public static void waitFor ( ) throws InterruptedException <nl> + { <nl> + while ( ! messageDeserializerExecutor _ . isTerminated ( ) ) <nl> + messageDeserializerExecutor _ . awaitTermination ( 5 , TimeUnit . SECONDS ) ; <nl> + while ( ! streamExecutor _ . isTerminated ( ) ) <nl> + streamExecutor _ . awaitTermination ( 5 , TimeUnit . SECONDS ) ; <nl> + } <nl> <nl> public static void shutdown ( ) <nl> { <nl> - logger _ . info ( " Shutting down . . . " ) ; <nl> + logger _ . info ( " Shutting down MessageService . . . " ) ; <nl> + <nl> + try <nl> + { <nl> + instance . socketThread . close ( ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new IOError ( e ) ; <nl> + } <nl> <nl> messageDeserializerExecutor _ . shutdownNow ( ) ; <nl> streamExecutor _ . shutdownNow ( ) ; <nl> - StageManager . shutdownNow ( ) ; <nl> <nl> / * shut down the cachetables * / <nl> taskCompletionMap _ . shutdown ( ) ; <nl> @ @ - 467 , 4 + 472 , 42 @ @ public class MessagingService implements IFailureDetectionEventListener <nl> buffer . flip ( ) ; <nl> return buffer ; <nl> } <nl> + <nl> + private class SocketThread extends Thread <nl> + { <nl> + private final ServerSocket server ; <nl> + <nl> + SocketThread ( ServerSocket server , String name ) <nl> + { <nl> + super ( name ) ; <nl> + this . server = server ; <nl> + } <nl> + <nl> + public void run ( ) <nl> + { <nl> + while ( true ) <nl> + { <nl> + try <nl> + { <nl> + Socket socket = server . accept ( ) ; <nl> + new IncomingTcpConnection ( socket ) . start ( ) ; <nl> + } <nl> + catch ( AsynchronousCloseException e ) <nl> + { <nl> + / / this happens when another thread calls close ( ) . <nl> + logger _ . info ( " MessagingService shutting down server thread . " ) ; <nl> + break ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new RuntimeException ( e ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + void close ( ) throws IOException <nl> + { <nl> + server . close ( ) ; <nl> + } <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index f1404f6 . . 713ae51 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 37 , 8 + 37 , 10 @ @ import com . google . common . collect . Multimaps ; <nl> import org . apache . cassandra . concurrent . * ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . db . * ; <nl> + import org . apache . cassandra . db . commitlog . CommitLog ; <nl> import org . apache . cassandra . dht . * ; <nl> import org . apache . cassandra . gms . * ; <nl> + import org . apache . cassandra . io . DeletionService ; <nl> import org . apache . cassandra . io . sstable . SSTable ; <nl> import org . apache . cassandra . io . sstable . SSTableReader ; <nl> import org . apache . cassandra . locator . * ; <nl> @ @ - 273 , 6 + 275 , 7 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe <nl> Gossiper . instance . unregister ( this ) ; <nl> Gossiper . instance . stop ( ) ; <nl> MessagingService . shutdown ( ) ; <nl> + StageManager . shutdownNow ( ) ; <nl> } <nl> <nl> public synchronized void initClient ( ) throws IOException <nl> @ @ - 1301 , 6 + 1304 , 7 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe <nl> { <nl> Gossiper . instance . stop ( ) ; <nl> MessagingService . shutdown ( ) ; <nl> + StageManager . shutdownNow ( ) ; <nl> setMode ( " Decommissioned " , true ) ; <nl> / / let op be responsible for killing the process <nl> } <nl> @ @ - 1525 , 4 + 1529 , 43 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe <nl> tokenMetadata _ = tmd ; <nl> return old ; <nl> } <nl> + <nl> + / * * shuts node off to writes , empties memtables and the commit log . * / <nl> + public synchronized void drain ( ) throws IOException , InterruptedException , ExecutionException <nl> + { <nl> + ExecutorService mutationStage = StageManager . getStage ( StageManager . MUTATION _ STAGE ) ; <nl> + if ( mutationStage . isTerminated ( ) ) <nl> + { <nl> + logger _ . warn ( " Cannot drain node ( did it already happen ? ) " ) ; <nl> + return ; <nl> + } <nl> + setMode ( " Starting drain process " , true ) ; <nl> + Gossiper . instance . stop ( ) ; <nl> + setMode ( " Draining : shutting down MessageService " , false ) ; <nl> + MessagingService . shutdown ( ) ; <nl> + setMode ( " Draining : emptying MessageService pools " , false ) ; <nl> + MessagingService . waitFor ( ) ; <nl> + <nl> + / / lets flush . <nl> + setMode ( " Draining : flushing column families " , false ) ; <nl> + for ( String tableName : DatabaseDescriptor . getNonSystemTables ( ) ) <nl> + for ( Future f : Table . open ( tableName ) . flush ( ) ) <nl> + f . get ( ) ; <nl> + <nl> + <nl> + setMode ( " Draining : replaying commit log " , false ) ; <nl> + CommitLog . instance ( ) . forceNewSegment ( ) ; <nl> + / / want to make sure that any segments deleted as a result of flushing are gone . <nl> + DeletionService . waitFor ( ) ; <nl> + CommitLog . recover ( ) ; <nl> + <nl> + / / commit log recovery just sends work to the mutation stage . ( there could have already been work there anyway . <nl> + / / Either way , we need to let this one drain naturally , and then we ' re finished . <nl> + setMode ( " Draining : clearing mutation stage " , false ) ; <nl> + mutationStage . shutdown ( ) ; <nl> + while ( ! mutationStage . isTerminated ( ) ) <nl> + mutationStage . awaitTermination ( 5 , TimeUnit . SECONDS ) ; <nl> + <nl> + setMode ( " Node is drained " , true ) ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> index 638430e . . dc1e8b5 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> @ @ - 23 , 6 + 23 , 7 @ @ import java . net . UnknownHostException ; <nl> import java . util . List ; <nl> import java . util . Map ; <nl> import java . util . Set ; <nl> + import java . util . concurrent . ExecutionException ; <nl> import java . util . concurrent . FutureTask ; <nl> <nl> import org . apache . cassandra . dht . Range ; <nl> @ @ - 165 , 4 + 166 , 7 @ @ public interface StorageServiceMBean <nl> <nl> / * * get the operational mode ( leaving , joining , normal , decommissioned , client ) * * / <nl> public String getOperationMode ( ) ; <nl> + <nl> + / * * makes node unavailable for writes , flushes memtables and replays commitlog . * / <nl> + public void drain ( ) throws IOException , InterruptedException , ExecutionException ; <nl> }

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 04902ad . . 4306de5 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 0 . 10 
 + * Fix NPE in FileCacheService . sizeInBytes ( CASSANDRA - 7756 ) 
 * ( cqlsh ) cqlsh should automatically disable tracing when selecting 
 from system _ traces ( CASSANDRA - 7641 ) 
 * ( Hadoop ) Add CqlOutputFormat ( CASSANDRA - 6927 ) 
 diff - - git a / src / java / org / apache / cassandra / io / util / RandomAccessReader . java b / src / java / org / apache / cassandra / io / util / RandomAccessReader . java 
 index 9a03480 . . 09ecac0 100644 
 - - - a / src / java / org / apache / cassandra / io / util / RandomAccessReader . java 
 + + + b / src / java / org / apache / cassandra / io / util / RandomAccessReader . java 
 @ @ - 154 , 7 + 154 , 10 @ @ public class RandomAccessReader extends RandomAccessFile implements FileDataInpu 
 
 public int getTotalBufferSize ( ) 
 { 
 - return buffer . length ; 
 + / / This may NPE so we make a ref 
 + / / https : / / issues . apache . org / jira / browse / CASSANDRA - 7756 
 + byte [ ] ref = buffer ; 
 + return ref ! = null ? ref . length : 0 ; 
 } 
 
 public void reset ( ) 
 diff - - git a / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java b / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java 
 index 90c27e3 . . a16b291 100644 
 - - - a / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java 
 + + + b / test / unit / org / apache / cassandra / io / util / BufferedRandomAccessFileTest . java 
 @ @ - 19 , 6 + 19 , 7 @ @ 
 * / 
 package org . apache . cassandra . io . util ; 
 
 + import org . apache . cassandra . service . FileCacheService ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 
 import java . io . File ; 
 @ @ - 28 , 6 + 29 , 11 @ @ import java . nio . ByteBuffer ; 
 import java . nio . channels . ClosedChannelException ; 
 import java . util . Arrays ; 
 import java . util . concurrent . Callable ; 
 + import java . util . concurrent . CountDownLatch ; 
 + import java . util . concurrent . ExecutorService ; 
 + import java . util . concurrent . Executors ; 
 + import java . util . concurrent . atomic . AtomicBoolean ; 
 + import java . util . concurrent . atomic . AtomicInteger ; 
 
 import static org . apache . cassandra . Util . expectEOF ; 
 import static org . apache . cassandra . Util . expectException ; 
 @ @ - 508 , 6 + 514 , 70 @ @ public class BufferedRandomAccessFileTest 
 } 
 
 @ Test 
 + public void testFileCacheService ( ) throws IOException , InterruptedException 
 + { 
 + / / see https : / / issues . apache . org / jira / browse / CASSANDRA - 7756 
 + 
 + final int THREAD _ COUNT = 40 ; 
 + ExecutorService executorService = Executors . newFixedThreadPool ( THREAD _ COUNT ) ; 
 + 
 + SequentialWriter w1 = createTempFile ( " fscache1 " ) ; 
 + SequentialWriter w2 = createTempFile ( " fscache2 " ) ; 
 + 
 + w1 . write ( new byte [ 30 ] ) ; 
 + w1 . close ( ) ; 
 + 
 + w2 . write ( new byte [ 30 ] ) ; 
 + w2 . close ( ) ; 
 + 
 + for ( int i = 0 ; i < 20 ; i + + ) 
 + { 
 + 
 + 
 + RandomAccessReader r1 = RandomAccessReader . open ( w1 ) ; 
 + RandomAccessReader r2 = RandomAccessReader . open ( w2 ) ; 
 + 
 + 
 + FileCacheService . instance . put ( r1 ) ; 
 + FileCacheService . instance . put ( r2 ) ; 
 + 
 + final CountDownLatch finished = new CountDownLatch ( THREAD _ COUNT ) ; 
 + final AtomicBoolean hadError = new AtomicBoolean ( false ) ; 
 + 
 + for ( int k = 0 ; k < THREAD _ COUNT ; k + + ) 
 + { 
 + executorService . execute ( new Runnable ( ) 
 + { 
 + @ Override 
 + public void run ( ) 
 + { 
 + try 
 + { 
 + long size = FileCacheService . instance . sizeInBytes ( ) ; 
 + 
 + while ( size > 0 ) 
 + size = FileCacheService . instance . sizeInBytes ( ) ; 
 + } 
 + catch ( Throwable t ) 
 + { 
 + t . printStackTrace ( ) ; 
 + hadError . set ( true ) ; 
 + } 
 + finally 
 + { 
 + finished . countDown ( ) ; 
 + } 
 + } 
 + } ) ; 
 + 
 + } 
 + 
 + finished . await ( ) ; 
 + assert ! hadError . get ( ) ; 
 + } 
 + } 
 + 
 + @ Test 
 public void testReadOnly ( ) throws IOException 
 { 
 SequentialWriter file = createTempFile ( " brafReadOnlyTest " ) ;

NEAREST DIFF:
diff - - git a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java 
 index 6c20cd0 . . a1a6d15 100644 
 - - - a / src / java / org / apache / cassandra / db / commitlog / CommitLog . java 
 + + + b / src / java / org / apache / cassandra / db / commitlog / CommitLog . java 
 @ @ - 39 , 6 + 39 , 7 @ @ import org . slf4j . LoggerFactory ; 
 
 import java . io . * ; 
 import java . util . * ; 
 + import java . util . concurrent . atomic . AtomicInteger ; 
 import java . util . zip . Checksum ; 
 import java . util . zip . CRC32 ; 
 import java . util . concurrent . Callable ; 
 @ @ - 173 , 12 + 174 , 10 @ @ public class CommitLog 
 logger . info ( " Log replay complete " ) ; 
 } 
 
 - 
 public static void recover ( File [ ] clogs ) throws IOException 
 { 
 Set < Table > tablesRecovered = new HashSet < Table > ( ) ; 
 - assert StageManager . getStage ( StageManager . MUTATION _ STAGE ) . getCompletedTaskCount ( ) = = 0 ; 
 - int rows = 0 ; 
 + final AtomicInteger counter = new AtomicInteger ( 0 ) ; 
 for ( File file : clogs ) 
 { 
 int bufferSize = ( int ) Math . min ( file . length ( ) , 32 * 1024 * 1024 ) ; 
 @ @ - 263 , 16 + 262 , 17 @ @ public class CommitLog 
 { 
 Table . open ( newRm . getTable ( ) ) . apply ( newRm , null , false ) ; 
 } 
 + counter . decrementAndGet ( ) ; 
 } 
 } ; 
 - StageManager . getStage ( StageManager . MUTATION _ STAGE ) . execute ( runnable ) ; 
 - rows + + ; 
 + counter . incrementAndGet ( ) ; 
 + StageManager . getStage ( StageManager . MUTATION _ STAGE ) . submit ( runnable ) ; 
 } 
 reader . close ( ) ; 
 } 
 
 / / wait for all the writes to finish on the mutation stage 
 - while ( StageManager . getStage ( StageManager . MUTATION _ STAGE ) . getCompletedTaskCount ( ) < rows ) 
 + while ( counter . get ( ) > 0 ) 
 { 
 try 
 { 
 diff - - git a / src / java / org / apache / cassandra / io / DeletionService . java b / src / java / org / apache / cassandra / io / DeletionService . java 
 index 9a534fe . . ae8a271 100644 
 - - - a / src / java / org / apache / cassandra / io / DeletionService . java 
 + + + b / src / java / org / apache / cassandra / io / DeletionService . java 
 @ @ - 23 , 6 + 23 , 7 @ @ package org . apache . cassandra . io ; 
 
 import java . io . File ; 
 import java . io . IOException ; 
 + import java . util . concurrent . ExecutionException ; 
 import java . util . concurrent . ExecutorService ; 
 
 import org . apache . cassandra . concurrent . JMXEnabledThreadPoolExecutor ; 
 @ @ - 48 , 6 + 49 , 11 @ @ public class DeletionService 
 } ; 
 executor . submit ( deleter ) ; 
 } 
 + 
 + public static void waitFor ( ) throws InterruptedException , ExecutionException 
 + { 
 + executor . submit ( new Runnable ( ) { public void run ( ) { } } ) . get ( ) ; 
 + } 
 
 public static void submitDeleteWithRetry ( String file ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java 
 index 02453f1 . . 79a4458 100644 
 - - - a / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java 
 + + + b / src / java / org / apache / cassandra / io / util / BufferedRandomAccessFile . java 
 @ @ - 164 , 7 + 164 , 7 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 { 
 if ( syncNeeded _ ) 
 { 
 - flush ( ) ; 
 + flushBuffer ( ) ; 
 getChannel ( ) . force ( true ) ; / / true , because file length counts as " metadata " 
 syncNeeded _ = false ; 
 } 
 @ @ - 172 , 20 + 172 , 11 @ @ public class BufferedRandomAccessFile extends RandomAccessFile implements FileDa 
 
 public void close ( ) throws IOException 
 { 
 - this . flush ( ) ; 
 + sync ( ) ; 
 this . buff _ = null ; 
 super . close ( ) ; 
 } 
 
 - / * * 
 - * Flush any bytes in the file ' s buffer that have not yet been written to 
 - * disk . If the file was created read - only , this method is a no - op . 
 - * / 
 - public void flush ( ) throws IOException 
 - { 
 - this . flushBuffer ( ) ; 
 - } 
 - 
 / * Flush any dirty bytes in the buffer to disk . * / 
 private void flushBuffer ( ) throws IOException 
 { 
 diff - - git a / src / java / org / apache / cassandra / net / MessagingService . java b / src / java / org / apache / cassandra / net / MessagingService . java 
 index 409a21e . . e0329c7 100644 
 - - - a / src / java / org / apache / cassandra / net / MessagingService . java 
 + + + b / src / java / org / apache / cassandra / net / MessagingService . java 
 @ @ - 32 , 12 + 32 , 14 @ @ import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 + import java . io . IOError ; 
 import java . io . IOException ; 
 import java . net . ServerSocket ; 
 import java . net . InetAddress ; 
 import java . net . InetSocketAddress ; 
 import java . net . Socket ; 
 import java . nio . ByteBuffer ; 
 + import java . nio . channels . AsynchronousCloseException ; 
 import java . nio . channels . ServerSocketChannel ; 
 import java . security . MessageDigest ; 
 import java . util . * ; 
 @ @ - 74 , 6 + 76 , 8 @ @ public class MessagingService implements IFailureDetectionEventListener 
 private static Logger logger _ = LoggerFactory . getLogger ( MessagingService . class ) ; 
 
 public static final MessagingService instance = new MessagingService ( ) ; 
 + 
 + private SocketThread socketThread ; 
 
 public static int getVersion ( ) 
 { 
 @ @ - 141 , 25 + 145 , 9 @ @ public class MessagingService implements IFailureDetectionEventListener 
 final ServerSocket ss = serverChannel . socket ( ) ; 
 ss . setReuseAddress ( true ) ; 
 ss . bind ( new InetSocketAddress ( localEp , DatabaseDescriptor . getStoragePort ( ) ) ) ; 
 + socketThread = new SocketThread ( ss , " ACCEPT - " + localEp ) ; 
 + socketThread . start ( ) ; 
 
 - new Thread ( new Runnable ( ) 
 - { 
 - public void run ( ) 
 - { 
 - while ( true ) 
 - { 
 - try 
 - { 
 - Socket socket = ss . accept ( ) ; 
 - new IncomingTcpConnection ( socket ) . start ( ) ; 
 - } 
 - catch ( IOException e ) 
 - { 
 - throw new RuntimeException ( e ) ; 
 - } 
 - } 
 - } 
 - } , " ACCEPT - " + localEp ) . start ( ) ; 
 } 
 
 public static OutboundTcpConnectionPool getConnectionPool ( InetAddress to ) 
 @ @ - 338 , 14 + 326 , 31 @ @ public class MessagingService implements IFailureDetectionEventListener 
 Runnable streamingTask = new FileStreamTask ( file , startPosition , endPosition , from , to ) ; 
 streamExecutor _ . execute ( streamingTask ) ; 
 } 
 + 
 + / * * blocks until the processing pools are empty and done . * / 
 + public static void waitFor ( ) throws InterruptedException 
 + { 
 + while ( ! messageDeserializerExecutor _ . isTerminated ( ) ) 
 + messageDeserializerExecutor _ . awaitTermination ( 5 , TimeUnit . SECONDS ) ; 
 + while ( ! streamExecutor _ . isTerminated ( ) ) 
 + streamExecutor _ . awaitTermination ( 5 , TimeUnit . SECONDS ) ; 
 + } 
 
 public static void shutdown ( ) 
 { 
 - logger _ . info ( " Shutting down . . . " ) ; 
 + logger _ . info ( " Shutting down MessageService . . . " ) ; 
 + 
 + try 
 + { 
 + instance . socketThread . close ( ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new IOError ( e ) ; 
 + } 
 
 messageDeserializerExecutor _ . shutdownNow ( ) ; 
 streamExecutor _ . shutdownNow ( ) ; 
 - StageManager . shutdownNow ( ) ; 
 
 / * shut down the cachetables * / 
 taskCompletionMap _ . shutdown ( ) ; 
 @ @ - 467 , 4 + 472 , 42 @ @ public class MessagingService implements IFailureDetectionEventListener 
 buffer . flip ( ) ; 
 return buffer ; 
 } 
 + 
 + private class SocketThread extends Thread 
 + { 
 + private final ServerSocket server ; 
 + 
 + SocketThread ( ServerSocket server , String name ) 
 + { 
 + super ( name ) ; 
 + this . server = server ; 
 + } 
 + 
 + public void run ( ) 
 + { 
 + while ( true ) 
 + { 
 + try 
 + { 
 + Socket socket = server . accept ( ) ; 
 + new IncomingTcpConnection ( socket ) . start ( ) ; 
 + } 
 + catch ( AsynchronousCloseException e ) 
 + { 
 + / / this happens when another thread calls close ( ) . 
 + logger _ . info ( " MessagingService shutting down server thread . " ) ; 
 + break ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new RuntimeException ( e ) ; 
 + } 
 + } 
 + } 
 + 
 + void close ( ) throws IOException 
 + { 
 + server . close ( ) ; 
 + } 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index f1404f6 . . 713ae51 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 37 , 8 + 37 , 10 @ @ import com . google . common . collect . Multimaps ; 
 import org . apache . cassandra . concurrent . * ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . db . * ; 
 + import org . apache . cassandra . db . commitlog . CommitLog ; 
 import org . apache . cassandra . dht . * ; 
 import org . apache . cassandra . gms . * ; 
 + import org . apache . cassandra . io . DeletionService ; 
 import org . apache . cassandra . io . sstable . SSTable ; 
 import org . apache . cassandra . io . sstable . SSTableReader ; 
 import org . apache . cassandra . locator . * ; 
 @ @ - 273 , 6 + 275 , 7 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe 
 Gossiper . instance . unregister ( this ) ; 
 Gossiper . instance . stop ( ) ; 
 MessagingService . shutdown ( ) ; 
 + StageManager . shutdownNow ( ) ; 
 } 
 
 public synchronized void initClient ( ) throws IOException 
 @ @ - 1301 , 6 + 1304 , 7 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe 
 { 
 Gossiper . instance . stop ( ) ; 
 MessagingService . shutdown ( ) ; 
 + StageManager . shutdownNow ( ) ; 
 setMode ( " Decommissioned " , true ) ; 
 / / let op be responsible for killing the process 
 } 
 @ @ - 1525 , 4 + 1529 , 43 @ @ public class StorageService implements IEndPointStateChangeSubscriber , StorageSe 
 tokenMetadata _ = tmd ; 
 return old ; 
 } 
 + 
 + / * * shuts node off to writes , empties memtables and the commit log . * / 
 + public synchronized void drain ( ) throws IOException , InterruptedException , ExecutionException 
 + { 
 + ExecutorService mutationStage = StageManager . getStage ( StageManager . MUTATION _ STAGE ) ; 
 + if ( mutationStage . isTerminated ( ) ) 
 + { 
 + logger _ . warn ( " Cannot drain node ( did it already happen ? ) " ) ; 
 + return ; 
 + } 
 + setMode ( " Starting drain process " , true ) ; 
 + Gossiper . instance . stop ( ) ; 
 + setMode ( " Draining : shutting down MessageService " , false ) ; 
 + MessagingService . shutdown ( ) ; 
 + setMode ( " Draining : emptying MessageService pools " , false ) ; 
 + MessagingService . waitFor ( ) ; 
 + 
 + / / lets flush . 
 + setMode ( " Draining : flushing column families " , false ) ; 
 + for ( String tableName : DatabaseDescriptor . getNonSystemTables ( ) ) 
 + for ( Future f : Table . open ( tableName ) . flush ( ) ) 
 + f . get ( ) ; 
 + 
 + 
 + setMode ( " Draining : replaying commit log " , false ) ; 
 + CommitLog . instance ( ) . forceNewSegment ( ) ; 
 + / / want to make sure that any segments deleted as a result of flushing are gone . 
 + DeletionService . waitFor ( ) ; 
 + CommitLog . recover ( ) ; 
 + 
 + / / commit log recovery just sends work to the mutation stage . ( there could have already been work there anyway . 
 + / / Either way , we need to let this one drain naturally , and then we ' re finished . 
 + setMode ( " Draining : clearing mutation stage " , false ) ; 
 + mutationStage . shutdown ( ) ; 
 + while ( ! mutationStage . isTerminated ( ) ) 
 + mutationStage . awaitTermination ( 5 , TimeUnit . SECONDS ) ; 
 + 
 + setMode ( " Node is drained " , true ) ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 index 638430e . . dc1e8b5 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 @ @ - 23 , 6 + 23 , 7 @ @ import java . net . UnknownHostException ; 
 import java . util . List ; 
 import java . util . Map ; 
 import java . util . Set ; 
 + import java . util . concurrent . ExecutionException ; 
 import java . util . concurrent . FutureTask ; 
 
 import org . apache . cassandra . dht . Range ; 
 @ @ - 165 , 4 + 166 , 7 @ @ public interface StorageServiceMBean 
 
 / * * get the operational mode ( leaving , joining , normal , decommissioned , client ) * * / 
 public String getOperationMode ( ) ; 
 + 
 + / * * makes node unavailable for writes , flushes memtables and replays commitlog . * / 
 + public void drain ( ) throws IOException , InterruptedException , ExecutionException ; 
 }
