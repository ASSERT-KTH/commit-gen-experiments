BLEU SCORE: 0.013934865340421458

TEST MSG: Properly close StreamCompressionInputStream to release any ByteBuffer
GENERATED MSG: Remove pre - 3 . 0 streaming compatibility code for 4 . 0

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 2498270 . . 5a8ab47 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 4 . 0 <nl> + * Properly close StreamCompressionInputStream to release any ByteBuf ( CASSANDRA - 13906 ) <nl> * Add SERIAL and LOCAL _ SERIAL support for cassandra - stress ( CASSANDRA - 13925 ) <nl> * LCS needlessly checks for L0 STCS candidates multiple times ( CASSANDRA - 12961 ) <nl> * Correctly close netty channels when a stream session ends ( CASSANDRA - 13905 ) <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamReader . java b / src / java / org / apache / cassandra / streaming / StreamReader . java <nl> index 590ba5f . . f4eb9c4 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamReader . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamReader . java <nl> @ @ - 106 , 12 + 106 , 12 @ @ public class StreamReader <nl> session . planId ( ) , fileSeqNum , session . peer , repairedAt , totalSize , cfs . keyspace . getName ( ) , <nl> cfs . getTableName ( ) , pendingRepair ) ; <nl> <nl> - <nl> - TrackedDataInputPlus in = new TrackedDataInputPlus ( new StreamCompressionInputStream ( inputPlus , StreamMessage . CURRENT _ VERSION ) ) ; <nl> - StreamDeserializer deserializer = new StreamDeserializer ( cfs . metadata ( ) , in , inputVersion , getHeader ( cfs . metadata ( ) ) ) ; <nl> + StreamDeserializer deserializer = null ; <nl> SSTableMultiWriter writer = null ; <nl> - try <nl> + try ( StreamCompressionInputStream streamCompressionInputStream = new StreamCompressionInputStream ( inputPlus , StreamMessage . CURRENT _ VERSION ) ) <nl> { <nl> + TrackedDataInputPlus in = new TrackedDataInputPlus ( streamCompressionInputStream ) ; <nl> + deserializer = new StreamDeserializer ( cfs . metadata ( ) , in , inputVersion , getHeader ( cfs . metadata ( ) ) ) ; <nl> writer = createWriter ( cfs , totalSize , repairedAt , pendingRepair , format ) ; <nl> while ( in . getBytesRead ( ) < totalSize ) <nl> { <nl> @ @ - 125 , 8 + 125 , 9 @ @ public class StreamReader <nl> } <nl> catch ( Throwable e ) <nl> { <nl> + Object partitionKey = deserializer ! = null ? deserializer . partitionKey ( ) : " " ; <nl> logger . warn ( " [ Stream { } ] Error while reading partition { } from stream on ks = ' { } ' and table = ' { } ' . " , <nl> - session . planId ( ) , deserializer . partitionKey ( ) , cfs . keyspace . getName ( ) , cfs . getTableName ( ) , e ) ; <nl> + session . planId ( ) , partitionKey , cfs . keyspace . getName ( ) , cfs . getTableName ( ) , e ) ; <nl> if ( writer ! = null ) <nl> { <nl> writer . abort ( e ) ; <nl> diff - - git a / src / java / org / apache / cassandra / streaming / compress / CompressedInputStream . java b / src / java / org / apache / cassandra / streaming / compress / CompressedInputStream . java <nl> index 76f76ea . . 4b9fc61 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / compress / CompressedInputStream . java <nl> + + + b / src / java / org / apache / cassandra / streaming / compress / CompressedInputStream . java <nl> @ @ - 44 , 7 + 44 , 7 @ @ import org . apache . cassandra . utils . WrappedRunnable ; <nl> * InputStream which reads data from underlining source with given { @ link CompressionInfo } . Uses { @ link # buffer } as a buffer <nl> * for uncompressed data ( which is read by stream consumers - { @ link StreamDeserializer } in this case ) . <nl> * / <nl> - public class CompressedInputStream extends RebufferingInputStream <nl> + public class CompressedInputStream extends RebufferingInputStream implements AutoCloseable <nl> { <nl> <nl> private static final Logger logger = LoggerFactory . getLogger ( CompressedInputStream . class ) ; <nl> @ @ - 200 , 6 + 200 , 8 @ @ public class CompressedInputStream extends RebufferingInputStream <nl> } <nl> <nl> / * * <nl> + * { @ inheritDoc } <nl> + * <nl> * Releases the resources specific to this instance , but not the { @ link DataInputPlus } that is used by the { @ link Reader } . <nl> * / <nl> @ Override <nl> diff - - git a / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java b / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java <nl> index e40788b . . bd44209 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java <nl> + + + b / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java <nl> @ @ - 75 , 14 + 75 , 12 @ @ public class CompressedStreamReader extends StreamReader <nl> session . planId ( ) , fileSeqNum , session . peer , repairedAt , totalSize , cfs . keyspace . getName ( ) , pendingRepair , <nl> cfs . getTableName ( ) ) ; <nl> <nl> - CompressedInputStream cis = new CompressedInputStream ( inputPlus , compressionInfo , <nl> - ChecksumType . CRC32 , cfs : : getCrcCheckChance ) ; <nl> - TrackedDataInputPlus in = new TrackedDataInputPlus ( cis ) ; <nl> - <nl> - StreamDeserializer deserializer = new StreamDeserializer ( cfs . metadata ( ) , in , inputVersion , getHeader ( cfs . metadata ( ) ) ) ; <nl> + StreamDeserializer deserializer = null ; <nl> SSTableMultiWriter writer = null ; <nl> - try <nl> + try ( CompressedInputStream cis = new CompressedInputStream ( inputPlus , compressionInfo , ChecksumType . CRC32 , cfs : : getCrcCheckChance ) ) <nl> { <nl> + TrackedDataInputPlus in = new TrackedDataInputPlus ( cis ) ; <nl> + deserializer = new StreamDeserializer ( cfs . metadata ( ) , in , inputVersion , getHeader ( cfs . metadata ( ) ) ) ; <nl> writer = createWriter ( cfs , totalSize , repairedAt , pendingRepair , format ) ; <nl> String filename = writer . getFilename ( ) ; <nl> int sectionIdx = 0 ; <nl> @ @ - 109 , 8 + 107 , 9 @ @ public class CompressedStreamReader extends StreamReader <nl> } <nl> catch ( Throwable e ) <nl> { <nl> + Object partitionKey = deserializer ! = null ? deserializer . partitionKey ( ) : " " ; <nl> logger . warn ( " [ Stream { } ] Error while reading partition { } from stream on ks = ' { } ' and table = ' { } ' . " , <nl> - session . planId ( ) , deserializer . partitionKey ( ) , cfs . keyspace . getName ( ) , cfs . getTableName ( ) ) ; <nl> + session . planId ( ) , partitionKey , cfs . keyspace . getName ( ) , cfs . getTableName ( ) ) ; <nl> if ( writer ! = null ) <nl> { <nl> writer . abort ( e ) ; <nl> @ @ - 119 , 10 + 118 , 6 @ @ public class CompressedStreamReader extends StreamReader <nl> throw e ; <nl> throw Throwables . propagate ( e ) ; <nl> } <nl> - finally <nl> - { <nl> - cis . close ( ) ; <nl> - } <nl> } <nl> <nl> @ Override <nl> diff - - git a / src / java / org / apache / cassandra / streaming / compress / StreamCompressionInputStream . java b / src / java / org / apache / cassandra / streaming / compress / StreamCompressionInputStream . java <nl> index 4b1459d . . daf6d28 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / compress / StreamCompressionInputStream . java <nl> + + + b / src / java / org / apache / cassandra / streaming / compress / StreamCompressionInputStream . java <nl> @ @ - 31 , 7 + 31 , 7 @ @ import org . apache . cassandra . io . util . RebufferingInputStream ; <nl> import org . apache . cassandra . net . async . RebufferingByteBufDataInputPlus ; <nl> import org . apache . cassandra . streaming . async . StreamCompressionSerializer ; <nl> <nl> - public class StreamCompressionInputStream extends RebufferingInputStream <nl> + public class StreamCompressionInputStream extends RebufferingInputStream implements AutoCloseable <nl> { <nl> / * * <nl> * The stream which contains buffers of compressed data that came from the peer . <nl> @ @ - 70 , 6 + 70 , 11 @ @ public class StreamCompressionInputStream extends RebufferingInputStream <nl> buffer = currentBuf . nioBuffer ( 0 , currentBuf . readableBytes ( ) ) ; <nl> } <nl> <nl> + / * * <nl> + * { @ inheritDoc } <nl> + * <nl> + * Close resources except { @ link # dataInputPlus } as that needs to remain open for other streaming activity . <nl> + * / <nl> @ Override <nl> public void close ( ) <nl> {
NEAREST DIFF (one line): ELIMINATEDSENTENCE

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 2498270 . . 5a8ab47 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 4 . 0 
 + * Properly close StreamCompressionInputStream to release any ByteBuf ( CASSANDRA - 13906 ) 
 * Add SERIAL and LOCAL _ SERIAL support for cassandra - stress ( CASSANDRA - 13925 ) 
 * LCS needlessly checks for L0 STCS candidates multiple times ( CASSANDRA - 12961 ) 
 * Correctly close netty channels when a stream session ends ( CASSANDRA - 13905 ) 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamReader . java b / src / java / org / apache / cassandra / streaming / StreamReader . java 
 index 590ba5f . . f4eb9c4 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamReader . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamReader . java 
 @ @ - 106 , 12 + 106 , 12 @ @ public class StreamReader 
 session . planId ( ) , fileSeqNum , session . peer , repairedAt , totalSize , cfs . keyspace . getName ( ) , 
 cfs . getTableName ( ) , pendingRepair ) ; 
 
 - 
 - TrackedDataInputPlus in = new TrackedDataInputPlus ( new StreamCompressionInputStream ( inputPlus , StreamMessage . CURRENT _ VERSION ) ) ; 
 - StreamDeserializer deserializer = new StreamDeserializer ( cfs . metadata ( ) , in , inputVersion , getHeader ( cfs . metadata ( ) ) ) ; 
 + StreamDeserializer deserializer = null ; 
 SSTableMultiWriter writer = null ; 
 - try 
 + try ( StreamCompressionInputStream streamCompressionInputStream = new StreamCompressionInputStream ( inputPlus , StreamMessage . CURRENT _ VERSION ) ) 
 { 
 + TrackedDataInputPlus in = new TrackedDataInputPlus ( streamCompressionInputStream ) ; 
 + deserializer = new StreamDeserializer ( cfs . metadata ( ) , in , inputVersion , getHeader ( cfs . metadata ( ) ) ) ; 
 writer = createWriter ( cfs , totalSize , repairedAt , pendingRepair , format ) ; 
 while ( in . getBytesRead ( ) < totalSize ) 
 { 
 @ @ - 125 , 8 + 125 , 9 @ @ public class StreamReader 
 } 
 catch ( Throwable e ) 
 { 
 + Object partitionKey = deserializer ! = null ? deserializer . partitionKey ( ) : " " ; 
 logger . warn ( " [ Stream { } ] Error while reading partition { } from stream on ks = ' { } ' and table = ' { } ' . " , 
 - session . planId ( ) , deserializer . partitionKey ( ) , cfs . keyspace . getName ( ) , cfs . getTableName ( ) , e ) ; 
 + session . planId ( ) , partitionKey , cfs . keyspace . getName ( ) , cfs . getTableName ( ) , e ) ; 
 if ( writer ! = null ) 
 { 
 writer . abort ( e ) ; 
 diff - - git a / src / java / org / apache / cassandra / streaming / compress / CompressedInputStream . java b / src / java / org / apache / cassandra / streaming / compress / CompressedInputStream . java 
 index 76f76ea . . 4b9fc61 100644 
 - - - a / src / java / org / apache / cassandra / streaming / compress / CompressedInputStream . java 
 + + + b / src / java / org / apache / cassandra / streaming / compress / CompressedInputStream . java 
 @ @ - 44 , 7 + 44 , 7 @ @ import org . apache . cassandra . utils . WrappedRunnable ; 
 * InputStream which reads data from underlining source with given { @ link CompressionInfo } . Uses { @ link # buffer } as a buffer 
 * for uncompressed data ( which is read by stream consumers - { @ link StreamDeserializer } in this case ) . 
 * / 
 - public class CompressedInputStream extends RebufferingInputStream 
 + public class CompressedInputStream extends RebufferingInputStream implements AutoCloseable 
 { 
 
 private static final Logger logger = LoggerFactory . getLogger ( CompressedInputStream . class ) ; 
 @ @ - 200 , 6 + 200 , 8 @ @ public class CompressedInputStream extends RebufferingInputStream 
 } 
 
 / * * 
 + * { @ inheritDoc } 
 + * 
 * Releases the resources specific to this instance , but not the { @ link DataInputPlus } that is used by the { @ link Reader } . 
 * / 
 @ Override 
 diff - - git a / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java b / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java 
 index e40788b . . bd44209 100644 
 - - - a / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java 
 + + + b / src / java / org / apache / cassandra / streaming / compress / CompressedStreamReader . java 
 @ @ - 75 , 14 + 75 , 12 @ @ public class CompressedStreamReader extends StreamReader 
 session . planId ( ) , fileSeqNum , session . peer , repairedAt , totalSize , cfs . keyspace . getName ( ) , pendingRepair , 
 cfs . getTableName ( ) ) ; 
 
 - CompressedInputStream cis = new CompressedInputStream ( inputPlus , compressionInfo , 
 - ChecksumType . CRC32 , cfs : : getCrcCheckChance ) ; 
 - TrackedDataInputPlus in = new TrackedDataInputPlus ( cis ) ; 
 - 
 - StreamDeserializer deserializer = new StreamDeserializer ( cfs . metadata ( ) , in , inputVersion , getHeader ( cfs . metadata ( ) ) ) ; 
 + StreamDeserializer deserializer = null ; 
 SSTableMultiWriter writer = null ; 
 - try 
 + try ( CompressedInputStream cis = new CompressedInputStream ( inputPlus , compressionInfo , ChecksumType . CRC32 , cfs : : getCrcCheckChance ) ) 
 { 
 + TrackedDataInputPlus in = new TrackedDataInputPlus ( cis ) ; 
 + deserializer = new StreamDeserializer ( cfs . metadata ( ) , in , inputVersion , getHeader ( cfs . metadata ( ) ) ) ; 
 writer = createWriter ( cfs , totalSize , repairedAt , pendingRepair , format ) ; 
 String filename = writer . getFilename ( ) ; 
 int sectionIdx = 0 ; 
 @ @ - 109 , 8 + 107 , 9 @ @ public class CompressedStreamReader extends StreamReader 
 } 
 catch ( Throwable e ) 
 { 
 + Object partitionKey = deserializer ! = null ? deserializer . partitionKey ( ) : " " ; 
 logger . warn ( " [ Stream { } ] Error while reading partition { } from stream on ks = ' { } ' and table = ' { } ' . " , 
 - session . planId ( ) , deserializer . partitionKey ( ) , cfs . keyspace . getName ( ) , cfs . getTableName ( ) ) ; 
 + session . planId ( ) , partitionKey , cfs . keyspace . getName ( ) , cfs . getTableName ( ) ) ; 
 if ( writer ! = null ) 
 { 
 writer . abort ( e ) ; 
 @ @ - 119 , 10 + 118 , 6 @ @ public class CompressedStreamReader extends StreamReader 
 throw e ; 
 throw Throwables . propagate ( e ) ; 
 } 
 - finally 
 - { 
 - cis . close ( ) ; 
 - } 
 } 
 
 @ Override 
 diff - - git a / src / java / org / apache / cassandra / streaming / compress / StreamCompressionInputStream . java b / src / java / org / apache / cassandra / streaming / compress / StreamCompressionInputStream . java 
 index 4b1459d . . daf6d28 100644 
 - - - a / src / java / org / apache / cassandra / streaming / compress / StreamCompressionInputStream . java 
 + + + b / src / java / org / apache / cassandra / streaming / compress / StreamCompressionInputStream . java 
 @ @ - 31 , 7 + 31 , 7 @ @ import org . apache . cassandra . io . util . RebufferingInputStream ; 
 import org . apache . cassandra . net . async . RebufferingByteBufDataInputPlus ; 
 import org . apache . cassandra . streaming . async . StreamCompressionSerializer ; 
 
 - public class StreamCompressionInputStream extends RebufferingInputStream 
 + public class StreamCompressionInputStream extends RebufferingInputStream implements AutoCloseable 
 { 
 / * * 
 * The stream which contains buffers of compressed data that came from the peer . 
 @ @ - 70 , 6 + 70 , 11 @ @ public class StreamCompressionInputStream extends RebufferingInputStream 
 buffer = currentBuf . nioBuffer ( 0 , currentBuf . readableBytes ( ) ) ; 
 } 
 
 + / * * 
 + * { @ inheritDoc } 
 + * 
 + * Close resources except { @ link # dataInputPlus } as that needs to remain open for other streaming activity . 
 + * / 
 @ Override 
 public void close ( ) 
 {

NEAREST DIFF:
ELIMINATEDSENTENCE
