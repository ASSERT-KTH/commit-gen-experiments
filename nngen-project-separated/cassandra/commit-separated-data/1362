BLEU SCORE: 0.018738883683389617

TEST MSG: Follow up to avoid mutating row while read repair is happening
GENERATED MSG: Remove system tables accounting from schema

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index d6a0af9 . . dcae493 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 1 . 9 <nl> + * Avoid race condition during read repair ( CASSANDRA - 9460 ) <nl> * ( cqlsh ) default load - from - file encoding to utf - 8 ( CASSANDRA - 9898 ) <nl> * Avoid returning Permission . NONE when failing to query users table ( CASSANDRA - 10168 ) <nl> * ( cqlsh ) Allow encoding to be set through command line ( CASSANDRA - 10004 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / ReadCommand . java b / src / java / org / apache / cassandra / db / ReadCommand . java <nl> index dedff6f . . cd86336 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ReadCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / ReadCommand . java <nl> @ @ - 118 , 9 + 118 , 9 @ @ public abstract class ReadCommand implements IReadCommand , Pageable <nl> } <nl> <nl> / / maybeTrim removes columns from a response that is too long <nl> - public void maybeTrim ( Row row ) <nl> + public Row maybeTrim ( Row row ) <nl> { <nl> - / / noop <nl> + return row ; <nl> } <nl> <nl> public long getTimeout ( ) <nl> diff - - git a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java <nl> index 6995193 . . 461a3a1 100644 <nl> - - - a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java <nl> + + + b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java <nl> @ @ - 113 , 12 + 113 , 12 @ @ public class SliceFromReadCommand extends ReadCommand <nl> } <nl> <nl> @ Override <nl> - public void maybeTrim ( Row row ) <nl> + public Row maybeTrim ( Row row ) <nl> { <nl> if ( ( row = = null ) | | ( row . cf = = null ) ) <nl> - return ; <nl> + return row ; <nl> <nl> - filter . trim ( row . cf , getOriginalRequestedCount ( ) , timestamp ) ; <nl> + return new Row ( row . key , filter . trim ( row . cf , getOriginalRequestedCount ( ) , timestamp ) ) ; <nl> } <nl> <nl> public IDiskAtomFilter filter ( ) <nl> diff - - git a / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java b / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java <nl> index 65925b1 . . 973477f 100644 <nl> - - - a / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java <nl> + + + b / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java <nl> @ @ - 342 , 14 + 342 , 17 @ @ public class SliceQueryFilter implements IDiskAtomFilter <nl> return new ColumnCounter . GroupByPrefix ( now , comparator , compositesToGroup ) ; <nl> } <nl> <nl> - public void trim ( ColumnFamily cf , int trimTo , long now ) <nl> + public ColumnFamily trim ( ColumnFamily cf , int trimTo , long now ) <nl> { <nl> / / each cell can increment the count by at most one , so if we have fewer cells than trimTo , we can skip trimming <nl> if ( cf . getColumnCount ( ) < trimTo ) <nl> - return ; <nl> + return cf ; <nl> <nl> ColumnCounter counter = columnCounter ( cf . getComparator ( ) , now ) ; <nl> <nl> + ColumnFamily trimmedCf = cf . getFactory ( ) . create ( cf . metadata ( ) , reversed , trimTo ) ; <nl> + trimmedCf . delete ( cf ) ; <nl> + <nl> Collection < Cell > cells = reversed <nl> ? cf . getReverseSortedColumns ( ) <nl> : cf . getSortedColumns ( ) ; <nl> @ @ - 363 , 14 + 366 , 15 @ @ public class SliceQueryFilter implements IDiskAtomFilter <nl> <nl> if ( counter . live ( ) > trimTo ) <nl> { <nl> - iter . remove ( ) ; <nl> - while ( iter . hasNext ( ) ) <nl> - { <nl> - iter . next ( ) ; <nl> - iter . remove ( ) ; <nl> - } <nl> + break ; <nl> + } <nl> + else <nl> + { <nl> + trimmedCf . addColumn ( cell ) ; <nl> } <nl> } <nl> + <nl> + return trimmedCf ; <nl> } <nl> <nl> public Composite start ( ) <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageProxy . java b / src / java / org / apache / cassandra / service / StorageProxy . java <nl> index 1536427 . . 161bec8 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageProxy . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageProxy . java <nl> @ @ - 1347 , 7 + 1347 , 7 @ @ public class StorageProxy implements StorageProxyMBean <nl> Row row = exec . get ( ) ; <nl> if ( row ! = null ) <nl> { <nl> - exec . command . maybeTrim ( row ) ; <nl> + row = exec . command . maybeTrim ( row ) ; <nl> rows . add ( row ) ; <nl> } <nl> <nl> @ @ - 1466 , 7 + 1466 , 7 @ @ public class StorageProxy implements StorageProxyMBean <nl> <nl> if ( row ! = null ) <nl> { <nl> - command . maybeTrim ( row ) ; <nl> + row = command . maybeTrim ( row ) ; <nl> rows . add ( row ) ; <nl> } <nl> }
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 12cc92a . . 48cb945 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 43 , 6 + 43 , 7 @ @ <nl> * Fix binary protocol NEW _ NODE event ( CASSANDRA - 4679 ) <nl> * Fix potential infinite loop in tombstone compaction ( CASSANDRA - 4781 ) <nl> * Remove system tables accounting from schema ( CASSANDRA - 4850 ) <nl> + * Force provided columns in clustering key order in ' CLUSTERING ORDER BY ' ( CASSANDRA - 4881 ) <nl> Merged from 1 . 1 : <nl> * add get [ Row | Key ] CacheEntries to CacheServiceMBean ( CASSANDRA - 4859 ) <nl> * fix get _ paged _ slice to wrap to next row correctly ( CASSANDRA - 4816 ) <nl> diff - - git a / src / java / org / apache / cassandra / cql3 / statements / CreateColumnFamilyStatement . java b / src / java / org / apache / cassandra / cql3 / statements / CreateColumnFamilyStatement . java <nl> index 1775398 . . b8ea732 100644 <nl> - - - a / src / java / org / apache / cassandra / cql3 / statements / CreateColumnFamilyStatement . java <nl> + + + b / src / java / org / apache / cassandra / cql3 / statements / CreateColumnFamilyStatement . java <nl> @ @ - 20 , 6 + 20 , 7 @ @ package org . apache . cassandra . cql3 . statements ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . ArrayList ; <nl> import java . util . HashMap ; <nl> + import java . util . LinkedHashMap ; <nl> import java . util . List ; <nl> import java . util . Map ; <nl> <nl> @ @ - 144 , 7 + 145 , 7 @ @ public class CreateColumnFamilyStatement extends SchemaAlteringStatement <nl> <nl> private final List < List < ColumnIdentifier > > keyAliases = new ArrayList < List < ColumnIdentifier > > ( ) ; <nl> private final List < ColumnIdentifier > columnAliases = new ArrayList < ColumnIdentifier > ( ) ; <nl> - private final Map < ColumnIdentifier , Boolean > definedOrdering = new HashMap < ColumnIdentifier , Boolean > ( ) ; <nl> + private final Map < ColumnIdentifier , Boolean > definedOrdering = new LinkedHashMap < ColumnIdentifier , Boolean > ( ) ; / / Insertion ordering is important <nl> <nl> private boolean useCompactStorage ; <nl> private final Multiset < ColumnIdentifier > definedNames = HashMultiset . create ( 1 ) ; <nl> @ @ - 305 , 6 + 306 , 28 @ @ public class CreateColumnFamilyStatement extends SchemaAlteringStatement <nl> : CFDefinition . definitionType ; <nl> } <nl> <nl> + <nl> + / / If we give a clustering order , we must explicitely do so for all aliases and in the order of the PK <nl> + if ( ! definedOrdering . isEmpty ( ) ) <nl> + { <nl> + if ( definedOrdering . size ( ) > columnAliases . size ( ) ) <nl> + throw new InvalidRequestException ( " Too much columns provided for CLUSTERING ORDER " ) ; <nl> + <nl> + int i = 0 ; <nl> + for ( ColumnIdentifier id : definedOrdering . keySet ( ) ) <nl> + { <nl> + ColumnIdentifier c = columnAliases . get ( i ) ; <nl> + if ( ! id . equals ( c ) ) <nl> + { <nl> + if ( definedOrdering . containsKey ( c ) ) <nl> + throw new InvalidRequestException ( String . format ( " The order of columns in the CLUSTERING ORDER directive must be the one of the clustering key ( % s must appear before % s ) " , c , id ) ) ; <nl> + else <nl> + throw new InvalidRequestException ( String . format ( " Missing CLUSTERING ORDER for column % s " , c ) ) ; <nl> + } <nl> + + + i ; <nl> + } <nl> + } <nl> + <nl> return new ParsedStatement . Prepared ( stmt ) ; <nl> } <nl>

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index d6a0af9 . . dcae493 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 1 . 9 
 + * Avoid race condition during read repair ( CASSANDRA - 9460 ) 
 * ( cqlsh ) default load - from - file encoding to utf - 8 ( CASSANDRA - 9898 ) 
 * Avoid returning Permission . NONE when failing to query users table ( CASSANDRA - 10168 ) 
 * ( cqlsh ) Allow encoding to be set through command line ( CASSANDRA - 10004 ) 
 diff - - git a / src / java / org / apache / cassandra / db / ReadCommand . java b / src / java / org / apache / cassandra / db / ReadCommand . java 
 index dedff6f . . cd86336 100644 
 - - - a / src / java / org / apache / cassandra / db / ReadCommand . java 
 + + + b / src / java / org / apache / cassandra / db / ReadCommand . java 
 @ @ - 118 , 9 + 118 , 9 @ @ public abstract class ReadCommand implements IReadCommand , Pageable 
 } 
 
 / / maybeTrim removes columns from a response that is too long 
 - public void maybeTrim ( Row row ) 
 + public Row maybeTrim ( Row row ) 
 { 
 - / / noop 
 + return row ; 
 } 
 
 public long getTimeout ( ) 
 diff - - git a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java 
 index 6995193 . . 461a3a1 100644 
 - - - a / src / java / org / apache / cassandra / db / SliceFromReadCommand . java 
 + + + b / src / java / org / apache / cassandra / db / SliceFromReadCommand . java 
 @ @ - 113 , 12 + 113 , 12 @ @ public class SliceFromReadCommand extends ReadCommand 
 } 
 
 @ Override 
 - public void maybeTrim ( Row row ) 
 + public Row maybeTrim ( Row row ) 
 { 
 if ( ( row = = null ) | | ( row . cf = = null ) ) 
 - return ; 
 + return row ; 
 
 - filter . trim ( row . cf , getOriginalRequestedCount ( ) , timestamp ) ; 
 + return new Row ( row . key , filter . trim ( row . cf , getOriginalRequestedCount ( ) , timestamp ) ) ; 
 } 
 
 public IDiskAtomFilter filter ( ) 
 diff - - git a / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java b / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java 
 index 65925b1 . . 973477f 100644 
 - - - a / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java 
 + + + b / src / java / org / apache / cassandra / db / filter / SliceQueryFilter . java 
 @ @ - 342 , 14 + 342 , 17 @ @ public class SliceQueryFilter implements IDiskAtomFilter 
 return new ColumnCounter . GroupByPrefix ( now , comparator , compositesToGroup ) ; 
 } 
 
 - public void trim ( ColumnFamily cf , int trimTo , long now ) 
 + public ColumnFamily trim ( ColumnFamily cf , int trimTo , long now ) 
 { 
 / / each cell can increment the count by at most one , so if we have fewer cells than trimTo , we can skip trimming 
 if ( cf . getColumnCount ( ) < trimTo ) 
 - return ; 
 + return cf ; 
 
 ColumnCounter counter = columnCounter ( cf . getComparator ( ) , now ) ; 
 
 + ColumnFamily trimmedCf = cf . getFactory ( ) . create ( cf . metadata ( ) , reversed , trimTo ) ; 
 + trimmedCf . delete ( cf ) ; 
 + 
 Collection < Cell > cells = reversed 
 ? cf . getReverseSortedColumns ( ) 
 : cf . getSortedColumns ( ) ; 
 @ @ - 363 , 14 + 366 , 15 @ @ public class SliceQueryFilter implements IDiskAtomFilter 
 
 if ( counter . live ( ) > trimTo ) 
 { 
 - iter . remove ( ) ; 
 - while ( iter . hasNext ( ) ) 
 - { 
 - iter . next ( ) ; 
 - iter . remove ( ) ; 
 - } 
 + break ; 
 + } 
 + else 
 + { 
 + trimmedCf . addColumn ( cell ) ; 
 } 
 } 
 + 
 + return trimmedCf ; 
 } 
 
 public Composite start ( ) 
 diff - - git a / src / java / org / apache / cassandra / service / StorageProxy . java b / src / java / org / apache / cassandra / service / StorageProxy . java 
 index 1536427 . . 161bec8 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageProxy . java 
 + + + b / src / java / org / apache / cassandra / service / StorageProxy . java 
 @ @ - 1347 , 7 + 1347 , 7 @ @ public class StorageProxy implements StorageProxyMBean 
 Row row = exec . get ( ) ; 
 if ( row ! = null ) 
 { 
 - exec . command . maybeTrim ( row ) ; 
 + row = exec . command . maybeTrim ( row ) ; 
 rows . add ( row ) ; 
 } 
 
 @ @ - 1466 , 7 + 1466 , 7 @ @ public class StorageProxy implements StorageProxyMBean 
 
 if ( row ! = null ) 
 { 
 - command . maybeTrim ( row ) ; 
 + row = command . maybeTrim ( row ) ; 
 rows . add ( row ) ; 
 } 
 }

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 12cc92a . . 48cb945 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 43 , 6 + 43 , 7 @ @ 
 * Fix binary protocol NEW _ NODE event ( CASSANDRA - 4679 ) 
 * Fix potential infinite loop in tombstone compaction ( CASSANDRA - 4781 ) 
 * Remove system tables accounting from schema ( CASSANDRA - 4850 ) 
 + * Force provided columns in clustering key order in ' CLUSTERING ORDER BY ' ( CASSANDRA - 4881 ) 
 Merged from 1 . 1 : 
 * add get [ Row | Key ] CacheEntries to CacheServiceMBean ( CASSANDRA - 4859 ) 
 * fix get _ paged _ slice to wrap to next row correctly ( CASSANDRA - 4816 ) 
 diff - - git a / src / java / org / apache / cassandra / cql3 / statements / CreateColumnFamilyStatement . java b / src / java / org / apache / cassandra / cql3 / statements / CreateColumnFamilyStatement . java 
 index 1775398 . . b8ea732 100644 
 - - - a / src / java / org / apache / cassandra / cql3 / statements / CreateColumnFamilyStatement . java 
 + + + b / src / java / org / apache / cassandra / cql3 / statements / CreateColumnFamilyStatement . java 
 @ @ - 20 , 6 + 20 , 7 @ @ package org . apache . cassandra . cql3 . statements ; 
 import java . nio . ByteBuffer ; 
 import java . util . ArrayList ; 
 import java . util . HashMap ; 
 + import java . util . LinkedHashMap ; 
 import java . util . List ; 
 import java . util . Map ; 
 
 @ @ - 144 , 7 + 145 , 7 @ @ public class CreateColumnFamilyStatement extends SchemaAlteringStatement 
 
 private final List < List < ColumnIdentifier > > keyAliases = new ArrayList < List < ColumnIdentifier > > ( ) ; 
 private final List < ColumnIdentifier > columnAliases = new ArrayList < ColumnIdentifier > ( ) ; 
 - private final Map < ColumnIdentifier , Boolean > definedOrdering = new HashMap < ColumnIdentifier , Boolean > ( ) ; 
 + private final Map < ColumnIdentifier , Boolean > definedOrdering = new LinkedHashMap < ColumnIdentifier , Boolean > ( ) ; / / Insertion ordering is important 
 
 private boolean useCompactStorage ; 
 private final Multiset < ColumnIdentifier > definedNames = HashMultiset . create ( 1 ) ; 
 @ @ - 305 , 6 + 306 , 28 @ @ public class CreateColumnFamilyStatement extends SchemaAlteringStatement 
 : CFDefinition . definitionType ; 
 } 
 
 + 
 + / / If we give a clustering order , we must explicitely do so for all aliases and in the order of the PK 
 + if ( ! definedOrdering . isEmpty ( ) ) 
 + { 
 + if ( definedOrdering . size ( ) > columnAliases . size ( ) ) 
 + throw new InvalidRequestException ( " Too much columns provided for CLUSTERING ORDER " ) ; 
 + 
 + int i = 0 ; 
 + for ( ColumnIdentifier id : definedOrdering . keySet ( ) ) 
 + { 
 + ColumnIdentifier c = columnAliases . get ( i ) ; 
 + if ( ! id . equals ( c ) ) 
 + { 
 + if ( definedOrdering . containsKey ( c ) ) 
 + throw new InvalidRequestException ( String . format ( " The order of columns in the CLUSTERING ORDER directive must be the one of the clustering key ( % s must appear before % s ) " , c , id ) ) ; 
 + else 
 + throw new InvalidRequestException ( String . format ( " Missing CLUSTERING ORDER for column % s " , c ) ) ; 
 + } 
 + + + i ; 
 + } 
 + } 
 + 
 return new ParsedStatement . Prepared ( stmt ) ; 
 } 

