BLEU SCORE: 0.009735361505804467

TEST MSG: Make creation of system _ { auth , traces } keyspaces less fragile
GENERATED MSG: move common setup code into AbstractCassandraDaemon . patch by Amol Deshpande ; reviewed by jbellis for CASSANDRA - 1500

TEST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index 35c67c4 . . 19e0a5a 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 51 , 9 + 51 , 7 @ @ import org . apache . cassandra . db . compaction . CompactionManager ; <nl> import org . apache . cassandra . db . index . SecondaryIndex ; <nl> import org . apache . cassandra . dht . * ; <nl> import org . apache . cassandra . dht . Range ; <nl> - import org . apache . cassandra . exceptions . ConfigurationException ; <nl> - import org . apache . cassandra . exceptions . InvalidRequestException ; <nl> - import org . apache . cassandra . exceptions . UnavailableException ; <nl> + import org . apache . cassandra . exceptions . * ; <nl> import org . apache . cassandra . gms . * ; <nl> import org . apache . cassandra . io . sstable . SSTableDeletingTask ; <nl> import org . apache . cassandra . io . sstable . SSTableLoader ; <nl> @ @ - 807 , 7 + 805 , 7 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> <nl> / / if we don ' t have system _ traces keyspace at this point , then create it manually <nl> if ( Schema . instance . getKSMetaData ( TraceKeyspace . NAME ) = = null ) <nl> - MigrationManager . announceNewKeyspace ( TraceKeyspace . definition ( ) , 0 , false ) ; <nl> + maybeAddKeyspace ( TraceKeyspace . definition ( ) ) ; <nl> <nl> if ( ! isSurveyMode ) <nl> { <nl> @ @ - 872 , 14 + 870 , 14 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> / / the ks exists with the only the legacy tables defined <nl> if ( Schema . instance . getKSMetaData ( AuthKeyspace . NAME ) = = null ) <nl> { <nl> - MigrationManager . announceNewKeyspace ( AuthKeyspace . definition ( ) , 0 , false ) ; <nl> + maybeAddKeyspace ( AuthKeyspace . definition ( ) ) ; <nl> } <nl> else <nl> { <nl> for ( Map . Entry < String , CFMetaData > table : AuthKeyspace . definition ( ) . cfMetaData ( ) . entrySet ( ) ) <nl> { <nl> if ( Schema . instance . getCFMetaData ( AuthKeyspace . NAME , table . getKey ( ) ) = = null ) <nl> - MigrationManager . announceNewColumnFamily ( table . getValue ( ) ) ; <nl> + maybeAddTable ( table . getValue ( ) ) ; <nl> } <nl> } <nl> } <nl> @ @ - 894 , 6 + 892 , 30 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE <nl> MigrationManager . instance . register ( new AuthMigrationListener ( ) ) ; <nl> } <nl> <nl> + private void maybeAddTable ( CFMetaData cfm ) <nl> + { <nl> + try <nl> + { <nl> + MigrationManager . announceNewColumnFamily ( cfm ) ; <nl> + } <nl> + catch ( AlreadyExistsException e ) <nl> + { <nl> + logger . debug ( " Attempted to create new table { } , but it already exists " , cfm . cfName ) ; <nl> + } <nl> + } <nl> + <nl> + private void maybeAddKeyspace ( KSMetaData ksm ) <nl> + { <nl> + try <nl> + { <nl> + MigrationManager . announceNewKeyspace ( ksm , 0 , false ) ; <nl> + } <nl> + catch ( AlreadyExistsException e ) <nl> + { <nl> + logger . debug ( " Attempted to create new keyspace { } , but it already exists " , ksm . name ) ; <nl> + } <nl> + } <nl> + <nl> public boolean isJoined ( ) <nl> { <nl> return joined ;
NEAREST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / avro / CassandraDaemon . java b / src / java / org / apache / cassandra / avro / CassandraDaemon . java <nl> index 4f2fa7a . . 280a0ea 100644 <nl> - - - a / src / java / org / apache / cassandra / avro / CassandraDaemon . java <nl> + + + b / src / java / org / apache / cassandra / avro / CassandraDaemon . java <nl> @ @ - 19 , 28 + 19 , 13 @ @ <nl> package org . apache . cassandra . avro ; <nl> <nl> import java . io . IOException ; <nl> - import java . net . InetAddress ; <nl> - import java . util . UUID ; <nl> <nl> - import org . apache . avro . ipc . HttpServer ; <nl> - import org . apache . avro . ipc . ResponderServlet ; <nl> - import org . apache . avro . specific . SpecificResponder ; <nl> - <nl> - import org . apache . cassandra . config . ConfigurationException ; <nl> - import org . apache . cassandra . config . DatabaseDescriptor ; <nl> - import org . apache . cassandra . db . CompactionManager ; <nl> - import org . apache . cassandra . db . SystemTable ; <nl> - import org . apache . cassandra . db . Table ; <nl> - import org . apache . cassandra . db . commitlog . CommitLog ; <nl> - import org . apache . cassandra . db . migration . Migration ; <nl> - import org . apache . cassandra . service . MigrationManager ; <nl> - import org . apache . cassandra . service . StorageService ; <nl> - import org . apache . cassandra . utils . FBUtilities ; <nl> - import org . apache . cassandra . utils . Mx4jTool ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> - / / see CASSANDRA - 1440 <nl> + import org . apache . avro . ipc . ResponderServlet ; <nl> + import org . apache . avro . specific . SpecificResponder ; <nl> + import org . apache . cassandra . utils . Mx4jTool ; <nl> import org . mortbay . jetty . servlet . Context ; <nl> import org . mortbay . jetty . servlet . ServletHolder ; <nl> <nl> @ @ - 51 , 85 + 36 , 7 @ @ import org . mortbay . jetty . servlet . ServletHolder ; <nl> public class CassandraDaemon extends org . apache . cassandra . service . AbstractCassandraDaemon { <nl> private static Logger logger = LoggerFactory . getLogger ( CassandraDaemon . class ) ; <nl> private org . mortbay . jetty . Server server ; <nl> - private InetAddress listenAddr ; <nl> - private int listenPort ; <nl> - <nl> - protected void setup ( ) throws IOException <nl> - { <nl> - FBUtilities . tryMlockall ( ) ; <nl> - <nl> - listenPort = DatabaseDescriptor . getRpcPort ( ) ; <nl> - listenAddr = DatabaseDescriptor . getRpcAddress ( ) ; <nl> - <nl> - / * <nl> - * If ThriftAddress was left completely unconfigured , then assume <nl> - * the same default as ListenAddress <nl> - * / <nl> - if ( listenAddr = = null ) <nl> - listenAddr = FBUtilities . getLocalAddress ( ) ; <nl> - <nl> - Thread . setDefaultUncaughtExceptionHandler ( new Thread . UncaughtExceptionHandler ( ) <nl> - { <nl> - public void uncaughtException ( Thread t , Throwable e ) <nl> - { <nl> - logger . error ( " Fatal exception in thread " + t , e ) ; <nl> - if ( e instanceof OutOfMemoryError ) <nl> - { <nl> - System . exit ( 100 ) ; <nl> - } <nl> - } <nl> - } ) ; <nl> - <nl> - / / check the system table for mismatched partitioner . <nl> - try <nl> - { <nl> - SystemTable . checkHealth ( ) ; <nl> - } <nl> - catch ( ConfigurationException e ) <nl> - { <nl> - logger . error ( " Fatal exception during initialization " , e ) ; <nl> - System . exit ( 100 ) ; <nl> - } <nl> - <nl> - try <nl> - { <nl> - DatabaseDescriptor . loadSchemas ( ) ; <nl> - } <nl> - catch ( IOException e ) <nl> - { <nl> - logger . error ( " Fatal exception during initialization " , e ) ; <nl> - System . exit ( 100 ) ; <nl> - } <nl> - <nl> - / / initialize keyspaces <nl> - for ( String table : DatabaseDescriptor . getTables ( ) ) <nl> - { <nl> - if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " opening keyspace " + table ) ; <nl> - Table . open ( table ) ; <nl> - } <nl> <nl> - / / replay the log if necessary and check for compaction candidates <nl> - CommitLog . recover ( ) ; <nl> - CompactionManager . instance . checkAllColumnFamilies ( ) ; <nl> - <nl> - / / check to see if CL . recovery modified the lastMigrationId . if it did , we need to re apply migrations . this isn ' t <nl> - / / the same as merely reloading the schema ( which wouldn ' t perform file deletion after a DROP ) . The solution <nl> - / / is to read those migrations from disk and apply them . <nl> - UUID currentMigration = DatabaseDescriptor . getDefsVersion ( ) ; <nl> - UUID lastMigration = Migration . getLastMigrationId ( ) ; <nl> - if ( ( lastMigration ! = null ) & & ( lastMigration . timestamp ( ) > currentMigration . timestamp ( ) ) ) <nl> - { <nl> - MigrationManager . applyMigrations ( currentMigration , lastMigration ) ; <nl> - } <nl> - <nl> - SystemTable . purgeIncompatibleHints ( ) ; <nl> - <nl> - / / start server internals <nl> - StorageService . instance . initServer ( ) ; <nl> - <nl> - } <nl> - <nl> / * * hook for JSVC * / <nl> public void start ( ) throws IOException <nl> { <nl> @ @ - 139 , 7 + 46 , 6 @ @ public class CassandraDaemon extends org . apache . cassandra . service . AbstractCassan <nl> SpecificResponder responder = new SpecificResponder ( Cassandra . class , cassandraServer ) ; <nl> <nl> logger . info ( " Listening for avro clients . . . " ) ; <nl> - Mx4jTool . maybeLoad ( ) ; <nl> <nl> / / FIXME : This isn ' t actually binding to listenAddr ( it should ) . <nl> server = new org . mortbay . jetty . Server ( listenPort ) ; <nl> diff - - git a / src / java / org / apache / cassandra / service / AbstractCassandraDaemon . java b / src / java / org / apache / cassandra / service / AbstractCassandraDaemon . java <nl> index f7d5711 . . d3cb29d 100644 <nl> - - - a / src / java / org / apache / cassandra / service / AbstractCassandraDaemon . java <nl> + + + b / src / java / org / apache / cassandra / service / AbstractCassandraDaemon . java <nl> @ @ - 20 , 14 + 20 , 25 @ @ package org . apache . cassandra . service ; <nl> <nl> import java . io . File ; <nl> import java . io . IOException ; <nl> + import java . net . InetAddress ; <nl> + import java . util . UUID ; <nl> + import java . util . concurrent . RejectedExecutionException ; <nl> import java . util . concurrent . SynchronousQueue ; <nl> import java . util . concurrent . ThreadPoolExecutor ; <nl> import java . util . concurrent . TimeUnit ; <nl> - import java . util . concurrent . RejectedExecutionException ; <nl> <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> + import org . apache . cassandra . config . ConfigurationException ; <nl> + import org . apache . cassandra . config . DatabaseDescriptor ; <nl> + import org . apache . cassandra . db . CompactionManager ; <nl> + import org . apache . cassandra . db . SystemTable ; <nl> + import org . apache . cassandra . db . Table ; <nl> + import org . apache . cassandra . db . commitlog . CommitLog ; <nl> + import org . apache . cassandra . db . migration . Migration ; <nl> + import org . apache . cassandra . utils . FBUtilities ; <nl> + import org . apache . cassandra . utils . Mx4jTool ; <nl> import org . mortbay . thread . ThreadPool ; <nl> <nl> / * * <nl> @ @ - 42 , 15 + 53 , 95 @ @ public abstract class AbstractCassandraDaemon implements CassandraDaemon <nl> private static Logger logger = LoggerFactory <nl> . getLogger ( AbstractCassandraDaemon . class ) ; <nl> <nl> + protected InetAddress listenAddr ; <nl> + protected int listenPort ; <nl> + <nl> public static final int MIN _ WORKER _ THREADS = 64 ; <nl> <nl> / * * <nl> * This is a hook for concrete daemons to initialize themselves suitably . <nl> - * <nl> + * <nl> + * Subclasses should override this to finish the job ( listening on ports , etc . ) <nl> + * <nl> * @ throws IOException <nl> * / <nl> - protected abstract void setup ( ) throws IOException ; <nl> - <nl> + protected void setup ( ) throws IOException <nl> + { <nl> + 	 FBUtilities . tryMlockall ( ) ; <nl> + <nl> + listenPort = DatabaseDescriptor . getRpcPort ( ) ; <nl> + listenAddr = DatabaseDescriptor . getRpcAddress ( ) ; <nl> + <nl> + / * <nl> + * If ThriftAddress was left completely unconfigured , then assume <nl> + * the same default as ListenAddress <nl> + * / <nl> + if ( listenAddr = = null ) <nl> + listenAddr = FBUtilities . getLocalAddress ( ) ; <nl> + <nl> + Thread . setDefaultUncaughtExceptionHandler ( new Thread . UncaughtExceptionHandler ( ) <nl> + { <nl> + public void uncaughtException ( Thread t , Throwable e ) <nl> + { <nl> + logger . error ( " Fatal exception in thread " + t , e ) ; <nl> + if ( e instanceof OutOfMemoryError ) <nl> + { <nl> + System . exit ( 100 ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> + <nl> + / / check the system table for mismatched partitioner . <nl> + try <nl> + { <nl> + SystemTable . checkHealth ( ) ; <nl> + } <nl> + catch ( ConfigurationException e ) <nl> + { <nl> + logger . error ( " Fatal exception during initialization " , e ) ; <nl> + System . exit ( 100 ) ; <nl> + } <nl> + <nl> + try <nl> + { <nl> + DatabaseDescriptor . loadSchemas ( ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + logger . error ( " Fatal exception during initialization " , e ) ; <nl> + System . exit ( 100 ) ; <nl> + } <nl> + <nl> + / / initialize keyspaces <nl> + for ( String table : DatabaseDescriptor . getTables ( ) ) <nl> + { <nl> + if ( logger . isDebugEnabled ( ) ) <nl> + logger . debug ( " opening keyspace " + table ) ; <nl> + Table . open ( table ) ; <nl> + } <nl> + <nl> + / / replay the log if necessary and check for compaction candidates <nl> + CommitLog . recover ( ) ; <nl> + CompactionManager . instance . checkAllColumnFamilies ( ) ; <nl> + <nl> + / / check to see if CL . recovery modified the lastMigrationId . if it did , we need to re apply migrations . this isn ' t <nl> + / / the same as merely reloading the schema ( which wouldn ' t perform file deletion after a DROP ) . The solution <nl> + / / is to read those migrations from disk and apply them . <nl> + UUID currentMigration = DatabaseDescriptor . getDefsVersion ( ) ; <nl> + UUID lastMigration = Migration . getLastMigrationId ( ) ; <nl> + if ( ( lastMigration ! = null ) & & ( lastMigration . timestamp ( ) > currentMigration . timestamp ( ) ) ) <nl> + { <nl> + MigrationManager . applyMigrations ( currentMigration , lastMigration ) ; <nl> + } <nl> + <nl> + SystemTable . purgeIncompatibleHints ( ) ; <nl> + <nl> + / / start server internals <nl> + StorageService . instance . initServer ( ) ; <nl> + <nl> + Mx4jTool . maybeLoad ( ) ; <nl> + } <nl> + <nl> / * * <nl> * Initialize the Cassandra Daemon based on the given < a <nl> * href = " http : / / commons . apache . org / daemon / jsvc . html " > Commons <nl> @ @ - 155 , 7 + 246 , 6 @ @ public abstract class AbstractCassandraDaemon implements CassandraDaemon <nl> / * * The following are cribbed from org . mortbay . thread . concurrent * / <nl> / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> <nl> - @ Override <nl> public boolean dispatch ( Runnable job ) <nl> { <nl> try <nl> @ @ - 170 , 25 + 260 , 21 @ @ public abstract class AbstractCassandraDaemon implements CassandraDaemon <nl> } <nl> } <nl> <nl> - @ Override <nl> public int getIdleThreads ( ) <nl> { <nl> return getPoolSize ( ) - getActiveCount ( ) ; <nl> } <nl> <nl> - @ Override <nl> public int getThreads ( ) <nl> { <nl> return getPoolSize ( ) ; <nl> } <nl> <nl> - @ Override <nl> public boolean isLowOnThreads ( ) <nl> { <nl> return getActiveCount ( ) > = getMaximumPoolSize ( ) ; <nl> } <nl> <nl> - @ Override <nl> public void join ( ) throws InterruptedException <nl> { <nl> this . awaitTermination ( Long . MAX _ VALUE , TimeUnit . MILLISECONDS ) ; <nl> diff - - git a / src / java / org / apache / cassandra / thrift / CassandraDaemon . java b / src / java / org / apache / cassandra / thrift / CassandraDaemon . java <nl> index b119da1 . . 6b816ca 100644 <nl> - - - a / src / java / org / apache / cassandra / thrift / CassandraDaemon . java <nl> + + + b / src / java / org / apache / cassandra / thrift / CassandraDaemon . java <nl> @ @ - 19 , 25 + 19 , 13 @ @ <nl> package org . apache . cassandra . thrift ; <nl> <nl> import java . io . IOException ; <nl> - import java . net . InetAddress ; <nl> import java . net . InetSocketAddress ; <nl> - import java . util . UUID ; <nl> import java . util . concurrent . ExecutorService ; <nl> - import java . util . concurrent . ThreadPoolExecutor ; <nl> - import java . util . concurrent . TimeUnit ; <nl> <nl> - import org . apache . cassandra . config . ConfigurationException ; <nl> + import org . slf4j . Logger ; <nl> + import org . slf4j . LoggerFactory ; <nl> + <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> - import org . apache . cassandra . db . CompactionManager ; <nl> - import org . apache . cassandra . db . SystemTable ; <nl> - import org . apache . cassandra . db . Table ; <nl> - import org . apache . cassandra . db . commitlog . CommitLog ; <nl> - import org . apache . cassandra . db . migration . Migration ; <nl> - import org . apache . cassandra . service . MigrationManager ; <nl> - import org . apache . cassandra . service . StorageService ; <nl> - import org . apache . cassandra . utils . CLibrary ; <nl> - import org . apache . cassandra . utils . FBUtilities ; <nl> - import org . apache . cassandra . utils . Mx4jTool ; <nl> import org . apache . thrift . TProcessorFactory ; <nl> import org . apache . thrift . protocol . TBinaryProtocol ; <nl> import org . apache . thrift . protocol . TProtocolFactory ; <nl> @ @ - 46 , 8 + 34 , 6 @ @ import org . apache . thrift . transport . TFramedTransport ; <nl> import org . apache . thrift . transport . TServerSocket ; <nl> import org . apache . thrift . transport . TTransportException ; <nl> import org . apache . thrift . transport . TTransportFactory ; <nl> - import org . slf4j . Logger ; <nl> - import org . slf4j . LoggerFactory ; <nl> <nl> / * * <nl> * This class supports two methods for creating a Cassandra node daemon , <nl> @ @ - 65 , 78 + 51 , 7 @ @ public class CassandraDaemon extends org . apache . cassandra . service . AbstractCassan <nl> <nl> protected void setup ( ) throws IOException <nl> { <nl> - FBUtilities . tryMlockall ( ) ; <nl> - <nl> - int listenPort = DatabaseDescriptor . getRpcPort ( ) ; <nl> - InetAddress listenAddr = DatabaseDescriptor . getRpcAddress ( ) ; <nl> - <nl> - / * <nl> - * If ThriftAddress was left completely unconfigured , then assume <nl> - * the same default as ListenAddress <nl> - * / <nl> - if ( listenAddr = = null ) <nl> - listenAddr = FBUtilities . getLocalAddress ( ) ; <nl> - <nl> - Thread . setDefaultUncaughtExceptionHandler ( new Thread . UncaughtExceptionHandler ( ) <nl> - { <nl> - public void uncaughtException ( Thread t , Throwable e ) <nl> - { <nl> - logger . error ( " Uncaught exception in thread " + t , e ) ; <nl> - if ( e instanceof OutOfMemoryError ) <nl> - { <nl> - System . exit ( 100 ) ; <nl> - } <nl> - } <nl> - } ) ; <nl> - <nl> - / / check the system table for mismatched partitioner . <nl> - try <nl> - { <nl> - SystemTable . checkHealth ( ) ; <nl> - } <nl> - catch ( ConfigurationException e ) <nl> - { <nl> - logger . error ( " Fatal exception during initialization " , e ) ; <nl> - System . exit ( 100 ) ; <nl> - } <nl> - <nl> - try <nl> - { <nl> - DatabaseDescriptor . loadSchemas ( ) ; <nl> - } <nl> - catch ( IOException e ) <nl> - { <nl> - logger . error ( " Fatal exception during initialization " , e ) ; <nl> - System . exit ( 100 ) ; <nl> - } <nl> - <nl> - / / initialize keyspaces <nl> - for ( String table : DatabaseDescriptor . getTables ( ) ) <nl> - { <nl> - if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " opening keyspace " + table ) ; <nl> - Table . open ( table ) ; <nl> - } <nl> - <nl> - / / replay the log if necessary and check for compaction candidates <nl> - CommitLog . recover ( ) ; <nl> - CompactionManager . instance . checkAllColumnFamilies ( ) ; <nl> - <nl> - / / check to see if CL . recovery modified the lastMigrationId . if it did , we need to re apply migrations . this isn ' t <nl> - / / the same as merely reloading the schema ( which wouldn ' t perform file deletion after a DROP ) . The solution <nl> - / / is to read those migrations from disk and apply them . <nl> - UUID currentMigration = DatabaseDescriptor . getDefsVersion ( ) ; <nl> - UUID lastMigration = Migration . getLastMigrationId ( ) ; <nl> - if ( ( lastMigration ! = null ) & & ( lastMigration . timestamp ( ) > currentMigration . timestamp ( ) ) ) <nl> - { <nl> - MigrationManager . applyMigrations ( currentMigration , lastMigration ) ; <nl> - } <nl> - <nl> - SystemTable . purgeIncompatibleHints ( ) ; <nl> - <nl> - / / start server internals <nl> - StorageService . instance . initServer ( ) ; <nl> - <nl> + super . setup ( ) ; <nl> / / now we start listening for clients <nl> final CassandraServer cassandraServer = new CassandraServer ( ) ; <nl> Cassandra . Processor processor = new Cassandra . Processor ( cassandraServer ) ; <nl> @ @ - 176 , 7 + 91 , 6 @ @ public class CassandraDaemon extends org . apache . cassandra . service . AbstractCassan <nl> outTransportFactory = new TTransportFactory ( ) ; <nl> } <nl> <nl> - <nl> / / ThreadPool Server <nl> CustomTThreadPoolServer . Options options = new CustomTThreadPoolServer . Options ( ) ; <nl> options . minWorkerThreads = MIN _ WORKER _ THREADS ; <nl> @ @ - 198 , 7 + 112 , 6 @ @ public class CassandraDaemon extends org . apache . cassandra . service . AbstractCassan <nl> public void start ( ) <nl> { <nl> logger . info ( " Listening for thrift clients . . . " ) ; <nl> - Mx4jTool . maybeLoad ( ) ; <nl> serverEngine . serve ( ) ; <nl> } <nl>

TEST DIFF:
diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index 35c67c4 . . 19e0a5a 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 51 , 9 + 51 , 7 @ @ import org . apache . cassandra . db . compaction . CompactionManager ; 
 import org . apache . cassandra . db . index . SecondaryIndex ; 
 import org . apache . cassandra . dht . * ; 
 import org . apache . cassandra . dht . Range ; 
 - import org . apache . cassandra . exceptions . ConfigurationException ; 
 - import org . apache . cassandra . exceptions . InvalidRequestException ; 
 - import org . apache . cassandra . exceptions . UnavailableException ; 
 + import org . apache . cassandra . exceptions . * ; 
 import org . apache . cassandra . gms . * ; 
 import org . apache . cassandra . io . sstable . SSTableDeletingTask ; 
 import org . apache . cassandra . io . sstable . SSTableLoader ; 
 @ @ - 807 , 7 + 805 , 7 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 
 / / if we don ' t have system _ traces keyspace at this point , then create it manually 
 if ( Schema . instance . getKSMetaData ( TraceKeyspace . NAME ) = = null ) 
 - MigrationManager . announceNewKeyspace ( TraceKeyspace . definition ( ) , 0 , false ) ; 
 + maybeAddKeyspace ( TraceKeyspace . definition ( ) ) ; 
 
 if ( ! isSurveyMode ) 
 { 
 @ @ - 872 , 14 + 870 , 14 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 / / the ks exists with the only the legacy tables defined 
 if ( Schema . instance . getKSMetaData ( AuthKeyspace . NAME ) = = null ) 
 { 
 - MigrationManager . announceNewKeyspace ( AuthKeyspace . definition ( ) , 0 , false ) ; 
 + maybeAddKeyspace ( AuthKeyspace . definition ( ) ) ; 
 } 
 else 
 { 
 for ( Map . Entry < String , CFMetaData > table : AuthKeyspace . definition ( ) . cfMetaData ( ) . entrySet ( ) ) 
 { 
 if ( Schema . instance . getCFMetaData ( AuthKeyspace . NAME , table . getKey ( ) ) = = null ) 
 - MigrationManager . announceNewColumnFamily ( table . getValue ( ) ) ; 
 + maybeAddTable ( table . getValue ( ) ) ; 
 } 
 } 
 } 
 @ @ - 894 , 6 + 892 , 30 @ @ public class StorageService extends NotificationBroadcasterSupport implements IE 
 MigrationManager . instance . register ( new AuthMigrationListener ( ) ) ; 
 } 
 
 + private void maybeAddTable ( CFMetaData cfm ) 
 + { 
 + try 
 + { 
 + MigrationManager . announceNewColumnFamily ( cfm ) ; 
 + } 
 + catch ( AlreadyExistsException e ) 
 + { 
 + logger . debug ( " Attempted to create new table { } , but it already exists " , cfm . cfName ) ; 
 + } 
 + } 
 + 
 + private void maybeAddKeyspace ( KSMetaData ksm ) 
 + { 
 + try 
 + { 
 + MigrationManager . announceNewKeyspace ( ksm , 0 , false ) ; 
 + } 
 + catch ( AlreadyExistsException e ) 
 + { 
 + logger . debug ( " Attempted to create new keyspace { } , but it already exists " , ksm . name ) ; 
 + } 
 + } 
 + 
 public boolean isJoined ( ) 
 { 
 return joined ;

NEAREST DIFF:
diff - - git a / src / java / org / apache / cassandra / avro / CassandraDaemon . java b / src / java / org / apache / cassandra / avro / CassandraDaemon . java 
 index 4f2fa7a . . 280a0ea 100644 
 - - - a / src / java / org / apache / cassandra / avro / CassandraDaemon . java 
 + + + b / src / java / org / apache / cassandra / avro / CassandraDaemon . java 
 @ @ - 19 , 28 + 19 , 13 @ @ 
 package org . apache . cassandra . avro ; 
 
 import java . io . IOException ; 
 - import java . net . InetAddress ; 
 - import java . util . UUID ; 
 
 - import org . apache . avro . ipc . HttpServer ; 
 - import org . apache . avro . ipc . ResponderServlet ; 
 - import org . apache . avro . specific . SpecificResponder ; 
 - 
 - import org . apache . cassandra . config . ConfigurationException ; 
 - import org . apache . cassandra . config . DatabaseDescriptor ; 
 - import org . apache . cassandra . db . CompactionManager ; 
 - import org . apache . cassandra . db . SystemTable ; 
 - import org . apache . cassandra . db . Table ; 
 - import org . apache . cassandra . db . commitlog . CommitLog ; 
 - import org . apache . cassandra . db . migration . Migration ; 
 - import org . apache . cassandra . service . MigrationManager ; 
 - import org . apache . cassandra . service . StorageService ; 
 - import org . apache . cassandra . utils . FBUtilities ; 
 - import org . apache . cassandra . utils . Mx4jTool ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 - / / see CASSANDRA - 1440 
 + import org . apache . avro . ipc . ResponderServlet ; 
 + import org . apache . avro . specific . SpecificResponder ; 
 + import org . apache . cassandra . utils . Mx4jTool ; 
 import org . mortbay . jetty . servlet . Context ; 
 import org . mortbay . jetty . servlet . ServletHolder ; 
 
 @ @ - 51 , 85 + 36 , 7 @ @ import org . mortbay . jetty . servlet . ServletHolder ; 
 public class CassandraDaemon extends org . apache . cassandra . service . AbstractCassandraDaemon { 
 private static Logger logger = LoggerFactory . getLogger ( CassandraDaemon . class ) ; 
 private org . mortbay . jetty . Server server ; 
 - private InetAddress listenAddr ; 
 - private int listenPort ; 
 - 
 - protected void setup ( ) throws IOException 
 - { 
 - FBUtilities . tryMlockall ( ) ; 
 - 
 - listenPort = DatabaseDescriptor . getRpcPort ( ) ; 
 - listenAddr = DatabaseDescriptor . getRpcAddress ( ) ; 
 - 
 - / * 
 - * If ThriftAddress was left completely unconfigured , then assume 
 - * the same default as ListenAddress 
 - * / 
 - if ( listenAddr = = null ) 
 - listenAddr = FBUtilities . getLocalAddress ( ) ; 
 - 
 - Thread . setDefaultUncaughtExceptionHandler ( new Thread . UncaughtExceptionHandler ( ) 
 - { 
 - public void uncaughtException ( Thread t , Throwable e ) 
 - { 
 - logger . error ( " Fatal exception in thread " + t , e ) ; 
 - if ( e instanceof OutOfMemoryError ) 
 - { 
 - System . exit ( 100 ) ; 
 - } 
 - } 
 - } ) ; 
 - 
 - / / check the system table for mismatched partitioner . 
 - try 
 - { 
 - SystemTable . checkHealth ( ) ; 
 - } 
 - catch ( ConfigurationException e ) 
 - { 
 - logger . error ( " Fatal exception during initialization " , e ) ; 
 - System . exit ( 100 ) ; 
 - } 
 - 
 - try 
 - { 
 - DatabaseDescriptor . loadSchemas ( ) ; 
 - } 
 - catch ( IOException e ) 
 - { 
 - logger . error ( " Fatal exception during initialization " , e ) ; 
 - System . exit ( 100 ) ; 
 - } 
 - 
 - / / initialize keyspaces 
 - for ( String table : DatabaseDescriptor . getTables ( ) ) 
 - { 
 - if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " opening keyspace " + table ) ; 
 - Table . open ( table ) ; 
 - } 
 
 - / / replay the log if necessary and check for compaction candidates 
 - CommitLog . recover ( ) ; 
 - CompactionManager . instance . checkAllColumnFamilies ( ) ; 
 - 
 - / / check to see if CL . recovery modified the lastMigrationId . if it did , we need to re apply migrations . this isn ' t 
 - / / the same as merely reloading the schema ( which wouldn ' t perform file deletion after a DROP ) . The solution 
 - / / is to read those migrations from disk and apply them . 
 - UUID currentMigration = DatabaseDescriptor . getDefsVersion ( ) ; 
 - UUID lastMigration = Migration . getLastMigrationId ( ) ; 
 - if ( ( lastMigration ! = null ) & & ( lastMigration . timestamp ( ) > currentMigration . timestamp ( ) ) ) 
 - { 
 - MigrationManager . applyMigrations ( currentMigration , lastMigration ) ; 
 - } 
 - 
 - SystemTable . purgeIncompatibleHints ( ) ; 
 - 
 - / / start server internals 
 - StorageService . instance . initServer ( ) ; 
 - 
 - } 
 - 
 / * * hook for JSVC * / 
 public void start ( ) throws IOException 
 { 
 @ @ - 139 , 7 + 46 , 6 @ @ public class CassandraDaemon extends org . apache . cassandra . service . AbstractCassan 
 SpecificResponder responder = new SpecificResponder ( Cassandra . class , cassandraServer ) ; 
 
 logger . info ( " Listening for avro clients . . . " ) ; 
 - Mx4jTool . maybeLoad ( ) ; 
 
 / / FIXME : This isn ' t actually binding to listenAddr ( it should ) . 
 server = new org . mortbay . jetty . Server ( listenPort ) ; 
 diff - - git a / src / java / org / apache / cassandra / service / AbstractCassandraDaemon . java b / src / java / org / apache / cassandra / service / AbstractCassandraDaemon . java 
 index f7d5711 . . d3cb29d 100644 
 - - - a / src / java / org / apache / cassandra / service / AbstractCassandraDaemon . java 
 + + + b / src / java / org / apache / cassandra / service / AbstractCassandraDaemon . java 
 @ @ - 20 , 14 + 20 , 25 @ @ package org . apache . cassandra . service ; 
 
 import java . io . File ; 
 import java . io . IOException ; 
 + import java . net . InetAddress ; 
 + import java . util . UUID ; 
 + import java . util . concurrent . RejectedExecutionException ; 
 import java . util . concurrent . SynchronousQueue ; 
 import java . util . concurrent . ThreadPoolExecutor ; 
 import java . util . concurrent . TimeUnit ; 
 - import java . util . concurrent . RejectedExecutionException ; 
 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 + import org . apache . cassandra . config . ConfigurationException ; 
 + import org . apache . cassandra . config . DatabaseDescriptor ; 
 + import org . apache . cassandra . db . CompactionManager ; 
 + import org . apache . cassandra . db . SystemTable ; 
 + import org . apache . cassandra . db . Table ; 
 + import org . apache . cassandra . db . commitlog . CommitLog ; 
 + import org . apache . cassandra . db . migration . Migration ; 
 + import org . apache . cassandra . utils . FBUtilities ; 
 + import org . apache . cassandra . utils . Mx4jTool ; 
 import org . mortbay . thread . ThreadPool ; 
 
 / * * 
 @ @ - 42 , 15 + 53 , 95 @ @ public abstract class AbstractCassandraDaemon implements CassandraDaemon 
 private static Logger logger = LoggerFactory 
 . getLogger ( AbstractCassandraDaemon . class ) ; 
 
 + protected InetAddress listenAddr ; 
 + protected int listenPort ; 
 + 
 public static final int MIN _ WORKER _ THREADS = 64 ; 
 
 / * * 
 * This is a hook for concrete daemons to initialize themselves suitably . 
 - * 
 + * 
 + * Subclasses should override this to finish the job ( listening on ports , etc . ) 
 + * 
 * @ throws IOException 
 * / 
 - protected abstract void setup ( ) throws IOException ; 
 - 
 + protected void setup ( ) throws IOException 
 + { 
 + 	 FBUtilities . tryMlockall ( ) ; 
 + 
 + listenPort = DatabaseDescriptor . getRpcPort ( ) ; 
 + listenAddr = DatabaseDescriptor . getRpcAddress ( ) ; 
 + 
 + / * 
 + * If ThriftAddress was left completely unconfigured , then assume 
 + * the same default as ListenAddress 
 + * / 
 + if ( listenAddr = = null ) 
 + listenAddr = FBUtilities . getLocalAddress ( ) ; 
 + 
 + Thread . setDefaultUncaughtExceptionHandler ( new Thread . UncaughtExceptionHandler ( ) 
 + { 
 + public void uncaughtException ( Thread t , Throwable e ) 
 + { 
 + logger . error ( " Fatal exception in thread " + t , e ) ; 
 + if ( e instanceof OutOfMemoryError ) 
 + { 
 + System . exit ( 100 ) ; 
 + } 
 + } 
 + } ) ; 
 + 
 + / / check the system table for mismatched partitioner . 
 + try 
 + { 
 + SystemTable . checkHealth ( ) ; 
 + } 
 + catch ( ConfigurationException e ) 
 + { 
 + logger . error ( " Fatal exception during initialization " , e ) ; 
 + System . exit ( 100 ) ; 
 + } 
 + 
 + try 
 + { 
 + DatabaseDescriptor . loadSchemas ( ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + logger . error ( " Fatal exception during initialization " , e ) ; 
 + System . exit ( 100 ) ; 
 + } 
 + 
 + / / initialize keyspaces 
 + for ( String table : DatabaseDescriptor . getTables ( ) ) 
 + { 
 + if ( logger . isDebugEnabled ( ) ) 
 + logger . debug ( " opening keyspace " + table ) ; 
 + Table . open ( table ) ; 
 + } 
 + 
 + / / replay the log if necessary and check for compaction candidates 
 + CommitLog . recover ( ) ; 
 + CompactionManager . instance . checkAllColumnFamilies ( ) ; 
 + 
 + / / check to see if CL . recovery modified the lastMigrationId . if it did , we need to re apply migrations . this isn ' t 
 + / / the same as merely reloading the schema ( which wouldn ' t perform file deletion after a DROP ) . The solution 
 + / / is to read those migrations from disk and apply them . 
 + UUID currentMigration = DatabaseDescriptor . getDefsVersion ( ) ; 
 + UUID lastMigration = Migration . getLastMigrationId ( ) ; 
 + if ( ( lastMigration ! = null ) & & ( lastMigration . timestamp ( ) > currentMigration . timestamp ( ) ) ) 
 + { 
 + MigrationManager . applyMigrations ( currentMigration , lastMigration ) ; 
 + } 
 + 
 + SystemTable . purgeIncompatibleHints ( ) ; 
 + 
 + / / start server internals 
 + StorageService . instance . initServer ( ) ; 
 + 
 + Mx4jTool . maybeLoad ( ) ; 
 + } 
 + 
 / * * 
 * Initialize the Cassandra Daemon based on the given < a 
 * href = " http : / / commons . apache . org / daemon / jsvc . html " > Commons 
 @ @ - 155 , 7 + 246 , 6 @ @ public abstract class AbstractCassandraDaemon implements CassandraDaemon 
 / * * The following are cribbed from org . mortbay . thread . concurrent * / 
 / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / 
 
 - @ Override 
 public boolean dispatch ( Runnable job ) 
 { 
 try 
 @ @ - 170 , 25 + 260 , 21 @ @ public abstract class AbstractCassandraDaemon implements CassandraDaemon 
 } 
 } 
 
 - @ Override 
 public int getIdleThreads ( ) 
 { 
 return getPoolSize ( ) - getActiveCount ( ) ; 
 } 
 
 - @ Override 
 public int getThreads ( ) 
 { 
 return getPoolSize ( ) ; 
 } 
 
 - @ Override 
 public boolean isLowOnThreads ( ) 
 { 
 return getActiveCount ( ) > = getMaximumPoolSize ( ) ; 
 } 
 
 - @ Override 
 public void join ( ) throws InterruptedException 
 { 
 this . awaitTermination ( Long . MAX _ VALUE , TimeUnit . MILLISECONDS ) ; 
 diff - - git a / src / java / org / apache / cassandra / thrift / CassandraDaemon . java b / src / java / org / apache / cassandra / thrift / CassandraDaemon . java 
 index b119da1 . . 6b816ca 100644 
 - - - a / src / java / org / apache / cassandra / thrift / CassandraDaemon . java 
 + + + b / src / java / org / apache / cassandra / thrift / CassandraDaemon . java 
 @ @ - 19 , 25 + 19 , 13 @ @ 
 package org . apache . cassandra . thrift ; 
 
 import java . io . IOException ; 
 - import java . net . InetAddress ; 
 import java . net . InetSocketAddress ; 
 - import java . util . UUID ; 
 import java . util . concurrent . ExecutorService ; 
 - import java . util . concurrent . ThreadPoolExecutor ; 
 - import java . util . concurrent . TimeUnit ; 
 
 - import org . apache . cassandra . config . ConfigurationException ; 
 + import org . slf4j . Logger ; 
 + import org . slf4j . LoggerFactory ; 
 + 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 - import org . apache . cassandra . db . CompactionManager ; 
 - import org . apache . cassandra . db . SystemTable ; 
 - import org . apache . cassandra . db . Table ; 
 - import org . apache . cassandra . db . commitlog . CommitLog ; 
 - import org . apache . cassandra . db . migration . Migration ; 
 - import org . apache . cassandra . service . MigrationManager ; 
 - import org . apache . cassandra . service . StorageService ; 
 - import org . apache . cassandra . utils . CLibrary ; 
 - import org . apache . cassandra . utils . FBUtilities ; 
 - import org . apache . cassandra . utils . Mx4jTool ; 
 import org . apache . thrift . TProcessorFactory ; 
 import org . apache . thrift . protocol . TBinaryProtocol ; 
 import org . apache . thrift . protocol . TProtocolFactory ; 
 @ @ - 46 , 8 + 34 , 6 @ @ import org . apache . thrift . transport . TFramedTransport ; 
 import org . apache . thrift . transport . TServerSocket ; 
 import org . apache . thrift . transport . TTransportException ; 
 import org . apache . thrift . transport . TTransportFactory ; 
 - import org . slf4j . Logger ; 
 - import org . slf4j . LoggerFactory ; 
 
 / * * 
 * This class supports two methods for creating a Cassandra node daemon , 
 @ @ - 65 , 78 + 51 , 7 @ @ public class CassandraDaemon extends org . apache . cassandra . service . AbstractCassan 
 
 protected void setup ( ) throws IOException 
 { 
 - FBUtilities . tryMlockall ( ) ; 
 - 
 - int listenPort = DatabaseDescriptor . getRpcPort ( ) ; 
 - InetAddress listenAddr = DatabaseDescriptor . getRpcAddress ( ) ; 
 - 
 - / * 
 - * If ThriftAddress was left completely unconfigured , then assume 
 - * the same default as ListenAddress 
 - * / 
 - if ( listenAddr = = null ) 
 - listenAddr = FBUtilities . getLocalAddress ( ) ; 
 - 
 - Thread . setDefaultUncaughtExceptionHandler ( new Thread . UncaughtExceptionHandler ( ) 
 - { 
 - public void uncaughtException ( Thread t , Throwable e ) 
 - { 
 - logger . error ( " Uncaught exception in thread " + t , e ) ; 
 - if ( e instanceof OutOfMemoryError ) 
 - { 
 - System . exit ( 100 ) ; 
 - } 
 - } 
 - } ) ; 
 - 
 - / / check the system table for mismatched partitioner . 
 - try 
 - { 
 - SystemTable . checkHealth ( ) ; 
 - } 
 - catch ( ConfigurationException e ) 
 - { 
 - logger . error ( " Fatal exception during initialization " , e ) ; 
 - System . exit ( 100 ) ; 
 - } 
 - 
 - try 
 - { 
 - DatabaseDescriptor . loadSchemas ( ) ; 
 - } 
 - catch ( IOException e ) 
 - { 
 - logger . error ( " Fatal exception during initialization " , e ) ; 
 - System . exit ( 100 ) ; 
 - } 
 - 
 - / / initialize keyspaces 
 - for ( String table : DatabaseDescriptor . getTables ( ) ) 
 - { 
 - if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " opening keyspace " + table ) ; 
 - Table . open ( table ) ; 
 - } 
 - 
 - / / replay the log if necessary and check for compaction candidates 
 - CommitLog . recover ( ) ; 
 - CompactionManager . instance . checkAllColumnFamilies ( ) ; 
 - 
 - / / check to see if CL . recovery modified the lastMigrationId . if it did , we need to re apply migrations . this isn ' t 
 - / / the same as merely reloading the schema ( which wouldn ' t perform file deletion after a DROP ) . The solution 
 - / / is to read those migrations from disk and apply them . 
 - UUID currentMigration = DatabaseDescriptor . getDefsVersion ( ) ; 
 - UUID lastMigration = Migration . getLastMigrationId ( ) ; 
 - if ( ( lastMigration ! = null ) & & ( lastMigration . timestamp ( ) > currentMigration . timestamp ( ) ) ) 
 - { 
 - MigrationManager . applyMigrations ( currentMigration , lastMigration ) ; 
 - } 
 - 
 - SystemTable . purgeIncompatibleHints ( ) ; 
 - 
 - / / start server internals 
 - StorageService . instance . initServer ( ) ; 
 - 
 + super . setup ( ) ; 
 / / now we start listening for clients 
 final CassandraServer cassandraServer = new CassandraServer ( ) ; 
 Cassandra . Processor processor = new Cassandra . Processor ( cassandraServer ) ; 
 @ @ - 176 , 7 + 91 , 6 @ @ public class CassandraDaemon extends org . apache . cassandra . service . AbstractCassan 
 outTransportFactory = new TTransportFactory ( ) ; 
 } 
 
 - 
 / / ThreadPool Server 
 CustomTThreadPoolServer . Options options = new CustomTThreadPoolServer . Options ( ) ; 
 options . minWorkerThreads = MIN _ WORKER _ THREADS ; 
 @ @ - 198 , 7 + 112 , 6 @ @ public class CassandraDaemon extends org . apache . cassandra . service . AbstractCassan 
 public void start ( ) 
 { 
 logger . info ( " Listening for thrift clients . . . " ) ; 
 - Mx4jTool . maybeLoad ( ) ; 
 serverEngine . serve ( ) ; 
 } 

