BLEU SCORE: 0.016087046643979717

TEST MSG: merge from 2 . 1
GENERATED MSG: SSTableExport uses correct validator to create string representation of partition keys

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index d60ed3d . . 991331f 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 15 , 6 + 15 , 8 @ @ <nl> <nl> <nl> 2 . 1 . 1 <nl> + * SSTableExport uses correct validator to create string representation of partition <nl> + keys ( CASSANDRA - 7498 ) <nl> * Avoid NPEs when receiving type changes for an unknown keyspace ( CASSANDRA - 7689 ) <nl> * Add support for custom 2i validation ( CASSANDRA - 7575 ) <nl> * Pig support for hadoop CqlInputFormat ( CASSANDRA - 6454 ) <nl> diff - - git a / src / java / org / apache / cassandra / tools / SSTableExport . java b / src / java / org / apache / cassandra / tools / SSTableExport . java <nl> index a63825e . . 3d5ff0b 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / SSTableExport . java <nl> + + + b / src / java / org / apache / cassandra / tools / SSTableExport . java <nl> @ @ - 38 , 9 + 38 , 6 @ @ import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . codehaus . jackson . JsonGenerator ; <nl> import org . codehaus . jackson . map . ObjectMapper ; <nl> <nl> - import static org . apache . cassandra . utils . ByteBufferUtil . bytesToHex ; <nl> - import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; <nl> - <nl> / * * <nl> * Export SSTables to JSON format . <nl> * / <nl> @ @ - 188 , 7 + 185 , 7 @ @ public class SSTableExport <nl> { <nl> out . print ( " { " ) ; <nl> writeKey ( out , " key " ) ; <nl> - writeJSON ( out , bytesToHex ( key . getKey ( ) ) ) ; <nl> + writeJSON ( out , metadata . getKeyValidator ( ) . getString ( key . getKey ( ) ) ) ; <nl> out . print ( " , \ n " ) ; <nl> <nl> if ( ! deletionInfo . isLive ( ) ) <nl> @ @ - 222 , 9 + 219 , 10 @ @ public class SSTableExport <nl> * <nl> * @ param desc the descriptor of the file to export the rows from <nl> * @ param outs PrintStream to write the output to <nl> + * @ param metadata Metadata to print keys in a proper format <nl> * @ throws IOException on failure to read / write input / output <nl> * / <nl> - public static void enumeratekeys ( Descriptor desc , PrintStream outs ) <nl> + public static void enumeratekeys ( Descriptor desc , PrintStream outs , CFMetaData metadata ) <nl> throws IOException <nl> { <nl> KeyIterator iter = new KeyIterator ( desc ) ; <nl> @ @ - 238 , 7 + 236 , 7 @ @ public class SSTableExport <nl> throw new IOException ( " Key out of order ! " + lastKey + " > " + key ) ; <nl> lastKey = key ; <nl> <nl> - outs . println ( bytesToHex ( key . getKey ( ) ) ) ; <nl> + outs . println ( metadata . getKeyValidator ( ) . getString ( key . getKey ( ) ) ) ; <nl> checkStream ( outs ) ; / / flushes <nl> } <nl> iter . close ( ) ; <nl> @ @ - 251 , 9 + 249 , 10 @ @ public class SSTableExport <nl> * @ param outs PrintStream to write the output to <nl> * @ param toExport the keys corresponding to the rows to export <nl> * @ param excludes keys to exclude from export <nl> + * @ param metadata Metadata to print keys in a proper format <nl> * @ throws IOException on failure to read / write input / output <nl> * / <nl> - public static void export ( Descriptor desc , PrintStream outs , Collection < String > toExport , String [ ] excludes ) throws IOException <nl> + public static void export ( Descriptor desc , PrintStream outs , Collection < String > toExport , String [ ] excludes , CFMetaData metadata ) throws IOException <nl> { <nl> SSTableReader sstable = SSTableReader . open ( desc ) ; <nl> RandomAccessReader dfile = sstable . openDataReader ( ) ; <nl> @ @ - 272 , 7 + 271 , 7 @ @ public class SSTableExport <nl> <nl> for ( String key : toExport ) <nl> { <nl> - DecoratedKey decoratedKey = partitioner . decorateKey ( hexToBytes ( key ) ) ; <nl> + DecoratedKey decoratedKey = partitioner . decorateKey ( metadata . getKeyValidator ( ) . fromString ( key ) ) ; <nl> <nl> if ( lastKey ! = null & & lastKey . compareTo ( decoratedKey ) > 0 ) <nl> throw new IOException ( " Key out of order ! " + lastKey + " > " + decoratedKey ) ; <nl> @ @ - 302 , 7 + 301 , 7 @ @ public class SSTableExport <nl> <nl> / / This is necessary to accommodate the test suite since you cannot open a Reader more <nl> / / than once from within the same process . <nl> - static void export ( SSTableReader reader , PrintStream outs , String [ ] excludes ) throws IOException <nl> + static void export ( SSTableReader reader , PrintStream outs , String [ ] excludes , CFMetaData metadata ) throws IOException <nl> { <nl> Set < String > excludeSet = new HashSet < String > ( ) ; <nl> <nl> @ @ - 322 , 7 + 321 , 7 @ @ public class SSTableExport <nl> { <nl> row = ( SSTableIdentityIterator ) scanner . next ( ) ; <nl> <nl> - String currentKey = bytesToHex ( row . getKey ( ) . getKey ( ) ) ; <nl> + String currentKey = row . getColumnFamily ( ) . metadata ( ) . getKeyValidator ( ) . getString ( row . getKey ( ) . getKey ( ) ) ; <nl> <nl> if ( excludeSet . contains ( currentKey ) ) <nl> continue ; <nl> @ @ - 347 , 11 + 346 , 12 @ @ public class SSTableExport <nl> * @ param desc the descriptor of the sstable to read from <nl> * @ param outs PrintStream to write the output to <nl> * @ param excludes keys to exclude from export <nl> + * @ param metadata Metadata to print keys in a proper format <nl> * @ throws IOException on failure to read / write input / output <nl> * / <nl> - public static void export ( Descriptor desc , PrintStream outs , String [ ] excludes ) throws IOException <nl> + public static void export ( Descriptor desc , PrintStream outs , String [ ] excludes , CFMetaData metadata ) throws IOException <nl> { <nl> - export ( SSTableReader . open ( desc ) , outs , excludes ) ; <nl> + export ( SSTableReader . open ( desc ) , outs , excludes , metadata ) ; <nl> } <nl> <nl> / * * <nl> @ @ - 359 , 11 + 359 , 12 @ @ public class SSTableExport <nl> * <nl> * @ param desc the descriptor of the sstable to read from <nl> * @ param excludes keys to exclude from export <nl> + * @ param metadata Metadata to print keys in a proper format <nl> * @ throws IOException on failure to read / write SSTable / standard out <nl> * / <nl> - public static void export ( Descriptor desc , String [ ] excludes ) throws IOException <nl> + public static void export ( Descriptor desc , String [ ] excludes , CFMetaData metadata ) throws IOException <nl> { <nl> - export ( desc , System . out , excludes ) ; <nl> + export ( desc , System . out , excludes , metadata ) ; <nl> } <nl> <nl> / * * <nl> @ @ - 415 , 7 + 416 , 7 @ @ public class SSTableExport <nl> } <nl> Keyspace keyspace = Keyspace . open ( descriptor . ksname ) ; <nl> <nl> - / / Make it work for indexes too - find parent cf if necessary <nl> + / / Make it works for indexes too - find parent cf if necessary <nl> String baseName = descriptor . cfname ; <nl> if ( descriptor . cfname . contains ( " . " ) ) <nl> { <nl> @ @ - 424 , 9 + 425 , 10 @ @ public class SSTableExport <nl> } <nl> <nl> / / IllegalArgumentException will be thrown here if ks / cf pair does not exist <nl> + ColumnFamilyStore cfStore = null ; <nl> try <nl> { <nl> - keyspace . getColumnFamilyStore ( baseName ) ; <nl> + cfStore = keyspace . getColumnFamilyStore ( baseName ) ; <nl> } <nl> catch ( IllegalArgumentException e ) <nl> { <nl> @ @ - 439 , 14 + 441 , 14 @ @ public class SSTableExport <nl> { <nl> if ( cmd . hasOption ( ENUMERATEKEYS _ OPTION ) ) <nl> { <nl> - enumeratekeys ( descriptor , System . out ) ; <nl> + enumeratekeys ( descriptor , System . out , cfStore . metadata ) ; <nl> } <nl> else <nl> { <nl> if ( ( keys ! = null ) & & ( keys . length > 0 ) ) <nl> - export ( descriptor , System . out , Arrays . asList ( keys ) , excludes ) ; <nl> + export ( descriptor , System . out , Arrays . asList ( keys ) , excludes , cfStore . metadata ) ; <nl> else <nl> - export ( descriptor , excludes ) ; <nl> + export ( descriptor , excludes , cfStore . metadata ) ; <nl> } <nl> } <nl> catch ( IOException e ) <nl> diff - - git a / src / java / org / apache / cassandra / tools / SSTableImport . java b / src / java / org / apache / cassandra / tools / SSTableImport . java <nl> index f5873a4 . . 290c92a 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / SSTableImport . java <nl> + + + b / src / java / org / apache / cassandra / tools / SSTableImport . java <nl> @ @ - 17 , 8 + 17 , 6 @ @ <nl> * / <nl> package org . apache . cassandra . tools ; <nl> <nl> - import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; <nl> - <nl> import java . io . File ; <nl> import java . io . IOException ; <nl> import java . nio . ByteBuffer ; <nl> @ @ - 308 , 7 + 306 , 7 @ @ public class SSTableImport <nl> for ( Object row : data ) <nl> { <nl> Map < ? , ? > rowAsMap = ( Map < ? , ? > ) row ; <nl> - decoratedKeys . put ( partitioner . decorateKey ( hexToBytes ( ( String ) rowAsMap . get ( " key " ) ) ) , rowAsMap ) ; <nl> + decoratedKeys . put ( partitioner . decorateKey ( getKeyValidator ( columnFamily ) . fromString ( ( String ) rowAsMap . get ( " key " ) ) ) , rowAsMap ) ; <nl> } <nl> <nl> for ( Map . Entry < DecoratedKey , Map < ? , ? > > row : decoratedKeys . entrySet ( ) ) <nl> @ @ - 381 , 7 + 379 , 7 @ @ public class SSTableImport <nl> { <nl> String key = parser . getCurrentName ( ) ; <nl> Map < ? , ? > row = parser . readValueAs ( new TypeReference < Map < ? , ? > > ( ) { } ) ; <nl> - DecoratedKey currentKey = partitioner . decorateKey ( hexToBytes ( ( String ) row . get ( " key " ) ) ) ; <nl> + DecoratedKey currentKey = partitioner . decorateKey ( getKeyValidator ( columnFamily ) . fromString ( ( String ) row . get ( " key " ) ) ) ; <nl> <nl> if ( row . containsKey ( " metadata " ) ) <nl> parseMeta ( ( Map < ? , ? > ) row . get ( " metadata " ) , columnFamily , null ) ; <nl> @ @ - 423 , 6 + 421 , 21 @ @ public class SSTableImport <nl> } <nl> <nl> / * * <nl> + * Get key validator for column family <nl> + * @ param columnFamily column family instance <nl> + * @ return key validator for given column family <nl> + * / <nl> + private AbstractType < ? > getKeyValidator ( ColumnFamily columnFamily ) { <nl> + / / this is a fix to support backward compatibility <nl> + / / which allows to skip the current key validator <nl> + / / please , take a look onto CASSANDRA - 7498 for more details <nl> + if ( " true " . equals ( System . getProperty ( " skip . key . validator " , " false " ) ) ) { <nl> + return BytesType . instance ; <nl> + } <nl> + return columnFamily . metadata ( ) . getKeyValidator ( ) ; <nl> + } <nl> + <nl> + / * * <nl> * Get JsonParser object for file <nl> * @ param fileName name of the file <nl> * @ return json parser instance for given file <nl> @ @ - 526 , 7 + 539 , 7 @ @ public class SSTableImport <nl> { <nl> try <nl> { <nl> - return ( type = = BytesType . instance ) ? hexToBytes ( content ) : type . fromString ( content ) ; <nl> + return type . fromString ( content ) ; <nl> } <nl> catch ( MarshalException e ) <nl> { <nl> diff - - git a / test / unit / org / apache / cassandra / SchemaLoader . java b / test / unit / org / apache / cassandra / SchemaLoader . java <nl> index 066f454 . . d18fd60 100644 <nl> - - - a / test / unit / org / apache / cassandra / SchemaLoader . java <nl> + + + b / test / unit / org / apache / cassandra / SchemaLoader . java <nl> @ @ - 170 , 7 + 170 , 8 @ @ public class SchemaLoader <nl> <nl> standardCFMD ( ks1 , " UUIDKeys " ) . keyValidator ( UUIDType . instance ) , <nl> CFMetaData . denseCFMetaData ( ks1 , " MixedTypes " , LongType . instance ) . keyValidator ( UUIDType . instance ) . defaultValidator ( BooleanType . instance ) , <nl> - CFMetaData . denseCFMetaData ( ks1 , " MixedTypesComposite " , composite ) . keyValidator ( composite ) . defaultValidator ( BooleanType . instance ) <nl> + CFMetaData . denseCFMetaData ( ks1 , " MixedTypesComposite " , composite ) . keyValidator ( composite ) . defaultValidator ( BooleanType . instance ) , <nl> + standardCFMD ( ks1 , " AsciiKeys " ) . keyValidator ( AsciiType . instance ) <nl> ) ) ; <nl> <nl> / / Keyspace 2 <nl> diff - - git a / test / unit / org / apache / cassandra / Util . java b / test / unit / org / apache / cassandra / Util . java <nl> index e06bd95 . . fd53170 100644 <nl> - - - a / test / unit / org / apache / cassandra / Util . java <nl> + + + b / test / unit / org / apache / cassandra / Util . java <nl> @ @ - 43 , 6 + 43 , 7 @ @ import org . apache . cassandra . db . filter . IDiskAtomFilter ; <nl> import org . apache . cassandra . db . filter . QueryFilter ; <nl> import org . apache . cassandra . db . filter . SliceQueryFilter ; <nl> import org . apache . cassandra . db . filter . NamesQueryFilter ; <nl> + import org . apache . cassandra . db . marshal . AbstractType ; <nl> import org . apache . cassandra . dht . * ; <nl> import org . apache . cassandra . gms . ApplicationState ; <nl> import org . apache . cassandra . gms . Gossiper ; <nl> @ @ - 65 , 6 + 66 , 11 @ @ public class Util <nl> return StorageService . getPartitioner ( ) . decorateKey ( ByteBufferUtil . bytes ( key ) ) ; <nl> } <nl> <nl> + public static DecoratedKey dk ( String key , AbstractType type ) <nl> + { <nl> + return StorageService . getPartitioner ( ) . decorateKey ( type . fromString ( key ) ) ; <nl> + } <nl> + <nl> public static DecoratedKey dk ( ByteBuffer key ) <nl> { <nl> return StorageService . getPartitioner ( ) . decorateKey ( key ) ; <nl> diff - - git a / test / unit / org / apache / cassandra / tools / SSTableExportTest . java b / test / unit / org / apache / cassandra / tools / SSTableExportTest . java <nl> index dbc6703 . . f1b7564 100644 <nl> - - - a / test / unit / org / apache / cassandra / tools / SSTableExportTest . java <nl> + + + b / test / unit / org / apache / cassandra / tools / SSTableExportTest . java <nl> @ @ - 18 , 25 + 18 , 28 @ @ <nl> * / <nl> package org . apache . cassandra . tools ; <nl> <nl> - import static org . apache . cassandra . Util . column ; <nl> - import static org . junit . Assert . assertEquals ; <nl> - import static org . junit . Assert . assertNotNull ; <nl> - import static org . apache . cassandra . io . sstable . SSTableUtils . tempSSTableFile ; <nl> - import static org . apache . cassandra . utils . ByteBufferUtil . bytesToHex ; <nl> - import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; <nl> - <nl> import java . io . File ; <nl> import java . io . FileReader ; <nl> import java . io . IOException ; <nl> - import java . io . OutputStream ; <nl> import java . io . PrintStream ; <nl> <nl> + import org . junit . BeforeClass ; <nl> + import org . junit . Test ; <nl> + <nl> import org . apache . cassandra . SchemaLoader ; <nl> import org . apache . cassandra . Util ; <nl> import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . KSMetaData ; <nl> - import org . apache . cassandra . db . * ; <nl> + import org . apache . cassandra . db . ArrayBackedSortedColumns ; <nl> + import org . apache . cassandra . db . BufferCell ; <nl> + import org . apache . cassandra . db . BufferCounterCell ; <nl> + import org . apache . cassandra . db . BufferExpiringCell ; <nl> + import org . apache . cassandra . db . ColumnFamily ; <nl> + import org . apache . cassandra . db . ColumnFamilyStore ; <nl> + import org . apache . cassandra . db . DeletionInfo ; <nl> + import org . apache . cassandra . db . Keyspace ; <nl> import org . apache . cassandra . db . filter . QueryFilter ; <nl> + import org . apache . cassandra . db . marshal . AsciiType ; <nl> import org . apache . cassandra . db . marshal . BytesType ; <nl> import org . apache . cassandra . db . marshal . CounterColumnType ; <nl> import org . apache . cassandra . db . marshal . UTF8Type ; <nl> @ @ - 54 , 8 + 57 , 13 @ @ import org . json . simple . JSONArray ; <nl> import org . json . simple . JSONObject ; <nl> import org . json . simple . JSONValue ; <nl> import org . json . simple . parser . ParseException ; <nl> - import org . junit . BeforeClass ; <nl> - import org . junit . Test ; <nl> + <nl> + import static org . apache . cassandra . Util . column ; <nl> + import static org . apache . cassandra . io . sstable . SSTableUtils . tempSSTableFile ; <nl> + import static org . apache . cassandra . utils . ByteBufferUtil . bytesToHex ; <nl> + import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; <nl> + import static org . junit . Assert . assertEquals ; <nl> + import static org . junit . Assert . assertNotNull ; <nl> <nl> public class SSTableExportTest <nl> { <nl> @ @ - 104 , 7 + 112 , 9 @ @ public class SSTableExportTest <nl> <nl> / / Enumerate and verify <nl> File temp = File . createTempFile ( " Standard1 " , " . txt " ) ; <nl> - SSTableExport . enumeratekeys ( Descriptor . fromFilename ( writer . getFilename ( ) ) , new PrintStream ( temp . getPath ( ) ) ) ; <nl> + final Descriptor descriptor = Descriptor . fromFilename ( writer . getFilename ( ) ) ; <nl> + SSTableExport . enumeratekeys ( descriptor , new PrintStream ( temp . getPath ( ) ) , <nl> + CFMetaData . sparseCFMetaData ( descriptor . ksname , descriptor . cfname , BytesType . instance ) ) ; <nl> <nl> <nl> try ( FileReader file = new FileReader ( temp ) ) <nl> @ @ - 146 , 7 + 156 , 8 @ @ public class SSTableExportTest <nl> <nl> / / Export to JSON and verify <nl> File tempJson = File . createTempFile ( " Standard1 " , " . json " ) ; <nl> - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ ] { asHex ( " rowExclude " ) } ) ; <nl> + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ ] { asHex ( " rowExclude " ) } , <nl> + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " Standard1 " , BytesType . instance ) ) ; <nl> <nl> JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; <nl> assertEquals ( " unexpected number of rows " , 2 , json . size ( ) ) ; <nl> @ @ - 195 , 7 + 206 , 8 @ @ public class SSTableExportTest <nl> <nl> / / Export to JSON and verify <nl> File tempJson = File . createTempFile ( " Standard1 " , " . json " ) ; <nl> - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ ] { asHex ( " rowExclude " ) } ) ; <nl> + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ ] { asHex ( " rowExclude " ) } , <nl> + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " Standard1 " , BytesType . instance ) ) ; <nl> <nl> / / Import JSON to another SSTable file <nl> File tempSS2 = tempSSTableFile ( KEYSPACE1 , " Standard1 " ) ; <nl> @ @ - 229 , 7 + 241 , 8 @ @ public class SSTableExportTest <nl> <nl> / / Export to JSON and verify <nl> File tempJson = File . createTempFile ( " Counter1 " , " . json " ) ; <nl> - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] ) ; <nl> + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] , <nl> + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " Counter1 " , BytesType . instance ) ) ; <nl> JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; <nl> assertEquals ( " unexpected number of rows " , 1 , json . size ( ) ) ; <nl> <nl> @ @ - 260 , 7 + 273 , 8 @ @ public class SSTableExportTest <nl> <nl> / / Export to JSON and verify <nl> File tempJson = File . createTempFile ( " ValuesWithQuotes " , " . json " ) ; <nl> - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] ) ; <nl> + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] , <nl> + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " ValuesWithQuotes " , BytesType . instance ) ) ; <nl> <nl> JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; <nl> assertEquals ( " unexpected number of rows " , 1 , json . size ( ) ) ; <nl> @ @ - 291 , 7 + 305 , 8 @ @ public class SSTableExportTest <nl> SSTableReader reader = writer . closeAndOpenReader ( ) ; <nl> / / Export to JSON and verify <nl> File tempJson = File . createTempFile ( " CFWithDeletionInfo " , " . json " ) ; <nl> - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] ) ; <nl> + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] , <nl> + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " Counter1 " , BytesType . instance ) ) ; <nl> <nl> JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; <nl> assertEquals ( " unexpected number of rows " , 1 , json . size ( ) ) ; <nl> @ @ - 350 , 7 + 365 , 8 @ @ public class SSTableExportTest <nl> SSTableReader reader = writer . closeAndOpenReader ( ) ; <nl> / / Export to JSON and verify <nl> File tempJson = File . createTempFile ( " CFWithColumnNameEqualToDefaultKeyAlias " , " . json " ) ; <nl> - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] ) ; <nl> + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] , <nl> + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " UUIDKeys " , BytesType . instance ) ) ; <nl> <nl> JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; <nl> assertEquals ( 1 , json . size ( ) ) ; <nl> @ @ - 364 , 4 + 380 , 31 @ @ public class SSTableExportTest <nl> assertEquals ( CFMetaData . DEFAULT _ KEY _ ALIAS , ByteBufferUtil . string ( hexToBytes ( ( String ) col . get ( 0 ) ) ) ) ; <nl> assertEquals ( " not a uuid " , ByteBufferUtil . string ( hexToBytes ( ( String ) col . get ( 1 ) ) ) ) ; <nl> } <nl> + <nl> + @ Test <nl> + public void testAsciiKeyValidator ( ) throws IOException , ParseException <nl> + { <nl> + File tempSS = tempSSTableFile ( " Keyspace1 " , " AsciiKeys " ) ; <nl> + ColumnFamily cfamily = ArrayBackedSortedColumns . factory . create ( " Keyspace1 " , " AsciiKeys " ) ; <nl> + SSTableWriter writer = new SSTableWriter ( tempSS . getPath ( ) , 2 , ActiveRepairService . UNREPAIRED _ SSTABLE ) ; <nl> + <nl> + / / Add a row <nl> + cfamily . addColumn ( column ( " column " , " value " , 1L ) ) ; <nl> + writer . append ( Util . dk ( " key " , AsciiType . instance ) , cfamily ) ; <nl> + <nl> + SSTableReader reader = writer . closeAndOpenReader ( ) ; <nl> + / / Export to JSON and verify <nl> + File tempJson = File . createTempFile ( " CFWithAsciiKeys " , " . json " ) ; <nl> + SSTableExport . export ( reader , <nl> + new PrintStream ( tempJson . getPath ( ) ) , <nl> + new String [ 0 ] , <nl> + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " AsciiKeys " , BytesType . instance ) ) ; <nl> + <nl> + JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; <nl> + assertEquals ( 1 , json . size ( ) ) ; <nl> + <nl> + JSONObject row = ( JSONObject ) json . get ( 0 ) ; <nl> + / / check row key <nl> + assertEquals ( " key " , row . get ( " key " ) ) ; <nl> + } <nl> } <nl> diff - - git a / test / unit / org / apache / cassandra / tools / SSTableImportTest . java b / test / unit / org / apache / cassandra / tools / SSTableImportTest . java <nl> index dba8408 . . 8ea0ab8 100644 <nl> - - - a / test / unit / org / apache / cassandra / tools / SSTableImportTest . java <nl> + + + b / test / unit / org / apache / cassandra / tools / SSTableImportTest . java <nl> @ @ - 18 , 10 + 18 , 6 @ @ <nl> * / <nl> package org . apache . cassandra . tools ; <nl> <nl> - import static org . junit . Assert . assertEquals ; <nl> - import static org . apache . cassandra . io . sstable . SSTableUtils . tempSSTableFile ; <nl> - import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; <nl> - <nl> import java . io . File ; <nl> import java . io . IOException ; <nl> import java . net . URI ; <nl> @ @ - 34 , 17 + 30 , 28 @ @ import org . apache . cassandra . SchemaLoader ; <nl> import org . apache . cassandra . Util ; <nl> import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . KSMetaData ; <nl> - import org . apache . cassandra . db . * ; <nl> + import org . apache . cassandra . db . ArrayBackedSortedColumns ; <nl> + import org . apache . cassandra . db . BufferDeletedCell ; <nl> + import org . apache . cassandra . db . Cell ; <nl> + import org . apache . cassandra . db . ColumnFamily ; <nl> + import org . apache . cassandra . db . CounterCell ; <nl> + import org . apache . cassandra . db . DeletionInfo ; <nl> + import org . apache . cassandra . db . ExpiringCell ; <nl> import org . apache . cassandra . db . columniterator . OnDiskAtomIterator ; <nl> import org . apache . cassandra . db . filter . QueryFilter ; <nl> + import org . apache . cassandra . db . marshal . AsciiType ; <nl> import org . apache . cassandra . db . marshal . BytesType ; <nl> import org . apache . cassandra . db . marshal . CounterColumnType ; <nl> import org . apache . cassandra . exceptions . ConfigurationException ; <nl> - import org . apache . cassandra . locator . SimpleStrategy ; <nl> import org . apache . cassandra . io . sstable . Descriptor ; <nl> import org . apache . cassandra . io . sstable . SSTableReader ; <nl> + import org . apache . cassandra . locator . SimpleStrategy ; <nl> import org . apache . thrift . TException ; <nl> <nl> + import static org . apache . cassandra . io . sstable . SSTableUtils . tempSSTableFile ; <nl> + import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; <nl> + import static org . junit . Assert . assertEquals ; <nl> + <nl> public class SSTableImportTest <nl> { <nl> public static final String KEYSPACE1 = " SSTableImportTest " ; <nl> @ @ - 160 , 4 + 167 , 41 @ @ public class SSTableImportTest <nl> assert c instanceof CounterCell : c ; <nl> assert ( ( CounterCell ) c ) . total ( ) = = 42 ; <nl> } <nl> + <nl> + @ Test <nl> + public void testImportWithAsciiKeyValidator ( ) throws IOException , URISyntaxException <nl> + { <nl> + / / Import JSON to temp SSTable file <nl> + String jsonUrl = resourcePath ( " SimpleCF . json " ) ; <nl> + File tempSS = tempSSTableFile ( " Keyspace1 " , " AsciiKeys " ) ; <nl> + new SSTableImport ( true ) . importJson ( jsonUrl , " Keyspace1 " , " AsciiKeys " , tempSS . getPath ( ) ) ; <nl> + <nl> + / / Verify results <nl> + SSTableReader reader = SSTableReader . open ( Descriptor . fromFilename ( tempSS . getPath ( ) ) ) ; <nl> + / / check that keys are treated as ascii <nl> + QueryFilter qf = QueryFilter . getIdentityFilter ( Util . dk ( " 726f7741 " , AsciiType . instance ) , " AsciiKeys " , System . currentTimeMillis ( ) ) ; <nl> + OnDiskAtomIterator iter = qf . getSSTableColumnIterator ( reader ) ; <nl> + assert iter . hasNext ( ) ; / / " ascii " key exists <nl> + QueryFilter qf2 = QueryFilter . getIdentityFilter ( Util . dk ( " 726f7741 " , BytesType . instance ) , " AsciiKeys " , System . currentTimeMillis ( ) ) ; <nl> + OnDiskAtomIterator iter2 = qf2 . getSSTableColumnIterator ( reader ) ; <nl> + assert ! iter2 . hasNext ( ) ; / / " bytes " key does not exist <nl> + } <nl> + <nl> + @ Test <nl> + public void testBackwardCompatibilityOfImportWithAsciiKeyValidator ( ) throws IOException , URISyntaxException <nl> + { <nl> + / / Import JSON to temp SSTable file <nl> + String jsonUrl = resourcePath ( " SimpleCF . json " ) ; <nl> + File tempSS = tempSSTableFile ( " Keyspace1 " , " AsciiKeys " ) ; <nl> + / / To ignore current key validator <nl> + System . setProperty ( " skip . key . validator " , " true " ) ; <nl> + new SSTableImport ( true ) . importJson ( jsonUrl , " Keyspace1 " , " AsciiKeys " , tempSS . getPath ( ) ) ; <nl> + <nl> + / / Verify results <nl> + SSTableReader reader = SSTableReader . open ( Descriptor . fromFilename ( tempSS . getPath ( ) ) ) ; <nl> + / / check that keys are treated as bytes <nl> + QueryFilter qf = QueryFilter . getIdentityFilter ( Util . dk ( " rowA " ) , " AsciiKeys " , System . currentTimeMillis ( ) ) ; <nl> + OnDiskAtomIterator iter = qf . getSSTableColumnIterator ( reader ) ; <nl> + assert iter . hasNext ( ) ; / / " bytes " key exists <nl> + } <nl> }
NEAREST DIFF (one line): ELIMINATEDSENTENCE

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index d60ed3d . . 991331f 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 15 , 6 + 15 , 8 @ @ 
 
 
 2 . 1 . 1 
 + * SSTableExport uses correct validator to create string representation of partition 
 + keys ( CASSANDRA - 7498 ) 
 * Avoid NPEs when receiving type changes for an unknown keyspace ( CASSANDRA - 7689 ) 
 * Add support for custom 2i validation ( CASSANDRA - 7575 ) 
 * Pig support for hadoop CqlInputFormat ( CASSANDRA - 6454 ) 
 diff - - git a / src / java / org / apache / cassandra / tools / SSTableExport . java b / src / java / org / apache / cassandra / tools / SSTableExport . java 
 index a63825e . . 3d5ff0b 100644 
 - - - a / src / java / org / apache / cassandra / tools / SSTableExport . java 
 + + + b / src / java / org / apache / cassandra / tools / SSTableExport . java 
 @ @ - 38 , 9 + 38 , 6 @ @ import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . codehaus . jackson . JsonGenerator ; 
 import org . codehaus . jackson . map . ObjectMapper ; 
 
 - import static org . apache . cassandra . utils . ByteBufferUtil . bytesToHex ; 
 - import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; 
 - 
 / * * 
 * Export SSTables to JSON format . 
 * / 
 @ @ - 188 , 7 + 185 , 7 @ @ public class SSTableExport 
 { 
 out . print ( " { " ) ; 
 writeKey ( out , " key " ) ; 
 - writeJSON ( out , bytesToHex ( key . getKey ( ) ) ) ; 
 + writeJSON ( out , metadata . getKeyValidator ( ) . getString ( key . getKey ( ) ) ) ; 
 out . print ( " , \ n " ) ; 
 
 if ( ! deletionInfo . isLive ( ) ) 
 @ @ - 222 , 9 + 219 , 10 @ @ public class SSTableExport 
 * 
 * @ param desc the descriptor of the file to export the rows from 
 * @ param outs PrintStream to write the output to 
 + * @ param metadata Metadata to print keys in a proper format 
 * @ throws IOException on failure to read / write input / output 
 * / 
 - public static void enumeratekeys ( Descriptor desc , PrintStream outs ) 
 + public static void enumeratekeys ( Descriptor desc , PrintStream outs , CFMetaData metadata ) 
 throws IOException 
 { 
 KeyIterator iter = new KeyIterator ( desc ) ; 
 @ @ - 238 , 7 + 236 , 7 @ @ public class SSTableExport 
 throw new IOException ( " Key out of order ! " + lastKey + " > " + key ) ; 
 lastKey = key ; 
 
 - outs . println ( bytesToHex ( key . getKey ( ) ) ) ; 
 + outs . println ( metadata . getKeyValidator ( ) . getString ( key . getKey ( ) ) ) ; 
 checkStream ( outs ) ; / / flushes 
 } 
 iter . close ( ) ; 
 @ @ - 251 , 9 + 249 , 10 @ @ public class SSTableExport 
 * @ param outs PrintStream to write the output to 
 * @ param toExport the keys corresponding to the rows to export 
 * @ param excludes keys to exclude from export 
 + * @ param metadata Metadata to print keys in a proper format 
 * @ throws IOException on failure to read / write input / output 
 * / 
 - public static void export ( Descriptor desc , PrintStream outs , Collection < String > toExport , String [ ] excludes ) throws IOException 
 + public static void export ( Descriptor desc , PrintStream outs , Collection < String > toExport , String [ ] excludes , CFMetaData metadata ) throws IOException 
 { 
 SSTableReader sstable = SSTableReader . open ( desc ) ; 
 RandomAccessReader dfile = sstable . openDataReader ( ) ; 
 @ @ - 272 , 7 + 271 , 7 @ @ public class SSTableExport 
 
 for ( String key : toExport ) 
 { 
 - DecoratedKey decoratedKey = partitioner . decorateKey ( hexToBytes ( key ) ) ; 
 + DecoratedKey decoratedKey = partitioner . decorateKey ( metadata . getKeyValidator ( ) . fromString ( key ) ) ; 
 
 if ( lastKey ! = null & & lastKey . compareTo ( decoratedKey ) > 0 ) 
 throw new IOException ( " Key out of order ! " + lastKey + " > " + decoratedKey ) ; 
 @ @ - 302 , 7 + 301 , 7 @ @ public class SSTableExport 
 
 / / This is necessary to accommodate the test suite since you cannot open a Reader more 
 / / than once from within the same process . 
 - static void export ( SSTableReader reader , PrintStream outs , String [ ] excludes ) throws IOException 
 + static void export ( SSTableReader reader , PrintStream outs , String [ ] excludes , CFMetaData metadata ) throws IOException 
 { 
 Set < String > excludeSet = new HashSet < String > ( ) ; 
 
 @ @ - 322 , 7 + 321 , 7 @ @ public class SSTableExport 
 { 
 row = ( SSTableIdentityIterator ) scanner . next ( ) ; 
 
 - String currentKey = bytesToHex ( row . getKey ( ) . getKey ( ) ) ; 
 + String currentKey = row . getColumnFamily ( ) . metadata ( ) . getKeyValidator ( ) . getString ( row . getKey ( ) . getKey ( ) ) ; 
 
 if ( excludeSet . contains ( currentKey ) ) 
 continue ; 
 @ @ - 347 , 11 + 346 , 12 @ @ public class SSTableExport 
 * @ param desc the descriptor of the sstable to read from 
 * @ param outs PrintStream to write the output to 
 * @ param excludes keys to exclude from export 
 + * @ param metadata Metadata to print keys in a proper format 
 * @ throws IOException on failure to read / write input / output 
 * / 
 - public static void export ( Descriptor desc , PrintStream outs , String [ ] excludes ) throws IOException 
 + public static void export ( Descriptor desc , PrintStream outs , String [ ] excludes , CFMetaData metadata ) throws IOException 
 { 
 - export ( SSTableReader . open ( desc ) , outs , excludes ) ; 
 + export ( SSTableReader . open ( desc ) , outs , excludes , metadata ) ; 
 } 
 
 / * * 
 @ @ - 359 , 11 + 359 , 12 @ @ public class SSTableExport 
 * 
 * @ param desc the descriptor of the sstable to read from 
 * @ param excludes keys to exclude from export 
 + * @ param metadata Metadata to print keys in a proper format 
 * @ throws IOException on failure to read / write SSTable / standard out 
 * / 
 - public static void export ( Descriptor desc , String [ ] excludes ) throws IOException 
 + public static void export ( Descriptor desc , String [ ] excludes , CFMetaData metadata ) throws IOException 
 { 
 - export ( desc , System . out , excludes ) ; 
 + export ( desc , System . out , excludes , metadata ) ; 
 } 
 
 / * * 
 @ @ - 415 , 7 + 416 , 7 @ @ public class SSTableExport 
 } 
 Keyspace keyspace = Keyspace . open ( descriptor . ksname ) ; 
 
 - / / Make it work for indexes too - find parent cf if necessary 
 + / / Make it works for indexes too - find parent cf if necessary 
 String baseName = descriptor . cfname ; 
 if ( descriptor . cfname . contains ( " . " ) ) 
 { 
 @ @ - 424 , 9 + 425 , 10 @ @ public class SSTableExport 
 } 
 
 / / IllegalArgumentException will be thrown here if ks / cf pair does not exist 
 + ColumnFamilyStore cfStore = null ; 
 try 
 { 
 - keyspace . getColumnFamilyStore ( baseName ) ; 
 + cfStore = keyspace . getColumnFamilyStore ( baseName ) ; 
 } 
 catch ( IllegalArgumentException e ) 
 { 
 @ @ - 439 , 14 + 441 , 14 @ @ public class SSTableExport 
 { 
 if ( cmd . hasOption ( ENUMERATEKEYS _ OPTION ) ) 
 { 
 - enumeratekeys ( descriptor , System . out ) ; 
 + enumeratekeys ( descriptor , System . out , cfStore . metadata ) ; 
 } 
 else 
 { 
 if ( ( keys ! = null ) & & ( keys . length > 0 ) ) 
 - export ( descriptor , System . out , Arrays . asList ( keys ) , excludes ) ; 
 + export ( descriptor , System . out , Arrays . asList ( keys ) , excludes , cfStore . metadata ) ; 
 else 
 - export ( descriptor , excludes ) ; 
 + export ( descriptor , excludes , cfStore . metadata ) ; 
 } 
 } 
 catch ( IOException e ) 
 diff - - git a / src / java / org / apache / cassandra / tools / SSTableImport . java b / src / java / org / apache / cassandra / tools / SSTableImport . java 
 index f5873a4 . . 290c92a 100644 
 - - - a / src / java / org / apache / cassandra / tools / SSTableImport . java 
 + + + b / src / java / org / apache / cassandra / tools / SSTableImport . java 
 @ @ - 17 , 8 + 17 , 6 @ @ 
 * / 
 package org . apache . cassandra . tools ; 
 
 - import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; 
 - 
 import java . io . File ; 
 import java . io . IOException ; 
 import java . nio . ByteBuffer ; 
 @ @ - 308 , 7 + 306 , 7 @ @ public class SSTableImport 
 for ( Object row : data ) 
 { 
 Map < ? , ? > rowAsMap = ( Map < ? , ? > ) row ; 
 - decoratedKeys . put ( partitioner . decorateKey ( hexToBytes ( ( String ) rowAsMap . get ( " key " ) ) ) , rowAsMap ) ; 
 + decoratedKeys . put ( partitioner . decorateKey ( getKeyValidator ( columnFamily ) . fromString ( ( String ) rowAsMap . get ( " key " ) ) ) , rowAsMap ) ; 
 } 
 
 for ( Map . Entry < DecoratedKey , Map < ? , ? > > row : decoratedKeys . entrySet ( ) ) 
 @ @ - 381 , 7 + 379 , 7 @ @ public class SSTableImport 
 { 
 String key = parser . getCurrentName ( ) ; 
 Map < ? , ? > row = parser . readValueAs ( new TypeReference < Map < ? , ? > > ( ) { } ) ; 
 - DecoratedKey currentKey = partitioner . decorateKey ( hexToBytes ( ( String ) row . get ( " key " ) ) ) ; 
 + DecoratedKey currentKey = partitioner . decorateKey ( getKeyValidator ( columnFamily ) . fromString ( ( String ) row . get ( " key " ) ) ) ; 
 
 if ( row . containsKey ( " metadata " ) ) 
 parseMeta ( ( Map < ? , ? > ) row . get ( " metadata " ) , columnFamily , null ) ; 
 @ @ - 423 , 6 + 421 , 21 @ @ public class SSTableImport 
 } 
 
 / * * 
 + * Get key validator for column family 
 + * @ param columnFamily column family instance 
 + * @ return key validator for given column family 
 + * / 
 + private AbstractType < ? > getKeyValidator ( ColumnFamily columnFamily ) { 
 + / / this is a fix to support backward compatibility 
 + / / which allows to skip the current key validator 
 + / / please , take a look onto CASSANDRA - 7498 for more details 
 + if ( " true " . equals ( System . getProperty ( " skip . key . validator " , " false " ) ) ) { 
 + return BytesType . instance ; 
 + } 
 + return columnFamily . metadata ( ) . getKeyValidator ( ) ; 
 + } 
 + 
 + / * * 
 * Get JsonParser object for file 
 * @ param fileName name of the file 
 * @ return json parser instance for given file 
 @ @ - 526 , 7 + 539 , 7 @ @ public class SSTableImport 
 { 
 try 
 { 
 - return ( type = = BytesType . instance ) ? hexToBytes ( content ) : type . fromString ( content ) ; 
 + return type . fromString ( content ) ; 
 } 
 catch ( MarshalException e ) 
 { 
 diff - - git a / test / unit / org / apache / cassandra / SchemaLoader . java b / test / unit / org / apache / cassandra / SchemaLoader . java 
 index 066f454 . . d18fd60 100644 
 - - - a / test / unit / org / apache / cassandra / SchemaLoader . java 
 + + + b / test / unit / org / apache / cassandra / SchemaLoader . java 
 @ @ - 170 , 7 + 170 , 8 @ @ public class SchemaLoader 
 
 standardCFMD ( ks1 , " UUIDKeys " ) . keyValidator ( UUIDType . instance ) , 
 CFMetaData . denseCFMetaData ( ks1 , " MixedTypes " , LongType . instance ) . keyValidator ( UUIDType . instance ) . defaultValidator ( BooleanType . instance ) , 
 - CFMetaData . denseCFMetaData ( ks1 , " MixedTypesComposite " , composite ) . keyValidator ( composite ) . defaultValidator ( BooleanType . instance ) 
 + CFMetaData . denseCFMetaData ( ks1 , " MixedTypesComposite " , composite ) . keyValidator ( composite ) . defaultValidator ( BooleanType . instance ) , 
 + standardCFMD ( ks1 , " AsciiKeys " ) . keyValidator ( AsciiType . instance ) 
 ) ) ; 
 
 / / Keyspace 2 
 diff - - git a / test / unit / org / apache / cassandra / Util . java b / test / unit / org / apache / cassandra / Util . java 
 index e06bd95 . . fd53170 100644 
 - - - a / test / unit / org / apache / cassandra / Util . java 
 + + + b / test / unit / org / apache / cassandra / Util . java 
 @ @ - 43 , 6 + 43 , 7 @ @ import org . apache . cassandra . db . filter . IDiskAtomFilter ; 
 import org . apache . cassandra . db . filter . QueryFilter ; 
 import org . apache . cassandra . db . filter . SliceQueryFilter ; 
 import org . apache . cassandra . db . filter . NamesQueryFilter ; 
 + import org . apache . cassandra . db . marshal . AbstractType ; 
 import org . apache . cassandra . dht . * ; 
 import org . apache . cassandra . gms . ApplicationState ; 
 import org . apache . cassandra . gms . Gossiper ; 
 @ @ - 65 , 6 + 66 , 11 @ @ public class Util 
 return StorageService . getPartitioner ( ) . decorateKey ( ByteBufferUtil . bytes ( key ) ) ; 
 } 
 
 + public static DecoratedKey dk ( String key , AbstractType type ) 
 + { 
 + return StorageService . getPartitioner ( ) . decorateKey ( type . fromString ( key ) ) ; 
 + } 
 + 
 public static DecoratedKey dk ( ByteBuffer key ) 
 { 
 return StorageService . getPartitioner ( ) . decorateKey ( key ) ; 
 diff - - git a / test / unit / org / apache / cassandra / tools / SSTableExportTest . java b / test / unit / org / apache / cassandra / tools / SSTableExportTest . java 
 index dbc6703 . . f1b7564 100644 
 - - - a / test / unit / org / apache / cassandra / tools / SSTableExportTest . java 
 + + + b / test / unit / org / apache / cassandra / tools / SSTableExportTest . java 
 @ @ - 18 , 25 + 18 , 28 @ @ 
 * / 
 package org . apache . cassandra . tools ; 
 
 - import static org . apache . cassandra . Util . column ; 
 - import static org . junit . Assert . assertEquals ; 
 - import static org . junit . Assert . assertNotNull ; 
 - import static org . apache . cassandra . io . sstable . SSTableUtils . tempSSTableFile ; 
 - import static org . apache . cassandra . utils . ByteBufferUtil . bytesToHex ; 
 - import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; 
 - 
 import java . io . File ; 
 import java . io . FileReader ; 
 import java . io . IOException ; 
 - import java . io . OutputStream ; 
 import java . io . PrintStream ; 
 
 + import org . junit . BeforeClass ; 
 + import org . junit . Test ; 
 + 
 import org . apache . cassandra . SchemaLoader ; 
 import org . apache . cassandra . Util ; 
 import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . KSMetaData ; 
 - import org . apache . cassandra . db . * ; 
 + import org . apache . cassandra . db . ArrayBackedSortedColumns ; 
 + import org . apache . cassandra . db . BufferCell ; 
 + import org . apache . cassandra . db . BufferCounterCell ; 
 + import org . apache . cassandra . db . BufferExpiringCell ; 
 + import org . apache . cassandra . db . ColumnFamily ; 
 + import org . apache . cassandra . db . ColumnFamilyStore ; 
 + import org . apache . cassandra . db . DeletionInfo ; 
 + import org . apache . cassandra . db . Keyspace ; 
 import org . apache . cassandra . db . filter . QueryFilter ; 
 + import org . apache . cassandra . db . marshal . AsciiType ; 
 import org . apache . cassandra . db . marshal . BytesType ; 
 import org . apache . cassandra . db . marshal . CounterColumnType ; 
 import org . apache . cassandra . db . marshal . UTF8Type ; 
 @ @ - 54 , 8 + 57 , 13 @ @ import org . json . simple . JSONArray ; 
 import org . json . simple . JSONObject ; 
 import org . json . simple . JSONValue ; 
 import org . json . simple . parser . ParseException ; 
 - import org . junit . BeforeClass ; 
 - import org . junit . Test ; 
 + 
 + import static org . apache . cassandra . Util . column ; 
 + import static org . apache . cassandra . io . sstable . SSTableUtils . tempSSTableFile ; 
 + import static org . apache . cassandra . utils . ByteBufferUtil . bytesToHex ; 
 + import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; 
 + import static org . junit . Assert . assertEquals ; 
 + import static org . junit . Assert . assertNotNull ; 
 
 public class SSTableExportTest 
 { 
 @ @ - 104 , 7 + 112 , 9 @ @ public class SSTableExportTest 
 
 / / Enumerate and verify 
 File temp = File . createTempFile ( " Standard1 " , " . txt " ) ; 
 - SSTableExport . enumeratekeys ( Descriptor . fromFilename ( writer . getFilename ( ) ) , new PrintStream ( temp . getPath ( ) ) ) ; 
 + final Descriptor descriptor = Descriptor . fromFilename ( writer . getFilename ( ) ) ; 
 + SSTableExport . enumeratekeys ( descriptor , new PrintStream ( temp . getPath ( ) ) , 
 + CFMetaData . sparseCFMetaData ( descriptor . ksname , descriptor . cfname , BytesType . instance ) ) ; 
 
 
 try ( FileReader file = new FileReader ( temp ) ) 
 @ @ - 146 , 7 + 156 , 8 @ @ public class SSTableExportTest 
 
 / / Export to JSON and verify 
 File tempJson = File . createTempFile ( " Standard1 " , " . json " ) ; 
 - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ ] { asHex ( " rowExclude " ) } ) ; 
 + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ ] { asHex ( " rowExclude " ) } , 
 + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " Standard1 " , BytesType . instance ) ) ; 
 
 JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; 
 assertEquals ( " unexpected number of rows " , 2 , json . size ( ) ) ; 
 @ @ - 195 , 7 + 206 , 8 @ @ public class SSTableExportTest 
 
 / / Export to JSON and verify 
 File tempJson = File . createTempFile ( " Standard1 " , " . json " ) ; 
 - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ ] { asHex ( " rowExclude " ) } ) ; 
 + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ ] { asHex ( " rowExclude " ) } , 
 + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " Standard1 " , BytesType . instance ) ) ; 
 
 / / Import JSON to another SSTable file 
 File tempSS2 = tempSSTableFile ( KEYSPACE1 , " Standard1 " ) ; 
 @ @ - 229 , 7 + 241 , 8 @ @ public class SSTableExportTest 
 
 / / Export to JSON and verify 
 File tempJson = File . createTempFile ( " Counter1 " , " . json " ) ; 
 - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] ) ; 
 + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] , 
 + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " Counter1 " , BytesType . instance ) ) ; 
 JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; 
 assertEquals ( " unexpected number of rows " , 1 , json . size ( ) ) ; 
 
 @ @ - 260 , 7 + 273 , 8 @ @ public class SSTableExportTest 
 
 / / Export to JSON and verify 
 File tempJson = File . createTempFile ( " ValuesWithQuotes " , " . json " ) ; 
 - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] ) ; 
 + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] , 
 + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " ValuesWithQuotes " , BytesType . instance ) ) ; 
 
 JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; 
 assertEquals ( " unexpected number of rows " , 1 , json . size ( ) ) ; 
 @ @ - 291 , 7 + 305 , 8 @ @ public class SSTableExportTest 
 SSTableReader reader = writer . closeAndOpenReader ( ) ; 
 / / Export to JSON and verify 
 File tempJson = File . createTempFile ( " CFWithDeletionInfo " , " . json " ) ; 
 - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] ) ; 
 + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] , 
 + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " Counter1 " , BytesType . instance ) ) ; 
 
 JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; 
 assertEquals ( " unexpected number of rows " , 1 , json . size ( ) ) ; 
 @ @ - 350 , 7 + 365 , 8 @ @ public class SSTableExportTest 
 SSTableReader reader = writer . closeAndOpenReader ( ) ; 
 / / Export to JSON and verify 
 File tempJson = File . createTempFile ( " CFWithColumnNameEqualToDefaultKeyAlias " , " . json " ) ; 
 - SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] ) ; 
 + SSTableExport . export ( reader , new PrintStream ( tempJson . getPath ( ) ) , new String [ 0 ] , 
 + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " UUIDKeys " , BytesType . instance ) ) ; 
 
 JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; 
 assertEquals ( 1 , json . size ( ) ) ; 
 @ @ - 364 , 4 + 380 , 31 @ @ public class SSTableExportTest 
 assertEquals ( CFMetaData . DEFAULT _ KEY _ ALIAS , ByteBufferUtil . string ( hexToBytes ( ( String ) col . get ( 0 ) ) ) ) ; 
 assertEquals ( " not a uuid " , ByteBufferUtil . string ( hexToBytes ( ( String ) col . get ( 1 ) ) ) ) ; 
 } 
 + 
 + @ Test 
 + public void testAsciiKeyValidator ( ) throws IOException , ParseException 
 + { 
 + File tempSS = tempSSTableFile ( " Keyspace1 " , " AsciiKeys " ) ; 
 + ColumnFamily cfamily = ArrayBackedSortedColumns . factory . create ( " Keyspace1 " , " AsciiKeys " ) ; 
 + SSTableWriter writer = new SSTableWriter ( tempSS . getPath ( ) , 2 , ActiveRepairService . UNREPAIRED _ SSTABLE ) ; 
 + 
 + / / Add a row 
 + cfamily . addColumn ( column ( " column " , " value " , 1L ) ) ; 
 + writer . append ( Util . dk ( " key " , AsciiType . instance ) , cfamily ) ; 
 + 
 + SSTableReader reader = writer . closeAndOpenReader ( ) ; 
 + / / Export to JSON and verify 
 + File tempJson = File . createTempFile ( " CFWithAsciiKeys " , " . json " ) ; 
 + SSTableExport . export ( reader , 
 + new PrintStream ( tempJson . getPath ( ) ) , 
 + new String [ 0 ] , 
 + CFMetaData . sparseCFMetaData ( " Keyspace1 " , " AsciiKeys " , BytesType . instance ) ) ; 
 + 
 + JSONArray json = ( JSONArray ) JSONValue . parseWithException ( new FileReader ( tempJson ) ) ; 
 + assertEquals ( 1 , json . size ( ) ) ; 
 + 
 + JSONObject row = ( JSONObject ) json . get ( 0 ) ; 
 + / / check row key 
 + assertEquals ( " key " , row . get ( " key " ) ) ; 
 + } 
 } 
 diff - - git a / test / unit / org / apache / cassandra / tools / SSTableImportTest . java b / test / unit / org / apache / cassandra / tools / SSTableImportTest . java 
 index dba8408 . . 8ea0ab8 100644 
 - - - a / test / unit / org / apache / cassandra / tools / SSTableImportTest . java 
 + + + b / test / unit / org / apache / cassandra / tools / SSTableImportTest . java 
 @ @ - 18 , 10 + 18 , 6 @ @ 
 * / 
 package org . apache . cassandra . tools ; 
 
 - import static org . junit . Assert . assertEquals ; 
 - import static org . apache . cassandra . io . sstable . SSTableUtils . tempSSTableFile ; 
 - import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; 
 - 
 import java . io . File ; 
 import java . io . IOException ; 
 import java . net . URI ; 
 @ @ - 34 , 17 + 30 , 28 @ @ import org . apache . cassandra . SchemaLoader ; 
 import org . apache . cassandra . Util ; 
 import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . KSMetaData ; 
 - import org . apache . cassandra . db . * ; 
 + import org . apache . cassandra . db . ArrayBackedSortedColumns ; 
 + import org . apache . cassandra . db . BufferDeletedCell ; 
 + import org . apache . cassandra . db . Cell ; 
 + import org . apache . cassandra . db . ColumnFamily ; 
 + import org . apache . cassandra . db . CounterCell ; 
 + import org . apache . cassandra . db . DeletionInfo ; 
 + import org . apache . cassandra . db . ExpiringCell ; 
 import org . apache . cassandra . db . columniterator . OnDiskAtomIterator ; 
 import org . apache . cassandra . db . filter . QueryFilter ; 
 + import org . apache . cassandra . db . marshal . AsciiType ; 
 import org . apache . cassandra . db . marshal . BytesType ; 
 import org . apache . cassandra . db . marshal . CounterColumnType ; 
 import org . apache . cassandra . exceptions . ConfigurationException ; 
 - import org . apache . cassandra . locator . SimpleStrategy ; 
 import org . apache . cassandra . io . sstable . Descriptor ; 
 import org . apache . cassandra . io . sstable . SSTableReader ; 
 + import org . apache . cassandra . locator . SimpleStrategy ; 
 import org . apache . thrift . TException ; 
 
 + import static org . apache . cassandra . io . sstable . SSTableUtils . tempSSTableFile ; 
 + import static org . apache . cassandra . utils . ByteBufferUtil . hexToBytes ; 
 + import static org . junit . Assert . assertEquals ; 
 + 
 public class SSTableImportTest 
 { 
 public static final String KEYSPACE1 = " SSTableImportTest " ; 
 @ @ - 160 , 4 + 167 , 41 @ @ public class SSTableImportTest 
 assert c instanceof CounterCell : c ; 
 assert ( ( CounterCell ) c ) . total ( ) = = 42 ; 
 } 
 + 
 + @ Test 
 + public void testImportWithAsciiKeyValidator ( ) throws IOException , URISyntaxException 
 + { 
 + / / Import JSON to temp SSTable file 
 + String jsonUrl = resourcePath ( " SimpleCF . json " ) ; 
 + File tempSS = tempSSTableFile ( " Keyspace1 " , " AsciiKeys " ) ; 
 + new SSTableImport ( true ) . importJson ( jsonUrl , " Keyspace1 " , " AsciiKeys " , tempSS . getPath ( ) ) ; 
 + 
 + / / Verify results 
 + SSTableReader reader = SSTableReader . open ( Descriptor . fromFilename ( tempSS . getPath ( ) ) ) ; 
 + / / check that keys are treated as ascii 
 + QueryFilter qf = QueryFilter . getIdentityFilter ( Util . dk ( " 726f7741 " , AsciiType . instance ) , " AsciiKeys " , System . currentTimeMillis ( ) ) ; 
 + OnDiskAtomIterator iter = qf . getSSTableColumnIterator ( reader ) ; 
 + assert iter . hasNext ( ) ; / / " ascii " key exists 
 + QueryFilter qf2 = QueryFilter . getIdentityFilter ( Util . dk ( " 726f7741 " , BytesType . instance ) , " AsciiKeys " , System . currentTimeMillis ( ) ) ; 
 + OnDiskAtomIterator iter2 = qf2 . getSSTableColumnIterator ( reader ) ; 
 + assert ! iter2 . hasNext ( ) ; / / " bytes " key does not exist 
 + } 
 + 
 + @ Test 
 + public void testBackwardCompatibilityOfImportWithAsciiKeyValidator ( ) throws IOException , URISyntaxException 
 + { 
 + / / Import JSON to temp SSTable file 
 + String jsonUrl = resourcePath ( " SimpleCF . json " ) ; 
 + File tempSS = tempSSTableFile ( " Keyspace1 " , " AsciiKeys " ) ; 
 + / / To ignore current key validator 
 + System . setProperty ( " skip . key . validator " , " true " ) ; 
 + new SSTableImport ( true ) . importJson ( jsonUrl , " Keyspace1 " , " AsciiKeys " , tempSS . getPath ( ) ) ; 
 + 
 + / / Verify results 
 + SSTableReader reader = SSTableReader . open ( Descriptor . fromFilename ( tempSS . getPath ( ) ) ) ; 
 + / / check that keys are treated as bytes 
 + QueryFilter qf = QueryFilter . getIdentityFilter ( Util . dk ( " rowA " ) , " AsciiKeys " , System . currentTimeMillis ( ) ) ; 
 + OnDiskAtomIterator iter = qf . getSSTableColumnIterator ( reader ) ; 
 + assert iter . hasNext ( ) ; / / " bytes " key exists 
 + } 
 }

NEAREST DIFF:
ELIMINATEDSENTENCE
