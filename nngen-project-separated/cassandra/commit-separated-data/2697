BLEU SCORE: 0.013934865340421458

TEST MSG: Fix RangeTombstoneTest for CASSANDRA - 6640 change
GENERATED MSG: Stop reading from sstables once we know we have the most recent columns

TEST DIFF (one line): diff - - git a / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java b / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java <nl> index 1885716 . . ce6028c 100644 <nl> - - - a / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java <nl> + + + b / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java <nl> @ @ - 341 , 19 + 341 , 16 @ @ public class RangeTombstoneTest extends SchemaLoader <nl> <nl> cfs . forceBlockingFlush ( ) ; <nl> <nl> - / / We should have 2 updates to the indexed " 1 " column <nl> - assertEquals ( 2 , index . inserts . size ( ) ) ; <nl> + / / We should have 1 insert and 1 update to the indexed " 1 " column <nl> + / / CASSANDRA - 6640 changed index update to just update , not insert then delete <nl> + assertEquals ( 1 , index . inserts . size ( ) ) ; <nl> + assertEquals ( 1 , index . updates . size ( ) ) ; <nl> <nl> CompactionManager . instance . performMaximal ( cfs ) ; <nl> <nl> - / / verify that the " 1 " indexed column removed from the index twice : <nl> - / / the first time by processing the RT , the second time by the <nl> - / / re - indexing caused by the second insertion . This second write <nl> - / / deletes from the 2i because the original column was still in the <nl> - / / main cf ' s memtable ( shadowed by the RT ) . One thing we ' re checking <nl> - / / for here is that there wasn ' t an additional , bogus delete issued <nl> - / / to the 2i ( CASSANDRA - 6517 ) <nl> - assertEquals ( 2 , index . deletes . size ( ) ) ; <nl> + / / verify that the " 1 " indexed column removed from the index <nl> + / / After CASSANDRA - 6640 , deletion only happens once <nl> + assertEquals ( 1 , index . deletes . size ( ) ) ; <nl> } <nl> <nl> private void runCompactionWithRangeTombstoneAndCheckSecondaryIndex ( ) throws Exception <nl> @ @ - 435 , 11 + 432 , 13 @ @ public class RangeTombstoneTest extends SchemaLoader <nl> { <nl> public List < Cell > inserts = new ArrayList < > ( ) ; <nl> public List < Cell > deletes = new ArrayList < > ( ) ; <nl> + public List < Cell > updates = new ArrayList < > ( ) ; <nl> <nl> public void resetCounts ( ) <nl> { <nl> inserts . clear ( ) ; <nl> deletes . clear ( ) ; <nl> + updates . clear ( ) ; <nl> } <nl> <nl> public void delete ( ByteBuffer rowKey , Cell col , OpOrder . Group opGroup ) <nl> @ @ - 452 , 7 + 451 , 10 @ @ public class RangeTombstoneTest extends SchemaLoader <nl> inserts . add ( col ) ; <nl> } <nl> <nl> - public void update ( ByteBuffer rowKey , Cell oldCol , Cell col , OpOrder . Group opGroup ) { } <nl> + public void update ( ByteBuffer rowKey , Cell oldCol , Cell col , OpOrder . Group opGroup ) <nl> + { <nl> + updates . add ( col ) ; <nl> + } <nl> <nl> public void init ( ) { } <nl>
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 70281be . . fd96002 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 37 , 7 + 37 , 7 @ @ <nl> and few other places responsible for work with SSTable files ( CASSANDRA - 3040 ) <nl> * Stop reading from sstables once we know we have the most recent columns , <nl> for query - by - name requests ( CASSANDRA - 2498 ) <nl> - <nl> + * Add query - by - column mode to stress . java ( CASSANDRA - 3064 ) <nl> <nl> 0 . 8 . 5 <nl> * fix NPE when encryption _ options is unspecified ( CASSANDRA - 3007 ) <nl> diff - - git a / tools / stress / src / org / apache / cassandra / stress / Session . java b / tools / stress / src / org / apache / cassandra / stress / Session . java <nl> index 1508379 . . df0305b 100644 <nl> - - - a / tools / stress / src / org / apache / cassandra / stress / Session . java <nl> + + + b / tools / stress / src / org / apache / cassandra / stress / Session . java <nl> @ @ - 20 , 10 + 20 , 14 @ @ package org . apache . cassandra . stress ; <nl> import java . io . * ; <nl> import java . net . InetAddress ; <nl> import java . net . UnknownHostException ; <nl> + import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> import java . util . concurrent . atomic . AtomicInteger ; <nl> import java . util . concurrent . atomic . AtomicLong ; <nl> <nl> + import org . apache . cassandra . config . ConfigurationException ; <nl> + import org . apache . cassandra . db . marshal . AbstractType ; <nl> + import org . apache . cassandra . db . marshal . TypeParser ; <nl> import org . apache . commons . cli . * ; <nl> <nl> import org . apache . cassandra . db . ColumnFamilyType ; <nl> @ @ - 41 , 6 + 45 , 9 @ @ public class Session implements Serializable <nl> / / command line options <nl> public static final Options availableOptions = new Options ( ) ; <nl> <nl> + public static final String DEFAULT _ COMPARATOR = " AsciiType " ; <nl> + public static final String DEFAULT _ VALIDATOR = " BytesType " ; <nl> + <nl> public final AtomicInteger operations ; <nl> public final AtomicInteger keys ; <nl> public final AtomicLong latency ; <nl> @ @ - 78 , 6 + 85 , 7 @ @ public class Session implements Serializable <nl> availableOptions . addOption ( " V " , " average - size - values " , false , " Generate column values of average rather than specific size " ) ; <nl> availableOptions . addOption ( " T " , " send - to " , true , " Send this as a request to the stress daemon at specified address . " ) ; <nl> availableOptions . addOption ( " I " , " compression " , false , " Use sstable compression when creating schema " ) ; <nl> + availableOptions . addOption ( " Q " , " query - names " , true , " Comma - separated list of column names to retrieve from each row . " ) ; <nl> } <nl> <nl> private int numKeys = 1000 * 1000 ; <nl> @ @ - 109 , 6 + 117 , 9 @ @ public class Session implements Serializable <nl> private String replicationStrategy = " org . apache . cassandra . locator . SimpleStrategy " ; <nl> private Map < String , String > replicationStrategyOptions = new HashMap < String , String > ( ) ; <nl> <nl> + / / if we know exactly column names that we want to read ( set by - Q option ) <nl> + public final List < ByteBuffer > columnNames ; <nl> + <nl> public final boolean averageSizeValues ; <nl> <nl> / / required by Gaussian distribution . <nl> @ @ - 275 , 11 + 286 , 30 @ @ public class Session implements Serializable <nl> { <nl> throw new RuntimeException ( e ) ; <nl> } <nl> + <nl> + if ( cmd . hasOption ( " Q " ) ) <nl> + { <nl> + AbstractType comparator = TypeParser . parse ( DEFAULT _ COMPARATOR ) ; <nl> + <nl> + String [ ] names = StringUtils . split ( cmd . getOptionValue ( " Q " ) , " , " ) ; <nl> + columnNames = new ArrayList < ByteBuffer > ( names . length ) ; <nl> + <nl> + for ( String columnName : names ) <nl> + columnNames . add ( comparator . fromString ( columnName ) ) ; <nl> + } <nl> + else <nl> + { <nl> + columnNames = null ; <nl> + } <nl> } <nl> catch ( ParseException e ) <nl> { <nl> throw new IllegalArgumentException ( e . getMessage ( ) , e ) ; <nl> } <nl> + catch ( ConfigurationException e ) <nl> + { <nl> + throw new IllegalStateException ( e . getMessage ( ) , e ) ; <nl> + } <nl> <nl> mean = numDifferentKeys / 2 ; <nl> sigma = numDifferentKeys * STDev ; <nl> @ @ - 417 , 8 + 447 , 11 @ @ public class Session implements Serializable <nl> <nl> / / column family for standard columns <nl> CfDef standardCfDef = new CfDef ( " Keyspace1 " , " Standard1 " ) ; <nl> - System . out . println ( " Compression = " + compression ) ; <nl> - standardCfDef . setComparator _ type ( " AsciiType " ) . setDefault _ validation _ class ( " BytesType " ) . setCompression ( compression ) ; <nl> + <nl> + standardCfDef . setComparator _ type ( DEFAULT _ COMPARATOR ) <nl> + . setDefault _ validation _ class ( DEFAULT _ VALIDATOR ) <nl> + . setCompression ( compression ) ; <nl> + <nl> if ( indexType ! = null ) <nl> { <nl> ColumnDef standardColumn = new ColumnDef ( ByteBufferUtil . bytes ( " C1 " ) , " BytesType " ) ; <nl> @ @ - 428 , 7 + 461 , 10 @ @ public class Session implements Serializable <nl> <nl> / / column family with super columns <nl> CfDef superCfDef = new CfDef ( " Keyspace1 " , " Super1 " ) . setColumn _ type ( " Super " ) ; <nl> - superCfDef . setComparator _ type ( " AsciiType " ) . setSubcomparator _ type ( " AsciiType " ) . setDefault _ validation _ class ( " BytesType " ) . setCompression ( compression ) ; <nl> + superCfDef . setComparator _ type ( DEFAULT _ COMPARATOR ) <nl> + . setSubcomparator _ type ( DEFAULT _ COMPARATOR ) <nl> + . setDefault _ validation _ class ( DEFAULT _ VALIDATOR ) <nl> + . setCompression ( compression ) ; <nl> <nl> / / column family for standard counters <nl> CfDef counterCfDef = new CfDef ( " Keyspace1 " , " Counter1 " ) . setDefault _ validation _ class ( " CounterColumnType " ) . setReplicate _ on _ write ( replicateOnWrite ) . setCompression ( compression ) ; <nl> diff - - git a / tools / stress / src / org / apache / cassandra / stress / operations / Reader . java b / tools / stress / src / org / apache / cassandra / stress / operations / Reader . java <nl> index 6dcd4cd . . b5a8781 100644 <nl> - - - a / tools / stress / src / org / apache / cassandra / stress / operations / Reader . java <nl> + + + b / tools / stress / src / org / apache / cassandra / stress / operations / Reader . java <nl> @ @ - 37 , 16 + 37 , 13 @ @ public class Reader extends Operation <nl> <nl> public void run ( Cassandra . Client client ) throws IOException <nl> { <nl> - SliceRange sliceRange = new SliceRange ( ) ; <nl> - <nl> - / / start / finish <nl> - sliceRange . setStart ( new byte [ ] { } ) . setFinish ( new byte [ ] { } ) ; <nl> - <nl> - / / reversed / count <nl> - sliceRange . setReversed ( false ) . setCount ( session . getColumnsPerKey ( ) ) ; <nl> - <nl> / / initialize SlicePredicate with existing SliceRange <nl> - SlicePredicate predicate = new SlicePredicate ( ) . setSlice _ range ( sliceRange ) ; <nl> + SlicePredicate predicate = new SlicePredicate ( ) ; <nl> + <nl> + if ( session . columnNames = = null ) <nl> + predicate . setSlice _ range ( getSliceRange ( ) ) ; <nl> + else / / see CASSANDRA - 3064 about why this is useful <nl> + predicate . setColumn _ names ( session . columnNames ) ; <nl> <nl> if ( session . getColumnFamilyType ( ) = = ColumnFamilyType . Super ) <nl> { <nl> @ @ - 150 , 4 + 147 , 12 @ @ public class Reader extends Operation <nl> session . latency . getAndAdd ( System . currentTimeMillis ( ) - start ) ; <nl> } <nl> <nl> + private SliceRange getSliceRange ( ) <nl> + { <nl> + return new SliceRange ( ) <nl> + . setStart ( new byte [ ] { } ) <nl> + . setFinish ( new byte [ ] { } ) <nl> + . setReversed ( false ) <nl> + . setCount ( session . getColumnsPerKey ( ) ) ; <nl> + } <nl> }

TEST DIFF:
diff - - git a / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java b / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java 
 index 1885716 . . ce6028c 100644 
 - - - a / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java 
 + + + b / test / unit / org / apache / cassandra / db / RangeTombstoneTest . java 
 @ @ - 341 , 19 + 341 , 16 @ @ public class RangeTombstoneTest extends SchemaLoader 
 
 cfs . forceBlockingFlush ( ) ; 
 
 - / / We should have 2 updates to the indexed " 1 " column 
 - assertEquals ( 2 , index . inserts . size ( ) ) ; 
 + / / We should have 1 insert and 1 update to the indexed " 1 " column 
 + / / CASSANDRA - 6640 changed index update to just update , not insert then delete 
 + assertEquals ( 1 , index . inserts . size ( ) ) ; 
 + assertEquals ( 1 , index . updates . size ( ) ) ; 
 
 CompactionManager . instance . performMaximal ( cfs ) ; 
 
 - / / verify that the " 1 " indexed column removed from the index twice : 
 - / / the first time by processing the RT , the second time by the 
 - / / re - indexing caused by the second insertion . This second write 
 - / / deletes from the 2i because the original column was still in the 
 - / / main cf ' s memtable ( shadowed by the RT ) . One thing we ' re checking 
 - / / for here is that there wasn ' t an additional , bogus delete issued 
 - / / to the 2i ( CASSANDRA - 6517 ) 
 - assertEquals ( 2 , index . deletes . size ( ) ) ; 
 + / / verify that the " 1 " indexed column removed from the index 
 + / / After CASSANDRA - 6640 , deletion only happens once 
 + assertEquals ( 1 , index . deletes . size ( ) ) ; 
 } 
 
 private void runCompactionWithRangeTombstoneAndCheckSecondaryIndex ( ) throws Exception 
 @ @ - 435 , 11 + 432 , 13 @ @ public class RangeTombstoneTest extends SchemaLoader 
 { 
 public List < Cell > inserts = new ArrayList < > ( ) ; 
 public List < Cell > deletes = new ArrayList < > ( ) ; 
 + public List < Cell > updates = new ArrayList < > ( ) ; 
 
 public void resetCounts ( ) 
 { 
 inserts . clear ( ) ; 
 deletes . clear ( ) ; 
 + updates . clear ( ) ; 
 } 
 
 public void delete ( ByteBuffer rowKey , Cell col , OpOrder . Group opGroup ) 
 @ @ - 452 , 7 + 451 , 10 @ @ public class RangeTombstoneTest extends SchemaLoader 
 inserts . add ( col ) ; 
 } 
 
 - public void update ( ByteBuffer rowKey , Cell oldCol , Cell col , OpOrder . Group opGroup ) { } 
 + public void update ( ByteBuffer rowKey , Cell oldCol , Cell col , OpOrder . Group opGroup ) 
 + { 
 + updates . add ( col ) ; 
 + } 
 
 public void init ( ) { } 


NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 70281be . . fd96002 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 37 , 7 + 37 , 7 @ @ 
 and few other places responsible for work with SSTable files ( CASSANDRA - 3040 ) 
 * Stop reading from sstables once we know we have the most recent columns , 
 for query - by - name requests ( CASSANDRA - 2498 ) 
 - 
 + * Add query - by - column mode to stress . java ( CASSANDRA - 3064 ) 
 
 0 . 8 . 5 
 * fix NPE when encryption _ options is unspecified ( CASSANDRA - 3007 ) 
 diff - - git a / tools / stress / src / org / apache / cassandra / stress / Session . java b / tools / stress / src / org / apache / cassandra / stress / Session . java 
 index 1508379 . . df0305b 100644 
 - - - a / tools / stress / src / org / apache / cassandra / stress / Session . java 
 + + + b / tools / stress / src / org / apache / cassandra / stress / Session . java 
 @ @ - 20 , 10 + 20 , 14 @ @ package org . apache . cassandra . stress ; 
 import java . io . * ; 
 import java . net . InetAddress ; 
 import java . net . UnknownHostException ; 
 + import java . nio . ByteBuffer ; 
 import java . util . * ; 
 import java . util . concurrent . atomic . AtomicInteger ; 
 import java . util . concurrent . atomic . AtomicLong ; 
 
 + import org . apache . cassandra . config . ConfigurationException ; 
 + import org . apache . cassandra . db . marshal . AbstractType ; 
 + import org . apache . cassandra . db . marshal . TypeParser ; 
 import org . apache . commons . cli . * ; 
 
 import org . apache . cassandra . db . ColumnFamilyType ; 
 @ @ - 41 , 6 + 45 , 9 @ @ public class Session implements Serializable 
 / / command line options 
 public static final Options availableOptions = new Options ( ) ; 
 
 + public static final String DEFAULT _ COMPARATOR = " AsciiType " ; 
 + public static final String DEFAULT _ VALIDATOR = " BytesType " ; 
 + 
 public final AtomicInteger operations ; 
 public final AtomicInteger keys ; 
 public final AtomicLong latency ; 
 @ @ - 78 , 6 + 85 , 7 @ @ public class Session implements Serializable 
 availableOptions . addOption ( " V " , " average - size - values " , false , " Generate column values of average rather than specific size " ) ; 
 availableOptions . addOption ( " T " , " send - to " , true , " Send this as a request to the stress daemon at specified address . " ) ; 
 availableOptions . addOption ( " I " , " compression " , false , " Use sstable compression when creating schema " ) ; 
 + availableOptions . addOption ( " Q " , " query - names " , true , " Comma - separated list of column names to retrieve from each row . " ) ; 
 } 
 
 private int numKeys = 1000 * 1000 ; 
 @ @ - 109 , 6 + 117 , 9 @ @ public class Session implements Serializable 
 private String replicationStrategy = " org . apache . cassandra . locator . SimpleStrategy " ; 
 private Map < String , String > replicationStrategyOptions = new HashMap < String , String > ( ) ; 
 
 + / / if we know exactly column names that we want to read ( set by - Q option ) 
 + public final List < ByteBuffer > columnNames ; 
 + 
 public final boolean averageSizeValues ; 
 
 / / required by Gaussian distribution . 
 @ @ - 275 , 11 + 286 , 30 @ @ public class Session implements Serializable 
 { 
 throw new RuntimeException ( e ) ; 
 } 
 + 
 + if ( cmd . hasOption ( " Q " ) ) 
 + { 
 + AbstractType comparator = TypeParser . parse ( DEFAULT _ COMPARATOR ) ; 
 + 
 + String [ ] names = StringUtils . split ( cmd . getOptionValue ( " Q " ) , " , " ) ; 
 + columnNames = new ArrayList < ByteBuffer > ( names . length ) ; 
 + 
 + for ( String columnName : names ) 
 + columnNames . add ( comparator . fromString ( columnName ) ) ; 
 + } 
 + else 
 + { 
 + columnNames = null ; 
 + } 
 } 
 catch ( ParseException e ) 
 { 
 throw new IllegalArgumentException ( e . getMessage ( ) , e ) ; 
 } 
 + catch ( ConfigurationException e ) 
 + { 
 + throw new IllegalStateException ( e . getMessage ( ) , e ) ; 
 + } 
 
 mean = numDifferentKeys / 2 ; 
 sigma = numDifferentKeys * STDev ; 
 @ @ - 417 , 8 + 447 , 11 @ @ public class Session implements Serializable 
 
 / / column family for standard columns 
 CfDef standardCfDef = new CfDef ( " Keyspace1 " , " Standard1 " ) ; 
 - System . out . println ( " Compression = " + compression ) ; 
 - standardCfDef . setComparator _ type ( " AsciiType " ) . setDefault _ validation _ class ( " BytesType " ) . setCompression ( compression ) ; 
 + 
 + standardCfDef . setComparator _ type ( DEFAULT _ COMPARATOR ) 
 + . setDefault _ validation _ class ( DEFAULT _ VALIDATOR ) 
 + . setCompression ( compression ) ; 
 + 
 if ( indexType ! = null ) 
 { 
 ColumnDef standardColumn = new ColumnDef ( ByteBufferUtil . bytes ( " C1 " ) , " BytesType " ) ; 
 @ @ - 428 , 7 + 461 , 10 @ @ public class Session implements Serializable 
 
 / / column family with super columns 
 CfDef superCfDef = new CfDef ( " Keyspace1 " , " Super1 " ) . setColumn _ type ( " Super " ) ; 
 - superCfDef . setComparator _ type ( " AsciiType " ) . setSubcomparator _ type ( " AsciiType " ) . setDefault _ validation _ class ( " BytesType " ) . setCompression ( compression ) ; 
 + superCfDef . setComparator _ type ( DEFAULT _ COMPARATOR ) 
 + . setSubcomparator _ type ( DEFAULT _ COMPARATOR ) 
 + . setDefault _ validation _ class ( DEFAULT _ VALIDATOR ) 
 + . setCompression ( compression ) ; 
 
 / / column family for standard counters 
 CfDef counterCfDef = new CfDef ( " Keyspace1 " , " Counter1 " ) . setDefault _ validation _ class ( " CounterColumnType " ) . setReplicate _ on _ write ( replicateOnWrite ) . setCompression ( compression ) ; 
 diff - - git a / tools / stress / src / org / apache / cassandra / stress / operations / Reader . java b / tools / stress / src / org / apache / cassandra / stress / operations / Reader . java 
 index 6dcd4cd . . b5a8781 100644 
 - - - a / tools / stress / src / org / apache / cassandra / stress / operations / Reader . java 
 + + + b / tools / stress / src / org / apache / cassandra / stress / operations / Reader . java 
 @ @ - 37 , 16 + 37 , 13 @ @ public class Reader extends Operation 
 
 public void run ( Cassandra . Client client ) throws IOException 
 { 
 - SliceRange sliceRange = new SliceRange ( ) ; 
 - 
 - / / start / finish 
 - sliceRange . setStart ( new byte [ ] { } ) . setFinish ( new byte [ ] { } ) ; 
 - 
 - / / reversed / count 
 - sliceRange . setReversed ( false ) . setCount ( session . getColumnsPerKey ( ) ) ; 
 - 
 / / initialize SlicePredicate with existing SliceRange 
 - SlicePredicate predicate = new SlicePredicate ( ) . setSlice _ range ( sliceRange ) ; 
 + SlicePredicate predicate = new SlicePredicate ( ) ; 
 + 
 + if ( session . columnNames = = null ) 
 + predicate . setSlice _ range ( getSliceRange ( ) ) ; 
 + else / / see CASSANDRA - 3064 about why this is useful 
 + predicate . setColumn _ names ( session . columnNames ) ; 
 
 if ( session . getColumnFamilyType ( ) = = ColumnFamilyType . Super ) 
 { 
 @ @ - 150 , 4 + 147 , 12 @ @ public class Reader extends Operation 
 session . latency . getAndAdd ( System . currentTimeMillis ( ) - start ) ; 
 } 
 
 + private SliceRange getSliceRange ( ) 
 + { 
 + return new SliceRange ( ) 
 + . setStart ( new byte [ ] { } ) 
 + . setFinish ( new byte [ ] { } ) 
 + . setReversed ( false ) 
 + . setCount ( session . getColumnsPerKey ( ) ) ; 
 + } 
 }
