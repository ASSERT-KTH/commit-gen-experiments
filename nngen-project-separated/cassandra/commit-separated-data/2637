BLEU SCORE: 0.02383853510228548

TEST MSG: Update hadoop _ cql3 _ word _ count example
GENERATED MSG: merge from 1 . 2

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 688a759 . . 040af7c 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 0 . 7 <nl> + * Update hadoop _ cql3 _ word _ count example ( CASSANDRA - 6793 ) <nl> * Fix handling of RejectedExecution in sync Thrift server ( CASSANDRA - 6788 ) <nl> * Log more information when exceeding tombstone _ warn _ threshold ( CASSANDRA - 6865 ) <nl> * Fix truncate to not abort due to unreachable fat clients ( CASSANDRA - 6864 ) <nl> diff - - git a / examples / hadoop _ cql3 _ word _ count / src / WordCount . java b / examples / hadoop _ cql3 _ word _ count / src / WordCount . java <nl> index c92f047 . . bc81a53 100644 <nl> - - - a / examples / hadoop _ cql3 _ word _ count / src / WordCount . java <nl> + + + b / examples / hadoop _ cql3 _ word _ count / src / WordCount . java <nl> @ @ - 45 , 21 + 45 , 16 @ @ import java . nio . charset . CharacterCodingException ; <nl> <nl> / * * <nl> * This counts the occurrences of words in ColumnFamily <nl> - * cql3 _ worldcount ( user _ id text , <nl> - * category _ id text , <nl> - * sub _ category _ id text , <nl> - * title text , <nl> - * body text , <nl> - * PRIMARY KEY ( user _ id , category _ id , sub _ category _ id ) ) <nl> + * cql3 _ worldcount ( id uuid , <nl> + * line text , <nl> + * PRIMARY KEY ( id ) ) <nl> * <nl> * For each word , we output the total number of occurrences across all body texts . <nl> * <nl> * When outputting to Cassandra , we write the word counts to column family <nl> - * output _ words ( row _ id1 text , <nl> - * row _ id2 text , <nl> - * word text , <nl> + * output _ words ( word text , <nl> * count _ num text , <nl> - * PRIMARY KEY ( ( row _ id1 , row _ id2 ) , word ) ) <nl> + * PRIMARY KEY ( word ) ) <nl> * as a { word , count } to columns : word , count _ num with a row key of " word sum " <nl> * / <nl> public class WordCount extends Configured implements Tool <nl> @ @ - 98 , 14 + 93 , 11 @ @ public class WordCount extends Configured implements Tool <nl> { <nl> for ( Entry < String , ByteBuffer > column : columns . entrySet ( ) ) <nl> { <nl> - if ( ! " body " . equalsIgnoreCase ( column . getKey ( ) ) ) <nl> + if ( ! " line " . equalsIgnoreCase ( column . getKey ( ) ) ) <nl> continue ; <nl> <nl> String value = ByteBufferUtil . string ( column . getValue ( ) ) ; <nl> <nl> - logger . debug ( " read { } : { } = { } from { } " , <nl> - new Object [ ] { toString ( keys ) , column . getKey ( ) , value , context . getInputSplit ( ) } ) ; <nl> - <nl> StringTokenizer itr = new StringTokenizer ( value ) ; <nl> while ( itr . hasMoreTokens ( ) ) <nl> { <nl> @ @ - 114 , 21 + 106 , 6 @ @ public class WordCount extends Configured implements Tool <nl> } <nl> } <nl> } <nl> - <nl> - private String toString ( Map < String , ByteBuffer > keys ) <nl> - { <nl> - String result = " " ; <nl> - try <nl> - { <nl> - for ( ByteBuffer key : keys . values ( ) ) <nl> - result = result + ByteBufferUtil . string ( key ) + " : " ; <nl> - } <nl> - catch ( CharacterCodingException e ) <nl> - { <nl> - logger . error ( " Failed to print keys " , e ) ; <nl> - } <nl> - return result ; <nl> - } <nl> } <nl> <nl> public static class ReducerToFilesystem extends Reducer < Text , IntWritable , Text , IntWritable > <nl> @ @ - 150 , 9 + 127 , 6 @ @ public class WordCount extends Configured implements Tool <nl> throws IOException , InterruptedException <nl> { <nl> keys = new LinkedHashMap < String , ByteBuffer > ( ) ; <nl> - String [ ] partitionKeys = context . getConfiguration ( ) . get ( PRIMARY _ KEY ) . split ( " , " ) ; <nl> - keys . put ( " row _ id1 " , ByteBufferUtil . bytes ( partitionKeys [ 0 ] ) ) ; <nl> - keys . put ( " row _ id2 " , ByteBufferUtil . bytes ( partitionKeys [ 1 ] ) ) ; <nl> } <nl> <nl> public void reduce ( Text word , Iterable < IntWritable > values , Context context ) throws IOException , InterruptedException <nl> @ @ - 160 , 13 + 134 , 13 @ @ public class WordCount extends Configured implements Tool <nl> int sum = 0 ; <nl> for ( IntWritable val : values ) <nl> sum + = val . get ( ) ; <nl> + keys . put ( " word " , ByteBufferUtil . bytes ( word . toString ( ) ) ) ; <nl> context . write ( keys , getBindVariables ( word , sum ) ) ; <nl> } <nl> <nl> private List < ByteBuffer > getBindVariables ( Text word , int sum ) <nl> { <nl> List < ByteBuffer > variables = new ArrayList < ByteBuffer > ( ) ; <nl> - keys . put ( " word " , ByteBufferUtil . bytes ( word . toString ( ) ) ) ; <nl> variables . add ( ByteBufferUtil . bytes ( String . valueOf ( sum ) ) ) ; <nl> return variables ; <nl> } <nl> @ @ - 223 , 9 + 197 , 7 @ @ public class WordCount extends Configured implements Tool <nl> ConfigHelper . setInputPartitioner ( job . getConfiguration ( ) , " Murmur3Partitioner " ) ; <nl> <nl> CqlConfigHelper . setInputCQLPageRowSize ( job . getConfiguration ( ) , " 3 " ) ; <nl> - / / this is the user defined filter clauses , you can comment it out if you want count all titles <nl> - CqlConfigHelper . setInputWhereClauses ( job . getConfiguration ( ) , " title = ' A ' " ) ; <nl> job . waitForCompletion ( true ) ; <nl> return 0 ; <nl> } <nl> - } <nl> \ No newline at end of file <nl> + } <nl> diff - - git a / examples / hadoop _ cql3 _ word _ count / src / WordCountCounters . java b / examples / hadoop _ cql3 _ word _ count / src / WordCountCounters . java <nl> index 8454b70 . . 542a473 100644 <nl> - - - a / examples / hadoop _ cql3 _ word _ count / src / WordCountCounters . java <nl> + + + b / examples / hadoop _ cql3 _ word _ count / src / WordCountCounters . java <nl> @ @ - 33 , 6 + 33 , 7 @ @ import org . apache . hadoop . io . Text ; <nl> import org . apache . hadoop . io . LongWritable ; <nl> import org . apache . hadoop . mapreduce . Job ; <nl> import org . apache . hadoop . mapreduce . Mapper ; <nl> + import org . apache . hadoop . mapreduce . Reducer ; <nl> import org . apache . hadoop . mapreduce . lib . output . FileOutputFormat ; <nl> import org . apache . hadoop . util . Tool ; <nl> import org . apache . hadoop . util . ToolRunner ; <nl> @ @ - 63 , 6 + 64 , 7 @ @ public class WordCountCounters extends Configured implements Tool <nl> public static class SumMapper extends Mapper < Map < String , ByteBuffer > , Map < String , ByteBuffer > , Text , LongWritable > <nl> { <nl> long sum = - 1 ; <nl> + <nl> public void map ( Map < String , ByteBuffer > key , Map < String , ByteBuffer > columns , Context context ) throws IOException , InterruptedException <nl> { <nl> if ( sum < 0 ) <nl> @ @ - 94 , 12 + 96 , 26 @ @ public class WordCountCounters extends Configured implements Tool <nl> } <nl> <nl> <nl> + public static class ReducerToFilesystem extends Reducer < Text , LongWritable , Text , LongWritable > <nl> + { <nl> + long sum = 0 ; <nl> + <nl> + public void reduce ( Text key , Iterable < LongWritable > values , Context context ) throws IOException , InterruptedException <nl> + { <nl> + for ( LongWritable val : values ) <nl> + sum + = val . get ( ) ; <nl> + context . write ( key , new LongWritable ( sum ) ) ; <nl> + } <nl> + } <nl> + <nl> public int run ( String [ ] args ) throws Exception <nl> { <nl> Job job = new Job ( getConf ( ) , " wordcountcounters " ) ; <nl> job . setJarByClass ( WordCountCounters . class ) ; <nl> job . setMapperClass ( SumMapper . class ) ; <nl> <nl> + job . setCombinerClass ( ReducerToFilesystem . class ) ; <nl> + job . setReducerClass ( ReducerToFilesystem . class ) ; <nl> job . setOutputKeyClass ( Text . class ) ; <nl> job . setOutputValueClass ( LongWritable . class ) ; <nl> FileOutputFormat . setOutputPath ( job , new Path ( OUTPUT _ PATH _ PREFIX ) ) ; <nl> diff - - git a / examples / hadoop _ cql3 _ word _ count / src / WordCountSetup . java b / examples / hadoop _ cql3 _ word _ count / src / WordCountSetup . java <nl> index 0acb8f7 . . ebf7485 100644 <nl> - - - a / examples / hadoop _ cql3 _ word _ count / src / WordCountSetup . java <nl> + + + b / examples / hadoop _ cql3 _ word _ count / src / WordCountSetup . java <nl> @ @ - 90 , 12 + 90 , 9 @ @ public class WordCountSetup <nl> TException <nl> { <nl> String query = " CREATE TABLE " + WordCount . KEYSPACE + " . " + WordCount . COLUMN _ FAMILY + <nl> - " ( user _ id text , " + <nl> - " category _ id text , " + <nl> - " sub _ category _ id text , " + <nl> - " title text , " + <nl> - " body text , " + <nl> - " PRIMARY KEY ( user _ id , category _ id , sub _ category _ id ) ) " ; <nl> + " ( id uuid , " + <nl> + " line text , " + <nl> + " PRIMARY KEY ( id ) ) " ; <nl> <nl> try <nl> { <nl> @ @ - 107 , 22 + 104 , 10 @ @ public class WordCountSetup <nl> logger . error ( " failed to create table " + WordCount . KEYSPACE + " . " + WordCount . COLUMN _ FAMILY , e ) ; <nl> } <nl> <nl> - query = " CREATE INDEX title on " + WordCount . COLUMN _ FAMILY + " ( title ) " ; <nl> - try <nl> - { <nl> - logger . info ( " set up index on title column " ) ; <nl> - client . execute _ cql3 _ query ( ByteBufferUtil . bytes ( query ) , Compression . NONE , ConsistencyLevel . ONE ) ; <nl> - } <nl> - catch ( InvalidRequestException e ) <nl> - { <nl> - logger . error ( " Failed to create index on title " , e ) ; <nl> - } <nl> - <nl> query = " CREATE TABLE " + WordCount . KEYSPACE + " . " + WordCount . OUTPUT _ COLUMN _ FAMILY + <nl> - " ( row _ id text , " + <nl> - " word text , " + <nl> + " ( word text , " + <nl> " count _ num text , " + <nl> - " PRIMARY KEY ( row _ id , word ) ) " ; <nl> + " PRIMARY KEY ( word ) ) " ; <nl> <nl> try <nl> { <nl> @ @ - 163 , 26 + 148 , 19 @ @ public class WordCountSetup <nl> TException <nl> { <nl> String query = " INSERT INTO " + WordCount . COLUMN _ FAMILY + <nl> - " ( user _ id , category _ id , sub _ category _ id , title , body ) " + <nl> - " values ( ? , ? , ? , ? , ? ) " ; <nl> + " ( id , line ) " + <nl> + " values ( ? , ? ) " ; <nl> CqlPreparedResult result = client . prepare _ cql3 _ query ( ByteBufferUtil . bytes ( query ) , Compression . NONE ) ; <nl> <nl> - String [ ] title = titleData ( ) ; <nl> String [ ] body = bodyData ( ) ; <nl> - for ( int i = 1 ; i < 5 ; i + + ) <nl> + for ( int i = 0 ; i < 5 ; i + + ) <nl> { <nl> - for ( int j = 1 ; j < 444 ; j + + ) <nl> + for ( int j = 1 ; j < = 200 ; j + + ) <nl> { <nl> - for ( int k = 1 ; k < 4 ; k + + ) <nl> - { <nl> List < ByteBuffer > values = new ArrayList < ByteBuffer > ( ) ; <nl> - values . add ( ByteBufferUtil . bytes ( String . valueOf ( j ) ) ) ; <nl> - values . add ( ByteBufferUtil . bytes ( String . valueOf ( i ) ) ) ; <nl> - values . add ( ByteBufferUtil . bytes ( String . valueOf ( k ) ) ) ; <nl> - values . add ( ByteBufferUtil . bytes ( title [ i ] ) ) ; <nl> + values . add ( ByteBufferUtil . bytes ( UUID . randomUUID ( ) ) ) ; <nl> values . add ( ByteBufferUtil . bytes ( body [ i ] ) ) ; <nl> client . execute _ prepared _ cql3 _ query ( result . itemId , values , ConsistencyLevel . ONE ) ; <nl> - } <nl> } <nl> } <nl> } <nl> @ @ - 190 , 7 + 168 , 6 @ @ public class WordCountSetup <nl> private static String [ ] bodyData ( ) <nl> { / / Public domain context , source http : / / en . wikisource . org / wiki / If % E2 % 80 % 94 <nl> return new String [ ] { <nl> - " " , <nl> " If you can keep your head when all about you " , <nl> " Are losing theirs and blaming it on you " , <nl> " If you can trust yourself when all men doubt you , " , <nl> @ @ - 198 , 16 + 175 , 4 @ @ public class WordCountSetup <nl> " If you can wait and not be tired by waiting , " <nl> } ; <nl> } <nl> - <nl> - private static String [ ] titleData ( ) <nl> - { / / Public domain context , source http : / / en . wikisource . org / wiki / If % E2 % 80 % 94 <nl> - return new String [ ] { <nl> - " " , <nl> - " A " , <nl> - " B " , <nl> - " C " , <nl> - " D " , <nl> - " E " <nl> - } ; <nl> - } <nl> }
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index b935425 . . 7f5a487 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 1 . 2 - rc1 <nl> + * fix cqlsh rendering of blob fields ( CASSANDRA - 4970 ) <nl> * fix cqlsh DESCRIBE command ( CASSANDRA - 4913 ) <nl> * save truncation position in system table ( CASSANDRA - 4906 ) <nl> * Move CompressionMetadata off - heap ( CASSANDRA - 4937 ) <nl> diff - - git a / pylib / cqlshlib / formatting . py b / pylib / cqlshlib / formatting . py <nl> index d15c083 . . bab3506 100644 <nl> - - - a / pylib / cqlshlib / formatting . py <nl> + + + b / pylib / cqlshlib / formatting . py <nl> @ @ - 88 , 8 + 88 , 8 @ @ def formatter _ for ( typname ) : <nl> return f <nl> return registrator <nl> <nl> - @ formatter _ for ( ' bytes ' ) <nl> - def format _ value _ bytes ( val , colormap , * * _ ) : <nl> + @ formatter _ for ( ' blob ' ) <nl> + def format _ value _ blob ( val , colormap , * * _ ) : <nl> bval = ' ' . join ( ' % 02x ' % ord ( c ) for c in val ) <nl> return colorme ( bval , colormap , ' hex ' ) <nl>

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 688a759 . . 040af7c 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 0 . 7 
 + * Update hadoop _ cql3 _ word _ count example ( CASSANDRA - 6793 ) 
 * Fix handling of RejectedExecution in sync Thrift server ( CASSANDRA - 6788 ) 
 * Log more information when exceeding tombstone _ warn _ threshold ( CASSANDRA - 6865 ) 
 * Fix truncate to not abort due to unreachable fat clients ( CASSANDRA - 6864 ) 
 diff - - git a / examples / hadoop _ cql3 _ word _ count / src / WordCount . java b / examples / hadoop _ cql3 _ word _ count / src / WordCount . java 
 index c92f047 . . bc81a53 100644 
 - - - a / examples / hadoop _ cql3 _ word _ count / src / WordCount . java 
 + + + b / examples / hadoop _ cql3 _ word _ count / src / WordCount . java 
 @ @ - 45 , 21 + 45 , 16 @ @ import java . nio . charset . CharacterCodingException ; 
 
 / * * 
 * This counts the occurrences of words in ColumnFamily 
 - * cql3 _ worldcount ( user _ id text , 
 - * category _ id text , 
 - * sub _ category _ id text , 
 - * title text , 
 - * body text , 
 - * PRIMARY KEY ( user _ id , category _ id , sub _ category _ id ) ) 
 + * cql3 _ worldcount ( id uuid , 
 + * line text , 
 + * PRIMARY KEY ( id ) ) 
 * 
 * For each word , we output the total number of occurrences across all body texts . 
 * 
 * When outputting to Cassandra , we write the word counts to column family 
 - * output _ words ( row _ id1 text , 
 - * row _ id2 text , 
 - * word text , 
 + * output _ words ( word text , 
 * count _ num text , 
 - * PRIMARY KEY ( ( row _ id1 , row _ id2 ) , word ) ) 
 + * PRIMARY KEY ( word ) ) 
 * as a { word , count } to columns : word , count _ num with a row key of " word sum " 
 * / 
 public class WordCount extends Configured implements Tool 
 @ @ - 98 , 14 + 93 , 11 @ @ public class WordCount extends Configured implements Tool 
 { 
 for ( Entry < String , ByteBuffer > column : columns . entrySet ( ) ) 
 { 
 - if ( ! " body " . equalsIgnoreCase ( column . getKey ( ) ) ) 
 + if ( ! " line " . equalsIgnoreCase ( column . getKey ( ) ) ) 
 continue ; 
 
 String value = ByteBufferUtil . string ( column . getValue ( ) ) ; 
 
 - logger . debug ( " read { } : { } = { } from { } " , 
 - new Object [ ] { toString ( keys ) , column . getKey ( ) , value , context . getInputSplit ( ) } ) ; 
 - 
 StringTokenizer itr = new StringTokenizer ( value ) ; 
 while ( itr . hasMoreTokens ( ) ) 
 { 
 @ @ - 114 , 21 + 106 , 6 @ @ public class WordCount extends Configured implements Tool 
 } 
 } 
 } 
 - 
 - private String toString ( Map < String , ByteBuffer > keys ) 
 - { 
 - String result = " " ; 
 - try 
 - { 
 - for ( ByteBuffer key : keys . values ( ) ) 
 - result = result + ByteBufferUtil . string ( key ) + " : " ; 
 - } 
 - catch ( CharacterCodingException e ) 
 - { 
 - logger . error ( " Failed to print keys " , e ) ; 
 - } 
 - return result ; 
 - } 
 } 
 
 public static class ReducerToFilesystem extends Reducer < Text , IntWritable , Text , IntWritable > 
 @ @ - 150 , 9 + 127 , 6 @ @ public class WordCount extends Configured implements Tool 
 throws IOException , InterruptedException 
 { 
 keys = new LinkedHashMap < String , ByteBuffer > ( ) ; 
 - String [ ] partitionKeys = context . getConfiguration ( ) . get ( PRIMARY _ KEY ) . split ( " , " ) ; 
 - keys . put ( " row _ id1 " , ByteBufferUtil . bytes ( partitionKeys [ 0 ] ) ) ; 
 - keys . put ( " row _ id2 " , ByteBufferUtil . bytes ( partitionKeys [ 1 ] ) ) ; 
 } 
 
 public void reduce ( Text word , Iterable < IntWritable > values , Context context ) throws IOException , InterruptedException 
 @ @ - 160 , 13 + 134 , 13 @ @ public class WordCount extends Configured implements Tool 
 int sum = 0 ; 
 for ( IntWritable val : values ) 
 sum + = val . get ( ) ; 
 + keys . put ( " word " , ByteBufferUtil . bytes ( word . toString ( ) ) ) ; 
 context . write ( keys , getBindVariables ( word , sum ) ) ; 
 } 
 
 private List < ByteBuffer > getBindVariables ( Text word , int sum ) 
 { 
 List < ByteBuffer > variables = new ArrayList < ByteBuffer > ( ) ; 
 - keys . put ( " word " , ByteBufferUtil . bytes ( word . toString ( ) ) ) ; 
 variables . add ( ByteBufferUtil . bytes ( String . valueOf ( sum ) ) ) ; 
 return variables ; 
 } 
 @ @ - 223 , 9 + 197 , 7 @ @ public class WordCount extends Configured implements Tool 
 ConfigHelper . setInputPartitioner ( job . getConfiguration ( ) , " Murmur3Partitioner " ) ; 
 
 CqlConfigHelper . setInputCQLPageRowSize ( job . getConfiguration ( ) , " 3 " ) ; 
 - / / this is the user defined filter clauses , you can comment it out if you want count all titles 
 - CqlConfigHelper . setInputWhereClauses ( job . getConfiguration ( ) , " title = ' A ' " ) ; 
 job . waitForCompletion ( true ) ; 
 return 0 ; 
 } 
 - } 
 \ No newline at end of file 
 + } 
 diff - - git a / examples / hadoop _ cql3 _ word _ count / src / WordCountCounters . java b / examples / hadoop _ cql3 _ word _ count / src / WordCountCounters . java 
 index 8454b70 . . 542a473 100644 
 - - - a / examples / hadoop _ cql3 _ word _ count / src / WordCountCounters . java 
 + + + b / examples / hadoop _ cql3 _ word _ count / src / WordCountCounters . java 
 @ @ - 33 , 6 + 33 , 7 @ @ import org . apache . hadoop . io . Text ; 
 import org . apache . hadoop . io . LongWritable ; 
 import org . apache . hadoop . mapreduce . Job ; 
 import org . apache . hadoop . mapreduce . Mapper ; 
 + import org . apache . hadoop . mapreduce . Reducer ; 
 import org . apache . hadoop . mapreduce . lib . output . FileOutputFormat ; 
 import org . apache . hadoop . util . Tool ; 
 import org . apache . hadoop . util . ToolRunner ; 
 @ @ - 63 , 6 + 64 , 7 @ @ public class WordCountCounters extends Configured implements Tool 
 public static class SumMapper extends Mapper < Map < String , ByteBuffer > , Map < String , ByteBuffer > , Text , LongWritable > 
 { 
 long sum = - 1 ; 
 + 
 public void map ( Map < String , ByteBuffer > key , Map < String , ByteBuffer > columns , Context context ) throws IOException , InterruptedException 
 { 
 if ( sum < 0 ) 
 @ @ - 94 , 12 + 96 , 26 @ @ public class WordCountCounters extends Configured implements Tool 
 } 
 
 
 + public static class ReducerToFilesystem extends Reducer < Text , LongWritable , Text , LongWritable > 
 + { 
 + long sum = 0 ; 
 + 
 + public void reduce ( Text key , Iterable < LongWritable > values , Context context ) throws IOException , InterruptedException 
 + { 
 + for ( LongWritable val : values ) 
 + sum + = val . get ( ) ; 
 + context . write ( key , new LongWritable ( sum ) ) ; 
 + } 
 + } 
 + 
 public int run ( String [ ] args ) throws Exception 
 { 
 Job job = new Job ( getConf ( ) , " wordcountcounters " ) ; 
 job . setJarByClass ( WordCountCounters . class ) ; 
 job . setMapperClass ( SumMapper . class ) ; 
 
 + job . setCombinerClass ( ReducerToFilesystem . class ) ; 
 + job . setReducerClass ( ReducerToFilesystem . class ) ; 
 job . setOutputKeyClass ( Text . class ) ; 
 job . setOutputValueClass ( LongWritable . class ) ; 
 FileOutputFormat . setOutputPath ( job , new Path ( OUTPUT _ PATH _ PREFIX ) ) ; 
 diff - - git a / examples / hadoop _ cql3 _ word _ count / src / WordCountSetup . java b / examples / hadoop _ cql3 _ word _ count / src / WordCountSetup . java 
 index 0acb8f7 . . ebf7485 100644 
 - - - a / examples / hadoop _ cql3 _ word _ count / src / WordCountSetup . java 
 + + + b / examples / hadoop _ cql3 _ word _ count / src / WordCountSetup . java 
 @ @ - 90 , 12 + 90 , 9 @ @ public class WordCountSetup 
 TException 
 { 
 String query = " CREATE TABLE " + WordCount . KEYSPACE + " . " + WordCount . COLUMN _ FAMILY + 
 - " ( user _ id text , " + 
 - " category _ id text , " + 
 - " sub _ category _ id text , " + 
 - " title text , " + 
 - " body text , " + 
 - " PRIMARY KEY ( user _ id , category _ id , sub _ category _ id ) ) " ; 
 + " ( id uuid , " + 
 + " line text , " + 
 + " PRIMARY KEY ( id ) ) " ; 
 
 try 
 { 
 @ @ - 107 , 22 + 104 , 10 @ @ public class WordCountSetup 
 logger . error ( " failed to create table " + WordCount . KEYSPACE + " . " + WordCount . COLUMN _ FAMILY , e ) ; 
 } 
 
 - query = " CREATE INDEX title on " + WordCount . COLUMN _ FAMILY + " ( title ) " ; 
 - try 
 - { 
 - logger . info ( " set up index on title column " ) ; 
 - client . execute _ cql3 _ query ( ByteBufferUtil . bytes ( query ) , Compression . NONE , ConsistencyLevel . ONE ) ; 
 - } 
 - catch ( InvalidRequestException e ) 
 - { 
 - logger . error ( " Failed to create index on title " , e ) ; 
 - } 
 - 
 query = " CREATE TABLE " + WordCount . KEYSPACE + " . " + WordCount . OUTPUT _ COLUMN _ FAMILY + 
 - " ( row _ id text , " + 
 - " word text , " + 
 + " ( word text , " + 
 " count _ num text , " + 
 - " PRIMARY KEY ( row _ id , word ) ) " ; 
 + " PRIMARY KEY ( word ) ) " ; 
 
 try 
 { 
 @ @ - 163 , 26 + 148 , 19 @ @ public class WordCountSetup 
 TException 
 { 
 String query = " INSERT INTO " + WordCount . COLUMN _ FAMILY + 
 - " ( user _ id , category _ id , sub _ category _ id , title , body ) " + 
 - " values ( ? , ? , ? , ? , ? ) " ; 
 + " ( id , line ) " + 
 + " values ( ? , ? ) " ; 
 CqlPreparedResult result = client . prepare _ cql3 _ query ( ByteBufferUtil . bytes ( query ) , Compression . NONE ) ; 
 
 - String [ ] title = titleData ( ) ; 
 String [ ] body = bodyData ( ) ; 
 - for ( int i = 1 ; i < 5 ; i + + ) 
 + for ( int i = 0 ; i < 5 ; i + + ) 
 { 
 - for ( int j = 1 ; j < 444 ; j + + ) 
 + for ( int j = 1 ; j < = 200 ; j + + ) 
 { 
 - for ( int k = 1 ; k < 4 ; k + + ) 
 - { 
 List < ByteBuffer > values = new ArrayList < ByteBuffer > ( ) ; 
 - values . add ( ByteBufferUtil . bytes ( String . valueOf ( j ) ) ) ; 
 - values . add ( ByteBufferUtil . bytes ( String . valueOf ( i ) ) ) ; 
 - values . add ( ByteBufferUtil . bytes ( String . valueOf ( k ) ) ) ; 
 - values . add ( ByteBufferUtil . bytes ( title [ i ] ) ) ; 
 + values . add ( ByteBufferUtil . bytes ( UUID . randomUUID ( ) ) ) ; 
 values . add ( ByteBufferUtil . bytes ( body [ i ] ) ) ; 
 client . execute _ prepared _ cql3 _ query ( result . itemId , values , ConsistencyLevel . ONE ) ; 
 - } 
 } 
 } 
 } 
 @ @ - 190 , 7 + 168 , 6 @ @ public class WordCountSetup 
 private static String [ ] bodyData ( ) 
 { / / Public domain context , source http : / / en . wikisource . org / wiki / If % E2 % 80 % 94 
 return new String [ ] { 
 - " " , 
 " If you can keep your head when all about you " , 
 " Are losing theirs and blaming it on you " , 
 " If you can trust yourself when all men doubt you , " , 
 @ @ - 198 , 16 + 175 , 4 @ @ public class WordCountSetup 
 " If you can wait and not be tired by waiting , " 
 } ; 
 } 
 - 
 - private static String [ ] titleData ( ) 
 - { / / Public domain context , source http : / / en . wikisource . org / wiki / If % E2 % 80 % 94 
 - return new String [ ] { 
 - " " , 
 - " A " , 
 - " B " , 
 - " C " , 
 - " D " , 
 - " E " 
 - } ; 
 - } 
 }

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index b935425 . . 7f5a487 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 1 . 2 - rc1 
 + * fix cqlsh rendering of blob fields ( CASSANDRA - 4970 ) 
 * fix cqlsh DESCRIBE command ( CASSANDRA - 4913 ) 
 * save truncation position in system table ( CASSANDRA - 4906 ) 
 * Move CompressionMetadata off - heap ( CASSANDRA - 4937 ) 
 diff - - git a / pylib / cqlshlib / formatting . py b / pylib / cqlshlib / formatting . py 
 index d15c083 . . bab3506 100644 
 - - - a / pylib / cqlshlib / formatting . py 
 + + + b / pylib / cqlshlib / formatting . py 
 @ @ - 88 , 8 + 88 , 8 @ @ def formatter _ for ( typname ) : 
 return f 
 return registrator 
 
 - @ formatter _ for ( ' bytes ' ) 
 - def format _ value _ bytes ( val , colormap , * * _ ) : 
 + @ formatter _ for ( ' blob ' ) 
 + def format _ value _ blob ( val , colormap , * * _ ) : 
 bval = ' ' . join ( ' % 02x ' % ord ( c ) for c in val ) 
 return colorme ( bval , colormap , ' hex ' ) 

