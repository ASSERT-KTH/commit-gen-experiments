BLEU SCORE: 0.026279617104084448

TEST MSG: Severe concurrency issues in STCS , DTCS , TWCS , TMD . Topology , TypeParser
GENERATED MSG: merge from 0 . 5

TEST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index 3482909 . . 355d710 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 2138 , 7 + 2138 , 6 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> assert data . getCompacting ( ) . isEmpty ( ) : data . getCompacting ( ) ; <nl> Iterable < SSTableReader > sstables = getLiveSSTables ( ) ; <nl> sstables = AbstractCompactionStrategy . filterSuspectSSTables ( sstables ) ; <nl> - sstables = ImmutableList . copyOf ( sstables ) ; <nl> LifecycleTransaction modifier = data . tryModify ( sstables , operationType ) ; <nl> assert modifier ! = null : " something marked things compacting while compactions are disabled " ; <nl> return modifier ; <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java <nl> index 9f07691 . . 2348d19 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java <nl> @ @ - 252 , 15 + 252 , 15 @ @ public abstract class AbstractCompactionStrategy <nl> * @ param originalCandidates The collection to check for blacklisted SSTables <nl> * @ return list of the SSTables with blacklisted ones filtered out <nl> * / <nl> - public static Iterable < SSTableReader > filterSuspectSSTables ( Iterable < SSTableReader > originalCandidates ) <nl> + public static List < SSTableReader > filterSuspectSSTables ( Iterable < SSTableReader > originalCandidates ) <nl> { <nl> - return Iterables . filter ( originalCandidates , new Predicate < SSTableReader > ( ) <nl> + List < SSTableReader > filtered = new ArrayList < > ( ) ; <nl> + for ( SSTableReader sstable : originalCandidates ) <nl> { <nl> - public boolean apply ( SSTableReader sstable ) <nl> - { <nl> - return ! sstable . isMarkedSuspect ( ) ; <nl> - } <nl> - } ) ; <nl> + if ( ! sstable . isMarkedSuspect ( ) ) <nl> + filtered . add ( sstable ) ; <nl> + } <nl> + return filtered ; <nl> } <nl> <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / DateTieredCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / DateTieredCompactionStrategy . java <nl> index 3e6ae61 . . 7c38fa8 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / DateTieredCompactionStrategy . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / DateTieredCompactionStrategy . java <nl> @ @ - 87 , 7 + 87 , 7 @ @ public class DateTieredCompactionStrategy extends AbstractCompactionStrategy <nl> * @ param gcBefore <nl> * @ return <nl> * / <nl> - private List < SSTableReader > getNextBackgroundSSTables ( final int gcBefore ) <nl> + private synchronized List < SSTableReader > getNextBackgroundSSTables ( final int gcBefore ) <nl> { <nl> if ( Iterables . isEmpty ( cfs . getSSTables ( SSTableSet . LIVE ) ) ) <nl> return Collections . emptyList ( ) ; <nl> @ @ - 193 , 11 + 193 , 6 @ @ public class DateTieredCompactionStrategy extends AbstractCompactionStrategy <nl> } ) ; <nl> } <nl> <nl> - / * * <nl> - * <nl> - * @ param sstables <nl> - * @ return <nl> - * / <nl> public static List < Pair < SSTableReader , Long > > createSSTableAndMinTimestampPairs ( Iterable < SSTableReader > sstables ) <nl> { <nl> List < Pair < SSTableReader , Long > > sstableMinTimestampPairs = Lists . newArrayListWithCapacity ( Iterables . size ( sstables ) ) ; <nl> @ @ - 205 , 14 + 200 , 15 @ @ public class DateTieredCompactionStrategy extends AbstractCompactionStrategy <nl> sstableMinTimestampPairs . add ( Pair . create ( sstable , sstable . getMinTimestamp ( ) ) ) ; <nl> return sstableMinTimestampPairs ; <nl> } <nl> + <nl> @ Override <nl> - public void addSSTable ( SSTableReader sstable ) <nl> + public synchronized void addSSTable ( SSTableReader sstable ) <nl> { <nl> sstables . add ( sstable ) ; <nl> } <nl> <nl> @ Override <nl> - public void removeSSTable ( SSTableReader sstable ) <nl> + public synchronized void removeSSTable ( SSTableReader sstable ) <nl> { <nl> sstables . remove ( sstable ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java <nl> index f8a8240 . . 80f5e8c 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java <nl> @ @ - 74 , 7 + 74 , 7 @ @ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy <nl> this . sizeTieredOptions = new SizeTieredCompactionStrategyOptions ( options ) ; <nl> } <nl> <nl> - private List < SSTableReader > getNextBackgroundSSTables ( final int gcBefore ) <nl> + private synchronized List < SSTableReader > getNextBackgroundSSTables ( final int gcBefore ) <nl> { <nl> / / make local copies so they can ' t be changed out from under us mid - method <nl> int minThreshold = cfs . getMinimumCompactionThreshold ( ) ; <nl> @ @ - 190 , 7 + 190 , 7 @ @ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy <nl> } <nl> <nl> @ SuppressWarnings ( " resource " ) <nl> - public Collection < AbstractCompactionTask > getMaximalTask ( final int gcBefore , boolean splitOutput ) <nl> + public synchronized Collection < AbstractCompactionTask > getMaximalTask ( final int gcBefore , boolean splitOutput ) <nl> { <nl> Iterable < SSTableReader > filteredSSTables = filterSuspectSSTables ( sstables ) ; <nl> if ( Iterables . isEmpty ( filteredSSTables ) ) <nl> @ @ - 316 , 13 + 316 , 13 @ @ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy <nl> } <nl> <nl> @ Override <nl> - public void addSSTable ( SSTableReader added ) <nl> + public synchronized void addSSTable ( SSTableReader added ) <nl> { <nl> sstables . add ( added ) ; <nl> } <nl> <nl> @ Override <nl> - public void removeSSTable ( SSTableReader sstable ) <nl> + public synchronized void removeSSTable ( SSTableReader sstable ) <nl> { <nl> sstables . remove ( sstable ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / compaction / TimeWindowCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / TimeWindowCompactionStrategy . java <nl> index 8d26d0c . . c44d3aa 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / TimeWindowCompactionStrategy . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / TimeWindowCompactionStrategy . java <nl> @ @ - 169 , 13 + 169 , 13 @ @ public class TimeWindowCompactionStrategy extends AbstractCompactionStrategy <nl> } <nl> <nl> @ Override <nl> - public void addSSTable ( SSTableReader sstable ) <nl> + public synchronized void addSSTable ( SSTableReader sstable ) <nl> { <nl> sstables . add ( sstable ) ; <nl> } <nl> <nl> @ Override <nl> - public void removeSSTable ( SSTableReader sstable ) <nl> + public synchronized void removeSSTable ( SSTableReader sstable ) <nl> { <nl> sstables . remove ( sstable ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / marshal / TypeParser . java b / src / java / org / apache / cassandra / db / marshal / TypeParser . java <nl> index 35d15ab . . 590eea3 100644 <nl> - - - a / src / java / org / apache / cassandra / db / marshal / TypeParser . java <nl> + + + b / src / java / org / apache / cassandra / db / marshal / TypeParser . java <nl> @ @ - 23 , 6 + 23 , 9 @ @ import java . lang . reflect . Method ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> <nl> + import com . google . common . base . Verify ; <nl> + import com . google . common . collect . ImmutableMap ; <nl> + <nl> import org . apache . cassandra . exceptions . * ; <nl> import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . apache . cassandra . utils . FBUtilities ; <nl> @ @ - 37 , 7 + 40 , 7 @ @ public class TypeParser <nl> private int idx ; <nl> <nl> / / A cache of parsed string , specially useful for DynamicCompositeType <nl> - private static final Map < String , AbstractType < ? > > cache = new HashMap < > ( ) ; <nl> + private static volatile ImmutableMap < String , AbstractType < ? > > cache = ImmutableMap . of ( ) ; <nl> <nl> public static final TypeParser EMPTY _ PARSER = new TypeParser ( " " , 0 ) ; <nl> <nl> @ @ - 60 , 6 + 63 , 7 @ @ public class TypeParser <nl> if ( str = = null ) <nl> return BytesType . instance ; <nl> <nl> + / / A single volatile read of ' cache ' should not hurt . <nl> AbstractType < ? > type = cache . get ( str ) ; <nl> <nl> if ( type ! = null ) <nl> @ @ - 83 , 9 + 87 , 27 @ @ public class TypeParser <nl> else <nl> type = getAbstractType ( name ) ; <nl> <nl> - / / We don ' t really care about concurrency here . Worst case scenario , we do some parsing unnecessarily <nl> - cache . put ( str , type ) ; <nl> - return type ; <nl> + Verify . verify ( type ! = null , " Parsing % s yielded null , which is a bug " , str ) ; <nl> + <nl> + / / Prevent concurrent modification to the map acting as the cache for TypeParser at the expense of <nl> + / / more allocation when the cache needs to be updated , since updates to the cache are rare compared <nl> + / / to the amount of reads . <nl> + / / <nl> + / / Copy the existing cache into a new map and add the parsed AbstractType instance and replace <nl> + / / the cache , if the type is not already in the cache . <nl> + / / <nl> + / / The cache - update is done in a short synchronized block to prevent duplicate instances of AbstractType <nl> + / / for the same string representation . <nl> + synchronized ( TypeParser . class ) <nl> + { <nl> + if ( ! cache . containsKey ( str ) ) <nl> + { <nl> + ImmutableMap . Builder < String , AbstractType < ? > > builder = ImmutableMap . builder ( ) ; <nl> + builder . putAll ( cache ) . put ( str , type ) ; <nl> + cache = builder . build ( ) ; <nl> + } <nl> + return type ; <nl> + } <nl> } <nl> <nl> public static AbstractType < ? > parse ( CharSequence compareWith ) throws SyntaxException , ConfigurationException <nl> diff - - git a / src / java / org / apache / cassandra / locator / NetworkTopologyStrategy . java b / src / java / org / apache / cassandra / locator / NetworkTopologyStrategy . java <nl> index 7c8d95e . . 82183bb 100644 <nl> - - - a / src / java / org / apache / cassandra / locator / NetworkTopologyStrategy . java <nl> + + + b / src / java / org / apache / cassandra / locator / NetworkTopologyStrategy . java <nl> @ @ - 29 , 6 + 29 , 7 @ @ import org . apache . cassandra . dht . Token ; <nl> import org . apache . cassandra . locator . TokenMetadata . Topology ; <nl> import org . apache . cassandra . utils . FBUtilities ; <nl> <nl> + import com . google . common . collect . ImmutableMultimap ; <nl> import com . google . common . collect . Multimap ; <nl> <nl> / * * <nl> @ @ - 91 , 7 + 92 , 7 @ @ public class NetworkTopologyStrategy extends AbstractReplicationStrategy <nl> / / all endpoints in each DC , so we can check when we have exhausted all the members of a DC <nl> Multimap < String , InetAddress > allEndpoints = topology . getDatacenterEndpoints ( ) ; <nl> / / all racks in a DC so we can check when we have exhausted all racks in a DC <nl> - Map < String , Multimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; <nl> + Map < String , ImmutableMultimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; <nl> assert ! allEndpoints . isEmpty ( ) & & ! racks . isEmpty ( ) : " not aware of any cluster members " ; <nl> <nl> / / tracks the racks we have already placed replicas in <nl> diff - - git a / src / java / org / apache / cassandra / locator / TokenMetadata . java b / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> index b44a1a1 . . 3978eeb 100644 <nl> - - - a / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> + + + b / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> @ @ - 95 , 9 + 95 , 10 @ @ public class TokenMetadata <nl> <nl> / * Use this lock for manipulating the token map * / <nl> private final ReadWriteLock lock = new ReentrantReadWriteLock ( true ) ; <nl> - private volatile ArrayList < Token > sortedTokens ; <nl> + private volatile ArrayList < Token > sortedTokens ; / / safe to be read without a lock , as it ' s never mutated <nl> + <nl> + private volatile Topology topology ; <nl> <nl> - private final Topology topology ; <nl> public final IPartitioner partitioner ; <nl> <nl> private static final Comparator < InetAddress > inetaddressCmp = new Comparator < InetAddress > ( ) <nl> @ @ - 115 , 7 + 116 , 7 @ @ public class TokenMetadata <nl> { <nl> this ( SortedBiMultiValMap . < Token , InetAddress > create ( null , inetaddressCmp ) , <nl> HashBiMap . < InetAddress , UUID > create ( ) , <nl> - new Topology ( ) , <nl> + Topology . empty ( ) , <nl> DatabaseDescriptor . getPartitioner ( ) ) ; <nl> } <nl> <nl> @ @ - 193 , 6 + 194 , 7 @ @ public class TokenMetadata <nl> try <nl> { <nl> boolean shouldSortTokens = false ; <nl> + Topology . Builder topologyBuilder = topology . unbuild ( ) ; <nl> for ( InetAddress endpoint : endpointTokens . keySet ( ) ) <nl> { <nl> Collection < Token > tokens = endpointTokens . get ( endpoint ) ; <nl> @ @ - 201 , 7 + 203 , 7 @ @ public class TokenMetadata <nl> <nl> bootstrapTokens . removeValue ( endpoint ) ; <nl> tokenToEndpointMap . removeValue ( endpoint ) ; <nl> - topology . addEndpoint ( endpoint ) ; <nl> + topologyBuilder . addEndpoint ( endpoint ) ; <nl> leavingEndpoints . remove ( endpoint ) ; <nl> replacementToOriginal . remove ( endpoint ) ; <nl> removeFromMoving ( endpoint ) ; / / also removing this endpoint from moving <nl> @ @ - 217 , 6 + 219 , 7 @ @ public class TokenMetadata <nl> } <nl> } <nl> } <nl> + topology = topologyBuilder . build ( ) ; <nl> <nl> if ( shouldSortTokens ) <nl> sortedTokens = sortTokens ( ) ; <nl> @ @ - 381 , 12 + 384 , 28 @ @ public class TokenMetadata <nl> <nl> public Optional < InetAddress > getReplacementNode ( InetAddress endpoint ) <nl> { <nl> - return Optional . ofNullable ( replacementToOriginal . inverse ( ) . get ( endpoint ) ) ; <nl> + lock . readLock ( ) . lock ( ) ; <nl> + try <nl> + { <nl> + return Optional . ofNullable ( replacementToOriginal . inverse ( ) . get ( endpoint ) ) ; <nl> + } <nl> + finally <nl> + { <nl> + lock . readLock ( ) . unlock ( ) ; <nl> + } <nl> } <nl> <nl> public Optional < InetAddress > getReplacingNode ( InetAddress endpoint ) <nl> { <nl> - return Optional . ofNullable ( ( replacementToOriginal . get ( endpoint ) ) ) ; <nl> + lock . readLock ( ) . lock ( ) ; <nl> + try <nl> + { <nl> + return Optional . ofNullable ( ( replacementToOriginal . get ( endpoint ) ) ) ; <nl> + } <nl> + finally <nl> + { <nl> + lock . readLock ( ) . unlock ( ) ; <nl> + } <nl> } <nl> <nl> public void removeBootstrapTokens ( Collection < Token > tokens ) <nl> @ @ - 430 , 7 + 449 , 6 @ @ public class TokenMetadata <nl> assert endpoint ! = null ; <nl> <nl> lock . writeLock ( ) . lock ( ) ; <nl> - <nl> try <nl> { <nl> movingEndpoints . add ( Pair . create ( token , endpoint ) ) ; <nl> @ @ - 450 , 7 + 468 , 7 @ @ public class TokenMetadata <nl> { <nl> bootstrapTokens . removeValue ( endpoint ) ; <nl> tokenToEndpointMap . removeValue ( endpoint ) ; <nl> - topology . removeEndpoint ( endpoint ) ; <nl> + topology = topology . unbuild ( ) . removeEndpoint ( endpoint ) . build ( ) ; <nl> leavingEndpoints . remove ( endpoint ) ; <nl> if ( replacementToOriginal . remove ( endpoint ) ! = null ) <nl> { <nl> @ @ - 469 , 7 + 487 , 7 @ @ public class TokenMetadata <nl> / * * <nl> * This is called when the snitch properties for this endpoint are updated , see CASSANDRA - 10238 . <nl> * / <nl> - public void updateTopology ( InetAddress endpoint ) <nl> + public Topology updateTopology ( InetAddress endpoint ) <nl> { <nl> assert endpoint ! = null ; <nl> <nl> @ @ - 477 , 8 + 495 , 9 @ @ public class TokenMetadata <nl> try <nl> { <nl> logger . info ( " Updating topology for { } " , endpoint ) ; <nl> - topology . updateEndpoint ( endpoint ) ; <nl> + topology = topology . unbuild ( ) . updateEndpoint ( endpoint ) . build ( ) ; <nl> invalidateCachedRings ( ) ; <nl> + return topology ; <nl> } <nl> finally <nl> { <nl> @ @ - 490 , 14 + 509 , 15 @ @ public class TokenMetadata <nl> * This is called when the snitch properties for many endpoints are updated , it will update <nl> * the topology mappings of any endpoints whose snitch has changed , see CASSANDRA - 10238 . <nl> * / <nl> - public void updateTopology ( ) <nl> + public Topology updateTopology ( ) <nl> { <nl> lock . writeLock ( ) . lock ( ) ; <nl> try <nl> { <nl> logger . info ( " Updating topology for all endpoints that have changed " ) ; <nl> - topology . updateEndpoints ( ) ; <nl> + topology = topology . unbuild ( ) . updateEndpoints ( ) . build ( ) ; <nl> invalidateCachedRings ( ) ; <nl> + return topology ; <nl> } <nl> finally <nl> { <nl> @ @ - 590 , 7 + 610 , 6 @ @ public class TokenMetadata <nl> assert endpoint ! = null ; <nl> <nl> lock . readLock ( ) . lock ( ) ; <nl> - <nl> try <nl> { <nl> for ( Pair < Token , InetAddress > pair : movingEndpoints ) <nl> @ @ - 620 , 7 + 639 , 7 @ @ public class TokenMetadata <nl> { <nl> return new TokenMetadata ( SortedBiMultiValMap . create ( tokenToEndpointMap , null , inetaddressCmp ) , <nl> HashBiMap . create ( endpointToHostIdMap ) , <nl> - new Topology ( topology ) , <nl> + topology , <nl> partitioner ) ; <nl> } <nl> finally <nl> @ @ - 690 , 7 + 709 , 6 @ @ public class TokenMetadata <nl> public TokenMetadata cloneAfterAllSettled ( ) <nl> { <nl> lock . readLock ( ) . lock ( ) ; <nl> - <nl> try <nl> { <nl> TokenMetadata metadata = cloneOnlyTokenMap ( ) ; <nl> @ @ - 807 , 50 + 825 , 49 @ @ public class TokenMetadata <nl> public void calculatePendingRanges ( AbstractReplicationStrategy strategy , String keyspaceName ) <nl> { <nl> / / avoid race between both branches - do not use a lock here as this will block any other unrelated operations ! <nl> + long startedAt = System . currentTimeMillis ( ) ; <nl> synchronized ( pendingRanges ) <nl> { <nl> - if ( bootstrapTokens . isEmpty ( ) & & leavingEndpoints . isEmpty ( ) & & movingEndpoints . isEmpty ( ) ) <nl> - { <nl> - if ( logger . isTraceEnabled ( ) ) <nl> - logger . trace ( " No bootstrapping , leaving or moving nodes - > empty pending ranges for { } " , keyspaceName ) ; <nl> + / / create clone of current state <nl> + BiMultiValMap < Token , InetAddress > bootstrapTokensClone ; <nl> + Set < InetAddress > leavingEndpointsClone ; <nl> + Set < Pair < Token , InetAddress > > movingEndpointsClone ; <nl> + TokenMetadata metadata ; <nl> <nl> - pendingRanges . put ( keyspaceName , new PendingRangeMaps ( ) ) ; <nl> - } <nl> - else <nl> + lock . readLock ( ) . lock ( ) ; <nl> + try <nl> { <nl> - if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " Starting pending range calculation for { } " , keyspaceName ) ; <nl> - <nl> - long startedAt = System . currentTimeMillis ( ) ; <nl> + if ( bootstrapTokens . isEmpty ( ) & & leavingEndpoints . isEmpty ( ) & & movingEndpoints . isEmpty ( ) ) <nl> + { <nl> + if ( logger . isTraceEnabled ( ) ) <nl> + logger . trace ( " No bootstrapping , leaving or moving nodes - > empty pending ranges for { } " , keyspaceName ) ; <nl> <nl> - / / create clone of current state <nl> - BiMultiValMap < Token , InetAddress > bootstrapTokens = new BiMultiValMap < > ( ) ; <nl> - Set < InetAddress > leavingEndpoints = new HashSet < > ( ) ; <nl> - Set < Pair < Token , InetAddress > > movingEndpoints = new HashSet < > ( ) ; <nl> - TokenMetadata metadata ; <nl> + pendingRanges . put ( keyspaceName , new PendingRangeMaps ( ) ) ; <nl> <nl> - lock . readLock ( ) . lock ( ) ; <nl> - try <nl> - { <nl> - bootstrapTokens . putAll ( this . bootstrapTokens ) ; <nl> - leavingEndpoints . addAll ( this . leavingEndpoints ) ; <nl> - movingEndpoints . addAll ( this . movingEndpoints ) ; <nl> - metadata = this . cloneOnlyTokenMap ( ) ; <nl> - } <nl> - finally <nl> - { <nl> - lock . readLock ( ) . unlock ( ) ; <nl> + return ; <nl> } <nl> <nl> - pendingRanges . put ( keyspaceName , calculatePendingRanges ( strategy , metadata , bootstrapTokens , <nl> - leavingEndpoints , movingEndpoints ) ) ; <nl> - long took = System . currentTimeMillis ( ) - startedAt ; <nl> - <nl> if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " Pending range calculation for { } completed ( took : { } ms ) " , keyspaceName , took ) ; <nl> - if ( logger . isTraceEnabled ( ) ) <nl> - logger . trace ( " Calculated pending ranges for { } : \ n { } " , keyspaceName , ( pendingRanges . isEmpty ( ) ? " < empty > " : printPendingRanges ( ) ) ) ; <nl> + logger . debug ( " Starting pending range calculation for { } " , keyspaceName ) ; <nl> + <nl> + bootstrapTokensClone = new BiMultiValMap < > ( this . bootstrapTokens ) ; <nl> + leavingEndpointsClone = new HashSet < > ( this . leavingEndpoints ) ; <nl> + movingEndpointsClone = new HashSet < > ( this . movingEndpoints ) ; <nl> + metadata = this . cloneOnlyTokenMap ( ) ; <nl> } <nl> + finally <nl> + { <nl> + lock . readLock ( ) . unlock ( ) ; <nl> + } <nl> + <nl> + pendingRanges . put ( keyspaceName , calculatePendingRanges ( strategy , metadata , bootstrapTokensClone , <nl> + leavingEndpointsClone , movingEndpointsClone ) ) ; <nl> + long took = System . currentTimeMillis ( ) - startedAt ; <nl> + <nl> + if ( logger . isDebugEnabled ( ) ) <nl> + logger . debug ( " Pending range calculation for { } completed ( took : { } ms ) " , keyspaceName , took ) ; <nl> + if ( logger . isTraceEnabled ( ) ) <nl> + logger . trace ( " Calculated pending ranges for { } : \ n { } " , keyspaceName , ( pendingRanges . isEmpty ( ) ? " < empty > " : printPendingRanges ( ) ) ) ; <nl> } <nl> } <nl> <nl> @ @ - 960 , 7 + 977 , 7 @ @ public class TokenMetadata <nl> { <nl> List tokens = sortedTokens ( ) ; <nl> int index = Collections . binarySearch ( tokens , token ) ; <nl> - assert index > = 0 : token + " not found in " + StringUtils . join ( tokenToEndpointMap . keySet ( ) , " , " ) ; <nl> + assert index > = 0 : token + " not found in " + tokenToEndpointMapKeysAsStrings ( ) ; <nl> return ( Token ) ( index = = 0 ? tokens . get ( tokens . size ( ) - 1 ) : tokens . get ( index - 1 ) ) ; <nl> } <nl> <nl> @ @ - 968 , 17 + 985 , 30 @ @ public class TokenMetadata <nl> { <nl> List tokens = sortedTokens ( ) ; <nl> int index = Collections . binarySearch ( tokens , token ) ; <nl> - assert index > = 0 : token + " not found in " + StringUtils . join ( tokenToEndpointMap . keySet ( ) , " , " ) ; <nl> + assert index > = 0 : token + " not found in " + tokenToEndpointMapKeysAsStrings ( ) ; <nl> return ( Token ) ( ( index = = ( tokens . size ( ) - 1 ) ) ? tokens . get ( 0 ) : tokens . get ( index + 1 ) ) ; <nl> } <nl> <nl> + private String tokenToEndpointMapKeysAsStrings ( ) <nl> + { <nl> + lock . readLock ( ) . lock ( ) ; <nl> + try <nl> + { <nl> + return StringUtils . join ( tokenToEndpointMap . keySet ( ) , " , " ) ; <nl> + } <nl> + finally <nl> + { <nl> + lock . readLock ( ) . unlock ( ) ; <nl> + } <nl> + } <nl> + <nl> / * * @ return a copy of the bootstrapping tokens map * / <nl> public BiMultiValMap < Token , InetAddress > getBootstrapTokens ( ) <nl> { <nl> lock . readLock ( ) . lock ( ) ; <nl> try <nl> { <nl> - return new BiMultiValMap < Token , InetAddress > ( bootstrapTokens ) ; <nl> + return new BiMultiValMap < > ( bootstrapTokens ) ; <nl> } <nl> finally <nl> { <nl> @ @ - 1103 , 7 + 1133 , 7 @ @ public class TokenMetadata <nl> pendingRanges . clear ( ) ; <nl> movingEndpoints . clear ( ) ; <nl> sortedTokens . clear ( ) ; <nl> - topology . clear ( ) ; <nl> + topology = Topology . empty ( ) ; <nl> invalidateCachedRings ( ) ; <nl> } <nl> finally <nl> @ @ - 1271 , 130 + 1301 , 170 @ @ public class TokenMetadata <nl> public static class Topology <nl> { <nl> / * * multi - map of DC to endpoints in that DC * / <nl> - private final Multimap < String , InetAddress > dcEndpoints ; <nl> + private final ImmutableMultimap < String , InetAddress > dcEndpoints ; <nl> / * * map of DC to multi - map of rack to endpoints in that rack * / <nl> - private final Map < String , Multimap < String , InetAddress > > dcRacks ; <nl> + private final ImmutableMap < String , ImmutableMultimap < String , InetAddress > > dcRacks ; <nl> / * * reverse - lookup map for endpoint to current known dc / rack assignment * / <nl> - private final Map < InetAddress , Pair < String , String > > currentLocations ; <nl> + private final ImmutableMap < InetAddress , Pair < String , String > > currentLocations ; <nl> <nl> - Topology ( ) <nl> + private Topology ( Builder builder ) <nl> { <nl> - dcEndpoints = HashMultimap . create ( ) ; <nl> - dcRacks = new HashMap < > ( ) ; <nl> - currentLocations = new HashMap < > ( ) ; <nl> - } <nl> + this . dcEndpoints = ImmutableMultimap . copyOf ( builder . dcEndpoints ) ; <nl> <nl> - void clear ( ) <nl> - { <nl> - dcEndpoints . clear ( ) ; <nl> - dcRacks . clear ( ) ; <nl> - currentLocations . clear ( ) ; <nl> + ImmutableMap . Builder < String , ImmutableMultimap < String , InetAddress > > dcRackBuilder = ImmutableMap . builder ( ) ; <nl> + for ( Map . Entry < String , Multimap < String , InetAddress > > entry : builder . dcRacks . entrySet ( ) ) <nl> + dcRackBuilder . put ( entry . getKey ( ) , ImmutableMultimap . copyOf ( entry . getValue ( ) ) ) ; <nl> + this . dcRacks = dcRackBuilder . build ( ) ; <nl> + <nl> + this . currentLocations = ImmutableMap . copyOf ( builder . currentLocations ) ; <nl> } <nl> <nl> / * * <nl> - * construct deep - copy of other <nl> + * @ return multi - map of DC to endpoints in that DC <nl> * / <nl> - Topology ( Topology other ) <nl> + public Multimap < String , InetAddress > getDatacenterEndpoints ( ) <nl> { <nl> - dcEndpoints = HashMultimap . create ( other . dcEndpoints ) ; <nl> - dcRacks = new HashMap < > ( ) ; <nl> - for ( String dc : other . dcRacks . keySet ( ) ) <nl> - dcRacks . put ( dc , HashMultimap . create ( other . dcRacks . get ( dc ) ) ) ; <nl> - currentLocations = new HashMap < > ( other . currentLocations ) ; <nl> + return dcEndpoints ; <nl> } <nl> <nl> / * * <nl> - * Stores current DC / rack assignment for ep <nl> + * @ return map of DC to multi - map of rack to endpoints in that rack <nl> * / <nl> - void addEndpoint ( InetAddress ep ) <nl> + public ImmutableMap < String , ImmutableMultimap < String , InetAddress > > getDatacenterRacks ( ) <nl> { <nl> - IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; <nl> - String dc = snitch . getDatacenter ( ep ) ; <nl> - String rack = snitch . getRack ( ep ) ; <nl> - Pair < String , String > current = currentLocations . get ( ep ) ; <nl> - if ( current ! = null ) <nl> - { <nl> - if ( current . left . equals ( dc ) & & current . right . equals ( rack ) ) <nl> - return ; <nl> - doRemoveEndpoint ( ep , current ) ; <nl> - } <nl> - <nl> - doAddEndpoint ( ep , dc , rack ) ; <nl> + return dcRacks ; <nl> } <nl> <nl> - private void doAddEndpoint ( InetAddress ep , String dc , String rack ) <nl> + Builder unbuild ( ) <nl> { <nl> - dcEndpoints . put ( dc , ep ) ; <nl> - <nl> - if ( ! dcRacks . containsKey ( dc ) ) <nl> - dcRacks . put ( dc , HashMultimap . < String , InetAddress > create ( ) ) ; <nl> - dcRacks . get ( dc ) . put ( rack , ep ) ; <nl> - <nl> - currentLocations . put ( ep , Pair . create ( dc , rack ) ) ; <nl> + return new Builder ( this ) ; <nl> } <nl> <nl> - / * * <nl> - * Removes current DC / rack assignment for ep <nl> - * / <nl> - void removeEndpoint ( InetAddress ep ) <nl> + static Builder builder ( ) <nl> { <nl> - if ( ! currentLocations . containsKey ( ep ) ) <nl> - return ; <nl> - <nl> - doRemoveEndpoint ( ep , currentLocations . remove ( ep ) ) ; <nl> + return new Builder ( ) ; <nl> } <nl> <nl> - private void doRemoveEndpoint ( InetAddress ep , Pair < String , String > current ) <nl> + static Topology empty ( ) <nl> { <nl> - dcRacks . get ( current . left ) . remove ( current . right , ep ) ; <nl> - dcEndpoints . remove ( current . left , ep ) ; <nl> + return builder ( ) . build ( ) ; <nl> } <nl> <nl> - void updateEndpoint ( InetAddress ep ) <nl> + private static class Builder <nl> { <nl> - IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; <nl> - if ( snitch = = null | | ! currentLocations . containsKey ( ep ) ) <nl> - return ; <nl> + / * * multi - map of DC to endpoints in that DC * / <nl> + private final Multimap < String , InetAddress > dcEndpoints ; <nl> + / * * map of DC to multi - map of rack to endpoints in that rack * / <nl> + private final Map < String , Multimap < String , InetAddress > > dcRacks ; <nl> + / * * reverse - lookup map for endpoint to current known dc / rack assignment * / <nl> + private final Map < InetAddress , Pair < String , String > > currentLocations ; <nl> <nl> - updateEndpoint ( ep , snitch ) ; <nl> - } <nl> + Builder ( ) <nl> + { <nl> + this . dcEndpoints = HashMultimap . create ( ) ; <nl> + this . dcRacks = new HashMap < > ( ) ; <nl> + this . currentLocations = new HashMap < > ( ) ; <nl> + } <nl> <nl> - void updateEndpoints ( ) <nl> - { <nl> - IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; <nl> - if ( snitch = = null ) <nl> - return ; <nl> + Builder ( Topology from ) <nl> + { <nl> + this . dcEndpoints = HashMultimap . create ( from . dcEndpoints ) ; <nl> + <nl> + this . dcRacks = Maps . newHashMapWithExpectedSize ( from . dcRacks . size ( ) ) ; <nl> + for ( Map . Entry < String , ImmutableMultimap < String , InetAddress > > entry : from . dcRacks . entrySet ( ) ) <nl> + dcRacks . put ( entry . getKey ( ) , HashMultimap . create ( entry . getValue ( ) ) ) ; <nl> + <nl> + this . currentLocations = new HashMap < > ( from . currentLocations ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Stores current DC / rack assignment for ep <nl> + * / <nl> + Builder addEndpoint ( InetAddress ep ) <nl> + { <nl> + IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; <nl> + String dc = snitch . getDatacenter ( ep ) ; <nl> + String rack = snitch . getRack ( ep ) ; <nl> + Pair < String , String > current = currentLocations . get ( ep ) ; <nl> + if ( current ! = null ) <nl> + { <nl> + if ( current . left . equals ( dc ) & & current . right . equals ( rack ) ) <nl> + return this ; <nl> + doRemoveEndpoint ( ep , current ) ; <nl> + } <nl> + <nl> + doAddEndpoint ( ep , dc , rack ) ; <nl> + return this ; <nl> + } <nl> + <nl> + private void doAddEndpoint ( InetAddress ep , String dc , String rack ) <nl> + { <nl> + dcEndpoints . put ( dc , ep ) ; <nl> + <nl> + if ( ! dcRacks . containsKey ( dc ) ) <nl> + dcRacks . put ( dc , HashMultimap . < String , InetAddress > create ( ) ) ; <nl> + dcRacks . get ( dc ) . put ( rack , ep ) ; <nl> + <nl> + currentLocations . put ( ep , Pair . create ( dc , rack ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Removes current DC / rack assignment for ep <nl> + * / <nl> + Builder removeEndpoint ( InetAddress ep ) <nl> + { <nl> + if ( ! currentLocations . containsKey ( ep ) ) <nl> + return this ; <nl> + <nl> + doRemoveEndpoint ( ep , currentLocations . remove ( ep ) ) ; <nl> + return this ; <nl> + } <nl> + <nl> + private void doRemoveEndpoint ( InetAddress ep , Pair < String , String > current ) <nl> + { <nl> + dcRacks . get ( current . left ) . remove ( current . right , ep ) ; <nl> + dcEndpoints . remove ( current . left , ep ) ; <nl> + } <nl> + <nl> + Builder updateEndpoint ( InetAddress ep ) <nl> + { <nl> + IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; <nl> + if ( snitch = = null | | ! currentLocations . containsKey ( ep ) ) <nl> + return this ; <nl> <nl> - for ( InetAddress ep : currentLocations . keySet ( ) ) <nl> updateEndpoint ( ep , snitch ) ; <nl> - } <nl> + return this ; <nl> + } <nl> <nl> - private void updateEndpoint ( InetAddress ep , IEndpointSnitch snitch ) <nl> - { <nl> - Pair < String , String > current = currentLocations . get ( ep ) ; <nl> - String dc = snitch . getDatacenter ( ep ) ; <nl> - String rack = snitch . getRack ( ep ) ; <nl> - if ( dc . equals ( current . left ) & & rack . equals ( current . right ) ) <nl> - return ; <nl> + Builder updateEndpoints ( ) <nl> + { <nl> + IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; <nl> + if ( snitch = = null ) <nl> + return this ; <nl> <nl> - doRemoveEndpoint ( ep , current ) ; <nl> - doAddEndpoint ( ep , dc , rack ) ; <nl> - } <nl> + for ( InetAddress ep : currentLocations . keySet ( ) ) <nl> + updateEndpoint ( ep , snitch ) ; <nl> <nl> - / * * <nl> - * @ return multi - map of DC to endpoints in that DC <nl> - * / <nl> - public Multimap < String , InetAddress > getDatacenterEndpoints ( ) <nl> - { <nl> - return dcEndpoints ; <nl> - } <nl> + return this ; <nl> + } <nl> <nl> - / * * <nl> - * @ return map of DC to multi - map of rack to endpoints in that rack <nl> - * / <nl> - public Map < String , Multimap < String , InetAddress > > getDatacenterRacks ( ) <nl> - { <nl> - return dcRacks ; <nl> + private void updateEndpoint ( InetAddress ep , IEndpointSnitch snitch ) <nl> + { <nl> + Pair < String , String > current = currentLocations . get ( ep ) ; <nl> + String dc = snitch . getDatacenter ( ep ) ; <nl> + String rack = snitch . getRack ( ep ) ; <nl> + if ( dc . equals ( current . left ) & & rack . equals ( current . right ) ) <nl> + return ; <nl> + <nl> + doRemoveEndpoint ( ep , current ) ; <nl> + doAddEndpoint ( ep , dc , rack ) ; <nl> + } <nl> + <nl> + Topology build ( ) <nl> + { <nl> + return new Topology ( this ) ; <nl> + } <nl> } <nl> + <nl> } <nl> } <nl> diff - - git a / test / unit / org / apache / cassandra / locator / TokenMetadataTest . java b / test / unit / org / apache / cassandra / locator / TokenMetadataTest . java <nl> index e7bb70a . . dab7082 100644 <nl> - - - a / test / unit / org / apache / cassandra / locator / TokenMetadataTest . java <nl> + + + b / test / unit / org / apache / cassandra / locator / TokenMetadataTest . java <nl> @ @ - 22 , 6 + 22 , 7 @ @ import java . net . UnknownHostException ; <nl> import java . util . ArrayList ; <nl> import java . util . Map ; <nl> <nl> + import com . google . common . collect . ImmutableMultimap ; <nl> import com . google . common . collect . Iterators ; <nl> import com . google . common . collect . Multimap ; <nl> <nl> @ @ - 29 , 18 + 30 , 18 @ @ import org . junit . BeforeClass ; <nl> import org . junit . Test ; <nl> import org . junit . runner . RunWith ; <nl> <nl> - import static junit . framework . Assert . assertNotNull ; <nl> - import static org . junit . Assert . assertEquals ; <nl> - <nl> - import static org . apache . cassandra . Util . token ; <nl> - import static org . junit . Assert . assertFalse ; <nl> - import static org . junit . Assert . assertTrue ; <nl> - <nl> import org . apache . cassandra . OrderedJUnit4ClassRunner ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . dht . Token ; <nl> import org . apache . cassandra . service . StorageService ; <nl> <nl> + import static org . junit . Assert . assertEquals ; <nl> + import static org . junit . Assert . assertNotNull ; <nl> + import static org . junit . Assert . assertFalse ; <nl> + import static org . junit . Assert . assertTrue ; <nl> + <nl> + import static org . apache . cassandra . Util . token ; <nl> + <nl> <nl> @ RunWith ( OrderedJUnit4ClassRunner . class ) <nl> public class TokenMetadataTest <nl> @ @ - 139 , 7 + 140 , 7 @ @ public class TokenMetadataTest <nl> assertTrue ( allEndpoints . get ( DATA _ CENTER ) . contains ( first ) ) ; <nl> assertTrue ( allEndpoints . get ( DATA _ CENTER ) . contains ( second ) ) ; <nl> <nl> - Map < String , Multimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; <nl> + Map < String , ImmutableMultimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; <nl> assertNotNull ( racks ) ; <nl> assertTrue ( racks . size ( ) = = 1 ) ; <nl> assertTrue ( racks . containsKey ( DATA _ CENTER ) ) ; <nl> @ @ - 171 , 7 + 172 , 7 @ @ public class TokenMetadataTest <nl> } ) ; <nl> <nl> tokenMetadata . updateTopology ( first ) ; <nl> - tokenMetadata . updateTopology ( second ) ; <nl> + topology = tokenMetadata . updateTopology ( second ) ; <nl> <nl> allEndpoints = topology . getDatacenterEndpoints ( ) ; <nl> assertNotNull ( allEndpoints ) ; <nl> @ @ - 237 , 7 + 238 , 7 @ @ public class TokenMetadataTest <nl> assertTrue ( allEndpoints . get ( DATA _ CENTER ) . contains ( first ) ) ; <nl> assertTrue ( allEndpoints . get ( DATA _ CENTER ) . contains ( second ) ) ; <nl> <nl> - Map < String , Multimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; <nl> + Map < String , ImmutableMultimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; <nl> assertNotNull ( racks ) ; <nl> assertTrue ( racks . size ( ) = = 1 ) ; <nl> assertTrue ( racks . containsKey ( DATA _ CENTER ) ) ; <nl> @ @ - 268 , 7 + 269 , 7 @ @ public class TokenMetadataTest <nl> } <nl> } ) ; <nl> <nl> - tokenMetadata . updateTopology ( ) ; <nl> + topology = tokenMetadata . updateTopology ( ) ; <nl> <nl> allEndpoints = topology . getDatacenterEndpoints ( ) ; <nl> assertNotNull ( allEndpoints ) ;
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 9edb36d . . 73a6717 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 2 , 6 + 2 , 10 @ @ <nl> * Fix potential NPE in get _ range _ slice ( CASSANDRA - 623 ) <nl> * add CRC32 to commitlog entries ( CASSANDRA - 605 ) <nl> * fix data streaming on windows ( CASSANDRA - 630 ) <nl> + * GC compacted sstables after cleanup and compaction ( CASSANDRA - 621 ) <nl> + * Speed up anti - entropy validation ( CASSANDRA - 629 ) <nl> + * Fix pending range conflicts when bootstapping or moving <nl> + multiple nodes at once ( CASSANDRA - 603 ) <nl> <nl> <nl> 0 . 5 . 0 beta 2 <nl> diff - - git a / NEWS . txt b / NEWS . txt <nl> index 108dd5d . . 966c7e9 100644 <nl> - - - a / NEWS . txt <nl> + + + b / NEWS . txt <nl> @ @ - 8 , 6 + 8 , 10 @ @ <nl> out ; if that happens , just go back to 0 . 4 and flush again . ) <nl> The format changed twice : from 0 . 4 to beta1 , and from beta2 to RC1 . <nl> <nl> + . 5 The gossip protocol has changed , meaning 0 . 5 nodes cannot coexist <nl> + in a cluster of 0 . 4 nodes or vice versa ; you must upgrade your <nl> + whole cluster at the same time . <nl> + <nl> 1 . Bootstrap , move , load balancing , and active repair have been added . <nl> See http : / / wiki . apache . org / cassandra / Operations . When upgrading <nl> from 0 . 4 , leave autobootstrap set to false for the first restart <nl> diff - - git a / src / java / org / apache / cassandra / locator / AbstractReplicationStrategy . java b / src / java / org / apache / cassandra / locator / AbstractReplicationStrategy . java <nl> index aa5f8fd . . fb2b480 100644 <nl> - - - a / src / java / org / apache / cassandra / locator / AbstractReplicationStrategy . java <nl> + + + b / src / java / org / apache / cassandra / locator / AbstractReplicationStrategy . java <nl> @ @ - 91 , 11 + 91 , 11 @ @ public abstract class AbstractReplicationStrategy <nl> <nl> List < InetAddress > endpoints = new ArrayList < InetAddress > ( naturalEndpoints ) ; <nl> <nl> - for ( Map . Entry < Range , InetAddress > entry : tokenMetadata _ . getPendingRanges ( ) . entrySet ( ) ) <nl> + for ( Map . Entry < Range , Collection < InetAddress > > entry : tokenMetadata _ . getPendingRanges ( ) . entrySet ( ) ) <nl> { <nl> if ( entry . getKey ( ) . contains ( token ) ) <nl> { <nl> - endpoints . add ( entry . getValue ( ) ) ; <nl> + endpoints . addAll ( entry . getValue ( ) ) ; <nl> } <nl> } <nl> <nl> @ @ - 202 , 26 + 202 , 9 @ @ public abstract class AbstractReplicationStrategy <nl> <nl> public Collection < Range > getPendingAddressRanges ( TokenMetadata metadata , Token pendingToken , InetAddress pendingAddress ) <nl> { <nl> - TokenMetadata temp = metadata . cloneWithoutPending ( ) ; <nl> - temp . update ( pendingToken , pendingAddress ) ; <nl> + TokenMetadata temp = metadata . cloneOnlyTokenMap ( ) ; <nl> + temp . updateNormalToken ( pendingToken , pendingAddress ) ; <nl> return getAddressRanges ( temp ) . get ( pendingAddress ) ; <nl> } <nl> <nl> - public void removeObsoletePendingRanges ( ) <nl> - { <nl> - Multimap < InetAddress , Range > ranges = getAddressRanges ( ) ; <nl> - for ( Map . Entry < Range , InetAddress > entry : tokenMetadata _ . getPendingRanges ( ) . entrySet ( ) ) <nl> - { <nl> - for ( Range currentRange : ranges . get ( entry . getValue ( ) ) ) <nl> - { <nl> - if ( currentRange . contains ( entry . getKey ( ) ) ) <nl> - { <nl> - if ( logger _ . isDebugEnabled ( ) ) <nl> - logger _ . debug ( " Removing obsolete pending range " + entry . getKey ( ) + " from " + entry . getValue ( ) ) ; <nl> - tokenMetadata _ . removePendingRange ( entry . getKey ( ) ) ; <nl> - break ; <nl> - } <nl> - } <nl> - } <nl> - } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / locator / TokenMetadata . java b / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> index 771ce2f . . 924e4d5 100644 <nl> - - - a / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> + + + b / src / java / org / apache / cassandra / locator / TokenMetadata . java <nl> @ @ - 29 , 15 + 29 , 33 @ @ import java . net . InetAddress ; <nl> <nl> import org . apache . commons . lang . StringUtils ; <nl> <nl> - import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; <nl> import com . google . common . collect . BiMap ; <nl> import com . google . common . collect . HashBiMap ; <nl> + import com . google . common . collect . Multimap ; <nl> + import com . google . common . collect . HashMultimap ; <nl> <nl> public class TokenMetadata <nl> { <nl> / * Maintains token to endpoint map of every node in the cluster . * / <nl> private BiMap < Token , InetAddress > tokenToEndPointMap ; <nl> - private Map < Range , InetAddress > pendingRanges ; <nl> + <nl> + / / Suppose that there is a ring of nodes A , C and E , with replication factor 3 . <nl> + / / Node D bootstraps between C and E , so its pending ranges will be E - A , A - C and C - D . <nl> + / / Now suppose node B bootstraps between A and C at the same time . Its pending ranges would be C - E , E - A and A - B . <nl> + / / Now both nodes have pending range E - A in their list , which will cause pending range collision <nl> + / / even though we ' re only talking about replica range , not even primary range . The same thing happens <nl> + / / for any nodes that boot simultaneously between same two nodes . For this we cannot simply make pending ranges a multimap , <nl> + / / since that would make us unable to notice the real problem of two nodes trying to boot using the same token . <nl> + / / In order to do this properly , we need to know what tokens are booting at any time . <nl> + private Map < Token , InetAddress > bootstrapTokens ; <nl> + <nl> + / / we will need to know at all times what nodes are leaving and calculate ranges accordingly . <nl> + / / An anonymous pending ranges list is not enough , as that does not tell which node is leaving <nl> + / / and / or if the ranges are there because of bootstrap or leave operation . <nl> + / / ( See CASSANDRA - 603 for more detail + examples ) . <nl> + private Set < InetAddress > leavingEndPoints ; <nl> + <nl> + private Multimap < Range , InetAddress > pendingRanges ; <nl> <nl> / * Use this lock for manipulating the token map * / <nl> private final ReadWriteLock lock = new ReentrantReadWriteLock ( true ) ; <nl> @ @ - 53 , 7 + 71 , 9 @ @ public class TokenMetadata <nl> if ( tokenToEndPointMap = = null ) <nl> tokenToEndPointMap = HashBiMap . create ( ) ; <nl> this . tokenToEndPointMap = tokenToEndPointMap ; <nl> - pendingRanges = new NonBlockingHashMap < Range , InetAddress > ( ) ; <nl> + bootstrapTokens = new HashMap < Token , InetAddress > ( ) ; <nl> + leavingEndPoints = new HashSet < InetAddress > ( ) ; <nl> + pendingRanges = HashMultimap . create ( ) ; <nl> sortedTokens = sortTokens ( ) ; <nl> } <nl> <nl> @ @ - 69 , 18 + 89 , 13 @ @ public class TokenMetadata <nl> { <nl> int n = 0 ; <nl> Range sourceRange = getPrimaryRangeFor ( getToken ( source ) ) ; <nl> - for ( Map . Entry < Range , InetAddress > entry : pendingRanges . entrySet ( ) ) <nl> - { <nl> - if ( sourceRange . contains ( entry . getKey ( ) ) | | entry . getValue ( ) . equals ( source ) ) <nl> + for ( Token token : bootstrapTokens . keySet ( ) ) <nl> + if ( sourceRange . contains ( token ) ) <nl> n + + ; <nl> - } <nl> return n ; <nl> } <nl> <nl> - / * * <nl> - * Update the two maps in an safe mode . <nl> - * / <nl> - public void update ( Token token , InetAddress endpoint ) <nl> + public void updateNormalToken ( Token token , InetAddress endpoint ) <nl> { <nl> assert token ! = null ; <nl> assert endpoint ! = null ; <nl> @ @ - 88 , 6 + 103 , 8 @ @ public class TokenMetadata <nl> lock . writeLock ( ) . lock ( ) ; <nl> try <nl> { <nl> + bootstrapTokens . remove ( token ) ; <nl> + <nl> tokenToEndPointMap . inverse ( ) . remove ( endpoint ) ; <nl> if ( ! endpoint . equals ( tokenToEndPointMap . put ( token , endpoint ) ) ) <nl> { <nl> @ @ - 100 , 13 + 117 , 49 @ @ public class TokenMetadata <nl> } <nl> } <nl> <nl> + public void addBootstrapToken ( Token token , InetAddress endpoint ) <nl> + { <nl> + assert token ! = null ; <nl> + assert endpoint ! = null ; <nl> + <nl> + lock . writeLock ( ) . lock ( ) ; <nl> + try <nl> + { <nl> + InetAddress oldEndPoint = bootstrapTokens . get ( token ) ; <nl> + if ( oldEndPoint ! = null & & ! oldEndPoint . equals ( endpoint ) ) <nl> + throw new RuntimeException ( " Bootstrap Token collision between " + oldEndPoint + " and " + endpoint + " ( token " + token ) ; <nl> + bootstrapTokens . put ( token , endpoint ) ; <nl> + } <nl> + finally <nl> + { <nl> + lock . writeLock ( ) . unlock ( ) ; <nl> + } <nl> + } <nl> + <nl> + public void addLeavingEndPoint ( InetAddress endpoint ) <nl> + { <nl> + assert endpoint ! = null ; <nl> + <nl> + lock . writeLock ( ) . lock ( ) ; <nl> + try <nl> + { <nl> + leavingEndPoints . add ( endpoint ) ; <nl> + } <nl> + finally <nl> + { <nl> + lock . writeLock ( ) . unlock ( ) ; <nl> + } <nl> + } <nl> + <nl> public void removeEndpoint ( InetAddress endpoint ) <nl> { <nl> assert tokenToEndPointMap . containsValue ( endpoint ) ; <nl> lock . writeLock ( ) . lock ( ) ; <nl> try <nl> { <nl> + bootstrapTokens . remove ( getToken ( endpoint ) ) ; <nl> tokenToEndPointMap . inverse ( ) . remove ( endpoint ) ; <nl> + leavingEndPoints . remove ( endpoint ) ; <nl> sortedTokens = sortTokens ( ) ; <nl> } <nl> finally <nl> @ @ - 161 , 7 + 214 , 11 @ @ public class TokenMetadata <nl> } <nl> } <nl> <nl> - public TokenMetadata cloneWithoutPending ( ) <nl> + / * * <nl> + * Create a copy of TokenMetadata with only tokenToEndPointMap . That is , pending ranges , <nl> + * bootstrap tokens and leaving endpoints are not included in the copy . <nl> + * / <nl> + public TokenMetadata cloneOnlyTokenMap ( ) <nl> { <nl> lock . readLock ( ) . lock ( ) ; <nl> try <nl> @ @ - 174 , 28 + 231 , 24 @ @ public class TokenMetadata <nl> } <nl> } <nl> <nl> - public String toString ( ) <nl> + / * * <nl> + * Create a copy of TokenMetadata with tokenToEndPointMap reflecting situation after all <nl> + * current leave operations have finished . <nl> + * / <nl> + public TokenMetadata cloneAfterAllLeft ( ) <nl> { <nl> - StringBuilder sb = new StringBuilder ( ) ; <nl> lock . readLock ( ) . lock ( ) ; <nl> try <nl> { <nl> - Set < InetAddress > eps = tokenToEndPointMap . inverse ( ) . keySet ( ) ; <nl> - <nl> - for ( InetAddress ep : eps ) <nl> - { <nl> - sb . append ( ep ) ; <nl> - sb . append ( " : " ) ; <nl> - sb . append ( tokenToEndPointMap . inverse ( ) . get ( ep ) ) ; <nl> - sb . append ( System . getProperty ( " line . separator " ) ) ; <nl> - } <nl> + TokenMetadata allLeftMetadata = cloneOnlyTokenMap ( ) ; <nl> + for ( InetAddress endPoint : leavingEndPoints ) <nl> + allLeftMetadata . removeEndpoint ( endPoint ) ; <nl> + return allLeftMetadata ; <nl> } <nl> finally <nl> { <nl> lock . readLock ( ) . unlock ( ) ; <nl> } <nl> - <nl> - return sb . toString ( ) ; <nl> } <nl> <nl> public InetAddress getEndPoint ( Token token ) <nl> @ @ - 211 , 12 + 264 , 6 @ @ public class TokenMetadata <nl> } <nl> } <nl> <nl> - public void clearUnsafe ( ) <nl> - { <nl> - tokenToEndPointMap . clear ( ) ; <nl> - pendingRanges . clear ( ) ; <nl> - } <nl> - <nl> public Range getPrimaryRangeFor ( Token right ) <nl> { <nl> return new Range ( getPredecessor ( right ) , right ) ; <nl> @ @ - 235 , 29 + 282 , 16 @ @ public class TokenMetadata <nl> } <nl> } <nl> <nl> - public void addPendingRange ( Range range , InetAddress endpoint ) <nl> - { <nl> - InetAddress oldEndpoint = pendingRanges . get ( range ) ; <nl> - if ( oldEndpoint ! = null & & ! oldEndpoint . equals ( endpoint ) ) <nl> - throw new RuntimeException ( " pending range collision between " + oldEndpoint + " and " + endpoint ) ; <nl> - pendingRanges . put ( range , endpoint ) ; <nl> - } <nl> - <nl> - public void removePendingRange ( Range range ) <nl> - { <nl> - pendingRanges . remove ( range ) ; <nl> - } <nl> - <nl> / * * a mutable map may be returned but caller should not modify it * / <nl> - public Map < Range , InetAddress > getPendingRanges ( ) <nl> + public Map < Range , Collection < InetAddress > > getPendingRanges ( ) <nl> { <nl> - return pendingRanges ; <nl> + return pendingRanges . asMap ( ) ; <nl> } <nl> <nl> public List < Range > getPendingRanges ( InetAddress endpoint ) <nl> { <nl> List < Range > ranges = new ArrayList < Range > ( ) ; <nl> - for ( Map . Entry < Range , InetAddress > entry : pendingRanges . entrySet ( ) ) <nl> + for ( Map . Entry < Range , InetAddress > entry : pendingRanges . entries ( ) ) <nl> { <nl> if ( entry . getValue ( ) . equals ( endpoint ) ) <nl> { <nl> @ @ - 267 , 6 + 301 , 11 @ @ public class TokenMetadata <nl> return ranges ; <nl> } <nl> <nl> + public void setPendingRanges ( Multimap < Range , InetAddress > pendingRanges ) <nl> + { <nl> + this . pendingRanges = pendingRanges ; <nl> + } <nl> + <nl> public Token getPredecessor ( Token token ) <nl> { <nl> List tokens = sortedTokens ( ) ; <nl> @ @ - 288 , 8 + 327 , 96 @ @ public class TokenMetadata <nl> return getEndPoint ( getSuccessor ( getToken ( endPoint ) ) ) ; <nl> } <nl> <nl> - public void clearPendingRanges ( ) <nl> + / * * caller should not modify bootstrapTokens * / <nl> + public Map < Token , InetAddress > getBootstrapTokens ( ) <nl> + { <nl> + return bootstrapTokens ; <nl> + } <nl> + <nl> + / * * caller should not modify leavigEndPoints * / <nl> + public Set < InetAddress > getLeavingEndPoints ( ) <nl> { <nl> + return leavingEndPoints ; <nl> + } <nl> + <nl> + / * * used by tests * / <nl> + public void clearUnsafe ( ) <nl> + { <nl> + bootstrapTokens . clear ( ) ; <nl> + tokenToEndPointMap . clear ( ) ; <nl> + leavingEndPoints . clear ( ) ; <nl> pendingRanges . clear ( ) ; <nl> } <nl> + <nl> + public String toString ( ) <nl> + { <nl> + StringBuilder sb = new StringBuilder ( ) ; <nl> + lock . readLock ( ) . lock ( ) ; <nl> + try <nl> + { <nl> + Set < InetAddress > eps = tokenToEndPointMap . inverse ( ) . keySet ( ) ; <nl> + <nl> + if ( ! eps . isEmpty ( ) ) <nl> + { <nl> + sb . append ( " Normal Tokens : " ) ; <nl> + sb . append ( System . getProperty ( " line . separator " ) ) ; <nl> + for ( InetAddress ep : eps ) <nl> + { <nl> + sb . append ( ep ) ; <nl> + sb . append ( " : " ) ; <nl> + sb . append ( tokenToEndPointMap . inverse ( ) . get ( ep ) ) ; <nl> + sb . append ( System . getProperty ( " line . separator " ) ) ; <nl> + } <nl> + } <nl> + <nl> + if ( ! bootstrapTokens . isEmpty ( ) ) <nl> + { <nl> + sb . append ( " Bootstrapping Tokens : " ) ; <nl> + sb . append ( System . getProperty ( " line . separator " ) ) ; <nl> + for ( Map . Entry < Token , InetAddress > entry : bootstrapTokens . entrySet ( ) ) <nl> + { <nl> + sb . append ( entry . getValue ( ) + " : " + entry . getKey ( ) ) ; <nl> + sb . append ( System . getProperty ( " line . separator " ) ) ; <nl> + } <nl> + } <nl> + <nl> + if ( ! leavingEndPoints . isEmpty ( ) ) <nl> + { <nl> + sb . append ( " Leaving EndPoints : " ) ; <nl> + sb . append ( System . getProperty ( " line . separator " ) ) ; <nl> + for ( InetAddress ep : leavingEndPoints ) <nl> + { <nl> + sb . append ( ep ) ; <nl> + sb . append ( System . getProperty ( " line . separator " ) ) ; <nl> + } <nl> + } <nl> + <nl> + if ( ! pendingRanges . isEmpty ( ) ) <nl> + { <nl> + sb . append ( " Pending Ranges : " ) ; <nl> + sb . append ( System . getProperty ( " line . separator " ) ) ; <nl> + sb . append ( printPendingRanges ( ) ) ; <nl> + } <nl> + } <nl> + finally <nl> + { <nl> + lock . readLock ( ) . unlock ( ) ; <nl> + } <nl> + <nl> + return sb . toString ( ) ; <nl> + } <nl> + <nl> + public String printPendingRanges ( ) <nl> + { <nl> + StringBuilder sb = new StringBuilder ( ) ; <nl> + <nl> + for ( Map . Entry < Range , InetAddress > entry : pendingRanges . entries ( ) ) <nl> + { <nl> + sb . append ( entry . getValue ( ) + " : " + entry . getKey ( ) ) ; <nl> + sb . append ( System . getProperty ( " line . separator " ) ) ; <nl> + } <nl> + <nl> + return sb . toString ( ) ; <nl> + } <nl> + <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index 1dfba20 . . e5f3988 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 183 , 7 + 183 , 7 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> if ( logger _ . isDebugEnabled ( ) ) <nl> logger _ . debug ( " Setting token to " + token ) ; <nl> SystemTable . updateToken ( token ) ; <nl> - tokenMetadata _ . update ( token , FBUtilities . getLocalAddress ( ) ) ; <nl> + tokenMetadata _ . updateNormalToken ( token , FBUtilities . getLocalAddress ( ) ) ; <nl> } <nl> <nl> public StorageService ( ) <nl> @ @ - 306 , 7 + 306 , 7 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> { <nl> SystemTable . setBootstrapped ( true ) ; <nl> Token token = storageMetadata _ . getToken ( ) ; <nl> - tokenMetadata _ . update ( token , FBUtilities . getLocalAddress ( ) ) ; <nl> + tokenMetadata _ . updateNormalToken ( token , FBUtilities . getLocalAddress ( ) ) ; <nl> Gossiper . instance ( ) . addApplicationState ( StorageService . STATE _ NORMAL , new ApplicationState ( partitioner _ . getTokenFactory ( ) . toString ( token ) ) ) ; <nl> } <nl> <nl> @ @ - 407 , 23 + 407 , 25 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> Token token = getPartitioner ( ) . getTokenFactory ( ) . fromString ( state . getValue ( ) ) ; <nl> if ( logger _ . isDebugEnabled ( ) ) <nl> logger _ . debug ( endpoint + " state bootstrapping , token " + token ) ; <nl> - updateBootstrapRanges ( token , endpoint ) ; <nl> + tokenMetadata _ . addBootstrapToken ( token , endpoint ) ; <nl> + calculatePendingRanges ( ) ; <nl> } <nl> else if ( STATE _ NORMAL . equals ( stateName ) ) <nl> { <nl> Token token = getPartitioner ( ) . getTokenFactory ( ) . fromString ( state . getValue ( ) ) ; <nl> if ( logger _ . isDebugEnabled ( ) ) <nl> logger _ . debug ( endpoint + " state normal , token " + token ) ; <nl> - tokenMetadata _ . update ( token , endpoint ) ; <nl> + tokenMetadata _ . updateNormalToken ( token , endpoint ) ; <nl> + calculatePendingRanges ( ) ; <nl> if ( ! isClientMode ) <nl> SystemTable . updateToken ( endpoint , token ) ; <nl> - replicationStrategy _ . removeObsoletePendingRanges ( ) ; <nl> } <nl> else if ( STATE _ LEAVING . equals ( stateName ) ) <nl> { <nl> Token token = getPartitioner ( ) . getTokenFactory ( ) . fromString ( state . getValue ( ) ) ; <nl> assert tokenMetadata _ . getToken ( endpoint ) . equals ( token ) ; <nl> - updateLeavingRanges ( endpoint ) ; <nl> + tokenMetadata _ . addLeavingEndPoint ( endpoint ) ; <nl> + calculatePendingRanges ( ) ; <nl> } <nl> else if ( STATE _ LEFT . equals ( stateName ) ) <nl> { <nl> @ @ - 442 , 6 + 444 , 7 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> logger _ . debug ( endpoint + " state left , token " + token ) ; <nl> assert tokenMetadata _ . getToken ( endpoint ) . equals ( token ) ; <nl> tokenMetadata _ . removeEndpoint ( endpoint ) ; <nl> + calculatePendingRanges ( ) ; <nl> } <nl> } <nl> else <nl> @ @ - 454 , 11 + 457 , 94 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> { <nl> restoreReplicaCount ( endPointThatLeft ) ; <nl> tokenMetadata _ . removeEndpoint ( endPointThatLeft ) ; <nl> + calculatePendingRanges ( ) ; <nl> } <nl> } <nl> + } <nl> + } <nl> + <nl> + / * * <nl> + * Calculate pending ranges according to bootsrapping and leaving nodes . Reasoning is : <nl> + * <nl> + * ( 1 ) When in doubt , it is better to write too much to a node than too little . That is , if <nl> + * there are multiple nodes moving , calculate the biggest ranges a node could have . Cleaning <nl> + * up unneeded data afterwards is better than missing writes during movement . <nl> + * ( 2 ) When a node leaves , ranges for other nodes can only grow ( a node might get additional <nl> + * ranges , but it will not lose any of its current ranges as a result of a leave ) . Therefore <nl> + * we will first remove _ all _ leaving tokens for the sake of calculation and then check what <nl> + * ranges would go where if all nodes are to leave . This way we get the biggest possible <nl> + * ranges with regard current leave operations , covering all subsets of possible final range <nl> + * values . <nl> + * ( 3 ) When a node bootstraps , ranges of other nodes can only get smaller . Without doing <nl> + * complex calculations to see if multiple bootstraps overlap , we simply base calculations <nl> + * on the same token ring used before ( reflecting situation after all leave operations have <nl> + * completed ) . Bootstrapping nodes will be added and removed one by one to that metadata and <nl> + * checked what their ranges would be . This will give us the biggest possible ranges the <nl> + * node could have . It might be that other bootstraps make our actual final ranges smaller , <nl> + * but it does not matter as we can clean up the data afterwards . <nl> + * <nl> + * NOTE : This is heavy and ineffective operation . This will be done only once when a node <nl> + * changes state in the cluster , so it should be manageable . <nl> + * / <nl> + private void calculatePendingRanges ( ) <nl> + { <nl> + calculatePendingRanges ( tokenMetadata _ , replicationStrategy _ ) ; <nl> + } <nl> + <nl> + / / public & static for testing purposes <nl> + public static void calculatePendingRanges ( TokenMetadata tm , AbstractReplicationStrategy strategy ) <nl> + { <nl> + Multimap < Range , InetAddress > pendingRanges = HashMultimap . create ( ) ; <nl> + Map < Token , InetAddress > bootstrapTokens = tm . getBootstrapTokens ( ) ; <nl> + Set < InetAddress > leavingEndPoints = tm . getLeavingEndPoints ( ) ; <nl> + <nl> + if ( bootstrapTokens . isEmpty ( ) & & leavingEndPoints . isEmpty ( ) ) <nl> + { <nl> + if ( logger _ . isDebugEnabled ( ) ) <nl> + logger _ . debug ( " No bootstrapping or leaving nodes - > empty pending ranges " ) ; <nl> + tm . setPendingRanges ( pendingRanges ) ; <nl> + return ; <nl> + } <nl> + <nl> + Multimap < InetAddress , Range > addressRanges = strategy . getAddressRanges ( ) ; <nl> + <nl> + / / Copy of metadata reflecting the situation after all leave operations are finished . <nl> + TokenMetadata allLeftMetadata = tm . cloneAfterAllLeft ( ) ; <nl> + <nl> + / / get all ranges that will be affected by leaving nodes <nl> + Set < Range > affectedRanges = new HashSet < Range > ( ) ; <nl> + for ( InetAddress endPoint : leavingEndPoints ) <nl> + affectedRanges . addAll ( addressRanges . get ( endPoint ) ) ; <nl> + <nl> + / / for each of those ranges , find what new nodes will be responsible for the range when <nl> + / / all leaving nodes are gone . <nl> + for ( Range range : affectedRanges ) <nl> + { <nl> + List < InetAddress > currentEndPoints = strategy . getNaturalEndpoints ( range . right ( ) , tm ) ; <nl> + List < InetAddress > newEndPoints = strategy . getNaturalEndpoints ( range . right ( ) , allLeftMetadata ) ; <nl> + newEndPoints . removeAll ( currentEndPoints ) ; <nl> + pendingRanges . putAll ( range , newEndPoints ) ; <nl> + } <nl> + <nl> + / / At this stage pendingRanges has been updated according to leave operations . We can <nl> + / / now finish the calculation by checking bootstrapping nodes . <nl> + <nl> + / / For each of the bootstrapping nodes , simply add and remove them one by one to <nl> + / / allLeftMetadata and check in between what their ranges would be . <nl> + for ( Map . Entry < Token , InetAddress > entry : bootstrapTokens . entrySet ( ) ) <nl> + { <nl> + InetAddress endPoint = entry . getValue ( ) ; <nl> <nl> - replicationStrategy _ . removeObsoletePendingRanges ( ) ; <nl> + allLeftMetadata . updateNormalToken ( entry . getKey ( ) , endPoint ) ; <nl> + for ( Range range : strategy . getAddressRanges ( allLeftMetadata ) . get ( endPoint ) ) <nl> + pendingRanges . put ( range , endPoint ) ; <nl> + allLeftMetadata . removeEndpoint ( endPoint ) ; <nl> } <nl> + <nl> + tm . setPendingRanges ( pendingRanges ) ; <nl> + <nl> + if ( logger _ . isDebugEnabled ( ) ) <nl> + logger _ . debug ( " Pending ranges : \ n " + tm . printPendingRanges ( ) ) ; <nl> } <nl> <nl> / * * <nl> @ @ - 534 , 7 + 620 , 7 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> Collection < Range > ranges = getRangesForEndPoint ( endpoint ) ; <nl> <nl> if ( logger _ . isDebugEnabled ( ) ) <nl> - logger _ . debug ( " leaving node ranges are [ " + StringUtils . join ( ranges , " , " ) + " ] " ) ; <nl> + logger _ . debug ( " Node " + endpoint + " ranges [ " + StringUtils . join ( ranges , " , " ) + " ] " ) ; <nl> <nl> Map < Range , ArrayList < InetAddress > > currentReplicaEndpoints = new HashMap < Range , ArrayList < InetAddress > > ( ) ; <nl> <nl> @ @ - 542 , 7 + 628 , 7 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> for ( Range range : ranges ) <nl> currentReplicaEndpoints . put ( range , replicationStrategy _ . getNaturalEndpoints ( range . right ( ) , tokenMetadata _ ) ) ; <nl> <nl> - TokenMetadata temp = tokenMetadata _ . cloneWithoutPending ( ) ; <nl> + TokenMetadata temp = tokenMetadata _ . cloneAfterAllLeft ( ) ; <nl> temp . removeEndpoint ( endpoint ) ; <nl> <nl> Multimap < Range , InetAddress > changedRanges = HashMultimap . create ( ) ; <nl> @ @ - 557 , 43 + 643 , 13 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> ArrayList < InetAddress > newReplicaEndpoints = replicationStrategy _ . getNaturalEndpoints ( range . right ( ) , temp ) ; <nl> newReplicaEndpoints . removeAll ( currentReplicaEndpoints . get ( range ) ) ; <nl> if ( logger _ . isDebugEnabled ( ) ) <nl> - logger _ . debug ( " adding pending range " + range + " to endpoints " + StringUtils . join ( newReplicaEndpoints , " , " ) ) ; <nl> + logger _ . debug ( " Range " + range + " will be responsibility of " + StringUtils . join ( newReplicaEndpoints , " , " ) ) ; <nl> changedRanges . putAll ( range , newReplicaEndpoints ) ; <nl> } <nl> <nl> return changedRanges ; <nl> } <nl> <nl> - private void updateLeavingRanges ( final InetAddress endpoint ) <nl> - { <nl> - if ( logger _ . isDebugEnabled ( ) ) <nl> - logger _ . debug ( endpoint + " is leaving ; calculating pendingranges " ) ; <nl> - Multimap < Range , InetAddress > ranges = getChangedRangesForLeaving ( endpoint ) ; <nl> - for ( Range range : ranges . keySet ( ) ) <nl> - { <nl> - for ( InetAddress newEndpoint : ranges . get ( range ) ) <nl> - { <nl> - tokenMetadata _ . addPendingRange ( range , newEndpoint ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> - private void updateBootstrapRanges ( Token token , InetAddress endpoint ) <nl> - { <nl> - for ( Range range : replicationStrategy _ . getPendingAddressRanges ( tokenMetadata _ , token , endpoint ) ) <nl> - { <nl> - tokenMetadata _ . addPendingRange ( range , endpoint ) ; <nl> - } <nl> - } <nl> - <nl> - public static void updateBootstrapRanges ( AbstractReplicationStrategy strategy , TokenMetadata metadata , Token token , InetAddress endpoint ) <nl> - { <nl> - for ( Range range : strategy . getPendingAddressRanges ( metadata , token , endpoint ) ) <nl> - { <nl> - metadata . addPendingRange ( range , endpoint ) ; <nl> - } <nl> - } <nl> - <nl> public void onJoin ( InetAddress endpoint , EndPointState epState ) <nl> { <nl> for ( Map . Entry < String , ApplicationState > entry : epState . getSortedApplicationStates ( ) ) <nl> @ @ - 1117 , 7 + 1173 , 6 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> { <nl> SystemTable . setBootstrapped ( false ) ; <nl> tokenMetadata _ . removeEndpoint ( FBUtilities . getLocalAddress ( ) ) ; <nl> - replicationStrategy _ . removeObsoletePendingRanges ( ) ; <nl> <nl> if ( logger _ . isDebugEnabled ( ) ) <nl> logger _ . debug ( " " ) ; <nl> @ @ - 1238 , 7 + 1293 , 6 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> <nl> restoreReplicaCount ( endPoint ) ; <nl> tokenMetadata _ . removeEndpoint ( endPoint ) ; <nl> - replicationStrategy _ . removeObsoletePendingRanges ( ) ; <nl> } <nl> <nl> / / This is not the cleanest way as we ' re adding STATE _ LEFT for <nl> @ @ - 1261 , 11 + 1315 , 6 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> return replicationStrategy _ ; <nl> } <nl> <nl> - public void cancelPendingRanges ( ) <nl> - { <nl> - tokenMetadata _ . clearPendingRanges ( ) ; <nl> - } <nl> - <nl> public boolean isClientMode ( ) <nl> { <nl> return isClientMode ; <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> index c09802a . . f4404fb 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> @ @ - 141 , 13 + 141 , 6 @ @ public interface StorageServiceMBean <nl> public void loadBalance ( ) throws IOException , InterruptedException ; <nl> <nl> / * * <nl> - * cancel writes to nodes that are set to be changing ranges . <nl> - * Only do this if the reason for the range changes no longer exists <nl> - * ( e . g . , a bootstrapping node was killed or crashed . ) <nl> - * / <nl> - public void cancelPendingRanges ( ) ; <nl> - <nl> - / * * <nl> * removeToken removes token ( and all data associated with <nl> * enpoint that had it ) from the ring <nl> * / <nl> diff - - git a / src / java / org / apache / cassandra / tools / NodeProbe . java b / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> index cd87901 . . 0135eb7 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> + + + b / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> @ @ - 398 , 11 + 398 , 6 @ @ public class NodeProbe <nl> ssProxy . move ( newToken ) ; <nl> } <nl> <nl> - public void cancelPendingRanges ( ) <nl> - { <nl> - ssProxy . cancelPendingRanges ( ) ; <nl> - } <nl> - <nl> public void removeToken ( String token ) <nl> { <nl> ssProxy . removeToken ( token ) ; <nl> @ @ - 503 , 7 + 498 , 7 @ @ public class NodeProbe <nl> HelpFormatter hf = new HelpFormatter ( ) ; <nl> String header = String . format ( <nl> " % nAvailable commands : ring , info , cleanup , compact , cfstats , snapshot [ name ] , clearsnapshot , " + <nl> - " tpstats , flush , repair , decommission , move , loadbalance , cancelpending , removetoken , " + <nl> + " tpstats , flush , repair , decommission , move , loadbalance , removetoken , " + <nl> " getcompactionthreshold , setcompactionthreshold [ minthreshold ] ( [ maxthreshold ] ) " ) ; <nl> String usage = String . format ( " java % s - host < arg > < command > % n " , NodeProbe . class . getName ( ) ) ; <nl> hf . printHelp ( usage , " " , options , header ) ; <nl> @ @ - 578 , 10 + 573 , 6 @ @ public class NodeProbe <nl> } <nl> probe . move ( arguments [ 1 ] ) ; <nl> } <nl> - else if ( cmdName . equals ( " cancelpending " ) ) <nl> - { <nl> - probe . cancelPendingRanges ( ) ; <nl> - } <nl> else if ( cmdName . equals ( " removetoken " ) ) <nl> { <nl> if ( arguments . length < = 1 ) <nl> diff - - git a / test / unit / org / apache / cassandra / dht / BootStrapperTest . java b / test / unit / org / apache / cassandra / dht / BootStrapperTest . java <nl> index b9a5a82 . . c910685 100644 <nl> - - - a / test / unit / org / apache / cassandra / dht / BootStrapperTest . java <nl> + + + b / test / unit / org / apache / cassandra / dht / BootStrapperTest . java <nl> @ @ - 32 , 6 + 32 , 7 @ @ import org . junit . Test ; <nl> import com . google . common . collect . Multimap ; <nl> import org . apache . cassandra . gms . IFailureDetectionEventListener ; <nl> import org . apache . cassandra . gms . IFailureDetector ; <nl> + import org . apache . cassandra . gms . ApplicationState ; <nl> import org . apache . cassandra . locator . TokenMetadata ; <nl> import org . apache . cassandra . service . StorageService ; <nl> import org . apache . cassandra . utils . FBUtilities ; <nl> @ @ - 61 , 7 + 62 , 8 @ @ public class BootStrapperTest <nl> Range range3 = ss . getPrimaryRangeForEndPoint ( three ) ; <nl> Token fakeToken = ( ( IPartitioner ) StorageService . getPartitioner ( ) ) . midpoint ( range3 . left ( ) , range3 . right ( ) ) ; <nl> assert range3 . contains ( fakeToken ) ; <nl> - StorageService . updateBootstrapRanges ( StorageService . instance ( ) . getReplicationStrategy ( ) , tmd , fakeToken , myEndpoint ) ; <nl> + ss . onChange ( myEndpoint , StorageService . STATE _ BOOTSTRAPPING , new ApplicationState ( ss . getPartitioner ( ) . getTokenFactory ( ) . toString ( fakeToken ) ) ) ; <nl> + tmd = ss . getTokenMetadata ( ) ; <nl> <nl> InetAddress source2 = BootStrapper . getBootstrapSource ( tmd , load ) ; <nl> assert two . equals ( source2 ) : source2 ; <nl> @ @ - 124 , 7 + 126 , 7 @ @ public class BootStrapperTest <nl> for ( int i = 1 ; i < = numOldNodes ; i + + ) <nl> { <nl> / / leave . 1 for myEndpoint <nl> - tmd . update ( p . getRandomToken ( ) , InetAddress . getByName ( " 127 . 0 . 0 . " + ( i + 1 ) ) ) ; <nl> + tmd . updateNormalToken ( p . getRandomToken ( ) , InetAddress . getByName ( " 127 . 0 . 0 . " + ( i + 1 ) ) ) ; <nl> } <nl> } <nl> } <nl> \ No newline at end of file <nl> diff - - git a / test / unit / org / apache / cassandra / locator / RackUnawareStrategyTest . java b / test / unit / org / apache / cassandra / locator / RackUnawareStrategyTest . java <nl> index 9169f7d . . c0e6cd2 100644 <nl> - - - a / test / unit / org / apache / cassandra / locator / RackUnawareStrategyTest . java <nl> + + + b / test / unit / org / apache / cassandra / locator / RackUnawareStrategyTest . java <nl> @ @ - 79 , 7 + 79 , 7 @ @ public class RackUnawareStrategyTest <nl> for ( int i = 0 ; i < endPointTokens . length ; i + + ) <nl> { <nl> InetAddress ep = InetAddress . getByName ( " 127 . 0 . 0 . " + String . valueOf ( i + 1 ) ) ; <nl> - tmd . update ( endPointTokens [ i ] , ep ) ; <nl> + tmd . updateNormalToken ( endPointTokens [ i ] , ep ) ; <nl> hosts . add ( ep ) ; <nl> } <nl> <nl> @ @ - 114 , 15 + 114 , 16 @ @ public class RackUnawareStrategyTest <nl> for ( int i = 0 ; i < endPointTokens . length ; i + + ) <nl> { <nl> InetAddress ep = InetAddress . getByName ( " 127 . 0 . 0 . " + String . valueOf ( i + 1 ) ) ; <nl> - tmd . update ( endPointTokens [ i ] , ep ) ; <nl> + tmd . updateNormalToken ( endPointTokens [ i ] , ep ) ; <nl> hosts . add ( ep ) ; <nl> } <nl> <nl> / / Add bootstrap node id = 6 <nl> Token bsToken = new BigIntegerToken ( String . valueOf ( 25 ) ) ; <nl> InetAddress bootstrapEndPoint = InetAddress . getByName ( " 127 . 0 . 0 . 6 " ) ; <nl> - StorageService . updateBootstrapRanges ( strategy , tmd , bsToken , bootstrapEndPoint ) ; <nl> - <nl> + tmd . addBootstrapToken ( bsToken , bootstrapEndPoint ) ; <nl> + StorageService . calculatePendingRanges ( tmd , strategy ) ; <nl> + <nl> for ( int i = 0 ; i < keyTokens . length ; i + + ) <nl> { <nl> Collection < InetAddress > endPoints = strategy . getWriteEndpoints ( keyTokens [ i ] , strategy . getNaturalEndpoints ( keyTokens [ i ] ) ) ; <nl> @ @ - 136 , 6 + 137 , 8 @ @ public class RackUnawareStrategyTest <nl> / / for 5 , 15 , 25 this should include bootstrap node <nl> if ( i < 3 ) <nl> assertTrue ( endPoints . contains ( bootstrapEndPoint ) ) ; <nl> + else <nl> + assertFalse ( endPoints . contains ( bootstrapEndPoint ) ) ; <nl> } <nl> } <nl> }

TEST DIFF:
diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index 3482909 . . 355d710 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 2138 , 7 + 2138 , 6 @ @ public class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 assert data . getCompacting ( ) . isEmpty ( ) : data . getCompacting ( ) ; 
 Iterable < SSTableReader > sstables = getLiveSSTables ( ) ; 
 sstables = AbstractCompactionStrategy . filterSuspectSSTables ( sstables ) ; 
 - sstables = ImmutableList . copyOf ( sstables ) ; 
 LifecycleTransaction modifier = data . tryModify ( sstables , operationType ) ; 
 assert modifier ! = null : " something marked things compacting while compactions are disabled " ; 
 return modifier ; 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java 
 index 9f07691 . . 2348d19 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / AbstractCompactionStrategy . java 
 @ @ - 252 , 15 + 252 , 15 @ @ public abstract class AbstractCompactionStrategy 
 * @ param originalCandidates The collection to check for blacklisted SSTables 
 * @ return list of the SSTables with blacklisted ones filtered out 
 * / 
 - public static Iterable < SSTableReader > filterSuspectSSTables ( Iterable < SSTableReader > originalCandidates ) 
 + public static List < SSTableReader > filterSuspectSSTables ( Iterable < SSTableReader > originalCandidates ) 
 { 
 - return Iterables . filter ( originalCandidates , new Predicate < SSTableReader > ( ) 
 + List < SSTableReader > filtered = new ArrayList < > ( ) ; 
 + for ( SSTableReader sstable : originalCandidates ) 
 { 
 - public boolean apply ( SSTableReader sstable ) 
 - { 
 - return ! sstable . isMarkedSuspect ( ) ; 
 - } 
 - } ) ; 
 + if ( ! sstable . isMarkedSuspect ( ) ) 
 + filtered . add ( sstable ) ; 
 + } 
 + return filtered ; 
 } 
 
 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / DateTieredCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / DateTieredCompactionStrategy . java 
 index 3e6ae61 . . 7c38fa8 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / DateTieredCompactionStrategy . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / DateTieredCompactionStrategy . java 
 @ @ - 87 , 7 + 87 , 7 @ @ public class DateTieredCompactionStrategy extends AbstractCompactionStrategy 
 * @ param gcBefore 
 * @ return 
 * / 
 - private List < SSTableReader > getNextBackgroundSSTables ( final int gcBefore ) 
 + private synchronized List < SSTableReader > getNextBackgroundSSTables ( final int gcBefore ) 
 { 
 if ( Iterables . isEmpty ( cfs . getSSTables ( SSTableSet . LIVE ) ) ) 
 return Collections . emptyList ( ) ; 
 @ @ - 193 , 11 + 193 , 6 @ @ public class DateTieredCompactionStrategy extends AbstractCompactionStrategy 
 } ) ; 
 } 
 
 - / * * 
 - * 
 - * @ param sstables 
 - * @ return 
 - * / 
 public static List < Pair < SSTableReader , Long > > createSSTableAndMinTimestampPairs ( Iterable < SSTableReader > sstables ) 
 { 
 List < Pair < SSTableReader , Long > > sstableMinTimestampPairs = Lists . newArrayListWithCapacity ( Iterables . size ( sstables ) ) ; 
 @ @ - 205 , 14 + 200 , 15 @ @ public class DateTieredCompactionStrategy extends AbstractCompactionStrategy 
 sstableMinTimestampPairs . add ( Pair . create ( sstable , sstable . getMinTimestamp ( ) ) ) ; 
 return sstableMinTimestampPairs ; 
 } 
 + 
 @ Override 
 - public void addSSTable ( SSTableReader sstable ) 
 + public synchronized void addSSTable ( SSTableReader sstable ) 
 { 
 sstables . add ( sstable ) ; 
 } 
 
 @ Override 
 - public void removeSSTable ( SSTableReader sstable ) 
 + public synchronized void removeSSTable ( SSTableReader sstable ) 
 { 
 sstables . remove ( sstable ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java 
 index f8a8240 . . 80f5e8c 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / SizeTieredCompactionStrategy . java 
 @ @ - 74 , 7 + 74 , 7 @ @ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy 
 this . sizeTieredOptions = new SizeTieredCompactionStrategyOptions ( options ) ; 
 } 
 
 - private List < SSTableReader > getNextBackgroundSSTables ( final int gcBefore ) 
 + private synchronized List < SSTableReader > getNextBackgroundSSTables ( final int gcBefore ) 
 { 
 / / make local copies so they can ' t be changed out from under us mid - method 
 int minThreshold = cfs . getMinimumCompactionThreshold ( ) ; 
 @ @ - 190 , 7 + 190 , 7 @ @ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy 
 } 
 
 @ SuppressWarnings ( " resource " ) 
 - public Collection < AbstractCompactionTask > getMaximalTask ( final int gcBefore , boolean splitOutput ) 
 + public synchronized Collection < AbstractCompactionTask > getMaximalTask ( final int gcBefore , boolean splitOutput ) 
 { 
 Iterable < SSTableReader > filteredSSTables = filterSuspectSSTables ( sstables ) ; 
 if ( Iterables . isEmpty ( filteredSSTables ) ) 
 @ @ - 316 , 13 + 316 , 13 @ @ public class SizeTieredCompactionStrategy extends AbstractCompactionStrategy 
 } 
 
 @ Override 
 - public void addSSTable ( SSTableReader added ) 
 + public synchronized void addSSTable ( SSTableReader added ) 
 { 
 sstables . add ( added ) ; 
 } 
 
 @ Override 
 - public void removeSSTable ( SSTableReader sstable ) 
 + public synchronized void removeSSTable ( SSTableReader sstable ) 
 { 
 sstables . remove ( sstable ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / compaction / TimeWindowCompactionStrategy . java b / src / java / org / apache / cassandra / db / compaction / TimeWindowCompactionStrategy . java 
 index 8d26d0c . . c44d3aa 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / TimeWindowCompactionStrategy . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / TimeWindowCompactionStrategy . java 
 @ @ - 169 , 13 + 169 , 13 @ @ public class TimeWindowCompactionStrategy extends AbstractCompactionStrategy 
 } 
 
 @ Override 
 - public void addSSTable ( SSTableReader sstable ) 
 + public synchronized void addSSTable ( SSTableReader sstable ) 
 { 
 sstables . add ( sstable ) ; 
 } 
 
 @ Override 
 - public void removeSSTable ( SSTableReader sstable ) 
 + public synchronized void removeSSTable ( SSTableReader sstable ) 
 { 
 sstables . remove ( sstable ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / marshal / TypeParser . java b / src / java / org / apache / cassandra / db / marshal / TypeParser . java 
 index 35d15ab . . 590eea3 100644 
 - - - a / src / java / org / apache / cassandra / db / marshal / TypeParser . java 
 + + + b / src / java / org / apache / cassandra / db / marshal / TypeParser . java 
 @ @ - 23 , 6 + 23 , 9 @ @ import java . lang . reflect . Method ; 
 import java . nio . ByteBuffer ; 
 import java . util . * ; 
 
 + import com . google . common . base . Verify ; 
 + import com . google . common . collect . ImmutableMap ; 
 + 
 import org . apache . cassandra . exceptions . * ; 
 import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . apache . cassandra . utils . FBUtilities ; 
 @ @ - 37 , 7 + 40 , 7 @ @ public class TypeParser 
 private int idx ; 
 
 / / A cache of parsed string , specially useful for DynamicCompositeType 
 - private static final Map < String , AbstractType < ? > > cache = new HashMap < > ( ) ; 
 + private static volatile ImmutableMap < String , AbstractType < ? > > cache = ImmutableMap . of ( ) ; 
 
 public static final TypeParser EMPTY _ PARSER = new TypeParser ( " " , 0 ) ; 
 
 @ @ - 60 , 6 + 63 , 7 @ @ public class TypeParser 
 if ( str = = null ) 
 return BytesType . instance ; 
 
 + / / A single volatile read of ' cache ' should not hurt . 
 AbstractType < ? > type = cache . get ( str ) ; 
 
 if ( type ! = null ) 
 @ @ - 83 , 9 + 87 , 27 @ @ public class TypeParser 
 else 
 type = getAbstractType ( name ) ; 
 
 - / / We don ' t really care about concurrency here . Worst case scenario , we do some parsing unnecessarily 
 - cache . put ( str , type ) ; 
 - return type ; 
 + Verify . verify ( type ! = null , " Parsing % s yielded null , which is a bug " , str ) ; 
 + 
 + / / Prevent concurrent modification to the map acting as the cache for TypeParser at the expense of 
 + / / more allocation when the cache needs to be updated , since updates to the cache are rare compared 
 + / / to the amount of reads . 
 + / / 
 + / / Copy the existing cache into a new map and add the parsed AbstractType instance and replace 
 + / / the cache , if the type is not already in the cache . 
 + / / 
 + / / The cache - update is done in a short synchronized block to prevent duplicate instances of AbstractType 
 + / / for the same string representation . 
 + synchronized ( TypeParser . class ) 
 + { 
 + if ( ! cache . containsKey ( str ) ) 
 + { 
 + ImmutableMap . Builder < String , AbstractType < ? > > builder = ImmutableMap . builder ( ) ; 
 + builder . putAll ( cache ) . put ( str , type ) ; 
 + cache = builder . build ( ) ; 
 + } 
 + return type ; 
 + } 
 } 
 
 public static AbstractType < ? > parse ( CharSequence compareWith ) throws SyntaxException , ConfigurationException 
 diff - - git a / src / java / org / apache / cassandra / locator / NetworkTopologyStrategy . java b / src / java / org / apache / cassandra / locator / NetworkTopologyStrategy . java 
 index 7c8d95e . . 82183bb 100644 
 - - - a / src / java / org / apache / cassandra / locator / NetworkTopologyStrategy . java 
 + + + b / src / java / org / apache / cassandra / locator / NetworkTopologyStrategy . java 
 @ @ - 29 , 6 + 29 , 7 @ @ import org . apache . cassandra . dht . Token ; 
 import org . apache . cassandra . locator . TokenMetadata . Topology ; 
 import org . apache . cassandra . utils . FBUtilities ; 
 
 + import com . google . common . collect . ImmutableMultimap ; 
 import com . google . common . collect . Multimap ; 
 
 / * * 
 @ @ - 91 , 7 + 92 , 7 @ @ public class NetworkTopologyStrategy extends AbstractReplicationStrategy 
 / / all endpoints in each DC , so we can check when we have exhausted all the members of a DC 
 Multimap < String , InetAddress > allEndpoints = topology . getDatacenterEndpoints ( ) ; 
 / / all racks in a DC so we can check when we have exhausted all racks in a DC 
 - Map < String , Multimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; 
 + Map < String , ImmutableMultimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; 
 assert ! allEndpoints . isEmpty ( ) & & ! racks . isEmpty ( ) : " not aware of any cluster members " ; 
 
 / / tracks the racks we have already placed replicas in 
 diff - - git a / src / java / org / apache / cassandra / locator / TokenMetadata . java b / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 index b44a1a1 . . 3978eeb 100644 
 - - - a / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 + + + b / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 @ @ - 95 , 9 + 95 , 10 @ @ public class TokenMetadata 
 
 / * Use this lock for manipulating the token map * / 
 private final ReadWriteLock lock = new ReentrantReadWriteLock ( true ) ; 
 - private volatile ArrayList < Token > sortedTokens ; 
 + private volatile ArrayList < Token > sortedTokens ; / / safe to be read without a lock , as it ' s never mutated 
 + 
 + private volatile Topology topology ; 
 
 - private final Topology topology ; 
 public final IPartitioner partitioner ; 
 
 private static final Comparator < InetAddress > inetaddressCmp = new Comparator < InetAddress > ( ) 
 @ @ - 115 , 7 + 116 , 7 @ @ public class TokenMetadata 
 { 
 this ( SortedBiMultiValMap . < Token , InetAddress > create ( null , inetaddressCmp ) , 
 HashBiMap . < InetAddress , UUID > create ( ) , 
 - new Topology ( ) , 
 + Topology . empty ( ) , 
 DatabaseDescriptor . getPartitioner ( ) ) ; 
 } 
 
 @ @ - 193 , 6 + 194 , 7 @ @ public class TokenMetadata 
 try 
 { 
 boolean shouldSortTokens = false ; 
 + Topology . Builder topologyBuilder = topology . unbuild ( ) ; 
 for ( InetAddress endpoint : endpointTokens . keySet ( ) ) 
 { 
 Collection < Token > tokens = endpointTokens . get ( endpoint ) ; 
 @ @ - 201 , 7 + 203 , 7 @ @ public class TokenMetadata 
 
 bootstrapTokens . removeValue ( endpoint ) ; 
 tokenToEndpointMap . removeValue ( endpoint ) ; 
 - topology . addEndpoint ( endpoint ) ; 
 + topologyBuilder . addEndpoint ( endpoint ) ; 
 leavingEndpoints . remove ( endpoint ) ; 
 replacementToOriginal . remove ( endpoint ) ; 
 removeFromMoving ( endpoint ) ; / / also removing this endpoint from moving 
 @ @ - 217 , 6 + 219 , 7 @ @ public class TokenMetadata 
 } 
 } 
 } 
 + topology = topologyBuilder . build ( ) ; 
 
 if ( shouldSortTokens ) 
 sortedTokens = sortTokens ( ) ; 
 @ @ - 381 , 12 + 384 , 28 @ @ public class TokenMetadata 
 
 public Optional < InetAddress > getReplacementNode ( InetAddress endpoint ) 
 { 
 - return Optional . ofNullable ( replacementToOriginal . inverse ( ) . get ( endpoint ) ) ; 
 + lock . readLock ( ) . lock ( ) ; 
 + try 
 + { 
 + return Optional . ofNullable ( replacementToOriginal . inverse ( ) . get ( endpoint ) ) ; 
 + } 
 + finally 
 + { 
 + lock . readLock ( ) . unlock ( ) ; 
 + } 
 } 
 
 public Optional < InetAddress > getReplacingNode ( InetAddress endpoint ) 
 { 
 - return Optional . ofNullable ( ( replacementToOriginal . get ( endpoint ) ) ) ; 
 + lock . readLock ( ) . lock ( ) ; 
 + try 
 + { 
 + return Optional . ofNullable ( ( replacementToOriginal . get ( endpoint ) ) ) ; 
 + } 
 + finally 
 + { 
 + lock . readLock ( ) . unlock ( ) ; 
 + } 
 } 
 
 public void removeBootstrapTokens ( Collection < Token > tokens ) 
 @ @ - 430 , 7 + 449 , 6 @ @ public class TokenMetadata 
 assert endpoint ! = null ; 
 
 lock . writeLock ( ) . lock ( ) ; 
 - 
 try 
 { 
 movingEndpoints . add ( Pair . create ( token , endpoint ) ) ; 
 @ @ - 450 , 7 + 468 , 7 @ @ public class TokenMetadata 
 { 
 bootstrapTokens . removeValue ( endpoint ) ; 
 tokenToEndpointMap . removeValue ( endpoint ) ; 
 - topology . removeEndpoint ( endpoint ) ; 
 + topology = topology . unbuild ( ) . removeEndpoint ( endpoint ) . build ( ) ; 
 leavingEndpoints . remove ( endpoint ) ; 
 if ( replacementToOriginal . remove ( endpoint ) ! = null ) 
 { 
 @ @ - 469 , 7 + 487 , 7 @ @ public class TokenMetadata 
 / * * 
 * This is called when the snitch properties for this endpoint are updated , see CASSANDRA - 10238 . 
 * / 
 - public void updateTopology ( InetAddress endpoint ) 
 + public Topology updateTopology ( InetAddress endpoint ) 
 { 
 assert endpoint ! = null ; 
 
 @ @ - 477 , 8 + 495 , 9 @ @ public class TokenMetadata 
 try 
 { 
 logger . info ( " Updating topology for { } " , endpoint ) ; 
 - topology . updateEndpoint ( endpoint ) ; 
 + topology = topology . unbuild ( ) . updateEndpoint ( endpoint ) . build ( ) ; 
 invalidateCachedRings ( ) ; 
 + return topology ; 
 } 
 finally 
 { 
 @ @ - 490 , 14 + 509 , 15 @ @ public class TokenMetadata 
 * This is called when the snitch properties for many endpoints are updated , it will update 
 * the topology mappings of any endpoints whose snitch has changed , see CASSANDRA - 10238 . 
 * / 
 - public void updateTopology ( ) 
 + public Topology updateTopology ( ) 
 { 
 lock . writeLock ( ) . lock ( ) ; 
 try 
 { 
 logger . info ( " Updating topology for all endpoints that have changed " ) ; 
 - topology . updateEndpoints ( ) ; 
 + topology = topology . unbuild ( ) . updateEndpoints ( ) . build ( ) ; 
 invalidateCachedRings ( ) ; 
 + return topology ; 
 } 
 finally 
 { 
 @ @ - 590 , 7 + 610 , 6 @ @ public class TokenMetadata 
 assert endpoint ! = null ; 
 
 lock . readLock ( ) . lock ( ) ; 
 - 
 try 
 { 
 for ( Pair < Token , InetAddress > pair : movingEndpoints ) 
 @ @ - 620 , 7 + 639 , 7 @ @ public class TokenMetadata 
 { 
 return new TokenMetadata ( SortedBiMultiValMap . create ( tokenToEndpointMap , null , inetaddressCmp ) , 
 HashBiMap . create ( endpointToHostIdMap ) , 
 - new Topology ( topology ) , 
 + topology , 
 partitioner ) ; 
 } 
 finally 
 @ @ - 690 , 7 + 709 , 6 @ @ public class TokenMetadata 
 public TokenMetadata cloneAfterAllSettled ( ) 
 { 
 lock . readLock ( ) . lock ( ) ; 
 - 
 try 
 { 
 TokenMetadata metadata = cloneOnlyTokenMap ( ) ; 
 @ @ - 807 , 50 + 825 , 49 @ @ public class TokenMetadata 
 public void calculatePendingRanges ( AbstractReplicationStrategy strategy , String keyspaceName ) 
 { 
 / / avoid race between both branches - do not use a lock here as this will block any other unrelated operations ! 
 + long startedAt = System . currentTimeMillis ( ) ; 
 synchronized ( pendingRanges ) 
 { 
 - if ( bootstrapTokens . isEmpty ( ) & & leavingEndpoints . isEmpty ( ) & & movingEndpoints . isEmpty ( ) ) 
 - { 
 - if ( logger . isTraceEnabled ( ) ) 
 - logger . trace ( " No bootstrapping , leaving or moving nodes - > empty pending ranges for { } " , keyspaceName ) ; 
 + / / create clone of current state 
 + BiMultiValMap < Token , InetAddress > bootstrapTokensClone ; 
 + Set < InetAddress > leavingEndpointsClone ; 
 + Set < Pair < Token , InetAddress > > movingEndpointsClone ; 
 + TokenMetadata metadata ; 
 
 - pendingRanges . put ( keyspaceName , new PendingRangeMaps ( ) ) ; 
 - } 
 - else 
 + lock . readLock ( ) . lock ( ) ; 
 + try 
 { 
 - if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " Starting pending range calculation for { } " , keyspaceName ) ; 
 - 
 - long startedAt = System . currentTimeMillis ( ) ; 
 + if ( bootstrapTokens . isEmpty ( ) & & leavingEndpoints . isEmpty ( ) & & movingEndpoints . isEmpty ( ) ) 
 + { 
 + if ( logger . isTraceEnabled ( ) ) 
 + logger . trace ( " No bootstrapping , leaving or moving nodes - > empty pending ranges for { } " , keyspaceName ) ; 
 
 - / / create clone of current state 
 - BiMultiValMap < Token , InetAddress > bootstrapTokens = new BiMultiValMap < > ( ) ; 
 - Set < InetAddress > leavingEndpoints = new HashSet < > ( ) ; 
 - Set < Pair < Token , InetAddress > > movingEndpoints = new HashSet < > ( ) ; 
 - TokenMetadata metadata ; 
 + pendingRanges . put ( keyspaceName , new PendingRangeMaps ( ) ) ; 
 
 - lock . readLock ( ) . lock ( ) ; 
 - try 
 - { 
 - bootstrapTokens . putAll ( this . bootstrapTokens ) ; 
 - leavingEndpoints . addAll ( this . leavingEndpoints ) ; 
 - movingEndpoints . addAll ( this . movingEndpoints ) ; 
 - metadata = this . cloneOnlyTokenMap ( ) ; 
 - } 
 - finally 
 - { 
 - lock . readLock ( ) . unlock ( ) ; 
 + return ; 
 } 
 
 - pendingRanges . put ( keyspaceName , calculatePendingRanges ( strategy , metadata , bootstrapTokens , 
 - leavingEndpoints , movingEndpoints ) ) ; 
 - long took = System . currentTimeMillis ( ) - startedAt ; 
 - 
 if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " Pending range calculation for { } completed ( took : { } ms ) " , keyspaceName , took ) ; 
 - if ( logger . isTraceEnabled ( ) ) 
 - logger . trace ( " Calculated pending ranges for { } : \ n { } " , keyspaceName , ( pendingRanges . isEmpty ( ) ? " < empty > " : printPendingRanges ( ) ) ) ; 
 + logger . debug ( " Starting pending range calculation for { } " , keyspaceName ) ; 
 + 
 + bootstrapTokensClone = new BiMultiValMap < > ( this . bootstrapTokens ) ; 
 + leavingEndpointsClone = new HashSet < > ( this . leavingEndpoints ) ; 
 + movingEndpointsClone = new HashSet < > ( this . movingEndpoints ) ; 
 + metadata = this . cloneOnlyTokenMap ( ) ; 
 } 
 + finally 
 + { 
 + lock . readLock ( ) . unlock ( ) ; 
 + } 
 + 
 + pendingRanges . put ( keyspaceName , calculatePendingRanges ( strategy , metadata , bootstrapTokensClone , 
 + leavingEndpointsClone , movingEndpointsClone ) ) ; 
 + long took = System . currentTimeMillis ( ) - startedAt ; 
 + 
 + if ( logger . isDebugEnabled ( ) ) 
 + logger . debug ( " Pending range calculation for { } completed ( took : { } ms ) " , keyspaceName , took ) ; 
 + if ( logger . isTraceEnabled ( ) ) 
 + logger . trace ( " Calculated pending ranges for { } : \ n { } " , keyspaceName , ( pendingRanges . isEmpty ( ) ? " < empty > " : printPendingRanges ( ) ) ) ; 
 } 
 } 
 
 @ @ - 960 , 7 + 977 , 7 @ @ public class TokenMetadata 
 { 
 List tokens = sortedTokens ( ) ; 
 int index = Collections . binarySearch ( tokens , token ) ; 
 - assert index > = 0 : token + " not found in " + StringUtils . join ( tokenToEndpointMap . keySet ( ) , " , " ) ; 
 + assert index > = 0 : token + " not found in " + tokenToEndpointMapKeysAsStrings ( ) ; 
 return ( Token ) ( index = = 0 ? tokens . get ( tokens . size ( ) - 1 ) : tokens . get ( index - 1 ) ) ; 
 } 
 
 @ @ - 968 , 17 + 985 , 30 @ @ public class TokenMetadata 
 { 
 List tokens = sortedTokens ( ) ; 
 int index = Collections . binarySearch ( tokens , token ) ; 
 - assert index > = 0 : token + " not found in " + StringUtils . join ( tokenToEndpointMap . keySet ( ) , " , " ) ; 
 + assert index > = 0 : token + " not found in " + tokenToEndpointMapKeysAsStrings ( ) ; 
 return ( Token ) ( ( index = = ( tokens . size ( ) - 1 ) ) ? tokens . get ( 0 ) : tokens . get ( index + 1 ) ) ; 
 } 
 
 + private String tokenToEndpointMapKeysAsStrings ( ) 
 + { 
 + lock . readLock ( ) . lock ( ) ; 
 + try 
 + { 
 + return StringUtils . join ( tokenToEndpointMap . keySet ( ) , " , " ) ; 
 + } 
 + finally 
 + { 
 + lock . readLock ( ) . unlock ( ) ; 
 + } 
 + } 
 + 
 / * * @ return a copy of the bootstrapping tokens map * / 
 public BiMultiValMap < Token , InetAddress > getBootstrapTokens ( ) 
 { 
 lock . readLock ( ) . lock ( ) ; 
 try 
 { 
 - return new BiMultiValMap < Token , InetAddress > ( bootstrapTokens ) ; 
 + return new BiMultiValMap < > ( bootstrapTokens ) ; 
 } 
 finally 
 { 
 @ @ - 1103 , 7 + 1133 , 7 @ @ public class TokenMetadata 
 pendingRanges . clear ( ) ; 
 movingEndpoints . clear ( ) ; 
 sortedTokens . clear ( ) ; 
 - topology . clear ( ) ; 
 + topology = Topology . empty ( ) ; 
 invalidateCachedRings ( ) ; 
 } 
 finally 
 @ @ - 1271 , 130 + 1301 , 170 @ @ public class TokenMetadata 
 public static class Topology 
 { 
 / * * multi - map of DC to endpoints in that DC * / 
 - private final Multimap < String , InetAddress > dcEndpoints ; 
 + private final ImmutableMultimap < String , InetAddress > dcEndpoints ; 
 / * * map of DC to multi - map of rack to endpoints in that rack * / 
 - private final Map < String , Multimap < String , InetAddress > > dcRacks ; 
 + private final ImmutableMap < String , ImmutableMultimap < String , InetAddress > > dcRacks ; 
 / * * reverse - lookup map for endpoint to current known dc / rack assignment * / 
 - private final Map < InetAddress , Pair < String , String > > currentLocations ; 
 + private final ImmutableMap < InetAddress , Pair < String , String > > currentLocations ; 
 
 - Topology ( ) 
 + private Topology ( Builder builder ) 
 { 
 - dcEndpoints = HashMultimap . create ( ) ; 
 - dcRacks = new HashMap < > ( ) ; 
 - currentLocations = new HashMap < > ( ) ; 
 - } 
 + this . dcEndpoints = ImmutableMultimap . copyOf ( builder . dcEndpoints ) ; 
 
 - void clear ( ) 
 - { 
 - dcEndpoints . clear ( ) ; 
 - dcRacks . clear ( ) ; 
 - currentLocations . clear ( ) ; 
 + ImmutableMap . Builder < String , ImmutableMultimap < String , InetAddress > > dcRackBuilder = ImmutableMap . builder ( ) ; 
 + for ( Map . Entry < String , Multimap < String , InetAddress > > entry : builder . dcRacks . entrySet ( ) ) 
 + dcRackBuilder . put ( entry . getKey ( ) , ImmutableMultimap . copyOf ( entry . getValue ( ) ) ) ; 
 + this . dcRacks = dcRackBuilder . build ( ) ; 
 + 
 + this . currentLocations = ImmutableMap . copyOf ( builder . currentLocations ) ; 
 } 
 
 / * * 
 - * construct deep - copy of other 
 + * @ return multi - map of DC to endpoints in that DC 
 * / 
 - Topology ( Topology other ) 
 + public Multimap < String , InetAddress > getDatacenterEndpoints ( ) 
 { 
 - dcEndpoints = HashMultimap . create ( other . dcEndpoints ) ; 
 - dcRacks = new HashMap < > ( ) ; 
 - for ( String dc : other . dcRacks . keySet ( ) ) 
 - dcRacks . put ( dc , HashMultimap . create ( other . dcRacks . get ( dc ) ) ) ; 
 - currentLocations = new HashMap < > ( other . currentLocations ) ; 
 + return dcEndpoints ; 
 } 
 
 / * * 
 - * Stores current DC / rack assignment for ep 
 + * @ return map of DC to multi - map of rack to endpoints in that rack 
 * / 
 - void addEndpoint ( InetAddress ep ) 
 + public ImmutableMap < String , ImmutableMultimap < String , InetAddress > > getDatacenterRacks ( ) 
 { 
 - IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; 
 - String dc = snitch . getDatacenter ( ep ) ; 
 - String rack = snitch . getRack ( ep ) ; 
 - Pair < String , String > current = currentLocations . get ( ep ) ; 
 - if ( current ! = null ) 
 - { 
 - if ( current . left . equals ( dc ) & & current . right . equals ( rack ) ) 
 - return ; 
 - doRemoveEndpoint ( ep , current ) ; 
 - } 
 - 
 - doAddEndpoint ( ep , dc , rack ) ; 
 + return dcRacks ; 
 } 
 
 - private void doAddEndpoint ( InetAddress ep , String dc , String rack ) 
 + Builder unbuild ( ) 
 { 
 - dcEndpoints . put ( dc , ep ) ; 
 - 
 - if ( ! dcRacks . containsKey ( dc ) ) 
 - dcRacks . put ( dc , HashMultimap . < String , InetAddress > create ( ) ) ; 
 - dcRacks . get ( dc ) . put ( rack , ep ) ; 
 - 
 - currentLocations . put ( ep , Pair . create ( dc , rack ) ) ; 
 + return new Builder ( this ) ; 
 } 
 
 - / * * 
 - * Removes current DC / rack assignment for ep 
 - * / 
 - void removeEndpoint ( InetAddress ep ) 
 + static Builder builder ( ) 
 { 
 - if ( ! currentLocations . containsKey ( ep ) ) 
 - return ; 
 - 
 - doRemoveEndpoint ( ep , currentLocations . remove ( ep ) ) ; 
 + return new Builder ( ) ; 
 } 
 
 - private void doRemoveEndpoint ( InetAddress ep , Pair < String , String > current ) 
 + static Topology empty ( ) 
 { 
 - dcRacks . get ( current . left ) . remove ( current . right , ep ) ; 
 - dcEndpoints . remove ( current . left , ep ) ; 
 + return builder ( ) . build ( ) ; 
 } 
 
 - void updateEndpoint ( InetAddress ep ) 
 + private static class Builder 
 { 
 - IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; 
 - if ( snitch = = null | | ! currentLocations . containsKey ( ep ) ) 
 - return ; 
 + / * * multi - map of DC to endpoints in that DC * / 
 + private final Multimap < String , InetAddress > dcEndpoints ; 
 + / * * map of DC to multi - map of rack to endpoints in that rack * / 
 + private final Map < String , Multimap < String , InetAddress > > dcRacks ; 
 + / * * reverse - lookup map for endpoint to current known dc / rack assignment * / 
 + private final Map < InetAddress , Pair < String , String > > currentLocations ; 
 
 - updateEndpoint ( ep , snitch ) ; 
 - } 
 + Builder ( ) 
 + { 
 + this . dcEndpoints = HashMultimap . create ( ) ; 
 + this . dcRacks = new HashMap < > ( ) ; 
 + this . currentLocations = new HashMap < > ( ) ; 
 + } 
 
 - void updateEndpoints ( ) 
 - { 
 - IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; 
 - if ( snitch = = null ) 
 - return ; 
 + Builder ( Topology from ) 
 + { 
 + this . dcEndpoints = HashMultimap . create ( from . dcEndpoints ) ; 
 + 
 + this . dcRacks = Maps . newHashMapWithExpectedSize ( from . dcRacks . size ( ) ) ; 
 + for ( Map . Entry < String , ImmutableMultimap < String , InetAddress > > entry : from . dcRacks . entrySet ( ) ) 
 + dcRacks . put ( entry . getKey ( ) , HashMultimap . create ( entry . getValue ( ) ) ) ; 
 + 
 + this . currentLocations = new HashMap < > ( from . currentLocations ) ; 
 + } 
 + 
 + / * * 
 + * Stores current DC / rack assignment for ep 
 + * / 
 + Builder addEndpoint ( InetAddress ep ) 
 + { 
 + IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; 
 + String dc = snitch . getDatacenter ( ep ) ; 
 + String rack = snitch . getRack ( ep ) ; 
 + Pair < String , String > current = currentLocations . get ( ep ) ; 
 + if ( current ! = null ) 
 + { 
 + if ( current . left . equals ( dc ) & & current . right . equals ( rack ) ) 
 + return this ; 
 + doRemoveEndpoint ( ep , current ) ; 
 + } 
 + 
 + doAddEndpoint ( ep , dc , rack ) ; 
 + return this ; 
 + } 
 + 
 + private void doAddEndpoint ( InetAddress ep , String dc , String rack ) 
 + { 
 + dcEndpoints . put ( dc , ep ) ; 
 + 
 + if ( ! dcRacks . containsKey ( dc ) ) 
 + dcRacks . put ( dc , HashMultimap . < String , InetAddress > create ( ) ) ; 
 + dcRacks . get ( dc ) . put ( rack , ep ) ; 
 + 
 + currentLocations . put ( ep , Pair . create ( dc , rack ) ) ; 
 + } 
 + 
 + / * * 
 + * Removes current DC / rack assignment for ep 
 + * / 
 + Builder removeEndpoint ( InetAddress ep ) 
 + { 
 + if ( ! currentLocations . containsKey ( ep ) ) 
 + return this ; 
 + 
 + doRemoveEndpoint ( ep , currentLocations . remove ( ep ) ) ; 
 + return this ; 
 + } 
 + 
 + private void doRemoveEndpoint ( InetAddress ep , Pair < String , String > current ) 
 + { 
 + dcRacks . get ( current . left ) . remove ( current . right , ep ) ; 
 + dcEndpoints . remove ( current . left , ep ) ; 
 + } 
 + 
 + Builder updateEndpoint ( InetAddress ep ) 
 + { 
 + IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; 
 + if ( snitch = = null | | ! currentLocations . containsKey ( ep ) ) 
 + return this ; 
 
 - for ( InetAddress ep : currentLocations . keySet ( ) ) 
 updateEndpoint ( ep , snitch ) ; 
 - } 
 + return this ; 
 + } 
 
 - private void updateEndpoint ( InetAddress ep , IEndpointSnitch snitch ) 
 - { 
 - Pair < String , String > current = currentLocations . get ( ep ) ; 
 - String dc = snitch . getDatacenter ( ep ) ; 
 - String rack = snitch . getRack ( ep ) ; 
 - if ( dc . equals ( current . left ) & & rack . equals ( current . right ) ) 
 - return ; 
 + Builder updateEndpoints ( ) 
 + { 
 + IEndpointSnitch snitch = DatabaseDescriptor . getEndpointSnitch ( ) ; 
 + if ( snitch = = null ) 
 + return this ; 
 
 - doRemoveEndpoint ( ep , current ) ; 
 - doAddEndpoint ( ep , dc , rack ) ; 
 - } 
 + for ( InetAddress ep : currentLocations . keySet ( ) ) 
 + updateEndpoint ( ep , snitch ) ; 
 
 - / * * 
 - * @ return multi - map of DC to endpoints in that DC 
 - * / 
 - public Multimap < String , InetAddress > getDatacenterEndpoints ( ) 
 - { 
 - return dcEndpoints ; 
 - } 
 + return this ; 
 + } 
 
 - / * * 
 - * @ return map of DC to multi - map of rack to endpoints in that rack 
 - * / 
 - public Map < String , Multimap < String , InetAddress > > getDatacenterRacks ( ) 
 - { 
 - return dcRacks ; 
 + private void updateEndpoint ( InetAddress ep , IEndpointSnitch snitch ) 
 + { 
 + Pair < String , String > current = currentLocations . get ( ep ) ; 
 + String dc = snitch . getDatacenter ( ep ) ; 
 + String rack = snitch . getRack ( ep ) ; 
 + if ( dc . equals ( current . left ) & & rack . equals ( current . right ) ) 
 + return ; 
 + 
 + doRemoveEndpoint ( ep , current ) ; 
 + doAddEndpoint ( ep , dc , rack ) ; 
 + } 
 + 
 + Topology build ( ) 
 + { 
 + return new Topology ( this ) ; 
 + } 
 } 
 + 
 } 
 } 
 diff - - git a / test / unit / org / apache / cassandra / locator / TokenMetadataTest . java b / test / unit / org / apache / cassandra / locator / TokenMetadataTest . java 
 index e7bb70a . . dab7082 100644 
 - - - a / test / unit / org / apache / cassandra / locator / TokenMetadataTest . java 
 + + + b / test / unit / org / apache / cassandra / locator / TokenMetadataTest . java 
 @ @ - 22 , 6 + 22 , 7 @ @ import java . net . UnknownHostException ; 
 import java . util . ArrayList ; 
 import java . util . Map ; 
 
 + import com . google . common . collect . ImmutableMultimap ; 
 import com . google . common . collect . Iterators ; 
 import com . google . common . collect . Multimap ; 
 
 @ @ - 29 , 18 + 30 , 18 @ @ import org . junit . BeforeClass ; 
 import org . junit . Test ; 
 import org . junit . runner . RunWith ; 
 
 - import static junit . framework . Assert . assertNotNull ; 
 - import static org . junit . Assert . assertEquals ; 
 - 
 - import static org . apache . cassandra . Util . token ; 
 - import static org . junit . Assert . assertFalse ; 
 - import static org . junit . Assert . assertTrue ; 
 - 
 import org . apache . cassandra . OrderedJUnit4ClassRunner ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . dht . Token ; 
 import org . apache . cassandra . service . StorageService ; 
 
 + import static org . junit . Assert . assertEquals ; 
 + import static org . junit . Assert . assertNotNull ; 
 + import static org . junit . Assert . assertFalse ; 
 + import static org . junit . Assert . assertTrue ; 
 + 
 + import static org . apache . cassandra . Util . token ; 
 + 
 
 @ RunWith ( OrderedJUnit4ClassRunner . class ) 
 public class TokenMetadataTest 
 @ @ - 139 , 7 + 140 , 7 @ @ public class TokenMetadataTest 
 assertTrue ( allEndpoints . get ( DATA _ CENTER ) . contains ( first ) ) ; 
 assertTrue ( allEndpoints . get ( DATA _ CENTER ) . contains ( second ) ) ; 
 
 - Map < String , Multimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; 
 + Map < String , ImmutableMultimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; 
 assertNotNull ( racks ) ; 
 assertTrue ( racks . size ( ) = = 1 ) ; 
 assertTrue ( racks . containsKey ( DATA _ CENTER ) ) ; 
 @ @ - 171 , 7 + 172 , 7 @ @ public class TokenMetadataTest 
 } ) ; 
 
 tokenMetadata . updateTopology ( first ) ; 
 - tokenMetadata . updateTopology ( second ) ; 
 + topology = tokenMetadata . updateTopology ( second ) ; 
 
 allEndpoints = topology . getDatacenterEndpoints ( ) ; 
 assertNotNull ( allEndpoints ) ; 
 @ @ - 237 , 7 + 238 , 7 @ @ public class TokenMetadataTest 
 assertTrue ( allEndpoints . get ( DATA _ CENTER ) . contains ( first ) ) ; 
 assertTrue ( allEndpoints . get ( DATA _ CENTER ) . contains ( second ) ) ; 
 
 - Map < String , Multimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; 
 + Map < String , ImmutableMultimap < String , InetAddress > > racks = topology . getDatacenterRacks ( ) ; 
 assertNotNull ( racks ) ; 
 assertTrue ( racks . size ( ) = = 1 ) ; 
 assertTrue ( racks . containsKey ( DATA _ CENTER ) ) ; 
 @ @ - 268 , 7 + 269 , 7 @ @ public class TokenMetadataTest 
 } 
 } ) ; 
 
 - tokenMetadata . updateTopology ( ) ; 
 + topology = tokenMetadata . updateTopology ( ) ; 
 
 allEndpoints = topology . getDatacenterEndpoints ( ) ; 
 assertNotNull ( allEndpoints ) ;

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 9edb36d . . 73a6717 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 2 , 6 + 2 , 10 @ @ 
 * Fix potential NPE in get _ range _ slice ( CASSANDRA - 623 ) 
 * add CRC32 to commitlog entries ( CASSANDRA - 605 ) 
 * fix data streaming on windows ( CASSANDRA - 630 ) 
 + * GC compacted sstables after cleanup and compaction ( CASSANDRA - 621 ) 
 + * Speed up anti - entropy validation ( CASSANDRA - 629 ) 
 + * Fix pending range conflicts when bootstapping or moving 
 + multiple nodes at once ( CASSANDRA - 603 ) 
 
 
 0 . 5 . 0 beta 2 
 diff - - git a / NEWS . txt b / NEWS . txt 
 index 108dd5d . . 966c7e9 100644 
 - - - a / NEWS . txt 
 + + + b / NEWS . txt 
 @ @ - 8 , 6 + 8 , 10 @ @ 
 out ; if that happens , just go back to 0 . 4 and flush again . ) 
 The format changed twice : from 0 . 4 to beta1 , and from beta2 to RC1 . 
 
 + . 5 The gossip protocol has changed , meaning 0 . 5 nodes cannot coexist 
 + in a cluster of 0 . 4 nodes or vice versa ; you must upgrade your 
 + whole cluster at the same time . 
 + 
 1 . Bootstrap , move , load balancing , and active repair have been added . 
 See http : / / wiki . apache . org / cassandra / Operations . When upgrading 
 from 0 . 4 , leave autobootstrap set to false for the first restart 
 diff - - git a / src / java / org / apache / cassandra / locator / AbstractReplicationStrategy . java b / src / java / org / apache / cassandra / locator / AbstractReplicationStrategy . java 
 index aa5f8fd . . fb2b480 100644 
 - - - a / src / java / org / apache / cassandra / locator / AbstractReplicationStrategy . java 
 + + + b / src / java / org / apache / cassandra / locator / AbstractReplicationStrategy . java 
 @ @ - 91 , 11 + 91 , 11 @ @ public abstract class AbstractReplicationStrategy 
 
 List < InetAddress > endpoints = new ArrayList < InetAddress > ( naturalEndpoints ) ; 
 
 - for ( Map . Entry < Range , InetAddress > entry : tokenMetadata _ . getPendingRanges ( ) . entrySet ( ) ) 
 + for ( Map . Entry < Range , Collection < InetAddress > > entry : tokenMetadata _ . getPendingRanges ( ) . entrySet ( ) ) 
 { 
 if ( entry . getKey ( ) . contains ( token ) ) 
 { 
 - endpoints . add ( entry . getValue ( ) ) ; 
 + endpoints . addAll ( entry . getValue ( ) ) ; 
 } 
 } 
 
 @ @ - 202 , 26 + 202 , 9 @ @ public abstract class AbstractReplicationStrategy 
 
 public Collection < Range > getPendingAddressRanges ( TokenMetadata metadata , Token pendingToken , InetAddress pendingAddress ) 
 { 
 - TokenMetadata temp = metadata . cloneWithoutPending ( ) ; 
 - temp . update ( pendingToken , pendingAddress ) ; 
 + TokenMetadata temp = metadata . cloneOnlyTokenMap ( ) ; 
 + temp . updateNormalToken ( pendingToken , pendingAddress ) ; 
 return getAddressRanges ( temp ) . get ( pendingAddress ) ; 
 } 
 
 - public void removeObsoletePendingRanges ( ) 
 - { 
 - Multimap < InetAddress , Range > ranges = getAddressRanges ( ) ; 
 - for ( Map . Entry < Range , InetAddress > entry : tokenMetadata _ . getPendingRanges ( ) . entrySet ( ) ) 
 - { 
 - for ( Range currentRange : ranges . get ( entry . getValue ( ) ) ) 
 - { 
 - if ( currentRange . contains ( entry . getKey ( ) ) ) 
 - { 
 - if ( logger _ . isDebugEnabled ( ) ) 
 - logger _ . debug ( " Removing obsolete pending range " + entry . getKey ( ) + " from " + entry . getValue ( ) ) ; 
 - tokenMetadata _ . removePendingRange ( entry . getKey ( ) ) ; 
 - break ; 
 - } 
 - } 
 - } 
 - } 
 } 
 diff - - git a / src / java / org / apache / cassandra / locator / TokenMetadata . java b / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 index 771ce2f . . 924e4d5 100644 
 - - - a / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 + + + b / src / java / org / apache / cassandra / locator / TokenMetadata . java 
 @ @ - 29 , 15 + 29 , 33 @ @ import java . net . InetAddress ; 
 
 import org . apache . commons . lang . StringUtils ; 
 
 - import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; 
 import com . google . common . collect . BiMap ; 
 import com . google . common . collect . HashBiMap ; 
 + import com . google . common . collect . Multimap ; 
 + import com . google . common . collect . HashMultimap ; 
 
 public class TokenMetadata 
 { 
 / * Maintains token to endpoint map of every node in the cluster . * / 
 private BiMap < Token , InetAddress > tokenToEndPointMap ; 
 - private Map < Range , InetAddress > pendingRanges ; 
 + 
 + / / Suppose that there is a ring of nodes A , C and E , with replication factor 3 . 
 + / / Node D bootstraps between C and E , so its pending ranges will be E - A , A - C and C - D . 
 + / / Now suppose node B bootstraps between A and C at the same time . Its pending ranges would be C - E , E - A and A - B . 
 + / / Now both nodes have pending range E - A in their list , which will cause pending range collision 
 + / / even though we ' re only talking about replica range , not even primary range . The same thing happens 
 + / / for any nodes that boot simultaneously between same two nodes . For this we cannot simply make pending ranges a multimap , 
 + / / since that would make us unable to notice the real problem of two nodes trying to boot using the same token . 
 + / / In order to do this properly , we need to know what tokens are booting at any time . 
 + private Map < Token , InetAddress > bootstrapTokens ; 
 + 
 + / / we will need to know at all times what nodes are leaving and calculate ranges accordingly . 
 + / / An anonymous pending ranges list is not enough , as that does not tell which node is leaving 
 + / / and / or if the ranges are there because of bootstrap or leave operation . 
 + / / ( See CASSANDRA - 603 for more detail + examples ) . 
 + private Set < InetAddress > leavingEndPoints ; 
 + 
 + private Multimap < Range , InetAddress > pendingRanges ; 
 
 / * Use this lock for manipulating the token map * / 
 private final ReadWriteLock lock = new ReentrantReadWriteLock ( true ) ; 
 @ @ - 53 , 7 + 71 , 9 @ @ public class TokenMetadata 
 if ( tokenToEndPointMap = = null ) 
 tokenToEndPointMap = HashBiMap . create ( ) ; 
 this . tokenToEndPointMap = tokenToEndPointMap ; 
 - pendingRanges = new NonBlockingHashMap < Range , InetAddress > ( ) ; 
 + bootstrapTokens = new HashMap < Token , InetAddress > ( ) ; 
 + leavingEndPoints = new HashSet < InetAddress > ( ) ; 
 + pendingRanges = HashMultimap . create ( ) ; 
 sortedTokens = sortTokens ( ) ; 
 } 
 
 @ @ - 69 , 18 + 89 , 13 @ @ public class TokenMetadata 
 { 
 int n = 0 ; 
 Range sourceRange = getPrimaryRangeFor ( getToken ( source ) ) ; 
 - for ( Map . Entry < Range , InetAddress > entry : pendingRanges . entrySet ( ) ) 
 - { 
 - if ( sourceRange . contains ( entry . getKey ( ) ) | | entry . getValue ( ) . equals ( source ) ) 
 + for ( Token token : bootstrapTokens . keySet ( ) ) 
 + if ( sourceRange . contains ( token ) ) 
 n + + ; 
 - } 
 return n ; 
 } 
 
 - / * * 
 - * Update the two maps in an safe mode . 
 - * / 
 - public void update ( Token token , InetAddress endpoint ) 
 + public void updateNormalToken ( Token token , InetAddress endpoint ) 
 { 
 assert token ! = null ; 
 assert endpoint ! = null ; 
 @ @ - 88 , 6 + 103 , 8 @ @ public class TokenMetadata 
 lock . writeLock ( ) . lock ( ) ; 
 try 
 { 
 + bootstrapTokens . remove ( token ) ; 
 + 
 tokenToEndPointMap . inverse ( ) . remove ( endpoint ) ; 
 if ( ! endpoint . equals ( tokenToEndPointMap . put ( token , endpoint ) ) ) 
 { 
 @ @ - 100 , 13 + 117 , 49 @ @ public class TokenMetadata 
 } 
 } 
 
 + public void addBootstrapToken ( Token token , InetAddress endpoint ) 
 + { 
 + assert token ! = null ; 
 + assert endpoint ! = null ; 
 + 
 + lock . writeLock ( ) . lock ( ) ; 
 + try 
 + { 
 + InetAddress oldEndPoint = bootstrapTokens . get ( token ) ; 
 + if ( oldEndPoint ! = null & & ! oldEndPoint . equals ( endpoint ) ) 
 + throw new RuntimeException ( " Bootstrap Token collision between " + oldEndPoint + " and " + endpoint + " ( token " + token ) ; 
 + bootstrapTokens . put ( token , endpoint ) ; 
 + } 
 + finally 
 + { 
 + lock . writeLock ( ) . unlock ( ) ; 
 + } 
 + } 
 + 
 + public void addLeavingEndPoint ( InetAddress endpoint ) 
 + { 
 + assert endpoint ! = null ; 
 + 
 + lock . writeLock ( ) . lock ( ) ; 
 + try 
 + { 
 + leavingEndPoints . add ( endpoint ) ; 
 + } 
 + finally 
 + { 
 + lock . writeLock ( ) . unlock ( ) ; 
 + } 
 + } 
 + 
 public void removeEndpoint ( InetAddress endpoint ) 
 { 
 assert tokenToEndPointMap . containsValue ( endpoint ) ; 
 lock . writeLock ( ) . lock ( ) ; 
 try 
 { 
 + bootstrapTokens . remove ( getToken ( endpoint ) ) ; 
 tokenToEndPointMap . inverse ( ) . remove ( endpoint ) ; 
 + leavingEndPoints . remove ( endpoint ) ; 
 sortedTokens = sortTokens ( ) ; 
 } 
 finally 
 @ @ - 161 , 7 + 214 , 11 @ @ public class TokenMetadata 
 } 
 } 
 
 - public TokenMetadata cloneWithoutPending ( ) 
 + / * * 
 + * Create a copy of TokenMetadata with only tokenToEndPointMap . That is , pending ranges , 
 + * bootstrap tokens and leaving endpoints are not included in the copy . 
 + * / 
 + public TokenMetadata cloneOnlyTokenMap ( ) 
 { 
 lock . readLock ( ) . lock ( ) ; 
 try 
 @ @ - 174 , 28 + 231 , 24 @ @ public class TokenMetadata 
 } 
 } 
 
 - public String toString ( ) 
 + / * * 
 + * Create a copy of TokenMetadata with tokenToEndPointMap reflecting situation after all 
 + * current leave operations have finished . 
 + * / 
 + public TokenMetadata cloneAfterAllLeft ( ) 
 { 
 - StringBuilder sb = new StringBuilder ( ) ; 
 lock . readLock ( ) . lock ( ) ; 
 try 
 { 
 - Set < InetAddress > eps = tokenToEndPointMap . inverse ( ) . keySet ( ) ; 
 - 
 - for ( InetAddress ep : eps ) 
 - { 
 - sb . append ( ep ) ; 
 - sb . append ( " : " ) ; 
 - sb . append ( tokenToEndPointMap . inverse ( ) . get ( ep ) ) ; 
 - sb . append ( System . getProperty ( " line . separator " ) ) ; 
 - } 
 + TokenMetadata allLeftMetadata = cloneOnlyTokenMap ( ) ; 
 + for ( InetAddress endPoint : leavingEndPoints ) 
 + allLeftMetadata . removeEndpoint ( endPoint ) ; 
 + return allLeftMetadata ; 
 } 
 finally 
 { 
 lock . readLock ( ) . unlock ( ) ; 
 } 
 - 
 - return sb . toString ( ) ; 
 } 
 
 public InetAddress getEndPoint ( Token token ) 
 @ @ - 211 , 12 + 264 , 6 @ @ public class TokenMetadata 
 } 
 } 
 
 - public void clearUnsafe ( ) 
 - { 
 - tokenToEndPointMap . clear ( ) ; 
 - pendingRanges . clear ( ) ; 
 - } 
 - 
 public Range getPrimaryRangeFor ( Token right ) 
 { 
 return new Range ( getPredecessor ( right ) , right ) ; 
 @ @ - 235 , 29 + 282 , 16 @ @ public class TokenMetadata 
 } 
 } 
 
 - public void addPendingRange ( Range range , InetAddress endpoint ) 
 - { 
 - InetAddress oldEndpoint = pendingRanges . get ( range ) ; 
 - if ( oldEndpoint ! = null & & ! oldEndpoint . equals ( endpoint ) ) 
 - throw new RuntimeException ( " pending range collision between " + oldEndpoint + " and " + endpoint ) ; 
 - pendingRanges . put ( range , endpoint ) ; 
 - } 
 - 
 - public void removePendingRange ( Range range ) 
 - { 
 - pendingRanges . remove ( range ) ; 
 - } 
 - 
 / * * a mutable map may be returned but caller should not modify it * / 
 - public Map < Range , InetAddress > getPendingRanges ( ) 
 + public Map < Range , Collection < InetAddress > > getPendingRanges ( ) 
 { 
 - return pendingRanges ; 
 + return pendingRanges . asMap ( ) ; 
 } 
 
 public List < Range > getPendingRanges ( InetAddress endpoint ) 
 { 
 List < Range > ranges = new ArrayList < Range > ( ) ; 
 - for ( Map . Entry < Range , InetAddress > entry : pendingRanges . entrySet ( ) ) 
 + for ( Map . Entry < Range , InetAddress > entry : pendingRanges . entries ( ) ) 
 { 
 if ( entry . getValue ( ) . equals ( endpoint ) ) 
 { 
 @ @ - 267 , 6 + 301 , 11 @ @ public class TokenMetadata 
 return ranges ; 
 } 
 
 + public void setPendingRanges ( Multimap < Range , InetAddress > pendingRanges ) 
 + { 
 + this . pendingRanges = pendingRanges ; 
 + } 
 + 
 public Token getPredecessor ( Token token ) 
 { 
 List tokens = sortedTokens ( ) ; 
 @ @ - 288 , 8 + 327 , 96 @ @ public class TokenMetadata 
 return getEndPoint ( getSuccessor ( getToken ( endPoint ) ) ) ; 
 } 
 
 - public void clearPendingRanges ( ) 
 + / * * caller should not modify bootstrapTokens * / 
 + public Map < Token , InetAddress > getBootstrapTokens ( ) 
 + { 
 + return bootstrapTokens ; 
 + } 
 + 
 + / * * caller should not modify leavigEndPoints * / 
 + public Set < InetAddress > getLeavingEndPoints ( ) 
 { 
 + return leavingEndPoints ; 
 + } 
 + 
 + / * * used by tests * / 
 + public void clearUnsafe ( ) 
 + { 
 + bootstrapTokens . clear ( ) ; 
 + tokenToEndPointMap . clear ( ) ; 
 + leavingEndPoints . clear ( ) ; 
 pendingRanges . clear ( ) ; 
 } 
 + 
 + public String toString ( ) 
 + { 
 + StringBuilder sb = new StringBuilder ( ) ; 
 + lock . readLock ( ) . lock ( ) ; 
 + try 
 + { 
 + Set < InetAddress > eps = tokenToEndPointMap . inverse ( ) . keySet ( ) ; 
 + 
 + if ( ! eps . isEmpty ( ) ) 
 + { 
 + sb . append ( " Normal Tokens : " ) ; 
 + sb . append ( System . getProperty ( " line . separator " ) ) ; 
 + for ( InetAddress ep : eps ) 
 + { 
 + sb . append ( ep ) ; 
 + sb . append ( " : " ) ; 
 + sb . append ( tokenToEndPointMap . inverse ( ) . get ( ep ) ) ; 
 + sb . append ( System . getProperty ( " line . separator " ) ) ; 
 + } 
 + } 
 + 
 + if ( ! bootstrapTokens . isEmpty ( ) ) 
 + { 
 + sb . append ( " Bootstrapping Tokens : " ) ; 
 + sb . append ( System . getProperty ( " line . separator " ) ) ; 
 + for ( Map . Entry < Token , InetAddress > entry : bootstrapTokens . entrySet ( ) ) 
 + { 
 + sb . append ( entry . getValue ( ) + " : " + entry . getKey ( ) ) ; 
 + sb . append ( System . getProperty ( " line . separator " ) ) ; 
 + } 
 + } 
 + 
 + if ( ! leavingEndPoints . isEmpty ( ) ) 
 + { 
 + sb . append ( " Leaving EndPoints : " ) ; 
 + sb . append ( System . getProperty ( " line . separator " ) ) ; 
 + for ( InetAddress ep : leavingEndPoints ) 
 + { 
 + sb . append ( ep ) ; 
 + sb . append ( System . getProperty ( " line . separator " ) ) ; 
 + } 
 + } 
 + 
 + if ( ! pendingRanges . isEmpty ( ) ) 
 + { 
 + sb . append ( " Pending Ranges : " ) ; 
 + sb . append ( System . getProperty ( " line . separator " ) ) ; 
 + sb . append ( printPendingRanges ( ) ) ; 
 + } 
 + } 
 + finally 
 + { 
 + lock . readLock ( ) . unlock ( ) ; 
 + } 
 + 
 + return sb . toString ( ) ; 
 + } 
 + 
 + public String printPendingRanges ( ) 
 + { 
 + StringBuilder sb = new StringBuilder ( ) ; 
 + 
 + for ( Map . Entry < Range , InetAddress > entry : pendingRanges . entries ( ) ) 
 + { 
 + sb . append ( entry . getValue ( ) + " : " + entry . getKey ( ) ) ; 
 + sb . append ( System . getProperty ( " line . separator " ) ) ; 
 + } 
 + 
 + return sb . toString ( ) ; 
 + } 
 + 
 } 
 diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index 1dfba20 . . e5f3988 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 183 , 7 + 183 , 7 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 if ( logger _ . isDebugEnabled ( ) ) 
 logger _ . debug ( " Setting token to " + token ) ; 
 SystemTable . updateToken ( token ) ; 
 - tokenMetadata _ . update ( token , FBUtilities . getLocalAddress ( ) ) ; 
 + tokenMetadata _ . updateNormalToken ( token , FBUtilities . getLocalAddress ( ) ) ; 
 } 
 
 public StorageService ( ) 
 @ @ - 306 , 7 + 306 , 7 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 { 
 SystemTable . setBootstrapped ( true ) ; 
 Token token = storageMetadata _ . getToken ( ) ; 
 - tokenMetadata _ . update ( token , FBUtilities . getLocalAddress ( ) ) ; 
 + tokenMetadata _ . updateNormalToken ( token , FBUtilities . getLocalAddress ( ) ) ; 
 Gossiper . instance ( ) . addApplicationState ( StorageService . STATE _ NORMAL , new ApplicationState ( partitioner _ . getTokenFactory ( ) . toString ( token ) ) ) ; 
 } 
 
 @ @ - 407 , 23 + 407 , 25 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 Token token = getPartitioner ( ) . getTokenFactory ( ) . fromString ( state . getValue ( ) ) ; 
 if ( logger _ . isDebugEnabled ( ) ) 
 logger _ . debug ( endpoint + " state bootstrapping , token " + token ) ; 
 - updateBootstrapRanges ( token , endpoint ) ; 
 + tokenMetadata _ . addBootstrapToken ( token , endpoint ) ; 
 + calculatePendingRanges ( ) ; 
 } 
 else if ( STATE _ NORMAL . equals ( stateName ) ) 
 { 
 Token token = getPartitioner ( ) . getTokenFactory ( ) . fromString ( state . getValue ( ) ) ; 
 if ( logger _ . isDebugEnabled ( ) ) 
 logger _ . debug ( endpoint + " state normal , token " + token ) ; 
 - tokenMetadata _ . update ( token , endpoint ) ; 
 + tokenMetadata _ . updateNormalToken ( token , endpoint ) ; 
 + calculatePendingRanges ( ) ; 
 if ( ! isClientMode ) 
 SystemTable . updateToken ( endpoint , token ) ; 
 - replicationStrategy _ . removeObsoletePendingRanges ( ) ; 
 } 
 else if ( STATE _ LEAVING . equals ( stateName ) ) 
 { 
 Token token = getPartitioner ( ) . getTokenFactory ( ) . fromString ( state . getValue ( ) ) ; 
 assert tokenMetadata _ . getToken ( endpoint ) . equals ( token ) ; 
 - updateLeavingRanges ( endpoint ) ; 
 + tokenMetadata _ . addLeavingEndPoint ( endpoint ) ; 
 + calculatePendingRanges ( ) ; 
 } 
 else if ( STATE _ LEFT . equals ( stateName ) ) 
 { 
 @ @ - 442 , 6 + 444 , 7 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 logger _ . debug ( endpoint + " state left , token " + token ) ; 
 assert tokenMetadata _ . getToken ( endpoint ) . equals ( token ) ; 
 tokenMetadata _ . removeEndpoint ( endpoint ) ; 
 + calculatePendingRanges ( ) ; 
 } 
 } 
 else 
 @ @ - 454 , 11 + 457 , 94 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 { 
 restoreReplicaCount ( endPointThatLeft ) ; 
 tokenMetadata _ . removeEndpoint ( endPointThatLeft ) ; 
 + calculatePendingRanges ( ) ; 
 } 
 } 
 + } 
 + } 
 + 
 + / * * 
 + * Calculate pending ranges according to bootsrapping and leaving nodes . Reasoning is : 
 + * 
 + * ( 1 ) When in doubt , it is better to write too much to a node than too little . That is , if 
 + * there are multiple nodes moving , calculate the biggest ranges a node could have . Cleaning 
 + * up unneeded data afterwards is better than missing writes during movement . 
 + * ( 2 ) When a node leaves , ranges for other nodes can only grow ( a node might get additional 
 + * ranges , but it will not lose any of its current ranges as a result of a leave ) . Therefore 
 + * we will first remove _ all _ leaving tokens for the sake of calculation and then check what 
 + * ranges would go where if all nodes are to leave . This way we get the biggest possible 
 + * ranges with regard current leave operations , covering all subsets of possible final range 
 + * values . 
 + * ( 3 ) When a node bootstraps , ranges of other nodes can only get smaller . Without doing 
 + * complex calculations to see if multiple bootstraps overlap , we simply base calculations 
 + * on the same token ring used before ( reflecting situation after all leave operations have 
 + * completed ) . Bootstrapping nodes will be added and removed one by one to that metadata and 
 + * checked what their ranges would be . This will give us the biggest possible ranges the 
 + * node could have . It might be that other bootstraps make our actual final ranges smaller , 
 + * but it does not matter as we can clean up the data afterwards . 
 + * 
 + * NOTE : This is heavy and ineffective operation . This will be done only once when a node 
 + * changes state in the cluster , so it should be manageable . 
 + * / 
 + private void calculatePendingRanges ( ) 
 + { 
 + calculatePendingRanges ( tokenMetadata _ , replicationStrategy _ ) ; 
 + } 
 + 
 + / / public & static for testing purposes 
 + public static void calculatePendingRanges ( TokenMetadata tm , AbstractReplicationStrategy strategy ) 
 + { 
 + Multimap < Range , InetAddress > pendingRanges = HashMultimap . create ( ) ; 
 + Map < Token , InetAddress > bootstrapTokens = tm . getBootstrapTokens ( ) ; 
 + Set < InetAddress > leavingEndPoints = tm . getLeavingEndPoints ( ) ; 
 + 
 + if ( bootstrapTokens . isEmpty ( ) & & leavingEndPoints . isEmpty ( ) ) 
 + { 
 + if ( logger _ . isDebugEnabled ( ) ) 
 + logger _ . debug ( " No bootstrapping or leaving nodes - > empty pending ranges " ) ; 
 + tm . setPendingRanges ( pendingRanges ) ; 
 + return ; 
 + } 
 + 
 + Multimap < InetAddress , Range > addressRanges = strategy . getAddressRanges ( ) ; 
 + 
 + / / Copy of metadata reflecting the situation after all leave operations are finished . 
 + TokenMetadata allLeftMetadata = tm . cloneAfterAllLeft ( ) ; 
 + 
 + / / get all ranges that will be affected by leaving nodes 
 + Set < Range > affectedRanges = new HashSet < Range > ( ) ; 
 + for ( InetAddress endPoint : leavingEndPoints ) 
 + affectedRanges . addAll ( addressRanges . get ( endPoint ) ) ; 
 + 
 + / / for each of those ranges , find what new nodes will be responsible for the range when 
 + / / all leaving nodes are gone . 
 + for ( Range range : affectedRanges ) 
 + { 
 + List < InetAddress > currentEndPoints = strategy . getNaturalEndpoints ( range . right ( ) , tm ) ; 
 + List < InetAddress > newEndPoints = strategy . getNaturalEndpoints ( range . right ( ) , allLeftMetadata ) ; 
 + newEndPoints . removeAll ( currentEndPoints ) ; 
 + pendingRanges . putAll ( range , newEndPoints ) ; 
 + } 
 + 
 + / / At this stage pendingRanges has been updated according to leave operations . We can 
 + / / now finish the calculation by checking bootstrapping nodes . 
 + 
 + / / For each of the bootstrapping nodes , simply add and remove them one by one to 
 + / / allLeftMetadata and check in between what their ranges would be . 
 + for ( Map . Entry < Token , InetAddress > entry : bootstrapTokens . entrySet ( ) ) 
 + { 
 + InetAddress endPoint = entry . getValue ( ) ; 
 
 - replicationStrategy _ . removeObsoletePendingRanges ( ) ; 
 + allLeftMetadata . updateNormalToken ( entry . getKey ( ) , endPoint ) ; 
 + for ( Range range : strategy . getAddressRanges ( allLeftMetadata ) . get ( endPoint ) ) 
 + pendingRanges . put ( range , endPoint ) ; 
 + allLeftMetadata . removeEndpoint ( endPoint ) ; 
 } 
 + 
 + tm . setPendingRanges ( pendingRanges ) ; 
 + 
 + if ( logger _ . isDebugEnabled ( ) ) 
 + logger _ . debug ( " Pending ranges : \ n " + tm . printPendingRanges ( ) ) ; 
 } 
 
 / * * 
 @ @ - 534 , 7 + 620 , 7 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 Collection < Range > ranges = getRangesForEndPoint ( endpoint ) ; 
 
 if ( logger _ . isDebugEnabled ( ) ) 
 - logger _ . debug ( " leaving node ranges are [ " + StringUtils . join ( ranges , " , " ) + " ] " ) ; 
 + logger _ . debug ( " Node " + endpoint + " ranges [ " + StringUtils . join ( ranges , " , " ) + " ] " ) ; 
 
 Map < Range , ArrayList < InetAddress > > currentReplicaEndpoints = new HashMap < Range , ArrayList < InetAddress > > ( ) ; 
 
 @ @ - 542 , 7 + 628 , 7 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 for ( Range range : ranges ) 
 currentReplicaEndpoints . put ( range , replicationStrategy _ . getNaturalEndpoints ( range . right ( ) , tokenMetadata _ ) ) ; 
 
 - TokenMetadata temp = tokenMetadata _ . cloneWithoutPending ( ) ; 
 + TokenMetadata temp = tokenMetadata _ . cloneAfterAllLeft ( ) ; 
 temp . removeEndpoint ( endpoint ) ; 
 
 Multimap < Range , InetAddress > changedRanges = HashMultimap . create ( ) ; 
 @ @ - 557 , 43 + 643 , 13 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 ArrayList < InetAddress > newReplicaEndpoints = replicationStrategy _ . getNaturalEndpoints ( range . right ( ) , temp ) ; 
 newReplicaEndpoints . removeAll ( currentReplicaEndpoints . get ( range ) ) ; 
 if ( logger _ . isDebugEnabled ( ) ) 
 - logger _ . debug ( " adding pending range " + range + " to endpoints " + StringUtils . join ( newReplicaEndpoints , " , " ) ) ; 
 + logger _ . debug ( " Range " + range + " will be responsibility of " + StringUtils . join ( newReplicaEndpoints , " , " ) ) ; 
 changedRanges . putAll ( range , newReplicaEndpoints ) ; 
 } 
 
 return changedRanges ; 
 } 
 
 - private void updateLeavingRanges ( final InetAddress endpoint ) 
 - { 
 - if ( logger _ . isDebugEnabled ( ) ) 
 - logger _ . debug ( endpoint + " is leaving ; calculating pendingranges " ) ; 
 - Multimap < Range , InetAddress > ranges = getChangedRangesForLeaving ( endpoint ) ; 
 - for ( Range range : ranges . keySet ( ) ) 
 - { 
 - for ( InetAddress newEndpoint : ranges . get ( range ) ) 
 - { 
 - tokenMetadata _ . addPendingRange ( range , newEndpoint ) ; 
 - } 
 - } 
 - } 
 - 
 - private void updateBootstrapRanges ( Token token , InetAddress endpoint ) 
 - { 
 - for ( Range range : replicationStrategy _ . getPendingAddressRanges ( tokenMetadata _ , token , endpoint ) ) 
 - { 
 - tokenMetadata _ . addPendingRange ( range , endpoint ) ; 
 - } 
 - } 
 - 
 - public static void updateBootstrapRanges ( AbstractReplicationStrategy strategy , TokenMetadata metadata , Token token , InetAddress endpoint ) 
 - { 
 - for ( Range range : strategy . getPendingAddressRanges ( metadata , token , endpoint ) ) 
 - { 
 - metadata . addPendingRange ( range , endpoint ) ; 
 - } 
 - } 
 - 
 public void onJoin ( InetAddress endpoint , EndPointState epState ) 
 { 
 for ( Map . Entry < String , ApplicationState > entry : epState . getSortedApplicationStates ( ) ) 
 @ @ - 1117 , 7 + 1173 , 6 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 { 
 SystemTable . setBootstrapped ( false ) ; 
 tokenMetadata _ . removeEndpoint ( FBUtilities . getLocalAddress ( ) ) ; 
 - replicationStrategy _ . removeObsoletePendingRanges ( ) ; 
 
 if ( logger _ . isDebugEnabled ( ) ) 
 logger _ . debug ( " " ) ; 
 @ @ - 1238 , 7 + 1293 , 6 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 
 restoreReplicaCount ( endPoint ) ; 
 tokenMetadata _ . removeEndpoint ( endPoint ) ; 
 - replicationStrategy _ . removeObsoletePendingRanges ( ) ; 
 } 
 
 / / This is not the cleanest way as we ' re adding STATE _ LEFT for 
 @ @ - 1261 , 11 + 1315 , 6 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 return replicationStrategy _ ; 
 } 
 
 - public void cancelPendingRanges ( ) 
 - { 
 - tokenMetadata _ . clearPendingRanges ( ) ; 
 - } 
 - 
 public boolean isClientMode ( ) 
 { 
 return isClientMode ; 
 diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 index c09802a . . f4404fb 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 @ @ - 141 , 13 + 141 , 6 @ @ public interface StorageServiceMBean 
 public void loadBalance ( ) throws IOException , InterruptedException ; 
 
 / * * 
 - * cancel writes to nodes that are set to be changing ranges . 
 - * Only do this if the reason for the range changes no longer exists 
 - * ( e . g . , a bootstrapping node was killed or crashed . ) 
 - * / 
 - public void cancelPendingRanges ( ) ; 
 - 
 - / * * 
 * removeToken removes token ( and all data associated with 
 * enpoint that had it ) from the ring 
 * / 
 diff - - git a / src / java / org / apache / cassandra / tools / NodeProbe . java b / src / java / org / apache / cassandra / tools / NodeProbe . java 
 index cd87901 . . 0135eb7 100644 
 - - - a / src / java / org / apache / cassandra / tools / NodeProbe . java 
 + + + b / src / java / org / apache / cassandra / tools / NodeProbe . java 
 @ @ - 398 , 11 + 398 , 6 @ @ public class NodeProbe 
 ssProxy . move ( newToken ) ; 
 } 
 
 - public void cancelPendingRanges ( ) 
 - { 
 - ssProxy . cancelPendingRanges ( ) ; 
 - } 
 - 
 public void removeToken ( String token ) 
 { 
 ssProxy . removeToken ( token ) ; 
 @ @ - 503 , 7 + 498 , 7 @ @ public class NodeProbe 
 HelpFormatter hf = new HelpFormatter ( ) ; 
 String header = String . format ( 
 " % nAvailable commands : ring , info , cleanup , compact , cfstats , snapshot [ name ] , clearsnapshot , " + 
 - " tpstats , flush , repair , decommission , move , loadbalance , cancelpending , removetoken , " + 
 + " tpstats , flush , repair , decommission , move , loadbalance , removetoken , " + 
 " getcompactionthreshold , setcompactionthreshold [ minthreshold ] ( [ maxthreshold ] ) " ) ; 
 String usage = String . format ( " java % s - host < arg > < command > % n " , NodeProbe . class . getName ( ) ) ; 
 hf . printHelp ( usage , " " , options , header ) ; 
 @ @ - 578 , 10 + 573 , 6 @ @ public class NodeProbe 
 } 
 probe . move ( arguments [ 1 ] ) ; 
 } 
 - else if ( cmdName . equals ( " cancelpending " ) ) 
 - { 
 - probe . cancelPendingRanges ( ) ; 
 - } 
 else if ( cmdName . equals ( " removetoken " ) ) 
 { 
 if ( arguments . length < = 1 ) 
 diff - - git a / test / unit / org / apache / cassandra / dht / BootStrapperTest . java b / test / unit / org / apache / cassandra / dht / BootStrapperTest . java 
 index b9a5a82 . . c910685 100644 
 - - - a / test / unit / org / apache / cassandra / dht / BootStrapperTest . java 
 + + + b / test / unit / org / apache / cassandra / dht / BootStrapperTest . java 
 @ @ - 32 , 6 + 32 , 7 @ @ import org . junit . Test ; 
 import com . google . common . collect . Multimap ; 
 import org . apache . cassandra . gms . IFailureDetectionEventListener ; 
 import org . apache . cassandra . gms . IFailureDetector ; 
 + import org . apache . cassandra . gms . ApplicationState ; 
 import org . apache . cassandra . locator . TokenMetadata ; 
 import org . apache . cassandra . service . StorageService ; 
 import org . apache . cassandra . utils . FBUtilities ; 
 @ @ - 61 , 7 + 62 , 8 @ @ public class BootStrapperTest 
 Range range3 = ss . getPrimaryRangeForEndPoint ( three ) ; 
 Token fakeToken = ( ( IPartitioner ) StorageService . getPartitioner ( ) ) . midpoint ( range3 . left ( ) , range3 . right ( ) ) ; 
 assert range3 . contains ( fakeToken ) ; 
 - StorageService . updateBootstrapRanges ( StorageService . instance ( ) . getReplicationStrategy ( ) , tmd , fakeToken , myEndpoint ) ; 
 + ss . onChange ( myEndpoint , StorageService . STATE _ BOOTSTRAPPING , new ApplicationState ( ss . getPartitioner ( ) . getTokenFactory ( ) . toString ( fakeToken ) ) ) ; 
 + tmd = ss . getTokenMetadata ( ) ; 
 
 InetAddress source2 = BootStrapper . getBootstrapSource ( tmd , load ) ; 
 assert two . equals ( source2 ) : source2 ; 
 @ @ - 124 , 7 + 126 , 7 @ @ public class BootStrapperTest 
 for ( int i = 1 ; i < = numOldNodes ; i + + ) 
 { 
 / / leave . 1 for myEndpoint 
 - tmd . update ( p . getRandomToken ( ) , InetAddress . getByName ( " 127 . 0 . 0 . " + ( i + 1 ) ) ) ; 
 + tmd . updateNormalToken ( p . getRandomToken ( ) , InetAddress . getByName ( " 127 . 0 . 0 . " + ( i + 1 ) ) ) ; 
 } 
 } 
 } 
 \ No newline at end of file 
 diff - - git a / test / unit / org / apache / cassandra / locator / RackUnawareStrategyTest . java b / test / unit / org / apache / cassandra / locator / RackUnawareStrategyTest . java 
 index 9169f7d . . c0e6cd2 100644 
 - - - a / test / unit / org / apache / cassandra / locator / RackUnawareStrategyTest . java 
 + + + b / test / unit / org / apache / cassandra / locator / RackUnawareStrategyTest . java 
 @ @ - 79 , 7 + 79 , 7 @ @ public class RackUnawareStrategyTest 
 for ( int i = 0 ; i < endPointTokens . length ; i + + ) 
 { 
 InetAddress ep = InetAddress . getByName ( " 127 . 0 . 0 . " + String . valueOf ( i + 1 ) ) ; 
 - tmd . update ( endPointTokens [ i ] , ep ) ; 
 + tmd . updateNormalToken ( endPointTokens [ i ] , ep ) ; 
 hosts . add ( ep ) ; 
 } 
 
 @ @ - 114 , 15 + 114 , 16 @ @ public class RackUnawareStrategyTest 
 for ( int i = 0 ; i < endPointTokens . length ; i + + ) 
 { 
 InetAddress ep = InetAddress . getByName ( " 127 . 0 . 0 . " + String . valueOf ( i + 1 ) ) ; 
 - tmd . update ( endPointTokens [ i ] , ep ) ; 
 + tmd . updateNormalToken ( endPointTokens [ i ] , ep ) ; 
 hosts . add ( ep ) ; 
 } 
 
 / / Add bootstrap node id = 6 
 Token bsToken = new BigIntegerToken ( String . valueOf ( 25 ) ) ; 
 InetAddress bootstrapEndPoint = InetAddress . getByName ( " 127 . 0 . 0 . 6 " ) ; 
 - StorageService . updateBootstrapRanges ( strategy , tmd , bsToken , bootstrapEndPoint ) ; 
 - 
 + tmd . addBootstrapToken ( bsToken , bootstrapEndPoint ) ; 
 + StorageService . calculatePendingRanges ( tmd , strategy ) ; 
 + 
 for ( int i = 0 ; i < keyTokens . length ; i + + ) 
 { 
 Collection < InetAddress > endPoints = strategy . getWriteEndpoints ( keyTokens [ i ] , strategy . getNaturalEndpoints ( keyTokens [ i ] ) ) ; 
 @ @ - 136 , 6 + 137 , 8 @ @ public class RackUnawareStrategyTest 
 / / for 5 , 15 , 25 this should include bootstrap node 
 if ( i < 3 ) 
 assertTrue ( endPoints . contains ( bootstrapEndPoint ) ) ; 
 + else 
 + assertFalse ( endPoints . contains ( bootstrapEndPoint ) ) ; 
 } 
 } 
 }
