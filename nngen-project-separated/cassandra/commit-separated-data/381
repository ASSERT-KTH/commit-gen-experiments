BLEU SCORE: 0.040583489434387374

TEST MSG: Add in - tree testing guidelines
GENERATED MSG: merge from 1 . 2

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 1191086 . . 03870dd 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 4 . 0 <nl> + * Add testing guidelines ( CASSANDRA - 13497 ) <nl> * Add more repair metrics ( CASSANDRA - 13531 ) <nl> * RangeStreamer should be smarter when picking endpoints for streaming ( CASSANDRA - 4650 ) <nl> * Avoid rewrapping an exception thrown for cache load functions ( CASSANDRA - 13367 ) <nl> diff - - git a / CONTRIBUTING . md b / CONTRIBUTING . md <nl> index 8366579 . . 25e15ee 100644 <nl> - - - a / CONTRIBUTING . md <nl> + + + b / CONTRIBUTING . md <nl> @ @ - 15 , 3 + 15 , 4 @ @ Use [ Cassandra JIRA ] ( https : / / issues . apache . org / jira / browse / CASSANDRA / ) to create <nl> - Running Cassandra in Eclipse [ guide ] ( https : / / wiki . apache . org / cassandra / RunningCassandraInEclipse ) <nl> - Cassandra Cluster Manager - [ CCM ] ( https : / / github . com / pcmanus / ccm ) and a guide [ blog post ] ( http : / / www . datastax . com / dev / blog / ccm - a - development - tool - for - creating - local - cassandra - clusters ) <nl> - Cassandra Distributed Tests aka [ dtests ] ( https : / / github . com / riptano / cassandra - dtest ) <nl> + - Cassandra Testing Guidelines - see TESTING . md <nl> diff - - git a / TESTING . md b / TESTING . md <nl> new file mode 100644 <nl> index 0000000 . . de0c34a <nl> - - - / dev / null <nl> + + + b / TESTING . md <nl> @ @ - 0 , 0 + 1 , 448 @ @ <nl> + The goal of this document is to establish guidelines on writing tests that drive incremental improvement of the test coverage and testability of <nl> + Cassandra , without overly burdening day to day work . While not every point here will be immediately practical to implement or relevant for every <nl> + contribution , it errs on the side of not making rules out of potential exceptions . It provides guidelines on test scope , style , and goals , as <nl> + weel as guidelines for dealing with global state and refactoring untested code . <nl> + <nl> + # # What to Test <nl> + <nl> + There are 3 main types of tests in Cassandra , unit tests , integration tests , and dtests . Below , each type of test is described , and a high level description of <nl> + what should and shouldn ' t be tested in each is given . <nl> + <nl> + # # # Unit Tests <nl> + JUnit tests of smaller components that are fairly narrow in scope ( ie : data structures , verb handlers , helper classes ) <nl> + <nl> + # # # # What should be tested <nl> + * All state transitions should be tested <nl> + * Illegal state transitions should be tested ( that they throw exceptions ) <nl> + * all conditional branches should be tested . <nl> + * Code that deals with ranges of values should have tests around expected ranges , unexpected ranges , different functional ranges and their boundaries . <nl> + * Exception handling should be tested . <nl> + <nl> + # # # # What shouldn ' t be tested <nl> + * implementation details ( test that the system under test works a certain way , not that it ' s implemented a certain way ) <nl> + <nl> + # # # Integration Tests <nl> + JUnit tests of larger components with a lot of moving parts , usually involved in some internode communication ( ie : Gossip , MessagingService ) . <nl> + The smaller components that make up the system under test in an integration test should be individually unit tested . <nl> + <nl> + # # # # What should be tested <nl> + * messages are sent when expected <nl> + * received messages have the intended side effects <nl> + * internal interfaces work as expected <nl> + * external interfaces are interacted with as expected <nl> + * multiple instances of components interact as expected ( with a mocked messaging service , and other dependencies , where appropriate ) <nl> + * dry start - test that a system starts up properly the first time a node start <nl> + * restart - test that a system starts up properly on node restart ( from both clean and unclean shutdown ) <nl> + * shutdown - test that a system can shutdown properly <nl> + * upgrade - test that a system is able to restart with data from a previous version <nl> + <nl> + # # # # What shouldn ' t be tested <nl> + * The rest of the application . It should be possible to test large systems without starting the entire database through the use of mocks . <nl> + <nl> + * * Note : * * it ' s generally not a good idea to mock out the storage layer if the component under test needs to interact with it . If you ' re testing <nl> + how multiple instances interact with each other , AND they need to use the storage layer , parameterizing the keyspace / table they store data is <nl> + the way to do it . <nl> + <nl> + # # # dtests <nl> + python / ccm tests that start local clusters and interact with them via the python client . <nl> + <nl> + dtests are effectively black box tests , and should be used for checking that clusters and client side interfaces work as expected . They are not <nl> + a replacement for proper functional java tests . They take much longer to run , and are much less flexible in what they can test . <nl> + <nl> + Systems under test in dtest should have more granular integration tests as well . <nl> + <nl> + # # # # What should be tested <nl> + * end to end cluster functionality <nl> + * client contracts <nl> + * trivial ( to create ) failure cases <nl> + <nl> + # # # # What shouldn ' t be tested <nl> + * internal implementation details <nl> + <nl> + # # Expanded Guidelines <nl> + <nl> + This section has more in depth descriptions and reasoning about some of the points raised in the previous section . <nl> + <nl> + # # # Test structure <nl> + <nl> + Tests cases should have a clear progression of setup , precondition check , performing some action under test , then a postcondition check . <nl> + <nl> + * * Example * * <nl> + <nl> + ` ` ` java <nl> + @ Test <nl> + public void increment ( ) throws Exception <nl> + { <nl> + 	 / / setup code <nl> + 	 int x = 1 ; <nl> + <nl> + 	 / / check preconditions <nl> + 	 assertEquals ( 1 , x ) ; <nl> + <nl> + 	 / / perform the state changing action under test <nl> + 	 x + + ; <nl> + <nl> + 	 / / check post conditions <nl> + 	 assertEquals ( 2 , x ) ; <nl> + } <nl> + ` ` ` <nl> + <nl> + # # # # Reason <nl> + <nl> + Test cases should be optimized for readability <nl> + <nl> + # # # # Exceptions <nl> + <nl> + Cases where simple cases can be tested in one line . Such as validation logic checks : <nl> + property - based state testing ( ie : ScalaCheck / QuickCheck ) <nl> + <nl> + * Example : * <nl> + ` ` ` java <nl> + @ Test <nl> + public void validation ( ) <nl> + { <nl> + 	 assertValidationFailure ( b - > b . withState ( null ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withSessionID ( null ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withCoordinator ( null ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withTableIds ( null ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withTableIds ( new HashSet < > ( ) ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withRepairedAt ( 0 ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withRepairedAt ( - 1 ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withRanges ( null ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withRanges ( new HashSet < > ( ) ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withParticipants ( null ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withParticipants ( new HashSet < > ( ) ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withStartedAt ( 0 ) ) ; <nl> + 	 assertValidationFailure ( b - > b . withLastUpdate ( 0 ) ) ; <nl> + } <nl> + ` ` ` <nl> + <nl> + # # # Test distributed components in junit <nl> + <nl> + Components that rely on nodes communicating with each other should be testable in java . <nl> + <nl> + # # # # Reason <nl> + <nl> + One of the more difficult aspects of distributed systems is ensuring that they continue to behave correctly during various failure modes . This includes weird <nl> + edge cases involving specific ordering of events between nodes that rarely occur in the wild . Testing these sorts of scenarios is much easier in junit because <nl> + mock ' clusters ' can be placed in specific states , and deterministically stepped through a sequence of events , ensuring that they behave as expected , and are in <nl> + the expected state after each step . <nl> + <nl> + # # # # Exceptions <nl> + <nl> + This rule mainly applies to new or significantly overhauled systems . Older systems * should * be refactored to be thoroughly tested , but it ' s not necessarily a <nl> + prerequisite for working on them . <nl> + <nl> + # # # Test all branches and inputs . <nl> + <nl> + All branches and inputs of a method should be exercised . For branches that require multiple criteria to be met , ( ie ` x > 10 & & y < 100 ` ) , there <nl> + should be tests demonstrating that the branch is taken when all critera are met ( ie ` x = 11 , y = 99 ` ) , and that it is not taken when only one is met <nl> + ( ie : ` x = 11 , y = 200 or x = 5 , y = 99 ` ) . If a method deals with ranges of values , ( ie ` x > = 10 ` ) , the boundaries of the ranges should be tested ( ie : ` x = 9 , x = 10 ` ) <nl> + <nl> + In the following example <nl> + <nl> + * * Example * * <nl> + ` ` ` java <nl> + class SomeClass <nl> + { <nl> + 	 public static int someFunction ( bool aFlag , int aValue ) <nl> + 	 { <nl> + 	 	 if ( aFlag & & aValue > 10 ) <nl> + 	 	 { <nl> + 	 	 	 return 20 ; <nl> + 	 	 } <nl> + 	 	 else if ( aValue > 5 ) <nl> + 	 	 { <nl> + 	 	 	 return 10 ; <nl> + 	 	 else <nl> + 	 	 { <nl> + 	 	 	 return 0 ; <nl> + 	 	 } <nl> + 	 } <nl> + } <nl> + <nl> + class SomeTest <nl> + { <nl> + 	 public void someFunction ( ) throws Exception <nl> + 	 { <nl> + 	 	 assertEquals ( 10 , somefunction ( true , 11 ) ) ; <nl> + 	 	 assertEquals ( 5 , somefunction ( false , 11 ) ) ; <nl> + 	 	 assertEquals ( 5 , somefunction ( true , 8 ) ) ; <nl> + 	 	 assertEquals ( 5 , somefunction ( false , 8 ) ) ; <nl> + 	 	 assertEquals ( 0 , somefunction ( false , 4 ) ) ; <nl> + 	 } <nl> + } <nl> + ` ` ` <nl> + <nl> + # # # Test any state transitions <nl> + <nl> + As an extension of testing all branches and inputs . For stateful systems , there should be tests demonstrating that states change under the intended <nl> + circumstances , and that state changes have the intended side effects . <nl> + <nl> + # # # Test unsupported arguments and states throw exceptions <nl> + <nl> + If a system is not intended to perform an action in a given state ( ie : a node performing reads during bootstrap ) , or a method is not intended <nl> + to encounter some type of argument ( ie : a method that is only designed to work with numeric values > 0 ) , then there should be tests demonstrating <nl> + that an appropriate exception is raised ( IllegalStateException or IllegalArgumentException , respectively ) in that case . <nl> + <nl> + The guava preconditions module makes this straightforward . <nl> + <nl> + # # # # Reason <nl> + <nl> + Inadvertent misuse of methods and systems cause bugs that are often silent and subtle . Raising exceptions on unintended usage helps <nl> + protect against future bugs and reduces developer surprise . <nl> + <nl> + # # Dealing with global state <nl> + <nl> + Unfortunately , the project has extensive amounts of global state which makes actually writing robust tests difficult , but not impossible . <nl> + <nl> + Having dependencies on global state is not an excuse to not test something , or to throw a dtest or assertion at it and call it a day . <nl> + <nl> + Structuring code in a way that interacts with global state that can still be deterministically tested just takes a few tweaks <nl> + <nl> + * * Example , bad * * <nl> + ` ` ` java <nl> + class SomeVerbHandler implements IVerbHandler < SomeMessage > <nl> + { <nl> + 	 public void doVerb ( MessageIn < SomeMessage > msg ) <nl> + 	 { <nl> + 	 	 if ( FailureDetector . instance . isAlive ( msg . payload . otherNode ) ) <nl> + 	 	 { <nl> + 	 	 	 new StreamPlan ( msg . payload . otherNode ) . requestRanges ( someRanges ) . execute ( ) ; <nl> + 	 	 } <nl> + 	 	 else <nl> + 	 	 { <nl> + 	 	 	 CompactionManager . instance . submitBackground ( msg . payload . cfs ) ; <nl> + 	 	 } <nl> + 	 } <nl> + } <nl> + ` ` ` <nl> + <nl> + In this made up example , we ' re checking global state , and then taking some action against other global state . None of the global state <nl> + we ' re working with is easy to manipulate for tests , so comprehensive tests for this aren ' t very likely to be written . Even worse , whether <nl> + the FailureDetector , streaming , or compaction work properly are out of scope for our purposes . We ' re concerned with whether SomeVerbHandler <nl> + works as expected . <nl> + <nl> + Ideally though , classes won ' t have dependencies on global state at all , and have everything they need to work passed in as constructor arguments . <nl> + This also enables comprehensive testing , and stops the spread of global state . <nl> + <nl> + This prevents the spread of global state , and also begins to identify and define the internal interfaces that will replace global state . <nl> + <nl> + * * Example , better * * <nl> + ` ` ` java <nl> + class SomeVerbHandler implements IVerbHandler < SomeMessage > <nl> + { <nl> + 	 private final IFailureDetector failureDetector ; <nl> + 	 private final ICompactionManager compactionManager ; <nl> + 	 private final IStreamManager streamManager ; <nl> + <nl> + 	 public SomeVerbHandler ( IFailureDetector failureDetector , ICompactionManager compactionManager , IStreamManager streamManager ) <nl> + 	 { <nl> + 	 	 this . failureDetector = failureDetector ; <nl> + 	 	 this . compactionManager = compactionManager ; <nl> + 	 	 this . streamManager = streamManager ; <nl> + 	 } <nl> + <nl> + 	 public void doVerb ( MessageIn < SomeMessage > msg ) <nl> + 	 { <nl> + 	 	 if ( failureDetector . isAlive ( msg . payload . otherNode ) ) <nl> + 	 	 { <nl> + 	 	 	 streamExecutor . submitPlan ( new StreamPlan ( msg . payload . otherNode ) . requestRanges ( someRanges ) ) ; <nl> + 	 	 } <nl> + 	 	 else <nl> + 	 	 { <nl> + 	 	 	 compactionManager . submitBackground ( msg . payload . cfs ) ; <nl> + 	 	 } <nl> + 	 } <nl> + } <nl> + ` ` ` <nl> + <nl> + * * Example test * * <nl> + ` ` ` java <nl> + class SomeVerbTest <nl> + { <nl> + 	 class InstrumentedFailureDetector implements IFailureDetector <nl> + 	 { <nl> + 	 	 boolean alive = false ; <nl> + 	 	 @ Override <nl> + 	 	 public boolean isAlive ( InetAddress address ) <nl> + 	 	 { <nl> + 	 	 	 return alive ; <nl> + 	 	 } <nl> + 	 } <nl> + <nl> + 	 class InstrumentedCompactionManager implements ICompactionManager <nl> + 	 { <nl> + 	 	 boolean submitted = false ; <nl> + 	 	 @ Override <nl> + 	 	 public void submitBackground ( ColumnFamilyStore cfs ) <nl> + 	 	 { <nl> + 	 	 	 submitted = true ; <nl> + 	 	 } <nl> + 	 } <nl> + <nl> + 	 class InstrumentedStreamManager implements IStreamManager <nl> + 	 { <nl> + 	 	 boolean submitted = false ; <nl> + 	 	 @ Override <nl> + 	 	 public void submitPlan ( StreamPlan plan ) <nl> + 	 	 { <nl> + 	 	 	 submitted = true ; <nl> + 	 	 } <nl> + 	 } <nl> + <nl> + 	 @ Test <nl> + 	 public void liveNode ( ) throws Exception <nl> + 	 { <nl> + 	 	 InstrumentedFailureDetector failureDetector = new InstrumentedFailureDetector ( ) ; <nl> + 	 	 failureDetector . alive = true ; <nl> + 	 	 InstrumentedCompactionManager compactionManager = new InstrumentedCompactionManager ( ) ; <nl> + 	 	 InstrumentedStreamManager streamManager = new InstrumentedStreamManager ( ) ; <nl> + 	 	 SomeVerbHandler handler = new SomeVerbHandler ( failureDetector , compactionManager , streamManager ) ; <nl> + <nl> + 	 	 MessageIn < SomeMessage > msg = new MessageIn < > ( . . . ) ; <nl> + <nl> + 	 	 assertFalse ( streamManager . submitted ) ; <nl> + 	 	 assertFalse ( compactionManager . submitted ) ; <nl> + <nl> + 	 	 handler . doVerb ( msg ) ; <nl> + <nl> + 	 	 assertTrue ( streamManager . submitted ) ; <nl> + 	 	 assertFalse ( compactionManager . submitted ) ; <nl> + 	 } <nl> + <nl> + 	 @ Test <nl> + 	 public void deadNode ( ) throws Exception <nl> + 	 { <nl> + 	 	 InstrumentedFailureDetector failureDetector = new InstrumentedFailureDetector ( ) ; <nl> + 	 	 failureDetector . alive = false ; <nl> + 	 	 InstrumentedCompactionManager compactionManager = new InstrumentedCompactionManager ( ) ; <nl> + 	 	 InstrumentedStreamManager streamManager = new InstrumentedStreamManager ( ) ; <nl> + 	 	 SomeVerbHandler handler = new SomeVerbHandler ( failureDetector , compactionManager , streamManager ) ; <nl> + <nl> + 	 	 MessageIn < SomeMessage > msg = new MessageIn < > ( . . . ) ; <nl> + <nl> + 	 	 assertFalse ( streamManager . submitted ) ; <nl> + 	 	 assertFalse ( compactionManager . submitted ) ; <nl> + <nl> + 	 	 handler . doVerb ( msg ) ; <nl> + <nl> + 	 	 assertFalse ( streamManager . submitted ) ; <nl> + 	 	 assertTrue ( compactionManager . submitted ) ; <nl> + 	 } <nl> + } <nl> + ` ` ` <nl> + <nl> + By abstracting away accesses to global state we can exhaustively test the paths this verb handler can take , and directly confirm that it ' s taking the correct <nl> + actions . Obviously , this is a simple example , but for classes or functions with more complex logic , this makes comprehensive testing much easier . <nl> + <nl> + Note that the interfaces used here probably shouldn ' t be the same ones we use for MBeans . <nl> + <nl> + However , in some cases , passing interfaces into the constructor may not be practical . Classes that are instantiated on startup need to be handled with care , since accessing <nl> + a singleton may change the initialization order of the database . It may also be a larger change than is warranted for something like a bug fix . In any case , if passing <nl> + dependencies into the constructor is not practical , wrapping accesses to global state in protected methods that are overridden for tests will achieve the same thing . <nl> + <nl> + <nl> + * * Example , alternative * * <nl> + ` ` ` javayy <nl> + class SomeVerbHandler implements IVerbHandler < SomeMessage > <nl> + { <nl> + 	 @ VisibleForTesting <nl> + 	 protected boolean isAlive ( InetAddress addr ) { return FailureDetector . instance . isAlive ( msg . payload . otherNode ) ; } <nl> + <nl> + 	 @ VisibleForTesting <nl> + 	 protected void streamSomethind ( InetAddress to ) { new StreamPlan ( to ) . requestRanges ( someRanges ) . execute ( ) ; } <nl> + <nl> + 	 @ VisibleForTesting <nl> + 	 protected void compactSomething ( ColumnFamilyStore cfs ) { CompactionManager . instance . submitBackground ( ) ; } <nl> + <nl> + 	 public void doVerb ( MessageIn < SomeMessage > msg ) <nl> + 	 { <nl> + 	 	 if ( isAlive ( msg . payload . otherNode ) ) <nl> + 	 	 { <nl> + 	 	 	 streamSomething ( msg . payload . otherNode ) ; <nl> + 	 	 } <nl> + 	 	 else <nl> + 	 	 { <nl> + 	 	 	 compactSomething ( ) ; <nl> + 	 	 } <nl> + 	 } <nl> + } <nl> + ` ` ` <nl> + <nl> + * * Example test * * <nl> + ` ` ` java <nl> + class SomeVerbTest <nl> + { <nl> + 	 static class InstrumentedSomeVerbHandler extends SomeVerbHandler <nl> + 	 { <nl> + 	 	 public boolean alive = false ; <nl> + 	 	 public boolean streamCalled = false ; <nl> + 	 	 public boolean compactCalled = false ; <nl> + <nl> + 	 	 @ Override <nl> + 	 	 protected boolean isAlive ( InetAddress addr ) { return alive ; } <nl> + 	 	 <nl> + 	 	 @ Override <nl> + 	 	 protected void streamSomethind ( InetAddress to ) { streamCalled = true ; } <nl> + <nl> + 	 	 @ Override <nl> + 	 	 protected void compactSomething ( ColumnFamilyStore cfs ) { compactCalled = true ; } <nl> + 	 } <nl> + <nl> + 	 @ Test <nl> + 	 public void liveNode ( ) throws Exception <nl> + 	 { <nl> + 	 	 InstrumentedSomeVerbHandler handler = new InstrumentedSomeVerbHandler ( ) ; <nl> + 	 	 handler . alive = true ; <nl> + 	 	 MessageIn < SomeMessage > msg = new MessageIn < > ( . . . ) ; <nl> + <nl> + 	 	 assertFalse ( handler . streamCalled ) ; <nl> + 	 	 assertFalse ( handler . compactCalled ) ; <nl> + <nl> + 	 	 handler . doVerb ( msg ) ; <nl> + <nl> + 	 	 assertTrue ( handler . streamCalled ) ; <nl> + 	 	 assertFalse ( handler . compactCalled ) ; <nl> + 	 } <nl> + <nl> + 	 @ Test <nl> + 	 public void deadNode ( ) throws Exception <nl> + 	 { <nl> + 	 	 InstrumentedSomeVerbHandler handler = new InstrumentedSomeVerbHandler ( ) ; <nl> + 	 	 handler . alive = false ; <nl> + 	 	 MessageIn < SomeMessage > msg = new MessageIn < > ( . . . ) ; <nl> + <nl> + 	 	 assertFalse ( handler . streamCalled ) ; <nl> + 	 	 assertFalse ( handler . compactCalled ) ; <nl> + <nl> + 	 	 handler . doVerb ( msg ) ; <nl> + <nl> + 	 	 assertFalse ( handler . streamCalled ) ; <nl> + 	 	 assertTrue ( handler . compactCalled ) ; <nl> + 	 } <nl> + } <nl> + ` ` ` <nl> + <nl> + # # Refactoring Existing Code <nl> + <nl> + If you ' re working on a section of the project that historically hasn ' t been well tested , it will likely be more difficult for you to write tests around <nl> + whatever you ' re doing , since the code may not have been written with testing in mind . You do need to add tests around the subject of you ' re <nl> + jira , and this will probably involve some refactoring , but you ' re also not expected to completely refactor a huge class to submit a bugfix . <nl> + <nl> + Basically , you need to be able to verify the behavior you intend to modify before and after your patch . The amount of testing debt you pay back should be <nl> + roughly proportional to the scope of your change . If you ' re doing a small bugfix , you can get away with refactoring just enough to make the subject of your <nl> + fix testable , even if you start to get into ' testing implementation details ' territory ' . The goal is incremental improvement , not making things perfect on <nl> + the first iteration . If you ' re doing something more ambitious though , you may have to do some extra work to sufficiently test your changes . <nl> + <nl> + # # Refactoring Untested Code <nl> + <nl> + There are several components that have very little , if any , direct test coverage . We really should try to improve the test coverage of these components . <nl> + For people interested in getting involved with the project , adding tests for these is a great way to get familiar with the codebase . <nl> + <nl> + First , get feedback on the subject and scope of your proposed refactor , especially larger ones . The smaller and more narrowly focused your proposed <nl> + refactor is , the easier it will be for you to get it reviewed and committed . <nl> + <nl> + Start with smaller pieces , refactor and test them , and work outwards , iteratively . Preferably in several jiras . Ideally , each patch should add some value <nl> + to the project on it ' s own in terms of test coverage . Patches that are heavy on refactoring , and light on tests are not likely to get committed . People come and go <nl> + from projects , and having a many small improvements is better for the project than several unfinished or ongoing refactors that don ' t add much test coverage .
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index b935425 . . 7f5a487 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 1 . 2 - rc1 <nl> + * fix cqlsh rendering of blob fields ( CASSANDRA - 4970 ) <nl> * fix cqlsh DESCRIBE command ( CASSANDRA - 4913 ) <nl> * save truncation position in system table ( CASSANDRA - 4906 ) <nl> * Move CompressionMetadata off - heap ( CASSANDRA - 4937 ) <nl> diff - - git a / pylib / cqlshlib / formatting . py b / pylib / cqlshlib / formatting . py <nl> index d15c083 . . bab3506 100644 <nl> - - - a / pylib / cqlshlib / formatting . py <nl> + + + b / pylib / cqlshlib / formatting . py <nl> @ @ - 88 , 8 + 88 , 8 @ @ def formatter _ for ( typname ) : <nl> return f <nl> return registrator <nl> <nl> - @ formatter _ for ( ' bytes ' ) <nl> - def format _ value _ bytes ( val , colormap , * * _ ) : <nl> + @ formatter _ for ( ' blob ' ) <nl> + def format _ value _ blob ( val , colormap , * * _ ) : <nl> bval = ' ' . join ( ' % 02x ' % ord ( c ) for c in val ) <nl> return colorme ( bval , colormap , ' hex ' ) <nl>

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 1191086 . . 03870dd 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 4 . 0 
 + * Add testing guidelines ( CASSANDRA - 13497 ) 
 * Add more repair metrics ( CASSANDRA - 13531 ) 
 * RangeStreamer should be smarter when picking endpoints for streaming ( CASSANDRA - 4650 ) 
 * Avoid rewrapping an exception thrown for cache load functions ( CASSANDRA - 13367 ) 
 diff - - git a / CONTRIBUTING . md b / CONTRIBUTING . md 
 index 8366579 . . 25e15ee 100644 
 - - - a / CONTRIBUTING . md 
 + + + b / CONTRIBUTING . md 
 @ @ - 15 , 3 + 15 , 4 @ @ Use [ Cassandra JIRA ] ( https : / / issues . apache . org / jira / browse / CASSANDRA / ) to create 
 - Running Cassandra in Eclipse [ guide ] ( https : / / wiki . apache . org / cassandra / RunningCassandraInEclipse ) 
 - Cassandra Cluster Manager - [ CCM ] ( https : / / github . com / pcmanus / ccm ) and a guide [ blog post ] ( http : / / www . datastax . com / dev / blog / ccm - a - development - tool - for - creating - local - cassandra - clusters ) 
 - Cassandra Distributed Tests aka [ dtests ] ( https : / / github . com / riptano / cassandra - dtest ) 
 + - Cassandra Testing Guidelines - see TESTING . md 
 diff - - git a / TESTING . md b / TESTING . md 
 new file mode 100644 
 index 0000000 . . de0c34a 
 - - - / dev / null 
 + + + b / TESTING . md 
 @ @ - 0 , 0 + 1 , 448 @ @ 
 + The goal of this document is to establish guidelines on writing tests that drive incremental improvement of the test coverage and testability of 
 + Cassandra , without overly burdening day to day work . While not every point here will be immediately practical to implement or relevant for every 
 + contribution , it errs on the side of not making rules out of potential exceptions . It provides guidelines on test scope , style , and goals , as 
 + weel as guidelines for dealing with global state and refactoring untested code . 
 + 
 + # # What to Test 
 + 
 + There are 3 main types of tests in Cassandra , unit tests , integration tests , and dtests . Below , each type of test is described , and a high level description of 
 + what should and shouldn ' t be tested in each is given . 
 + 
 + # # # Unit Tests 
 + JUnit tests of smaller components that are fairly narrow in scope ( ie : data structures , verb handlers , helper classes ) 
 + 
 + # # # # What should be tested 
 + * All state transitions should be tested 
 + * Illegal state transitions should be tested ( that they throw exceptions ) 
 + * all conditional branches should be tested . 
 + * Code that deals with ranges of values should have tests around expected ranges , unexpected ranges , different functional ranges and their boundaries . 
 + * Exception handling should be tested . 
 + 
 + # # # # What shouldn ' t be tested 
 + * implementation details ( test that the system under test works a certain way , not that it ' s implemented a certain way ) 
 + 
 + # # # Integration Tests 
 + JUnit tests of larger components with a lot of moving parts , usually involved in some internode communication ( ie : Gossip , MessagingService ) . 
 + The smaller components that make up the system under test in an integration test should be individually unit tested . 
 + 
 + # # # # What should be tested 
 + * messages are sent when expected 
 + * received messages have the intended side effects 
 + * internal interfaces work as expected 
 + * external interfaces are interacted with as expected 
 + * multiple instances of components interact as expected ( with a mocked messaging service , and other dependencies , where appropriate ) 
 + * dry start - test that a system starts up properly the first time a node start 
 + * restart - test that a system starts up properly on node restart ( from both clean and unclean shutdown ) 
 + * shutdown - test that a system can shutdown properly 
 + * upgrade - test that a system is able to restart with data from a previous version 
 + 
 + # # # # What shouldn ' t be tested 
 + * The rest of the application . It should be possible to test large systems without starting the entire database through the use of mocks . 
 + 
 + * * Note : * * it ' s generally not a good idea to mock out the storage layer if the component under test needs to interact with it . If you ' re testing 
 + how multiple instances interact with each other , AND they need to use the storage layer , parameterizing the keyspace / table they store data is 
 + the way to do it . 
 + 
 + # # # dtests 
 + python / ccm tests that start local clusters and interact with them via the python client . 
 + 
 + dtests are effectively black box tests , and should be used for checking that clusters and client side interfaces work as expected . They are not 
 + a replacement for proper functional java tests . They take much longer to run , and are much less flexible in what they can test . 
 + 
 + Systems under test in dtest should have more granular integration tests as well . 
 + 
 + # # # # What should be tested 
 + * end to end cluster functionality 
 + * client contracts 
 + * trivial ( to create ) failure cases 
 + 
 + # # # # What shouldn ' t be tested 
 + * internal implementation details 
 + 
 + # # Expanded Guidelines 
 + 
 + This section has more in depth descriptions and reasoning about some of the points raised in the previous section . 
 + 
 + # # # Test structure 
 + 
 + Tests cases should have a clear progression of setup , precondition check , performing some action under test , then a postcondition check . 
 + 
 + * * Example * * 
 + 
 + ` ` ` java 
 + @ Test 
 + public void increment ( ) throws Exception 
 + { 
 + 	 / / setup code 
 + 	 int x = 1 ; 
 + 
 + 	 / / check preconditions 
 + 	 assertEquals ( 1 , x ) ; 
 + 
 + 	 / / perform the state changing action under test 
 + 	 x + + ; 
 + 
 + 	 / / check post conditions 
 + 	 assertEquals ( 2 , x ) ; 
 + } 
 + ` ` ` 
 + 
 + # # # # Reason 
 + 
 + Test cases should be optimized for readability 
 + 
 + # # # # Exceptions 
 + 
 + Cases where simple cases can be tested in one line . Such as validation logic checks : 
 + property - based state testing ( ie : ScalaCheck / QuickCheck ) 
 + 
 + * Example : * 
 + ` ` ` java 
 + @ Test 
 + public void validation ( ) 
 + { 
 + 	 assertValidationFailure ( b - > b . withState ( null ) ) ; 
 + 	 assertValidationFailure ( b - > b . withSessionID ( null ) ) ; 
 + 	 assertValidationFailure ( b - > b . withCoordinator ( null ) ) ; 
 + 	 assertValidationFailure ( b - > b . withTableIds ( null ) ) ; 
 + 	 assertValidationFailure ( b - > b . withTableIds ( new HashSet < > ( ) ) ) ; 
 + 	 assertValidationFailure ( b - > b . withRepairedAt ( 0 ) ) ; 
 + 	 assertValidationFailure ( b - > b . withRepairedAt ( - 1 ) ) ; 
 + 	 assertValidationFailure ( b - > b . withRanges ( null ) ) ; 
 + 	 assertValidationFailure ( b - > b . withRanges ( new HashSet < > ( ) ) ) ; 
 + 	 assertValidationFailure ( b - > b . withParticipants ( null ) ) ; 
 + 	 assertValidationFailure ( b - > b . withParticipants ( new HashSet < > ( ) ) ) ; 
 + 	 assertValidationFailure ( b - > b . withStartedAt ( 0 ) ) ; 
 + 	 assertValidationFailure ( b - > b . withLastUpdate ( 0 ) ) ; 
 + } 
 + ` ` ` 
 + 
 + # # # Test distributed components in junit 
 + 
 + Components that rely on nodes communicating with each other should be testable in java . 
 + 
 + # # # # Reason 
 + 
 + One of the more difficult aspects of distributed systems is ensuring that they continue to behave correctly during various failure modes . This includes weird 
 + edge cases involving specific ordering of events between nodes that rarely occur in the wild . Testing these sorts of scenarios is much easier in junit because 
 + mock ' clusters ' can be placed in specific states , and deterministically stepped through a sequence of events , ensuring that they behave as expected , and are in 
 + the expected state after each step . 
 + 
 + # # # # Exceptions 
 + 
 + This rule mainly applies to new or significantly overhauled systems . Older systems * should * be refactored to be thoroughly tested , but it ' s not necessarily a 
 + prerequisite for working on them . 
 + 
 + # # # Test all branches and inputs . 
 + 
 + All branches and inputs of a method should be exercised . For branches that require multiple criteria to be met , ( ie ` x > 10 & & y < 100 ` ) , there 
 + should be tests demonstrating that the branch is taken when all critera are met ( ie ` x = 11 , y = 99 ` ) , and that it is not taken when only one is met 
 + ( ie : ` x = 11 , y = 200 or x = 5 , y = 99 ` ) . If a method deals with ranges of values , ( ie ` x > = 10 ` ) , the boundaries of the ranges should be tested ( ie : ` x = 9 , x = 10 ` ) 
 + 
 + In the following example 
 + 
 + * * Example * * 
 + ` ` ` java 
 + class SomeClass 
 + { 
 + 	 public static int someFunction ( bool aFlag , int aValue ) 
 + 	 { 
 + 	 	 if ( aFlag & & aValue > 10 ) 
 + 	 	 { 
 + 	 	 	 return 20 ; 
 + 	 	 } 
 + 	 	 else if ( aValue > 5 ) 
 + 	 	 { 
 + 	 	 	 return 10 ; 
 + 	 	 else 
 + 	 	 { 
 + 	 	 	 return 0 ; 
 + 	 	 } 
 + 	 } 
 + } 
 + 
 + class SomeTest 
 + { 
 + 	 public void someFunction ( ) throws Exception 
 + 	 { 
 + 	 	 assertEquals ( 10 , somefunction ( true , 11 ) ) ; 
 + 	 	 assertEquals ( 5 , somefunction ( false , 11 ) ) ; 
 + 	 	 assertEquals ( 5 , somefunction ( true , 8 ) ) ; 
 + 	 	 assertEquals ( 5 , somefunction ( false , 8 ) ) ; 
 + 	 	 assertEquals ( 0 , somefunction ( false , 4 ) ) ; 
 + 	 } 
 + } 
 + ` ` ` 
 + 
 + # # # Test any state transitions 
 + 
 + As an extension of testing all branches and inputs . For stateful systems , there should be tests demonstrating that states change under the intended 
 + circumstances , and that state changes have the intended side effects . 
 + 
 + # # # Test unsupported arguments and states throw exceptions 
 + 
 + If a system is not intended to perform an action in a given state ( ie : a node performing reads during bootstrap ) , or a method is not intended 
 + to encounter some type of argument ( ie : a method that is only designed to work with numeric values > 0 ) , then there should be tests demonstrating 
 + that an appropriate exception is raised ( IllegalStateException or IllegalArgumentException , respectively ) in that case . 
 + 
 + The guava preconditions module makes this straightforward . 
 + 
 + # # # # Reason 
 + 
 + Inadvertent misuse of methods and systems cause bugs that are often silent and subtle . Raising exceptions on unintended usage helps 
 + protect against future bugs and reduces developer surprise . 
 + 
 + # # Dealing with global state 
 + 
 + Unfortunately , the project has extensive amounts of global state which makes actually writing robust tests difficult , but not impossible . 
 + 
 + Having dependencies on global state is not an excuse to not test something , or to throw a dtest or assertion at it and call it a day . 
 + 
 + Structuring code in a way that interacts with global state that can still be deterministically tested just takes a few tweaks 
 + 
 + * * Example , bad * * 
 + ` ` ` java 
 + class SomeVerbHandler implements IVerbHandler < SomeMessage > 
 + { 
 + 	 public void doVerb ( MessageIn < SomeMessage > msg ) 
 + 	 { 
 + 	 	 if ( FailureDetector . instance . isAlive ( msg . payload . otherNode ) ) 
 + 	 	 { 
 + 	 	 	 new StreamPlan ( msg . payload . otherNode ) . requestRanges ( someRanges ) . execute ( ) ; 
 + 	 	 } 
 + 	 	 else 
 + 	 	 { 
 + 	 	 	 CompactionManager . instance . submitBackground ( msg . payload . cfs ) ; 
 + 	 	 } 
 + 	 } 
 + } 
 + ` ` ` 
 + 
 + In this made up example , we ' re checking global state , and then taking some action against other global state . None of the global state 
 + we ' re working with is easy to manipulate for tests , so comprehensive tests for this aren ' t very likely to be written . Even worse , whether 
 + the FailureDetector , streaming , or compaction work properly are out of scope for our purposes . We ' re concerned with whether SomeVerbHandler 
 + works as expected . 
 + 
 + Ideally though , classes won ' t have dependencies on global state at all , and have everything they need to work passed in as constructor arguments . 
 + This also enables comprehensive testing , and stops the spread of global state . 
 + 
 + This prevents the spread of global state , and also begins to identify and define the internal interfaces that will replace global state . 
 + 
 + * * Example , better * * 
 + ` ` ` java 
 + class SomeVerbHandler implements IVerbHandler < SomeMessage > 
 + { 
 + 	 private final IFailureDetector failureDetector ; 
 + 	 private final ICompactionManager compactionManager ; 
 + 	 private final IStreamManager streamManager ; 
 + 
 + 	 public SomeVerbHandler ( IFailureDetector failureDetector , ICompactionManager compactionManager , IStreamManager streamManager ) 
 + 	 { 
 + 	 	 this . failureDetector = failureDetector ; 
 + 	 	 this . compactionManager = compactionManager ; 
 + 	 	 this . streamManager = streamManager ; 
 + 	 } 
 + 
 + 	 public void doVerb ( MessageIn < SomeMessage > msg ) 
 + 	 { 
 + 	 	 if ( failureDetector . isAlive ( msg . payload . otherNode ) ) 
 + 	 	 { 
 + 	 	 	 streamExecutor . submitPlan ( new StreamPlan ( msg . payload . otherNode ) . requestRanges ( someRanges ) ) ; 
 + 	 	 } 
 + 	 	 else 
 + 	 	 { 
 + 	 	 	 compactionManager . submitBackground ( msg . payload . cfs ) ; 
 + 	 	 } 
 + 	 } 
 + } 
 + ` ` ` 
 + 
 + * * Example test * * 
 + ` ` ` java 
 + class SomeVerbTest 
 + { 
 + 	 class InstrumentedFailureDetector implements IFailureDetector 
 + 	 { 
 + 	 	 boolean alive = false ; 
 + 	 	 @ Override 
 + 	 	 public boolean isAlive ( InetAddress address ) 
 + 	 	 { 
 + 	 	 	 return alive ; 
 + 	 	 } 
 + 	 } 
 + 
 + 	 class InstrumentedCompactionManager implements ICompactionManager 
 + 	 { 
 + 	 	 boolean submitted = false ; 
 + 	 	 @ Override 
 + 	 	 public void submitBackground ( ColumnFamilyStore cfs ) 
 + 	 	 { 
 + 	 	 	 submitted = true ; 
 + 	 	 } 
 + 	 } 
 + 
 + 	 class InstrumentedStreamManager implements IStreamManager 
 + 	 { 
 + 	 	 boolean submitted = false ; 
 + 	 	 @ Override 
 + 	 	 public void submitPlan ( StreamPlan plan ) 
 + 	 	 { 
 + 	 	 	 submitted = true ; 
 + 	 	 } 
 + 	 } 
 + 
 + 	 @ Test 
 + 	 public void liveNode ( ) throws Exception 
 + 	 { 
 + 	 	 InstrumentedFailureDetector failureDetector = new InstrumentedFailureDetector ( ) ; 
 + 	 	 failureDetector . alive = true ; 
 + 	 	 InstrumentedCompactionManager compactionManager = new InstrumentedCompactionManager ( ) ; 
 + 	 	 InstrumentedStreamManager streamManager = new InstrumentedStreamManager ( ) ; 
 + 	 	 SomeVerbHandler handler = new SomeVerbHandler ( failureDetector , compactionManager , streamManager ) ; 
 + 
 + 	 	 MessageIn < SomeMessage > msg = new MessageIn < > ( . . . ) ; 
 + 
 + 	 	 assertFalse ( streamManager . submitted ) ; 
 + 	 	 assertFalse ( compactionManager . submitted ) ; 
 + 
 + 	 	 handler . doVerb ( msg ) ; 
 + 
 + 	 	 assertTrue ( streamManager . submitted ) ; 
 + 	 	 assertFalse ( compactionManager . submitted ) ; 
 + 	 } 
 + 
 + 	 @ Test 
 + 	 public void deadNode ( ) throws Exception 
 + 	 { 
 + 	 	 InstrumentedFailureDetector failureDetector = new InstrumentedFailureDetector ( ) ; 
 + 	 	 failureDetector . alive = false ; 
 + 	 	 InstrumentedCompactionManager compactionManager = new InstrumentedCompactionManager ( ) ; 
 + 	 	 InstrumentedStreamManager streamManager = new InstrumentedStreamManager ( ) ; 
 + 	 	 SomeVerbHandler handler = new SomeVerbHandler ( failureDetector , compactionManager , streamManager ) ; 
 + 
 + 	 	 MessageIn < SomeMessage > msg = new MessageIn < > ( . . . ) ; 
 + 
 + 	 	 assertFalse ( streamManager . submitted ) ; 
 + 	 	 assertFalse ( compactionManager . submitted ) ; 
 + 
 + 	 	 handler . doVerb ( msg ) ; 
 + 
 + 	 	 assertFalse ( streamManager . submitted ) ; 
 + 	 	 assertTrue ( compactionManager . submitted ) ; 
 + 	 } 
 + } 
 + ` ` ` 
 + 
 + By abstracting away accesses to global state we can exhaustively test the paths this verb handler can take , and directly confirm that it ' s taking the correct 
 + actions . Obviously , this is a simple example , but for classes or functions with more complex logic , this makes comprehensive testing much easier . 
 + 
 + Note that the interfaces used here probably shouldn ' t be the same ones we use for MBeans . 
 + 
 + However , in some cases , passing interfaces into the constructor may not be practical . Classes that are instantiated on startup need to be handled with care , since accessing 
 + a singleton may change the initialization order of the database . It may also be a larger change than is warranted for something like a bug fix . In any case , if passing 
 + dependencies into the constructor is not practical , wrapping accesses to global state in protected methods that are overridden for tests will achieve the same thing . 
 + 
 + 
 + * * Example , alternative * * 
 + ` ` ` javayy 
 + class SomeVerbHandler implements IVerbHandler < SomeMessage > 
 + { 
 + 	 @ VisibleForTesting 
 + 	 protected boolean isAlive ( InetAddress addr ) { return FailureDetector . instance . isAlive ( msg . payload . otherNode ) ; } 
 + 
 + 	 @ VisibleForTesting 
 + 	 protected void streamSomethind ( InetAddress to ) { new StreamPlan ( to ) . requestRanges ( someRanges ) . execute ( ) ; } 
 + 
 + 	 @ VisibleForTesting 
 + 	 protected void compactSomething ( ColumnFamilyStore cfs ) { CompactionManager . instance . submitBackground ( ) ; } 
 + 
 + 	 public void doVerb ( MessageIn < SomeMessage > msg ) 
 + 	 { 
 + 	 	 if ( isAlive ( msg . payload . otherNode ) ) 
 + 	 	 { 
 + 	 	 	 streamSomething ( msg . payload . otherNode ) ; 
 + 	 	 } 
 + 	 	 else 
 + 	 	 { 
 + 	 	 	 compactSomething ( ) ; 
 + 	 	 } 
 + 	 } 
 + } 
 + ` ` ` 
 + 
 + * * Example test * * 
 + ` ` ` java 
 + class SomeVerbTest 
 + { 
 + 	 static class InstrumentedSomeVerbHandler extends SomeVerbHandler 
 + 	 { 
 + 	 	 public boolean alive = false ; 
 + 	 	 public boolean streamCalled = false ; 
 + 	 	 public boolean compactCalled = false ; 
 + 
 + 	 	 @ Override 
 + 	 	 protected boolean isAlive ( InetAddress addr ) { return alive ; } 
 + 	 	 
 + 	 	 @ Override 
 + 	 	 protected void streamSomethind ( InetAddress to ) { streamCalled = true ; } 
 + 
 + 	 	 @ Override 
 + 	 	 protected void compactSomething ( ColumnFamilyStore cfs ) { compactCalled = true ; } 
 + 	 } 
 + 
 + 	 @ Test 
 + 	 public void liveNode ( ) throws Exception 
 + 	 { 
 + 	 	 InstrumentedSomeVerbHandler handler = new InstrumentedSomeVerbHandler ( ) ; 
 + 	 	 handler . alive = true ; 
 + 	 	 MessageIn < SomeMessage > msg = new MessageIn < > ( . . . ) ; 
 + 
 + 	 	 assertFalse ( handler . streamCalled ) ; 
 + 	 	 assertFalse ( handler . compactCalled ) ; 
 + 
 + 	 	 handler . doVerb ( msg ) ; 
 + 
 + 	 	 assertTrue ( handler . streamCalled ) ; 
 + 	 	 assertFalse ( handler . compactCalled ) ; 
 + 	 } 
 + 
 + 	 @ Test 
 + 	 public void deadNode ( ) throws Exception 
 + 	 { 
 + 	 	 InstrumentedSomeVerbHandler handler = new InstrumentedSomeVerbHandler ( ) ; 
 + 	 	 handler . alive = false ; 
 + 	 	 MessageIn < SomeMessage > msg = new MessageIn < > ( . . . ) ; 
 + 
 + 	 	 assertFalse ( handler . streamCalled ) ; 
 + 	 	 assertFalse ( handler . compactCalled ) ; 
 + 
 + 	 	 handler . doVerb ( msg ) ; 
 + 
 + 	 	 assertFalse ( handler . streamCalled ) ; 
 + 	 	 assertTrue ( handler . compactCalled ) ; 
 + 	 } 
 + } 
 + ` ` ` 
 + 
 + # # Refactoring Existing Code 
 + 
 + If you ' re working on a section of the project that historically hasn ' t been well tested , it will likely be more difficult for you to write tests around 
 + whatever you ' re doing , since the code may not have been written with testing in mind . You do need to add tests around the subject of you ' re 
 + jira , and this will probably involve some refactoring , but you ' re also not expected to completely refactor a huge class to submit a bugfix . 
 + 
 + Basically , you need to be able to verify the behavior you intend to modify before and after your patch . The amount of testing debt you pay back should be 
 + roughly proportional to the scope of your change . If you ' re doing a small bugfix , you can get away with refactoring just enough to make the subject of your 
 + fix testable , even if you start to get into ' testing implementation details ' territory ' . The goal is incremental improvement , not making things perfect on 
 + the first iteration . If you ' re doing something more ambitious though , you may have to do some extra work to sufficiently test your changes . 
 + 
 + # # Refactoring Untested Code 
 + 
 + There are several components that have very little , if any , direct test coverage . We really should try to improve the test coverage of these components . 
 + For people interested in getting involved with the project , adding tests for these is a great way to get familiar with the codebase . 
 + 
 + First , get feedback on the subject and scope of your proposed refactor , especially larger ones . The smaller and more narrowly focused your proposed 
 + refactor is , the easier it will be for you to get it reviewed and committed . 
 + 
 + Start with smaller pieces , refactor and test them , and work outwards , iteratively . Preferably in several jiras . Ideally , each patch should add some value 
 + to the project on it ' s own in terms of test coverage . Patches that are heavy on refactoring , and light on tests are not likely to get committed . People come and go 
 + from projects , and having a many small improvements is better for the project than several unfinished or ongoing refactors that don ' t add much test coverage .

NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index b935425 . . 7f5a487 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 1 . 2 - rc1 
 + * fix cqlsh rendering of blob fields ( CASSANDRA - 4970 ) 
 * fix cqlsh DESCRIBE command ( CASSANDRA - 4913 ) 
 * save truncation position in system table ( CASSANDRA - 4906 ) 
 * Move CompressionMetadata off - heap ( CASSANDRA - 4937 ) 
 diff - - git a / pylib / cqlshlib / formatting . py b / pylib / cqlshlib / formatting . py 
 index d15c083 . . bab3506 100644 
 - - - a / pylib / cqlshlib / formatting . py 
 + + + b / pylib / cqlshlib / formatting . py 
 @ @ - 88 , 8 + 88 , 8 @ @ def formatter _ for ( typname ) : 
 return f 
 return registrator 
 
 - @ formatter _ for ( ' bytes ' ) 
 - def format _ value _ bytes ( val , colormap , * * _ ) : 
 + @ formatter _ for ( ' blob ' ) 
 + def format _ value _ blob ( val , colormap , * * _ ) : 
 bval = ' ' . join ( ' % 02x ' % ord ( c ) for c in val ) 
 return colorme ( bval , colormap , ' hex ' ) 

