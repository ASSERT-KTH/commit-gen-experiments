BLEU SCORE: 0.028398387225677897

TEST MSG: merged cassandra - 2 . 1 to trunk ( for CASSANDRA - 7033 )
GENERATED MSG: update stress tool to be able to use CQL3

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 284f8a6 . . fa1e3af 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 57 , 6 + 57 , 7 @ @ <nl> * Clean up IndexInfo on keyspace / table drops ( CASSANDRA - 6924 ) <nl> * Only snapshot relative SSTables when sequential repair ( CASSANDRA - 7024 ) <nl> * Require nodetool rebuild _ index to specify index names ( CASSANDRA - 7038 ) <nl> + * fix cassandra stress errors on reads with native protocol ( CASANDRA - 7033 ) <nl> Merged from 2 . 0 : <nl> * Use LOCAL _ QUORUM for data reads at LOCAL _ SERIAL ( CASSANDRA - 6939 ) <nl> * Log a warning for large batches ( CASSANDRA - 6487 ) <nl> diff - - git a / tools / stress / src / org / apache / cassandra / stress / operations / CqlIndexedRangeSlicer . java b / tools / stress / src / org / apache / cassandra / stress / operations / CqlIndexedRangeSlicer . java <nl> index 6febe26 . . 961c8fe 100644 <nl> - - - a / tools / stress / src / org / apache / cassandra / stress / operations / CqlIndexedRangeSlicer . java <nl> + + + b / tools / stress / src / org / apache / cassandra / stress / operations / CqlIndexedRangeSlicer . java <nl> @ @ - 47 , 10 + 47 , 13 @ @ public class CqlIndexedRangeSlicer extends CqlOperation < byte [ ] [ ] > <nl> @ Override <nl> protected String buildQuery ( ) <nl> { <nl> - final String indexColumn = ( state . settings . columns . namestrs . get ( 1 ) ) ; <nl> - StringBuilder query = new StringBuilder ( " SELECT * FROM " ) ; <nl> + StringBuilder query = new StringBuilder ( " SELECT " ) ; <nl> + query . append ( wrapInQuotes ( " key " ) ) ; <nl> + query . append ( " FROM " ) ; <nl> query . append ( wrapInQuotes ( state . type . table ) ) ; <nl> - query . append ( " WHERE " ) . append ( indexColumn ) . append ( " = ? " ) <nl> + <nl> + final String columnName = ( state . settings . columns . namestrs . get ( 1 ) ) ; <nl> + query . append ( " WHERE " ) . append ( columnName ) . append ( " = ? " ) <nl> . append ( " AND KEY > ? LIMIT " ) . append ( state . settings . command . keysAtOnce ) ; <nl> return query . toString ( ) ; <nl> } <nl> diff - - git a / tools / stress / src / org / apache / cassandra / stress / operations / CqlOperation . java b / tools / stress / src / org / apache / cassandra / stress / operations / CqlOperation . java <nl> index 6da145e . . 11fb637 100644 <nl> - - - a / tools / stress / src / org / apache / cassandra / stress / operations / CqlOperation . java <nl> + + + b / tools / stress / src / org / apache / cassandra / stress / operations / CqlOperation . java <nl> @ @ - 145 , 7 + 145 , 7 @ @ public abstract class CqlOperation < V > extends Operation <nl> @ Override <nl> public boolean validate ( Integer result ) <nl> { <nl> - return true ; <nl> + return result > 0 ; <nl> } <nl> <nl> @ Override <nl> @ @ - 195 , 12 + 195 , 8 @ @ public abstract class CqlOperation < V > extends Operation <nl> if ( result . length ! = expect . size ( ) ) <nl> return false ; <nl> for ( int i = 0 ; i < result . length ; i + + ) <nl> - { <nl> - List < ByteBuffer > resultRow = Arrays . asList ( result [ i ] ) ; <nl> - resultRow = resultRow . subList ( 1 , resultRow . size ( ) ) ; <nl> - if ( expect . get ( i ) ! = null & & ! expect . get ( i ) . equals ( resultRow ) ) <nl> + if ( expect . get ( i ) ! = null & & ! expect . get ( i ) . equals ( Arrays . asList ( result [ i ] ) ) ) <nl> return false ; <nl> - } <nl> return true ; <nl> } <nl> } <nl> @ @ - 473 , 9 + 469 , 9 @ @ public abstract class CqlOperation < V > extends Operation <nl> for ( int i = 0 ; i < r . length ; i + + ) <nl> { <nl> Row row = rows . get ( i ) ; <nl> - r [ i ] = new ByteBuffer [ row . getColumnDefinitions ( ) . size ( ) - 1 ] ; <nl> - for ( int j = 1 ; j < row . getColumnDefinitions ( ) . size ( ) ; j + + ) <nl> - r [ i ] [ j - 1 ] = row . getBytes ( j ) ; <nl> + r [ i ] = new ByteBuffer [ row . getColumnDefinitions ( ) . size ( ) ] ; <nl> + for ( int j = 0 ; j < row . getColumnDefinitions ( ) . size ( ) ; j + + ) <nl> + r [ i ] [ j ] = row . getBytes ( j ) ; <nl> } <nl> return r ; <nl> } <nl> diff - - git a / tools / stress / src / org / apache / cassandra / stress / operations / CqlReader . java b / tools / stress / src / org / apache / cassandra / stress / operations / CqlReader . java <nl> index c9d8870 . . b2ea8c1 100644 <nl> - - - a / tools / stress / src / org / apache / cassandra / stress / operations / CqlReader . java <nl> + + + b / tools / stress / src / org / apache / cassandra / stress / operations / CqlReader . java <nl> @ @ - 22 , 11 + 22 , 13 @ @ package org . apache . cassandra . stress . operations ; <nl> <nl> <nl> import java . nio . ByteBuffer ; <nl> - import java . util . ArrayList ; <nl> + import java . nio . charset . CharacterCodingException ; <nl> import java . util . Arrays ; <nl> import java . util . Collections ; <nl> import java . util . List ; <nl> <nl> + import org . apache . cassandra . utils . ByteBufferUtil ; <nl> + <nl> public class CqlReader extends CqlOperation < ByteBuffer [ ] [ ] > <nl> { <nl> <nl> @ @ - 46 , 11 + 48 , 18 @ @ public class CqlReader extends CqlOperation < ByteBuffer [ ] [ ] > <nl> } <nl> else <nl> { <nl> - for ( int i = 0 ; i < state . settings . columns . names . size ( ) ; i + + ) <nl> + try <nl> + { <nl> + for ( int i = 0 ; i < state . settings . columns . names . size ( ) ; i + + ) <nl> + { <nl> + if ( i > 0 ) <nl> + query . append ( " , " ) ; <nl> + query . append ( wrapInQuotes ( ByteBufferUtil . string ( state . settings . columns . names . get ( i ) ) ) ) ; <nl> + } <nl> + } <nl> + catch ( CharacterCodingException e ) <nl> { <nl> - if ( i > 0 ) <nl> - query . append ( " , " ) ; <nl> - query . append ( ' ? ' ) ; <nl> + throw new IllegalStateException ( e ) ; <nl> } <nl> } <nl> <nl> @ @ - 63 , 14 + 72 , 6 @ @ public class CqlReader extends CqlOperation < ByteBuffer [ ] [ ] > <nl> @ Override <nl> protected List < Object > getQueryParameters ( byte [ ] key ) <nl> { <nl> - if ( state . settings . columns . names ! = null ) <nl> - { <nl> - final List < Object > queryParams = new ArrayList < > ( ) ; <nl> - for ( ByteBuffer name : state . settings . columns . names ) <nl> - queryParams . add ( name ) ; <nl> - queryParams . add ( ByteBuffer . wrap ( key ) ) ; <nl> - return queryParams ; <nl> - } <nl> return Collections . < Object > singletonList ( ByteBuffer . wrap ( key ) ) ; <nl> } <nl>
NEAREST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 896b8cc . . 95a8b18 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 5 + 1 , 5 @ @ <nl> 1 . 2 - beta1 <nl> - * add atomic _ batch _ mutate ( CASSANDRA - 4542 ) <nl> + * add atomic _ batch _ mutate ( CASSANDRA - 4542 , - 4635 ) <nl> * increase default max _ hint _ window _ in _ ms to 3h ( CASSANDRA - 4632 ) <nl> * include message initiation time to replicas so they can more <nl> accurately drop timed - out requests ( CASSANDRA - 2858 ) <nl> diff - - git a / src / java / org / apache / cassandra / config / CFMetaData . java b / src / java / org / apache / cassandra / config / CFMetaData . java <nl> index 9ee684c . . 4e29fc7 100644 <nl> - - - a / src / java / org / apache / cassandra / config / CFMetaData . java <nl> + + + b / src / java / org / apache / cassandra / config / CFMetaData . java <nl> @ @ - 194 , 7 + 194 , 6 @ @ public final class CFMetaData <nl> <nl> public static final CFMetaData BatchlogCF = compile ( 16 , " CREATE TABLE " + SystemTable . BATCHLOG _ CF + " ( " <nl> + " id uuid PRIMARY KEY , " <nl> - + " coordinator inet , " <nl> + " written _ at timestamp , " <nl> + " data blob " <nl> + " ) WITH COMMENT = ' uncommited batches ' AND gc _ grace _ seconds = 0 " ) ; <nl> diff - - git a / src / java / org / apache / cassandra / db / BatchlogManager . java b / src / java / org / apache / cassandra / db / BatchlogManager . java <nl> index 2ae9361 . . ded1ca4 100644 <nl> - - - a / src / java / org / apache / cassandra / db / BatchlogManager . java <nl> + + + b / src / java / org / apache / cassandra / db / BatchlogManager . java <nl> @ @ - 23 , 6 + 23 , 8 @ @ import java . net . InetAddress ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . * ; <nl> import java . util . concurrent . TimeUnit ; <nl> + import java . util . concurrent . atomic . AtomicBoolean ; <nl> + import java . util . concurrent . atomic . AtomicLong ; <nl> import javax . management . MBeanServer ; <nl> import javax . management . ObjectName ; <nl> <nl> @ @ - 32 , 17 + 34 , 16 @ @ import org . slf4j . LoggerFactory ; <nl> <nl> import org . apache . cassandra . config . CFMetaData ; <nl> import org . apache . cassandra . config . DatabaseDescriptor ; <nl> + import org . apache . cassandra . db . filter . IFilter ; <nl> import org . apache . cassandra . db . filter . NamesQueryFilter ; <nl> import org . apache . cassandra . db . filter . QueryFilter ; <nl> import org . apache . cassandra . db . filter . QueryPath ; <nl> - import org . apache . cassandra . db . marshal . InetAddressType ; <nl> import org . apache . cassandra . db . marshal . LongType ; <nl> import org . apache . cassandra . db . marshal . UTF8Type ; <nl> import org . apache . cassandra . db . marshal . UUIDType ; <nl> import org . apache . cassandra . dht . AbstractBounds ; <nl> import org . apache . cassandra . dht . IPartitioner ; <nl> import org . apache . cassandra . dht . Range ; <nl> - import org . apache . cassandra . gms . FailureDetector ; <nl> import org . apache . cassandra . io . util . FastByteArrayOutputStream ; <nl> import org . apache . cassandra . net . MessagingService ; <nl> import org . apache . cassandra . service . StorageProxy ; <nl> @ @ - 54 , 17 + 55 , 18 @ @ public class BatchlogManager implements BatchlogManagerMBean <nl> { <nl> private static final String MBEAN _ NAME = " org . apache . cassandra . db : type = BatchlogManager " ; <nl> private static final int VERSION = MessagingService . VERSION _ 12 ; <nl> - private static final long TIMEOUT = 2 * DatabaseDescriptor . getRpcTimeout ( ) ; <nl> + private static final long TIMEOUT = 2 * DatabaseDescriptor . getWriteRpcTimeout ( ) ; <nl> <nl> - private static final ByteBuffer COORDINATOR = columnName ( " coordinator " ) ; <nl> private static final ByteBuffer WRITTEN _ AT = columnName ( " written _ at " ) ; <nl> private static final ByteBuffer DATA = columnName ( " data " ) ; <nl> - private static final SortedSet < ByteBuffer > META = ImmutableSortedSet . of ( COORDINATOR , WRITTEN _ AT ) ; <nl> <nl> private static final Logger logger = LoggerFactory . getLogger ( BatchlogManager . class ) ; <nl> <nl> public static final BatchlogManager instance = new BatchlogManager ( ) ; <nl> <nl> + private final AtomicLong totalBatchesReplayed = new AtomicLong ( ) ; <nl> + private final AtomicBoolean isReplaying = new AtomicBoolean ( ) ; <nl> + <nl> public void start ( ) <nl> { <nl> MBeanServer mbs = ManagementFactory . getPlatformMBeanServer ( ) ; <nl> @ @ - 90 , 15 + 92 , 43 @ @ public class BatchlogManager implements BatchlogManagerMBean <nl> TimeUnit . MILLISECONDS ) ; <nl> } <nl> <nl> + public int countAllBatches ( ) <nl> + { <nl> + int count = 0 ; <nl> + <nl> + for ( Row row : getRangeSlice ( new NamesQueryFilter ( ImmutableSortedSet . < ByteBuffer > of ( ) ) ) ) <nl> + { <nl> + if ( row . cf ! = null & & ! row . cf . isMarkedForDelete ( ) ) <nl> + count + + ; <nl> + } <nl> + <nl> + return count ; <nl> + } <nl> + <nl> + public long getTotalBatchesReplayed ( ) <nl> + { <nl> + return totalBatchesReplayed . longValue ( ) ; <nl> + } <nl> + <nl> + public void forceBatchlogReplay ( ) <nl> + { <nl> + Runnable runnable = new Runnable ( ) <nl> + { <nl> + public void run ( ) <nl> + { <nl> + replayAllFailedBatches ( ) ; <nl> + } <nl> + } ; <nl> + StorageService . optionalTasks . execute ( runnable ) ; <nl> + } <nl> + <nl> public static RowMutation getBatchlogMutationFor ( Collection < RowMutation > mutations , UUID uuid ) <nl> { <nl> long timestamp = FBUtilities . timestampMicros ( ) ; <nl> - ByteBuffer coordinator = InetAddressType . instance . decompose ( FBUtilities . getBroadcastAddress ( ) ) ; <nl> ByteBuffer writtenAt = LongType . instance . decompose ( timestamp / 1000 ) ; <nl> ByteBuffer data = serializeRowMutations ( mutations ) ; <nl> <nl> ColumnFamily cf = ColumnFamily . create ( CFMetaData . BatchlogCF ) ; <nl> - cf . addColumn ( new Column ( COORDINATOR , coordinator , timestamp ) ) ; <nl> cf . addColumn ( new Column ( WRITTEN _ AT , writtenAt , timestamp ) ) ; <nl> cf . addColumn ( new Column ( DATA , data , timestamp ) ) ; <nl> RowMutation rm = new RowMutation ( Table . SYSTEM _ KS , UUIDType . instance . decompose ( uuid ) ) ; <nl> @ @ - 126 , 55 + 156 , 38 @ @ public class BatchlogManager implements BatchlogManagerMBean <nl> return ByteBuffer . wrap ( bos . toByteArray ( ) ) ; <nl> } <nl> <nl> - private static void replayAllFailedBatches ( ) <nl> + private void replayAllFailedBatches ( ) <nl> { <nl> - if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " Started replayAllFailedBatches " ) ; <nl> - <nl> - ColumnFamilyStore store = Table . open ( Table . SYSTEM _ KS ) . getColumnFamilyStore ( SystemTable . BATCHLOG _ CF ) ; <nl> - <nl> - if ( store . isEmpty ( ) ) <nl> + if ( ! isReplaying . compareAndSet ( false , true ) ) <nl> return ; <nl> <nl> - IPartitioner partitioner = StorageService . getPartitioner ( ) ; <nl> - RowPosition minPosition = partitioner . getMinimumToken ( ) . minKeyBound ( ) ; <nl> - AbstractBounds < RowPosition > range = new Range < RowPosition > ( minPosition , minPosition , partitioner ) ; <nl> - <nl> - List < Row > rows = store . getRangeSlice ( null , range , Integer . MAX _ VALUE , new NamesQueryFilter ( META ) , null ) ; <nl> - <nl> - for ( Row row : rows ) <nl> + try <nl> { <nl> - if ( row . cf . isMarkedForDelete ( ) ) <nl> - continue ; <nl> - <nl> - IColumn coordinatorColumn = row . cf . getColumn ( COORDINATOR ) ; <nl> - IColumn writtenAtColumn = row . cf . getColumn ( WRITTEN _ AT ) ; <nl> + logger . debug ( " Started replayAllFailedBatches " ) ; <nl> <nl> - if ( coordinatorColumn = = null | | writtenAtColumn = = null ) <nl> + for ( Row row : getRangeSlice ( new NamesQueryFilter ( WRITTEN _ AT ) ) ) <nl> { <nl> - replayBatch ( row . key ) ; <nl> - continue ; <nl> - } <nl> + if ( row . cf = = null | | row . cf . isMarkedForDelete ( ) ) <nl> + continue ; <nl> <nl> - InetAddress coordinator = InetAddressType . instance . compose ( coordinatorColumn . value ( ) ) ; <nl> - long writtenAt = LongType . instance . compose ( writtenAtColumn . value ( ) ) ; <nl> - / / if the batch is new and its coordinator is alive - give it a chance to complete naturally . <nl> - if ( System . currentTimeMillis ( ) < writtenAt + TIMEOUT & & FailureDetector . instance . isAlive ( coordinator ) ) <nl> - continue ; <nl> - <nl> - replayBatch ( row . key ) ; <nl> + IColumn writtenAt = row . cf . getColumn ( WRITTEN _ AT ) ; <nl> + if ( writtenAt = = null | | System . currentTimeMillis ( ) > LongType . instance . compose ( writtenAt . value ( ) ) + TIMEOUT ) <nl> + replayBatch ( row . key ) ; <nl> + } <nl> + } <nl> + finally <nl> + { <nl> + isReplaying . set ( false ) ; <nl> } <nl> <nl> - if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " Finished replayAllFailedBatches " ) ; <nl> + logger . debug ( " Finished replayAllFailedBatches " ) ; <nl> } <nl> <nl> - private static void replayBatch ( DecoratedKey key ) <nl> + private void replayBatch ( DecoratedKey key ) <nl> { <nl> UUID uuid = UUIDType . instance . compose ( key . key ) ; <nl> <nl> - if ( logger . isDebugEnabled ( ) ) <nl> - logger . debug ( " Replaying batch { } " , uuid ) ; <nl> + logger . debug ( " Replaying batch { } " , uuid ) ; <nl> <nl> ColumnFamilyStore store = Table . open ( Table . SYSTEM _ KS ) . getColumnFamilyStore ( SystemTable . BATCHLOG _ CF ) ; <nl> QueryFilter filter = QueryFilter . getNamesFilter ( key , new QueryPath ( SystemTable . BATCHLOG _ CF ) , DATA ) ; <nl> @ @ - 195 , 6 + 208 , 7 @ @ public class BatchlogManager implements BatchlogManagerMBean <nl> } <nl> <nl> deleteBatch ( key ) ; <nl> + totalBatchesReplayed . incrementAndGet ( ) ; <nl> } <nl> <nl> private static void writeHintsForSerializedMutations ( ByteBuffer data ) throws IOException <nl> @ @ - 228 , 4 + 242 , 13 @ @ public class BatchlogManager implements BatchlogManagerMBean <nl> ByteBuffer raw = UTF8Type . instance . decompose ( name ) ; <nl> return CFMetaData . BatchlogCF . getCfDef ( ) . getColumnNameBuilder ( ) . add ( raw ) . build ( ) ; <nl> } <nl> + <nl> + private static List < Row > getRangeSlice ( IFilter columnFilter ) <nl> + { <nl> + ColumnFamilyStore store = Table . open ( Table . SYSTEM _ KS ) . getColumnFamilyStore ( SystemTable . BATCHLOG _ CF ) ; <nl> + IPartitioner partitioner = StorageService . getPartitioner ( ) ; <nl> + RowPosition minPosition = partitioner . getMinimumToken ( ) . minKeyBound ( ) ; <nl> + AbstractBounds < RowPosition > range = new Range < RowPosition > ( minPosition , minPosition , partitioner ) ; <nl> + return store . getRangeSlice ( null , range , Integer . MAX _ VALUE , columnFilter , null ) ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / BatchlogManagerMBean . java b / src / java / org / apache / cassandra / db / BatchlogManagerMBean . java <nl> index 0322b21 . . 2e60ba4 100644 <nl> - - - a / src / java / org / apache / cassandra / db / BatchlogManagerMBean . java <nl> + + + b / src / java / org / apache / cassandra / db / BatchlogManagerMBean . java <nl> @ @ - 19 , 4 + 19 , 20 @ @ package org . apache . cassandra . db ; <nl> <nl> public interface BatchlogManagerMBean <nl> { <nl> + / * * <nl> + * Counts all batches currently in the batchlog . <nl> + * <nl> + * @ return total batch count <nl> + * / <nl> + public int countAllBatches ( ) ; <nl> + <nl> + / * * <nl> + * @ return total count of batches replayed since node start <nl> + * / <nl> + public long getTotalBatchesReplayed ( ) ; <nl> + <nl> + / * * <nl> + * Forces batchlog replay . Returns immediately if replay is already in progress . <nl> + * / <nl> + public void forceBatchlogReplay ( ) ; <nl> }

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 284f8a6 . . fa1e3af 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 57 , 6 + 57 , 7 @ @ 
 * Clean up IndexInfo on keyspace / table drops ( CASSANDRA - 6924 ) 
 * Only snapshot relative SSTables when sequential repair ( CASSANDRA - 7024 ) 
 * Require nodetool rebuild _ index to specify index names ( CASSANDRA - 7038 ) 
 + * fix cassandra stress errors on reads with native protocol ( CASANDRA - 7033 ) 
 Merged from 2 . 0 : 
 * Use LOCAL _ QUORUM for data reads at LOCAL _ SERIAL ( CASSANDRA - 6939 ) 
 * Log a warning for large batches ( CASSANDRA - 6487 ) 
 diff - - git a / tools / stress / src / org / apache / cassandra / stress / operations / CqlIndexedRangeSlicer . java b / tools / stress / src / org / apache / cassandra / stress / operations / CqlIndexedRangeSlicer . java 
 index 6febe26 . . 961c8fe 100644 
 - - - a / tools / stress / src / org / apache / cassandra / stress / operations / CqlIndexedRangeSlicer . java 
 + + + b / tools / stress / src / org / apache / cassandra / stress / operations / CqlIndexedRangeSlicer . java 
 @ @ - 47 , 10 + 47 , 13 @ @ public class CqlIndexedRangeSlicer extends CqlOperation < byte [ ] [ ] > 
 @ Override 
 protected String buildQuery ( ) 
 { 
 - final String indexColumn = ( state . settings . columns . namestrs . get ( 1 ) ) ; 
 - StringBuilder query = new StringBuilder ( " SELECT * FROM " ) ; 
 + StringBuilder query = new StringBuilder ( " SELECT " ) ; 
 + query . append ( wrapInQuotes ( " key " ) ) ; 
 + query . append ( " FROM " ) ; 
 query . append ( wrapInQuotes ( state . type . table ) ) ; 
 - query . append ( " WHERE " ) . append ( indexColumn ) . append ( " = ? " ) 
 + 
 + final String columnName = ( state . settings . columns . namestrs . get ( 1 ) ) ; 
 + query . append ( " WHERE " ) . append ( columnName ) . append ( " = ? " ) 
 . append ( " AND KEY > ? LIMIT " ) . append ( state . settings . command . keysAtOnce ) ; 
 return query . toString ( ) ; 
 } 
 diff - - git a / tools / stress / src / org / apache / cassandra / stress / operations / CqlOperation . java b / tools / stress / src / org / apache / cassandra / stress / operations / CqlOperation . java 
 index 6da145e . . 11fb637 100644 
 - - - a / tools / stress / src / org / apache / cassandra / stress / operations / CqlOperation . java 
 + + + b / tools / stress / src / org / apache / cassandra / stress / operations / CqlOperation . java 
 @ @ - 145 , 7 + 145 , 7 @ @ public abstract class CqlOperation < V > extends Operation 
 @ Override 
 public boolean validate ( Integer result ) 
 { 
 - return true ; 
 + return result > 0 ; 
 } 
 
 @ Override 
 @ @ - 195 , 12 + 195 , 8 @ @ public abstract class CqlOperation < V > extends Operation 
 if ( result . length ! = expect . size ( ) ) 
 return false ; 
 for ( int i = 0 ; i < result . length ; i + + ) 
 - { 
 - List < ByteBuffer > resultRow = Arrays . asList ( result [ i ] ) ; 
 - resultRow = resultRow . subList ( 1 , resultRow . size ( ) ) ; 
 - if ( expect . get ( i ) ! = null & & ! expect . get ( i ) . equals ( resultRow ) ) 
 + if ( expect . get ( i ) ! = null & & ! expect . get ( i ) . equals ( Arrays . asList ( result [ i ] ) ) ) 
 return false ; 
 - } 
 return true ; 
 } 
 } 
 @ @ - 473 , 9 + 469 , 9 @ @ public abstract class CqlOperation < V > extends Operation 
 for ( int i = 0 ; i < r . length ; i + + ) 
 { 
 Row row = rows . get ( i ) ; 
 - r [ i ] = new ByteBuffer [ row . getColumnDefinitions ( ) . size ( ) - 1 ] ; 
 - for ( int j = 1 ; j < row . getColumnDefinitions ( ) . size ( ) ; j + + ) 
 - r [ i ] [ j - 1 ] = row . getBytes ( j ) ; 
 + r [ i ] = new ByteBuffer [ row . getColumnDefinitions ( ) . size ( ) ] ; 
 + for ( int j = 0 ; j < row . getColumnDefinitions ( ) . size ( ) ; j + + ) 
 + r [ i ] [ j ] = row . getBytes ( j ) ; 
 } 
 return r ; 
 } 
 diff - - git a / tools / stress / src / org / apache / cassandra / stress / operations / CqlReader . java b / tools / stress / src / org / apache / cassandra / stress / operations / CqlReader . java 
 index c9d8870 . . b2ea8c1 100644 
 - - - a / tools / stress / src / org / apache / cassandra / stress / operations / CqlReader . java 
 + + + b / tools / stress / src / org / apache / cassandra / stress / operations / CqlReader . java 
 @ @ - 22 , 11 + 22 , 13 @ @ package org . apache . cassandra . stress . operations ; 
 
 
 import java . nio . ByteBuffer ; 
 - import java . util . ArrayList ; 
 + import java . nio . charset . CharacterCodingException ; 
 import java . util . Arrays ; 
 import java . util . Collections ; 
 import java . util . List ; 
 
 + import org . apache . cassandra . utils . ByteBufferUtil ; 
 + 
 public class CqlReader extends CqlOperation < ByteBuffer [ ] [ ] > 
 { 
 
 @ @ - 46 , 11 + 48 , 18 @ @ public class CqlReader extends CqlOperation < ByteBuffer [ ] [ ] > 
 } 
 else 
 { 
 - for ( int i = 0 ; i < state . settings . columns . names . size ( ) ; i + + ) 
 + try 
 + { 
 + for ( int i = 0 ; i < state . settings . columns . names . size ( ) ; i + + ) 
 + { 
 + if ( i > 0 ) 
 + query . append ( " , " ) ; 
 + query . append ( wrapInQuotes ( ByteBufferUtil . string ( state . settings . columns . names . get ( i ) ) ) ) ; 
 + } 
 + } 
 + catch ( CharacterCodingException e ) 
 { 
 - if ( i > 0 ) 
 - query . append ( " , " ) ; 
 - query . append ( ' ? ' ) ; 
 + throw new IllegalStateException ( e ) ; 
 } 
 } 
 
 @ @ - 63 , 14 + 72 , 6 @ @ public class CqlReader extends CqlOperation < ByteBuffer [ ] [ ] > 
 @ Override 
 protected List < Object > getQueryParameters ( byte [ ] key ) 
 { 
 - if ( state . settings . columns . names ! = null ) 
 - { 
 - final List < Object > queryParams = new ArrayList < > ( ) ; 
 - for ( ByteBuffer name : state . settings . columns . names ) 
 - queryParams . add ( name ) ; 
 - queryParams . add ( ByteBuffer . wrap ( key ) ) ; 
 - return queryParams ; 
 - } 
 return Collections . < Object > singletonList ( ByteBuffer . wrap ( key ) ) ; 
 } 


NEAREST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 896b8cc . . 95a8b18 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 5 + 1 , 5 @ @ 
 1 . 2 - beta1 
 - * add atomic _ batch _ mutate ( CASSANDRA - 4542 ) 
 + * add atomic _ batch _ mutate ( CASSANDRA - 4542 , - 4635 ) 
 * increase default max _ hint _ window _ in _ ms to 3h ( CASSANDRA - 4632 ) 
 * include message initiation time to replicas so they can more 
 accurately drop timed - out requests ( CASSANDRA - 2858 ) 
 diff - - git a / src / java / org / apache / cassandra / config / CFMetaData . java b / src / java / org / apache / cassandra / config / CFMetaData . java 
 index 9ee684c . . 4e29fc7 100644 
 - - - a / src / java / org / apache / cassandra / config / CFMetaData . java 
 + + + b / src / java / org / apache / cassandra / config / CFMetaData . java 
 @ @ - 194 , 7 + 194 , 6 @ @ public final class CFMetaData 
 
 public static final CFMetaData BatchlogCF = compile ( 16 , " CREATE TABLE " + SystemTable . BATCHLOG _ CF + " ( " 
 + " id uuid PRIMARY KEY , " 
 - + " coordinator inet , " 
 + " written _ at timestamp , " 
 + " data blob " 
 + " ) WITH COMMENT = ' uncommited batches ' AND gc _ grace _ seconds = 0 " ) ; 
 diff - - git a / src / java / org / apache / cassandra / db / BatchlogManager . java b / src / java / org / apache / cassandra / db / BatchlogManager . java 
 index 2ae9361 . . ded1ca4 100644 
 - - - a / src / java / org / apache / cassandra / db / BatchlogManager . java 
 + + + b / src / java / org / apache / cassandra / db / BatchlogManager . java 
 @ @ - 23 , 6 + 23 , 8 @ @ import java . net . InetAddress ; 
 import java . nio . ByteBuffer ; 
 import java . util . * ; 
 import java . util . concurrent . TimeUnit ; 
 + import java . util . concurrent . atomic . AtomicBoolean ; 
 + import java . util . concurrent . atomic . AtomicLong ; 
 import javax . management . MBeanServer ; 
 import javax . management . ObjectName ; 
 
 @ @ - 32 , 17 + 34 , 16 @ @ import org . slf4j . LoggerFactory ; 
 
 import org . apache . cassandra . config . CFMetaData ; 
 import org . apache . cassandra . config . DatabaseDescriptor ; 
 + import org . apache . cassandra . db . filter . IFilter ; 
 import org . apache . cassandra . db . filter . NamesQueryFilter ; 
 import org . apache . cassandra . db . filter . QueryFilter ; 
 import org . apache . cassandra . db . filter . QueryPath ; 
 - import org . apache . cassandra . db . marshal . InetAddressType ; 
 import org . apache . cassandra . db . marshal . LongType ; 
 import org . apache . cassandra . db . marshal . UTF8Type ; 
 import org . apache . cassandra . db . marshal . UUIDType ; 
 import org . apache . cassandra . dht . AbstractBounds ; 
 import org . apache . cassandra . dht . IPartitioner ; 
 import org . apache . cassandra . dht . Range ; 
 - import org . apache . cassandra . gms . FailureDetector ; 
 import org . apache . cassandra . io . util . FastByteArrayOutputStream ; 
 import org . apache . cassandra . net . MessagingService ; 
 import org . apache . cassandra . service . StorageProxy ; 
 @ @ - 54 , 17 + 55 , 18 @ @ public class BatchlogManager implements BatchlogManagerMBean 
 { 
 private static final String MBEAN _ NAME = " org . apache . cassandra . db : type = BatchlogManager " ; 
 private static final int VERSION = MessagingService . VERSION _ 12 ; 
 - private static final long TIMEOUT = 2 * DatabaseDescriptor . getRpcTimeout ( ) ; 
 + private static final long TIMEOUT = 2 * DatabaseDescriptor . getWriteRpcTimeout ( ) ; 
 
 - private static final ByteBuffer COORDINATOR = columnName ( " coordinator " ) ; 
 private static final ByteBuffer WRITTEN _ AT = columnName ( " written _ at " ) ; 
 private static final ByteBuffer DATA = columnName ( " data " ) ; 
 - private static final SortedSet < ByteBuffer > META = ImmutableSortedSet . of ( COORDINATOR , WRITTEN _ AT ) ; 
 
 private static final Logger logger = LoggerFactory . getLogger ( BatchlogManager . class ) ; 
 
 public static final BatchlogManager instance = new BatchlogManager ( ) ; 
 
 + private final AtomicLong totalBatchesReplayed = new AtomicLong ( ) ; 
 + private final AtomicBoolean isReplaying = new AtomicBoolean ( ) ; 
 + 
 public void start ( ) 
 { 
 MBeanServer mbs = ManagementFactory . getPlatformMBeanServer ( ) ; 
 @ @ - 90 , 15 + 92 , 43 @ @ public class BatchlogManager implements BatchlogManagerMBean 
 TimeUnit . MILLISECONDS ) ; 
 } 
 
 + public int countAllBatches ( ) 
 + { 
 + int count = 0 ; 
 + 
 + for ( Row row : getRangeSlice ( new NamesQueryFilter ( ImmutableSortedSet . < ByteBuffer > of ( ) ) ) ) 
 + { 
 + if ( row . cf ! = null & & ! row . cf . isMarkedForDelete ( ) ) 
 + count + + ; 
 + } 
 + 
 + return count ; 
 + } 
 + 
 + public long getTotalBatchesReplayed ( ) 
 + { 
 + return totalBatchesReplayed . longValue ( ) ; 
 + } 
 + 
 + public void forceBatchlogReplay ( ) 
 + { 
 + Runnable runnable = new Runnable ( ) 
 + { 
 + public void run ( ) 
 + { 
 + replayAllFailedBatches ( ) ; 
 + } 
 + } ; 
 + StorageService . optionalTasks . execute ( runnable ) ; 
 + } 
 + 
 public static RowMutation getBatchlogMutationFor ( Collection < RowMutation > mutations , UUID uuid ) 
 { 
 long timestamp = FBUtilities . timestampMicros ( ) ; 
 - ByteBuffer coordinator = InetAddressType . instance . decompose ( FBUtilities . getBroadcastAddress ( ) ) ; 
 ByteBuffer writtenAt = LongType . instance . decompose ( timestamp / 1000 ) ; 
 ByteBuffer data = serializeRowMutations ( mutations ) ; 
 
 ColumnFamily cf = ColumnFamily . create ( CFMetaData . BatchlogCF ) ; 
 - cf . addColumn ( new Column ( COORDINATOR , coordinator , timestamp ) ) ; 
 cf . addColumn ( new Column ( WRITTEN _ AT , writtenAt , timestamp ) ) ; 
 cf . addColumn ( new Column ( DATA , data , timestamp ) ) ; 
 RowMutation rm = new RowMutation ( Table . SYSTEM _ KS , UUIDType . instance . decompose ( uuid ) ) ; 
 @ @ - 126 , 55 + 156 , 38 @ @ public class BatchlogManager implements BatchlogManagerMBean 
 return ByteBuffer . wrap ( bos . toByteArray ( ) ) ; 
 } 
 
 - private static void replayAllFailedBatches ( ) 
 + private void replayAllFailedBatches ( ) 
 { 
 - if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " Started replayAllFailedBatches " ) ; 
 - 
 - ColumnFamilyStore store = Table . open ( Table . SYSTEM _ KS ) . getColumnFamilyStore ( SystemTable . BATCHLOG _ CF ) ; 
 - 
 - if ( store . isEmpty ( ) ) 
 + if ( ! isReplaying . compareAndSet ( false , true ) ) 
 return ; 
 
 - IPartitioner partitioner = StorageService . getPartitioner ( ) ; 
 - RowPosition minPosition = partitioner . getMinimumToken ( ) . minKeyBound ( ) ; 
 - AbstractBounds < RowPosition > range = new Range < RowPosition > ( minPosition , minPosition , partitioner ) ; 
 - 
 - List < Row > rows = store . getRangeSlice ( null , range , Integer . MAX _ VALUE , new NamesQueryFilter ( META ) , null ) ; 
 - 
 - for ( Row row : rows ) 
 + try 
 { 
 - if ( row . cf . isMarkedForDelete ( ) ) 
 - continue ; 
 - 
 - IColumn coordinatorColumn = row . cf . getColumn ( COORDINATOR ) ; 
 - IColumn writtenAtColumn = row . cf . getColumn ( WRITTEN _ AT ) ; 
 + logger . debug ( " Started replayAllFailedBatches " ) ; 
 
 - if ( coordinatorColumn = = null | | writtenAtColumn = = null ) 
 + for ( Row row : getRangeSlice ( new NamesQueryFilter ( WRITTEN _ AT ) ) ) 
 { 
 - replayBatch ( row . key ) ; 
 - continue ; 
 - } 
 + if ( row . cf = = null | | row . cf . isMarkedForDelete ( ) ) 
 + continue ; 
 
 - InetAddress coordinator = InetAddressType . instance . compose ( coordinatorColumn . value ( ) ) ; 
 - long writtenAt = LongType . instance . compose ( writtenAtColumn . value ( ) ) ; 
 - / / if the batch is new and its coordinator is alive - give it a chance to complete naturally . 
 - if ( System . currentTimeMillis ( ) < writtenAt + TIMEOUT & & FailureDetector . instance . isAlive ( coordinator ) ) 
 - continue ; 
 - 
 - replayBatch ( row . key ) ; 
 + IColumn writtenAt = row . cf . getColumn ( WRITTEN _ AT ) ; 
 + if ( writtenAt = = null | | System . currentTimeMillis ( ) > LongType . instance . compose ( writtenAt . value ( ) ) + TIMEOUT ) 
 + replayBatch ( row . key ) ; 
 + } 
 + } 
 + finally 
 + { 
 + isReplaying . set ( false ) ; 
 } 
 
 - if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " Finished replayAllFailedBatches " ) ; 
 + logger . debug ( " Finished replayAllFailedBatches " ) ; 
 } 
 
 - private static void replayBatch ( DecoratedKey key ) 
 + private void replayBatch ( DecoratedKey key ) 
 { 
 UUID uuid = UUIDType . instance . compose ( key . key ) ; 
 
 - if ( logger . isDebugEnabled ( ) ) 
 - logger . debug ( " Replaying batch { } " , uuid ) ; 
 + logger . debug ( " Replaying batch { } " , uuid ) ; 
 
 ColumnFamilyStore store = Table . open ( Table . SYSTEM _ KS ) . getColumnFamilyStore ( SystemTable . BATCHLOG _ CF ) ; 
 QueryFilter filter = QueryFilter . getNamesFilter ( key , new QueryPath ( SystemTable . BATCHLOG _ CF ) , DATA ) ; 
 @ @ - 195 , 6 + 208 , 7 @ @ public class BatchlogManager implements BatchlogManagerMBean 
 } 
 
 deleteBatch ( key ) ; 
 + totalBatchesReplayed . incrementAndGet ( ) ; 
 } 
 
 private static void writeHintsForSerializedMutations ( ByteBuffer data ) throws IOException 
 @ @ - 228 , 4 + 242 , 13 @ @ public class BatchlogManager implements BatchlogManagerMBean 
 ByteBuffer raw = UTF8Type . instance . decompose ( name ) ; 
 return CFMetaData . BatchlogCF . getCfDef ( ) . getColumnNameBuilder ( ) . add ( raw ) . build ( ) ; 
 } 
 + 
 + private static List < Row > getRangeSlice ( IFilter columnFilter ) 
 + { 
 + ColumnFamilyStore store = Table . open ( Table . SYSTEM _ KS ) . getColumnFamilyStore ( SystemTable . BATCHLOG _ CF ) ; 
 + IPartitioner partitioner = StorageService . getPartitioner ( ) ; 
 + RowPosition minPosition = partitioner . getMinimumToken ( ) . minKeyBound ( ) ; 
 + AbstractBounds < RowPosition > range = new Range < RowPosition > ( minPosition , minPosition , partitioner ) ; 
 + return store . getRangeSlice ( null , range , Integer . MAX _ VALUE , columnFilter , null ) ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / BatchlogManagerMBean . java b / src / java / org / apache / cassandra / db / BatchlogManagerMBean . java 
 index 0322b21 . . 2e60ba4 100644 
 - - - a / src / java / org / apache / cassandra / db / BatchlogManagerMBean . java 
 + + + b / src / java / org / apache / cassandra / db / BatchlogManagerMBean . java 
 @ @ - 19 , 4 + 19 , 20 @ @ package org . apache . cassandra . db ; 
 
 public interface BatchlogManagerMBean 
 { 
 + / * * 
 + * Counts all batches currently in the batchlog . 
 + * 
 + * @ return total batch count 
 + * / 
 + public int countAllBatches ( ) ; 
 + 
 + / * * 
 + * @ return total count of batches replayed since node start 
 + * / 
 + public long getTotalBatchesReplayed ( ) ; 
 + 
 + / * * 
 + * Forces batchlog replay . Returns immediately if replay is already in progress . 
 + * / 
 + public void forceBatchlogReplay ( ) ; 
 }
