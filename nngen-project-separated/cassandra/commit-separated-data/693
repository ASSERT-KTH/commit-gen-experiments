BLEU SCORE: 0.027611988917697356

TEST MSG: Update CHANGES . txt for 3 . 9
GENERATED MSG: Fix typo in changelog

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index b27d974 . . 7bfe659 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 4 @ @ <nl> - 3 . 8 <nl> + 3 . 9 <nl> * Fix value skipping with counter columns ( CASSANDRA - 11726 ) <nl> * Fix nodetool tablestats miss SSTable count ( CASSANDRA - 12205 ) <nl> * Fixed flacky SSTablesIteratedTest ( CASSANDRA - 12282 )
NEAREST DIFF (one line): diff - - git a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> index ca0b8aa . . 0eb13f1 100644 <nl> - - - a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> + + + b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java <nl> @ @ - 832 , 7 + 832 , 7 @ @ public class CompactionManager implements CompactionManagerMBean <nl> public Future < SSTableReader > submitSSTableBuild ( final Descriptor desc , OperationType type ) <nl> { <nl> / / invalid descriptions due to missing or dropped CFS are handled by SSTW and StreamInSession . <nl> - final Rebuilder builder = SSTableWriter . createBuilder ( desc , type ) ; <nl> + final SSTableWriter . Builder builder = SSTableWriter . createBuilder ( desc , type ) ; <nl> Callable < SSTableReader > callable = new Callable < SSTableReader > ( ) <nl> { <nl> public SSTableReader call ( ) throws IOException <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / IndexWriter . java b / src / java / org / apache / cassandra / io / sstable / IndexWriter . java <nl> deleted file mode 100644 <nl> index 8510241 . . 0000000 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / IndexWriter . java <nl> + + + / dev / null <nl> @ @ - 1 , 93 + 0 , 0 @ @ <nl> - package org . apache . cassandra . io . sstable ; <nl> - <nl> - import java . io . DataOutputStream ; <nl> - import java . io . File ; <nl> - import java . io . FileOutputStream ; <nl> - import java . io . IOException ; <nl> - <nl> - import org . slf4j . Logger ; <nl> - import org . slf4j . LoggerFactory ; <nl> - <nl> - import org . apache . cassandra . config . DatabaseDescriptor ; <nl> - import org . apache . cassandra . db . DecoratedKey ; <nl> - import org . apache . cassandra . dht . IPartitioner ; <nl> - import org . apache . cassandra . io . util . BufferedRandomAccessFile ; <nl> - import org . apache . cassandra . io . util . FileMark ; <nl> - import org . apache . cassandra . io . util . FileUtils ; <nl> - import org . apache . cassandra . io . util . SegmentedFile ; <nl> - import org . apache . cassandra . utils . BloomFilter ; <nl> - import org . apache . cassandra . utils . ByteBufferUtil ; <nl> - <nl> - / * * <nl> - * Encapsulates writing the index and filter for an SSTable . The state of this object is not valid until it has been closed . <nl> - * / <nl> - class IndexWriter <nl> - { <nl> - private static final Logger logger = LoggerFactory . getLogger ( SSTableWriter . class ) ; <nl> - <nl> - private final BufferedRandomAccessFile indexFile ; <nl> - public final Descriptor desc ; <nl> - public final IPartitioner partitioner ; <nl> - public final SegmentedFile . Builder builder ; <nl> - public final IndexSummary summary ; <nl> - public final BloomFilter bf ; <nl> - private FileMark mark ; <nl> - <nl> - IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException <nl> - { <nl> - this . desc = desc ; <nl> - this . partitioner = part ; <nl> - indexFile = new BufferedRandomAccessFile ( new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) , " rw " , 8 * 1024 * 1024 , true ) ; <nl> - builder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; <nl> - summary = new IndexSummary ( keyCount ) ; <nl> - bf = BloomFilter . getFilter ( keyCount , 15 ) ; <nl> - } <nl> - <nl> - public void afterAppend ( DecoratedKey key , long dataPosition ) throws IOException <nl> - { <nl> - bf . add ( key . key ) ; <nl> - long indexPosition = indexFile . getFilePointer ( ) ; <nl> - ByteBufferUtil . writeWithShortLength ( key . key , indexFile ) ; <nl> - indexFile . writeLong ( dataPosition ) ; <nl> - if ( logger . isTraceEnabled ( ) ) <nl> - logger . trace ( " wrote index of " + key + " at " + indexPosition ) ; <nl> - <nl> - summary . maybeAddEntry ( key , indexPosition ) ; <nl> - builder . addPotentialBoundary ( indexPosition ) ; <nl> - } <nl> - <nl> - / * * <nl> - * Closes the index and bloomfilter , making the public state of this writer valid for consumption . <nl> - * / <nl> - public void close ( ) throws IOException <nl> - { <nl> - / / bloom filter <nl> - FileOutputStream fos = new FileOutputStream ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; <nl> - DataOutputStream stream = new DataOutputStream ( fos ) ; <nl> - BloomFilter . serializer ( ) . serialize ( bf , stream ) ; <nl> - stream . flush ( ) ; <nl> - fos . getFD ( ) . sync ( ) ; <nl> - stream . close ( ) ; <nl> - <nl> - / / index <nl> - long position = indexFile . getFilePointer ( ) ; <nl> - indexFile . close ( ) ; / / calls force <nl> - FileUtils . truncate ( indexFile . getPath ( ) , position ) ; <nl> - <nl> - / / finalize in - memory index state <nl> - summary . complete ( ) ; <nl> - } <nl> - <nl> - public void mark ( ) <nl> - { <nl> - mark = indexFile . mark ( ) ; <nl> - } <nl> - <nl> - public void reset ( ) throws IOException <nl> - { <nl> - / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . <nl> - / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so <nl> - / / we assume that if that worked then we won ' t be trying to reset . <nl> - indexFile . reset ( mark ) ; <nl> - } <nl> - } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / Rebuilder . java b / src / java / org / apache / cassandra / io / sstable / Rebuilder . java <nl> deleted file mode 100644 <nl> index 803eb64 . . 0000000 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / Rebuilder . java <nl> + + + / dev / null <nl> @ @ - 1 , 92 + 0 , 0 @ @ <nl> - package org . apache . cassandra . io . sstable ; <nl> - <nl> - import java . io . File ; <nl> - import java . io . IOError ; <nl> - import java . io . IOException ; <nl> - <nl> - import org . slf4j . Logger ; <nl> - import org . slf4j . LoggerFactory ; <nl> - <nl> - import org . apache . cassandra . db . ColumnFamilyStore ; <nl> - import org . apache . cassandra . db . Table ; <nl> - import org . apache . cassandra . db . compaction . CompactionInfo ; <nl> - import org . apache . cassandra . db . compaction . CompactionType ; <nl> - import org . apache . cassandra . streaming . OperationType ; <nl> - <nl> - / * * <nl> - * Removes the given SSTable from temporary status and opens it , rebuilding the <nl> - * bloom filter and row index from the data file . <nl> - * / <nl> - public class Rebuilder implements CompactionInfo . Holder <nl> - { <nl> - private static final Logger logger = LoggerFactory . getLogger ( SSTableWriter . class ) ; <nl> - <nl> - private final Descriptor desc ; <nl> - private final OperationType type ; <nl> - private final ColumnFamilyStore cfs ; <nl> - private SSTableWriter . RowIndexer indexer ; <nl> - <nl> - public Rebuilder ( Descriptor desc , OperationType type ) <nl> - { <nl> - this . desc = desc ; <nl> - this . type = type ; <nl> - cfs = Table . open ( desc . ksname ) . getColumnFamilyStore ( desc . cfname ) ; <nl> - } <nl> - <nl> - public CompactionInfo getCompactionInfo ( ) <nl> - { <nl> - maybeOpenIndexer ( ) ; <nl> - try <nl> - { <nl> - / / both file offsets are still valid post - close <nl> - return new CompactionInfo ( desc . ksname , <nl> - desc . cfname , <nl> - CompactionType . SSTABLE _ BUILD , <nl> - indexer . dfile . getFilePointer ( ) , <nl> - indexer . dfile . length ( ) ) ; <nl> - } <nl> - catch ( IOException e ) <nl> - { <nl> - throw new IOError ( e ) ; <nl> - } <nl> - } <nl> - <nl> - / / lazy - initialize the file to avoid opening it until it ' s actually executing on the CompactionManager , <nl> - / / since the 8MB buffers can use up heap quickly <nl> - private void maybeOpenIndexer ( ) <nl> - { <nl> - if ( indexer ! = null ) <nl> - return ; <nl> - try <nl> - { <nl> - if ( cfs . metadata . getDefaultValidator ( ) . isCommutative ( ) ) <nl> - indexer = new SSTableWriter . CommutativeRowIndexer ( desc , cfs , type ) ; <nl> - else <nl> - indexer = new SSTableWriter . RowIndexer ( desc , cfs , type ) ; <nl> - } <nl> - catch ( IOException e ) <nl> - { <nl> - throw new IOError ( e ) ; <nl> - } <nl> - } <nl> - <nl> - public SSTableReader build ( ) throws IOException <nl> - { <nl> - if ( cfs . isInvalid ( ) ) <nl> - return null ; <nl> - maybeOpenIndexer ( ) ; <nl> - <nl> - File ifile = new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) ; <nl> - File ffile = new File ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; <nl> - assert ! ifile . exists ( ) ; <nl> - assert ! ffile . exists ( ) ; <nl> - <nl> - long estimatedRows = indexer . prepareIndexing ( ) ; <nl> - <nl> - / / build the index and filter <nl> - long rows = indexer . index ( ) ; <nl> - <nl> - logger . debug ( " estimated row count was { } of real count " , ( ( double ) estimatedRows ) / rows ) ; <nl> - return SSTableReader . open ( SSTableWriter . rename ( desc , SSTable . componentsFor ( desc , false ) ) ) ; <nl> - } <nl> - } <nl> diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> index fa902b3 . . da179e9 100644 <nl> - - - a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> + + + b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java <nl> @ @ - 19 , 9 + 19 , 7 @ @ <nl> <nl> package org . apache . cassandra . io . sstable ; <nl> <nl> - import java . io . File ; <nl> - import java . io . IOError ; <nl> - import java . io . IOException ; <nl> + import java . io . * ; <nl> import java . nio . ByteBuffer ; <nl> import java . util . Arrays ; <nl> import java . util . Collections ; <nl> @ @ - 29 , 6 + 27 , 10 @ @ import java . util . HashSet ; <nl> import java . util . Set ; <nl> <nl> import com . google . common . collect . Sets ; <nl> + <nl> + import org . apache . cassandra . db . commitlog . ReplayPosition ; <nl> + import org . apache . cassandra . db . compaction . * ; <nl> + import org . apache . cassandra . utils . ByteBufferUtil ; <nl> import org . slf4j . Logger ; <nl> import org . slf4j . LoggerFactory ; <nl> <nl> @ @ - 37 , 10 + 39 , 7 @ @ import org . apache . cassandra . config . DatabaseDescriptor ; <nl> import org . apache . cassandra . db . ColumnFamily ; <nl> import org . apache . cassandra . db . ColumnFamilyStore ; <nl> import org . apache . cassandra . db . DecoratedKey ; <nl> - import org . apache . cassandra . db . commitlog . ReplayPosition ; <nl> - import org . apache . cassandra . db . compaction . AbstractCompactedRow ; <nl> - import org . apache . cassandra . db . compaction . CompactionController ; <nl> - import org . apache . cassandra . db . compaction . PrecompactedRow ; <nl> + import org . apache . cassandra . db . Table ; <nl> import org . apache . cassandra . dht . IPartitioner ; <nl> import org . apache . cassandra . io . util . BufferedRandomAccessFile ; <nl> import org . apache . cassandra . io . util . FileMark ; <nl> @ @ - 48 , 7 + 47 , 7 @ @ import org . apache . cassandra . io . util . FileUtils ; <nl> import org . apache . cassandra . io . util . SegmentedFile ; <nl> import org . apache . cassandra . service . StorageService ; <nl> import org . apache . cassandra . streaming . OperationType ; <nl> - import org . apache . cassandra . utils . ByteBufferUtil ; <nl> + import org . apache . cassandra . utils . BloomFilter ; <nl> import org . apache . cassandra . utils . EstimatedHistogram ; <nl> import org . apache . cassandra . utils . FBUtilities ; <nl> <nl> @ @ - 233 , 7 + 232 , 7 @ @ public class SSTableWriter extends SSTable <nl> return dataFile . getFilePointer ( ) ; <nl> } <nl> <nl> - public static Rebuilder createBuilder ( Descriptor desc , OperationType type ) <nl> + public static Builder createBuilder ( Descriptor desc , OperationType type ) <nl> { <nl> if ( ! desc . isLatestVersion ) <nl> / / TODO : streaming between different versions will fail : need support for <nl> @ @ - 241 , 7 + 240 , 83 @ @ public class SSTableWriter extends SSTable <nl> throw new RuntimeException ( String . format ( " Cannot recover SSTable with version % s ( current version % s ) . " , <nl> desc . version , Descriptor . CURRENT _ VERSION ) ) ; <nl> <nl> - return new Rebuilder ( desc , type ) ; <nl> + return new Builder ( desc , type ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Removes the given SSTable from temporary status and opens it , rebuilding the <nl> + * bloom filter and row index from the data file . <nl> + * / <nl> + public static class Builder implements CompactionInfo . Holder <nl> + { <nl> + private final Descriptor desc ; <nl> + private final OperationType type ; <nl> + private final ColumnFamilyStore cfs ; <nl> + private RowIndexer indexer ; <nl> + <nl> + public Builder ( Descriptor desc , OperationType type ) <nl> + { <nl> + this . desc = desc ; <nl> + this . type = type ; <nl> + cfs = Table . open ( desc . ksname ) . getColumnFamilyStore ( desc . cfname ) ; <nl> + } <nl> + <nl> + public CompactionInfo getCompactionInfo ( ) <nl> + { <nl> + maybeOpenIndexer ( ) ; <nl> + try <nl> + { <nl> + / / both file offsets are still valid post - close <nl> + return new CompactionInfo ( desc . ksname , <nl> + desc . cfname , <nl> + CompactionType . SSTABLE _ BUILD , <nl> + indexer . dfile . getFilePointer ( ) , <nl> + indexer . dfile . length ( ) ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new IOError ( e ) ; <nl> + } <nl> + } <nl> + <nl> + / / lazy - initialize the file to avoid opening it until it ' s actually executing on the CompactionManager , <nl> + / / since the 8MB buffers can use up heap quickly <nl> + private void maybeOpenIndexer ( ) <nl> + { <nl> + if ( indexer ! = null ) <nl> + return ; <nl> + try <nl> + { <nl> + if ( cfs . metadata . getDefaultValidator ( ) . isCommutative ( ) ) <nl> + indexer = new CommutativeRowIndexer ( desc , cfs , type ) ; <nl> + else <nl> + indexer = new RowIndexer ( desc , cfs , type ) ; <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + throw new IOError ( e ) ; <nl> + } <nl> + } <nl> + <nl> + public SSTableReader build ( ) throws IOException <nl> + { <nl> + if ( cfs . isInvalid ( ) ) <nl> + return null ; <nl> + maybeOpenIndexer ( ) ; <nl> + <nl> + File ifile = new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) ; <nl> + File ffile = new File ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; <nl> + assert ! ifile . exists ( ) ; <nl> + assert ! ffile . exists ( ) ; <nl> + <nl> + long estimatedRows = indexer . prepareIndexing ( ) ; <nl> + <nl> + / / build the index and filter <nl> + long rows = indexer . index ( ) ; <nl> + <nl> + logger . debug ( " estimated row count was { } of real count " , ( ( double ) estimatedRows ) / rows ) ; <nl> + return SSTableReader . open ( rename ( desc , SSTable . componentsFor ( desc , false ) ) ) ; <nl> + } <nl> } <nl> <nl> static class RowIndexer <nl> @ @ - 465 , 4 + 540 , 75 @ @ public class SSTableWriter extends SSTable <nl> } <nl> } <nl> <nl> + / * * <nl> + * Encapsulates writing the index and filter for an SSTable . The state of this object is not valid until it has been closed . <nl> + * / <nl> + static class IndexWriter <nl> + { <nl> + private final BufferedRandomAccessFile indexFile ; <nl> + public final Descriptor desc ; <nl> + public final IPartitioner partitioner ; <nl> + public final SegmentedFile . Builder builder ; <nl> + public final IndexSummary summary ; <nl> + public final BloomFilter bf ; <nl> + private FileMark mark ; <nl> + <nl> + IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException <nl> + { <nl> + this . desc = desc ; <nl> + this . partitioner = part ; <nl> + indexFile = new BufferedRandomAccessFile ( new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) , " rw " , 8 * 1024 * 1024 , true ) ; <nl> + builder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; <nl> + summary = new IndexSummary ( keyCount ) ; <nl> + bf = BloomFilter . getFilter ( keyCount , 15 ) ; <nl> + } <nl> + <nl> + public void afterAppend ( DecoratedKey key , long dataPosition ) throws IOException <nl> + { <nl> + bf . add ( key . key ) ; <nl> + long indexPosition = indexFile . getFilePointer ( ) ; <nl> + ByteBufferUtil . writeWithShortLength ( key . key , indexFile ) ; <nl> + indexFile . writeLong ( dataPosition ) ; <nl> + if ( logger . isTraceEnabled ( ) ) <nl> + logger . trace ( " wrote index of " + key + " at " + indexPosition ) ; <nl> + <nl> + summary . maybeAddEntry ( key , indexPosition ) ; <nl> + builder . addPotentialBoundary ( indexPosition ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Closes the index and bloomfilter , making the public state of this writer valid for consumption . <nl> + * / <nl> + public void close ( ) throws IOException <nl> + { <nl> + / / bloom filter <nl> + FileOutputStream fos = new FileOutputStream ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; <nl> + DataOutputStream stream = new DataOutputStream ( fos ) ; <nl> + BloomFilter . serializer ( ) . serialize ( bf , stream ) ; <nl> + stream . flush ( ) ; <nl> + fos . getFD ( ) . sync ( ) ; <nl> + stream . close ( ) ; <nl> + <nl> + / / index <nl> + long position = indexFile . getFilePointer ( ) ; <nl> + indexFile . close ( ) ; / / calls force <nl> + FileUtils . truncate ( indexFile . getPath ( ) , position ) ; <nl> + <nl> + / / finalize in - memory index state <nl> + summary . complete ( ) ; <nl> + } <nl> + <nl> + public void mark ( ) <nl> + { <nl> + mark = indexFile . mark ( ) ; <nl> + } <nl> + <nl> + public void reset ( ) throws IOException <nl> + { <nl> + / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . <nl> + / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so <nl> + / / we assume that if that worked then we won ' t be trying to reset . <nl> + indexFile . reset ( mark ) ; <nl> + } <nl> + } <nl> }

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index b27d974 . . 7bfe659 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 4 @ @ 
 - 3 . 8 
 + 3 . 9 
 * Fix value skipping with counter columns ( CASSANDRA - 11726 ) 
 * Fix nodetool tablestats miss SSTable count ( CASSANDRA - 12205 ) 
 * Fixed flacky SSTablesIteratedTest ( CASSANDRA - 12282 )

NEAREST DIFF:
diff - - git a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 index ca0b8aa . . 0eb13f1 100644 
 - - - a / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 + + + b / src / java / org / apache / cassandra / db / compaction / CompactionManager . java 
 @ @ - 832 , 7 + 832 , 7 @ @ public class CompactionManager implements CompactionManagerMBean 
 public Future < SSTableReader > submitSSTableBuild ( final Descriptor desc , OperationType type ) 
 { 
 / / invalid descriptions due to missing or dropped CFS are handled by SSTW and StreamInSession . 
 - final Rebuilder builder = SSTableWriter . createBuilder ( desc , type ) ; 
 + final SSTableWriter . Builder builder = SSTableWriter . createBuilder ( desc , type ) ; 
 Callable < SSTableReader > callable = new Callable < SSTableReader > ( ) 
 { 
 public SSTableReader call ( ) throws IOException 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / IndexWriter . java b / src / java / org / apache / cassandra / io / sstable / IndexWriter . java 
 deleted file mode 100644 
 index 8510241 . . 0000000 
 - - - a / src / java / org / apache / cassandra / io / sstable / IndexWriter . java 
 + + + / dev / null 
 @ @ - 1 , 93 + 0 , 0 @ @ 
 - package org . apache . cassandra . io . sstable ; 
 - 
 - import java . io . DataOutputStream ; 
 - import java . io . File ; 
 - import java . io . FileOutputStream ; 
 - import java . io . IOException ; 
 - 
 - import org . slf4j . Logger ; 
 - import org . slf4j . LoggerFactory ; 
 - 
 - import org . apache . cassandra . config . DatabaseDescriptor ; 
 - import org . apache . cassandra . db . DecoratedKey ; 
 - import org . apache . cassandra . dht . IPartitioner ; 
 - import org . apache . cassandra . io . util . BufferedRandomAccessFile ; 
 - import org . apache . cassandra . io . util . FileMark ; 
 - import org . apache . cassandra . io . util . FileUtils ; 
 - import org . apache . cassandra . io . util . SegmentedFile ; 
 - import org . apache . cassandra . utils . BloomFilter ; 
 - import org . apache . cassandra . utils . ByteBufferUtil ; 
 - 
 - / * * 
 - * Encapsulates writing the index and filter for an SSTable . The state of this object is not valid until it has been closed . 
 - * / 
 - class IndexWriter 
 - { 
 - private static final Logger logger = LoggerFactory . getLogger ( SSTableWriter . class ) ; 
 - 
 - private final BufferedRandomAccessFile indexFile ; 
 - public final Descriptor desc ; 
 - public final IPartitioner partitioner ; 
 - public final SegmentedFile . Builder builder ; 
 - public final IndexSummary summary ; 
 - public final BloomFilter bf ; 
 - private FileMark mark ; 
 - 
 - IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException 
 - { 
 - this . desc = desc ; 
 - this . partitioner = part ; 
 - indexFile = new BufferedRandomAccessFile ( new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) , " rw " , 8 * 1024 * 1024 , true ) ; 
 - builder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; 
 - summary = new IndexSummary ( keyCount ) ; 
 - bf = BloomFilter . getFilter ( keyCount , 15 ) ; 
 - } 
 - 
 - public void afterAppend ( DecoratedKey key , long dataPosition ) throws IOException 
 - { 
 - bf . add ( key . key ) ; 
 - long indexPosition = indexFile . getFilePointer ( ) ; 
 - ByteBufferUtil . writeWithShortLength ( key . key , indexFile ) ; 
 - indexFile . writeLong ( dataPosition ) ; 
 - if ( logger . isTraceEnabled ( ) ) 
 - logger . trace ( " wrote index of " + key + " at " + indexPosition ) ; 
 - 
 - summary . maybeAddEntry ( key , indexPosition ) ; 
 - builder . addPotentialBoundary ( indexPosition ) ; 
 - } 
 - 
 - / * * 
 - * Closes the index and bloomfilter , making the public state of this writer valid for consumption . 
 - * / 
 - public void close ( ) throws IOException 
 - { 
 - / / bloom filter 
 - FileOutputStream fos = new FileOutputStream ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; 
 - DataOutputStream stream = new DataOutputStream ( fos ) ; 
 - BloomFilter . serializer ( ) . serialize ( bf , stream ) ; 
 - stream . flush ( ) ; 
 - fos . getFD ( ) . sync ( ) ; 
 - stream . close ( ) ; 
 - 
 - / / index 
 - long position = indexFile . getFilePointer ( ) ; 
 - indexFile . close ( ) ; / / calls force 
 - FileUtils . truncate ( indexFile . getPath ( ) , position ) ; 
 - 
 - / / finalize in - memory index state 
 - summary . complete ( ) ; 
 - } 
 - 
 - public void mark ( ) 
 - { 
 - mark = indexFile . mark ( ) ; 
 - } 
 - 
 - public void reset ( ) throws IOException 
 - { 
 - / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . 
 - / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so 
 - / / we assume that if that worked then we won ' t be trying to reset . 
 - indexFile . reset ( mark ) ; 
 - } 
 - } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / Rebuilder . java b / src / java / org / apache / cassandra / io / sstable / Rebuilder . java 
 deleted file mode 100644 
 index 803eb64 . . 0000000 
 - - - a / src / java / org / apache / cassandra / io / sstable / Rebuilder . java 
 + + + / dev / null 
 @ @ - 1 , 92 + 0 , 0 @ @ 
 - package org . apache . cassandra . io . sstable ; 
 - 
 - import java . io . File ; 
 - import java . io . IOError ; 
 - import java . io . IOException ; 
 - 
 - import org . slf4j . Logger ; 
 - import org . slf4j . LoggerFactory ; 
 - 
 - import org . apache . cassandra . db . ColumnFamilyStore ; 
 - import org . apache . cassandra . db . Table ; 
 - import org . apache . cassandra . db . compaction . CompactionInfo ; 
 - import org . apache . cassandra . db . compaction . CompactionType ; 
 - import org . apache . cassandra . streaming . OperationType ; 
 - 
 - / * * 
 - * Removes the given SSTable from temporary status and opens it , rebuilding the 
 - * bloom filter and row index from the data file . 
 - * / 
 - public class Rebuilder implements CompactionInfo . Holder 
 - { 
 - private static final Logger logger = LoggerFactory . getLogger ( SSTableWriter . class ) ; 
 - 
 - private final Descriptor desc ; 
 - private final OperationType type ; 
 - private final ColumnFamilyStore cfs ; 
 - private SSTableWriter . RowIndexer indexer ; 
 - 
 - public Rebuilder ( Descriptor desc , OperationType type ) 
 - { 
 - this . desc = desc ; 
 - this . type = type ; 
 - cfs = Table . open ( desc . ksname ) . getColumnFamilyStore ( desc . cfname ) ; 
 - } 
 - 
 - public CompactionInfo getCompactionInfo ( ) 
 - { 
 - maybeOpenIndexer ( ) ; 
 - try 
 - { 
 - / / both file offsets are still valid post - close 
 - return new CompactionInfo ( desc . ksname , 
 - desc . cfname , 
 - CompactionType . SSTABLE _ BUILD , 
 - indexer . dfile . getFilePointer ( ) , 
 - indexer . dfile . length ( ) ) ; 
 - } 
 - catch ( IOException e ) 
 - { 
 - throw new IOError ( e ) ; 
 - } 
 - } 
 - 
 - / / lazy - initialize the file to avoid opening it until it ' s actually executing on the CompactionManager , 
 - / / since the 8MB buffers can use up heap quickly 
 - private void maybeOpenIndexer ( ) 
 - { 
 - if ( indexer ! = null ) 
 - return ; 
 - try 
 - { 
 - if ( cfs . metadata . getDefaultValidator ( ) . isCommutative ( ) ) 
 - indexer = new SSTableWriter . CommutativeRowIndexer ( desc , cfs , type ) ; 
 - else 
 - indexer = new SSTableWriter . RowIndexer ( desc , cfs , type ) ; 
 - } 
 - catch ( IOException e ) 
 - { 
 - throw new IOError ( e ) ; 
 - } 
 - } 
 - 
 - public SSTableReader build ( ) throws IOException 
 - { 
 - if ( cfs . isInvalid ( ) ) 
 - return null ; 
 - maybeOpenIndexer ( ) ; 
 - 
 - File ifile = new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) ; 
 - File ffile = new File ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; 
 - assert ! ifile . exists ( ) ; 
 - assert ! ffile . exists ( ) ; 
 - 
 - long estimatedRows = indexer . prepareIndexing ( ) ; 
 - 
 - / / build the index and filter 
 - long rows = indexer . index ( ) ; 
 - 
 - logger . debug ( " estimated row count was { } of real count " , ( ( double ) estimatedRows ) / rows ) ; 
 - return SSTableReader . open ( SSTableWriter . rename ( desc , SSTable . componentsFor ( desc , false ) ) ) ; 
 - } 
 - } 
 diff - - git a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 index fa902b3 . . da179e9 100644 
 - - - a / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 + + + b / src / java / org / apache / cassandra / io / sstable / SSTableWriter . java 
 @ @ - 19 , 9 + 19 , 7 @ @ 
 
 package org . apache . cassandra . io . sstable ; 
 
 - import java . io . File ; 
 - import java . io . IOError ; 
 - import java . io . IOException ; 
 + import java . io . * ; 
 import java . nio . ByteBuffer ; 
 import java . util . Arrays ; 
 import java . util . Collections ; 
 @ @ - 29 , 6 + 27 , 10 @ @ import java . util . HashSet ; 
 import java . util . Set ; 
 
 import com . google . common . collect . Sets ; 
 + 
 + import org . apache . cassandra . db . commitlog . ReplayPosition ; 
 + import org . apache . cassandra . db . compaction . * ; 
 + import org . apache . cassandra . utils . ByteBufferUtil ; 
 import org . slf4j . Logger ; 
 import org . slf4j . LoggerFactory ; 
 
 @ @ - 37 , 10 + 39 , 7 @ @ import org . apache . cassandra . config . DatabaseDescriptor ; 
 import org . apache . cassandra . db . ColumnFamily ; 
 import org . apache . cassandra . db . ColumnFamilyStore ; 
 import org . apache . cassandra . db . DecoratedKey ; 
 - import org . apache . cassandra . db . commitlog . ReplayPosition ; 
 - import org . apache . cassandra . db . compaction . AbstractCompactedRow ; 
 - import org . apache . cassandra . db . compaction . CompactionController ; 
 - import org . apache . cassandra . db . compaction . PrecompactedRow ; 
 + import org . apache . cassandra . db . Table ; 
 import org . apache . cassandra . dht . IPartitioner ; 
 import org . apache . cassandra . io . util . BufferedRandomAccessFile ; 
 import org . apache . cassandra . io . util . FileMark ; 
 @ @ - 48 , 7 + 47 , 7 @ @ import org . apache . cassandra . io . util . FileUtils ; 
 import org . apache . cassandra . io . util . SegmentedFile ; 
 import org . apache . cassandra . service . StorageService ; 
 import org . apache . cassandra . streaming . OperationType ; 
 - import org . apache . cassandra . utils . ByteBufferUtil ; 
 + import org . apache . cassandra . utils . BloomFilter ; 
 import org . apache . cassandra . utils . EstimatedHistogram ; 
 import org . apache . cassandra . utils . FBUtilities ; 
 
 @ @ - 233 , 7 + 232 , 7 @ @ public class SSTableWriter extends SSTable 
 return dataFile . getFilePointer ( ) ; 
 } 
 
 - public static Rebuilder createBuilder ( Descriptor desc , OperationType type ) 
 + public static Builder createBuilder ( Descriptor desc , OperationType type ) 
 { 
 if ( ! desc . isLatestVersion ) 
 / / TODO : streaming between different versions will fail : need support for 
 @ @ - 241 , 7 + 240 , 83 @ @ public class SSTableWriter extends SSTable 
 throw new RuntimeException ( String . format ( " Cannot recover SSTable with version % s ( current version % s ) . " , 
 desc . version , Descriptor . CURRENT _ VERSION ) ) ; 
 
 - return new Rebuilder ( desc , type ) ; 
 + return new Builder ( desc , type ) ; 
 + } 
 + 
 + / * * 
 + * Removes the given SSTable from temporary status and opens it , rebuilding the 
 + * bloom filter and row index from the data file . 
 + * / 
 + public static class Builder implements CompactionInfo . Holder 
 + { 
 + private final Descriptor desc ; 
 + private final OperationType type ; 
 + private final ColumnFamilyStore cfs ; 
 + private RowIndexer indexer ; 
 + 
 + public Builder ( Descriptor desc , OperationType type ) 
 + { 
 + this . desc = desc ; 
 + this . type = type ; 
 + cfs = Table . open ( desc . ksname ) . getColumnFamilyStore ( desc . cfname ) ; 
 + } 
 + 
 + public CompactionInfo getCompactionInfo ( ) 
 + { 
 + maybeOpenIndexer ( ) ; 
 + try 
 + { 
 + / / both file offsets are still valid post - close 
 + return new CompactionInfo ( desc . ksname , 
 + desc . cfname , 
 + CompactionType . SSTABLE _ BUILD , 
 + indexer . dfile . getFilePointer ( ) , 
 + indexer . dfile . length ( ) ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new IOError ( e ) ; 
 + } 
 + } 
 + 
 + / / lazy - initialize the file to avoid opening it until it ' s actually executing on the CompactionManager , 
 + / / since the 8MB buffers can use up heap quickly 
 + private void maybeOpenIndexer ( ) 
 + { 
 + if ( indexer ! = null ) 
 + return ; 
 + try 
 + { 
 + if ( cfs . metadata . getDefaultValidator ( ) . isCommutative ( ) ) 
 + indexer = new CommutativeRowIndexer ( desc , cfs , type ) ; 
 + else 
 + indexer = new RowIndexer ( desc , cfs , type ) ; 
 + } 
 + catch ( IOException e ) 
 + { 
 + throw new IOError ( e ) ; 
 + } 
 + } 
 + 
 + public SSTableReader build ( ) throws IOException 
 + { 
 + if ( cfs . isInvalid ( ) ) 
 + return null ; 
 + maybeOpenIndexer ( ) ; 
 + 
 + File ifile = new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) ; 
 + File ffile = new File ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; 
 + assert ! ifile . exists ( ) ; 
 + assert ! ffile . exists ( ) ; 
 + 
 + long estimatedRows = indexer . prepareIndexing ( ) ; 
 + 
 + / / build the index and filter 
 + long rows = indexer . index ( ) ; 
 + 
 + logger . debug ( " estimated row count was { } of real count " , ( ( double ) estimatedRows ) / rows ) ; 
 + return SSTableReader . open ( rename ( desc , SSTable . componentsFor ( desc , false ) ) ) ; 
 + } 
 } 
 
 static class RowIndexer 
 @ @ - 465 , 4 + 540 , 75 @ @ public class SSTableWriter extends SSTable 
 } 
 } 
 
 + / * * 
 + * Encapsulates writing the index and filter for an SSTable . The state of this object is not valid until it has been closed . 
 + * / 
 + static class IndexWriter 
 + { 
 + private final BufferedRandomAccessFile indexFile ; 
 + public final Descriptor desc ; 
 + public final IPartitioner partitioner ; 
 + public final SegmentedFile . Builder builder ; 
 + public final IndexSummary summary ; 
 + public final BloomFilter bf ; 
 + private FileMark mark ; 
 + 
 + IndexWriter ( Descriptor desc , IPartitioner part , long keyCount ) throws IOException 
 + { 
 + this . desc = desc ; 
 + this . partitioner = part ; 
 + indexFile = new BufferedRandomAccessFile ( new File ( desc . filenameFor ( SSTable . COMPONENT _ INDEX ) ) , " rw " , 8 * 1024 * 1024 , true ) ; 
 + builder = SegmentedFile . getBuilder ( DatabaseDescriptor . getIndexAccessMode ( ) ) ; 
 + summary = new IndexSummary ( keyCount ) ; 
 + bf = BloomFilter . getFilter ( keyCount , 15 ) ; 
 + } 
 + 
 + public void afterAppend ( DecoratedKey key , long dataPosition ) throws IOException 
 + { 
 + bf . add ( key . key ) ; 
 + long indexPosition = indexFile . getFilePointer ( ) ; 
 + ByteBufferUtil . writeWithShortLength ( key . key , indexFile ) ; 
 + indexFile . writeLong ( dataPosition ) ; 
 + if ( logger . isTraceEnabled ( ) ) 
 + logger . trace ( " wrote index of " + key + " at " + indexPosition ) ; 
 + 
 + summary . maybeAddEntry ( key , indexPosition ) ; 
 + builder . addPotentialBoundary ( indexPosition ) ; 
 + } 
 + 
 + / * * 
 + * Closes the index and bloomfilter , making the public state of this writer valid for consumption . 
 + * / 
 + public void close ( ) throws IOException 
 + { 
 + / / bloom filter 
 + FileOutputStream fos = new FileOutputStream ( desc . filenameFor ( SSTable . COMPONENT _ FILTER ) ) ; 
 + DataOutputStream stream = new DataOutputStream ( fos ) ; 
 + BloomFilter . serializer ( ) . serialize ( bf , stream ) ; 
 + stream . flush ( ) ; 
 + fos . getFD ( ) . sync ( ) ; 
 + stream . close ( ) ; 
 + 
 + / / index 
 + long position = indexFile . getFilePointer ( ) ; 
 + indexFile . close ( ) ; / / calls force 
 + FileUtils . truncate ( indexFile . getPath ( ) , position ) ; 
 + 
 + / / finalize in - memory index state 
 + summary . complete ( ) ; 
 + } 
 + 
 + public void mark ( ) 
 + { 
 + mark = indexFile . mark ( ) ; 
 + } 
 + 
 + public void reset ( ) throws IOException 
 + { 
 + / / we can ' t un - set the bloom filter addition , but extra keys in there are harmless . 
 + / / we can ' t reset dbuilder either , but that is the last thing called in afterappend so 
 + / / we assume that if that worked then we won ' t be trying to reset . 
 + indexFile . reset ( mark ) ; 
 + } 
 + } 
 }
