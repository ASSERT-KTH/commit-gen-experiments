BLEU SCORE: 0.033864985683445356

TEST MSG: Release sstables of failed stream sessions only when outgoing transfers are finished
GENERATED MSG: Fix SSTable not released if stream session fails

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 6f709f7 . . 87228d3 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 2 . 8 <nl> + * Release sstables of failed stream sessions only when outgoing transfers are finished ( CASSANDRA - 11345 ) <nl> * Revert CASSANDRA - 11427 ( CASSANDRA - 12351 ) <nl> * Wait for tracing events before returning response and query at same consistency level client side ( CASSANDRA - 11465 ) <nl> * cqlsh copyutil should get host metadata by connected address ( CASSANDRA - 11979 ) <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamSession . java b / src / java / org / apache / cassandra / streaming / StreamSession . java <nl> index f4c900e . . 294b9c1 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamSession . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamSession . java <nl> @ @ - 139 , 7 + 139 , 8 @ @ public class StreamSession implements IEndpointStateChangeSubscriber <nl> / / stream requests to send to the peer <nl> protected final Set < StreamRequest > requests = Sets . newConcurrentHashSet ( ) ; <nl> / / streaming tasks are created and managed per ColumnFamily ID <nl> - private final ConcurrentHashMap < UUID , StreamTransferTask > transfers = new ConcurrentHashMap < > ( ) ; <nl> + @ VisibleForTesting <nl> + protected final ConcurrentHashMap < UUID , StreamTransferTask > transfers = new ConcurrentHashMap < > ( ) ; <nl> / / data receivers , filled after receiving prepare message <nl> private final Map < UUID , StreamReceiveTask > receivers = new ConcurrentHashMap < > ( ) ; <nl> private final StreamingMetrics metrics ; <nl> diff - - git a / src / java / org / apache / cassandra / streaming / StreamTransferTask . java b / src / java / org / apache / cassandra / streaming / StreamTransferTask . java <nl> index f14abd2 . . c1c5055 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / StreamTransferTask . java <nl> + + + b / src / java / org / apache / cassandra / streaming / StreamTransferTask . java <nl> @ @ - 22 , 6 + 22 , 7 @ @ import java . util . concurrent . * ; <nl> import java . util . concurrent . ScheduledFuture ; <nl> import java . util . concurrent . atomic . AtomicInteger ; <nl> <nl> + import com . google . common . annotations . VisibleForTesting ; <nl> import com . google . common . base . Throwables ; <nl> import com . google . common . collect . Iterables ; <nl> <nl> @ @ - 42 , 7 + 43 , 8 @ @ public class StreamTransferTask extends StreamTask <nl> private final AtomicInteger sequenceNumber = new AtomicInteger ( 0 ) ; <nl> private boolean aborted = false ; <nl> <nl> - private final Map < Integer , OutgoingFileMessage > files = new HashMap < > ( ) ; <nl> + @ VisibleForTesting <nl> + protected final Map < Integer , OutgoingFileMessage > files = new HashMap < > ( ) ; <nl> private final Map < Integer , ScheduledFuture > timeoutTasks = new HashMap < > ( ) ; <nl> <nl> private long totalSize ; <nl> diff - - git a / src / java / org / apache / cassandra / streaming / messages / FileMessageHeader . java b / src / java / org / apache / cassandra / streaming / messages / FileMessageHeader . java <nl> index e9a727f . . b2af699 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / messages / FileMessageHeader . java <nl> + + + b / src / java / org / apache / cassandra / streaming / messages / FileMessageHeader . java <nl> @ @ - 59 , 6 + 59 , 9 @ @ public class FileMessageHeader <nl> public final long repairedAt ; <nl> public final int sstableLevel ; <nl> <nl> + / * cached size value * / <nl> + private transient final long size ; <nl> + <nl> public FileMessageHeader ( UUID cfId , <nl> int sequenceNumber , <nl> String version , <nl> @ @ - 79 , 6 + 82 , 7 @ @ public class FileMessageHeader <nl> this . compressionMetadata = null ; <nl> this . repairedAt = repairedAt ; <nl> this . sstableLevel = sstableLevel ; <nl> + this . size = calculateSize ( ) ; <nl> } <nl> <nl> public FileMessageHeader ( UUID cfId , <nl> @ @ - 101 , 6 + 105 , 7 @ @ public class FileMessageHeader <nl> this . compressionMetadata = compressionMetadata ; <nl> this . repairedAt = repairedAt ; <nl> this . sstableLevel = sstableLevel ; <nl> + this . size = calculateSize ( ) ; <nl> } <nl> <nl> public boolean isCompressed ( ) <nl> @ @ - 113 , 23 + 118 , 28 @ @ public class FileMessageHeader <nl> * / <nl> public long size ( ) <nl> { <nl> - long size = 0 ; <nl> + return size ; <nl> + } <nl> + <nl> + private long calculateSize ( ) <nl> + { <nl> + long transferSize = 0 ; <nl> if ( compressionInfo ! = null ) <nl> { <nl> / / calculate total length of transferring chunks <nl> for ( CompressionMetadata . Chunk chunk : compressionInfo . chunks ) <nl> - size + = chunk . length + 4 ; / / 4 bytes for CRC <nl> + transferSize + = chunk . length + 4 ; / / 4 bytes for CRC <nl> } <nl> else if ( compressionMetadata ! = null ) <nl> { <nl> - size = compressionMetadata . getTotalSizeForSections ( sections ) ; <nl> + transferSize = compressionMetadata . getTotalSizeForSections ( sections ) ; <nl> } <nl> else <nl> { <nl> for ( Pair < Long , Long > section : sections ) <nl> - size + = section . right - section . left ; <nl> + transferSize + = section . right - section . left ; <nl> } <nl> - return size ; <nl> + return transferSize ; <nl> } <nl> <nl> @ Override <nl> diff - - git a / src / java / org / apache / cassandra / streaming / messages / OutgoingFileMessage . java b / src / java / org / apache / cassandra / streaming / messages / OutgoingFileMessage . java <nl> index c8175ea . . a88386e 100644 <nl> - - - a / src / java / org / apache / cassandra / streaming / messages / OutgoingFileMessage . java <nl> + + + b / src / java / org / apache / cassandra / streaming / messages / OutgoingFileMessage . java <nl> @ @ - 21 , 6 + 21 , 8 @ @ import java . io . IOException ; <nl> import java . nio . channels . ReadableByteChannel ; <nl> import java . util . List ; <nl> <nl> + import com . google . common . annotations . VisibleForTesting ; <nl> + <nl> import org . apache . cassandra . io . compress . CompressionMetadata ; <nl> import org . apache . cassandra . io . sstable . format . SSTableReader ; <nl> import org . apache . cassandra . io . util . DataOutputStreamPlus ; <nl> @ @ - 45 , 8 + 47 , 16 @ @ public class OutgoingFileMessage extends StreamMessage <nl> <nl> public void serialize ( OutgoingFileMessage message , DataOutputStreamPlus out , int version , StreamSession session ) throws IOException <nl> { <nl> - message . serialize ( out , version , session ) ; <nl> - session . fileSent ( message . header ) ; <nl> + message . startTransfer ( ) ; <nl> + try <nl> + { <nl> + message . serialize ( out , version , session ) ; <nl> + session . fileSent ( message . header ) ; <nl> + } <nl> + finally <nl> + { <nl> + message . finishTransfer ( ) ; <nl> + } <nl> } <nl> } ; <nl> <nl> @ @ - 54 , 6 + 64 , 7 @ @ public class OutgoingFileMessage extends StreamMessage <nl> private final Ref < SSTableReader > ref ; <nl> private final String filename ; <nl> private boolean completed = false ; <nl> + private boolean transferring = false ; <nl> <nl> public OutgoingFileMessage ( Ref < SSTableReader > ref , int sequenceNumber , long estimatedKeys , List < Pair < Long , Long > > sections , long repairedAt , boolean keepSSTableLevel ) <nl> { <nl> @ @ - 90 , 12 + 101 , 33 @ @ public class OutgoingFileMessage extends StreamMessage <nl> writer . write ( out ) ; <nl> } <nl> <nl> + @ VisibleForTesting <nl> + public synchronized void finishTransfer ( ) <nl> + { <nl> + transferring = false ; <nl> + / / session was aborted mid - transfer , now it ' s safe to release <nl> + if ( completed ) <nl> + { <nl> + ref . release ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ VisibleForTesting <nl> + public synchronized void startTransfer ( ) <nl> + { <nl> + transferring = true ; <nl> + } <nl> + <nl> public synchronized void complete ( ) <nl> { <nl> if ( ! completed ) <nl> { <nl> completed = true ; <nl> - ref . release ( ) ; <nl> + / / release only if not transferring <nl> + if ( ! transferring ) <nl> + { <nl> + ref . release ( ) ; <nl> + } <nl> } <nl> } <nl> <nl> diff - - git a / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java b / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java <nl> index c3c16b8 . . 02af9a7 100644 <nl> - - - a / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java <nl> + + + b / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java <nl> @ @ - 19 , 13 + 19 , 18 @ @ package org . apache . cassandra . streaming ; <nl> <nl> import java . net . InetAddress ; <nl> import java . util . ArrayList ; <nl> + import java . util . Collection ; <nl> + import java . util . Collections ; <nl> + import java . util . LinkedList ; <nl> import java . util . List ; <nl> + import java . util . UUID ; <nl> import java . util . concurrent . CancellationException ; <nl> import java . util . concurrent . Future ; <nl> import java . util . concurrent . TimeUnit ; <nl> <nl> import org . apache . cassandra . io . sstable . format . SSTableReader ; <nl> import org . junit . BeforeClass ; <nl> + import org . junit . After ; <nl> import org . junit . Test ; <nl> <nl> import junit . framework . Assert ; <nl> @ @ - 37 , 7 + 42 , 9 @ @ import org . apache . cassandra . dht . Range ; <nl> import org . apache . cassandra . dht . Token ; <nl> import org . apache . cassandra . exceptions . ConfigurationException ; <nl> import org . apache . cassandra . locator . SimpleStrategy ; <nl> + import org . apache . cassandra . streaming . messages . OutgoingFileMessage ; <nl> import org . apache . cassandra . utils . FBUtilities ; <nl> + import org . apache . cassandra . utils . concurrent . Ref ; <nl> <nl> import static org . junit . Assert . assertEquals ; <nl> import static org . junit . Assert . assertNull ; <nl> @ @ - 57 , 20 + 64 , 24 @ @ public class StreamTransferTaskTest <nl> SchemaLoader . standardCFMD ( KEYSPACE1 , CF _ STANDARD ) ) ; <nl> } <nl> <nl> + @ After <nl> + public void tearDown ( ) <nl> + { <nl> + ColumnFamilyStore cfs = Keyspace . open ( KEYSPACE1 ) . getColumnFamilyStore ( CF _ STANDARD ) ; <nl> + cfs . clearUnsafe ( ) ; <nl> + } <nl> + <nl> @ Test <nl> public void testScheduleTimeout ( ) throws Exception <nl> { <nl> - String ks = KEYSPACE1 ; <nl> - String cf = " Standard1 " ; <nl> - <nl> InetAddress peer = FBUtilities . getBroadcastAddress ( ) ; <nl> StreamSession session = new StreamSession ( peer , peer , null , 0 , true , false ) ; <nl> - ColumnFamilyStore cfs = Keyspace . open ( ks ) . getColumnFamilyStore ( cf ) ; <nl> + ColumnFamilyStore cfs = Keyspace . open ( KEYSPACE1 ) . getColumnFamilyStore ( CF _ STANDARD ) ; <nl> <nl> / / create two sstables <nl> for ( int i = 0 ; i < 2 ; i + + ) <nl> { <nl> - SchemaLoader . insertData ( ks , cf , i , 1 ) ; <nl> + SchemaLoader . insertData ( KEYSPACE1 , CF _ STANDARD , i , 1 ) ; <nl> cfs . forceBlockingFlush ( ) ; <nl> } <nl> <nl> @ @ - 104 , 4 + 115 , 68 @ @ public class StreamTransferTaskTest <nl> / / when all streaming are done , time out task should not be scheduled . <nl> assertNull ( task . scheduleTimeout ( 1 , 1 , TimeUnit . SECONDS ) ) ; <nl> } <nl> + <nl> + @ Test <nl> + public void testFailSessionDuringTransferShouldNotReleaseReferences ( ) throws Exception <nl> + { <nl> + InetAddress peer = FBUtilities . getBroadcastAddress ( ) ; <nl> + StreamCoordinator streamCoordinator = new StreamCoordinator ( 1 , true , false , null ) ; <nl> + StreamResultFuture future = StreamResultFuture . init ( UUID . randomUUID ( ) , " " , Collections . < StreamEventHandler > emptyList ( ) , streamCoordinator ) ; <nl> + StreamSession session = new StreamSession ( peer , peer , null , 0 , true , false ) ; <nl> + session . init ( future ) ; <nl> + ColumnFamilyStore cfs = Keyspace . open ( KEYSPACE1 ) . getColumnFamilyStore ( CF _ STANDARD ) ; <nl> + <nl> + / / create two sstables <nl> + for ( int i = 0 ; i < 2 ; i + + ) <nl> + { <nl> + SchemaLoader . insertData ( KEYSPACE1 , CF _ STANDARD , i , 1 ) ; <nl> + cfs . forceBlockingFlush ( ) ; <nl> + } <nl> + <nl> + / / create streaming task that streams those two sstables <nl> + StreamTransferTask task = new StreamTransferTask ( session , cfs . metadata . cfId ) ; <nl> + List < Ref < SSTableReader > > refs = new ArrayList < > ( cfs . getSSTables ( ) . size ( ) ) ; <nl> + for ( SSTableReader sstable : cfs . getSSTables ( ) ) <nl> + { <nl> + List < Range < Token > > ranges = new ArrayList < > ( ) ; <nl> + ranges . add ( new Range < > ( sstable . first . getToken ( ) , sstable . last . getToken ( ) ) ) ; <nl> + Ref < SSTableReader > ref = sstable . selfRef ( ) ; <nl> + refs . add ( ref ) ; <nl> + task . addTransferFile ( ref , 1 , sstable . getPositionsForRanges ( ranges ) , 0 ) ; <nl> + } <nl> + assertEquals ( 2 , task . getTotalNumberOfFiles ( ) ) ; <nl> + <nl> + / / add task to stream session , so it is aborted when stream session fails <nl> + session . transfers . put ( UUID . randomUUID ( ) , task ) ; <nl> + <nl> + / / make a copy of outgoing file messages , since task is cleared when it ' s aborted <nl> + Collection < OutgoingFileMessage > files = new LinkedList < > ( task . files . values ( ) ) ; <nl> + <nl> + / / simulate start transfer <nl> + for ( OutgoingFileMessage file : files ) <nl> + { <nl> + file . startTransfer ( ) ; <nl> + } <nl> + <nl> + / / fail stream session mid - transfer <nl> + session . onError ( new Exception ( " Fake exception " ) ) ; <nl> + <nl> + / / make sure reference was not released <nl> + for ( Ref < SSTableReader > ref : refs ) <nl> + { <nl> + assertEquals ( 1 , ref . globalCount ( ) ) ; <nl> + } <nl> + <nl> + / / simulate finish transfer <nl> + for ( OutgoingFileMessage file : files ) <nl> + { <nl> + file . finishTransfer ( ) ; <nl> + } <nl> + <nl> + / / now reference should be released <nl> + for ( Ref < SSTableReader > ref : refs ) <nl> + { <nl> + assertEquals ( 0 , ref . globalCount ( ) ) ; <nl> + } <nl> + } <nl> }
NEAREST DIFF (one line): ELIMINATEDSENTENCE

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 6f709f7 . . 87228d3 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 2 . 8 
 + * Release sstables of failed stream sessions only when outgoing transfers are finished ( CASSANDRA - 11345 ) 
 * Revert CASSANDRA - 11427 ( CASSANDRA - 12351 ) 
 * Wait for tracing events before returning response and query at same consistency level client side ( CASSANDRA - 11465 ) 
 * cqlsh copyutil should get host metadata by connected address ( CASSANDRA - 11979 ) 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamSession . java b / src / java / org / apache / cassandra / streaming / StreamSession . java 
 index f4c900e . . 294b9c1 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamSession . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamSession . java 
 @ @ - 139 , 7 + 139 , 8 @ @ public class StreamSession implements IEndpointStateChangeSubscriber 
 / / stream requests to send to the peer 
 protected final Set < StreamRequest > requests = Sets . newConcurrentHashSet ( ) ; 
 / / streaming tasks are created and managed per ColumnFamily ID 
 - private final ConcurrentHashMap < UUID , StreamTransferTask > transfers = new ConcurrentHashMap < > ( ) ; 
 + @ VisibleForTesting 
 + protected final ConcurrentHashMap < UUID , StreamTransferTask > transfers = new ConcurrentHashMap < > ( ) ; 
 / / data receivers , filled after receiving prepare message 
 private final Map < UUID , StreamReceiveTask > receivers = new ConcurrentHashMap < > ( ) ; 
 private final StreamingMetrics metrics ; 
 diff - - git a / src / java / org / apache / cassandra / streaming / StreamTransferTask . java b / src / java / org / apache / cassandra / streaming / StreamTransferTask . java 
 index f14abd2 . . c1c5055 100644 
 - - - a / src / java / org / apache / cassandra / streaming / StreamTransferTask . java 
 + + + b / src / java / org / apache / cassandra / streaming / StreamTransferTask . java 
 @ @ - 22 , 6 + 22 , 7 @ @ import java . util . concurrent . * ; 
 import java . util . concurrent . ScheduledFuture ; 
 import java . util . concurrent . atomic . AtomicInteger ; 
 
 + import com . google . common . annotations . VisibleForTesting ; 
 import com . google . common . base . Throwables ; 
 import com . google . common . collect . Iterables ; 
 
 @ @ - 42 , 7 + 43 , 8 @ @ public class StreamTransferTask extends StreamTask 
 private final AtomicInteger sequenceNumber = new AtomicInteger ( 0 ) ; 
 private boolean aborted = false ; 
 
 - private final Map < Integer , OutgoingFileMessage > files = new HashMap < > ( ) ; 
 + @ VisibleForTesting 
 + protected final Map < Integer , OutgoingFileMessage > files = new HashMap < > ( ) ; 
 private final Map < Integer , ScheduledFuture > timeoutTasks = new HashMap < > ( ) ; 
 
 private long totalSize ; 
 diff - - git a / src / java / org / apache / cassandra / streaming / messages / FileMessageHeader . java b / src / java / org / apache / cassandra / streaming / messages / FileMessageHeader . java 
 index e9a727f . . b2af699 100644 
 - - - a / src / java / org / apache / cassandra / streaming / messages / FileMessageHeader . java 
 + + + b / src / java / org / apache / cassandra / streaming / messages / FileMessageHeader . java 
 @ @ - 59 , 6 + 59 , 9 @ @ public class FileMessageHeader 
 public final long repairedAt ; 
 public final int sstableLevel ; 
 
 + / * cached size value * / 
 + private transient final long size ; 
 + 
 public FileMessageHeader ( UUID cfId , 
 int sequenceNumber , 
 String version , 
 @ @ - 79 , 6 + 82 , 7 @ @ public class FileMessageHeader 
 this . compressionMetadata = null ; 
 this . repairedAt = repairedAt ; 
 this . sstableLevel = sstableLevel ; 
 + this . size = calculateSize ( ) ; 
 } 
 
 public FileMessageHeader ( UUID cfId , 
 @ @ - 101 , 6 + 105 , 7 @ @ public class FileMessageHeader 
 this . compressionMetadata = compressionMetadata ; 
 this . repairedAt = repairedAt ; 
 this . sstableLevel = sstableLevel ; 
 + this . size = calculateSize ( ) ; 
 } 
 
 public boolean isCompressed ( ) 
 @ @ - 113 , 23 + 118 , 28 @ @ public class FileMessageHeader 
 * / 
 public long size ( ) 
 { 
 - long size = 0 ; 
 + return size ; 
 + } 
 + 
 + private long calculateSize ( ) 
 + { 
 + long transferSize = 0 ; 
 if ( compressionInfo ! = null ) 
 { 
 / / calculate total length of transferring chunks 
 for ( CompressionMetadata . Chunk chunk : compressionInfo . chunks ) 
 - size + = chunk . length + 4 ; / / 4 bytes for CRC 
 + transferSize + = chunk . length + 4 ; / / 4 bytes for CRC 
 } 
 else if ( compressionMetadata ! = null ) 
 { 
 - size = compressionMetadata . getTotalSizeForSections ( sections ) ; 
 + transferSize = compressionMetadata . getTotalSizeForSections ( sections ) ; 
 } 
 else 
 { 
 for ( Pair < Long , Long > section : sections ) 
 - size + = section . right - section . left ; 
 + transferSize + = section . right - section . left ; 
 } 
 - return size ; 
 + return transferSize ; 
 } 
 
 @ Override 
 diff - - git a / src / java / org / apache / cassandra / streaming / messages / OutgoingFileMessage . java b / src / java / org / apache / cassandra / streaming / messages / OutgoingFileMessage . java 
 index c8175ea . . a88386e 100644 
 - - - a / src / java / org / apache / cassandra / streaming / messages / OutgoingFileMessage . java 
 + + + b / src / java / org / apache / cassandra / streaming / messages / OutgoingFileMessage . java 
 @ @ - 21 , 6 + 21 , 8 @ @ import java . io . IOException ; 
 import java . nio . channels . ReadableByteChannel ; 
 import java . util . List ; 
 
 + import com . google . common . annotations . VisibleForTesting ; 
 + 
 import org . apache . cassandra . io . compress . CompressionMetadata ; 
 import org . apache . cassandra . io . sstable . format . SSTableReader ; 
 import org . apache . cassandra . io . util . DataOutputStreamPlus ; 
 @ @ - 45 , 8 + 47 , 16 @ @ public class OutgoingFileMessage extends StreamMessage 
 
 public void serialize ( OutgoingFileMessage message , DataOutputStreamPlus out , int version , StreamSession session ) throws IOException 
 { 
 - message . serialize ( out , version , session ) ; 
 - session . fileSent ( message . header ) ; 
 + message . startTransfer ( ) ; 
 + try 
 + { 
 + message . serialize ( out , version , session ) ; 
 + session . fileSent ( message . header ) ; 
 + } 
 + finally 
 + { 
 + message . finishTransfer ( ) ; 
 + } 
 } 
 } ; 
 
 @ @ - 54 , 6 + 64 , 7 @ @ public class OutgoingFileMessage extends StreamMessage 
 private final Ref < SSTableReader > ref ; 
 private final String filename ; 
 private boolean completed = false ; 
 + private boolean transferring = false ; 
 
 public OutgoingFileMessage ( Ref < SSTableReader > ref , int sequenceNumber , long estimatedKeys , List < Pair < Long , Long > > sections , long repairedAt , boolean keepSSTableLevel ) 
 { 
 @ @ - 90 , 12 + 101 , 33 @ @ public class OutgoingFileMessage extends StreamMessage 
 writer . write ( out ) ; 
 } 
 
 + @ VisibleForTesting 
 + public synchronized void finishTransfer ( ) 
 + { 
 + transferring = false ; 
 + / / session was aborted mid - transfer , now it ' s safe to release 
 + if ( completed ) 
 + { 
 + ref . release ( ) ; 
 + } 
 + } 
 + 
 + @ VisibleForTesting 
 + public synchronized void startTransfer ( ) 
 + { 
 + transferring = true ; 
 + } 
 + 
 public synchronized void complete ( ) 
 { 
 if ( ! completed ) 
 { 
 completed = true ; 
 - ref . release ( ) ; 
 + / / release only if not transferring 
 + if ( ! transferring ) 
 + { 
 + ref . release ( ) ; 
 + } 
 } 
 } 
 
 diff - - git a / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java b / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java 
 index c3c16b8 . . 02af9a7 100644 
 - - - a / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java 
 + + + b / test / unit / org / apache / cassandra / streaming / StreamTransferTaskTest . java 
 @ @ - 19 , 13 + 19 , 18 @ @ package org . apache . cassandra . streaming ; 
 
 import java . net . InetAddress ; 
 import java . util . ArrayList ; 
 + import java . util . Collection ; 
 + import java . util . Collections ; 
 + import java . util . LinkedList ; 
 import java . util . List ; 
 + import java . util . UUID ; 
 import java . util . concurrent . CancellationException ; 
 import java . util . concurrent . Future ; 
 import java . util . concurrent . TimeUnit ; 
 
 import org . apache . cassandra . io . sstable . format . SSTableReader ; 
 import org . junit . BeforeClass ; 
 + import org . junit . After ; 
 import org . junit . Test ; 
 
 import junit . framework . Assert ; 
 @ @ - 37 , 7 + 42 , 9 @ @ import org . apache . cassandra . dht . Range ; 
 import org . apache . cassandra . dht . Token ; 
 import org . apache . cassandra . exceptions . ConfigurationException ; 
 import org . apache . cassandra . locator . SimpleStrategy ; 
 + import org . apache . cassandra . streaming . messages . OutgoingFileMessage ; 
 import org . apache . cassandra . utils . FBUtilities ; 
 + import org . apache . cassandra . utils . concurrent . Ref ; 
 
 import static org . junit . Assert . assertEquals ; 
 import static org . junit . Assert . assertNull ; 
 @ @ - 57 , 20 + 64 , 24 @ @ public class StreamTransferTaskTest 
 SchemaLoader . standardCFMD ( KEYSPACE1 , CF _ STANDARD ) ) ; 
 } 
 
 + @ After 
 + public void tearDown ( ) 
 + { 
 + ColumnFamilyStore cfs = Keyspace . open ( KEYSPACE1 ) . getColumnFamilyStore ( CF _ STANDARD ) ; 
 + cfs . clearUnsafe ( ) ; 
 + } 
 + 
 @ Test 
 public void testScheduleTimeout ( ) throws Exception 
 { 
 - String ks = KEYSPACE1 ; 
 - String cf = " Standard1 " ; 
 - 
 InetAddress peer = FBUtilities . getBroadcastAddress ( ) ; 
 StreamSession session = new StreamSession ( peer , peer , null , 0 , true , false ) ; 
 - ColumnFamilyStore cfs = Keyspace . open ( ks ) . getColumnFamilyStore ( cf ) ; 
 + ColumnFamilyStore cfs = Keyspace . open ( KEYSPACE1 ) . getColumnFamilyStore ( CF _ STANDARD ) ; 
 
 / / create two sstables 
 for ( int i = 0 ; i < 2 ; i + + ) 
 { 
 - SchemaLoader . insertData ( ks , cf , i , 1 ) ; 
 + SchemaLoader . insertData ( KEYSPACE1 , CF _ STANDARD , i , 1 ) ; 
 cfs . forceBlockingFlush ( ) ; 
 } 
 
 @ @ - 104 , 4 + 115 , 68 @ @ public class StreamTransferTaskTest 
 / / when all streaming are done , time out task should not be scheduled . 
 assertNull ( task . scheduleTimeout ( 1 , 1 , TimeUnit . SECONDS ) ) ; 
 } 
 + 
 + @ Test 
 + public void testFailSessionDuringTransferShouldNotReleaseReferences ( ) throws Exception 
 + { 
 + InetAddress peer = FBUtilities . getBroadcastAddress ( ) ; 
 + StreamCoordinator streamCoordinator = new StreamCoordinator ( 1 , true , false , null ) ; 
 + StreamResultFuture future = StreamResultFuture . init ( UUID . randomUUID ( ) , " " , Collections . < StreamEventHandler > emptyList ( ) , streamCoordinator ) ; 
 + StreamSession session = new StreamSession ( peer , peer , null , 0 , true , false ) ; 
 + session . init ( future ) ; 
 + ColumnFamilyStore cfs = Keyspace . open ( KEYSPACE1 ) . getColumnFamilyStore ( CF _ STANDARD ) ; 
 + 
 + / / create two sstables 
 + for ( int i = 0 ; i < 2 ; i + + ) 
 + { 
 + SchemaLoader . insertData ( KEYSPACE1 , CF _ STANDARD , i , 1 ) ; 
 + cfs . forceBlockingFlush ( ) ; 
 + } 
 + 
 + / / create streaming task that streams those two sstables 
 + StreamTransferTask task = new StreamTransferTask ( session , cfs . metadata . cfId ) ; 
 + List < Ref < SSTableReader > > refs = new ArrayList < > ( cfs . getSSTables ( ) . size ( ) ) ; 
 + for ( SSTableReader sstable : cfs . getSSTables ( ) ) 
 + { 
 + List < Range < Token > > ranges = new ArrayList < > ( ) ; 
 + ranges . add ( new Range < > ( sstable . first . getToken ( ) , sstable . last . getToken ( ) ) ) ; 
 + Ref < SSTableReader > ref = sstable . selfRef ( ) ; 
 + refs . add ( ref ) ; 
 + task . addTransferFile ( ref , 1 , sstable . getPositionsForRanges ( ranges ) , 0 ) ; 
 + } 
 + assertEquals ( 2 , task . getTotalNumberOfFiles ( ) ) ; 
 + 
 + / / add task to stream session , so it is aborted when stream session fails 
 + session . transfers . put ( UUID . randomUUID ( ) , task ) ; 
 + 
 + / / make a copy of outgoing file messages , since task is cleared when it ' s aborted 
 + Collection < OutgoingFileMessage > files = new LinkedList < > ( task . files . values ( ) ) ; 
 + 
 + / / simulate start transfer 
 + for ( OutgoingFileMessage file : files ) 
 + { 
 + file . startTransfer ( ) ; 
 + } 
 + 
 + / / fail stream session mid - transfer 
 + session . onError ( new Exception ( " Fake exception " ) ) ; 
 + 
 + / / make sure reference was not released 
 + for ( Ref < SSTableReader > ref : refs ) 
 + { 
 + assertEquals ( 1 , ref . globalCount ( ) ) ; 
 + } 
 + 
 + / / simulate finish transfer 
 + for ( OutgoingFileMessage file : files ) 
 + { 
 + file . finishTransfer ( ) ; 
 + } 
 + 
 + / / now reference should be released 
 + for ( Ref < SSTableReader > ref : refs ) 
 + { 
 + assertEquals ( 0 , ref . globalCount ( ) ) ; 
 + } 
 + } 
 }

NEAREST DIFF:
ELIMINATEDSENTENCE
