BLEU SCORE: 0.11752701606523268

TEST MSG: Make batchlog replay asynchronous
GENERATED MSG: Improve batchlog replay behavior and hint ttl handling

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 3dd47a1 . . d43a0f5 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 12 , 6 + 12 , 7 @ @ <nl> * Fix repair hang when given CF does not exist ( CASSANDRA - 7189 ) <nl> * Allow c * to be shutdown in an embedded mode ( CASSANDRA - 5635 ) <nl> * Add server side batching to native transport ( CASSANDRA - 5663 ) <nl> + * Make batchlog replay asynchronous ( CASSANDRA - 6134 ) <nl> Merged from 2 . 0 : <nl> * ( Hadoop ) Close java driver Cluster in CQLRR . close ( CASSANDRA - 7228 ) <nl> * Warn when ' USING TIMESTAMP ' is used on a CAS BATCH ( CASSANDRA - 7067 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / BatchlogManager . java b / src / java / org / apache / cassandra / db / BatchlogManager . java <nl> index 3ffc7a7 . . 1a441f6 100644 <nl> - - - a / src / java / org / apache / cassandra / db / BatchlogManager . java <nl> + + + b / src / java / org / apache / cassandra / db / BatchlogManager . java <nl> @ @ - 48 , 6 + 48 , 8 @ @ import org . apache . cassandra . gms . FailureDetector ; <nl> import org . apache . cassandra . io . sstable . Descriptor ; <nl> import org . apache . cassandra . io . sstable . SSTableReader ; <nl> import org . apache . cassandra . io . util . DataOutputBuffer ; <nl> + import org . apache . cassandra . net . MessageIn ; <nl> + import org . apache . cassandra . net . MessageOut ; <nl> import org . apache . cassandra . net . MessagingService ; <nl> import org . apache . cassandra . service . StorageProxy ; <nl> import org . apache . cassandra . service . StorageService ; <nl> @ @ - 193 , 162 + 195 , 247 @ @ public class BatchlogManager implements BatchlogManagerMBean <nl> logger . debug ( " Finished replayAllFailedBatches " ) ; <nl> } <nl> <nl> - / / returns the UUID of the last seen batch <nl> + private void deleteBatch ( UUID id ) <nl> + { <nl> + Mutation mutation = new Mutation ( Keyspace . SYSTEM _ KS , UUIDType . instance . decompose ( id ) ) ; <nl> + mutation . delete ( SystemKeyspace . BATCHLOG _ CF , FBUtilities . timestampMicros ( ) ) ; <nl> + mutation . apply ( ) ; <nl> + } <nl> + <nl> private UUID processBatchlogPage ( UntypedResultSet page , RateLimiter rateLimiter ) <nl> { <nl> UUID id = null ; <nl> + ArrayList < Batch > batches = new ArrayList < > ( page . size ( ) ) ; <nl> + <nl> + / / Sending out batches for replay without waiting for them , so that one stuck batch doesn ' t affect others <nl> for ( UntypedResultSet . Row row : page ) <nl> { <nl> id = row . getUUID ( " id " ) ; <nl> long writtenAt = row . getLong ( " written _ at " ) ; <nl> - int version = row . has ( " version " ) ? row . getInt ( " version " ) : MessagingService . VERSION _ 12 ; <nl> / / enough time for the actual write + batchlog entry mutation delivery ( two separate requests ) . <nl> long timeout = DatabaseDescriptor . getWriteRpcTimeout ( ) * 2 ; / / enough time for the actual write + BM removal mutation <nl> if ( System . currentTimeMillis ( ) < writtenAt + timeout ) <nl> continue ; / / not ready to replay yet , might still get a deletion . <nl> - replayBatch ( id , row . getBytes ( " data " ) , writtenAt , version , rateLimiter ) ; <nl> + <nl> + int version = row . has ( " version " ) ? row . getInt ( " version " ) : MessagingService . VERSION _ 12 ; <nl> + Batch batch = new Batch ( id , writtenAt , row . getBytes ( " data " ) , version ) ; <nl> + try <nl> + { <nl> + if ( batch . replay ( rateLimiter ) > 0 ) <nl> + { <nl> + batches . add ( batch ) ; <nl> + } <nl> + else <nl> + { <nl> + deleteBatch ( id ) ; / / no write mutations were sent ( either expired or all CFs involved truncated ) . <nl> + totalBatchesReplayed . incrementAndGet ( ) ; <nl> + } <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + logger . warn ( " Skipped batch replay of { } due to { } " , id , e ) ; <nl> + deleteBatch ( id ) ; <nl> + } <nl> + } <nl> + <nl> + / / now waiting for all batches to complete their processing <nl> + / / schedule hints for timed out deliveries <nl> + for ( Batch batch : batches ) <nl> + { <nl> + batch . finish ( ) ; <nl> + deleteBatch ( batch . id ) ; <nl> } <nl> + <nl> + totalBatchesReplayed . addAndGet ( batches . size ( ) ) ; <nl> + <nl> return id ; <nl> } <nl> <nl> - private void replayBatch ( UUID id , ByteBuffer data , long writtenAt , int version , RateLimiter rateLimiter ) <nl> + private static class Batch <nl> { <nl> - logger . debug ( " Replaying batch { } " , id ) ; <nl> + private final UUID id ; <nl> + private final long writtenAt ; <nl> + private final ByteBuffer data ; <nl> + private final int version ; <nl> <nl> - try <nl> + private List < ReplayWriteResponseHandler > replayHandlers ; <nl> + <nl> + public Batch ( UUID id , long writtenAt , ByteBuffer data , int version ) <nl> { <nl> - replaySerializedMutations ( data , writtenAt , version , rateLimiter ) ; <nl> + this . id = id ; <nl> + this . writtenAt = writtenAt ; <nl> + this . data = data ; <nl> + this . version = version ; <nl> } <nl> - catch ( IOException e ) <nl> + <nl> + public int replay ( RateLimiter rateLimiter ) throws IOException <nl> { <nl> - logger . warn ( " Skipped batch replay of { } due to { } " , id , e ) ; <nl> - } <nl> + logger . debug ( " Replaying batch { } " , id ) ; <nl> <nl> - deleteBatch ( id ) ; <nl> + List < Mutation > mutations = replayingMutations ( ) ; <nl> <nl> - totalBatchesReplayed . incrementAndGet ( ) ; <nl> - } <nl> + if ( mutations . isEmpty ( ) ) <nl> + return 0 ; <nl> <nl> - private void deleteBatch ( UUID id ) <nl> - { <nl> - Mutation mutation = new Mutation ( Keyspace . SYSTEM _ KS , UUIDType . instance . decompose ( id ) ) ; <nl> - mutation . delete ( SystemKeyspace . BATCHLOG _ CF , FBUtilities . timestampMicros ( ) ) ; <nl> - mutation . apply ( ) ; <nl> - } <nl> + int ttl = calculateHintTTL ( mutations ) ; <nl> + if ( ttl < = 0 ) <nl> + return 0 ; <nl> <nl> - private void replaySerializedMutations ( ByteBuffer data , long writtenAt , int version , RateLimiter rateLimiter ) throws IOException <nl> - { <nl> - DataInputStream in = new DataInputStream ( ByteBufferUtil . inputStream ( data ) ) ; <nl> - int size = in . readInt ( ) ; <nl> - List < Mutation > mutations = new ArrayList < > ( size ) ; <nl> + replayHandlers = sendReplays ( mutations , writtenAt , ttl ) ; <nl> + <nl> + rateLimiter . acquire ( data . remaining ( ) ) ; / / acquire afterwards , to not mess up ttl calculation . <nl> <nl> - for ( int i = 0 ; i < size ; i + + ) <nl> + return replayHandlers . size ( ) ; <nl> + } <nl> + <nl> + public void finish ( ) <nl> { <nl> - Mutation mutation = Mutation . serializer . deserialize ( in , version ) ; <nl> + for ( int i = 0 ; i < replayHandlers . size ( ) ; i + + ) <nl> + { <nl> + ReplayWriteResponseHandler handler = replayHandlers . get ( i ) ; <nl> + try <nl> + { <nl> + handler . get ( ) ; <nl> + } <nl> + catch ( WriteTimeoutException e ) <nl> + { <nl> + logger . debug ( " Timed out replaying a batched mutation to a node , will write a hint " ) ; <nl> + / / writing hints for the rest to hints , starting from i <nl> + writeHintsForUndeliveredEndpoints ( i ) ; <nl> + return ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + private List < Mutation > replayingMutations ( ) throws IOException <nl> + { <nl> + DataInputStream in = new DataInputStream ( ByteBufferUtil . inputStream ( data ) ) ; <nl> + int size = in . readInt ( ) ; <nl> + List < Mutation > mutations = new ArrayList < > ( size ) ; <nl> + for ( int i = 0 ; i < size ; i + + ) <nl> + { <nl> + Mutation mutation = Mutation . serializer . deserialize ( in , version ) ; <nl> <nl> - / / Remove CFs that have been truncated since . writtenAt and SystemTable # getTruncatedAt ( ) both return millis . <nl> - / / We don ' t abort the replay entirely b / c this can be considered a succes ( truncated is same as delivered then <nl> - / / truncated . <nl> - for ( UUID cfId : mutation . getColumnFamilyIds ( ) ) <nl> - if ( writtenAt < = SystemKeyspace . getTruncatedAt ( cfId ) ) <nl> - mutation = mutation . without ( cfId ) ; <nl> + / / Remove CFs that have been truncated since . writtenAt and SystemTable # getTruncatedAt ( ) both return millis . <nl> + / / We don ' t abort the replay entirely b / c this can be considered a success ( truncated is same as delivered then <nl> + / / truncated . <nl> + for ( UUID cfId : mutation . getColumnFamilyIds ( ) ) <nl> + if ( writtenAt < = SystemKeyspace . getTruncatedAt ( cfId ) ) <nl> + mutation = mutation . without ( cfId ) ; <nl> <nl> - if ( ! mutation . isEmpty ( ) ) <nl> - mutations . add ( mutation ) ; <nl> + if ( ! mutation . isEmpty ( ) ) <nl> + mutations . add ( mutation ) ; <nl> + } <nl> + return mutations ; <nl> } <nl> <nl> - if ( ! mutations . isEmpty ( ) ) <nl> - replayMutations ( mutations , writtenAt , version , rateLimiter ) ; <nl> - } <nl> + private void writeHintsForUndeliveredEndpoints ( int startFrom ) <nl> + { <nl> + try <nl> + { <nl> + / / Here we deserialize mutations 2nd time from byte buffer . <nl> + / / but this is ok , because timeout on batch direct delivery is rare <nl> + / / ( it can happen only several seconds until node is marked dead ) <nl> + / / so trading some cpu to keep less objects <nl> + List < Mutation > replayingMutations = replayingMutations ( ) ; <nl> + for ( int i = startFrom ; i < replayHandlers . size ( ) ; i + + ) <nl> + { <nl> + Mutation undeliveredMutation = replayingMutations . get ( i ) ; <nl> + int ttl = calculateHintTTL ( replayingMutations ) ; <nl> + ReplayWriteResponseHandler handler = replayHandlers . get ( i ) ; <nl> <nl> - / * <nl> - * We try to deliver the mutations to the replicas ourselves if they are alive and only resort to writing hints <nl> - * when a replica is down or a write request times out . <nl> - * / <nl> - private void replayMutations ( List < Mutation > mutations , long writtenAt , int version , RateLimiter rateLimiter ) throws IOException <nl> - { <nl> - int ttl = calculateHintTTL ( mutations , writtenAt ) ; <nl> - if ( ttl < = 0 ) <nl> - return ; / / this batchlog entry has ' expired ' <nl> - <nl> - List < InetAddress > liveEndpoints = new ArrayList < > ( ) ; <nl> - List < InetAddress > hintEndpoints = new ArrayList < > ( ) ; <nl> - <nl> - for ( Mutation mutation : mutations ) <nl> + if ( ttl > 0 & & handler ! = null ) <nl> + for ( InetAddress endpoint : handler . undelivered ) <nl> + StorageProxy . writeHintForMutation ( undeliveredMutation , writtenAt , ttl , endpoint ) ; <nl> + } <nl> + } <nl> + catch ( IOException e ) <nl> + { <nl> + logger . error ( " Cannot schedule hints for undelivered batch " , e ) ; <nl> + } <nl> + } <nl> + <nl> + private List < ReplayWriteResponseHandler > sendReplays ( List < Mutation > mutations , long writtenAt , int ttl ) <nl> { <nl> + List < ReplayWriteResponseHandler > handlers = new ArrayList < > ( mutations . size ( ) ) ; <nl> + for ( Mutation mutation : mutations ) <nl> + { <nl> + ReplayWriteResponseHandler handler = sendSingleReplayMutation ( mutation , writtenAt , ttl ) ; <nl> + if ( handler ! = null ) <nl> + handlers . add ( handler ) ; <nl> + } <nl> + return handlers ; <nl> + } <nl> + <nl> + / * * <nl> + * We try to deliver the mutations to the replicas ourselves if they are alive and only resort to writing hints <nl> + * when a replica is down or a write request times out . <nl> + * <nl> + * @ return direct delivery handler to wait on or null , if no live nodes found <nl> + * / <nl> + private ReplayWriteResponseHandler sendSingleReplayMutation ( final Mutation mutation , long writtenAt , int ttl ) <nl> + { <nl> + Set < InetAddress > liveEndpoints = new HashSet < > ( ) ; <nl> String ks = mutation . getKeyspaceName ( ) ; <nl> - Token tk = StorageService . getPartitioner ( ) . getToken ( mutation . key ( ) ) ; <nl> - int mutationSize = ( int ) Mutation . serializer . serializedSize ( mutation , version ) ; <nl> + Token < ? > tk = StorageService . getPartitioner ( ) . getToken ( mutation . key ( ) ) ; <nl> <nl> for ( InetAddress endpoint : Iterables . concat ( StorageService . instance . getNaturalEndpoints ( ks , tk ) , <nl> StorageService . instance . getTokenMetadata ( ) . pendingEndpointsFor ( tk , ks ) ) ) <nl> { <nl> - rateLimiter . acquire ( mutationSize ) ; <nl> if ( endpoint . equals ( FBUtilities . getBroadcastAddress ( ) ) ) <nl> mutation . apply ( ) ; <nl> else if ( FailureDetector . instance . isAlive ( endpoint ) ) <nl> liveEndpoints . add ( endpoint ) ; / / will try delivering directly instead of writing a hint . <nl> else <nl> - hintEndpoints . add ( endpoint ) ; <nl> + StorageProxy . writeHintForMutation ( mutation , writtenAt , ttl , endpoint ) ; <nl> } <nl> <nl> - if ( ! liveEndpoints . isEmpty ( ) ) <nl> - hintEndpoints . addAll ( attemptDirectDelivery ( mutation , liveEndpoints ) ) ; <nl> + if ( liveEndpoints . isEmpty ( ) ) <nl> + return null ; <nl> <nl> - for ( InetAddress endpoint : hintEndpoints ) <nl> - StorageProxy . writeHintForMutation ( mutation , writtenAt , ttl , endpoint ) ; <nl> - <nl> - liveEndpoints . clear ( ) ; <nl> - hintEndpoints . clear ( ) ; <nl> + ReplayWriteResponseHandler handler = new ReplayWriteResponseHandler ( liveEndpoints ) ; <nl> + MessageOut < Mutation > message = mutation . createMessage ( ) ; <nl> + for ( InetAddress endpoint : liveEndpoints ) <nl> + MessagingService . instance ( ) . sendRR ( message , endpoint , handler , false ) ; <nl> + return handler ; <nl> } <nl> - } <nl> <nl> - / / Returns the endpoints we failed to deliver to . <nl> - private Set < InetAddress > attemptDirectDelivery ( Mutation mutation , List < InetAddress > endpoints ) throws IOException <nl> - { <nl> - final List < WriteResponseHandler > handlers = new ArrayList < > ( ) ; <nl> - final Set < InetAddress > undelivered = Collections . synchronizedSet ( new HashSet < InetAddress > ( ) ) ; <nl> - <nl> - for ( final InetAddress ep : endpoints ) <nl> + / * <nl> + * Calculate ttl for the mutations ' hints ( and reduce ttl by the time the mutations spent in the batchlog ) . <nl> + * This ensures that deletes aren ' t " undone " by an old batch replay . <nl> + * / <nl> + private int calculateHintTTL ( Collection < Mutation > mutations ) <nl> { <nl> - Runnable callback = new Runnable ( ) <nl> - { <nl> - public void run ( ) <nl> - { <nl> - undelivered . remove ( ep ) ; <nl> - } <nl> - } ; <nl> - WriteResponseHandler handler = new WriteResponseHandler ( ep , WriteType . UNLOGGED _ BATCH , callback ) ; <nl> - MessagingService . instance ( ) . sendRR ( mutation . createMessage ( ) , ep , handler , false ) ; <nl> - handlers . add ( handler ) ; <nl> + int unadjustedTTL = Integer . MAX _ VALUE ; <nl> + for ( Mutation mutation : mutations ) <nl> + unadjustedTTL = Math . min ( unadjustedTTL , HintedHandOffManager . calculateHintTTL ( mutation ) ) ; <nl> + return unadjustedTTL - ( int ) TimeUnit . MILLISECONDS . toSeconds ( System . currentTimeMillis ( ) - writtenAt ) ; <nl> } <nl> <nl> - / / Wait for all the requests to complete . <nl> - for ( WriteResponseHandler handler : handlers ) <nl> + private static class ReplayWriteResponseHandler extends WriteResponseHandler <nl> { <nl> - try <nl> + private final Set < InetAddress > undelivered = Collections . newSetFromMap ( new ConcurrentHashMap < InetAddress , Boolean > ( ) ) ; <nl> + <nl> + public ReplayWriteResponseHandler ( Collection < InetAddress > writeEndpoints ) <nl> { <nl> - handler . get ( ) ; <nl> + super ( writeEndpoints , Collections . < InetAddress > emptySet ( ) , null , null , null , WriteType . UNLOGGED _ BATCH ) ; <nl> + undelivered . addAll ( writeEndpoints ) ; <nl> } <nl> - catch ( WriteTimeoutException e ) <nl> + <nl> + @ Override <nl> + protected int totalBlockFor ( ) <nl> { <nl> - logger . debug ( " Timed out replaying a batched mutation to a node , will write a hint " ) ; <nl> + return this . naturalEndpoints . size ( ) ; <nl> } <nl> - } <nl> <nl> - return undelivered ; <nl> - } <nl> - <nl> - / * <nl> - * Calculate ttl for the mutations ' hints ( and reduce ttl by the time the mutations spent in the batchlog ) . <nl> - * This ensures that deletes aren ' t " undone " by an old batch replay . <nl> - * / <nl> - private int calculateHintTTL ( List < Mutation > mutations , long writtenAt ) <nl> - { <nl> - int unadjustedTTL = Integer . MAX _ VALUE ; <nl> - for ( Mutation mutation : mutations ) <nl> - unadjustedTTL = Math . min ( unadjustedTTL , HintedHandOffManager . calculateHintTTL ( mutation ) ) ; <nl> - return unadjustedTTL - ( int ) TimeUnit . MILLISECONDS . toSeconds ( System . currentTimeMillis ( ) - writtenAt ) ; <nl> + @ Override <nl> + public void response ( MessageIn m ) <nl> + { <nl> + boolean removed = undelivered . remove ( m . from ) ; <nl> + assert removed ; <nl> + super . response ( m ) ; <nl> + } <nl> + } <nl> } <nl> <nl> / / force flush + compaction to reclaim space from the replayed batches
NEAREST DIFF (one line): diff - - git a / NEWS . txt b / NEWS . txt <nl> index 63d1e58 . . 706cd29 100644 <nl> - - - a / NEWS . txt <nl> + + + b / NEWS . txt <nl> @ @ - 42 , 7 + 42 , 7 @ @ Features <nl> <nl> Upgrading <nl> - - - - - - - - - <nl> - - CQL3 uses to be case - insensitive for property map key in ALTER and CREATE <nl> + - CQL3 used to be case - insensitive for property map key in ALTER and CREATE <nl> statements . In other words : <nl> CREATE KEYSPACE test WITH replication = { ' CLASS ' : ' SimpleStrategy ' , <nl> ' REPLICATION _ FACTOR ' : ' 1 ' }

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 3dd47a1 . . d43a0f5 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 12 , 6 + 12 , 7 @ @ 
 * Fix repair hang when given CF does not exist ( CASSANDRA - 7189 ) 
 * Allow c * to be shutdown in an embedded mode ( CASSANDRA - 5635 ) 
 * Add server side batching to native transport ( CASSANDRA - 5663 ) 
 + * Make batchlog replay asynchronous ( CASSANDRA - 6134 ) 
 Merged from 2 . 0 : 
 * ( Hadoop ) Close java driver Cluster in CQLRR . close ( CASSANDRA - 7228 ) 
 * Warn when ' USING TIMESTAMP ' is used on a CAS BATCH ( CASSANDRA - 7067 ) 
 diff - - git a / src / java / org / apache / cassandra / db / BatchlogManager . java b / src / java / org / apache / cassandra / db / BatchlogManager . java 
 index 3ffc7a7 . . 1a441f6 100644 
 - - - a / src / java / org / apache / cassandra / db / BatchlogManager . java 
 + + + b / src / java / org / apache / cassandra / db / BatchlogManager . java 
 @ @ - 48 , 6 + 48 , 8 @ @ import org . apache . cassandra . gms . FailureDetector ; 
 import org . apache . cassandra . io . sstable . Descriptor ; 
 import org . apache . cassandra . io . sstable . SSTableReader ; 
 import org . apache . cassandra . io . util . DataOutputBuffer ; 
 + import org . apache . cassandra . net . MessageIn ; 
 + import org . apache . cassandra . net . MessageOut ; 
 import org . apache . cassandra . net . MessagingService ; 
 import org . apache . cassandra . service . StorageProxy ; 
 import org . apache . cassandra . service . StorageService ; 
 @ @ - 193 , 162 + 195 , 247 @ @ public class BatchlogManager implements BatchlogManagerMBean 
 logger . debug ( " Finished replayAllFailedBatches " ) ; 
 } 
 
 - / / returns the UUID of the last seen batch 
 + private void deleteBatch ( UUID id ) 
 + { 
 + Mutation mutation = new Mutation ( Keyspace . SYSTEM _ KS , UUIDType . instance . decompose ( id ) ) ; 
 + mutation . delete ( SystemKeyspace . BATCHLOG _ CF , FBUtilities . timestampMicros ( ) ) ; 
 + mutation . apply ( ) ; 
 + } 
 + 
 private UUID processBatchlogPage ( UntypedResultSet page , RateLimiter rateLimiter ) 
 { 
 UUID id = null ; 
 + ArrayList < Batch > batches = new ArrayList < > ( page . size ( ) ) ; 
 + 
 + / / Sending out batches for replay without waiting for them , so that one stuck batch doesn ' t affect others 
 for ( UntypedResultSet . Row row : page ) 
 { 
 id = row . getUUID ( " id " ) ; 
 long writtenAt = row . getLong ( " written _ at " ) ; 
 - int version = row . has ( " version " ) ? row . getInt ( " version " ) : MessagingService . VERSION _ 12 ; 
 / / enough time for the actual write + batchlog entry mutation delivery ( two separate requests ) . 
 long timeout = DatabaseDescriptor . getWriteRpcTimeout ( ) * 2 ; / / enough time for the actual write + BM removal mutation 
 if ( System . currentTimeMillis ( ) < writtenAt + timeout ) 
 continue ; / / not ready to replay yet , might still get a deletion . 
 - replayBatch ( id , row . getBytes ( " data " ) , writtenAt , version , rateLimiter ) ; 
 + 
 + int version = row . has ( " version " ) ? row . getInt ( " version " ) : MessagingService . VERSION _ 12 ; 
 + Batch batch = new Batch ( id , writtenAt , row . getBytes ( " data " ) , version ) ; 
 + try 
 + { 
 + if ( batch . replay ( rateLimiter ) > 0 ) 
 + { 
 + batches . add ( batch ) ; 
 + } 
 + else 
 + { 
 + deleteBatch ( id ) ; / / no write mutations were sent ( either expired or all CFs involved truncated ) . 
 + totalBatchesReplayed . incrementAndGet ( ) ; 
 + } 
 + } 
 + catch ( IOException e ) 
 + { 
 + logger . warn ( " Skipped batch replay of { } due to { } " , id , e ) ; 
 + deleteBatch ( id ) ; 
 + } 
 + } 
 + 
 + / / now waiting for all batches to complete their processing 
 + / / schedule hints for timed out deliveries 
 + for ( Batch batch : batches ) 
 + { 
 + batch . finish ( ) ; 
 + deleteBatch ( batch . id ) ; 
 } 
 + 
 + totalBatchesReplayed . addAndGet ( batches . size ( ) ) ; 
 + 
 return id ; 
 } 
 
 - private void replayBatch ( UUID id , ByteBuffer data , long writtenAt , int version , RateLimiter rateLimiter ) 
 + private static class Batch 
 { 
 - logger . debug ( " Replaying batch { } " , id ) ; 
 + private final UUID id ; 
 + private final long writtenAt ; 
 + private final ByteBuffer data ; 
 + private final int version ; 
 
 - try 
 + private List < ReplayWriteResponseHandler > replayHandlers ; 
 + 
 + public Batch ( UUID id , long writtenAt , ByteBuffer data , int version ) 
 { 
 - replaySerializedMutations ( data , writtenAt , version , rateLimiter ) ; 
 + this . id = id ; 
 + this . writtenAt = writtenAt ; 
 + this . data = data ; 
 + this . version = version ; 
 } 
 - catch ( IOException e ) 
 + 
 + public int replay ( RateLimiter rateLimiter ) throws IOException 
 { 
 - logger . warn ( " Skipped batch replay of { } due to { } " , id , e ) ; 
 - } 
 + logger . debug ( " Replaying batch { } " , id ) ; 
 
 - deleteBatch ( id ) ; 
 + List < Mutation > mutations = replayingMutations ( ) ; 
 
 - totalBatchesReplayed . incrementAndGet ( ) ; 
 - } 
 + if ( mutations . isEmpty ( ) ) 
 + return 0 ; 
 
 - private void deleteBatch ( UUID id ) 
 - { 
 - Mutation mutation = new Mutation ( Keyspace . SYSTEM _ KS , UUIDType . instance . decompose ( id ) ) ; 
 - mutation . delete ( SystemKeyspace . BATCHLOG _ CF , FBUtilities . timestampMicros ( ) ) ; 
 - mutation . apply ( ) ; 
 - } 
 + int ttl = calculateHintTTL ( mutations ) ; 
 + if ( ttl < = 0 ) 
 + return 0 ; 
 
 - private void replaySerializedMutations ( ByteBuffer data , long writtenAt , int version , RateLimiter rateLimiter ) throws IOException 
 - { 
 - DataInputStream in = new DataInputStream ( ByteBufferUtil . inputStream ( data ) ) ; 
 - int size = in . readInt ( ) ; 
 - List < Mutation > mutations = new ArrayList < > ( size ) ; 
 + replayHandlers = sendReplays ( mutations , writtenAt , ttl ) ; 
 + 
 + rateLimiter . acquire ( data . remaining ( ) ) ; / / acquire afterwards , to not mess up ttl calculation . 
 
 - for ( int i = 0 ; i < size ; i + + ) 
 + return replayHandlers . size ( ) ; 
 + } 
 + 
 + public void finish ( ) 
 { 
 - Mutation mutation = Mutation . serializer . deserialize ( in , version ) ; 
 + for ( int i = 0 ; i < replayHandlers . size ( ) ; i + + ) 
 + { 
 + ReplayWriteResponseHandler handler = replayHandlers . get ( i ) ; 
 + try 
 + { 
 + handler . get ( ) ; 
 + } 
 + catch ( WriteTimeoutException e ) 
 + { 
 + logger . debug ( " Timed out replaying a batched mutation to a node , will write a hint " ) ; 
 + / / writing hints for the rest to hints , starting from i 
 + writeHintsForUndeliveredEndpoints ( i ) ; 
 + return ; 
 + } 
 + } 
 + } 
 + 
 + private List < Mutation > replayingMutations ( ) throws IOException 
 + { 
 + DataInputStream in = new DataInputStream ( ByteBufferUtil . inputStream ( data ) ) ; 
 + int size = in . readInt ( ) ; 
 + List < Mutation > mutations = new ArrayList < > ( size ) ; 
 + for ( int i = 0 ; i < size ; i + + ) 
 + { 
 + Mutation mutation = Mutation . serializer . deserialize ( in , version ) ; 
 
 - / / Remove CFs that have been truncated since . writtenAt and SystemTable # getTruncatedAt ( ) both return millis . 
 - / / We don ' t abort the replay entirely b / c this can be considered a succes ( truncated is same as delivered then 
 - / / truncated . 
 - for ( UUID cfId : mutation . getColumnFamilyIds ( ) ) 
 - if ( writtenAt < = SystemKeyspace . getTruncatedAt ( cfId ) ) 
 - mutation = mutation . without ( cfId ) ; 
 + / / Remove CFs that have been truncated since . writtenAt and SystemTable # getTruncatedAt ( ) both return millis . 
 + / / We don ' t abort the replay entirely b / c this can be considered a success ( truncated is same as delivered then 
 + / / truncated . 
 + for ( UUID cfId : mutation . getColumnFamilyIds ( ) ) 
 + if ( writtenAt < = SystemKeyspace . getTruncatedAt ( cfId ) ) 
 + mutation = mutation . without ( cfId ) ; 
 
 - if ( ! mutation . isEmpty ( ) ) 
 - mutations . add ( mutation ) ; 
 + if ( ! mutation . isEmpty ( ) ) 
 + mutations . add ( mutation ) ; 
 + } 
 + return mutations ; 
 } 
 
 - if ( ! mutations . isEmpty ( ) ) 
 - replayMutations ( mutations , writtenAt , version , rateLimiter ) ; 
 - } 
 + private void writeHintsForUndeliveredEndpoints ( int startFrom ) 
 + { 
 + try 
 + { 
 + / / Here we deserialize mutations 2nd time from byte buffer . 
 + / / but this is ok , because timeout on batch direct delivery is rare 
 + / / ( it can happen only several seconds until node is marked dead ) 
 + / / so trading some cpu to keep less objects 
 + List < Mutation > replayingMutations = replayingMutations ( ) ; 
 + for ( int i = startFrom ; i < replayHandlers . size ( ) ; i + + ) 
 + { 
 + Mutation undeliveredMutation = replayingMutations . get ( i ) ; 
 + int ttl = calculateHintTTL ( replayingMutations ) ; 
 + ReplayWriteResponseHandler handler = replayHandlers . get ( i ) ; 
 
 - / * 
 - * We try to deliver the mutations to the replicas ourselves if they are alive and only resort to writing hints 
 - * when a replica is down or a write request times out . 
 - * / 
 - private void replayMutations ( List < Mutation > mutations , long writtenAt , int version , RateLimiter rateLimiter ) throws IOException 
 - { 
 - int ttl = calculateHintTTL ( mutations , writtenAt ) ; 
 - if ( ttl < = 0 ) 
 - return ; / / this batchlog entry has ' expired ' 
 - 
 - List < InetAddress > liveEndpoints = new ArrayList < > ( ) ; 
 - List < InetAddress > hintEndpoints = new ArrayList < > ( ) ; 
 - 
 - for ( Mutation mutation : mutations ) 
 + if ( ttl > 0 & & handler ! = null ) 
 + for ( InetAddress endpoint : handler . undelivered ) 
 + StorageProxy . writeHintForMutation ( undeliveredMutation , writtenAt , ttl , endpoint ) ; 
 + } 
 + } 
 + catch ( IOException e ) 
 + { 
 + logger . error ( " Cannot schedule hints for undelivered batch " , e ) ; 
 + } 
 + } 
 + 
 + private List < ReplayWriteResponseHandler > sendReplays ( List < Mutation > mutations , long writtenAt , int ttl ) 
 { 
 + List < ReplayWriteResponseHandler > handlers = new ArrayList < > ( mutations . size ( ) ) ; 
 + for ( Mutation mutation : mutations ) 
 + { 
 + ReplayWriteResponseHandler handler = sendSingleReplayMutation ( mutation , writtenAt , ttl ) ; 
 + if ( handler ! = null ) 
 + handlers . add ( handler ) ; 
 + } 
 + return handlers ; 
 + } 
 + 
 + / * * 
 + * We try to deliver the mutations to the replicas ourselves if they are alive and only resort to writing hints 
 + * when a replica is down or a write request times out . 
 + * 
 + * @ return direct delivery handler to wait on or null , if no live nodes found 
 + * / 
 + private ReplayWriteResponseHandler sendSingleReplayMutation ( final Mutation mutation , long writtenAt , int ttl ) 
 + { 
 + Set < InetAddress > liveEndpoints = new HashSet < > ( ) ; 
 String ks = mutation . getKeyspaceName ( ) ; 
 - Token tk = StorageService . getPartitioner ( ) . getToken ( mutation . key ( ) ) ; 
 - int mutationSize = ( int ) Mutation . serializer . serializedSize ( mutation , version ) ; 
 + Token < ? > tk = StorageService . getPartitioner ( ) . getToken ( mutation . key ( ) ) ; 
 
 for ( InetAddress endpoint : Iterables . concat ( StorageService . instance . getNaturalEndpoints ( ks , tk ) , 
 StorageService . instance . getTokenMetadata ( ) . pendingEndpointsFor ( tk , ks ) ) ) 
 { 
 - rateLimiter . acquire ( mutationSize ) ; 
 if ( endpoint . equals ( FBUtilities . getBroadcastAddress ( ) ) ) 
 mutation . apply ( ) ; 
 else if ( FailureDetector . instance . isAlive ( endpoint ) ) 
 liveEndpoints . add ( endpoint ) ; / / will try delivering directly instead of writing a hint . 
 else 
 - hintEndpoints . add ( endpoint ) ; 
 + StorageProxy . writeHintForMutation ( mutation , writtenAt , ttl , endpoint ) ; 
 } 
 
 - if ( ! liveEndpoints . isEmpty ( ) ) 
 - hintEndpoints . addAll ( attemptDirectDelivery ( mutation , liveEndpoints ) ) ; 
 + if ( liveEndpoints . isEmpty ( ) ) 
 + return null ; 
 
 - for ( InetAddress endpoint : hintEndpoints ) 
 - StorageProxy . writeHintForMutation ( mutation , writtenAt , ttl , endpoint ) ; 
 - 
 - liveEndpoints . clear ( ) ; 
 - hintEndpoints . clear ( ) ; 
 + ReplayWriteResponseHandler handler = new ReplayWriteResponseHandler ( liveEndpoints ) ; 
 + MessageOut < Mutation > message = mutation . createMessage ( ) ; 
 + for ( InetAddress endpoint : liveEndpoints ) 
 + MessagingService . instance ( ) . sendRR ( message , endpoint , handler , false ) ; 
 + return handler ; 
 } 
 - } 
 
 - / / Returns the endpoints we failed to deliver to . 
 - private Set < InetAddress > attemptDirectDelivery ( Mutation mutation , List < InetAddress > endpoints ) throws IOException 
 - { 
 - final List < WriteResponseHandler > handlers = new ArrayList < > ( ) ; 
 - final Set < InetAddress > undelivered = Collections . synchronizedSet ( new HashSet < InetAddress > ( ) ) ; 
 - 
 - for ( final InetAddress ep : endpoints ) 
 + / * 
 + * Calculate ttl for the mutations ' hints ( and reduce ttl by the time the mutations spent in the batchlog ) . 
 + * This ensures that deletes aren ' t " undone " by an old batch replay . 
 + * / 
 + private int calculateHintTTL ( Collection < Mutation > mutations ) 
 { 
 - Runnable callback = new Runnable ( ) 
 - { 
 - public void run ( ) 
 - { 
 - undelivered . remove ( ep ) ; 
 - } 
 - } ; 
 - WriteResponseHandler handler = new WriteResponseHandler ( ep , WriteType . UNLOGGED _ BATCH , callback ) ; 
 - MessagingService . instance ( ) . sendRR ( mutation . createMessage ( ) , ep , handler , false ) ; 
 - handlers . add ( handler ) ; 
 + int unadjustedTTL = Integer . MAX _ VALUE ; 
 + for ( Mutation mutation : mutations ) 
 + unadjustedTTL = Math . min ( unadjustedTTL , HintedHandOffManager . calculateHintTTL ( mutation ) ) ; 
 + return unadjustedTTL - ( int ) TimeUnit . MILLISECONDS . toSeconds ( System . currentTimeMillis ( ) - writtenAt ) ; 
 } 
 
 - / / Wait for all the requests to complete . 
 - for ( WriteResponseHandler handler : handlers ) 
 + private static class ReplayWriteResponseHandler extends WriteResponseHandler 
 { 
 - try 
 + private final Set < InetAddress > undelivered = Collections . newSetFromMap ( new ConcurrentHashMap < InetAddress , Boolean > ( ) ) ; 
 + 
 + public ReplayWriteResponseHandler ( Collection < InetAddress > writeEndpoints ) 
 { 
 - handler . get ( ) ; 
 + super ( writeEndpoints , Collections . < InetAddress > emptySet ( ) , null , null , null , WriteType . UNLOGGED _ BATCH ) ; 
 + undelivered . addAll ( writeEndpoints ) ; 
 } 
 - catch ( WriteTimeoutException e ) 
 + 
 + @ Override 
 + protected int totalBlockFor ( ) 
 { 
 - logger . debug ( " Timed out replaying a batched mutation to a node , will write a hint " ) ; 
 + return this . naturalEndpoints . size ( ) ; 
 } 
 - } 
 
 - return undelivered ; 
 - } 
 - 
 - / * 
 - * Calculate ttl for the mutations ' hints ( and reduce ttl by the time the mutations spent in the batchlog ) . 
 - * This ensures that deletes aren ' t " undone " by an old batch replay . 
 - * / 
 - private int calculateHintTTL ( List < Mutation > mutations , long writtenAt ) 
 - { 
 - int unadjustedTTL = Integer . MAX _ VALUE ; 
 - for ( Mutation mutation : mutations ) 
 - unadjustedTTL = Math . min ( unadjustedTTL , HintedHandOffManager . calculateHintTTL ( mutation ) ) ; 
 - return unadjustedTTL - ( int ) TimeUnit . MILLISECONDS . toSeconds ( System . currentTimeMillis ( ) - writtenAt ) ; 
 + @ Override 
 + public void response ( MessageIn m ) 
 + { 
 + boolean removed = undelivered . remove ( m . from ) ; 
 + assert removed ; 
 + super . response ( m ) ; 
 + } 
 + } 
 } 
 
 / / force flush + compaction to reclaim space from the replayed batches

NEAREST DIFF:
diff - - git a / NEWS . txt b / NEWS . txt 
 index 63d1e58 . . 706cd29 100644 
 - - - a / NEWS . txt 
 + + + b / NEWS . txt 
 @ @ - 42 , 7 + 42 , 7 @ @ Features 
 
 Upgrading 
 - - - - - - - - - 
 - - CQL3 uses to be case - insensitive for property map key in ALTER and CREATE 
 + - CQL3 used to be case - insensitive for property map key in ALTER and CREATE 
 statements . In other words : 
 CREATE KEYSPACE test WITH replication = { ' CLASS ' : ' SimpleStrategy ' , 
 ' REPLICATION _ FACTOR ' : ' 1 ' }
