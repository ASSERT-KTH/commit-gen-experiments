BLEU SCORE: 1.0

TEST MSG: Bugs handling range tombstones in the sstable iterators
GENERATED MSG: Bugs handling range tombstones in the sstable iterators

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index c58fad8 . . 728e3e7 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 13 , 6 + 13 , 7 @ @ <nl> * NoReplicationTokenAllocator should work with zero replication factor ( CASSANDRA - 12983 ) <nl> * Address message coalescing regression ( CASSANDRA - 12676 ) <nl> Merged from 3 . 0 : <nl> + * Bugs handling range tombstones in the sstable iterators ( CASSANDRA - 13340 ) <nl> * Fix CONTAINS filtering for null collections ( CASSANDRA - 13246 ) <nl> * Applying : Use a unique metric reservoir per test run when using Cassandra - wide metrics residing in MBeans ( CASSANDRA - 13216 ) <nl> * Propagate row deletions in 2i tables on upgrade ( CASSANDRA - 13320 ) <nl> diff - - git a / src / java / org / apache / cassandra / db / ClusteringPrefix . java b / src / java / org / apache / cassandra / db / ClusteringPrefix . java <nl> index 340e237 . . 1ecc92d 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ClusteringPrefix . java <nl> + + + b / src / java / org / apache / cassandra / db / ClusteringPrefix . java <nl> @ @ - 482 , 7 + 482 , 7 @ @ public interface ClusteringPrefix extends IMeasurableMemory , Clusterable <nl> } <nl> <nl> if ( bound . size ( ) = = nextSize ) <nl> - return nextKind . compareTo ( bound . kind ( ) ) ; <nl> + return Kind . compare ( nextKind , bound . kind ( ) ) ; <nl> <nl> / / We know that we ' ll have exited already if nextSize < bound . size <nl> return - bound . kind ( ) . comparedToClustering ; <nl> diff - - git a / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java b / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java <nl> index 79b8636 . . b977907 100644 <nl> - - - a / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java <nl> + + + b / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java <nl> @ @ - 690 , 6 + 690 , 5 @ @ public abstract class UnfilteredDeserializer <nl> } <nl> } <nl> } <nl> - <nl> } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableIterator . java <nl> index b3c2e94 . . e21bd72 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableIterator . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableIterator . java <nl> @ @ - 138 , 7 + 138 , 14 @ @ public class SSTableIterator extends AbstractSSTableIterator <nl> { <nl> assert deserializer ! = null ; <nl> <nl> - if ( ! deserializer . hasNext ( ) | | deserializer . compareNextTo ( end ) > 0 ) <nl> + / / We use a same reasoning as in handlePreSliceData regarding the strictness of the inequality below . <nl> + / / We want to exclude deserialized unfiltered equal to end , because 1 ) we won ' t miss any rows since those <nl> + / / woudn ' t be equal to a slice bound and 2 ) a end bound can be equal to a start bound <nl> + / / ( EXCL _ END ( x ) = = INCL _ START ( x ) for instance ) and in that case we don ' t want to return start bound because <nl> + / / it ' s fundamentally excluded . And if the bound is a end ( for a range tombstone ) , it means it ' s exactly <nl> + / / our slice end , but in that case we will properly close the range tombstone anyway as part of our " close <nl> + / / an open marker " code in hasNextInterna <nl> + if ( ! deserializer . hasNext ( ) | | deserializer . compareNextTo ( end ) > = 0 ) <nl> return null ; <nl> <nl> Unfiltered next = deserializer . readNext ( ) ; <nl> @ @ - 281 , 7 + 288 , 7 @ @ public class SSTableIterator extends AbstractSSTableIterator <nl> if ( indexState . isDone ( ) <nl> | | indexState . currentBlockIdx ( ) > lastBlockIdx <nl> | | ! deserializer . hasNext ( ) <nl> - | | ( indexState . currentBlockIdx ( ) = = lastBlockIdx & & deserializer . compareNextTo ( end ) > 0 ) ) <nl> + | | ( indexState . currentBlockIdx ( ) = = lastBlockIdx & & deserializer . compareNextTo ( end ) > = 0 ) ) <nl> return null ; <nl> <nl> <nl> diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java <nl> index c74b5db . . c4bcd9e 100644 <nl> - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java <nl> + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java <nl> @ @ - 28 , 6 + 28 , 7 @ @ import org . apache . cassandra . db . rows . * ; <nl> import org . apache . cassandra . io . sstable . format . SSTableReader ; <nl> import org . apache . cassandra . io . util . FileDataInput ; <nl> import org . apache . cassandra . io . util . FileHandle ; <nl> + import org . apache . cassandra . utils . AbstractIterator ; <nl> import org . apache . cassandra . utils . btree . BTree ; <nl> <nl> / * * <nl> @ @ - 81 , 6 + 82 , 11 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> protected ReusablePartitionData buffer ; <nl> protected Iterator < Unfiltered > iterator ; <nl> <nl> + / / Set in loadFromDisk ( ) and used in setIterator to handle range tombstone extending on multiple index block . See <nl> + / / loadFromDisk for details . Note that those are always false for non - indexed readers . <nl> + protected boolean skipFirstIteratedItem ; <nl> + protected boolean skipLastIteratedItem ; <nl> + <nl> private ReverseReader ( FileDataInput file , boolean shouldCloseFile ) <nl> { <nl> super ( file , shouldCloseFile ) ; <nl> @ @ - 123 , 8 + 129 , 8 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> buffer = createBuffer ( 1 ) ; <nl> / / Note that we can reuse that buffer between slices ( we could alternatively re - read from disk <nl> / / every time , but that feels more wasteful ) so we want to include everything from the beginning . <nl> - / / We can stop at the last slice end however since any following slice will be before that . <nl> - loadFromDisk ( null , slice . end ( ) , true ) ; <nl> + / / We can stop at the slice end however since any following slice will be before that . <nl> + loadFromDisk ( null , slice . end ( ) , true , false , false ) ; <nl> } <nl> setIterator ( slice ) ; <nl> } <nl> @ @ - 133 , 6 + 139 , 15 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> { <nl> assert buffer ! = null ; <nl> iterator = buffer . built . unfilteredIterator ( columns , Slices . with ( metadata ( ) . comparator , slice ) , true ) ; <nl> + <nl> + if ( ! iterator . hasNext ( ) ) <nl> + return ; <nl> + <nl> + if ( skipFirstIteratedItem ) <nl> + iterator . next ( ) ; <nl> + <nl> + if ( skipLastIteratedItem ) <nl> + iterator = new SkipLastIterator ( iterator ) ; <nl> } <nl> <nl> protected boolean hasNextInternal ( ) throws IOException <nl> @ @ - 158 , 9 + 173 , 18 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> <nl> / / Reads the unfiltered from disk and load them into the reader buffer . It stops reading when either the partition <nl> / / is fully read , or when stopReadingDisk ( ) returns true . <nl> - protected void loadFromDisk ( ClusteringBound start , ClusteringBound end , boolean includeFirst ) throws IOException <nl> + protected void loadFromDisk ( ClusteringBound start , <nl> + ClusteringBound end , <nl> + boolean includeFirst , <nl> + boolean hasPreviousBlock , <nl> + boolean hasNextBlock ) throws IOException <nl> { <nl> + / / start ! = null means it ' s the block covering the beginning of the slice , so it has to be the last block for this slice . <nl> + assert start = = null | | ! hasNextBlock ; <nl> + <nl> buffer . reset ( ) ; <nl> + skipFirstIteratedItem = false ; <nl> + skipLastIteratedItem = false ; <nl> <nl> boolean isFirst = true ; <nl> <nl> @ @ - 177 , 16 + 201 , 30 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> } <nl> } <nl> <nl> - / / If we have an open marker , it ' s either one from what we just skipped ( if start ! = null ) , or it ' s from the previous index block . <nl> + / / If we have an open marker , it ' s either one from what we just skipped or it ' s one that open in the next ( or <nl> + / / one of the next ) index block ( if openMarker = = openMarkerAtStartOfBlock ) . <nl> if ( openMarker ! = null ) <nl> { <nl> + / / We have to feed a marker to the buffer , because that marker is likely to be close later and ImmtableBTreePartition <nl> + / / doesn ' t take kindly to marker that comes without their counterpart . If that ' s the last block we ' re gonna read ( for <nl> + / / the current slice at least ) it ' s easy because we ' ll want to return that open marker at the end of the data in this <nl> + / / block anyway , so we have nothing more to do than adding it to the buffer . <nl> + / / If it ' s not the last block however , in which case we know we ' ll have start = = null , it means this marker is really <nl> + / / open in a next block and so while we do need to add it the buffer for the reason mentioned above , we don ' t <nl> + / / want to " return " it just yet , we ' ll wait until we reach it in the next blocks . That ' s why we trigger <nl> + / / skipLastIteratedItem in that case ( this is first item of the block , but we ' re iterating in reverse order <nl> + / / so it will be last returned by the iterator ) . <nl> ClusteringBound markerStart = start = = null ? ClusteringBound . BOTTOM : start ; <nl> buffer . add ( new RangeTombstoneBoundMarker ( markerStart , openMarker ) ) ; <nl> + if ( hasNextBlock ) <nl> + skipLastIteratedItem = true ; <nl> } <nl> <nl> / / Now deserialize everything until we reach our requested end ( if we have one ) <nl> + / / See SSTableIterator . ForwardRead . computeNext ( ) for why this is a strict inequality below : this is the same <nl> + / / reasoning here . <nl> while ( deserializer . hasNext ( ) <nl> - & & ( end = = null | | deserializer . compareNextTo ( end ) < = 0 ) <nl> + & & ( end = = null | | deserializer . compareNextTo ( end ) < 0 ) <nl> & & ! stopReadingDisk ( ) ) <nl> { <nl> Unfiltered unfiltered = deserializer . readNext ( ) ; <nl> @ @ - 202 , 9 + 240 , 18 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> / / If we have an open marker , we should close it before finishing <nl> if ( openMarker ! = null ) <nl> { <nl> - / / If we have no end and still an openMarker , this means we ' re indexed and the marker is closed in a following block . <nl> + / / This is the reverse problem than the one at the start of the block . Namely , if it ' s the first block <nl> + / / we deserialize for the slice ( the one covering the slice end basically ) , then it ' s easy , we just want <nl> + / / to add the close marker to the buffer and return it normally . <nl> + / / If it ' s note our first block ( for the slice ) however , it means that marker closed in a previously read <nl> + / / block and we have already returned it . So while we should still add it to the buffer for the sake of <nl> + / / not breaking ImmutableBTreePartition , we should skip it when returning from the iterator , hence the <nl> + / / skipFirstIteratedItem ( this is the last item of the block , but we ' re iterating in reverse order so it will <nl> + / / be the first returned by the iterator ) . <nl> ClusteringBound markerEnd = end = = null ? ClusteringBound . TOP : end ; <nl> buffer . add ( new RangeTombstoneBoundMarker ( markerEnd , getAndClearOpenMarker ( ) ) ) ; <nl> + if ( hasPreviousBlock ) <nl> + skipFirstIteratedItem = true ; <nl> } <nl> <nl> buffer . build ( ) ; <nl> @ @ - 267 , 13 + 314 , 13 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> if ( startIdx > = indexState . blocksCount ( ) ) <nl> startIdx = indexState . blocksCount ( ) - 1 ; <nl> <nl> - if ( startIdx ! = indexState . currentBlockIdx ( ) ) <nl> - { <nl> - indexState . setToBlock ( startIdx ) ; <nl> - readCurrentBlock ( true ) ; <nl> - } <nl> + / / Note that even if we were already set on the proper block ( which would happen if the previous slice <nl> + / / requested ended on the same block this one start ) , we can ' t reuse it because when reading the previous <nl> + / / slice we ' ve only read that block from the previous slice start . Re - reading also handles <nl> + / / skipFirstIteratedItem / skipLastIteratedItem that we would need to handle otherwise . <nl> + indexState . setToBlock ( startIdx ) ; <nl> <nl> - setIterator ( slice ) ; <nl> + readCurrentBlock ( false , startIdx ! = lastBlockIdx ) ; <nl> } <nl> <nl> @ Override <nl> @ @ - 282 , 15 + 329 , 14 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> if ( super . hasNextInternal ( ) ) <nl> return true ; <nl> <nl> - / / We have nothing more for our current block , move the previous one . <nl> - int previousBlockIdx = indexState . currentBlockIdx ( ) - 1 ; <nl> - if ( previousBlockIdx < 0 | | previousBlockIdx < lastBlockIdx ) <nl> + / / We have nothing more for our current block , move the next one ( so the one before on disk ) . <nl> + int nextBlockIdx = indexState . currentBlockIdx ( ) - 1 ; <nl> + if ( nextBlockIdx < 0 | | nextBlockIdx < lastBlockIdx ) <nl> return false ; <nl> <nl> / / The slice start can be in <nl> - indexState . setToBlock ( previousBlockIdx ) ; <nl> - readCurrentBlock ( false ) ; <nl> - setIterator ( slice ) ; <nl> + indexState . setToBlock ( nextBlockIdx ) ; <nl> + readCurrentBlock ( true , nextBlockIdx ! = lastBlockIdx ) ; <nl> / / since that new block is within the bounds we ' ve computed in setToSlice ( ) , we know there will <nl> / / always be something matching the slice unless we ' re on the lastBlockIdx ( in which case there <nl> / / may or may not be results , but if there isn ' t , we ' re done for the slice ) . <nl> @ @ - 300 , 33 + 346 , 42 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> / * * <nl> * Reads the current block , the last one we ' ve set . <nl> * <nl> - * @ param canIncludeSliceEnd whether the block can include the slice end . <nl> + * @ param hasPreviousBlock is whether we have already read a previous block for the current slice . <nl> + * @ param hasNextBlock is whether we have more blocks to read for the current slice . <nl> * / <nl> - private void readCurrentBlock ( boolean canIncludeSliceEnd ) throws IOException <nl> + private void readCurrentBlock ( boolean hasPreviousBlock , boolean hasNextBlock ) throws IOException <nl> { <nl> if ( buffer = = null ) <nl> buffer = createBuffer ( indexState . blocksCount ( ) ) ; <nl> <nl> int currentBlock = indexState . currentBlockIdx ( ) ; <nl> <nl> - boolean canIncludeSliceStart = currentBlock = = lastBlockIdx ; <nl> + / / The slice start ( resp . slice end ) is only meaningful on the last ( resp . first ) block read ( since again , <nl> + / / we read blocks in reverse order ) . <nl> + boolean canIncludeSliceStart = ! hasNextBlock ; <nl> + boolean canIncludeSliceEnd = ! hasPreviousBlock ; <nl> <nl> / / When dealing with old format sstable , we have the problem that a row can span 2 index block , i . e . it can <nl> / / start at the end of a block and end at the beginning of the next one . That ' s not a problem per se for <nl> / / UnfilteredDeserializer . OldFormatSerializer , since it always read rows entirely , even if they span index <nl> / / blocks , but as we reading index block in reverse we must be careful to not read the end of the row at <nl> / / beginning of a block before we ' re reading the beginning of that row . So what we do is that if we detect <nl> - / / that the row starting this block is also the row ending the previous one , we skip that first result and <nl> - / / let it be read when we ' ll read the previous block . <nl> + / / that the row starting this block is also the row ending the next one we ' re read ( previous on disk ) , then <nl> + / / we ' ll skip that first result and let it be read with the next block . <nl> boolean includeFirst = true ; <nl> if ( ! sstable . descriptor . version . storeRows ( ) & & currentBlock > 0 ) <nl> { <nl> - ClusteringPrefix lastOfPrevious = indexState . index ( currentBlock - 1 ) . lastName ; <nl> + ClusteringPrefix lastOfNext = indexState . index ( currentBlock - 1 ) . lastName ; <nl> ClusteringPrefix firstOfCurrent = indexState . index ( currentBlock ) . firstName ; <nl> - includeFirst = metadata ( ) . comparator . compare ( lastOfPrevious , firstOfCurrent ) ! = 0 ; <nl> + includeFirst = metadata ( ) . comparator . compare ( lastOfNext , firstOfCurrent ) ! = 0 ; <nl> } <nl> <nl> - loadFromDisk ( canIncludeSliceStart ? slice . start ( ) : null , canIncludeSliceEnd ? slice . end ( ) : null , includeFirst ) ; <nl> + loadFromDisk ( canIncludeSliceStart ? slice . start ( ) : null , <nl> + canIncludeSliceEnd ? slice . end ( ) : null , <nl> + includeFirst , <nl> + hasPreviousBlock , <nl> + hasNextBlock ) ; <nl> + setIterator ( slice ) ; <nl> } <nl> <nl> @ Override <nl> @ @ - 382 , 4 + 437 , 23 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator <nl> deletionBuilder = null ; <nl> } <nl> } <nl> + <nl> + private static class SkipLastIterator extends AbstractIterator < Unfiltered > <nl> + { <nl> + private final Iterator < Unfiltered > iterator ; <nl> + <nl> + private SkipLastIterator ( Iterator < Unfiltered > iterator ) <nl> + { <nl> + this . iterator = iterator ; <nl> + } <nl> + <nl> + protected Unfiltered computeNext ( ) <nl> + { <nl> + if ( ! iterator . hasNext ( ) ) <nl> + return endOfData ( ) ; <nl> + <nl> + Unfiltered next = iterator . next ( ) ; <nl> + return iterator . hasNext ( ) ? next : endOfData ( ) ; <nl> + } <nl> + } <nl> } <nl> diff - - git a / test / unit / org / apache / cassandra / cql3 / validation / operations / DeleteTest . java b / test / unit / org / apache / cassandra / cql3 / validation / operations / DeleteTest . java <nl> index 4694ffc . . 6edca38 100644 <nl> - - - a / test / unit / org / apache / cassandra / cql3 / validation / operations / DeleteTest . java <nl> + + + b / test / unit / org / apache / cassandra / cql3 / validation / operations / DeleteTest . java <nl> @ @ - 1345 , 6 + 1345 , 76 @ @ public class DeleteTest extends CQLTester <nl> assertTrue ( " The memtable should be empty but is not " , isMemtableEmpty ( ) ) ; <nl> } <nl> <nl> + @ Test <nl> + public void testQueryingOnRangeTombstoneBoundForward ( ) throws Throwable <nl> + { <nl> + createTable ( " CREATE TABLE % s ( k text , i int , PRIMARY KEY ( k , i ) ) " ) ; <nl> + <nl> + execute ( " INSERT INTO % s ( k , i ) VALUES ( ? , ? ) " , " a " , 0 ) ; <nl> + <nl> + execute ( " DELETE FROM % s WHERE k = ? AND i > ? AND i < = ? " , " a " , 0 , 1 ) ; <nl> + execute ( " DELETE FROM % s WHERE k = ? AND i > ? " , " a " , 1 ) ; <nl> + <nl> + flush ( ) ; <nl> + <nl> + assertEmpty ( execute ( " SELECT i FROM % s WHERE k = ? AND i = ? " , " a " , 1 ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testQueryingOnRangeTombstoneBoundReverse ( ) throws Throwable <nl> + { <nl> + createTable ( " CREATE TABLE % s ( k text , i int , PRIMARY KEY ( k , i ) ) " ) ; <nl> + <nl> + execute ( " INSERT INTO % s ( k , i ) VALUES ( ? , ? ) " , " a " , 0 ) ; <nl> + <nl> + execute ( " DELETE FROM % s WHERE k = ? AND i > ? AND i < = ? " , " a " , 0 , 1 ) ; <nl> + execute ( " DELETE FROM % s WHERE k = ? AND i > ? " , " a " , 1 ) ; <nl> + <nl> + flush ( ) ; <nl> + <nl> + assertRows ( execute ( " SELECT i FROM % s WHERE k = ? AND i < = ? ORDER BY i DESC " , " a " , 1 ) , row ( 0 ) ) ; <nl> + } <nl> + <nl> + @ Test <nl> + public void testReverseQueryWithRangeTombstoneOnMultipleBlocks ( ) throws Throwable <nl> + { <nl> + createTable ( " CREATE TABLE % s ( k text , i int , v text , PRIMARY KEY ( k , i ) ) " ) ; <nl> + <nl> + StringBuilder sb = new StringBuilder ( ) ; <nl> + for ( int i = 0 ; i < 1200 ; i + + ) <nl> + sb . append ( ' a ' ) ; <nl> + String longText = sb . toString ( ) ; <nl> + <nl> + for ( int i = 0 ; i < 10 ; i + + ) <nl> + execute ( " INSERT INTO % s ( k , i , v ) VALUES ( ? , ? , ? ) USING TIMESTAMP 3 " , " a " , i * 2 , longText ) ; <nl> + <nl> + execute ( " DELETE FROM % s USING TIMESTAMP 1 WHERE k = ? AND i > = ? AND i < = ? " , " a " , 12 , 16 ) ; <nl> + <nl> + flush ( ) ; <nl> + <nl> + execute ( " INSERT INTO % s ( k , i , v ) VALUES ( ? , ? , ? ) USING TIMESTAMP 0 " , " a " , 3 , longText ) ; <nl> + execute ( " INSERT INTO % s ( k , i , v ) VALUES ( ? , ? , ? ) USING TIMESTAMP 3 " , " a " , 11 , longText ) ; <nl> + execute ( " INSERT INTO % s ( k , i , v ) VALUES ( ? , ? , ? ) USING TIMESTAMP 0 " , " a " , 15 , longText ) ; <nl> + execute ( " INSERT INTO % s ( k , i , v ) VALUES ( ? , ? , ? ) USING TIMESTAMP 0 " , " a " , 17 , longText ) ; <nl> + <nl> + flush ( ) ; <nl> + <nl> + assertRows ( execute ( " SELECT i FROM % s WHERE k = ? ORDER BY i DESC " , " a " ) , <nl> + row ( 18 ) , <nl> + row ( 17 ) , <nl> + row ( 16 ) , <nl> + row ( 14 ) , <nl> + row ( 12 ) , <nl> + row ( 11 ) , <nl> + row ( 10 ) , <nl> + row ( 8 ) , <nl> + row ( 6 ) , <nl> + row ( 4 ) , <nl> + row ( 3 ) , <nl> + row ( 2 ) , <nl> + row ( 0 ) ) ; <nl> + } <nl> + <nl> / * * <nl> * Test for CASSANDRA - 13305 <nl> * /
NEAREST DIFF (one line): ELIMINATEDSENTENCE

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index c58fad8 . . 728e3e7 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 13 , 6 + 13 , 7 @ @ 
 * NoReplicationTokenAllocator should work with zero replication factor ( CASSANDRA - 12983 ) 
 * Address message coalescing regression ( CASSANDRA - 12676 ) 
 Merged from 3 . 0 : 
 + * Bugs handling range tombstones in the sstable iterators ( CASSANDRA - 13340 ) 
 * Fix CONTAINS filtering for null collections ( CASSANDRA - 13246 ) 
 * Applying : Use a unique metric reservoir per test run when using Cassandra - wide metrics residing in MBeans ( CASSANDRA - 13216 ) 
 * Propagate row deletions in 2i tables on upgrade ( CASSANDRA - 13320 ) 
 diff - - git a / src / java / org / apache / cassandra / db / ClusteringPrefix . java b / src / java / org / apache / cassandra / db / ClusteringPrefix . java 
 index 340e237 . . 1ecc92d 100644 
 - - - a / src / java / org / apache / cassandra / db / ClusteringPrefix . java 
 + + + b / src / java / org / apache / cassandra / db / ClusteringPrefix . java 
 @ @ - 482 , 7 + 482 , 7 @ @ public interface ClusteringPrefix extends IMeasurableMemory , Clusterable 
 } 
 
 if ( bound . size ( ) = = nextSize ) 
 - return nextKind . compareTo ( bound . kind ( ) ) ; 
 + return Kind . compare ( nextKind , bound . kind ( ) ) ; 
 
 / / We know that we ' ll have exited already if nextSize < bound . size 
 return - bound . kind ( ) . comparedToClustering ; 
 diff - - git a / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java b / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java 
 index 79b8636 . . b977907 100644 
 - - - a / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java 
 + + + b / src / java / org / apache / cassandra / db / UnfilteredDeserializer . java 
 @ @ - 690 , 6 + 690 , 5 @ @ public abstract class UnfilteredDeserializer 
 } 
 } 
 } 
 - 
 } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableIterator . java 
 index b3c2e94 . . e21bd72 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableIterator . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableIterator . java 
 @ @ - 138 , 7 + 138 , 14 @ @ public class SSTableIterator extends AbstractSSTableIterator 
 { 
 assert deserializer ! = null ; 
 
 - if ( ! deserializer . hasNext ( ) | | deserializer . compareNextTo ( end ) > 0 ) 
 + / / We use a same reasoning as in handlePreSliceData regarding the strictness of the inequality below . 
 + / / We want to exclude deserialized unfiltered equal to end , because 1 ) we won ' t miss any rows since those 
 + / / woudn ' t be equal to a slice bound and 2 ) a end bound can be equal to a start bound 
 + / / ( EXCL _ END ( x ) = = INCL _ START ( x ) for instance ) and in that case we don ' t want to return start bound because 
 + / / it ' s fundamentally excluded . And if the bound is a end ( for a range tombstone ) , it means it ' s exactly 
 + / / our slice end , but in that case we will properly close the range tombstone anyway as part of our " close 
 + / / an open marker " code in hasNextInterna 
 + if ( ! deserializer . hasNext ( ) | | deserializer . compareNextTo ( end ) > = 0 ) 
 return null ; 
 
 Unfiltered next = deserializer . readNext ( ) ; 
 @ @ - 281 , 7 + 288 , 7 @ @ public class SSTableIterator extends AbstractSSTableIterator 
 if ( indexState . isDone ( ) 
 | | indexState . currentBlockIdx ( ) > lastBlockIdx 
 | | ! deserializer . hasNext ( ) 
 - | | ( indexState . currentBlockIdx ( ) = = lastBlockIdx & & deserializer . compareNextTo ( end ) > 0 ) ) 
 + | | ( indexState . currentBlockIdx ( ) = = lastBlockIdx & & deserializer . compareNextTo ( end ) > = 0 ) ) 
 return null ; 
 
 
 diff - - git a / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java b / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java 
 index c74b5db . . c4bcd9e 100644 
 - - - a / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java 
 + + + b / src / java / org / apache / cassandra / db / columniterator / SSTableReversedIterator . java 
 @ @ - 28 , 6 + 28 , 7 @ @ import org . apache . cassandra . db . rows . * ; 
 import org . apache . cassandra . io . sstable . format . SSTableReader ; 
 import org . apache . cassandra . io . util . FileDataInput ; 
 import org . apache . cassandra . io . util . FileHandle ; 
 + import org . apache . cassandra . utils . AbstractIterator ; 
 import org . apache . cassandra . utils . btree . BTree ; 
 
 / * * 
 @ @ - 81 , 6 + 82 , 11 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 protected ReusablePartitionData buffer ; 
 protected Iterator < Unfiltered > iterator ; 
 
 + / / Set in loadFromDisk ( ) and used in setIterator to handle range tombstone extending on multiple index block . See 
 + / / loadFromDisk for details . Note that those are always false for non - indexed readers . 
 + protected boolean skipFirstIteratedItem ; 
 + protected boolean skipLastIteratedItem ; 
 + 
 private ReverseReader ( FileDataInput file , boolean shouldCloseFile ) 
 { 
 super ( file , shouldCloseFile ) ; 
 @ @ - 123 , 8 + 129 , 8 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 buffer = createBuffer ( 1 ) ; 
 / / Note that we can reuse that buffer between slices ( we could alternatively re - read from disk 
 / / every time , but that feels more wasteful ) so we want to include everything from the beginning . 
 - / / We can stop at the last slice end however since any following slice will be before that . 
 - loadFromDisk ( null , slice . end ( ) , true ) ; 
 + / / We can stop at the slice end however since any following slice will be before that . 
 + loadFromDisk ( null , slice . end ( ) , true , false , false ) ; 
 } 
 setIterator ( slice ) ; 
 } 
 @ @ - 133 , 6 + 139 , 15 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 { 
 assert buffer ! = null ; 
 iterator = buffer . built . unfilteredIterator ( columns , Slices . with ( metadata ( ) . comparator , slice ) , true ) ; 
 + 
 + if ( ! iterator . hasNext ( ) ) 
 + return ; 
 + 
 + if ( skipFirstIteratedItem ) 
 + iterator . next ( ) ; 
 + 
 + if ( skipLastIteratedItem ) 
 + iterator = new SkipLastIterator ( iterator ) ; 
 } 
 
 protected boolean hasNextInternal ( ) throws IOException 
 @ @ - 158 , 9 + 173 , 18 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 
 / / Reads the unfiltered from disk and load them into the reader buffer . It stops reading when either the partition 
 / / is fully read , or when stopReadingDisk ( ) returns true . 
 - protected void loadFromDisk ( ClusteringBound start , ClusteringBound end , boolean includeFirst ) throws IOException 
 + protected void loadFromDisk ( ClusteringBound start , 
 + ClusteringBound end , 
 + boolean includeFirst , 
 + boolean hasPreviousBlock , 
 + boolean hasNextBlock ) throws IOException 
 { 
 + / / start ! = null means it ' s the block covering the beginning of the slice , so it has to be the last block for this slice . 
 + assert start = = null | | ! hasNextBlock ; 
 + 
 buffer . reset ( ) ; 
 + skipFirstIteratedItem = false ; 
 + skipLastIteratedItem = false ; 
 
 boolean isFirst = true ; 
 
 @ @ - 177 , 16 + 201 , 30 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 } 
 } 
 
 - / / If we have an open marker , it ' s either one from what we just skipped ( if start ! = null ) , or it ' s from the previous index block . 
 + / / If we have an open marker , it ' s either one from what we just skipped or it ' s one that open in the next ( or 
 + / / one of the next ) index block ( if openMarker = = openMarkerAtStartOfBlock ) . 
 if ( openMarker ! = null ) 
 { 
 + / / We have to feed a marker to the buffer , because that marker is likely to be close later and ImmtableBTreePartition 
 + / / doesn ' t take kindly to marker that comes without their counterpart . If that ' s the last block we ' re gonna read ( for 
 + / / the current slice at least ) it ' s easy because we ' ll want to return that open marker at the end of the data in this 
 + / / block anyway , so we have nothing more to do than adding it to the buffer . 
 + / / If it ' s not the last block however , in which case we know we ' ll have start = = null , it means this marker is really 
 + / / open in a next block and so while we do need to add it the buffer for the reason mentioned above , we don ' t 
 + / / want to " return " it just yet , we ' ll wait until we reach it in the next blocks . That ' s why we trigger 
 + / / skipLastIteratedItem in that case ( this is first item of the block , but we ' re iterating in reverse order 
 + / / so it will be last returned by the iterator ) . 
 ClusteringBound markerStart = start = = null ? ClusteringBound . BOTTOM : start ; 
 buffer . add ( new RangeTombstoneBoundMarker ( markerStart , openMarker ) ) ; 
 + if ( hasNextBlock ) 
 + skipLastIteratedItem = true ; 
 } 
 
 / / Now deserialize everything until we reach our requested end ( if we have one ) 
 + / / See SSTableIterator . ForwardRead . computeNext ( ) for why this is a strict inequality below : this is the same 
 + / / reasoning here . 
 while ( deserializer . hasNext ( ) 
 - & & ( end = = null | | deserializer . compareNextTo ( end ) < = 0 ) 
 + & & ( end = = null | | deserializer . compareNextTo ( end ) < 0 ) 
 & & ! stopReadingDisk ( ) ) 
 { 
 Unfiltered unfiltered = deserializer . readNext ( ) ; 
 @ @ - 202 , 9 + 240 , 18 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 / / If we have an open marker , we should close it before finishing 
 if ( openMarker ! = null ) 
 { 
 - / / If we have no end and still an openMarker , this means we ' re indexed and the marker is closed in a following block . 
 + / / This is the reverse problem than the one at the start of the block . Namely , if it ' s the first block 
 + / / we deserialize for the slice ( the one covering the slice end basically ) , then it ' s easy , we just want 
 + / / to add the close marker to the buffer and return it normally . 
 + / / If it ' s note our first block ( for the slice ) however , it means that marker closed in a previously read 
 + / / block and we have already returned it . So while we should still add it to the buffer for the sake of 
 + / / not breaking ImmutableBTreePartition , we should skip it when returning from the iterator , hence the 
 + / / skipFirstIteratedItem ( this is the last item of the block , but we ' re iterating in reverse order so it will 
 + / / be the first returned by the iterator ) . 
 ClusteringBound markerEnd = end = = null ? ClusteringBound . TOP : end ; 
 buffer . add ( new RangeTombstoneBoundMarker ( markerEnd , getAndClearOpenMarker ( ) ) ) ; 
 + if ( hasPreviousBlock ) 
 + skipFirstIteratedItem = true ; 
 } 
 
 buffer . build ( ) ; 
 @ @ - 267 , 13 + 314 , 13 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 if ( startIdx > = indexState . blocksCount ( ) ) 
 startIdx = indexState . blocksCount ( ) - 1 ; 
 
 - if ( startIdx ! = indexState . currentBlockIdx ( ) ) 
 - { 
 - indexState . setToBlock ( startIdx ) ; 
 - readCurrentBlock ( true ) ; 
 - } 
 + / / Note that even if we were already set on the proper block ( which would happen if the previous slice 
 + / / requested ended on the same block this one start ) , we can ' t reuse it because when reading the previous 
 + / / slice we ' ve only read that block from the previous slice start . Re - reading also handles 
 + / / skipFirstIteratedItem / skipLastIteratedItem that we would need to handle otherwise . 
 + indexState . setToBlock ( startIdx ) ; 
 
 - setIterator ( slice ) ; 
 + readCurrentBlock ( false , startIdx ! = lastBlockIdx ) ; 
 } 
 
 @ Override 
 @ @ - 282 , 15 + 329 , 14 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 if ( super . hasNextInternal ( ) ) 
 return true ; 
 
 - / / We have nothing more for our current block , move the previous one . 
 - int previousBlockIdx = indexState . currentBlockIdx ( ) - 1 ; 
 - if ( previousBlockIdx < 0 | | previousBlockIdx < lastBlockIdx ) 
 + / / We have nothing more for our current block , move the next one ( so the one before on disk ) . 
 + int nextBlockIdx = indexState . currentBlockIdx ( ) - 1 ; 
 + if ( nextBlockIdx < 0 | | nextBlockIdx < lastBlockIdx ) 
 return false ; 
 
 / / The slice start can be in 
 - indexState . setToBlock ( previousBlockIdx ) ; 
 - readCurrentBlock ( false ) ; 
 - setIterator ( slice ) ; 
 + indexState . setToBlock ( nextBlockIdx ) ; 
 + readCurrentBlock ( true , nextBlockIdx ! = lastBlockIdx ) ; 
 / / since that new block is within the bounds we ' ve computed in setToSlice ( ) , we know there will 
 / / always be something matching the slice unless we ' re on the lastBlockIdx ( in which case there 
 / / may or may not be results , but if there isn ' t , we ' re done for the slice ) . 
 @ @ - 300 , 33 + 346 , 42 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 / * * 
 * Reads the current block , the last one we ' ve set . 
 * 
 - * @ param canIncludeSliceEnd whether the block can include the slice end . 
 + * @ param hasPreviousBlock is whether we have already read a previous block for the current slice . 
 + * @ param hasNextBlock is whether we have more blocks to read for the current slice . 
 * / 
 - private void readCurrentBlock ( boolean canIncludeSliceEnd ) throws IOException 
 + private void readCurrentBlock ( boolean hasPreviousBlock , boolean hasNextBlock ) throws IOException 
 { 
 if ( buffer = = null ) 
 buffer = createBuffer ( indexState . blocksCount ( ) ) ; 
 
 int currentBlock = indexState . currentBlockIdx ( ) ; 
 
 - boolean canIncludeSliceStart = currentBlock = = lastBlockIdx ; 
 + / / The slice start ( resp . slice end ) is only meaningful on the last ( resp . first ) block read ( since again , 
 + / / we read blocks in reverse order ) . 
 + boolean canIncludeSliceStart = ! hasNextBlock ; 
 + boolean canIncludeSliceEnd = ! hasPreviousBlock ; 
 
 / / When dealing with old format sstable , we have the problem that a row can span 2 index block , i . e . it can 
 / / start at the end of a block and end at the beginning of the next one . That ' s not a problem per se for 
 / / UnfilteredDeserializer . OldFormatSerializer , since it always read rows entirely , even if they span index 
 / / blocks , but as we reading index block in reverse we must be careful to not read the end of the row at 
 / / beginning of a block before we ' re reading the beginning of that row . So what we do is that if we detect 
 - / / that the row starting this block is also the row ending the previous one , we skip that first result and 
 - / / let it be read when we ' ll read the previous block . 
 + / / that the row starting this block is also the row ending the next one we ' re read ( previous on disk ) , then 
 + / / we ' ll skip that first result and let it be read with the next block . 
 boolean includeFirst = true ; 
 if ( ! sstable . descriptor . version . storeRows ( ) & & currentBlock > 0 ) 
 { 
 - ClusteringPrefix lastOfPrevious = indexState . index ( currentBlock - 1 ) . lastName ; 
 + ClusteringPrefix lastOfNext = indexState . index ( currentBlock - 1 ) . lastName ; 
 ClusteringPrefix firstOfCurrent = indexState . index ( currentBlock ) . firstName ; 
 - includeFirst = metadata ( ) . comparator . compare ( lastOfPrevious , firstOfCurrent ) ! = 0 ; 
 + includeFirst = metadata ( ) . comparator . compare ( lastOfNext , firstOfCurrent ) ! = 0 ; 
 } 
 
 - loadFromDisk ( canIncludeSliceStart ? slice . start ( ) : null , canIncludeSliceEnd ? slice . end ( ) : null , includeFirst ) ; 
 + loadFromDisk ( canIncludeSliceStart ? slice . start ( ) : null , 
 + canIncludeSliceEnd ? slice . end ( ) : null , 
 + includeFirst , 
 + hasPreviousBlock , 
 + hasNextBlock ) ; 
 + setIterator ( slice ) ; 
 } 
 
 @ Override 
 @ @ - 382 , 4 + 437 , 23 @ @ public class SSTableReversedIterator extends AbstractSSTableIterator 
 deletionBuilder = null ; 
 } 
 } 
 + 
 + private static class SkipLastIterator extends AbstractIterator < Unfiltered > 
 + { 
 + private final Iterator < Unfiltered > iterator ; 
 + 
 + private SkipLastIterator ( Iterator < Unfiltered > iterator ) 
 + { 
 + this . iterator = iterator ; 
 + } 
 + 
 + protected Unfiltered computeNext ( ) 
 + { 
 + if ( ! iterator . hasNext ( ) ) 
 + return endOfData ( ) ; 
 + 
 + Unfiltered next = iterator . next ( ) ; 
 + return iterator . hasNext ( ) ? next : endOfData ( ) ; 
 + } 
 + } 
 } 
 diff - - git a / test / unit / org / apache / cassandra / cql3 / validation / operations / DeleteTest . java b / test / unit / org / apache / cassandra / cql3 / validation / operations / DeleteTest . java 
 index 4694ffc . . 6edca38 100644 
 - - - a / test / unit / org / apache / cassandra / cql3 / validation / operations / DeleteTest . java 
 + + + b / test / unit / org / apache / cassandra / cql3 / validation / operations / DeleteTest . java 
 @ @ - 1345 , 6 + 1345 , 76 @ @ public class DeleteTest extends CQLTester 
 assertTrue ( " The memtable should be empty but is not " , isMemtableEmpty ( ) ) ; 
 } 
 
 + @ Test 
 + public void testQueryingOnRangeTombstoneBoundForward ( ) throws Throwable 
 + { 
 + createTable ( " CREATE TABLE % s ( k text , i int , PRIMARY KEY ( k , i ) ) " ) ; 
 + 
 + execute ( " INSERT INTO % s ( k , i ) VALUES ( ? , ? ) " , " a " , 0 ) ; 
 + 
 + execute ( " DELETE FROM % s WHERE k = ? AND i > ? AND i < = ? " , " a " , 0 , 1 ) ; 
 + execute ( " DELETE FROM % s WHERE k = ? AND i > ? " , " a " , 1 ) ; 
 + 
 + flush ( ) ; 
 + 
 + assertEmpty ( execute ( " SELECT i FROM % s WHERE k = ? AND i = ? " , " a " , 1 ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testQueryingOnRangeTombstoneBoundReverse ( ) throws Throwable 
 + { 
 + createTable ( " CREATE TABLE % s ( k text , i int , PRIMARY KEY ( k , i ) ) " ) ; 
 + 
 + execute ( " INSERT INTO % s ( k , i ) VALUES ( ? , ? ) " , " a " , 0 ) ; 
 + 
 + execute ( " DELETE FROM % s WHERE k = ? AND i > ? AND i < = ? " , " a " , 0 , 1 ) ; 
 + execute ( " DELETE FROM % s WHERE k = ? AND i > ? " , " a " , 1 ) ; 
 + 
 + flush ( ) ; 
 + 
 + assertRows ( execute ( " SELECT i FROM % s WHERE k = ? AND i < = ? ORDER BY i DESC " , " a " , 1 ) , row ( 0 ) ) ; 
 + } 
 + 
 + @ Test 
 + public void testReverseQueryWithRangeTombstoneOnMultipleBlocks ( ) throws Throwable 
 + { 
 + createTable ( " CREATE TABLE % s ( k text , i int , v text , PRIMARY KEY ( k , i ) ) " ) ; 
 + 
 + StringBuilder sb = new StringBuilder ( ) ; 
 + for ( int i = 0 ; i < 1200 ; i + + ) 
 + sb . append ( ' a ' ) ; 
 + String longText = sb . toString ( ) ; 
 + 
 + for ( int i = 0 ; i < 10 ; i + + ) 
 + execute ( " INSERT INTO % s ( k , i , v ) VALUES ( ? , ? , ? ) USING TIMESTAMP 3 " , " a " , i * 2 , longText ) ; 
 + 
 + execute ( " DELETE FROM % s USING TIMESTAMP 1 WHERE k = ? AND i > = ? AND i < = ? " , " a " , 12 , 16 ) ; 
 + 
 + flush ( ) ; 
 + 
 + execute ( " INSERT INTO % s ( k , i , v ) VALUES ( ? , ? , ? ) USING TIMESTAMP 0 " , " a " , 3 , longText ) ; 
 + execute ( " INSERT INTO % s ( k , i , v ) VALUES ( ? , ? , ? ) USING TIMESTAMP 3 " , " a " , 11 , longText ) ; 
 + execute ( " INSERT INTO % s ( k , i , v ) VALUES ( ? , ? , ? ) USING TIMESTAMP 0 " , " a " , 15 , longText ) ; 
 + execute ( " INSERT INTO % s ( k , i , v ) VALUES ( ? , ? , ? ) USING TIMESTAMP 0 " , " a " , 17 , longText ) ; 
 + 
 + flush ( ) ; 
 + 
 + assertRows ( execute ( " SELECT i FROM % s WHERE k = ? ORDER BY i DESC " , " a " ) , 
 + row ( 18 ) , 
 + row ( 17 ) , 
 + row ( 16 ) , 
 + row ( 14 ) , 
 + row ( 12 ) , 
 + row ( 11 ) , 
 + row ( 10 ) , 
 + row ( 8 ) , 
 + row ( 6 ) , 
 + row ( 4 ) , 
 + row ( 3 ) , 
 + row ( 2 ) , 
 + row ( 0 ) ) ; 
 + } 
 + 
 / * * 
 * Test for CASSANDRA - 13305 
 * /

NEAREST DIFF:
ELIMINATEDSENTENCE
