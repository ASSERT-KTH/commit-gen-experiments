BLEU SCORE: 0.005031649373920587

TEST MSG: Bulk Loader API could not tolerate even node failure
GENERATED MSG: Fixes to make BinaryMemtable useful . Highlights are configurable threads for [ binary ] memtable flushing and flushAndShutdown JMX / nodeprobe directive .

TEST DIFF (one line): diff - - git a / CHANGES . txt b / CHANGES . txt <nl> index 0ad2b36 . . eec8161 100644 <nl> - - - a / CHANGES . txt <nl> + + + b / CHANGES . txt <nl> @ @ - 1 , 4 + 1 , 5 @ @ <nl> 2 . 1 . 10 <nl> + * Bulk Loader API could not tolerate even node failure ( CASSANDRA - 10347 ) <nl> * Avoid misleading pushed notifications when multiple nodes <nl> share an rpc _ address ( CASSANDRA - 10052 ) <nl> * Fix dropping undroppable when message queue is full ( CASSANDRA - 10113 ) <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / AbstractBulkOutputFormat . java b / src / java / org / apache / cassandra / hadoop / AbstractBulkOutputFormat . java <nl> index c0e91da . . e893ba6 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / AbstractBulkOutputFormat . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / AbstractBulkOutputFormat . java <nl> @ @ - 19 , 6 + 19 , 7 @ @ package org . apache . cassandra . hadoop ; <nl> <nl> <nl> import java . io . IOException ; <nl> + import java . util . Collection ; <nl> <nl> import org . apache . hadoop . conf . Configuration ; <nl> import org . apache . hadoop . mapreduce . * ; <nl> @ @ - 70 , 4 + 71 , 35 @ @ public abstract class AbstractBulkOutputFormat < K , V > extends OutputFormat < K , V > <nl> <nl> public void setupTask ( TaskAttemptContext taskContext ) { } <nl> } <nl> + <nl> + / * * <nl> + * Set the hosts to ignore as comma delimited values . <nl> + * Data will not be bulk loaded onto the ignored nodes . <nl> + * @ param conf job configuration <nl> + * @ param ignoreNodesCsv a comma delimited list of nodes to ignore <nl> + * / <nl> + public static void setIgnoreHosts ( Configuration conf , String ignoreNodesCsv ) <nl> + { <nl> + conf . set ( AbstractBulkRecordWriter . IGNORE _ HOSTS , ignoreNodesCsv ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Set the hosts to ignore . Data will not be bulk loaded onto the ignored nodes . <nl> + * @ param conf job configuration <nl> + * @ param ignoreNodes the nodes to ignore <nl> + * / <nl> + public static void setIgnoreHosts ( Configuration conf , String . . . ignoreNodes ) <nl> + { <nl> + conf . setStrings ( AbstractBulkRecordWriter . IGNORE _ HOSTS , ignoreNodes ) ; <nl> + } <nl> + <nl> + / * * <nl> + * Get the hosts to ignore as a collection of strings <nl> + * @ param conf job configuration <nl> + * @ return the nodes to ignore as a collection of stirngs <nl> + * / <nl> + public static Collection < String > getIgnoreHosts ( Configuration conf ) <nl> + { <nl> + return conf . getStringCollection ( AbstractBulkRecordWriter . IGNORE _ HOSTS ) ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / hadoop / AbstractBulkRecordWriter . java b / src / java / org / apache / cassandra / hadoop / AbstractBulkRecordWriter . java <nl> index 22255a6 . . f9322c7 100644 <nl> - - - a / src / java / org / apache / cassandra / hadoop / AbstractBulkRecordWriter . java <nl> + + + b / src / java / org / apache / cassandra / hadoop / AbstractBulkRecordWriter . java <nl> @ @ - 21 , 6 + 21 , 7 @ @ import java . io . Closeable ; <nl> import java . io . IOException ; <nl> import java . net . InetAddress ; <nl> import java . net . UnknownHostException ; <nl> + import java . util . Collection ; <nl> import java . util . HashMap ; <nl> import java . util . HashSet ; <nl> import java . util . Iterator ; <nl> @ @ - 60 , 12 + 61 , 14 @ @ implements org . apache . hadoop . mapred . RecordWriter < K , V > <nl> public final static String BUFFER _ SIZE _ IN _ MB = " mapreduce . output . bulkoutputformat . buffersize " ; <nl> public final static String STREAM _ THROTTLE _ MBITS = " mapreduce . output . bulkoutputformat . streamthrottlembits " ; <nl> public final static String MAX _ FAILED _ HOSTS = " mapreduce . output . bulkoutputformat . maxfailedhosts " ; <nl> + public static final String IGNORE _ HOSTS = " mapreduce . output . bulkoutputformat . ignorehosts " ; <nl> <nl> private final Logger logger = LoggerFactory . getLogger ( AbstractBulkRecordWriter . class ) ; <nl> <nl> protected final Configuration conf ; <nl> protected final int maxFailures ; <nl> - protected final int bufferSize ; <nl> + protected final int bufferSize ; <nl> + protected final Set < InetAddress > ignores = new HashSet < > ( ) ; <nl> protected Closeable writer ; <nl> protected SSTableLoader loader ; <nl> protected Progressable progress ; <nl> @ @ - 91 , 6 + 94 , 15 @ @ implements org . apache . hadoop . mapred . RecordWriter < K , V > <nl> DatabaseDescriptor . setStreamThroughputOutboundMegabitsPerSec ( Integer . parseInt ( conf . get ( STREAM _ THROTTLE _ MBITS , " 0 " ) ) ) ; <nl> maxFailures = Integer . parseInt ( conf . get ( MAX _ FAILED _ HOSTS , " 0 " ) ) ; <nl> bufferSize = Integer . parseInt ( conf . get ( BUFFER _ SIZE _ IN _ MB , " 64 " ) ) ; <nl> + try <nl> + { <nl> + for ( String hostToIgnore : AbstractBulkOutputFormat . getIgnoreHosts ( conf ) ) <nl> + ignores . add ( InetAddress . getByName ( hostToIgnore ) ) ; <nl> + } <nl> + catch ( UnknownHostException e ) <nl> + { <nl> + throw new RuntimeException ( ( " Unknown host : " + e . getMessage ( ) ) ) ; <nl> + } <nl> } <nl> <nl> protected String getOutputLocation ( ) throws IOException <nl> @ @ - 119 , 7 + 131 , 7 @ @ implements org . apache . hadoop . mapred . RecordWriter < K , V > <nl> if ( writer ! = null ) <nl> { <nl> writer . close ( ) ; <nl> - Future < StreamState > future = loader . stream ( ) ; <nl> + Future < StreamState > future = loader . stream ( ignores ) ; <nl> while ( true ) <nl> { <nl> try
NEAREST DIFF (one line): diff - - git a / conf / storage - conf . xml b / conf / storage - conf . xml <nl> index 8aaeeb6 . . 25d2901 100644 <nl> - - - a / conf / storage - conf . xml <nl> + + + b / conf / storage - conf . xml <nl> @ @ - 308 , 4 + 308 , 19 @ @ <nl> ~ ten days . <nl> - - > <nl> < GCGraceSeconds > 864000 < / GCGraceSeconds > <nl> + <nl> + < ! - - <nl> + ~ Number of threads to run when flushing memtables to disk . Set this to <nl> + ~ the number of disks you physically have in your machine allocated for DataDirectory * 2 . <nl> + ~ If you are planning to use the Binary Memtable , its recommended to increase the max threads <nl> + ~ to maintain a higher quality of service while under load when normal memtables are flushing to disk . <nl> + - - > <nl> + < FlushMinThreads > 1 < / FlushMinThreads > <nl> + < FlushMaxThreads > 1 < / FlushMaxThreads > <nl> + <nl> + < ! - - <nl> + ~ The threshold size in megabytes the binary memtable must grow to , before it ' s submitted for flushing to disk . <nl> + - - > <nl> + < BinaryMemtableSizeInMB > 256 < / BinaryMemtableSizeInMB > <nl> + <nl> < / Storage > <nl> diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> index 9016676 . . e86b134 100644 <nl> - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java <nl> @ @ - 74 , 6 + 74 , 9 @ @ public class DatabaseDescriptor <nl> private static int slicedReadBufferSizeInKB _ = 64 ; <nl> private static List < String > tables _ = new ArrayList < String > ( ) ; <nl> private static Set < String > applicationColumnFamilies _ = new HashSet < String > ( ) ; <nl> + private static int flushMinThreads _ = 1 ; <nl> + private static int flushMaxThreads _ = 1 ; <nl> + private static int bmtThreshold _ = 256 ; <nl> <nl> / / Default descriptive names for introspection . The user can override <nl> / / these choices in the config file . These are not case sensitive . <nl> @ @ - 271 , 6 + 274 , 24 @ @ public class DatabaseDescriptor <nl> slicedReadBufferSizeInKB _ = Integer . parseInt ( rawSlicedBuffer ) ; <nl> } <nl> <nl> + String rawflushMinThreads = xmlUtils . getNodeValue ( " / Storage / FlushMinThreads " ) ; <nl> + if ( rawflushMinThreads ! = null ) <nl> + { <nl> + flushMinThreads _ = Integer . parseInt ( rawflushMinThreads ) ; <nl> + } <nl> + <nl> + String rawflushMaxThreads = xmlUtils . getNodeValue ( " / Storage / FlushMaxThreads " ) ; <nl> + if ( rawflushMaxThreads ! = null ) <nl> + { <nl> + flushMaxThreads _ = Integer . parseInt ( rawflushMaxThreads ) ; <nl> + } <nl> + <nl> + String bmtThreshold = xmlUtils . getNodeValue ( " / Storage / BinaryMemtableSizeInMB " ) ; <nl> + if ( bmtThreshold ! = null ) <nl> + { <nl> + bmtThreshold _ = Integer . parseInt ( bmtThreshold ) ; <nl> + } <nl> + <nl> / * TCP port on which the storage system listens * / <nl> String port = xmlUtils . getNodeValue ( " / Storage / StoragePort " ) ; <nl> if ( port ! = null ) <nl> @ @ - 999 , 4 + 1020 , 19 @ @ public class DatabaseDescriptor <nl> { <nl> return slicedReadBufferSizeInKB _ ; <nl> } <nl> + <nl> + public static int getFlushMinThreads ( ) <nl> + { <nl> + return flushMinThreads _ ; <nl> + } <nl> + <nl> + public static int getFlushMaxThreads ( ) <nl> + { <nl> + return flushMaxThreads _ ; <nl> + } <nl> + <nl> + public static int getBMTThreshold ( ) <nl> + { <nl> + return bmtThreshold _ ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / BinaryMemtable . java b / src / java / org / apache / cassandra / db / BinaryMemtable . java <nl> index 2cd439a . . 4530e8b 100644 <nl> - - - a / src / java / org / apache / cassandra / db / BinaryMemtable . java <nl> + + + b / src / java / org / apache / cassandra / db / BinaryMemtable . java <nl> @ @ - 34 , 11 + 34 , 13 @ @ import org . apache . cassandra . config . DatabaseDescriptor ; <nl> <nl> import org . apache . log4j . Logger ; <nl> import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; <nl> + import java . util . * ; <nl> + import org . apache . cassandra . dht . IPartitioner ; <nl> <nl> public class BinaryMemtable <nl> { <nl> private static Logger logger _ = Logger . getLogger ( Memtable . class ) ; <nl> - private int threshold _ = 512 * 1024 * 1024 ; <nl> + private int threshold _ = DatabaseDescriptor . getBMTThreshold ( ) * 1024 * 1024 ; <nl> private AtomicInteger currentSize _ = new AtomicInteger ( 0 ) ; <nl> <nl> / * Table and ColumnFamily name are used to determine the ColumnFamilyStore * / <nl> @ @ - 138 , 10 + 140 , 31 @ @ public class BinaryMemtable <nl> * Use the SSTable to write the contents of the TreeMap <nl> * to disk . <nl> * / <nl> + <nl> + String path ; <nl> + SSTableWriter writer ; <nl> ColumnFamilyStore cfStore = Table . open ( table _ ) . getColumnFamilyStore ( cfName _ ) ; <nl> List < String > keys = new ArrayList < String > ( columnFamilies _ . keySet ( ) ) ; <nl> - SSTableWriter writer = new SSTableWriter ( cfStore . getTempSSTablePath ( ) , keys . size ( ) , StorageService . getPartitioner ( ) ) ; <nl> - Collections . sort ( keys ) ; <nl> + / * <nl> + Adding a lock here so data directories are evenly used . By default currentIndex <nl> + is incremented , not an AtomicInteger . Let ' s fix this ! <nl> + * / <nl> + lock _ . lock ( ) ; <nl> + try <nl> + { <nl> + path = cfStore . getTempSSTablePath ( ) ; <nl> + writer = new SSTableWriter ( path , keys . size ( ) , StorageService . getPartitioner ( ) ) ; <nl> + } <nl> + finally <nl> + { <nl> + lock _ . unlock ( ) ; <nl> + } <nl> + <nl> + final IPartitioner partitioner = StorageService . getPartitioner ( ) ; <nl> + final Comparator < String > dc = partitioner . getDecoratedKeyComparator ( ) ; <nl> + Collections . sort ( keys , dc ) ; <nl> + <nl> + <nl> / * Use this BloomFilter to decide if a key exists in a SSTable * / <nl> for ( String key : keys ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> index b08cf6b . . af6e247 100644 <nl> - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java <nl> @ @ - 38 , 6 + 38 , 7 @ @ import org . apache . cassandra . net . EndPoint ; <nl> import org . apache . cassandra . service . StorageService ; <nl> import org . apache . cassandra . utils . * ; <nl> import org . apache . cassandra . concurrent . DebuggableThreadPoolExecutor ; <nl> + import org . apache . cassandra . concurrent . ThreadFactoryImpl ; <nl> import org . apache . cassandra . db . filter . * ; <nl> import org . apache . cassandra . db . marshal . AbstractType ; <nl> <nl> @ @ - 55 , 8 + 56 , 8 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> private static final int BUFSIZE = 128 * 1024 * 1024 ; <nl> <nl> private static NonBlockingHashMap < String , Set < Memtable > > memtablesPendingFlush = new NonBlockingHashMap < String , Set < Memtable > > ( ) ; <nl> - private static ExecutorService flusher _ = new DebuggableThreadPoolExecutor ( " MEMTABLE - FLUSHER - POOL " ) ; <nl> - <nl> + private static ExecutorService flusher _ = new DebuggableThreadPoolExecutor ( DatabaseDescriptor . getFlushMinThreads ( ) , DatabaseDescriptor . getFlushMaxThreads ( ) , Integer . MAX _ VALUE , TimeUnit . SECONDS , new LinkedBlockingQueue < Runnable > ( ) , new ThreadFactoryImpl ( " MEMTABLE - FLUSHER - POOL " ) ) ; <nl> + <nl> private final String table _ ; <nl> public final String columnFamily _ ; <nl> private final boolean isSuper _ ; <nl> @ @ - 457 , 7 + 458 , 7 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean <nl> assert oldMemtable . isFlushed ( ) | | oldMemtable . isClean ( ) ; <nl> } <nl> <nl> - void forceFlushBinary ( ) <nl> + public void forceFlushBinary ( ) <nl> { <nl> submitFlush ( binaryMemtable _ . get ( ) ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / db / Table . java b / src / java / org / apache / cassandra / db / Table . java <nl> index 54389e5 . . 04b28fb 100644 <nl> - - - a / src / java / org / apache / cassandra / db / Table . java <nl> + + + b / src / java / org / apache / cassandra / db / Table . java <nl> @ @ - 642 , 11 + 642 , 11 @ @ public class Table <nl> for ( ColumnFamily columnFamily : row . getColumnFamilies ( ) ) <nl> { <nl> Collection < IColumn > columns = columnFamily . getSortedColumns ( ) ; <nl> - for ( IColumn column : columns ) <nl> + for ( IColumn column : columns ) <nl> { <nl> - ColumnFamilyStore cfStore = columnFamilyStores _ . get ( column . name ( ) ) ; <nl> + ColumnFamilyStore cfStore = columnFamilyStores _ . get ( new String ( column . name ( ) , " UTF - 8 " ) ) ; <nl> cfStore . applyBinary ( key , column . value ( ) ) ; <nl> - 	 } <nl> + } <nl> } <nl> row . clear ( ) ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / net / MessagingService . java b / src / java / org / apache / cassandra / net / MessagingService . java <nl> index 954324b . . 21f97d2 100644 <nl> - - - a / src / java / org / apache / cassandra / net / MessagingService . java <nl> + + + b / src / java / org / apache / cassandra / net / MessagingService . java <nl> @ @ - 478 , 14 + 478 , 26 @ @ public class MessagingService implements IMessagingService <nl> { <nl> isStreaming _ . set ( bVal ) ; <nl> } <nl> + public static void flushAndshutdown ( ) <nl> + { <nl> + / / safely shutdown and send all writes <nl> + for ( Map . Entry < String , TcpConnectionManager > entry : poolTable _ . entrySet ( ) ) <nl> + { <nl> + for ( TcpConnection connection : entry . getValue ( ) . getConnections ( ) ) <nl> + { <nl> + connection . doPendingWrites ( ) ; <nl> + } <nl> + } <nl> + shutdown ( ) ; <nl> + } <nl> <nl> public static void shutdown ( ) <nl> { <nl> logger _ . info ( " Shutting down . . . " ) ; <nl> - synchronized ( MessagingService . class ) <nl> - { <nl> - / * Stop listening on any socket * / <nl> - for ( SelectionKey skey : listenSockets _ . values ( ) ) <nl> + synchronized ( MessagingService . class ) <nl> + { <nl> + / * Stop listening on any socket * / <nl> + for ( SelectionKey skey : listenSockets _ . values ( ) ) <nl> { <nl> skey . cancel ( ) ; <nl> try <nl> @ @ - 495 , 26 + 507 , 25 @ @ public class MessagingService implements IMessagingService <nl> catch ( IOException e ) { } <nl> } <nl> listenSockets _ . clear ( ) ; <nl> - <nl> - / * Shutdown the threads in the EventQueue ' s * / <nl> - messageDeserializationExecutor _ . shutdownNow ( ) ; <nl> + <nl> + / * Shutdown the threads in the EventQueue ' s * / <nl> + messageDeserializationExecutor _ . shutdownNow ( ) ; <nl> messageSerializerExecutor _ . shutdownNow ( ) ; <nl> messageDeserializerExecutor _ . shutdownNow ( ) ; <nl> streamExecutor _ . shutdownNow ( ) ; <nl> - <nl> + <nl> / * shut down the cachetables * / <nl> taskCompletionMap _ . shutdown ( ) ; <nl> - callbackMap _ . shutdown ( ) ; <nl> - <nl> + callbackMap _ . shutdown ( ) ; <nl> + <nl> / * Interrupt the selector manager thread * / <nl> SelectorManager . getSelectorManager ( ) . interrupt ( ) ; <nl> - <nl> - poolTable _ . clear ( ) ; <nl> - verbHandlers _ . clear ( ) ; <nl> + <nl> + poolTable _ . clear ( ) ; <nl> + verbHandlers _ . clear ( ) ; <nl> bShutdown _ = true ; <nl> } <nl> - if ( logger _ . isDebugEnabled ( ) ) <nl> - logger _ . debug ( " Shutdown invocation complete . " ) ; <nl> + logger _ . info ( " Shutdown invocation complete . " ) ; <nl> } <nl> <nl> public static void receive ( Message message ) <nl> diff - - git a / src / java / org / apache / cassandra / net / TcpConnection . java b / src / java / org / apache / cassandra / net / TcpConnection . java <nl> index 5039833 . . 08afda8 100644 <nl> - - - a / src / java / org / apache / cassandra / net / TcpConnection . java <nl> + + + b / src / java / org / apache / cassandra / net / TcpConnection . java <nl> @ @ - 387 , 7 + 387 , 7 @ @ public class TcpConnection extends SelectionKeyHandler implements Comparable <nl> resumeStreaming ( ) ; <nl> } <nl> <nl> - void doPendingWrites ( ) <nl> + public void doPendingWrites ( ) <nl> { <nl> synchronized ( this ) <nl> { <nl> diff - - git a / src / java / org / apache / cassandra / net / TcpConnectionManager . java b / src / java / org / apache / cassandra / net / TcpConnectionManager . java <nl> index e29eb9d . . b8fa909 100644 <nl> - - - a / src / java / org / apache / cassandra / net / TcpConnectionManager . java <nl> + + + b / src / java / org / apache / cassandra / net / TcpConnectionManager . java <nl> @ @ - 211 , 4 + 211 , 8 @ @ class TcpConnectionManager <nl> { <nl> return allConnections _ . contains ( connection ) ; <nl> } <nl> + List < TcpConnection > getConnections ( ) <nl> + { <nl> + return allConnections _ ; <nl> + } <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java <nl> index 62cc110 . . 0e2dd24 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageService . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageService . java <nl> @ @ - 778 , 6 + 778 , 24 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto <nl> logger _ . debug ( " Cleared out all snapshot directories " ) ; <nl> } <nl> <nl> + public void forceTableFlushBinary ( String tableName ) throws IOException <nl> + { <nl> + if ( DatabaseDescriptor . getTable ( tableName ) = = null ) <nl> + { <nl> + throw new IOException ( " Table " + tableName + " does not exist " ) ; <nl> + } <nl> + <nl> + Table table = Table . open ( tableName ) ; <nl> + Set < String > columnFamilies = table . getColumnFamilies ( ) ; <nl> + for ( String columnFamily : columnFamilies ) <nl> + { <nl> + ColumnFamilyStore cfStore = table . getColumnFamilyStore ( columnFamily ) ; <nl> + logger _ . debug ( " Forcing flush on keyspace " + tableName + " on CF " + columnFamily ) ; <nl> + cfStore . forceFlushBinary ( ) ; <nl> + } <nl> + } <nl> + <nl> + <nl> / * End of MBean interface methods * / <nl> <nl> / * * <nl> diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> index 2e21ecb . . 046fb26 100644 <nl> - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java <nl> @ @ - 84 , 4 + 84 , 11 @ @ public interface StorageServiceMBean <nl> * Remove all the existing snapshots . <nl> * / <nl> public void clearSnapshot ( ) throws IOException ; <nl> + <nl> + / * * <nl> + * Flush all binary memtables for a table <nl> + * @ param tableName <nl> + * @ throws IOException <nl> + * / <nl> + public void forceTableFlushBinary ( String tableName ) throws IOException ; <nl> } <nl> diff - - git a / src / java / org / apache / cassandra / tools / NodeProbe . java b / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> index f0df925 . . b6d846f 100644 <nl> - - - a / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> + + + b / src / java / org / apache / cassandra / tools / NodeProbe . java <nl> @ @ - 257 , 7 + 257 , 16 @ @ public class NodeProbe <nl> { <nl> ssProxy . forceTableCompaction ( ) ; <nl> } <nl> - <nl> + <nl> + / * * <nl> + * Trigger a binary flush on CFs of a table . <nl> + * / <nl> + public void forceTableFlushBinary ( String tableName ) throws IOException <nl> + { <nl> + ssProxy . forceTableFlushBinary ( tableName ) ; <nl> + } <nl> + <nl> + <nl> / * * <nl> * Write a textual representation of the Cassandra ring . <nl> * <nl> @ @ - 517 , 7 + 526 , 7 @ @ public class NodeProbe <nl> { <nl> HelpFormatter hf = new HelpFormatter ( ) ; <nl> String header = String . format ( <nl> - " % nAvailable commands : ring , cluster , info , cleanup , compact , cfstats , snapshot [ name ] , clearsnapshot , bootstrap , tpstats " ) ; <nl> + " % nAvailable commands : ring , cluster , info , cleanup , compact , cfstats , snapshot [ name ] , clearsnapshot , bootstrap , tpstats , flush _ binary " ) ; <nl> String usage = String . format ( " java % s - host < arg > < command > % n " , NodeProbe . class . getName ( ) ) ; <nl> hf . printHelp ( usage , " " , options , header ) ; <nl> } <nl> @ @ - 609 , 6 + 618 , 16 @ @ public class NodeProbe <nl> { <nl> probe . printThreadPoolStats ( System . out ) ; <nl> } <nl> + else if ( cmdName . equals ( " flush _ binary " ) ) <nl> + { <nl> + if ( probe . getArgs ( ) . length < 2 ) <nl> + { <nl> + System . err . println ( " Missing keyspace argument . " ) ; <nl> + NodeProbe . printUsage ( ) ; <nl> + System . exit ( 1 ) ; <nl> + } <nl> + probe . forceTableFlushBinary ( probe . getArgs ( ) [ 1 ] ) ; <nl> + } <nl> else <nl> { <nl> System . err . println ( " Unrecognized command : " + cmdName + " . " ) ;

TEST DIFF:
diff - - git a / CHANGES . txt b / CHANGES . txt 
 index 0ad2b36 . . eec8161 100644 
 - - - a / CHANGES . txt 
 + + + b / CHANGES . txt 
 @ @ - 1 , 4 + 1 , 5 @ @ 
 2 . 1 . 10 
 + * Bulk Loader API could not tolerate even node failure ( CASSANDRA - 10347 ) 
 * Avoid misleading pushed notifications when multiple nodes 
 share an rpc _ address ( CASSANDRA - 10052 ) 
 * Fix dropping undroppable when message queue is full ( CASSANDRA - 10113 ) 
 diff - - git a / src / java / org / apache / cassandra / hadoop / AbstractBulkOutputFormat . java b / src / java / org / apache / cassandra / hadoop / AbstractBulkOutputFormat . java 
 index c0e91da . . e893ba6 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / AbstractBulkOutputFormat . java 
 + + + b / src / java / org / apache / cassandra / hadoop / AbstractBulkOutputFormat . java 
 @ @ - 19 , 6 + 19 , 7 @ @ package org . apache . cassandra . hadoop ; 
 
 
 import java . io . IOException ; 
 + import java . util . Collection ; 
 
 import org . apache . hadoop . conf . Configuration ; 
 import org . apache . hadoop . mapreduce . * ; 
 @ @ - 70 , 4 + 71 , 35 @ @ public abstract class AbstractBulkOutputFormat < K , V > extends OutputFormat < K , V > 
 
 public void setupTask ( TaskAttemptContext taskContext ) { } 
 } 
 + 
 + / * * 
 + * Set the hosts to ignore as comma delimited values . 
 + * Data will not be bulk loaded onto the ignored nodes . 
 + * @ param conf job configuration 
 + * @ param ignoreNodesCsv a comma delimited list of nodes to ignore 
 + * / 
 + public static void setIgnoreHosts ( Configuration conf , String ignoreNodesCsv ) 
 + { 
 + conf . set ( AbstractBulkRecordWriter . IGNORE _ HOSTS , ignoreNodesCsv ) ; 
 + } 
 + 
 + / * * 
 + * Set the hosts to ignore . Data will not be bulk loaded onto the ignored nodes . 
 + * @ param conf job configuration 
 + * @ param ignoreNodes the nodes to ignore 
 + * / 
 + public static void setIgnoreHosts ( Configuration conf , String . . . ignoreNodes ) 
 + { 
 + conf . setStrings ( AbstractBulkRecordWriter . IGNORE _ HOSTS , ignoreNodes ) ; 
 + } 
 + 
 + / * * 
 + * Get the hosts to ignore as a collection of strings 
 + * @ param conf job configuration 
 + * @ return the nodes to ignore as a collection of stirngs 
 + * / 
 + public static Collection < String > getIgnoreHosts ( Configuration conf ) 
 + { 
 + return conf . getStringCollection ( AbstractBulkRecordWriter . IGNORE _ HOSTS ) ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / hadoop / AbstractBulkRecordWriter . java b / src / java / org / apache / cassandra / hadoop / AbstractBulkRecordWriter . java 
 index 22255a6 . . f9322c7 100644 
 - - - a / src / java / org / apache / cassandra / hadoop / AbstractBulkRecordWriter . java 
 + + + b / src / java / org / apache / cassandra / hadoop / AbstractBulkRecordWriter . java 
 @ @ - 21 , 6 + 21 , 7 @ @ import java . io . Closeable ; 
 import java . io . IOException ; 
 import java . net . InetAddress ; 
 import java . net . UnknownHostException ; 
 + import java . util . Collection ; 
 import java . util . HashMap ; 
 import java . util . HashSet ; 
 import java . util . Iterator ; 
 @ @ - 60 , 12 + 61 , 14 @ @ implements org . apache . hadoop . mapred . RecordWriter < K , V > 
 public final static String BUFFER _ SIZE _ IN _ MB = " mapreduce . output . bulkoutputformat . buffersize " ; 
 public final static String STREAM _ THROTTLE _ MBITS = " mapreduce . output . bulkoutputformat . streamthrottlembits " ; 
 public final static String MAX _ FAILED _ HOSTS = " mapreduce . output . bulkoutputformat . maxfailedhosts " ; 
 + public static final String IGNORE _ HOSTS = " mapreduce . output . bulkoutputformat . ignorehosts " ; 
 
 private final Logger logger = LoggerFactory . getLogger ( AbstractBulkRecordWriter . class ) ; 
 
 protected final Configuration conf ; 
 protected final int maxFailures ; 
 - protected final int bufferSize ; 
 + protected final int bufferSize ; 
 + protected final Set < InetAddress > ignores = new HashSet < > ( ) ; 
 protected Closeable writer ; 
 protected SSTableLoader loader ; 
 protected Progressable progress ; 
 @ @ - 91 , 6 + 94 , 15 @ @ implements org . apache . hadoop . mapred . RecordWriter < K , V > 
 DatabaseDescriptor . setStreamThroughputOutboundMegabitsPerSec ( Integer . parseInt ( conf . get ( STREAM _ THROTTLE _ MBITS , " 0 " ) ) ) ; 
 maxFailures = Integer . parseInt ( conf . get ( MAX _ FAILED _ HOSTS , " 0 " ) ) ; 
 bufferSize = Integer . parseInt ( conf . get ( BUFFER _ SIZE _ IN _ MB , " 64 " ) ) ; 
 + try 
 + { 
 + for ( String hostToIgnore : AbstractBulkOutputFormat . getIgnoreHosts ( conf ) ) 
 + ignores . add ( InetAddress . getByName ( hostToIgnore ) ) ; 
 + } 
 + catch ( UnknownHostException e ) 
 + { 
 + throw new RuntimeException ( ( " Unknown host : " + e . getMessage ( ) ) ) ; 
 + } 
 } 
 
 protected String getOutputLocation ( ) throws IOException 
 @ @ - 119 , 7 + 131 , 7 @ @ implements org . apache . hadoop . mapred . RecordWriter < K , V > 
 if ( writer ! = null ) 
 { 
 writer . close ( ) ; 
 - Future < StreamState > future = loader . stream ( ) ; 
 + Future < StreamState > future = loader . stream ( ignores ) ; 
 while ( true ) 
 { 
 try

NEAREST DIFF:
diff - - git a / conf / storage - conf . xml b / conf / storage - conf . xml 
 index 8aaeeb6 . . 25d2901 100644 
 - - - a / conf / storage - conf . xml 
 + + + b / conf / storage - conf . xml 
 @ @ - 308 , 4 + 308 , 19 @ @ 
 ~ ten days . 
 - - > 
 < GCGraceSeconds > 864000 < / GCGraceSeconds > 
 + 
 + < ! - - 
 + ~ Number of threads to run when flushing memtables to disk . Set this to 
 + ~ the number of disks you physically have in your machine allocated for DataDirectory * 2 . 
 + ~ If you are planning to use the Binary Memtable , its recommended to increase the max threads 
 + ~ to maintain a higher quality of service while under load when normal memtables are flushing to disk . 
 + - - > 
 + < FlushMinThreads > 1 < / FlushMinThreads > 
 + < FlushMaxThreads > 1 < / FlushMaxThreads > 
 + 
 + < ! - - 
 + ~ The threshold size in megabytes the binary memtable must grow to , before it ' s submitted for flushing to disk . 
 + - - > 
 + < BinaryMemtableSizeInMB > 256 < / BinaryMemtableSizeInMB > 
 + 
 < / Storage > 
 diff - - git a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 index 9016676 . . e86b134 100644 
 - - - a / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 + + + b / src / java / org / apache / cassandra / config / DatabaseDescriptor . java 
 @ @ - 74 , 6 + 74 , 9 @ @ public class DatabaseDescriptor 
 private static int slicedReadBufferSizeInKB _ = 64 ; 
 private static List < String > tables _ = new ArrayList < String > ( ) ; 
 private static Set < String > applicationColumnFamilies _ = new HashSet < String > ( ) ; 
 + private static int flushMinThreads _ = 1 ; 
 + private static int flushMaxThreads _ = 1 ; 
 + private static int bmtThreshold _ = 256 ; 
 
 / / Default descriptive names for introspection . The user can override 
 / / these choices in the config file . These are not case sensitive . 
 @ @ - 271 , 6 + 274 , 24 @ @ public class DatabaseDescriptor 
 slicedReadBufferSizeInKB _ = Integer . parseInt ( rawSlicedBuffer ) ; 
 } 
 
 + String rawflushMinThreads = xmlUtils . getNodeValue ( " / Storage / FlushMinThreads " ) ; 
 + if ( rawflushMinThreads ! = null ) 
 + { 
 + flushMinThreads _ = Integer . parseInt ( rawflushMinThreads ) ; 
 + } 
 + 
 + String rawflushMaxThreads = xmlUtils . getNodeValue ( " / Storage / FlushMaxThreads " ) ; 
 + if ( rawflushMaxThreads ! = null ) 
 + { 
 + flushMaxThreads _ = Integer . parseInt ( rawflushMaxThreads ) ; 
 + } 
 + 
 + String bmtThreshold = xmlUtils . getNodeValue ( " / Storage / BinaryMemtableSizeInMB " ) ; 
 + if ( bmtThreshold ! = null ) 
 + { 
 + bmtThreshold _ = Integer . parseInt ( bmtThreshold ) ; 
 + } 
 + 
 / * TCP port on which the storage system listens * / 
 String port = xmlUtils . getNodeValue ( " / Storage / StoragePort " ) ; 
 if ( port ! = null ) 
 @ @ - 999 , 4 + 1020 , 19 @ @ public class DatabaseDescriptor 
 { 
 return slicedReadBufferSizeInKB _ ; 
 } 
 + 
 + public static int getFlushMinThreads ( ) 
 + { 
 + return flushMinThreads _ ; 
 + } 
 + 
 + public static int getFlushMaxThreads ( ) 
 + { 
 + return flushMaxThreads _ ; 
 + } 
 + 
 + public static int getBMTThreshold ( ) 
 + { 
 + return bmtThreshold _ ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / BinaryMemtable . java b / src / java / org / apache / cassandra / db / BinaryMemtable . java 
 index 2cd439a . . 4530e8b 100644 
 - - - a / src / java / org / apache / cassandra / db / BinaryMemtable . java 
 + + + b / src / java / org / apache / cassandra / db / BinaryMemtable . java 
 @ @ - 34 , 11 + 34 , 13 @ @ import org . apache . cassandra . config . DatabaseDescriptor ; 
 
 import org . apache . log4j . Logger ; 
 import org . cliffc . high _ scale _ lib . NonBlockingHashMap ; 
 + import java . util . * ; 
 + import org . apache . cassandra . dht . IPartitioner ; 
 
 public class BinaryMemtable 
 { 
 private static Logger logger _ = Logger . getLogger ( Memtable . class ) ; 
 - private int threshold _ = 512 * 1024 * 1024 ; 
 + private int threshold _ = DatabaseDescriptor . getBMTThreshold ( ) * 1024 * 1024 ; 
 private AtomicInteger currentSize _ = new AtomicInteger ( 0 ) ; 
 
 / * Table and ColumnFamily name are used to determine the ColumnFamilyStore * / 
 @ @ - 138 , 10 + 140 , 31 @ @ public class BinaryMemtable 
 * Use the SSTable to write the contents of the TreeMap 
 * to disk . 
 * / 
 + 
 + String path ; 
 + SSTableWriter writer ; 
 ColumnFamilyStore cfStore = Table . open ( table _ ) . getColumnFamilyStore ( cfName _ ) ; 
 List < String > keys = new ArrayList < String > ( columnFamilies _ . keySet ( ) ) ; 
 - SSTableWriter writer = new SSTableWriter ( cfStore . getTempSSTablePath ( ) , keys . size ( ) , StorageService . getPartitioner ( ) ) ; 
 - Collections . sort ( keys ) ; 
 + / * 
 + Adding a lock here so data directories are evenly used . By default currentIndex 
 + is incremented , not an AtomicInteger . Let ' s fix this ! 
 + * / 
 + lock _ . lock ( ) ; 
 + try 
 + { 
 + path = cfStore . getTempSSTablePath ( ) ; 
 + writer = new SSTableWriter ( path , keys . size ( ) , StorageService . getPartitioner ( ) ) ; 
 + } 
 + finally 
 + { 
 + lock _ . unlock ( ) ; 
 + } 
 + 
 + final IPartitioner partitioner = StorageService . getPartitioner ( ) ; 
 + final Comparator < String > dc = partitioner . getDecoratedKeyComparator ( ) ; 
 + Collections . sort ( keys , dc ) ; 
 + 
 + 
 / * Use this BloomFilter to decide if a key exists in a SSTable * / 
 for ( String key : keys ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 index b08cf6b . . af6e247 100644 
 - - - a / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 + + + b / src / java / org / apache / cassandra / db / ColumnFamilyStore . java 
 @ @ - 38 , 6 + 38 , 7 @ @ import org . apache . cassandra . net . EndPoint ; 
 import org . apache . cassandra . service . StorageService ; 
 import org . apache . cassandra . utils . * ; 
 import org . apache . cassandra . concurrent . DebuggableThreadPoolExecutor ; 
 + import org . apache . cassandra . concurrent . ThreadFactoryImpl ; 
 import org . apache . cassandra . db . filter . * ; 
 import org . apache . cassandra . db . marshal . AbstractType ; 
 
 @ @ - 55 , 8 + 56 , 8 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 private static final int BUFSIZE = 128 * 1024 * 1024 ; 
 
 private static NonBlockingHashMap < String , Set < Memtable > > memtablesPendingFlush = new NonBlockingHashMap < String , Set < Memtable > > ( ) ; 
 - private static ExecutorService flusher _ = new DebuggableThreadPoolExecutor ( " MEMTABLE - FLUSHER - POOL " ) ; 
 - 
 + private static ExecutorService flusher _ = new DebuggableThreadPoolExecutor ( DatabaseDescriptor . getFlushMinThreads ( ) , DatabaseDescriptor . getFlushMaxThreads ( ) , Integer . MAX _ VALUE , TimeUnit . SECONDS , new LinkedBlockingQueue < Runnable > ( ) , new ThreadFactoryImpl ( " MEMTABLE - FLUSHER - POOL " ) ) ; 
 + 
 private final String table _ ; 
 public final String columnFamily _ ; 
 private final boolean isSuper _ ; 
 @ @ - 457 , 7 + 458 , 7 @ @ public final class ColumnFamilyStore implements ColumnFamilyStoreMBean 
 assert oldMemtable . isFlushed ( ) | | oldMemtable . isClean ( ) ; 
 } 
 
 - void forceFlushBinary ( ) 
 + public void forceFlushBinary ( ) 
 { 
 submitFlush ( binaryMemtable _ . get ( ) ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / db / Table . java b / src / java / org / apache / cassandra / db / Table . java 
 index 54389e5 . . 04b28fb 100644 
 - - - a / src / java / org / apache / cassandra / db / Table . java 
 + + + b / src / java / org / apache / cassandra / db / Table . java 
 @ @ - 642 , 11 + 642 , 11 @ @ public class Table 
 for ( ColumnFamily columnFamily : row . getColumnFamilies ( ) ) 
 { 
 Collection < IColumn > columns = columnFamily . getSortedColumns ( ) ; 
 - for ( IColumn column : columns ) 
 + for ( IColumn column : columns ) 
 { 
 - ColumnFamilyStore cfStore = columnFamilyStores _ . get ( column . name ( ) ) ; 
 + ColumnFamilyStore cfStore = columnFamilyStores _ . get ( new String ( column . name ( ) , " UTF - 8 " ) ) ; 
 cfStore . applyBinary ( key , column . value ( ) ) ; 
 - 	 } 
 + } 
 } 
 row . clear ( ) ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / net / MessagingService . java b / src / java / org / apache / cassandra / net / MessagingService . java 
 index 954324b . . 21f97d2 100644 
 - - - a / src / java / org / apache / cassandra / net / MessagingService . java 
 + + + b / src / java / org / apache / cassandra / net / MessagingService . java 
 @ @ - 478 , 14 + 478 , 26 @ @ public class MessagingService implements IMessagingService 
 { 
 isStreaming _ . set ( bVal ) ; 
 } 
 + public static void flushAndshutdown ( ) 
 + { 
 + / / safely shutdown and send all writes 
 + for ( Map . Entry < String , TcpConnectionManager > entry : poolTable _ . entrySet ( ) ) 
 + { 
 + for ( TcpConnection connection : entry . getValue ( ) . getConnections ( ) ) 
 + { 
 + connection . doPendingWrites ( ) ; 
 + } 
 + } 
 + shutdown ( ) ; 
 + } 
 
 public static void shutdown ( ) 
 { 
 logger _ . info ( " Shutting down . . . " ) ; 
 - synchronized ( MessagingService . class ) 
 - { 
 - / * Stop listening on any socket * / 
 - for ( SelectionKey skey : listenSockets _ . values ( ) ) 
 + synchronized ( MessagingService . class ) 
 + { 
 + / * Stop listening on any socket * / 
 + for ( SelectionKey skey : listenSockets _ . values ( ) ) 
 { 
 skey . cancel ( ) ; 
 try 
 @ @ - 495 , 26 + 507 , 25 @ @ public class MessagingService implements IMessagingService 
 catch ( IOException e ) { } 
 } 
 listenSockets _ . clear ( ) ; 
 - 
 - / * Shutdown the threads in the EventQueue ' s * / 
 - messageDeserializationExecutor _ . shutdownNow ( ) ; 
 + 
 + / * Shutdown the threads in the EventQueue ' s * / 
 + messageDeserializationExecutor _ . shutdownNow ( ) ; 
 messageSerializerExecutor _ . shutdownNow ( ) ; 
 messageDeserializerExecutor _ . shutdownNow ( ) ; 
 streamExecutor _ . shutdownNow ( ) ; 
 - 
 + 
 / * shut down the cachetables * / 
 taskCompletionMap _ . shutdown ( ) ; 
 - callbackMap _ . shutdown ( ) ; 
 - 
 + callbackMap _ . shutdown ( ) ; 
 + 
 / * Interrupt the selector manager thread * / 
 SelectorManager . getSelectorManager ( ) . interrupt ( ) ; 
 - 
 - poolTable _ . clear ( ) ; 
 - verbHandlers _ . clear ( ) ; 
 + 
 + poolTable _ . clear ( ) ; 
 + verbHandlers _ . clear ( ) ; 
 bShutdown _ = true ; 
 } 
 - if ( logger _ . isDebugEnabled ( ) ) 
 - logger _ . debug ( " Shutdown invocation complete . " ) ; 
 + logger _ . info ( " Shutdown invocation complete . " ) ; 
 } 
 
 public static void receive ( Message message ) 
 diff - - git a / src / java / org / apache / cassandra / net / TcpConnection . java b / src / java / org / apache / cassandra / net / TcpConnection . java 
 index 5039833 . . 08afda8 100644 
 - - - a / src / java / org / apache / cassandra / net / TcpConnection . java 
 + + + b / src / java / org / apache / cassandra / net / TcpConnection . java 
 @ @ - 387 , 7 + 387 , 7 @ @ public class TcpConnection extends SelectionKeyHandler implements Comparable 
 resumeStreaming ( ) ; 
 } 
 
 - void doPendingWrites ( ) 
 + public void doPendingWrites ( ) 
 { 
 synchronized ( this ) 
 { 
 diff - - git a / src / java / org / apache / cassandra / net / TcpConnectionManager . java b / src / java / org / apache / cassandra / net / TcpConnectionManager . java 
 index e29eb9d . . b8fa909 100644 
 - - - a / src / java / org / apache / cassandra / net / TcpConnectionManager . java 
 + + + b / src / java / org / apache / cassandra / net / TcpConnectionManager . java 
 @ @ - 211 , 4 + 211 , 8 @ @ class TcpConnectionManager 
 { 
 return allConnections _ . contains ( connection ) ; 
 } 
 + List < TcpConnection > getConnections ( ) 
 + { 
 + return allConnections _ ; 
 + } 
 } 
 diff - - git a / src / java / org / apache / cassandra / service / StorageService . java b / src / java / org / apache / cassandra / service / StorageService . java 
 index 62cc110 . . 0e2dd24 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageService . java 
 + + + b / src / java / org / apache / cassandra / service / StorageService . java 
 @ @ - 778 , 6 + 778 , 24 @ @ public final class StorageService implements IEndPointStateChangeSubscriber , Sto 
 logger _ . debug ( " Cleared out all snapshot directories " ) ; 
 } 
 
 + public void forceTableFlushBinary ( String tableName ) throws IOException 
 + { 
 + if ( DatabaseDescriptor . getTable ( tableName ) = = null ) 
 + { 
 + throw new IOException ( " Table " + tableName + " does not exist " ) ; 
 + } 
 + 
 + Table table = Table . open ( tableName ) ; 
 + Set < String > columnFamilies = table . getColumnFamilies ( ) ; 
 + for ( String columnFamily : columnFamilies ) 
 + { 
 + ColumnFamilyStore cfStore = table . getColumnFamilyStore ( columnFamily ) ; 
 + logger _ . debug ( " Forcing flush on keyspace " + tableName + " on CF " + columnFamily ) ; 
 + cfStore . forceFlushBinary ( ) ; 
 + } 
 + } 
 + 
 + 
 / * End of MBean interface methods * / 
 
 / * * 
 diff - - git a / src / java / org / apache / cassandra / service / StorageServiceMBean . java b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 index 2e21ecb . . 046fb26 100644 
 - - - a / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 + + + b / src / java / org / apache / cassandra / service / StorageServiceMBean . java 
 @ @ - 84 , 4 + 84 , 11 @ @ public interface StorageServiceMBean 
 * Remove all the existing snapshots . 
 * / 
 public void clearSnapshot ( ) throws IOException ; 
 + 
 + / * * 
 + * Flush all binary memtables for a table 
 + * @ param tableName 
 + * @ throws IOException 
 + * / 
 + public void forceTableFlushBinary ( String tableName ) throws IOException ; 
 } 
 diff - - git a / src / java / org / apache / cassandra / tools / NodeProbe . java b / src / java / org / apache / cassandra / tools / NodeProbe . java 
 index f0df925 . . b6d846f 100644 
 - - - a / src / java / org / apache / cassandra / tools / NodeProbe . java 
 + + + b / src / java / org / apache / cassandra / tools / NodeProbe . java 
 @ @ - 257 , 7 + 257 , 16 @ @ public class NodeProbe 
 { 
 ssProxy . forceTableCompaction ( ) ; 
 } 
 - 
 + 
 + / * * 
 + * Trigger a binary flush on CFs of a table . 
 + * / 
 + public void forceTableFlushBinary ( String tableName ) throws IOException 
 + { 
 + ssProxy . forceTableFlushBinary ( tableName ) ; 
 + } 
 + 
 + 
 / * * 
 * Write a textual representation of the Cassandra ring . 
 * 
 @ @ - 517 , 7 + 526 , 7 @ @ public class NodeProbe 
 { 
 HelpFormatter hf = new HelpFormatter ( ) ; 
 String header = String . format ( 
 - " % nAvailable commands : ring , cluster , info , cleanup , compact , cfstats , snapshot [ name ] , clearsnapshot , bootstrap , tpstats " ) ; 
 + " % nAvailable commands : ring , cluster , info , cleanup , compact , cfstats , snapshot [ name ] , clearsnapshot , bootstrap , tpstats , flush _ binary " ) ; 
 String usage = String . format ( " java % s - host < arg > < command > % n " , NodeProbe . class . getName ( ) ) ; 
 hf . printHelp ( usage , " " , options , header ) ; 
 } 
 @ @ - 609 , 6 + 618 , 16 @ @ public class NodeProbe 
 { 
 probe . printThreadPoolStats ( System . out ) ; 
 } 
 + else if ( cmdName . equals ( " flush _ binary " ) ) 
 + { 
 + if ( probe . getArgs ( ) . length < 2 ) 
 + { 
 + System . err . println ( " Missing keyspace argument . " ) ; 
 + NodeProbe . printUsage ( ) ; 
 + System . exit ( 1 ) ; 
 + } 
 + probe . forceTableFlushBinary ( probe . getArgs ( ) [ 1 ] ) ; 
 + } 
 else 
 { 
 System . err . println ( " Unrecognized command : " + cmdName + " . " ) ;
